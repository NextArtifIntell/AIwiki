<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AIR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="air---449">AIR - 449</h2>
<ul>
<li><details>
<summary>
(2023). Correction to: Estimation of most effected cycles and
busiest network route based on complexity function of graph in fuzzy
environment. <em>AIR</em>, <em>56</em>(12), 15567. (<a
href="https://doi.org/10.1007/s10462-023-10495-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIR},
  author       = {Ghorai, Ganesh and Poulik, Soumitra},
  doi          = {10.1007/s10462-023-10495-3},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {15567},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Correction to: Estimation of most effected cycles and busiest network route based on complexity function of graph in fuzzy environment},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). AFOX: A new adaptive nature-inspired optimization
algorithm. <em>AIR</em>, <em>56</em>(12), 15523–15566. (<a
href="https://doi.org/10.1007/s10462-023-10542-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization is a common phenomenon that we encounter in our daily routine, which involves selecting the best option from a set of alternatives. A lot of algorithms have been developed, including metaheuristics algorithms, which aim to find solutions close to optimal to solve optimization problems. Many metaheuristic algorithms have been inspired by the behavior of natural phenomena, animals, and biological sciences. This paper proposes a novel nature-based metaheuristic optimization algorithm called Adaptive Fox Optimization (AFOX) Algorithm, which is inspired by the hunting behavior of foxes. The proposed algorithm enhances the FOX algorithm by balancing the exploration and exploitation phases, speeding up convergence to the global solution, and avoiding local optima. The efficacy of the AFOX algorithm was tested on eight classical benchmark functions, the functions of CEC2018, and the functions of the CEC2019 Benchmarks. Moreover, AFOX was applied to solve real-world optimization problems, such as prediction and engineering design problems, and compared with a wide range of metaheuristic algorithms such as variant versions of FOX, the Dragon-Fly Algorithm, particle swarm optimization, Fitness Dependent Optimizer, Grey Wolf Optimization, Whale Optimization Algorithm, Chimp Optimization Algorithm, Butterfly Optimization Algorithm, and Genetic Algorithm. The results demonstrate the effectiveness of the AFOX algorithm in finding optimal solutions with higher accuracy and faster convergence. Thus, the AFOX algorithm is deemed to be highly efficient in solving real-world optimization problems with accuracy and speed.},
  archive      = {J_AIR},
  author       = {ALRahhal, Hosam and Jamous, Razan},
  doi          = {10.1007/s10462-023-10542-z},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {15523-15566},
  shortjournal = {Artif. Intell. Rev.},
  title        = {AFOX: A new adaptive nature-inspired optimization algorithm},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An effective conflict management method based on belief
similarity measure and entropy for multi-sensor data fusion.
<em>AIR</em>, <em>56</em>(12), 15495–15522. (<a
href="https://doi.org/10.1007/s10462-023-10533-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-sensor data fusion has received substantial attention thanks to its ability to integrate information from distinct sources efficiently. Nevertheless, the information collected from multi-sensors may be uncertain and imprecise, even conflicting in real applications. As a distinguished theory to handle uncertain and imprecise information, belief functions theory (BFT) is prevalent in the various fields of multi-sensor data fusion. Unfortunately, counter-intuitive behaviors may generate once facing highly conflicting pieces of evidence. To deal with the above-mentioned issue, in this paper, we study a novel belief Sørensen coefficient ( $$\mathcal {BSC}$$ ) to measure the conflict between the pieces of evidence based on BFT. On the top of $$\mathcal {BSC}$$ , we propose a new belief conflict coefficient, and prove some important properties, namely, non-negativity, symmetry, non-degeneracy, bounded, extreme consistency and insensitivity to refinement. In parallel, some numerical examples are employed to demonstrate the superiority of the belief conflict coefficient in quantifying the degree of conflict between the pieces of evidence. Finally, we design a new multi-sensor data fusion method based on the proposed $$\mathcal {BSC}$$ and the improved belief entropy, and verify the effectiveness and practicability of the proposed method with respect to other methods through several application cases.},
  archive      = {J_AIR},
  author       = {Liu, Zhe},
  doi          = {10.1007/s10462-023-10533-0},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {15495-15522},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An effective conflict management method based on belief similarity measure and entropy for multi-sensor data fusion},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review on the significance of body temperature
interpretation for early infectious disease diagnosis. <em>AIR</em>,
<em>56</em>(12), 15449–15494. (<a
href="https://doi.org/10.1007/s10462-023-10528-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infectious diseases have always been a serious discussion worldwide due to their disease elevation leading to mortality. Although vaccination and prevention exist for this kind of disease, the severity is still in many countries, especially COVID-19. Diagnosing these diseases typically relies on time-consuming laboratory tests, conventional vital sign monitoring, and visual inspection by medical practitioners in hospitals. However, these time-consuming clinical procedures will cause a delay in diagnosis while increasing the risk of transmission in the community. Besides, most of the vital sign monitor and associated analysis software available in the commercial medical device market do not support infectious disease screening based on state-of-the-art algorithms as a clinical decision support system. As a result, research has been proposed to apply various techniques to diagnose and differentiate infectious diseases by focusing on clinical presentations, laboratory parameters, and temperature time series data. While most studies strongly justify clinical presentations and laboratory parameters could provide good diagnosing efficiency, some research also extends the possibility of early disease diagnosis based on body temperature alone. On the other hand, many studies proposed incorporating mobile technologies and machine learning which is suitable for early health monitoring at home. This paper discusses all the possible techniques in clinical and laboratory parameter analysis, body temperature data configuration, and symptoms mapping for infectious diseases diagnosis. The adequate data preprocessing, statistical analysis, machine learning models, performance metrics and mobile technologies implementation for disease diagnosis are also discussed to identify the best solution for effective infectious disease screening.},
  archive      = {J_AIR},
  author       = {Zaman, Nurul Izzati Darul and Hau, Yuan Wen and Leong, Ming Chern and Al-ashwal, Rania Hussien Ahmed},
  doi          = {10.1007/s10462-023-10528-x},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {15449-15494},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review on the significance of body temperature interpretation for early infectious disease diagnosis},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Image data hiding schemes based on metaheuristic
optimization: A review. <em>AIR</em>, <em>56</em>(12), 15375–15447. (<a
href="https://doi.org/10.1007/s10462-023-10537-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The digital content exchange on the Internet is associated with information security risks. Hiding data in digital images is a promising direction in data protection and is an alternative to cryptographic methods. Steganography algorithms create covert communication channels and protect the confidentiality of messages embedded in cover images. Watermarking algorithms embed invisible marks in images for further image authentication and proof of the authorship. The main difficulty in the development of data hiding schemes is to achieve a balance between indicators of embedding quality, including imperceptibility, capacity, and robustness. An effective approach to solving this problem is the use of metaheuristic optimization algorithms, such as genetic algorithm, particle swarm optimization, artificial bee colony, and others. In this paper, we present an overview of data hiding techniques based on metaheuristic optimization. We review and analyze image steganography and image watermarking schemes over the past 6 years. We propose three levels of research classification: embedding purpose level, optimization purpose level, and level of metaheuristics. The results demonstrate the high relevance of using metaheuristic optimization in the development of new data hiding algorithms. Based on the results of the review, we formulate the main problems of this scientific field and suggest promising areas for further research.},
  archive      = {J_AIR},
  author       = {Melman, Anna and Evsutin, Oleg},
  doi          = {10.1007/s10462-023-10537-w},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {15375-15447},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Image data hiding schemes based on metaheuristic optimization: A review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scene text understanding: Recapitulating the past decade.
<em>AIR</em>, <em>56</em>(12), 15301–15373. (<a
href="https://doi.org/10.1007/s10462-023-10530-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational perception has indeed been dramatically modified and reformed from handcrafted feature-based techniques to the advent of deep learning. Scene text identification and recognition have inexorably been touched by this bow effort of upheaval, ushering in the period of deep learning. It is an important aspect of machine vision. Society has seen significant improvements in thinking, approach, and effectiveness over time. The goal of this study is to summarize and analyze the important developments and notable advancements in scene text identification and recognition over the past decade. We have discussed the significant handcrafted feature-based techniques which had been regarded as flagship systems in the past. They were succeeded by deep learning-based techniques. We have discussed such approaches from their inception to the development of complex models which have taken scene text identification to the next stage.},
  archive      = {J_AIR},
  author       = {Ghosh, Mridul and Mukherjee, Himadri and Obaidullah, Sk Md and Gao, Xiao-Zhi and Roy, Kaushik},
  doi          = {10.1007/s10462-023-10530-3},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {15301-15373},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Scene text understanding: Recapitulating the past decade},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transition of traditional method to deep learning based
computer-aided system for breast cancer using automated breast
ultrasound system (ABUS) images: A review. <em>AIR</em>,
<em>56</em>(12), 15271–15300. (<a
href="https://doi.org/10.1007/s10462-023-10511-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer (BC) is the leading cause of death among women worldwide. Early detection and diagnosis of BC can help significantly reduce the mortality rate. Ultrasound (US) can be an ideal screening tool for BC detection. However, the hand-held US (HHUS) is an impractical tool because it is operator-dependent, time-consuming, and increases the likelihood of false-positive results. Thus, to address these issues, the 3D Automated Breast Ultrasound System (ABUS) was designed for BC detection and diagnosis. This paper presents the transition from traditional approaches to deep learning (DL) based CAD systems in the ABUS image data set. The capabilities and limitations of both techniques are also reviewed rigorously. This review will help in understanding the current limitations to leverage their potential in diagnostic radiology to improve performance and BC patient care.},
  archive      = {J_AIR},
  author       = {Pengiran Mohamad, Dayangku Nur Faizah and Mashohor, Syamsiah and Mahmud, Rozi and Hanafi, Marsyita and Bahari, Norafida},
  doi          = {10.1007/s10462-023-10511-6},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {15271-15300},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Transition of traditional method to deep learning based computer-aided system for breast cancer using automated breast ultrasound system (ABUS) images: A review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A comprehensive survey on NSGA-II for multi-objective
optimization and applications. <em>AIR</em>, <em>56</em>(12),
15217–15270. (<a
href="https://doi.org/10.1007/s10462-023-10526-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last two decades, the fast and elitist non-dominated sorting genetic algorithm (NSGA-II) has attracted extensive research interests, and it is still one of the hottest research methods to deal with multi-objective optimization problems. Considering the importance and wide applications of NSGA-II method, we believe it is the right time to provide a comprehensive survey of the research work in this area, and also to discuss the potential in the future research. The purpose of this paper is to summarize and explore the literature on NSGA-II and another version called NSGA-III, a reference-point based many-objective NSGA-II approach. In this paper, we first introduce the concept of multi-objective optimization and the foundation of NSGA-II. Then we review the family of NSGA-II and their modifications, and classify their applications in engineering community. Finally, we present several interesting open research directions of NSGA-II for multi-objective optimization.},
  archive      = {J_AIR},
  author       = {Ma, Haiping and Zhang, Yajing and Sun, Shengyi and Liu, Ting and Shan, Yu},
  doi          = {10.1007/s10462-023-10526-z},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {15217-15270},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comprehensive survey on NSGA-II for multi-objective optimization and applications},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic review of applications of natural language
processing and future challenges with special emphasis in text-based
emotion detection. <em>AIR</em>, <em>56</em>(12), 15129–15215. (<a
href="https://doi.org/10.1007/s10462-023-10509-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) has been used for processing data to make decisions, Interact with humans, and understand their feelings and emotions. With the advent of the Internet, people share and express their thoughts on day-to-day activities and global and local events through text messaging applications. Hence, it is essential for machines to understand emotions in opinions, feedback, and textual dialogues to provide emotionally aware responses to users in today&#39;s online world. The field of text-based emotion detection (TBED) is advancing to provide automated solutions to various applications, such as business and finance, to name a few. TBED has gained a lot of attention in recent times. The paper presents a systematic literature review of the existing literature published between 2005 and 2021 in TBED. This review has meticulously examined 63 research papers from the IEEE, Science Direct, Scopus, and Web of Science databases to address four primary research questions. It also reviews the different applications of TBED across various research domains and highlights its use. An overview of various emotion models, techniques, feature extraction methods, datasets, and research challenges with future directions has also been represented.},
  archive      = {J_AIR},
  author       = {Kusal, Sheetal and Patil, Shruti and Choudrie, Jyoti and Kotecha, Ketan and Vora, Deepali and Pappas, Ilias},
  doi          = {10.1007/s10462-023-10509-0},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {15129-15215},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A systematic review of applications of natural language processing and future challenges with special emphasis in text-based emotion detection},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Granular reduction in formal fuzzy contexts: Graph
representation, graph approach and its algorithm. <em>AIR</em>,
<em>56</em>(12), 15101–15127. (<a
href="https://doi.org/10.1007/s10462-023-10523-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction is one of the significant research issues in the formal fuzzy context (FFC). However, the extant method of computing the minimal granular reducts by Boolean reasoning is an NP problem. To this end, a graph-theoretic-based heuristic algorithm is proposed to compute the granular reducts in an FFC. We introduce the induced graph of the granular discernibility matrix and show that the minimal vertex cover of this induced graph is equivalent to the reduction of the FFC, thus transforming the problem of reduction the FFC into the problem of finding the minimal vertex cover of the graph. The manuscript also sets forth algorithms for finding minimal granular reducts based on graph theory. Further, data experiments are designed, and we formulate a transformation model from an information system with multi-valued attributes to an FFC, considering the characteristics of the continuous type of numerical attributes used in the experiments. Experimental results show that our proposed method performs well in terms of time complexity and running time.},
  archive      = {J_AIR},
  author       = {Gong, Zengtai and Zhang, Jing},
  doi          = {10.1007/s10462-023-10523-2},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {15101-15127},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Granular reduction in formal fuzzy contexts: Graph representation, graph approach and its algorithm},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimisation of electrical impedance tomography image
reconstruction error using heuristic algorithms. <em>AIR</em>,
<em>56</em>(12), 15079–15099. (<a
href="https://doi.org/10.1007/s10462-023-10527-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preventing living tissues’ direct exposure to ionising radiation has resulted in tremendous growth in medical imaging and e-health, enhancing intensive care of perilous patients and helping to improve quality of life. Moreover, the practice of image-reconstruction instruments that utilise ionising radiation significantly impacts the patient’s health. Prolonged or frequent exposure to ionising radiation is linked to several illnesses like cancer. These factors urged the advancement of non-invasive approaches, for instance, Electrical Impedance Tomography (EIT), a portable, non-invasive, low-cost, and safe imaging method. EIT image reconstruction still demands more exploitation, as it is an inverse and ill-conditioned problem. Numerous numerical techniques are used to answer this problem without producing anatomically unpredictable outcomes. Evolutionary Computational techniques can substitute conventional methods that usually create low-resolution blurry images. EIT reconstruction techniques optimise the relative error of reconstruction using population-based optimisation methods presented in this work. Three advanced optimisation methods have been developed to facilitate the iterative procedure for avoiding anatomically erratic solutions. Three different optimising techniques, namely, (a) Advanced Particle Swarm Optimisation Algorithm, (b) Advanced Gravitational Search Algorithm, and (c) Hybrid Gravitational Search Particle Swarm Optimization Algorithm (HGSPSO), are used. By utilising the advantages of these proposed techniques, the convergence and solution stability performance is improved. EIT images were obtained from the EIDORS library database for two case studies. The image reconstruction was optimised using the three proposed algorithms. EIDORS library was used for generating and solving forward and reverse problems. Two case studies were undertaken, i.e. circular tank simulation and gastric emptying. Thus, the results are analysed and presented as a real-world application of population-based optimisation methods. Results obtained from the proposed methods are quantitatively assessed with ground truth images using the relative mean squared error, confirming that a low error value is reached in the results. The HGSPSO algorithm performs better than the other proposed methods regarding solution quality and stability.},
  archive      = {J_AIR},
  author       = {Khan, Talha A. and Ling, Sai Ho and Rizvi, Arslan A.},
  doi          = {10.1007/s10462-023-10527-y},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {15079-15099},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Optimisation of electrical impedance tomography image reconstruction error using heuristic algorithms},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient data interpretation and artificial intelligence
enabled IoT based smart sensing system. <em>AIR</em>, <em>56</em>(12),
15053–15077. (<a
href="https://doi.org/10.1007/s10462-023-10519-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater wireless communications (UWC), based on acoustic waves, radio frequency waves, and optical waves, are currently deployed using underwater communications networks. Wireless sensor communications are among the most common UWC technologies because they offer connectivity over long distances. However, the UWC complex problems include restricted bandwidth, multitrack loss, limited battery power, and latency in propagation. Hence in this paper, Artificial Intelligence based Effective Data Interpretation Approach (AI-EDIA) has been proposed to improve the underwater wireless sensor network communication and less computational Time in IoT platform. The proposed AI-EIDA utilizes the discrete cosine transform (DCT) with frequency modulation multiplexing (FMM) for underwater acoustic communication. Underwater acoustic channels are categorized as double Time and frequency distribution channels. Therefore, the reverse DCT structure provides the orthogonal characteristic of the traditional FMM with the additional advantages of reduced execution and improved speed when the actual calculations are needed. Thus the experimental results show that AI-EDIA decreases energy usage and less delay rate to 0.45 s.},
  archive      = {J_AIR},
  author       = {Shankar, Achyut},
  doi          = {10.1007/s10462-023-10519-y},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {15053-15077},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Efficient data interpretation and artificial intelligence enabled IoT based smart sensing system},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Systematic study on deep learning-based plant disease
detection or classification. <em>AIR</em>, <em>56</em>(12), 14955–15052.
(<a href="https://doi.org/10.1007/s10462-023-10517-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plant diseases impact extensively on agricultural production growth. It results in a price hike on food grains and vegetables. To reduce economic loss and to predict yield loss, early detection of plant disease is highly essential. Current plant disease detection involves the physical presence of domain experts to ascertain the disease; this approach has significant limitations, namely: domain experts need to move from one place to another place which involves transportation cost as well as travel time; heavy transportation charge makes the domain expert not travel a long distance, and domain experts may not be available all the time, and though the domain experts are available, the domain expert(s) may charge high consultation charge which may not be feasible for many farmers. Thus, there is a need for a cost-effective, robust automated plant disease detection or classification approach. In this line, various plant disease detection approaches are proposed in the literature. This systematic study provides various Deep Learning-based and Machine Learning-based plant disease detection or classification approaches; 160 diverse research works are considered in this study, which comprises single network models, hybrid models, and also real-time detection approaches. Around 57 studies considered multiple plants, and 103 works considered a single plant. 50 different plant leaf disease datasets are discussed, which include publicly available and publicly unavailable datasets. This study also discusses the various challenges and research gaps in plant disease detection. This study also highlighted the importance of hyperparameters in deep learning.},
  archive      = {J_AIR},
  author       = {Sunil, C. K. and Jaidhar, C. D. and Patil, Nagamma},
  doi          = {10.1007/s10462-023-10517-0},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {14955-15052},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Systematic study on deep learning-based plant disease detection or classification},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent techniques in e-learning: A literature review.
<em>AIR</em>, <em>56</em>(12), 14907–14953. (<a
href="https://doi.org/10.1007/s10462-023-10508-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online learning has become increasingly important, having in mind the latest events, imposed isolation measures and closed schools and campuses. Consequently, teachers and students need to embrace digital tools and platforms, bridge the newly established physical gap between them, and consume education in various new ways. Although literature indicates that the development of intelligent techniques must be incorporated in e-learning systems to make them more effective, the need exists for research on how these techniques impact the whole process of online learning, and how they affect learners’ performance. This paper aims to provide comprehensive research on innovations in e-learning, and present a literature review of used intelligent techniques and explore their potential benefits. This research presents a categorization of intelligent techniques, and explores their roles in e-learning environments. By summarizing the state of the art in the area, the authors outline past research, highlight its gaps, and indicate important implications for practice. The goal is to understand better available intelligent techniques, their implementation and application in e-learning context, and their impact on improving learning in online education. Finally, the review concludes that AI-supported solutions not only can support learner and teacher, by recommending resources and grading submissions, but they can offer fully personalized learning experience.},
  archive      = {J_AIR},
  author       = {Ilić, Miloš and Mikić, Vladimir and Kopanja, Lazar and Vesin, Boban},
  doi          = {10.1007/s10462-023-10508-1},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {14907-14953},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Intelligent techniques in e-learning: A literature review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fraction ranking-based multi-criteria decision-making
method for water resource management under bipolar neutrosophic fuzzy
environment. <em>AIR</em>, <em>56</em>(12), 14865–14906. (<a
href="https://doi.org/10.1007/s10462-023-10514-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kolkata city is the capital of West Bengal, India. Due to improper administration, this city has long been plagued by a drinking water shortage. The rapid urbanisation and population growth, the rising daily water demand, and the steadily falling availability of drinking water per capita are the main contributors to the city’s drinking water shortage. The sustained development of drinking water supplies in Kolkata city depends on effective water resource management. With decision-making approaches, we can easily handle the drinking water scarcity situation. Therefore, we have developed a novel multi-criteria decision-making (MCDM) technique for the sustainable development of the drinking water crisis in Kolkata city. First, we introduce a fraction ranking ( $$R_{\lambda ^{+}}, R_{\lambda ^{-}}$$ ) method of single-valued triangular bipolar neutrosophic (SVTrBN) number based on grades ( $$V_{\lambda ^{+}}, V_{\lambda ^{-}}$$ ) and illegibilities ( $$A_{\lambda ^{+}}, A_{\lambda ^{-}}$$ ). Here, we have invented the $$\lambda$$ -weighted positive and negative fraction index for SVTrBN-numbers. Using the fraction ranking method, we formulate a novel MCDM technique. This decision-making technique is applicable for accurate decisions, primarily when human choices depend on positive and negative effects. In addition, we give some fundamental definitions and important ethos of bipolar neutrosophic numbers. By the proposed MCDM technique, we have exercised a water resources management (WRM) problem in Kolkata under a bipolar neutrosophic environment. To check the applicability and feasibility of the proposed MCDM method, we illustrated numerically and graphically of proposed WRM problem under SVTrBN-environment.},
  archive      = {J_AIR},
  author       = {Garai, Totan and Garg, Harish and Biswas, George},
  doi          = {10.1007/s10462-023-10514-3},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {14865-14906},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A fraction ranking-based multi-criteria decision-making method for water resource management under bipolar neutrosophic fuzzy environment},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Convolutional network fabric pruning with label noise.
<em>AIR</em>, <em>56</em>(12), 14841–14864. (<a
href="https://doi.org/10.1007/s10462-023-10507-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an iterative pruning strategy for Convolutional Network Fabrics (CNF) in presence of noisy training and testing data. With the continuous increase in size of neural network models, various authors have developed pruning approaches to build more compact network structures requiring less resources, while preserving performance. As we show in this paper, because of their intrinsic structure and function, Convolutional Network Fabrics are ideal candidates for pruning. We present a series of pruning strategies that can significantly reduce both the final network size and required training time by pruning either entire convolutional filters or individual weights, so that the grid remains visually understandable but that overall execution quality stays within controllable boundaries. Our approach can be iteratively applied during training so that the network complexity decreases rapidly, saving computational time. The paper addresses both data-dependent and data-independent strategies, and also experimentally establishes the most efficient approaches when training or testing data contain annotation errors.},
  archive      = {J_AIR},
  author       = {Benjelloun, Ilias and Lamiroy, Bart and Koudou, Efoevi Angelo},
  doi          = {10.1007/s10462-023-10507-2},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {14841-14864},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Convolutional network fabric pruning with label noise},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A large-scale multi-objective evolutionary algorithm based
on importance rankings and information feedback. <em>AIR</em>,
<em>56</em>(12), 14803–14840. (<a
href="https://doi.org/10.1007/s10462-023-10522-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For large-scale multi-objective optimization problems, the trade-off between convergence and diversity brings significant challenges for researchers. Most of the reproduction operators in the evolutionary algorithms fail to achieve a superior performance. In order to address this issue, this work proposes a large-scale multi-objective evolutionary algorithm (LSMOEA) named LMOEA-IRIF. In the LMOEA-IRIF, a novel grouping strategy and an information feedback model (IFM) are designed to evolve the population. Specifically, the decision variables are clustered into multiple convergence-related and diversity-related subgroups based on their importance rankings. The importance rankings of decision variables are quantized by the maximum Euclidean distance between individuals generated in the objective space. Then the decision variables in each subgroup are optimized in a low-dimensional decision subspace, which can effectively speed up the convergence of population. Furthermore, the IFM, which takes the information from the previous generation into consideration, is devised to generate high-quality offspring and used to enhance the diversity of population. Comprehensive experiments are performed to validate the effectiveness of the LMOEA-IRIF. The experimental results show that the proposed algorithm obtains competitive performance in 56 of 76 benchmark instances against five state-of-the-art LSMOEAs.},
  archive      = {J_AIR},
  author       = {Cao, Jie and Guo, Kaiyue and Zhang, Jianlin and Chen, Zuohan},
  doi          = {10.1007/s10462-023-10522-3},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {14803-14840},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A large-scale multi-objective evolutionary algorithm based on importance rankings and information feedback},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review on big data based on deep neural network
approaches. <em>AIR</em>, <em>56</em>(12), 14765–14801. (<a
href="https://doi.org/10.1007/s10462-023-10512-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data analytics has become a significant trend for many businesses as a result of the daily acquisition of enormous volumes of data. This information has been gathered because it may be important for dealing with complicated problems including fraud, marketing, healthcare, and cyber security. Analytics are used by big businesses like Facebook and Google to analyse and make decisions about their massive volumes of collected data. Such analyses and decisions impact both the present and the future of technology. The inherent non-linear properties in huge data may be captured by deep learning (DL) algorithms using automated feature extraction techniques. In order to estimate renewable energy, energy consumption, demand, and supply, among other things, over the short, medium, and long term, a complete and in-depth investigation of generative, hybrid, and discriminative DL models is being conducted. This article examines the benefits and drawbacks of DL that depends on a variety of deep neural networks, including recurrent neural networks, multilayer neural networks, auto encoders and long short-term memory.},
  archive      = {J_AIR},
  author       = {Rithani, M. and Kumar, R. Prasanna and Doss, Srinath},
  doi          = {10.1007/s10462-023-10512-5},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {14765-14801},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review on big data based on deep neural network approaches},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Uncertainty measurement of partially labeled categorical
data with application to semi-supervised attribute reduction.
<em>AIR</em>, <em>56</em>(12), 14731–14764. (<a
href="https://doi.org/10.1007/s10462-023-10518-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many practical applications of machine learning, there are a large number of partially labeled categorical data due to the high cost of labelling data. Semi-supervised learning algorithm is needed to deal with such data. This paper studies uncertainty measurement (UM) of partially labeled categorical data and considers semi-supervised attribute reduction in a partially labeled categorical decision information system (p-CDIS). The fact that a discernibility pair set for categorical data is actually a distinguishable relation is first stated. Then, a p-CDIS is divided into two categorical decision information systems: one is the labeled categorical decision information system (l-CDIS) and the other is the unlabeled categorical decision information system (u-CDIS). Next, based on the indistinguishable relation, distinguishable relation and dependence function, four degrees of importance are defined. They are the weighted sum of l-CDIS and u-CDIS determined by the label missing rate and can be considered as the UM of p-CDIS. Moreover, the numerical experiments and statistical tests on 10 datasets verify their effectiveness. In addition, an adaptive semi-supervised reduction algorithm based on the defined degrees of importance is proposed, which can automatically adapt to various label missing rates. Finally, the results of experiments and statistical tests on 10 datasets show the proposed algorithm is statistically better than some stat-of-the-art algorithms according to classification accuracy.},
  archive      = {J_AIR},
  author       = {Wang, Pei and Zhang, Qinli and Pedrycz, Witold and Li, Zhaowen and Wen, Ching-Feng},
  doi          = {10.1007/s10462-023-10518-z},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {14731-14764},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Uncertainty measurement of partially labeled categorical data with application to semi-supervised attribute reduction},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DeepThink IoT: The strength of deep learning in internet of
things. <em>AIR</em>, <em>56</em>(12), 14663–14730. (<a
href="https://doi.org/10.1007/s10462-023-10513-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of Deep Learning (DL) and the Internet of Things (IoT) has revolutionized technology in the twenty-first century, enabling humans and machines to perform tasks more efficiently. The combination of DL and the IoT has resulted in significant advancements in technology by improving the efficiency, security, and user experience of IoT devices and systems. The integration of DL and IoT offers several benefits, including improved data processing and analysis capabilities, the ability for IoT devices to learn from data and adapt to changing conditions, and the early detection of system malfunctions and potential security breaches. This survey paper provides a comprehensive overview of the impact of DL on IoT, including an analysis of sensor data to detect patterns and make predictions, and the implications for various industries such as healthcare, manufacturing, agriculture, and smart cities. The survey paper covers topics such as DL models, frameworks, IoT connectivity terminologies, IoT components, IoT service-oriented architecture, IoT applications, the role of DL in IoT, and challenges faced by DL in IoT. The study also presents quantitative achievements that highlight the potential impact of IoT and DL in environmental contexts such as precision farming and energy consumption. Overall, the survey paper provides an excellent resource for researchers interested in exploring the potential of IoT and DL in their field.},
  archive      = {J_AIR},
  author       = {Thakur, Divyansh and Saini, Jaspal Kaur and Srinivasan, Srikant},
  doi          = {10.1007/s10462-023-10513-4},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {14663-14730},
  shortjournal = {Artif. Intell. Rev.},
  title        = {DeepThink IoT: The strength of deep learning in internet of things},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Geometric deep learning and equivariant neural networks.
<em>AIR</em>, <em>56</em>(12), 14605–14662. (<a
href="https://doi.org/10.1007/s10462-023-10502-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We survey the mathematical foundations of geometric deep learning, focusing on group equivariant and gauge equivariant neural networks. We develop gauge equivariant convolutional neural networks on arbitrary manifolds $$\mathcal {M}$$ using principal bundles with structure group K and equivariant maps between sections of associated vector bundles. We also discuss group equivariant neural networks for homogeneous spaces $$\mathcal {M}=G/K$$ , which are instead equivariant with respect to the global symmetry G on $$\mathcal {M}$$ . Group equivariant layers can be interpreted as intertwiners between induced representations of G, and we show their relation to gauge equivariant convolutional layers. We analyze several applications of this formalism, including semantic segmentation and object detection networks. We also discuss the case of spherical networks in great detail, corresponding to the case $$\mathcal {M}=S^2=\textrm{SO}(3)/\textrm{SO}(2)$$ . Here we emphasize the use of Fourier analysis involving Wigner matrices, spherical harmonics and Clebsch–Gordan coefficients for $$G=\textrm{SO}(3)$$ , illustrating the power of representation theory for deep learning.},
  archive      = {J_AIR},
  author       = {Gerken, Jan E. and Aronsson, Jimmy and Carlsson, Oscar and Linander, Hampus and Ohlsson, Fredrik and Petersson, Christoffer and Persson, Daniel},
  doi          = {10.1007/s10462-023-10502-7},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {14605-14662},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Geometric deep learning and equivariant neural networks},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Failure mode and effect analysis approach considering risk
attitude of dynamic reference point cumulative prospect theory in
uncertainty contexts. <em>AIR</em>, <em>56</em>(12), 14557–14604. (<a
href="https://doi.org/10.1007/s10462-023-10501-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failure mode and effect analysis (FMEA) method is widely utilized as a powerful reliability management tool to effectively evaluate and prevent risk problems that occur in all aspects of production, service and transportation. Since FMEA experts have different professional backgrounds and the particularity of the risk assessment environment, they may show different risk attitudes and bounded rational behavior. Thus, this paper develops an FMEA framework based on the dynamic reference point cumulative prospect theory considering risk attitude. The linguistic distribution assessment (LDA) and linguistic scale function are utilized to indicate the risk attitude based personalized FMEA experts’ evaluation information. Further, based on the idea of maximizing deviation and the LDA-EMD (earth mover’s distance) formula, the criteria weight determination method considering the different risk attitudes of the FMEA expert is constructed. Then, a dynamic reference point cumulative prospect theory considering different risk attitudes is developed to obtain the prospect value of the failure modes (FMs) under each FMEA expert. The comprehensive expert weight determination method is established which takes the subjective and objective aspects of expert evaluation and revision factor into account. Finally, the numerical example is carried out to verify the validity and superiority performance of the proposed FMEA method. The improved FMEA method can enhance the flexibility and reliability of risk assessment. Findings proved that it is necessary to consider the different and dynamic risk attitudes of experts in the practical risk assessment.},
  archive      = {J_AIR},
  author       = {Li, Ying and Liu, Peide and Wu, Xiaoming},
  doi          = {10.1007/s10462-023-10501-8},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {14557-14604},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Failure mode and effect analysis approach considering risk attitude of dynamic reference point cumulative prospect theory in uncertainty contexts},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development of artificial neural network based mathematical
models for predicting small scale quarry powder factor for efficient
fragmentation coupled with uniformity index model. <em>AIR</em>,
<em>56</em>(12), 14535–14556. (<a
href="https://doi.org/10.1007/s10462-023-10524-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blasting is the primary method for reducing rock size in small-scale mining operations. The primary purpose of blasting is to assist rock mass reduction and transportation from the mine to the processing facility. The explosive charge utilized in this blasting operation has an impact on production output, safety, and profitability. The explosive powder factor is used in mining to calculate the quantity of explosive required per mass of rock fragmented, and this study looks at how different powder factors affect blast fragmentation. A machine learning approach was used in this study to optimize explosive use in small-scale quarries. This study employed data from a small-scale dolomite quarry in Akoko Edo, Nigeria, for artificial neural network (ANN) modeling and uniformity index model creation (10 production blasts and 38 blast record datasets). Powder factors greater than 0.7–0.8 kg/m3 result in a lower uniformity index, according to an analysis of monitored blast results. The results showed that powder factors of 0.7 kg/m3 (between 1.6 and 1.7) had the highest uniformity index. According to the findings, the small-scale optimum blast uniformity index is between 1.33 and 1.68. The proposed ANN model performs well in terms of prediction accuracy, as determined by five error indices with coefficients of correlation (R2) of 0.997 on the training dataset and 0.97 on the testing dataset. Based on the model performance analysis results, the suggested ANN model can be used to improve the small-scale blast powder factor in actual applications.},
  archive      = {J_AIR},
  author       = {Taiwo, Blessing Olamide and Yewuhalashet, Fissha and Adamolekun, Lateef Bankole and Bidemi, Ogunyemi Olaoluwa and Famobuwa, Oluwaseun Victor and Victoria, Adediran Oluwatomisin},
  doi          = {10.1007/s10462-023-10524-1},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {14535-14556},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Development of artificial neural network based mathematical models for predicting small scale quarry powder factor for efficient fragmentation coupled with uniformity index model},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Image embedding for denoising generative models.
<em>AIR</em>, <em>56</em>(12), 14511–14533. (<a
href="https://doi.org/10.1007/s10462-023-10504-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Denoising Diffusion models are gaining increasing popularity in the field of generative modeling for several reasons, including the simple and stable training, the excellent generative quality, and the solid probabilistic foundation. In this article, we address the problem of embedding an image into the latent space of Denoising Diffusion Models, that is finding a suitable “noisy” image whose denoising results in the original image. We particularly focus on Denoising Diffusion Implicit Models due to the deterministic nature of their reverse diffusion process. As a side result of our investigation, we gain a deeper insight into the structure of the latent space of diffusion models, opening interesting perspectives on its exploration, the definition of semantic trajectories, and the manipulation/conditioning of encodings for editing purposes. A particularly interesting property highlighted by our research, which is also characteristic of this class of generative models, is the independence of the latent representation from the networks implementing the reverse diffusion process. In other words, a common seed passed to different networks (each trained on the same dataset), eventually results in identical images.},
  archive      = {J_AIR},
  author       = {Asperti, Andrea and Evangelista, Davide and Marro, Samuele and Merizzi, Fabio},
  doi          = {10.1007/s10462-023-10504-5},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {14511-14533},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Image embedding for denoising generative models},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). An adaptive spatio-temporal neural network for PM2.5
concentration forecasting. <em>AIR</em>, <em>56</em>(12), 14483–14510.
(<a href="https://doi.org/10.1007/s10462-023-10503-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate PM2.5 concentration prediction is essential for environmental control management, therefore numerous air quality monitoring stations have been established, which generate multiple time series with spatio-temporal correlation. However, the statistical distribution of data from different monitoring stations varies widely, which needs to provide higher flexibility in the feature extraction stage. Moreover, the spatio-temporal correlation and mutation characteristics of the time series are difficult to capture. To this end, an adaptive spatio-temporal prediction network (ASTP-NET) is proposed, in which the encoder adaptively extracts the input data features, then captures the spatio-temporal dependencies and dynamic changes of the time series, the decoder part maps the encoded features into a predicted future time series representation, while an objective function is proposed to measure the overall fluctuations of the model’s multi-step prediction. In this paper, ASTP-NET is evaluated based on the Xi&#39;an air quality dataset, and the results show that the model outperforms other baseline methods.},
  archive      = {J_AIR},
  author       = {Zhang, Xiaoxia and Li, Qixiong and Liang, Dong},
  doi          = {10.1007/s10462-023-10503-6},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {14483-14510},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An adaptive spatio-temporal neural network for PM2.5 concentration forecasting},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A brief survey on recent advances in coreference resolution.
<em>AIR</em>, <em>56</em>(12), 14439–14481. (<a
href="https://doi.org/10.1007/s10462-023-10506-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of resolving repeated objects in natural languages is known as coreference resolution, and it is an important part of modern natural language processing. It is classified into two categories depending on the resolved objects, namely entity coreference resolution and event coreference resolution. Predicting coreference connections and identifying mentions/triggers are the major challenges in coreference resolution, because these implicit relationships are particularly difficult in natural language understanding in downstream tasks. Coreference resolution techniques have experienced considerable advances in recent years, encouraging us to review this task in the following aspects: current employed evaluation metrics, datasets, and methods. We investigate 10 widely used metrics, 18 datasets and 4 main technical trends in this survey. We believe that this work is a comprehensive roadmap for understanding the past and the future of coreference resolution.},
  archive      = {J_AIR},
  author       = {Liu, Ruicheng and Mao, Rui and Luu, Anh Tuan and Cambria, Erik},
  doi          = {10.1007/s10462-023-10506-3},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {14439-14481},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A brief survey on recent advances in coreference resolution},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NmODE: Neural memory ordinary differential equation.
<em>AIR</em>, <em>56</em>(12), 14403–14438. (<a
href="https://doi.org/10.1007/s10462-023-10496-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain neural networks are regarded as dynamical systems in neural science, in which memories are interpreted as attractors of the systems. Mathematically, ordinary differential equations (ODEs) can be utilized to describe dynamical systems. Any ODE that is employed to describe the dynamics of a neural network can be called a neuralODE. Inspired by rethinking the nonlinear representation ability of existing artificial neural networks together with the functions of columns in the neocortex, this paper proposes a theory of memory-based neuralODE, which is composed of two novel artificial neural network models: nmODE and $$\epsilon$$ -net, and two learning algorithms: nmLA and $$\epsilon$$ -LA. The nmODE (neural memory Ordinary Differential Equation) is designed with a special structure that separates learning neurons from memory neurons, making its dynamics clear. Given any external input, the nmODE possesses the global attractor property and is thus embedded with a memory mechanism. The nmODE establishes a nonlinear mapping from the external input to its associated attractor and does not have the problem of learning features homeomorphic to the input data space, as occurs frequently in most existing neuralODEs. The nmLA (neural memory Learning Algorithm) is developed by proposing an interesting three-dimensional inverse ODE (invODE) and has advantages in memory and parameter efficiency. The proposed $$\epsilon$$ -net is a discrete version of the nmODE, which is particularly feasible for digital computing. The proposed $$\epsilon$$ -LA ( $$\epsilon$$ learning algorithm) requires no prior knowledge of the number of network layers. Both nmLA and $$\epsilon$$ -LA have no problem with gradient vanishing. Experimental results show that the proposed theory is comparable to state-of-the-art methods.},
  archive      = {J_AIR},
  author       = {Yi, Zhang},
  doi          = {10.1007/s10462-023-10496-2},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {14403-14438},
  shortjournal = {Artif. Intell. Rev.},
  title        = {NmODE: Neural memory ordinary differential equation},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning implementations in mining applications: A
compact critical review. <em>AIR</em>, <em>56</em>(12), 14367–14402. (<a
href="https://doi.org/10.1007/s10462-023-10500-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning is a sub-field of artificial intelligence that combines feature engineering and classification in one method. It is a data-driven technique that optimises a predictive model via learning from a large dataset. Digitisation in industry has included acquisition and storage of a variety of large datasets for interpretation and decision making. This has led to the adoption of deep learning in different industries, such as transportation, manufacturing, medicine and agriculture. However, in the mining industry, the adoption and development of new technologies, including deep learning methods, has not progressed at the same rate as in other industries. Nevertheless, in the past 5 years, applications of deep learning have been increasing in the mining research space. Deep learning has been implemented to solve a variety of problems related to mine exploration, ore and metal extraction and reclamation processes. The increased automation adoption in mining provides an avenue for wider application of deep learning as an element within a mine automation framework. This work provides a compact, comprehensive review of deep learning implementations in mining-related applications. The trends of these implementations in terms of years, venues, deep learning network types, tasks and general implementation, categorised by the value chain operations of exploration, extraction and reclamation are outlined. The review enables shortcomings regarding progress within the research context to be highlighted such as the proprietary nature of data, small datasets (tens to thousands of data points) limited to single operations with unique geology, mine design and equipment, lack of large scale publicly available mining related datasets and limited sensor types leading to the majority of applications being image-based analysis. Gaps identified for future research and application includes the usage of a wider range of sensor data, improved understanding of the outputs by mining practitioners, adversarial testing of the deep learning models, development of public datasets covering the extensive range of conditions experienced in mines.},
  archive      = {J_AIR},
  author       = {Azhari, Faris and Sennersten, Charlotte C. and Lindley, Craig A. and Sellers, Ewan},
  doi          = {10.1007/s10462-023-10500-9},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {14367-14402},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep learning implementations in mining applications: A compact critical review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SAR-BSO meta-heuristic hybridization for feature selection
and classification using DBNover stream data. <em>AIR</em>,
<em>56</em>(12), 14327–14365. (<a
href="https://doi.org/10.1007/s10462-023-10494-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancements in cloud technologies have increased the infrastructural needs of data centers due to storage needs and processing of extensive dimensional data. Many service providers envisage anomaly detection criteria to guarantee availability to avoid breakdowns and complexities caused due to large-scale operations. The streaming log data generated is associated with multi-dimensional complexity and thus poses a considerable challenge to detect the anomalies or unusual occurrences in the data. In this research, a hybrid model is proposed that is motivated by deep belief criteria and meta-heuristics. Using Search-and-Rescue—BrainStorm Optimization (SAR-BSO), a hybrid feature selection (FS) and deep belief network classifier is used to localize and detect anomalies for streaming data logs. The significant contribution of the research lies in FS, which is carried out using SAR-BSO which increases the detection power of the model as it selects the most significant variables by minimizing redundant features. The evaluation of accuracy is efficiently improved when compared with the predictable methods, such as Extract Local Outlier Factor (ELOF), Track-plus, Hybrid Distributed Batch Stream (HDBS), IForestASD, DBN, BSO-based Feature Selection with DBN, Genetic Algorithm-Deep Belief Network (GA-DBN), Mutual Information-Deep Belief Network (MI-DBN), information entropy-Deep Belief Network(I + DBN), Flat Field-Deep Belief Network (FF + DBN), African Vulture Optimization Algorithm-Deep Belief Network(AVOA + DBN), Gorilla Troop Optimizer-Deep Belief Network(GTO-DBN), and SARO-based Feature Selection with DBN. Further, the accurate detection of the anomalies in the data stream is established by the Deep Belief Neural Network (DBN) classifier. The model’s efficacy is determined using Apache, Hadoop, HDFS, Spark, and Linux datasets and evaluated against existing similar models. The model efficiency is provided using multiple evaluation metrics and is found effective. From the experimentation, the accuracy of the proposed model is found to be 93.3, 95.4, 93.6, 94.2, and 93.5\% respectively for the dataset such as Apache, Hadoop, HDFS, spark, and Linux. This enhancement in accuracy is due to the selection of optimal features by the proposed SAR-BSO algorithm.},
  archive      = {J_AIR},
  author       = {Talapula, Dharani Kumar and Ravulakollu, Kiran Kumar and Kumar, Manoj and Kumar, Adarsh},
  doi          = {10.1007/s10462-023-10494-4},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {14327-14365},
  shortjournal = {Artif. Intell. Rev.},
  title        = {SAR-BSO meta-heuristic hybridization for feature selection and classification using DBNover stream data},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal energy management in EVCS and distribution system
considering QoS using hybrid technique. <em>AIR</em>, <em>56</em>(12),
14297–14326. (<a
href="https://doi.org/10.1007/s10462-023-10458-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This manuscript proposes a hybrid method to effectively manage the energy on electric vehicle charging station (EVCS) and distribution system. The proposed method is consolidation of shell game optimization (SGO) and recalling-enhanced recurrent neural network (RERNN) named SGO-RERNN technique. The main aim of this work is to offer maximal amount of energy in this system and charging plans for EVCSs. The hybrid SGO-RERNN system is used to obtain the balancing solution. The intention of the distribution system is to maximize the planning charged for EVCSs. The proposed algorithm is related to supply function equilibrium method and it is used to modify and examine the interaction of each electric vehicle charging known as leader and the distributed system is known as follower. The hybrid SGO-RERNN technique is used to acquire the equilibrium solution. The SGO-RERNN system is implemented on MATLAB platform and the performance is compared to existing systems. Furthermore, the EVCS and distribution system efficiency is analyzed with the help of proposed method. The SGO-RERNN method attains electric vehicle charging station 1 attains 600.234, electric vehicle charging station 2 attains 3509.19, electric vehicle charging station 3 attains 4413.09, and distribution system attains 4327.033. The experimental outcomes prove that the integrated energy system costs minimized 3.89\% and gains maximized to 7.8\%. Finally, the SGO-RERNN method locates the optimum global solutions efficiently and accurately over the existing methods.},
  archive      = {J_AIR},
  author       = {Dharmalingam, Uma and Arumugam, Vijayakumar},
  doi          = {10.1007/s10462-023-10458-8},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {14297-14326},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Optimal energy management in EVCS and distribution system considering QoS using hybrid technique},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dimensionality reduced training by pruning and freezing
parts of a deep neural network: A survey. <em>AIR</em>, <em>56</em>(12),
14257–14295. (<a
href="https://doi.org/10.1007/s10462-023-10489-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-of-the-art deep learning models have a parameter count that reaches into the billions. Training, storing and transferring such models is energy and time consuming, thus costly. A big part of these costs is caused by training the network. Model compression lowers storage and transfer costs, and can further make training more efficient by decreasing the number of computations in the forward and/or backward pass. Thus, compressing networks also at training time while maintaining a high performance is an important research topic. This work is a survey on methods which reduce the number of trained weights in deep learning models throughout the training. Most of the introduced methods set network parameters to zero which is called pruning. The presented pruning approaches are categorized into pruning at initialization, lottery tickets and dynamic sparse training. Moreover, we discuss methods that freeze parts of a network at its random initialization. By freezing weights, the number of trainable parameters is shrunken which reduces gradient computations and the dimensionality of the model’s optimization space. In this survey we first propose dimensionality reduced training as an underlying mathematical model that covers pruning and freezing during training. Afterwards, we present and discuss different dimensionality reduced training methods—with a strong focus on unstructured pruning and freezing methods.},
  archive      = {J_AIR},
  author       = {Wimmer, Paul and Mehnert, Jens and Condurache, Alexandru Paul},
  doi          = {10.1007/s10462-023-10489-1},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {14257-14295},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Dimensionality reduced training by pruning and freezing parts of a deep neural network: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic review of the use of topic models for short
text social media analysis. <em>AIR</em>, <em>56</em>(12), 14223–14255.
(<a href="https://doi.org/10.1007/s10462-023-10471-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, research on short text topic models has addressed the challenges of social media datasets. These models are typically evaluated using automated measures. However, recent work suggests that these evaluation measures do not inform whether the topics produced can yield meaningful insights for those examining social media data. Efforts to address this issue, including gauging the alignment between automated and human evaluation tasks, are hampered by a lack of knowledge about how researchers use topic models. Further problems could arise if researchers do not construct topic models optimally or use them in a way that exceeds the models’ limitations. These scenarios threaten the validity of topic model development and the insights produced by researchers employing topic modelling as a methodology. However, there is currently a lack of information about how and why topic models are used in applied research. As such, we performed a systematic literature review of 189 articles where topic modelling was used for social media analysis to understand how and why topic models are used for social media analysis. Our results suggest that the development of topic models is not aligned with the needs of those who use them for social media analysis. We have found that researchers use topic models sub-optimally. There is a lack of methodological support for researchers to build and interpret topics. We offer a set of recommendations for topic model researchers to address these problems and bridge the gap between development and applied research on short text topic models.},
  archive      = {J_AIR},
  author       = {Laureate, Caitlin Doogan Poet and Buntine, Wray and Linger, Henry},
  doi          = {10.1007/s10462-023-10471-x},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {14223-14255},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A systematic review of the use of topic models for short text social media analysis},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Impact of employee digital competence on the relationship
between digital autonomy and innovative work behavior: A systematic
review. <em>AIR</em>, <em>56</em>(12), 14193–14222. (<a
href="https://doi.org/10.1007/s10462-023-10492-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of the COVID-19 pandemic, the level of concern regarding employee digital competence has increased significantly. Several studies provide different surveys, but they cannot describe the relationship between digital autonomy and innovative work behaviour concerning the impact of employee digital competence. Hence, it is necessary to conduct a survey that provides a deeper understanding of these concerns and suggests a suitable study for other researchers. Using scientific publication databases and adhering to the PRISMA statement, this systematic literature review aims to offer a current overview of employee digital competence impact on the relationship between digital autonomy and innovative work behaviour from 2015 to 2022, covering definitions, research purposes, methodologies, outcomes, and limitations. When reviewing the selected articles, 18 articles were examined under relationship topics, and 12 articles reported on impact topics under different tasks. The main findings highlight the significance of digital competence and autonomy in promoting employee creativity, learning, and sharing knowledge. According to the review findings, employees with greater digital autonomy are more likely to engage in innovative work, leading to improved job performance and empowerment. Therefore, the development of digital autonomy prioritizes organizations by providing access to digital tools, training, and a supportive work environment. Overall, the current review indicates a strong positive correlation between digital autonomy, innovative work behaviour, and employee impact. This underscores the importance for organizations to not only participate in digital competence and skills, but also to create a culture that values autonomy, creativity, and innovation among its employees.},
  archive      = {J_AIR},
  author       = {Huu, Pham Thanh},
  doi          = {10.1007/s10462-023-10492-6},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {14193-14222},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Impact of employee digital competence on the relationship between digital autonomy and innovative work behavior: A systematic review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Non-player character decision-making in computer games.
<em>AIR</em>, <em>56</em>(12), 14159–14191. (<a
href="https://doi.org/10.1007/s10462-023-10491-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most overlooked challenges in artificial intelligence (AI) for computer games is to create non-player game characters (NPCs) with human-like behavior. Modern NPCs determine their actions in different situations using certain decision-making methods, enabling them to change the current state of the game world. In this paper, we survey current decision-making methods used by NPCs in games, identifying five categories. We give detailed overview of these five categories and determine the previous studies that belong to each of these categories. We also discuss the hybrid methods which are the combinations of different decision-making methods and the frameworks that are created for NPC decision-making. As a result of this analysis, we create a taxonomy table based on these covered studies. Lastly, the challenges faced in our study and future possibilities for improvement are described.},
  archive      = {J_AIR},
  author       = {Uludağlı, Muhtar Çağkan and Oğuz, Kaya},
  doi          = {10.1007/s10462-023-10491-7},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {14159-14191},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Non-player character decision-making in computer games},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Multiple criteria decision analytic methods in management
with t-spherical fuzzy information. <em>AIR</em>, <em>56</em>(12),
14087–14157. (<a
href="https://doi.org/10.1007/s10462-023-10461-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With a focus on T-spherical fuzzy (T-SF) sets, the aim of this paper is to create a split-new appraisal mechanism and an innovative decision analytic method for use with multiple-criteria assessment and selection in uncertain situations. The T-SF frame is the latest recent advancement in fuzzy settings and uses four facets (consisting of membership grades of positivity, neutrality, negativity, and refusal) to elucidate complex uncertainties, thereby evidently reducing information loss, in anticipation of fully manifesting indistinct and equivocal information. This paper adds to the body of knowledge regarding multiple criteria choice modeling by raising T-SF correlation-oriented measurements connected to the fixed and displaced ideal/anti-ideal benchmarks and by creating an approachable appraisal mechanism for advancing a T-SF decision analytic methodology. Consider, in particular, the performance ratings of available options in terms of judging criteria under the T-SF type of uncertainties. This research gives correlation-oriented measurements focusing on two varieties of maximum and square root functions in T-SF situations, which serve as a solid foundation for an efficacious appraisal mechanism from two views of anchored judgments corresponding to the fixed and displaced benchmarks. The T-SF Minkowski distance index is generated to integrate the outranking and outranked identifiers relying on correlation-oriented measurements for figuring out the local outranking and outranked indices. The T-SF decision analytic procedures are constructed using a new appraisal significance index that is founded on certain valuable insights of correlation-oriented maximizing and minimizing indices as well as global outranking and outranked indices. Additionally, a concrete location selection dilemma is dealt with in this research to showcase the applicability and efficiency of the suggested T-SF decision analytic methodology. Sensitivity analyses and comparative studies are carried out to investigate substantial modifications in pertinent parameters and to confirm the robustness of the predominance relationships among the available options. The suggested approaches are adaptable, flexible, and reliable, according to the application outcomes and comparison findings. This research provides four scientific contributions: (1) the utilization of T-SF correlation coefficients as the basis for prioritization analysis involving multiple criteria assessments, (2) the evolution of the T-SF Minkowski distance index to model outranking decision-making processes, (3) the creation of a reliable appraisal mechanism based on T-SF correlation-oriented measurements for intelligent decision support, and (4) the advancement of computational tools and procedures (e.g., correlation-oriented maximizing and minimizing indices, global outranking and outranked indices, and appraisal significance indices) to perform the decision analytic procedure in T-SF settings. In terms of managerial implications, the solution findings support the employment of the fixed ideal/anti-ideal benchmarking mechanism, as its measurements and indices are easy to operate and suitably sensitive. Next, in practical implementations of the T-SF decision analytic procedure, it is advised to utilize the T-SF Manhattan distance index for calculating convenience. Finally, the T-SF decision analytic techniques offer fundamental ideas and measurements appropriate for manipulating T-SF information in complex decision situations, thereby increasing the application potential in the area of decision-making with information uncertainty.},
  archive      = {J_AIR},
  author       = {Chen, Ting-Yu},
  doi          = {10.1007/s10462-023-10461-z},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {14087-14157},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Multiple criteria decision analytic methods in management with T-spherical fuzzy information},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning and deep learning techniques for the
analysis of heart disease: A systematic literature review, open
challenges and future directions. <em>AIR</em>, <em>56</em>(12),
14035–14086. (<a
href="https://doi.org/10.1007/s10462-023-10493-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Myocardial infarction, commonly known as heart attack, is one of the most common heart diseases prevailing in the human world. Heart or cardiac disease is one of the leading causes of human deaths. It is observed that cardiac arrest or cardiac disease mostly develop over time but are hard to discover due to the lack of knowledge and technology, mostly in developing countries. Even though these are preventable, the lack of experience and equipment is one of the leading factors for such a high death rate. In this study, we will discuss different practices used for the analysis of various heart diseases using Machine Learning (ML) and Deep Learning (DL) algorithms such as Convolutional Neural Networks (CNNs), recurrent neural networks, deep belief networks, long short-term memory, and others investigated by different researchers over the time span. The articles, for this study, were considered from 2018 to 2022 and after the screening, 63 articles were used for primary study. This systematic literature review on analysing heart diseases will help the future researchers to understand the pre-existing ML and DL practices in the healthcare industry. It gives an insight of the prominent techniques such as random forest, support vector machine, CNNs, decision tree, and so on. It also discusses the popular datasets used for the deployment of numerous diagnostic models. It also highlights the popular publishers along with journals and conferences from where the literature can be analysed. Further, it will help them in comprehending the existing open issues or challenges faced by the previous researchers. The most common issue was the unavailability of larger and discrete datasets followed by the improvement of the pre-existing models.},
  archive      = {J_AIR},
  author       = {Bhushan, Megha and Pandit, Akkshat and Garg, Ayush},
  doi          = {10.1007/s10462-023-10493-5},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {14035-14086},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Machine learning and deep learning techniques for the analysis of heart disease: A systematic literature review, open challenges and future directions},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Forty years of color quantization: A modern, algorithmic
survey. <em>AIR</em>, <em>56</em>(12), 13953–14034. (<a
href="https://doi.org/10.1007/s10462-023-10406-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Color quantization (cq), the reduction of the number of distinct colors in a given image with minimal distortion, is a common image processing operation with various applications in computer graphics, image processing/analysis, and computer vision. The first cq algorithm, median-cut, was proposed over 40 years ago. Since then, many clustering algorithms have been applied to the cq problem. In this paper, we present a comprehensive overview of the cq algorithms proposed in the literature. We first examine various aspects of cq, including the number of distinguishable colors, cq artifacts, types of cq, applications of cq, data structures, data reduction, color spaces and color difference equations, and color image fidelity assessment. We then provide an overview of image-independent cq algorithms, followed by a detailed survey of image-dependent ones. After presenting a brief discussion of pixel mapping, we conclude our survey with an outline of the open problems in cq.},
  archive      = {J_AIR},
  author       = {Celebi, M. Emre},
  doi          = {10.1007/s10462-023-10406-6},
  journal      = {Artificial Intelligence Review},
  number       = {12},
  pages        = {13953-14034},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Forty years of color quantization: A modern, algorithmic survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Author correction: Arabic natural language processing for
qur’anic research: A systematic review. <em>AIR</em>, <em>56</em>(11),
13951–13952. (<a
href="https://doi.org/10.1007/s10462-023-10390-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIR},
  author       = {Bashir, Muhammad Huzaifa and Azmi, Aqil M. and Nawaz, Haq and Zaghouani, Wajdi and Diab, Mona and Al-Fuqaha, Ala and Qadir, Junaid},
  doi          = {10.1007/s10462-023-10390-x},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {13951-13952},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Author correction: arabic natural language processing for qur’anic research: a systematic review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of fractional calculus applications in artificial
neural networks. <em>AIR</em>, <em>56</em>(11), 13897–13950. (<a
href="https://doi.org/10.1007/s10462-023-10474-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural network (ANN) is the backbone of machine learning, specifically deep learning. The interpolating and learning ability of an ANN makes it an ideal tool for modelling, control and various other complex tasks. Fractional calculus (FC) involving derivatives and integrals of arbitrary non-integer order has recently been popular for its capability to model memory-type systems. There have been many attempts to explore the possibilities of combining these two fields, the most popular combination being the use of fractional derivative in the learning algorithm. This paper reviews the use of fractional calculus in various artificial neural network architectures, such as radial basis functions, recurrent neural networks, backpropagation NNs, and convolutional neural networks. These ANNs are popularly known as fractional-order artificial neural networks (FANNs). A detailed review of the various concepts related to FANNs, including activation functions, training algorithms based on fractional derivative, stability, synchronization, hardware implementations of FANNs, and real-world applications of FANNs, is presented. The study also highlights the advantage of combining fractional derivatives with ANN, the impact of fractional derivative order on performance indices like mean square error, the time required for training and testing FANN, stability, and synchronization in FANN. The survey reports interesting observations: combining FC to an ANN endows it with the memory feature; Caputo definition of fractional derivative is the most commonly used in FANNs; fractional derivative-based activation functions in ANN provide additional adjustable hyperparameters to the networks; the FANN has more degree of freedom for adjusting parameters compared to an ordinary ANN; use of multiple types of activation functions can be employed in FANN, and many more.},
  archive      = {J_AIR},
  author       = {Joshi, Manisha and Bhosale, Savita and Vyawahare, Vishwesh A.},
  doi          = {10.1007/s10462-023-10474-8},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {13897-13950},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of fractional calculus applications in artificial neural networks},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The role of artificial intelligence in developing a banking
risk index: An application of adaptive neural network-based fuzzy
inference system (ANFIS). <em>AIR</em>, <em>56</em>(11), 13873–13895.
(<a href="https://doi.org/10.1007/s10462-023-10473-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Banking risk measurement and management remain one of many challenges for managers and policymakers. This study contributes to the banking literature and practice in two ways by (a) proposing a risk ranking index based on the Mahalanobis Distance (MD) between a multidimensional point representing a bank’s risk measures and the corresponding critical ratios set by the banking authorities and (b) determining the relative importance of a bank’s risk ratios in affecting its financial standing using an Adaptive Neuro-Fuzzy Inference System. In this study, ten financial ratios representing five risk areas were considered, namely: Capital Adequacy, Credit, Liquidity, Earning Quality, and Operational risk. Data from 45 Gulf banks for the period 2016–2020 was used to develop the model. Our findings indicate that a bank is in a sound risk position at the 99\%, 95\%, and 90\% confidence level if its Mahalanobis distance exceeds 4.82, 4.28, and 4.0, respectively. The maximum distance computed for the banks in this study was 9.31; only five out of the forty-five banks were below the 4.82 and one below the 4.28 and 4.0 thresholds at 3.96. Sensitivity analysis of the risks indicated that the Net Interest Margin is the most significant factor in explaining variations in a bank’s risk position, followed by Capital Adequacy Ratio, Common Equity Tier1, and Tier1 Equity in order. The remaining financial ratios: Non-Performing Loans, Equity Leverage, Cost Income Ratio, Loans to Total Assets, and Loans to Deposits have the least influence in the order given; the Provisional Loans Ratio appears to have no influence.},
  archive      = {J_AIR},
  author       = {Ahmed, Ibrahim Elsiddig and Mehdi, Riyadh and Mohamed, Elfadil A.},
  doi          = {10.1007/s10462-023-10473-9},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {13873-13895},
  shortjournal = {Artif. Intell. Rev.},
  title        = {The role of artificial intelligence in developing a banking risk index: An application of adaptive neural network-based fuzzy inference system (ANFIS)},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Literature review on intention mining-oriented process
mining in information system. <em>AIR</em>, <em>56</em>(11),
13841–13872. (<a
href="https://doi.org/10.1007/s10462-023-10490-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process Mining focused only on the activity-oriented process and neglected the users’ behaviors behind the activities, which led to overlooking the reality that they proposed to create. Recognizing the users’ underlying intentions can improve the guidance and offer better recommendations. As a result, an area of study known as Intention Mining has been merged. It aims at discovering the users’ behaviors using an event log. The intention is frequently used in different computer science research fields, including requirements definition, business process, and method engineering for context adaption. This paper reviews Intention-Oriented Process Mining based on event logs in the information systems engineering field. The objective is to identify the different models, methodologies, and algorithms proposed, the tools used, and the different challenges in these fields based on the four steps of review for the selection process, which start with the identification, followed by the screening, the eligibility, and the inclusion. For the first time, we are focused on Process Mining and intention mining based on log files and their relationship to get an idea about the area of intention mining. This paper reviews academic papers that are published in peer-reviewed venues from 2013 to 2022. These papers were examined through six main investigate questions and a systematic review. Also, we detailed the existing approaches in the Intention Mining area and present our comparative study. The results of the existing approaches indicate that Intention Mining shows a meaningful trace of research and creates existing opportunities for real technical applications.},
  archive      = {J_AIR},
  author       = {Bouricha, Hajer and Hsairi, Lobna and Ghédira, Khaled},
  doi          = {10.1007/s10462-023-10490-8},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {13841-13872},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Literature review on intention mining-oriented process mining in information system},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mathematical modeling and simulation of multi-focus image
fusion techniques using the effect of image enhancement criteria: A
systematic review and performance evaluation. <em>AIR</em>,
<em>56</em>(11), 13787–13839. (<a
href="https://doi.org/10.1007/s10462-023-10487-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image fusion is a long-established and well-known study area of digital image processing. The reason is its substantial approach in several practical applications in which multi-focus image fusion (MFIF) is one of the most essential and commonly employed applications in the current situation. However, low contrast, colour distortion, and different fusion losses are significant challenges that must be addressed while generating the composite image. So, this study proposes an experimental and comprehensive review with an idea/methodology to encounter these challenges in which pre-hand enhancement criteria are applied for both gray-scale and colour images before fusion for multi-focus images. First, a detailed analysis of many categories and their sub-categories is offered, providing the groundwork for this study. Following this, we explain the enhancement methodology, which utilises the histogram for gray-scale and colour balancing for colour images. Besides this, several non-reference objective evaluation fusion metrics are also presented. In addition, simulation using MATLAB software from the conventional approach to the recent deep learning approach is carried out with and without enhancement for twenty state-of-the-art MFIF algorithms to check the validity of the adopted criteria. The results obtained with the enhancement approach as a pre-processing step show that almost all the outcomes are better or comparable with the original methodologies in both an objective and subjective manner. Moreover, the additional running time of just 0.2582 s at pre-processing stage indicates little computational complexity. Lastly, we discuss the current status of research, ongoing difficulties, and future possibilities.},
  archive      = {J_AIR},
  author       = {Choudhary, Gaurav and Sethi, Dinesh},
  doi          = {10.1007/s10462-023-10487-3},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {13787-13839},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Mathematical modeling and simulation of multi-focus image fusion techniques using the effect of image enhancement criteria: A systematic review and performance evaluation},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fuzzy bayesian regression model with gaussian process
prior based on exact predictors and fuzzy responses. <em>AIR</em>,
<em>56</em>(11), 13765–13785. (<a
href="https://doi.org/10.1007/s10462-023-10485-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this study is to develop a new fuzzy regression model based on a common Bayesian nonparametric-based method with exact predictors and fuzzy responses. To this end, the left, center, and right values of the unknown fuzzy smooth function were evaluated based on the conventional kernel-based Bayesian method adopted with Gaussian kernel and a multivariate normal distribution as a prior distribution function in the cases where the residuals were assumed to be observed values of a normal distribution function. The unknown components of the model including bandwidth and variance were estimated via a hybrid algorithm. In this regard, a generalized cross-validation and similarity measure between two LR-fuzzy numbers were applied. The mean similarity measure criterion and a mean square error were utilized to assess the performance of the proposed method. Some applied examples and comparison studies were considered to clarify the proposed method and illustrate its performance relative to some common fuzzy nonlinear methods. The results indicated the superior performance of the proposed method over other nonlinear methods. Further, two essential assumptions associated with proposed regression models including homoscedasticity and normality of residuals were also analyzed in each example based on some common scatter plots and a well-established hypothesis test.},
  archive      = {J_AIR},
  author       = {Hesamian, Gholamreza and Akbari, Mohammad Ghasem},
  doi          = {10.1007/s10462-023-10485-5},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {13765-13785},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A fuzzy bayesian regression model with gaussian process prior based on exact predictors and fuzzy responses},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-task learning for few-shot biomedical relation
extraction. <em>AIR</em>, <em>56</em>(11), 13743–13763. (<a
href="https://doi.org/10.1007/s10462-023-10484-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) has advanced rapidly, but it has limited impact on biomedical text understanding due to a lack of annotated datasets (a.k.a. few-shot learning). Multi-task learning, which uses data from multiple datasets and tasks with related syntax and semantics, has potential to address this issue. However, the effectiveness of this approach heavily relies on the quality of the available data and its transferability between tasks. In this paper, we propose a framework, built upon a state-of-the-art multi-task method (i.e. MT-DNN), that leverages different publicly available biomedical datasets to enhance relation extraction performance. Our model employs a transformer-based architecture with shared encoding layers across multiple tasks, and task-specific classification layers to generate task-specific representations. To further improve performance, we utilize a knowledge distillation technique. In our experiments, we assess the impact of incorporating biomedical datasets in a multi-task learning setting and demonstrate that it consistently outperforms state-of-the-art few-shot learning methods in cases of limited data. This results in significant improvement across most datasets and few-shot scenarios, particularly in terms of recall scores.},
  archive      = {J_AIR},
  author       = {Moscato, Vincenzo and Napolano, Giuseppe and Postiglione, Marco and Sperlì, Giancarlo},
  doi          = {10.1007/s10462-023-10484-6},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {13743-13763},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Multi-task learning for few-shot biomedical relation extraction},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of multilayer extreme learning machine neural
networks. <em>AIR</em>, <em>56</em>(11), 13691–13742. (<a
href="https://doi.org/10.1007/s10462-023-10478-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Extreme Learning Machine is a single-hidden-layer feedforward learning algorithm, which has been successfully applied in regression and classification problems in different research fields. The traditional algorithm assigns random weights and biases in the hidden layer, and the Moore–Penrose inverse matrix in the regularized least-squares method is adopted to compute the weights of the output layer. Training speed, generalization ability, and robustness are the advantages that characterize this algorithm, but it has some shortcomings in solving highly nonlinear problems. The scientific community adopted non-iterative multilayer learning models as effective and efficient measures, starting with the Multilayer Extreme Learning Machine, which incorporates an unsupervised extreme learning Autoencoder into its architecture for feature mapping. Since the literature does not present an in-depth review of non-iterative multilayer models, this paper focuses on a current description of the evolution of multilayer models, which are grouped into random mappings, kernel-correntropy strategies, and conditional probability techniques. In addition to showing the mathematical fundamentals of each model, a list of databases widely used in training multilayer networks is included. Finally, we present a class of fast iterative algorithms called Shrinkage-Thresholding, which solve the minimization problem associated with an Autoencoder.},
  archive      = {J_AIR},
  author       = {Vásquez-Coronel, José A. and Mora, Marco and Vilches, Karina},
  doi          = {10.1007/s10462-023-10478-4},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {13691-13742},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review of multilayer extreme learning machine neural networks},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Some new product operations of t-spherical fuzzy graphs and
an application of t-spherical fuzzy graphs in MCGDM. <em>AIR</em>,
<em>56</em>(11), 13663–13689. (<a
href="https://doi.org/10.1007/s10462-023-10477-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A T-spherical fuzzy (T-SF) graph (T-SFG) structure is a generalization of the spherical fuzzy graphs (SFGs) and other extensions of the fuzzy graphs (FGs). In this paper, we define the strong product, cross product, lexicographic product, modular product, and homomorphic product operations between two T-SFGs and investigate some of their properties. We give examples to make the defined operations more understandable. We also propose a multi-criteria group decision-making (MCGDM) method under the T-SF-environment. Besides, a numerical example is given to show the progress of the proposed method.},
  archive      = {J_AIR},
  author       = {Karaaslan, Faruk and Karamaz, Fatih},
  doi          = {10.1007/s10462-023-10477-5},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {13663-13689},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Some new product operations of T-spherical fuzzy graphs and an application of T-spherical fuzzy graphs in MCGDM},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A comprehensive survey on image captioning: From handcrafted
to deep learning-based techniques, a taxonomy and open research issues.
<em>AIR</em>, <em>56</em>(11), 13619–13661. (<a
href="https://doi.org/10.1007/s10462-023-10488-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image captioning is a pretty modern area of the convergence of computer vision and natural language processing and is widely used in a range of applications such as multi-modal search, robotics, security, remote sensing, medical, and visual aid. The image captioning techniques have witnessed a paradigm shift from classical machine-learning-based approaches to the most contemporary deep learning-based techniques. We present an in-depth investigation of image captioning methodologies in this survey using our proposed taxonomy. Furthermore, the study investigates several eras of image captioning advancements, including template-based, retrieval-based, and encoder-decoder-based models. We also explore captioning in languages other than English. A thorough investigation of benchmark image captioning datasets and assessment measures is also discussed. The effectiveness of real-time image captioning is a severe barrier that prevents its use in sensitive applications such as visual aid, security, and medicine. Another observation from our research is the scarcity of personalized domain datasets that limits its adoption into more advanced issues. Despite influential contributions from several academics, further efforts are required to construct substantially robust and reliable image captioning models.},
  archive      = {J_AIR},
  author       = {Sharma, Himanshu and Padha, Devanand},
  doi          = {10.1007/s10462-023-10488-2},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {13619-13661},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comprehensive survey on image captioning: From handcrafted to deep learning-based techniques, a taxonomy and open research issues},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning modelling techniques: Current progress,
applications, advantages, and challenges. <em>AIR</em>, <em>56</em>(11),
13521–13617. (<a
href="https://doi.org/10.1007/s10462-023-10466-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) is revolutionizing evidence-based decision-making techniques that can be applied across various sectors. Specifically, it possesses the ability to utilize two or more levels of non-linear feature transformation of the given data via representation learning in order to overcome limitations posed by large datasets. As a multidisciplinary field that is still in its nascent phase, articles that survey DL architectures encompassing the full scope of the field are rather limited. Thus, this paper comprehensively reviews the state-of-art DL modelling techniques and provides insights into their advantages and challenges. It was found that many of the models exhibit a highly domain-specific efficiency and could be trained by two or more methods. However, training DL models can be very time-consuming, expensive, and requires huge samples for better accuracy. Since DL is also susceptible to deception and misclassification and tends to get stuck on local minima, improved optimization of parameters is required to create more robust models. Regardless, DL has already been leading to groundbreaking results in the healthcare, education, security, commercial, industrial, as well as government sectors. Some models, like the convolutional neural network (CNN), generative adversarial networks (GAN), recurrent neural network (RNN), recursive neural networks, and autoencoders, are frequently used, while the potential of other models remains widely unexplored. Pertinently, hybrid conventional DL architectures have the capacity to overcome the challenges experienced by conventional models. Considering that capsule architectures may dominate future DL models, this work aimed to compile information for stakeholders involved in the development and use of DL models in the contemporary world.},
  archive      = {J_AIR},
  author       = {Ahmed, Shams Forruque and Alam, Md. Sakib Bin and Hassan, Maruf and Rozbu, Mahtabin Rodela and Ishtiak, Taoseef and Rafa, Nazifa and Mofijur, M. and Shawkat Ali, A. B. M. and Gandomi, Amir H.},
  doi          = {10.1007/s10462-023-10466-8},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {13521-13617},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep learning modelling techniques: Current progress, applications, advantages, and challenges},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel adaptive memetic binary optimization algorithm for
feature selection. <em>AIR</em>, <em>56</em>(11), 13463–13520. (<a
href="https://doi.org/10.1007/s10462-023-10482-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) determines the beneficial features in data and decreases the disadvantages of the curse of dimensionality. This work proposes a novel adaptive memetic binary optimization (AMBO) algoraaithm for FS. FS is an NP-Hard binary optimization problem. AMBO is a pure binary optimization algorithm that works in binary discrete search space. New candidate individuals are adaptively created by a single point, double point, uniform crossovers, and canonical mutation mechanism. Local improvement for the best and worst individuals is provided with a new binary logic-gate based memetic smart local search mechanism. The balance between exploration and exploitation is achieved by adaptively. A diverse dimension dataset experimental setup is provided for determining the success of the proposed method. AMBO firstly was compared with binary particle swarm optimization (BPSO), a genetic algorithm with a random wheel selection strategy (GARW), a genetic algorithm with a tournaments selection strategy (GATS), and a genetic algorithm with a random selection strategy (GARS). AMBO outperformed the opponents on 11 datasets, especially the largest one. Wilcoxon signed-rank test and Friedman’s test were conducted to show the statistical significance of AMBO. For an additional experiment with state-of-art metaheuristic algorithms in the literature, Population reduction binary gaining sharing knowledge-based algorithm with V-4 shaped transfer function (PbGSK-V4), binary salp swarm algorithm (BSSA), binary differential evolution algorithm (BDE), binary dragonfly algorithm (BDA), binary particle swarm optimization algorithm (BPSO), binary bat algorithm (BBA), binary ant lion optimization (BALO) and binary grey wolf optimizer (BGWO) are used in experiments with 21 datasets. The experimental results of the proposed AMBO algorithm are significantly better than the state-of-art algorithms, in terms of classification error rate, fitness function, and average selected features.},
  archive      = {J_AIR},
  author       = {Cinar, Ahmet Cevahir},
  doi          = {10.1007/s10462-023-10482-8},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {13463-13520},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A novel adaptive memetic binary optimization algorithm for feature selection},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic review of social network sentiment analysis
with comparative study of ensemble-based techniques. <em>AIR</em>,
<em>56</em>(11), 13407–13461. (<a
href="https://doi.org/10.1007/s10462-023-10472-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment Analysis (SA) of text reviews is an emerging concern in Natural Language Processing (NLP). It is a broadly active method for analyzing and extracting opinions from text using individual or ensemble learning techniques. This field has unquestionable potential in the digital world and social media platforms. Therefore, we present a systematic survey that organizes and describes the current scenario of the SA and provides a structured overview of proposed approaches from traditional to advance. This work also discusses the SA-related challenges, feature engineering techniques, benchmark datasets, popular publication platforms, and best algorithms to advance the automatic SA. Furthermore, a comparative study has been conducted to assess the performance of bagging and boosting-based ensemble techniques for social network SA. Bagging and Boosting are two major approaches of ensemble learning that contain various ensemble algorithms to classify sentiment polarity. Recent studies recommend that ensemble learning techniques have the potential of applicability for sentiment classification. This analytical study examines the bagging and boosting-based ensemble techniques on four benchmark datasets to provide extensive knowledge regarding ensemble techniques for SA. The efficiency and accuracy of these techniques have been measured in terms of TPR, FPR, Weighted F-Score, Weighted Precision, Weighted Recall, Accuracy, ROC-AUC curve, and Run-Time. Moreover, comparative results reveal that bagging-based ensemble techniques outperformed boosting-based techniques for text classification. This extensive review aims to present benchmark information regarding social network SA that will be helpful for future research in this field.},
  archive      = {J_AIR},
  author       = {Tiwari, Dimple and Nagpal, Bharti and Bhati, Bhoopesh Singh and Mishra, Ashutosh and Kumar, Manoj},
  doi          = {10.1007/s10462-023-10472-w},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {13407-13461},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A systematic review of social network sentiment analysis with comparative study of ensemble-based techniques},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The q-rung fuzzy LOPCOW-VIKOR model to assess the role of
unmanned aerial vehicles for precision agriculture realization in the
agri-food 4.0 era. <em>AIR</em>, <em>56</em>(11), 13373–13406. (<a
href="https://doi.org/10.1007/s10462-023-10476-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart agriculture is gaining a lot of attention recently, owing to technological advancement and promotion of sustainable habits. Unmanned aerial vehicles (UAVs) play a crucial role in smart agriculture by aiding in different phases of agriculture. The contribution of UAVs to sustainable and precision agriculture is a critical and challenging issue to be taken into account, particularly for smallholder farmers in order to save time and money, and improve their agricultural skills. Thence, this study targets to propose an integrated group decision-making framework to determine the best agricultural UAV. Previous studies on UAV evaluation, (i) could not model uncertainty effectively, (ii) weights of experts are not methodically determined; (iii) importance of experts and criteria types are not considered during criteria weight calculation, and (iv) personalized ranking of UAVs is lacking along with consideration to dual weight entities. Herein, nine critical selection criteria are identified, drawing upon the relevant literature and experts’ opinions, and five extant UAVs are considered for evaluation. To circumvent the gaps, in this work, a new integrated framework is developed considering q-rung orthopair fuzzy numbers (q-ROFNs) for apt UAV selection. Specifically, methodical estimation of experts’ weights is achieved by presenting the regret measure. Further, weighted logarithmic percentage change-driven objective weighting (LOPCOW) technique is formulated for criteria weight calculation, and an algorithm for personalized ranking of UAVs is presented with visekriterijumska optimizacija i kompromisno resenje (VIKOR) approach combined with Copeland strategy. The findings show that the foremost criteria in agricultural UAV selection are “camera,” “power system,” and “radar system,” respectively. Further, it is inferred that the most promising UAV is the DJ AGRAS T30. Since the applicability of UAV in agriculture will get inevitable, the developed framework can be an effective decision support system for farmers, managers, policymakers, and other stakeholders.},
  archive      = {J_AIR},
  author       = {Ecer, Fatih and Ögel, İlkin Yaran and Krishankumar, Raghunathan and Tirkolaee, Erfan Babaee},
  doi          = {10.1007/s10462-023-10476-6},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {13373-13406},
  shortjournal = {Artif. Intell. Rev.},
  title        = {The q-rung fuzzy LOPCOW-VIKOR model to assess the role of unmanned aerial vehicles for precision agriculture realization in the agri-food 4.0 era},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Video description: A comprehensive survey of deep learning
approaches. <em>AIR</em>, <em>56</em>(11), 13293–13372. (<a
href="https://doi.org/10.1007/s10462-023-10414-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video description refers to understanding visual content and transforming that acquired understanding into automatic textual narration. It bridges the key AI fields of computer vision and natural language processing in conjunction with real-time and practical applications. Deep learning-based approaches employed for video description have demonstrated enhanced results compared to conventional approaches. The current literature lacks a thorough interpretation of the recently developed and employed sequence to sequence techniques for video description. This paper fills that gap by focusing mainly on deep learning-enabled approaches to automatic caption generation. Sequence to sequence models follow an Encoder–Decoder architecture employing a specific composition of CNN, RNN, or the variants LSTM or GRU as an encoder and decoder block. This standard-architecture can be fused with an attention mechanism to focus on a specific distinctiveness, achieving high quality results. Reinforcement learning employed within the Encoder–Decoder structure can progressively deliver state-of-the-art captions by following exploration and exploitation strategies. The transformer mechanism is a modern and efficient transductive architecture for robust output. Free from recurrence, and solely based on self-attention, it allows parallelization along with training on a massive amount of data. It can fully utilize the available GPUs for most NLP tasks. Recently, with the emergence of several versions of transformers, long term dependency handling is not an issue anymore for researchers engaged in video processing for summarization and description, or for autonomous-vehicle, surveillance, and instructional purposes. They can get auspicious directions from this research.},
  archive      = {J_AIR},
  author       = {Rafiq, Ghazala and Rafiq, Muhammad and Choi, Gyu Sang},
  doi          = {10.1007/s10462-023-10414-6},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {13293-13372},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Video description: A comprehensive survey of deep learning approaches},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classification of spinal curvature types using radiography
images: Deep learning versus classical methods. <em>AIR</em>,
<em>56</em>(11), 13259–13291. (<a
href="https://doi.org/10.1007/s10462-023-10480-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scoliosis is a spinal abnormality that has two types of curves (C-shaped or S-shaped). The vertebrae of the spine reach an equilibrium at different times, which makes it challenging to detect the type of curves. In addition, it may be challenging to detect curvatures due to observer bias and image quality. This paper aims to evaluate spinal deformity by automatically classifying the type of spine curvature. Automatic spinal curvature classification is performed using SVM and KNN algorithms, and pre-trained Xception and MobileNetV2 networks with SVM as the final activation function to avoid vanishing gradient. Different feature extraction methods should be used to investigate the SVM and KNN machine learning methods in detecting the curvature type. Features are extracted through the representation of radiographic images. These representations are of two groups: (i) Low-level image representation techniques such as texture features and (ii) local patch-based representations such as Bag of Words (BoW). Such features are utilized by various algorithms for classification by SVM and KNN. The feature extraction process is automated in pre-trained deep networks. In this study, 1000 anterior–posterior (AP) radiographic images of the spine were collected as a private dataset from Shafa Hospital, Tehran, Iran. The transfer learning was used due to the relatively small private dataset of anterior–posterior radiology images of the spine. Based on the results of these experiments, pre-trained deep networks were found to be approximately 10\% more accurate than classical methods in classifying whether the spinal curvature is C-shaped or S-shaped. As a result of automatic feature extraction, it has been found that the pre-trained Xception and mobilenetV2 networks with SVM as the final activation function for controlling the vanishing gradient perform better than the classical machine learning methods of classification of spinal curvature types.},
  archive      = {J_AIR},
  author       = {Tavana, Parisa and Akraminia, Mahdi and Koochari, Abbas and Bagherifard, Abolfazl},
  doi          = {10.1007/s10462-023-10480-w},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {13259-13291},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Classification of spinal curvature types using radiography images: Deep learning versus classical methods},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An exhaustive review of the metaheuristic algorithms for
search and optimization: Taxonomy, applications, and open challenges.
<em>AIR</em>, <em>56</em>(11), 13187–13257. (<a
href="https://doi.org/10.1007/s10462-023-10470-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the world moves towards industrialization, optimization problems become more challenging to solve in a reasonable time. More than 500 new metaheuristic algorithms (MAs) have been developed to date, with over 350 of them appearing in the last decade. The literature has grown significantly in recent years and should be thoroughly reviewed. In this study, approximately 540 MAs are tracked, and statistical information is also provided. Due to the proliferation of MAs in recent years, the issue of substantial similarities between algorithms with different names has become widespread. This raises an essential question: can an optimization technique be called ‘novel’ if its search properties are modified or almost equal to existing methods? Many recent MAs are said to be based on ‘novel ideas’, so they are discussed. Furthermore, this study categorizes MAs based on the number of control parameters, which is a new taxonomy in the field. MAs have been extensively employed in various fields as powerful optimization tools, and some of their real-world applications are demonstrated. A few limitations and open challenges have been identified, which may lead to a new direction for MAs in the future. Although researchers have reported many excellent results in several research papers, review articles, and monographs during the last decade, many unexplored places are still waiting to be discovered. This study will assist newcomers in understanding some of the major domains of metaheuristics and their real-world applications. We anticipate this resource will also be useful to our research community.},
  archive      = {J_AIR},
  author       = {Rajwar, Kanchan and Deep, Kusum and Das, Swagatam},
  doi          = {10.1007/s10462-023-10470-y},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {13187-13257},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An exhaustive review of the metaheuristic algorithms for search and optimization: Taxonomy, applications, and open challenges},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A critical empirical evaluation of deep learning models for
solving aspect based sentiment analysis. <em>AIR</em>, <em>56</em>(11),
13127–13186. (<a
href="https://doi.org/10.1007/s10462-023-10460-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) has captured great attention from researchers and industrialists owing to their pulverized nature of sentiment analysis task and the goal to anticipate sentiment polarity of given aspect of provided text. Massive growth nudged the researchers to innovate methodologies and strategies for every distinct research analysis question which could muddle through the impending concerns and composite schema of ABSA. The exponential growth of deep learning has extensively labeled this task with several Deep Neural Network (DNN) models. This survey article furnishes a comparative review about the proposed cutting-edge deep learning methods to solve an ABSA problem infusing the common exemplar datasets, assessment metrics and available performance analysis of deep-learning methods. The critical analysis of the materialized current solutions has proposed future research pathways for researchers and hence is instrumental for tweaking sentiment classification at aspect-level.},
  archive      = {J_AIR},
  author       = {Dhanith, P. R. Joe and Prabha, K. S. Sakunthala},
  doi          = {10.1007/s10462-023-10460-0},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {13127-13186},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A critical empirical evaluation of deep learning models for solving aspect based sentiment analysis},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The crowd dynamics under terrorist attacks revealed by
simulations of three-dimensional agents. <em>AIR</em>, <em>56</em>(11),
13103–13125. (<a
href="https://doi.org/10.1007/s10462-023-10452-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The terrorist attack has been widely modeled, in terms of crowd behavior, complex environments, attack patterns, and evacuation systems. However, most models are two-dimensional, which is unreal. The 3D factors, especially individual heights, will significantly shape both the process and outcome of terrorist attacks. Hence, the 3D model is more realistic. Taking the example of the Peshawar shooting in 2014, we apply 3D agents to reveal real-world behaviors of individuals, such as hiding, fighting, and escaping during the whole process. Based on the optimal solution out of simulations, the validity and robustness of our model can be well supported. To reveal the exact effects of key factors or mechanisms, we use counterfactual experiments and have some findings. For the fighting, more fighting of heroes can save more civilians. The hiding action of civilians can reduce the death probability. When the fighting rate in the crowd is higher, choosing to hide may be advisable for civilians. Meanwhile, hiding also has more benefits from increasing the hiding rate. A huge crowd hiding may reduce the fighting rate and then cause more deaths. Based on situations, the hiding should be chosen to maximize the gains. Our 3D model has made theoretical contributions to the field of public health and human behavior. It implies that civilians should hide properly, and be self-encouraged to be heroes, which should be advocated by the public.},
  archive      = {J_AIR},
  author       = {Lu, Peng and Li, Mengdi and Zhang, Zhuo},
  doi          = {10.1007/s10462-023-10452-0},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {13103-13125},
  shortjournal = {Artif. Intell. Rev.},
  title        = {The crowd dynamics under terrorist attacks revealed by simulations of three-dimensional agents},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge graphs: Opportunities and challenges.
<em>AIR</em>, <em>56</em>(11), 13071–13102. (<a
href="https://doi.org/10.1007/s10462-023-10465-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive growth of artificial intelligence (AI) and big data, it has become vitally important to organize and represent the enormous volume of knowledge appropriately. As graph data, knowledge graphs accumulate and convey knowledge of the real world. It has been well-recognized that knowledge graphs effectively represent complex information; hence, they rapidly gain the attention of academia and industry in recent years. Thus to develop a deeper understanding of knowledge graphs, this paper presents a systematic overview of this field. Specifically, we focus on the opportunities and challenges of knowledge graphs. We first review the opportunities of knowledge graphs in terms of two aspects: (1) AI systems built upon knowledge graphs; (2) potential application fields of knowledge graphs. Then, we thoroughly discuss severe technical challenges in this field, such as knowledge graph embeddings, knowledge acquisition, knowledge graph completion, knowledge fusion, and knowledge reasoning. We expect that this survey will shed new light on future research and the development of knowledge graphs.},
  archive      = {J_AIR},
  author       = {Peng, Ciyuan and Xia, Feng and Naseriparsa, Mehdi and Osborne, Francesco},
  doi          = {10.1007/s10462-023-10465-9},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {13071-13102},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Knowledge graphs: Opportunities and challenges},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic review on fruit fly optimization algorithm and
its applications. <em>AIR</em>, <em>56</em>(11), 13015–13069. (<a
href="https://doi.org/10.1007/s10462-023-10451-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fruit Fly Optimization Algorithm (FOA) is a metaheuristic algorithm inspired by fruit fly foraging behaviours. A large numbers of variants of FOA have been proposed by many researchers. These have been applied to solve various engineering optimization problems. The existing variants and improvements can be categorized as discrete, chaotic, hybrid, improved or modified, and multi-objective. In this paper, a systematic review of FOA has been presented. The review investigates into FOA variants and their pros and cons, as well as FOA applications in various engineering fields. The study is carried out using the PRISMA methodology. The manuscripts have been identified and included in the review using this methodology. In general, researchers around the world confront difficulties in identifying appropriate algorithms to handle real-world optimization problems. This study can be used by researchers to address real-world problems in various domains using FOA, and it can also be used to design variants of FOA and other metaheuristic algorithms.},
  archive      = {J_AIR},
  author       = {Ranjan, Ranjeet Kumar and Kumar, Vijay},
  doi          = {10.1007/s10462-023-10451-1},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {13015-13069},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A systematic review on fruit fly optimization algorithm and its applications},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A comprehensive review of binary neural network.
<em>AIR</em>, <em>56</em>(11), 12949–13013. (<a
href="https://doi.org/10.1007/s10462-023-10464-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) has recently changed the development of intelligent systems and is widely adopted in many real-life applications. Despite their various benefits and potentials, there is a high demand for DL processing in different computationally limited and energy-constrained devices. It is natural to study game-changing technologies such as Binary Neural Networks (BNN) to increase DL capabilities. Recently remarkable progress has been made in BNN since they can be implemented and embedded on tiny restricted devices and save a significant amount of storage, computation cost, and energy consumption. However, nearly all BNN acts trade with extra memory, computation cost, and higher performance. This article provides a complete overview of recent developments in BNN. This article focuses exclusively on 1-bit activations and weights 1-bit convolution networks, contrary to previous surveys in which low-bit works are mixed in. It conducted a complete investigation of BNN’s development—from their predecessors to the latest BNN algorithms/techniques, presenting a broad design pipeline and discussing each module’s variants. Along the way, it examines BNN (a) purpose: their early successes and challenges; (b) BNN optimization: selected representative works that contain essential optimization techniques; (c) deployment: open-source frameworks for BNN modeling and development; (d) terminal: efficient computing architectures and devices for BNN and (e) applications: diverse applications with BNN. Moreover, this paper discusses potential directions and future research opportunities in each section.},
  archive      = {J_AIR},
  author       = {Yuan, Chunyu and Agaian, Sos S.},
  doi          = {10.1007/s10462-023-10464-w},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {12949-13013},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comprehensive review of binary neural network},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reinforcement learning for predictive maintenance: A
systematic technical review. <em>AIR</em>, <em>56</em>(11), 12885–12947.
(<a href="https://doi.org/10.1007/s10462-023-10468-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The manufacturing world is subject to ever-increasing cost optimization pressures. Maintenance adds to cost and disrupts production; optimized maintenance is therefore of utmost interest. As an autonomous learning mechanism reinforcement learning (RL) is increasingly used to solve complex tasks. While designing an optimal, model-free RL solution for predictive maintenance (PdM) is an attractive proposition, there are several key steps and design elements to be considered—from modeling degradation of the physical equipment to creating RL formulations. In this article, we survey how researchers have applied RL to optimally predict maintenance in diverse forms—from early diagnosis to computing a “health index” to directly suggesting a maintenance action. Contributions of this article include developing a taxonomy for PdM techniques in general and one specifically for RL applied to PdM. We discovered and studied unique techniques and applications by applying $$tf-idf$$ (a text mining technique). Furthermore, we systematically studied how researchers have mathematically formulated RL concepts and included some detailed case-studies that help demonstrate the complete flow of applying RL to PdM. Finally, in Sect. 14, we summarize the insights for researchers, and for the industrial practitioner we lay out a simple approach for implementing RL for PdM.},
  archive      = {J_AIR},
  author       = {Siraskar, Rajesh and Kumar, Satish and Patil, Shruti and Bongale, Arunkumar and Kotecha, Ketan},
  doi          = {10.1007/s10462-023-10468-6},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {12885-12947},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Reinforcement learning for predictive maintenance: A systematic technical review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vision-based techniques for automatic marine plankton
classification. <em>AIR</em>, <em>56</em>(11), 12853–12884. (<a
href="https://doi.org/10.1007/s10462-023-10456-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plankton are an important component of life on Earth. Since the 19th century, scientists have attempted to quantify species distributions using many techniques, such as direct counting, sizing, and classification with microscopes. Since then, extraordinary work has been performed regarding the development of plankton imaging systems, producing a massive backlog of images that await classification. Automatic image processing and classification approaches are opening new avenues for avoiding time-consuming manual procedures. While some algorithms have been adapted from many other applications for use with plankton, other exciting techniques have been developed exclusively for this issue. Achieving higher accuracy than that of human taxonomists is not yet possible, but an expeditious analysis is essential for discovering the world beyond plankton. Recent studies have shown the imminent development of real-time, in situ plankton image classification systems, which have only been slowed down by the complex implementations of algorithms on low-power processing hardware. This article compiles the techniques that have been proposed for classifying marine plankton, focusing on automatic methods that utilize image processing, from the beginnings of this field to the present day.},
  archive      = {J_AIR},
  author       = {Sosa-Trejo, David and Bandera, Antonio and González, Martín and Hernández-León, Santiago},
  doi          = {10.1007/s10462-023-10456-w},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {12853-12884},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Vision-based techniques for automatic marine plankton classification},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detecting hate speech in memes: A review. <em>AIR</em>,
<em>56</em>(11), 12833–12851. (<a
href="https://doi.org/10.1007/s10462-023-10459-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Methods that detect hate speech in memes have become vital in our connected society, especially in the context of many social media companies. Memes are a quick way to transfer ideas, events, or other content from the real world to the digital one. Massively created, they reproduce like viruses and aim to get people’s attention. They are powerful tools, that, when used to spread hate speech, are able to have global reach. Meme has a broad definition and different formats, such as short videos, GIFS, challenges, among others. In this paper, we follow the classical format of an image with superimposed text. In this context, the hateful meme detection task is extremely challenging, especially due to memes’ multimodal nature, i.e., they have two different sources: image and text. Consequently, when dealing with memes, a classification model needs to tackle both components in order to classify them as hateful or not-hateful. This work contributes to the effort to solve this task. We list the most recent research, synthesize and discuss the approaches proposed in the current literature by providing a critical analysis of these methods, highlighting their strengths and points to improve. We also introduce a taxonomy to allow grouping similar approaches. Our conclusion indicates that, despite the few studies currently available and the few public datasets specially designed for this topic, there is an evolution in the methodologies used, which is reflected in the evolution of the results attained.},
  archive      = {J_AIR},
  author       = {Hermida, Paulo Cezar de Q. and Santos, Eulanda M. dos},
  doi          = {10.1007/s10462-023-10459-7},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {12833-12851},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Detecting hate speech in memes: A review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic review of artificial intelligence impact
assessments. <em>AIR</em>, <em>56</em>(11), 12799–12831. (<a
href="https://doi.org/10.1007/s10462-023-10420-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) is producing highly beneficial impacts in many domains, from transport to healthcare, from energy distribution to marketing, but it also raises concerns about undesirable ethical and social consequences. AI impact assessments (AI-IAs) are a way of identifying positive and negative impacts early on to safeguard AI’s benefits and avoid its downsides. This article describes the first systematic review of these AI-IAs. Working with a population of 181 documents, the authors identified 38 actual AI-IAs and subjected them to a rigorous qualitative analysis with regard to their purpose, scope, organisational context, expected issues, timeframe, process and methods, transparency and challenges. The review demonstrates some convergence between AI-IAs. It also shows that the field is not yet at the point of full agreement on content, structure and implementation. The article suggests that AI-IAs are best understood as means to stimulate reflection and discussion concerning the social and ethical consequences of AI ecosystems. Based on the analysis of existing AI-IAs, the authors describe a baseline process of implementing AI-IAs that can be implemented by AI developers and vendors and that can be used as a critical yardstick by regulators and external observers to evaluate organisations’ approaches to AI.},
  archive      = {J_AIR},
  author       = {Stahl, Bernd Carsten and Antoniou, Josephina and Bhalla, Nitika and Brooks, Laurence and Jansen, Philip and Lindqvist, Blerta and Kirichenko, Alexey and Marchal, Samuel and Rodrigues, Rowena and Santiago, Nicole and Warso, Zuzanna and Wright, David},
  doi          = {10.1007/s10462-023-10420-8},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {12799-12831},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A systematic review of artificial intelligence impact assessments},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Applications of AI in oil and gas projects towards
sustainable development: A systematic literature review. <em>AIR</em>,
<em>56</em>(11), 12771–12798. (<a
href="https://doi.org/10.1007/s10462-023-10467-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oil and gas construction projects are critical for meeting global demand for fossil fuels, but they also present unique risks and challenges that require innovative construction approaches. Artificial Intelligence (AI) has emerged as a promising technology for tackling these challenges, and this study examines its applications for sustainable development in the oil and gas industry. Using a systematic literature review (SLR), this research evaluates research trends from 2011 to 2022. It provides a detailed analysis of how AI suits oil and gas construction. A total of 115 research articles were reviewed to identify original contributions, and the findings indicate a positive trend in AI research related to oil and gas construction projects, especially after 2016. The originality of this study lies in its comprehensive analysis of the latest research on AI applications in the oil and gas industry and its contribution to developing recommendations for improving the sustainability of oil and gas projects. This research’s originality is in providing insight into the most promising AI applications and methodologies that can help drive sustainable development in the oil and gas industry.},
  archive      = {J_AIR},
  author       = {Waqar, Ahsan and Othman, Idris and Shafiq, Nasir and Mansoor, Muhammad Shoaib},
  doi          = {10.1007/s10462-023-10467-7},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {12771-12798},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Applications of AI in oil and gas projects towards sustainable development: A systematic literature review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detection of cross-site scripting (XSS) attacks using
machine learning techniques: A review. <em>AIR</em>, <em>56</em>(11),
12725–12769. (<a
href="https://doi.org/10.1007/s10462-023-10433-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rising demand for E-commerce, Social Networking websites, it has become essential to develop security protocols over the World Wide Web that can provide security and privacy to Internet users all over the globe. Several traditional encryption techniques and attack detection protocols can secure the data transmitted over public networks. However, hackers can effortlessly exploit them to acquire access to the users’ sensitive information such as user ID, session ID, cookies, passwords, bank account details, contact numbers, private PINs, database information, etc. Researchers have continuously innovated new techniques to build a secure and robust system that cannot be easily hacked and manipulated. Still, there is much scope for novelty to provide security against contemporary techniques used by intruders. The motivation of this survey is to observe the recent developments in Cross-Site Scripting attacks and techniques used by researchers to secure confidential information. Cross-Site Scripting (XSS) has been recognized as one of the top 10 online application security risks by the Open Web Application Security Project (OWASP) for decades. Therefore, dealing with this security flaw in web applications has become essential to avoid further personal and financial damage to Internet users and business organizations. There is a need for an extensive survey of recent XSS attack detection techniques that can provide the right direction to researchers and security professionals. We present a complete overview of recent machine learning and neural network-based XSS attack detection techniques in this paper, covering deep neural networks, decision trees, web-log-based detection models, and many more. This paper also highlights the research gaps that must be addressed while designing attack detection models. Further, challenges researchers face during the development of recent techniques are also discussed. Finally, future directions are provided to reflect on new concepts that can be used in forthcoming research works to improve XSS attack detection techniques.},
  archive      = {J_AIR},
  author       = {Kaur, Jasleen and Garg, Urvashi and Bathla, Gourav},
  doi          = {10.1007/s10462-023-10433-3},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {12725-12769},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Detection of cross-site scripting (XSS) attacks using machine learning techniques: A review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An advanced similarity measure for pythagorean fuzzy sets
and its applications in transportation problem. <em>AIR</em>,
<em>56</em>(11), 12689–12724. (<a
href="https://doi.org/10.1007/s10462-023-10421-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty is excessively a common, inevitable, and conspicuopus aspect of any decision-making process, including transportation problems. Since its inception, a plethora of uncertainty representation methods has been put forward to deal with uncertainty by various researchers. Among those, fuzzy set and Intuitionistic fuzzy set is remarkably effective representation methods of uncertainty modeling. However, the existing uncertainty modeling methods have some severe limitations. Consequently, here we adopt the concept of the Pythagorean fuzzy set, an extension of the intuitionistic fuzzy set for its extensive flexibility characteristic and advantages. On the other hand, the similarity measure plays a crucial role in transportation problems under uncertainty. Therefore, we strive to introduce an advanced similarity measure of Pythagorean fuzzy sets. The proposed similarity measure is constructed based on the distances of the degree of membership, non-membership, and hesitancy of Pythagorean fuzzy sets. The present similarity measure also holds the general axioms of the similarity measure. Furthermore, we adopt some numerical examples to showcase the superiority of the proposed similarity measure and apply it to solve transportation problems. The core motive for transportation problems is minimizing transportation costs, and hence, we modified Monalisa’s method of Pythagorean fuzzy sets with the help of the proposed similarity measure. The proposed method has been demonstrated with an example and compared its output with the other pre-existing methods available in the literature. At length, statistical tests and result analysis are drawn to judge the significance of the proposed method.},
  archive      = {J_AIR},
  author       = {Saikia, Bornali and Dutta, Palash and Talukdar, Pranjal},
  doi          = {10.1007/s10462-023-10421-7},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {12689-12724},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An advanced similarity measure for pythagorean fuzzy sets and its applications in transportation problem},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Reinforcement learning architecture for
cyber–physical–social AI: State-of-the-art and perspectives.
<em>AIR</em>, <em>56</em>(11), 12655–12688. (<a
href="https://doi.org/10.1007/s10462-023-10450-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the extension of cyber–physical systems (CPSs), cyber–physical–social systems (CPSSs) seamlessly integrate cyber space, physical space, and social space. CPSS provide a more comprehensive smart space of perception for Reinforcement Learning (RL), so as to lead a revolution in Artificial Intelligence (AI), which urgently require innovation in computing system architecture. This paper aims to provide a comprehensive review and perspectives of RL architecture for collaborative computing system in CPSS. Firstly, we analyze CPSS AI’s features from data perspective, including multi-modal data fusion from multi-spaces, and rule discover and representation, collaborative computing system architectures for multi-spaces, intelligent decision-making (policy) discovery. After that, we propose to use the action aware transition tensor to fuse the CPSS data for collaborative RL. Then the typical architectures and methods of RL are surveyed. Furthermore, a tensor based unified collaborative computing reinforcement architecture are proposed for CPSS AI, including architecture and optimal policy solution. In the end, we summarize the paper and discuss the future work.},
  archive      = {J_AIR},
  author       = {Li, Xue and Wang, Puming and Jin, Xin and Jiang, Qian and Zhou, Wei and Yao, Saowen},
  doi          = {10.1007/s10462-023-10450-2},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {12655-12688},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Reinforcement learning architecture for cyber–physical–social AI: State-of-the-art and perspectives},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Review on chest pathogies detection systems using deep
learning techniques. <em>AIR</em>, <em>56</em>(11), 12607–12653. (<a
href="https://doi.org/10.1007/s10462-023-10457-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chest radiography is the standard and most affordable way to diagnose, analyze, and examine different thoracic and chest diseases. Typically, the radiograph is examined by an expert radiologist or physician to decide about a particular anomaly, if exists. Moreover, computer-aided methods are used to assist radiologists and make the analysis process accurate, fast, and more automated. A tremendous improvement in automatic chest pathologies detection and analysis can be observed with the emergence of deep learning. The survey aims to review, technically evaluate, and synthesize the different computer-aided chest pathologies detection systems. The state-of-the-art of single and multi-pathologies detection systems, which are published in the last five years, are thoroughly discussed. The taxonomy of image acquisition, dataset preprocessing, feature extraction, and deep learning models are presented. The mathematical concepts related to feature extraction model architectures are discussed. Moreover, the different articles are compared based on their contributions, datasets, methods used, and the results achieved. The article ends with the main findings, current trends, challenges, and future recommendations.},
  archive      = {J_AIR},
  author       = {Rehman, Arshia and Khan, Ahmad and Fatima, Gohar and Naz, Saeeda and Razzak, Imran},
  doi          = {10.1007/s10462-023-10457-9},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {12607-12653},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Review on chest pathogies detection systems using deep learning techniques},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Medical image data augmentation: Techniques, comparisons and
interpretations. <em>AIR</em>, <em>56</em>(11), 12561–12605. (<a
href="https://doi.org/10.1007/s10462-023-10453-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing deep learning based methods with medical images has always been an attractive area of research to assist clinicians in rapid examination and accurate diagnosis. Those methods need a large number of datasets including all variations in their training stages. On the other hand, medical images are always scarce due to several reasons, such as not enough patients for some diseases, patients do not want to allow their images to be used, lack of medical equipment or equipment, inability to obtain images that meet the desired criteria. This issue leads to bias in datasets, overfitting, and inaccurate results. Data augmentation is a common solution to overcome this issue and various augmentation techniques have been applied to different types of images in the literature. However, it is not clear which data augmentation technique provides more efficient results for which image type since different diseases are handled, different network architectures are used, and these architectures are trained and tested with different numbers of data sets in the literature. Therefore, in this work, the augmentation techniques used to improve performances of deep learning based diagnosis of the diseases in different organs (brain, lung, breast, and eye) from different imaging modalities (MR, CT, mammography, and fundoscopy) have been examined. Also, the most commonly used augmentation methods have been implemented, and their effectiveness in classifications with a deep network has been discussed based on quantitative performance evaluations. Experiments indicated that augmentation techniques should be chosen carefully according to image types.},
  archive      = {J_AIR},
  author       = {Goceri, Evgin},
  doi          = {10.1007/s10462-023-10453-z},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {12561-12605},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Medical image data augmentation: Techniques, comparisons and interpretations},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sentiment analysis: A survey on design framework,
applications and future scopes. <em>AIR</em>, <em>56</em>(11),
12505–12560. (<a
href="https://doi.org/10.1007/s10462-023-10442-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is a solution that enables the extraction of a summarized opinion or minute sentimental details regarding any topic or context from a voluminous source of data. Even though several research papers address various sentiment analysis methods, implementations, and algorithms, a paper that includes a thorough analysis of the process for developing an efficient sentiment analysis model is highly desirable. Various factors such as extraction of relevant sentimental words, proper classification of sentiments, dataset, data cleansing, etc. heavily influence the performance of a sentiment analysis model. This survey presents a systematic and in-depth knowledge of different techniques, algorithms, and other factors associated with designing an effective sentiment analysis model. The paper performs a critical assessment of different modules of a sentiment analysis framework while discussing various shortcomings associated with the existing methods or systems. The paper proposes potential multidisciplinary application areas of sentiment analysis based on the contents of data and provides prospective research directions.},
  archive      = {J_AIR},
  author       = {Bordoloi, Monali and Biswas, Saroj Kumar},
  doi          = {10.1007/s10462-023-10442-2},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {12505-12560},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Sentiment analysis: A survey on design framework, applications and future scopes},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HHO-EAS: A new metaheuristic bio-inspired of the win–win
hunting synergy between the two predators crow and wolf. <em>AIR</em>,
<em>56</em>(11), 12439–12504. (<a
href="https://doi.org/10.1007/s10462-023-10428-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Harris Hawk Optimization (HHO) is a bio-inspired metaheuristic of Harris Hawk’s pack hunting. Although having provided competitive results in some optimization problems in science and engineering, HHO has weaknesses for highly multimodal and high-dimensional optimization problems. In this article, we propose a new metaheuristic Harris Hawk Optimization Encirclement Attack Synergy (HHO-EAS) with the ambition to obtain better capabilities than HHO in solving highly multimodal and high-dimensional optimization problems. Our hybridization strategy is entirely bio-inspired by a win-win hunting synergy between two predators during the extremely difficult winter periods: the crow and the wolf. The smart exploratory faculties of crows combined with the ability of wolves to capture prey larger than themselves with speed and efficiency, allow these two predators to detect and catch good prey that is very rare and very difficult to hunt in harsh winter periods. In order to mathematically model this win-win hunting synergy with the encirclement and attack equations and integrate it into HHO, we used fuzzy logic to create a Mamdani-like fuzzy inference system (FIS). HHO-EAS was tested firstly with HHO, GWO and PSO on a general benchmark of 19 well-known functions and secondly with HHO on a specific benchmark of the 20 most complex functions of CEC 2017. The experimental results obtained on these two benchmarks demonstrate the superiority of HHO-EAS over HHO for highly multimodal and high-dimensional optimization problems and validate our fully bio-inspired hybridization strategy.},
  archive      = {J_AIR},
  author       = {Sassi, Mohamed and Chelouah, Rachid},
  doi          = {10.1007/s10462-023-10428-0},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {12439-12504},
  shortjournal = {Artif. Intell. Rev.},
  title        = {HHO-EAS: A new metaheuristic bio-inspired of the win–win hunting synergy between the two predators crow and wolf},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Open-source intelligence: A comprehensive review of the
current state, applications and future perspectives in cyber security.
<em>AIR</em>, <em>56</em>(11), 12407–12438. (<a
href="https://doi.org/10.1007/s10462-023-10454-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The volume of data generated by today’s digitally connected world is enormous, and a significant portion of it is publicly available. These data sources are web archives, public databases, and social networks such as Facebook, Twitter, LinkedIn, Emails, Telegrams, etc. Open-source intelligence (OSINT) extracts information from a collection of publicly available and accessible data. OSINT can provide a solution to the challenges in extracting and gathering intelligence from various publicly available information and social networks. OSINT is currently expanding at an incredible rate, bringing new artificial intelligence-based approaches to address issues of national security, political campaign, the cyber industry, criminal profiling, and society, as well as cyber threats and crimes. In this paper, we have described the current state of OSINT tools/techniques and the state of the art for various applications of OSINT in cyber security. In addition, we have discussed the challenges and future directions to develop autonomous models. These models can provide solutions for different social network-based security, digital forensics, and cyber crime-based problems using various machine learning (ML), deep learning (DL) and artificial intelligence (AI) with OSINT.},
  archive      = {J_AIR},
  author       = {Yadav, Ashok and Kumar, Atul and Singh, Vrijendra},
  doi          = {10.1007/s10462-023-10454-y},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {12407-12438},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Open-source intelligence: A comprehensive review of the current state, applications and future perspectives in cyber security},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neurosymbolic AI: The 3rd wave. <em>AIR</em>,
<em>56</em>(11), 12387–12406. (<a
href="https://doi.org/10.1007/s10462-023-10448-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current advances in Artificial Intelligence (AI) and Machine Learning have achieved unprecedented impact across research communities and industry. Nevertheless, concerns around trust, safety, interpretability and accountability of AI were raised by influential thinkers. Many identified the need for well-founded knowledge representation and reasoning to be integrated with deep learning and for sound explainability. Neurosymbolic computing has been an active area of research for many years seeking to bring together robust learning in neural networks with reasoning and explainability by offering symbolic representations for neural models. In this paper, we relate recent and early research in neurosymbolic AI with the objective of identifying the most important ingredients of neurosymbolic AI systems. We focus on research that integrates in a principled way neural network-based learning with symbolic knowledge representation and logical reasoning. Finally, this review identifies promising directions and challenges for the next decade of AI research from the perspective of neurosymbolic computing, commonsense reasoning and causal explanation.},
  archive      = {J_AIR},
  author       = {Garcez, Artur d’Avila and Lamb, Luís C.},
  doi          = {10.1007/s10462-023-10448-w},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {12387-12406},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Neurosymbolic AI: The 3rd wave},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Video summarization using deep learning techniques: A
detailed analysis and investigation. <em>AIR</em>, <em>56</em>(11),
12347–12385. (<a
href="https://doi.org/10.1007/s10462-023-10444-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the critical multimedia analysis problems in today’s digital world is video summarization (VS). Many VS methods have been suggested based on deep learning methods. Nevertheless, These are inefficient in processing, extracting, and deriving information in the minimum amount of time from long-duration videos. Detailed analysis and investigation of numerous deep learning approach accomplished to determine root of problems connected with different deep learning methods in identifying and summarizing the essential activities in such videos. Various deep learning techniques have been investigated and examined to detect the event and summarization capability for detecting and summarizing multiple activities. Keyframe selection Event detection, categorization, and the activity feature summarization correspond to each activity. The limitations related to each category are also discussed in depth. Concerns about detecting low activity using the deep network on various types of public datasets are also discussed. Viable strategies are suggested to evaluate and improve the generated video summaries on such datasets. Moreover, Potential recommended applications based on literature are listed out. Various deep learning tools for experimental analysis have also been discussed in the paper. Future directions are presented for further exploration of research in VS using deep learning strategies.},
  archive      = {J_AIR},
  author       = {Saini, Parul and Kumar, Krishan and Kashid, Shamal and Saini, Ashray and Negi, Alok},
  doi          = {10.1007/s10462-023-10444-0},
  journal      = {Artificial Intelligence Review},
  number       = {11},
  pages        = {12347-12385},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Video summarization using deep learning techniques: A detailed analysis and investigation},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Advanced value iteration for discrete-time intelligent
critic control: A survey. <em>AIR</em>, <em>56</em>(10), 12315–12346.
(<a href="https://doi.org/10.1007/s10462-023-10497-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal control problems are ubiquitous in practical engineering applications and social life with the idea of cost or resource conservation. Based on the critic learning scheme, adaptive dynamic programming (ADP) is regarded as a significant avenue to address the optimal control problems by combining the advanced design ideas such as adaptive control, reinforcement learning, and intelligent control. This survey introduces the recent development of ADP and related intelligent critic control with an emphasis on advanced value iteration (VI) schemes for discrete-time nonlinear systems. The theoretical results focus on convergence and stability properties for general VI, stabilizing VI, integrated VI, evolving VI, adjustable VI schemes and so on. Several significant applications are also elaborated in aspects of optimal regulation, optimal tracking, and zero-sum games. We aim to break through the bottleneck problems for VI algorithms in realizing evolving control, accelerating learning speed, and reducing the calculation expense. In addition, the prospects of new theoretical and technical fields for advanced VI schemes are looked ahead.},
  archive      = {J_AIR},
  author       = {Zhao, Mingming and Wang, Ding and Qiao, Junfei and Ha, Mingming and Ren, Jin},
  doi          = {10.1007/s10462-023-10497-1},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {12315-12346},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Advanced value iteration for discrete-time intelligent critic control: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic path planning of unmanned combat aerial vehicle
based on double-layer coding method with enhanced grey wolf optimizer.
<em>AIR</em>, <em>56</em>(10), 12257–12314. (<a
href="https://doi.org/10.1007/s10462-023-10481-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The unmanned combat aerial vehicle (UCAV) technology has to deal with a lot of challenges in complex battlefield environments. The UCAV requires a high number of points to build the path to avoid dangers in order to achieve a safe and low-energy flying path, which increases the issue dimension and uses more computer resources while producing unstable results. To address the issue, this paper proposes a double-layer (DLC) model for path planning, which reduces the outputting dimension of path-forming points, reduces the computational cost and enhances the path stability. Meanwhile, this paper improves the grey wolf optimizer (K-FDGWO) by introducing adaptive K-neighbourhood-based learning strategy and differential “hunger-hunting strategy”, and using fitness distance correlation (FDC) to balance the global exploration and local exploitation. Besides, the K-FDGWO and Differential Evolution (DE) algorithm are jointly used for the DLC model (DLC-K-FDGWO). The experimental results indicated that the proposed DLC-K-FDGWO method for path planning always generated the ideal flight path in complicated environments.},
  archive      = {J_AIR},
  author       = {Jia, Yingjuan and Qu, Liangdong and Li, Xiaoqin},
  doi          = {10.1007/s10462-023-10481-9},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {12257-12314},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Automatic path planning of unmanned combat aerial vehicle based on double-layer coding method with enhanced grey wolf optimizer},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring the knowledge diffusion and research front of OWA
operator: A main path analysis. <em>AIR</em>, <em>56</em>(10),
12233–12255. (<a
href="https://doi.org/10.1007/s10462-023-10462-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, more and more attention is paid to the OWA operator in the academy. Growth curve analysis, which is often used in ecosystem studies, also indicates that this growth trend will continue. However, prior literature has not made a big picture to help researchers make clear of the development of this field by identifying the evolution path. The classic main path analysis is an excellent method combining quantitative analysis and qualitative analysis. We conducted the classic main path analysis and its variants on a citation network with 1474 papers to probe the development trajectories and research topics of OWA. We obtained several findings by constructing local and global main path, and multiple main paths. The path results indicate that weight generation and operator generalization run through the overall OWA domain, show that the multiple criteria decision making process assumed in the related research begins to be dynamic and multi-period, and reveal that some theories such as social network theory are introduced into the OWA operator and the applications are also greatly expanded.},
  archive      = {J_AIR},
  author       = {Yu, Dejian and Pan, Tianxing and Xu, Zeshui and Yager, Ronald R.},
  doi          = {10.1007/s10462-023-10462-y},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {12233-12255},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Exploring the knowledge diffusion and research front of OWA operator: A main path analysis},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gift: Granularity over specific-class for feature selection.
<em>AIR</em>, <em>56</em>(10), 12201–12232. (<a
href="https://doi.org/10.1007/s10462-023-10499-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a fundamental material of Granular Computing, information granulation sheds new light on the topic of feature selection. Although information granulation has been effectively applied to feature selection, existing feature selection methods lack the characterization of feature potential. Such an ability is one of the important factors in evaluating the importance of features, which determines whether candidate features have sufficient ability to distinguish different target variables. In view of this, a novel concept of granularity over specific-class from the perspective of information granulation is proposed. Essentially, such a granularity is a fusion of intra-class and extra-class based granularities, which enables to exploit the discrimination ability of features. Accordingly, an intuitive yet effective framework named Gift, i.e., granularity over specific-class for feature selection, is proposed. Comprehensive experiments on 29 public datasets clearly validate the effectiveness of Gift as compared with other feature selection strategies, especially in noisy data.},
  archive      = {J_AIR},
  author       = {Ba, Jing and Liu, Keyu and Yang, Xibei and Qian, Yuhua},
  doi          = {10.1007/s10462-023-10499-z},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {12201-12232},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Gift: Granularity over specific-class for feature selection},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-level granularity entropies for fuzzy coverings and
feature subset selection. <em>AIR</em>, <em>56</em>(10), 12171–12200.
(<a href="https://doi.org/10.1007/s10462-023-10479-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various fuzzy covering based rough set models can characterize and approximate a given target concept with different lower and upper approximation operators. However, due to the lack of effective construction method and semantic interpretation on real data, there are few investigation on a comprehensive uncertain measure for fuzzy covering, as well as its applications in feature subset selection. For this reason, a new uncertain measure called multi-level granularity entropy is proposed by means of different fuzzy neighbourhoods. First, five types of granularity structure and granularity entropy for fuzzy covering are studied; Second, a multi-level granularity entropy is introduced, using which one can evaluate the discrimination information implied in a family of fuzzy coverings from different hierarchical levels. Some variants of the multi-level granularity entropy, such as conditional granularity entropy, joint granularity entropy, and mutual granularity entropy, are then proposed to reflect the change of uncertain information. Finally, the dimensionality reduction is implemented in the light of maintaining the discrimination ability, and a forward feature selection algorithm is developed by using the multi-level entropy. Extensive numerical experiments demonstrate that the presented model exhibits better performance in feature learning, and outperforms some representative feature selection algorithms in terms of classification accuracy and the number of selected features.},
  archive      = {J_AIR},
  author       = {Huang, Zhehuang and Li, Jinjin},
  doi          = {10.1007/s10462-023-10479-3},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {12171-12200},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Multi-level granularity entropies for fuzzy coverings and feature subset selection},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of real-time surface defect inspection methods
based on deep learning. <em>AIR</em>, <em>56</em>(10), 12131–12170. (<a
href="https://doi.org/10.1007/s10462-023-10475-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning methods have been widely used in various industrial scenarios, promoting industrial intelligence. Real-time surface defect inspection of industrial products is one of the research focuses in industry. Surface defect inspection methods based on deep learning show great advantages and make it possible to detect defects in real time with high accuracy. From the perspective of real-time inspection, according to different types of surfaces in industry, this paper reviews the latest deep learning-based surface defect inspection methods from three levels: defect classification, defect detection and defect segmentation. After that, this paper introduces commonly used metrics for evaluating the performance of surface defect inspection models and public surface defect datasets. Then, this paper discusses the challenges faced by deep learning-based real-time surface defect inspection methods, including the acquisition of surface defect datasets, balancing the accuracy and speed of inspection models, and the application in industrial environments. Finally, this paper provides an outlook on the future development trend of surface defect inspection.},
  archive      = {J_AIR},
  author       = {Liu, Yi and Zhang, Changsheng and Dong, Xingjun},
  doi          = {10.1007/s10462-023-10475-7},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {12131-12170},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of real-time surface defect inspection methods based on deep learning},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the current state of query formulation for book search.
<em>AIR</em>, <em>56</em>(10), 12085–12130. (<a
href="https://doi.org/10.1007/s10462-023-10483-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The role of formulating a well-defined query in the retrieval of relevant search results is well-known to the users of an Information Retrieval (IR) system. Researchers have experimented with various approaches to formulating a search query, e.g., using topic fields in different combinations, reducing verbose queries, and query expansion to name a few. These approaches have been tested in various domain-specific IR applications. However, to the best of our knowledge, no survey or review article reviews the current state of query formulation in the domain of book search. This paper fills this gap in the literature by reviewing research publications on query formulation, published during 2007–2022. These publications have been selected through a rigorous search and selection strategy, where the findings have been summarized using a well-defined theoretical framework. It identifies the current trends and presents a cross-comparison for identifying the best-performing methods. The paper has implications for researchers working in IR in general and book search in specific.},
  archive      = {J_AIR},
  author       = {Ullah, Irfan and Alam, Sikandar and Ali, Zafar and Khan, Mahmood and Jabeen, Fouzia and Khusro, Shah},
  doi          = {10.1007/s10462-023-10483-7},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {12085-12130},
  shortjournal = {Artif. Intell. Rev.},
  title        = {On the current state of query formulation for book search},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 3D point cloud descriptors: State-of-the-art. <em>AIR</em>,
<em>56</em>(10), 12033–12083. (<a
href="https://doi.org/10.1007/s10462-023-10486-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of inexpensive 3D data acquisition devices has promisingly facilitated the wide availability and popularity of point clouds, which attracts increasing attention to the effective extraction of 3D point cloud descriptors for accuracy of the efficiency of 3D computer vision tasks in recent years. However, how to develop discriminative and robust feature representations from 3D point clouds remains a challenging task due to their intrinsic characteristics. In this paper, we give a comprehensively insightful investigation of the existing 3D point cloud descriptors. These methods can be principally divided into two categories according to their advancement: hand-crafted and deep learning-based approaches, which will be further discussed from the perspective of elaborate classification, their advantages, and limitations. Finally, we present the future research directions of the extraction of 3D point cloud descriptors.},
  archive      = {J_AIR},
  author       = {Han, Xian-Feng and Feng, Zhi-Ao and Sun, Shi-Jie and Xiao, Guo-Qiang},
  doi          = {10.1007/s10462-023-10486-4},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {12033-12083},
  shortjournal = {Artif. Intell. Rev.},
  title        = {3D point cloud descriptors: State-of-the-art},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Backtracking search algorithm driven by generalized mean
position for numerical and industrial engineering problems.
<em>AIR</em>, <em>56</em>(10), 11985–12031. (<a
href="https://doi.org/10.1007/s10462-023-10463-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Backtracking search algorithm (BSA) is a very popular and efficient population-based optimization technique. BSA has a very simple structure and good global search ability. However, BSA may be trapped into the local optimum in solving challenging multimodal optimization problems due to the single learning strategy. To enhance the global search ability of BSA, this paper proposes an improved version of BSA called backtracking search algorithm driven by generalized mean position (GMPBSA). In GMPBSA, two types of generalized mean positions are defined based on the built feature zones, which are employed to design the comprehensive learning mechanism consisting of three candidate learning strategies. Note that, this learning mechanism doesn’t introduce new control parameters and refer to the complex calculation. To verify the performance of GMPBSA, GMPBSA is used to solve the well-known CEC 2013 and CEC 2017 test suites, and three complex engineering optimization problems. Experimental results support the great potential of GMPBSA applied to the challenging multimodal optimization problems. The source code of GMPBSA can be found from https://github.com/jsuzyy/GMPBSA .},
  archive      = {J_AIR},
  author       = {Zhang, Yiying},
  doi          = {10.1007/s10462-023-10463-x},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {11985-12031},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Backtracking search algorithm driven by generalized mean position for numerical and industrial engineering problems},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application of deep generative networks for SAR/ISAR: A
review. <em>AIR</em>, <em>56</em>(10), 11905–11983. (<a
href="https://doi.org/10.1007/s10462-023-10469-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Military, agricultural, and urban planning have all made extensive use of SAR/ISAR in the realm of remote sensing. SAR/ISAR images are more capable of identifying the details of the targets than optical images and can be taken in any condition. Due to the challenges associated with SAR/ISAR imaging, the lack of data causes many jobs relying on data-driven deep learning algorithms to perform less than satisfactorily. Cropping, rotation, and other procedures are examples of classic data augmentation techniques now in use, although they do not fundamentally differ from basic replication and cannot increase the model’s stability and robustness. Deep generative models are used to generate SAR/ISAR images, which is a more efficient way than the conventional ones. The generation techniques are outlined and organized depending on the application fields in this review, including SAR/ISAR data augmentation (26 papers), SAR/ISAR image translation (29 papers), SAR/ISAR image enhancement (22 papers), azimuth interpolation (9 papers), and deceptive jamming (1 paper). The connected works are then summarized based on several deep generative models. 87 linked studies and 5 associated survey papers from 2017 to 2022 are compiled in this review. Finally, the summarized works are systematically analyzed. There are 27 papers using MSTAR for image generation, which is the mostly applied dataset. For evaluation, the combination of SSIM and PSNR is applied most widely (32.19\%). In conclusion, this review offers fresh perspectives on the direction in which deep generative models for SAR/ISAR image generation are headed. The cutting-edge methods outlined in this paper are also available to researchers in other domains.},
  archive      = {J_AIR},
  author       = {Zhang, Jiawei and Liu, Zhen and Jiang, Weidong and Liu, Yongxiang and Zhou, Xiaolin and Li, Xiang},
  doi          = {10.1007/s10462-023-10469-5},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {11905-11983},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Application of deep generative networks for SAR/ISAR: A review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cauchy balanced nonnegative matrix factorization.
<em>AIR</em>, <em>56</em>(10), 11867–11903. (<a
href="https://doi.org/10.1007/s10462-022-10379-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonnegative Matrix Factorization (NMF) plays an important role in many data mining and machine learning tasks. Standard NMF uses the Frobenius norm as the loss function which is well-known to be sensitive to noise. To address this issue, we propose a robust formulation of NMF, i.e., Cauchy-NMF, which is derived based on the assumption that the noise generally follows identical independent distributed (i.i.d.) Cauchy distribution. In particular, we derive the Cauchy Balanced NMF model (Cauchy-B-NMF) using Cauchy distribution, where (a) the numerical value of each element in the coefficient matrix is viewed as the posterior probability, which allows the clustering result to be obtained directly from the coefficient matrix without any additional post-processing; (b) a novel manifold regularization term is incorporated into the loss function, explicitly making the distant data points have dissimilar embeddings, while implicitly making the neighbouring data points have similar embeddings; (c) a balanced clustering term is enforced to achieve the desired equal number of data points across different clusters. We derive an efficient computational algorithm to solve the resultant optimization problem, and also provide a rigorous analysis of the algorithm convergence. Experimental results on several benchmarks demonstrate the effectiveness of our algorithms, which consistently provides better clustering results compared to many other NMF variants.},
  archive      = {J_AIR},
  author       = {Xiong, He and Kong, Deguang and Nie, Feiping},
  doi          = {10.1007/s10462-022-10379-y},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {11867-11903},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Cauchy balanced nonnegative matrix factorization},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ship detection with deep learning: A survey. <em>AIR</em>,
<em>56</em>(10), 11825–11865. (<a
href="https://doi.org/10.1007/s10462-023-10455-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ship detection plays a pivotal role in efficient marine monitoring, port management, and safe navigation. However, the development of ship detection techniques is vastly behind other detection techniques, such as face detection, pedestrian detection, traffic sign/light detection, text detection, etc. In this paper, we explore the status quo and identify the following reasons for the slow development: (1) the existing methodologies are weakly systematic; (2) there are no unified evaluation criteria; (3) there are no widely accepted datasets which vastly hinder its development in deep learning era. In this context, we conduct a critical review of the state-of-the-art ship detection techniques based on deep learning. The main contributions of this work are: (1) existing works on object detection are comprehensively reviewed; (2) popular/benchmark datasets are extensively collected and analysed; (3) evaluation criteria for ship detection are ultimately unified; and (4) challenges and optimization methods are discussed and future directions projected.},
  archive      = {J_AIR},
  author       = {Er, Meng Joo and Zhang, Yani and Chen, Jie and Gao, Wenxiao},
  doi          = {10.1007/s10462-023-10455-x},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {11825-11865},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Ship detection with deep learning: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bayesian learning for neural networks: An algorithmic
survey. <em>AIR</em>, <em>56</em>(10), 11773–11823. (<a
href="https://doi.org/10.1007/s10462-023-10443-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The last decade witnessed a growing interest in Bayesian learning. Yet, the technicality of the topic and the multitude of ingredients involved therein, besides the complexity of turning theory into practical implementations, limit the use of the Bayesian learning paradigm, preventing its widespread adoption across different fields and applications. This self-contained survey engages and introduces readers to the principles and algorithms of Bayesian Learning for Neural Networks. It provides an introduction to the topic from an accessible, practical-algorithmic perspective. Upon providing a general introduction to Bayesian Neural Networks, we discuss and present both standard and recent approaches for Bayesian inference, with an emphasis on solutions relying on Variational Inference and the use of Natural gradients. We also discuss the use of manifold optimization as a state-of-the-art approach to Bayesian learning. We examine the characteristic properties of all the discussed methods, and provide pseudo-codes for their implementation, paying attention to practical aspects, such as the computation of the gradients.},
  archive      = {J_AIR},
  author       = {Magris, Martin and Iosifidis, Alexandros},
  doi          = {10.1007/s10462-023-10443-1},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {11773-11823},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Bayesian learning for neural networks: An algorithmic survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Implementing bargaining game-based fuzzy cognitive map and
mixed-motive games for group decisions in the healthcare supplier
selection. <em>AIR</em>, <em>56</em>(10), 11739–11772. (<a
href="https://doi.org/10.1007/s10462-023-10432-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating and selecting proper suppliers in the healthcare centers due to their high impact on the financial situation and citizens’ satisfaction is vital. The abundance of various criteria affecting the Supplier Selection (SS) problem makes it a decision-making problem. To this end, an approach according to the Bargaining Game-based Fuzzy Cognitive Map (BG-FCM) and mixed-motive games has been proposed for simultaneously modeling the SS complexity and suppliers’ competition in the market. First, according to the BG-FCM, the causal relationships between SS criteria have been determined. Then, by implementing Particle Swarm Optimization and the S-shaped transfer function (PSO-STF) and scenario-making, the BG-FCM is executed to extract robust payoffs for suppliers to compete. The competition between suppliers is modeled by mixed-motive games and their robust payoffs to determine their best strategies in the competition. Finally, suppliers compete with each other two by two, and suppliers with the most wins will have higher priority. The proposed approach has been applied in a general hospital to evaluate major suppliers for purchasing necessities. Then, it is compared with two well-known Multi-Criteria Decision Making (MCDM) approaches, showing a better performance in modeling the complexity and competition in the problem. The proposed approach can help the hospital select the most appropriate suppliers according to its preferences and avoid cooperating with inappropriate suppliers, which may cause a low-quality Supply Chain (SC) system or financial calamities.},
  archive      = {J_AIR},
  author       = {Abbaspour Onari, Mohsen and Jahangoshai Rezaee, Mustafa},
  doi          = {10.1007/s10462-023-10432-4},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {11739-11772},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Implementing bargaining game-based fuzzy cognitive map and mixed-motive games for group decisions in the healthcare supplier selection},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spider wasp optimizer: A novel meta-heuristic optimization
algorithm. <em>AIR</em>, <em>56</em>(10), 11675–11738. (<a
href="https://doi.org/10.1007/s10462-023-10446-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a new nature-inspired meta-heuristic algorithm named spider wasp optimization (SWO) algorithm, which is based on replicating the hunting, nesting, and mating behaviors of the female spider wasps in nature. This proposed algorithm has various unique updating strategies, making it applicable to a wide range of optimization problems with different exploration and exploitation requirements. The proposed SWO is compared with nine newly published and well-established metaheuristics over four different benchmarks: (1) Standard benchmark, including 23 unimodal and multimodal test functions; (2) test suite of CEC2017, (3) test suite of CEC2020, and (4) test suite of CEC2014 to validate its reliability. Moreover, two classical engineering design problems, namely, welded bean and pressure vessel designs, and parameter estimation of the single-diode, double-diode, and triple-diode photovoltaic models are used to further evaluate the performance of SWO in optimizing real-world optimization problems. Experimental findings demonstrate that SWO is more competitive compared with the state-of-art meta-heuristic methods for four validated benchmarks and superior to all observed real-world optimization problems. Specifically, SWO achieves an overall effective percentage of 78.2\% on the standard benchmark, 92.31\% on CEC2014, 77.78\% on CEC2017, 60\% on CEC2020, and 100\% on real-world problems. The source code of SWO is publicly available at https://www.mathworks.com/matlabcentral/fileexchange/126010-spider-wasp-optimizer-swo .},
  archive      = {J_AIR},
  author       = {Abdel-Basset, Mohamed and Mohamed, Reda and Jameel, Mohammed and Abouhawwash, Mohamed},
  doi          = {10.1007/s10462-023-10446-y},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {11675-11738},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Spider wasp optimizer: A novel meta-heuristic optimization algorithm},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent energy management systems: A review.
<em>AIR</em>, <em>56</em>(10), 11635–11674. (<a
href="https://doi.org/10.1007/s10462-023-10441-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Climate change has become a major problem for humanity in the last two decades. One of the reasons that caused it, is our daily energy waste. People consume electricity in order to use home/work appliances and devices and also reach certain levels of comfort while working or being at home. However, even though the environmental impact of this behavior is not immediately observed, it leads to increased CO2 emissions coming from energy generation from power plants. It has been shown that about 40\% of these emissions come from the electricity consumption and also that about 20\% of this percentage could have been saved if we started using energy more efficiently. Confronting such a problem efficiently will affect both the environment and our society. Monitoring energy consumption in real-time, changing energy wastage behavior of occupants and using automations with incorporated energy savings scenarios, are ways to decrease global energy footprint. In this review, we study intelligent systems for energy management in residential, commercial and educational buildings, classifying them in two major categories depending on whether they provide direct or indirect control. The article also discusses what the strengths and weaknesses are, which optimization techniques do they use and finally, provide insights about how these systems can be improved in the future.},
  archive      = {J_AIR},
  author       = {Mischos, Stavros and Dalagdi, Eleanna and Vrakas, Dimitrios},
  doi          = {10.1007/s10462-023-10441-3},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {11635-11674},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Intelligent energy management systems: A review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A comprehensive study of automatic video summarization
techniques. <em>AIR</em>, <em>56</em>(10), 11473–11633. (<a
href="https://doi.org/10.1007/s10462-023-10429-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video summarization deals with the generation of a condensed version of the original video by including meaningful frames or segments while eliminating redundant information. The main challenge in a video summarization task is to identify important frames or segments corresponding to human perception which varies from one genre to another. In the past two decades, several summarization techniques ranging from conventional non-learning to deep learning based mechanisms have been developed. This study provides a comprehensive survey focusing on the massive literature with scope ranging from general to domain specific methods, single view to multi-view processes, generic to user-interaction based mechanisms and conventional to deep learning-based approaches. The presented work provides general pipeline and broad classification of video summarization systems. The survey also presents genre-wise datasets description, various evaluation techniques and future recommendations. The key-points of presented work lie in its approach of analyzing literature in a systematic manner and its wide coverage by including some of the domains that have been overlooked over the time like aerial videos, medical videos and user-customization based approaches. The research work in each category is investigated, compared and analyzed on the basis of various intrinsic characteristics. The main objective of this manuscript is to guide future researchers about state-of-the-art work done in various domains of the video summarization field, so that the scope and performance of automatic video summarization systems can be enhanced further by designing new approaches or by improving different existing techniques.},
  archive      = {J_AIR},
  author       = {Gupta, Deeksha and Sharma, Akashdeep},
  doi          = {10.1007/s10462-023-10429-z},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {11473-11633},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comprehensive study of automatic video summarization techniques},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dimensional decision covariance colony predation algorithm:
Global optimization and high−dimensional feature selection.
<em>AIR</em>, <em>56</em>(10), 11415–11471. (<a
href="https://doi.org/10.1007/s10462-023-10412-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The colony Predation Algorithm (CPA) has been proven to be one of the heuristic algorithms that can efficiently solve global optimization problems. Balancing the paradox between exploration and exploitation capabilities while mitigating premature convergence are two key subjects that need to be addressed in CPA research. To effectively alleviate these problems, this study proposes a CPA variant named Covariance Gaussian cuckoo Colony Predation Algorithm (CGCPA). Specifically, the designed gaussian cuckoo variable dimensional strategy is used to decentralize the agent population in CPA to enhance the search agents&#39; population diversity and global search ability. The covariance matrix adaptation evolution strategy is used to enhance the convergence speed of the evolutionary agents and the ability to capture the global optimal solution at a later stage. This study subjects CGCPA to competitive experiments with ten basic metaheuristics and ten state−of−the−art algorithms on the IEEE CEC 2017 function test suite. Experimental results confirm that CGCPA outperforms several state−of−the−art DE variants and the latest proposed algorithms in terms of convergence speed and accuracy. In addition, this study proposes a discrete binary feature selection method to better select features in medical data classification named BCGCPA. Its feature selection capability is evaluated in detail on 12 high−dimensional biomedical datasets in the UCI machine learning repository. BCGCPA achieves the lowest classification error rate on all 12 high−dimensional datasets, realizing the best feature selection classification accuracy. BCGCPA can be an efficient pre−processing tool for the dimensionality reduction of high−dimensional biomedical data. It has crucial applications in search space optimization and feature selection of medical datasets.},
  archive      = {J_AIR},
  author       = {Xu, Boyang and Heidari, Ali Asghar and Cai, Zhennao and Chen, Huiling},
  doi          = {10.1007/s10462-023-10412-8},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {11415-11471},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Dimensional decision covariance colony predation algorithm: Global optimization and high−dimensional feature selection},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Individual heights and phase transition under crowd
emergencies: Agent-based modeling from 2 to 3D. <em>AIR</em>,
<em>56</em>(10), 11391–11413. (<a
href="https://doi.org/10.1007/s10462-023-10407-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergencies such as terrorist attacks, with a large number of casualties, have spread worldwide and become the global issue for a long time. Previous researchers employed traditional two-dimensional (2D) models to simulate the crowd dynamics between terrorists and civilians. However, these 2D models simplify real situations and have yet to consider individual heights and visions. Therefore, more accurate models are needed. In this work, we extend the 2D model and propose the three-dimensional (3D) model, and the core is to bring the mechanism of individuals heights into decision-making process of these 3D agents for both terrorists and civilians. We first build the 3D environment. For the mechanism of crowd dynamics, under the framework of perception-decision-behavior, our 3D model has included individualized heights for all agents. Comparing 2D and 3D models, we find that individual heights and visions have greatly shaped the outcomes. The height heterogeneity has significant effects on attack deaths and slight effects on stampede deaths because smaller heights slow the moving speed for the crowd, and the higher heterogeneity (of heights) impairs the visibility of civilians. The effects of height heterogeneity on deaths will be more obvious, as the group size of civilians is beyond 1900. We have the phase transition threshold of 3030, beyond which stampede deaths exceed attack deaths. Moreover, the size effect of heroes follows the law of diminishing marginal returns. We also find that the number of heroes should twice that of terrorists, guiding better allocations of the police force and other public resources for emergencies responses. To strengthen the counter-force, heterogeneity effects of civilian heights should be controlled, and self-motivated heroes should be encouraged, which is critical for public safety worldwide.},
  archive      = {J_AIR},
  author       = {Lu, Peng and Zhang, Zhuo and Li, Mengdi},
  doi          = {10.1007/s10462-023-10407-5},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {11391-11413},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Individual heights and phase transition under crowd emergencies: Agent-based modeling from 2 to 3D},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Federated learning for 6G-enabled secure communication
systems: A comprehensive survey. <em>AIR</em>, <em>56</em>(10),
11297–11389. (<a
href="https://doi.org/10.1007/s10462-023-10417-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) and Deep learning (DL) models are popular in many areas, from business, medicine, industries, healthcare, transportation, smart cities, and many more. However, the conventional centralized training techniques may not apply to upcoming distributed applications, which require high accuracy and quick response time. It is mainly due to limited storage and performance bottleneck problems on the centralized servers during the execution of various ML and DL-based models. However, federated learning (FL) is a developing approach to training ML models in a collaborative and distributed manner. It allows the full potential exploitation of these models with unlimited data and distributed computing power. In FL, edge computing devices collaborate to train a global model on their private data and computational power without sharing their private data on the network, thereby offering privacy preservation by default. But the distributed nature of FL faces various challenges related to data heterogeneity, client mobility, scalability, and seamless data aggregation. Moreover, the communication channels, clients, and central servers are also vulnerable to attacks which may give various security threats. Thus, a structured vulnerability and risk assessment are needed to deploy FL successfully in real-life scenarios. Furthermore, the scope of FL is expanding in terms of its application areas, with each area facing different threats. In this paper, we analyze various vulnerabilities present in the FL environment and design a literature survey of possible threats from the perspective of different application areas. Also, we review the most recent defensive algorithms and strategies used to guard against security and privacy threats in those areas. For a systematic coverage of the topic, we considered various applications under four main categories: space, air, ground, and underwater communications. We also compared the proposed methodologies regarding the underlying approach, base model, datasets, evaluation matrices, and achievements. Lastly, various approaches’ future directions and existing drawbacks are discussed in detail.},
  archive      = {J_AIR},
  author       = {Sirohi, Deepika and Kumar, Neeraj and Rana, Prashant Singh and Tanwar, Sudeep and Iqbal, Rahat and Hijjii, Mohammad},
  doi          = {10.1007/s10462-023-10417-3},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {11297-11389},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Federated learning for 6G-enabled secure communication systems: A comprehensive survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Trustworthy artificial intelligence in alzheimer’s disease:
State of the art, opportunities, and challenges. <em>AIR</em>,
<em>56</em>(10), 11149–11296. (<a
href="https://doi.org/10.1007/s10462-023-10415-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical applications of Artificial Intelligence (AI) have consistently shown remarkable performance in providing medical professionals and patients with support for complex tasks. Nevertheless, the use of these applications in sensitive clinical domains where high-stakes decisions are involved could be much more extensive if patients, medical professionals, and regulators were provided with mechanisms for trusting the results provided by AI systems. A key issue for achieving this is endowing AI systems with key dimensions of Trustworthy AI (TAI), such as fairness, transparency, robustness, or accountability, which are not usually considered within this context in a generalized and systematic manner. This paper reviews the recent advances in the TAI domain, including TAI standards and guidelines. We propose several requirements to be addressed in the design, development, and deployment of TAI systems and present a novel machine learning pipeline that contains TAI requirements as embedded components. Moreover, as an example of how current AI systems in medicine consider the TAI perspective, the study extensively reviews the recent literature (2017–2021) on AI systems in a prevalent and high social-impact disease: diagnosis and progression detection of Alzheimer’s Disease (AD). The most relevant AI systems in the AD domain are compared and discussed (such as machine learning, deep learning, ensembles, time series, and multimodal multitask) from the perspective of how they address TAI in their design. Several open challenges are highlighted, which could be claimed as one of the main reasons to justify the rare application of AI systems in real clinical environments. The study provides a roadmap to measure the TAI status of an AI systems and highlights its limitations. In addition, it provides the main guidelines to overcome these limitations and build medically trusted AI-based applications in the medical domain.},
  archive      = {J_AIR},
  author       = {El-Sappagh, Shaker and Alonso-Moral, Jose M. and Abuhmed, Tamer and Ali, Farman and Bugarín-Diz, Alberto},
  doi          = {10.1007/s10462-023-10415-5},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {11149-11296},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Trustworthy artificial intelligence in alzheimer’s disease: State of the art, opportunities, and challenges},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PC-IEN: A click-through rate prediction method based on
dynamic collaborative personalized interest extraction. <em>AIR</em>,
<em>56</em>(10), 11123–11147. (<a
href="https://doi.org/10.1007/s10462-023-10447-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of online social networks enables users to generate a large amount of historical behavior data. How to effectively extract user interests from these data is crucial to improve the performance of click-through rate (CTR) prediction. However, existing research ignores the importance of collaborative personalized interest extraction based on the dynamic relationship in CTR prediction, which will cause the model to lose some important information to improve performance. Therefore, this paper designs an adaptive dynamic extraction (ADE) Unit to obtain user interest representations. First, the ADE unit designs a time weighting function to consider the dynamic evolution of user interests; then, the user’s personalized interest representation is generated for a specific item. Finally, collaborative users are used to obtain the interest intensity of newly interested users. Based on the ADE unit, a new CTR prediction model is proposed, called personalized collaborative interest extraction network (PC-IEN). The model design feature embedding layer obtains a low-dimensional representation vector. Mini-batch aware regularization and the Dice activation function are employed to train many parameters of the network. The experimental results on three real datasets show that compared with other algorithms, the model can improve AUC by at least 0.11\% and GAUC by 0.2\%, indicating that the proposed algorithm outperforms other models in performance.},
  archive      = {J_AIR},
  author       = {Cheng’ai, Sun and Caixia, Jing and Liqing, Qiu and Qingyu, Yang and Chunxue, Zhang},
  doi          = {10.1007/s10462-023-10447-x},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {11123-11147},
  shortjournal = {Artif. Intell. Rev.},
  title        = {PC-IEN: A click-through rate prediction method based on dynamic collaborative personalized interest extraction},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Time-series dynamic three-way group decision-making model
and its application in TCM efficacy evaluation. <em>AIR</em>,
<em>56</em>(10), 11095–11121. (<a
href="https://doi.org/10.1007/s10462-023-10445-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical curative effect is the core value and fundamental pursuit of medicine. The data-driven clinical quantitative evaluation model is an important research issue in clinical efficacy evaluation. The existing clinical efficacy evaluation methods have made a lot of contributions to the structured information of static attributes, but less attention is paid to the heterogeneous information with dynamic and random characteristics. This paper discusses a class of clinical efficacy evaluation decision-making problems that contain both time-series and dynamic characteristics and uses the three-way decision principle to describe these characteristics. The group decision-making theory is introduced to aggregate the evaluation information of time series dynamic features generated in the decision-making process. A time series dynamic three-way group decision model for clinical efficacy evaluation is constructed, the optimal decision rules with minimum expected loss objective are calculated and proofed in the proposed model, and then the optimal treatment alternative is obtained. Finally, taking the decision-making problem of clinical efficacy evaluation of traditional Chinese medicine (TCM) treatment of atopic dermatitis as the research object, based on the actual clinical data of Guangdong Provincial Hospital of TCM, the decision-making process and steps of the theoretical model constructed in this paper are verified and applied. The data-driven quantitative clinical evaluation model has achieved better application effects than the actual clinical scenarios. The research results in this paper provide new ideas and theoretical methods for real-world clinical efficacy evaluation research.},
  archive      = {J_AIR},
  author       = {Chu, Xiaoli and Sun, Bingzhen and Mo, Xiumei and Liu, Junfeng and Zhang, Yu and Weng, Heng and Chen, Dacan},
  doi          = {10.1007/s10462-023-10445-z},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {11095-11121},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Time-series dynamic three-way group decision-making model and its application in TCM efficacy evaluation},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new intuitionistic fuzzy best worst method for deriving
weight vector of criteria and its application. <em>AIR</em>,
<em>56</em>(10), 11071–11093. (<a
href="https://doi.org/10.1007/s10462-023-10439-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intuitionistic fuzzy Best Worst method (IFBWM) is an effective method to deal with multi-criteria decision making problems via intuitionistic fuzzy reference comparisons of experts, which has attracted increasing attention from different decision fields. However, there are drawbacks in the existing IFBWMs, which can result in unreasoning and incorrect ranking order of criteria or alternatives. To overcome the existing drawbacks of the IFBWMs, we propose a new IFBWM considering the multiplicative consistency of intuitionistic fuzzy reference comparisons. First, combining the multiplicative consistent intuitionistic fuzzy preference relation with the fully multiplicative consistency of the intuitionistic fuzzy reference comparisons, we build the mathematical programming model for obtaining the normalized intuitionistic fuzzy weight vector. Then, we define the concept of the consistency ratio for evaluating the multiplicative consistency of intuitionistic fuzzy reference comparisons. Afterwards, an algorithm for repairing the inconsistency of intuitionistic fuzzy reference comparisons is developed, which only adjust the preference degree of the best criterion over the worst criterion. Subsequently we propose a new IFBWM with the multiplicative consistency. Furthermore, we apply the proposed method to Advanced Mathematics textbooks selection. The computational results show that the consistency ratio is 0.0091, implying the intuitionistic fuzzy reference comparisons are acceptable, and the ranking order of the alternatives $$C_{1} \succ C_{2} \succ C_{4} \succ C_{3}$$ is consistent with the initial judgment of experts and the actual usage of Advanced Mathematics textbooks in universities of China. The computational results of the practical example through the other methods reveal that there are some troubles in the consistency ratio, the weights of alternatives or the ranking order of the alternative. Therefore, the results suggest that the proposed method may have significant effects on the theoretical development and practical application of IFBWM.},
  archive      = {J_AIR},
  author       = {Liu, Weifeng and Du, Yingxue and Chang, Juan},
  doi          = {10.1007/s10462-023-10439-x},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {11071-11093},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A new intuitionistic fuzzy best worst method for deriving weight vector of criteria and its application},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Representing interlingual meaning in lexical databases.
<em>AIR</em>, <em>56</em>(10), 11053–11069. (<a
href="https://doi.org/10.1007/s10462-023-10427-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s multilingual lexical databases, the majority of the world’s languages are under-represented. Beyond a mere issue of resource incompleteness, we show that existing lexical databases have structural limitations that result in a reduced expressivity on culturally-specific words and in mapping them across languages. In particular, the lexical meaning space of dominant languages, such as English, is represented more accurately while linguistically or culturally diverse languages are mapped in an approximate manner. Our paper assesses state-of-the-art multilingual lexical databases and evaluates their strengths and limitations with respect to their expressivity on lexical phenomena of linguistic diversity.},
  archive      = {J_AIR},
  author       = {Giunchiglia, Fausto and Bella, Gábor and Nair, Nandu C. and Chi, Yang and Xu, Hao},
  doi          = {10.1007/s10462-023-10427-1},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {11053-11069},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Representing interlingual meaning in lexical databases},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive type2-possibilistic c-means clustering and its
application to microarray datasets. <em>AIR</em>, <em>56</em>(10),
11017–11052. (<a
href="https://doi.org/10.1007/s10462-022-10380-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microarray technology is an important innovation that simultaneously facilitates measuring the expression level for thousands of genes in different samples. One basic and widely used technique in microarray data analysis is clustering. Due to some characteristics of microarray data related to noise, redundancy, and complex biological hidden process, a robust clustering method is required. In this paper, adaptive interval type2-possibilistic C-means and adaptive interval type2-possibilistic fuzzy C-means clustering methods are developed to better manage the mentioned characteristics and uncertainties. The proposed algorithm not only takes advantage of possibilistic C-means clustering and type2-fuzzy sets to handle noise and uncertainty, but also uses the concepts of “adaptive parameter” and “shadow sets” for each cluster per iteration. Therefore, based on the uncertainty of bandwidth, the permissive and strict bandwidths are defined, which makes the model more resistant to noise and outliers. In order to evaluate the proposed algorithms, synthetic datasets, UCI datasets, and microarray datasets of Alzheimer’s disease (AD) have been implemented. Considering AD datasets, several clustering methods were initially evaluated through sample-based clustering, using comparative analysis. Then, the proposed methods were applied based on gene-based clustering, where heatmaps visualized the results. The outcomes of the experiments demonstrated better clustering performances for the proposed methods as compared to some well-known soft clustering methods.},
  archive      = {J_AIR},
  author       = {Moattar Husseini, Zohre and Fazel Zarandi, Mohammad Hossein and Ahmadi, Abbas},
  doi          = {10.1007/s10462-022-10380-5},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {11017-11052},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Adaptive type2-possibilistic C-means clustering and its application to microarray datasets},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Direct multi-view spectral clustering with consistent
kernelized graph and convolved nonnegative representation. <em>AIR</em>,
<em>56</em>(10), 10987–11015. (<a
href="https://doi.org/10.1007/s10462-023-10440-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering attempts to partition unlabeled objects into clusters by making full use of complementary and consistent information in the features of multiple views. Most existing methods perform this task in three sequential phases: Estimating individual or consistent similarity matrices, spectral embedding, and cluster partitioning. In this paper, we present a novel method that can overcome some of the shortcomings of previous multi-view clustering methods. Our approach is called &quot;Multi-view Clustering via Kernelized Graph and Nonnegative Embedding&quot;. Based on a single global criterion, it can jointly provide the consistent similarity matrix for all views, the consistent spectral representation, the soft cluster assignments, and the view weights. To our knowledge, our approach is the first to combine all these unknown matrices into a single criterion. Our proposed scheme has two interesting properties that the recent works do not have simultaneously. First, the proposed approach does not require an additional clustering step since the clustering assignments are solved directly. Second, the soft cluster assignments are directly linked to the representation of the views. Several experiments on real datasets demonstrate the effectiveness of the proposed method. It performs well compared to many competing methods.},
  archive      = {J_AIR},
  author       = {Dornaika, F. and El Hajjar, S.},
  doi          = {10.1007/s10462-023-10440-4},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {10987-11015},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Direct multi-view spectral clustering with consistent kernelized graph and convolved nonnegative representation},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MISO hierarchical inference engine satisfying the law of
importation with aggregation functions. <em>AIR</em>, <em>56</em>(10),
10961–10986. (<a
href="https://doi.org/10.1007/s10462-022-10356-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy inference engine, as one of the most important components of fuzzy systems, can obtain some meaningful outputs from fuzzy sets on input space and fuzzy rule base using fuzzy logic inference methods. In multi-input–single-output (MISO) fuzzy systems, in order to enhance the computational efficiency of fuzzy inference engine, this paper aims mainly to investigate three MISO fuzzy hierarchical inference engines employed fuzzy implications satisfying the law of importation with aggregation functions (LIA). We firstly find some aggregation functions for well-known fuzzy implications such that they satisfy LIA. The fuzzy implication satisfying LIA with respect to a given aggregation function is then characterized. Finally, three fuzzy hierarchical inference engines in MISO fuzzy systems are constructed according to aforementioned theoretical developments. Three examples are also provided to illustrate our theoretical arguments.},
  archive      = {J_AIR},
  author       = {Li, Dechao and Guo, Qiannan},
  doi          = {10.1007/s10462-022-10356-5},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {10961-10986},
  shortjournal = {Artif. Intell. Rev.},
  title        = {MISO hierarchical inference engine satisfying the law of importation with aggregation functions},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predicting dynamic spectrum allocation: A review covering
simulation, modelling, and prediction. <em>AIR</em>, <em>56</em>(10),
10921–10959. (<a
href="https://doi.org/10.1007/s10462-023-10449-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of the Internet of Things and 5G has further accelerated the growth in devices attempting to gain access to the wireless spectrum. A consequence of this has been the commensurate growth in spectrum conflict and congestion across the wireless spectrum, which has begun to impose a significant impost upon innovation in both the public and private sectors. One potential avenue for resolving these issues, and improving the efficiency of spectrum utilisation can be found in devices making intelligent decisions about their access to spectrum through Dynamic Spectrum Allocation. Changing to a system of Dynamic Spectrum Allocation would require the development of complex and sophisticated inference frameworks, that would be able to be deployed at a scale able to support significant numbers of devices. The development and deployment of these systems cannot exist in isolation, but rather would require the development of tools that can simulate, measure, and predict Spectral Occupancy. To support the development such tools, this work reviews not just the available prediction frameworks for networked systems with sparse sensing over large scale geospatial environments, but also holistically considers the myriad of technological approaches required to support Dynamic Spectrum Allocation.},
  archive      = {J_AIR},
  author       = {Cullen, Andrew C. and Rubinstein, Benjamin I. P. and Kandeepan, Sithamparanathan and Flower, Barry and Leong, Philip H. W.},
  doi          = {10.1007/s10462-023-10449-9},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {10921-10959},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Predicting dynamic spectrum allocation: A review covering simulation, modelling, and prediction},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Review and empirical analysis of sparrow search algorithm.
<em>AIR</em>, <em>56</em>(10), 10867–10919. (<a
href="https://doi.org/10.1007/s10462-023-10435-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, swarm intelligence algorithms have received extensive attention and research. Swarm intelligence algorithms are a biological heuristic method, which is widely used in solving optimization problems. The traditional swarm intelligence algorithms provide new ideas and new ways to solve some practical problems, and they have made positive progress in fields such as combinatorial optimization, task scheduling, process control, engineering prediction, and image processing. In particular, the sparrow search algorithm is a new type of group intelligence optimization algorithm inspired by the group foraging behavior to perform local and global search by imitating the foraging and anti-predation behavior of sparrows. In view of the shortcomings of the original sparrow search algorithm, such as its easy fall into local optimum, slow convergence speed, and low convergence accuracy, scholars at home and abroad have improved the sparrow search algorithm and have made practical applications in various fields. Firstly, this paper introduces the basic principle of sparrow search algorithm, analyzes the factors affecting the performance of the algorithm, further proposes the improvement strategy of the algorithm, and performs function test comparison and performance analysis with particle swarm optimization algorithm, monarch butterfly algorithm, colony spider algorithm, and pigeon swarm optimization algorithm. After that, the application and development of the sparrow search algorithm in power grid load forecasting, image processing, path tracking, wireless sensor network routing performance optimization, wireless location, and fault diagnosis are described. Finally, combined with the performance characteristics and application direction of the sparrow search algorithm, the future research and development direction of the sparrow search algorithm is prospected.},
  archive      = {J_AIR},
  author       = {Yue, Yinggao and Cao, Li and Lu, Dongwan and Hu, Zhongyi and Xu, Minghai and Wang, Shuxin and Li, Bo and Ding, Haihua},
  doi          = {10.1007/s10462-023-10435-1},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {10867-10919},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Review and empirical analysis of sparrow search algorithm},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Image synthesis: A review of methods, datasets, evaluation
metrics, and future outlook. <em>AIR</em>, <em>56</em>(10), 10813–10865.
(<a href="https://doi.org/10.1007/s10462-023-10434-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image synthesis is a process of converting the input text, sketch, or other sources, i.e., another image or mask, into an image. It is an important problem in the computer vision field, where it has attracted the research community to attempt to solve this challenge at a high level to generate photorealistic images. Different techniques and strategies have been employed to achieve this purpose. Thus, the aim of this paper is to provide a comprehensive review of various image synthesis models covering several aspects. First, the image synthesis concept is introduced. We then review different image synthesis methods divided into three categories: image generation from text, sketch, and other inputs, respectively. Each sub-category is introduced under the proper category based upon the general framework to provide a broad vision of all existing image synthesis methods. Next, brief details of the benchmarked datasets used in image synthesis are discussed along with specifying the image synthesis models that leverage them. Regarding the evaluation, we summarize the metrics used to evaluate the image synthesis models. Moreover, a detailed analysis based on the evaluation metrics of the results of the introduced image synthesis is provided. Finally, we discuss some existing challenges and suggest possible future research directions.},
  archive      = {J_AIR},
  author       = {Baraheem, Samah Saeed and Le, Trung-Nghia and Nguyen, Tam V.},
  doi          = {10.1007/s10462-023-10434-2},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {10813-10865},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Image synthesis: A review of methods, datasets, evaluation metrics, and future outlook},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Zero-day attack detection: A systematic literature review.
<em>AIR</em>, <em>56</em>(10), 10733–10811. (<a
href="https://doi.org/10.1007/s10462-023-10437-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous increase in cyberattacks over the past few decades, the quest to develop a comprehensive, robust, and effective intrusion detection system (IDS) in the research community has gained traction. Many of the recently proposed solutions lack a holistic IDS approach due to explicitly relying on attack signature repositories, outdated datasets or the lack of considering zero-day (unknown) attacks while developing, training, or testing the machine learning (ML) or deep learning (DL)-based models. Overlooking these factors makes the proposed IDS less robust or practical in real-time environments. On the other hand, detecting zero-day attacks is a challenging subject, despite the many solutions proposed over the past many years. One of the goals of this systematic literature review (SLR) is to provide a research asset to future researchers on various methodologies, techniques, ML and DL algorithms that researchers used for the detection of zero-day attacks. The extensive literature review on the recent publications reveals exciting future research trends and challenges in this particular field. With all the advances in technology, the availability of large datasets, and the strong processing capabilities of DL algorithms, detecting a completely new or unknown attack remains an open research area. This SLR is an effort towards completing the gap in providing a single repository of finding ML and DL-based tools and techniques used by researchers for the detection of zero-day attacks.},
  archive      = {J_AIR},
  author       = {Ahmad, Rasheed and Alsmadi, Izzat and Alhamdani, Wasim and Tawalbeh, Lo’ai},
  doi          = {10.1007/s10462-023-10437-z},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {10733-10811},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Zero-day attack detection: A systematic literature review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Novel variants of grasshopper optimization algorithm to
solve numerical problems and demand side management in smart grids.
<em>AIR</em>, <em>56</em>(10), 10679–10732. (<a
href="https://doi.org/10.1007/s10462-023-10431-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The grasshopper optimization algorithm (GOA), which is one of the recent metaheuristic optimization algorithms, mimics the natural movements of grasshoppers in swarms seeking food sources. Some deficiencies have existed in the original GOA such as slow convergence speed, and the original GOA may get quickly stuck into local solutions facing some complex. For tackling these drawbacks of the original GOA, enhanced versions of GOA have been proposed to deal with the optimization problems more effectively. In the current study, two strategies have been integrated into GOA: the grouping mechanism of non-linear ‘c’ parameters and the mutation mechanism. Moreover, two different groups of non-linear ‘c’ parameters have been suggested in the grouping mechanism. Incorporating the grouping mechanism into GOA can update the grasshoppers’ positions within a limited local area, whereas the diversity of agents can be improved by integrating the mutation mechanism. Eight Novel-Variants GOA (NVGOAs) are proposed to address the deficiencies of the original GOA. Where two variants NVGOA1_1 and NVGOA2_1 represent the impact of each proposed group of ‘c’ parameters. Another two variants NVGOA3 and NVGOA4 represent the impact of the mutation mechanism with two different values of probability. Moreover, four variants: NVGOA1_2, NVGOA1_3, NVGOA2_2, and NVGOA2_3 represent the combination of the two proposed mechanisms. First, the comparison between the performance of the proposed variants and the original GOA has been conducted. Then, for validation of the efficiency of the proposed NVGOAs, the performance of the best-recorded NVGOA variants has been tested against the 29 CEC-2017 benchmark functions and compared with six state-of-the-art optimization algorithms based on the mean and the standard deviation metrics. Moreover, the Wilcoxon Signed-Rank test has been employed to exhibit the efficiency of the proposed variants. As well comparative analysis with previous enhancements of GOA has been conducted against the best-recorded NVGOA variants. Also, conducting a dimension study between the best-recorded chaotic previous variants against the best-recorded proposed NVGOA variants has revealed the superiority of NVGOAs. The results of all these analyses demonstrated the success and efficiency of the proposed NVGOA variants to solve numerical optimization problems. Concerning demand side management in smart grids, the proposed NVGOA variants have been applied to schedule the loads in three areas: residential, commercial, and industrial to decrease the daily operating costs and peak demand. The results show that the peak demand is reduced by 23.9\%, 17.6\%, and 9.2\% in residential areas, commercial areas, and industrial areas respectively. Also, the operating cost decreased by 7.25\%, 9.2\%, and 18.89\% in residential, commercial, and industrial areas, respectively. Finally, the overall results show that the proposed NVGOA algorithms are effective solutions to address the flaws of the original version of GOA and can get high-quality solutions for different optimization problems.},
  archive      = {J_AIR},
  author       = {Badr, Azzahraa A. and Saafan, Mahmoud M. and Abdelsalam, Mohamed M. and Haikal, Amira Y.},
  doi          = {10.1007/s10462-023-10431-5},
  journal      = {Artificial Intelligence Review},
  number       = {10},
  pages        = {10679-10732},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Novel variants of grasshopper optimization algorithm to solve numerical problems and demand side management in smart grids},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient lightweight convolutional neural network for
industrial surface defect detection. <em>AIR</em>, <em>56</em>(9),
10651–10677. (<a
href="https://doi.org/10.1007/s10462-023-10438-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since surface defect detection is significant to ensure the utility, integrality, and security of productions, and it has become a key issue to control the quality of industrial products, which arouses interests of researchers. However, deploying deep convolutional neural networks (DCNNs) on embedded devices is very difficult due to limited storage space and computational resources. In this paper, an efficient lightweight convolutional neural network (CNN) model is designed for surface defect detection of industrial productions in the perspective of image processing via deep learning. By combining the inverse residual architecture with coordinate attention (CA) mechanism, a coordinate attention mobile (CAM) backbone network is constructed for feature extraction. Then, in order to solve the small object detection problem, the multi-scale strategy is developed by introducing the CA into the cross-layer information flow to improve the quality of feature extraction and augment the representation ability on multi-scale features. Hereafter, the multi-scale feature is integrated to design a novel bidirectional weighted feature pyramid network (BWFPN) to improve the model detection accuracy without increasing much computational burden. From the comparative experimental results on open source datasets, the effectiveness of the developed lightweight CNN is evaluated, and the detection accuracy attains on par with the state-of-the-art (SOTA) model with less parameters and calculation.},
  archive      = {J_AIR},
  author       = {Zhang, Dehua and Hao, Xinyuan and Wang, Dechen and Qin, Chunbin and Zhao, Bo and Liang, Linlin and Liu, Wei},
  doi          = {10.1007/s10462-023-10438-y},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {10651-10677},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An efficient lightweight convolutional neural network for industrial surface defect detection},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Disentangling causality: Assumptions in causal discovery and
inference. <em>AIR</em>, <em>56</em>(9), 10613–10649. (<a
href="https://doi.org/10.1007/s10462-023-10411-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causality has been a burgeoning field of research leading to the point where the literature abounds with different components addressing distinct parts of causality. For researchers, it has been increasingly difficult to discern the assumptions they have to abide by in order to glean sound conclusions from causal concepts or methods. This paper aims to disambiguate the different causal concepts that have emerged in causal inference and causal discovery from observational data by attributing them to different levels of Pearl’s Causal Hierarchy. We will provide the reader with a comprehensive arrangement of assumptions necessary to engage in causal reasoning at the desired level of the hierarchy. Therefore, the assumptions underlying each of these causal concepts will be emphasized and their concomitant graphical components will be examined. We show which assumptions are necessary to bridge the gaps between causal discovery, causal identification and causal inference from a parametric and a non-parametric perspective. Finally, this paper points to further research areas related to the strong assumptions that researchers have glibly adopted to take part in causal discovery, causal identification and causal inference.},
  archive      = {J_AIR},
  author       = {Vonk, Maarten C. and Malekovic, Ninoslav and Bäck, Thomas and Kononova, Anna V.},
  doi          = {10.1007/s10462-023-10411-9},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {10613-10649},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Disentangling causality: Assumptions in causal discovery and inference},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence applications for microgrids
integration and management of hybrid renewable energy sources.
<em>AIR</em>, <em>56</em>(9), 10557–10611. (<a
href="https://doi.org/10.1007/s10462-023-10410-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of renewable energy sources (RESs) has become more attractive to provide electricity to rural and remote areas, which increases the reliability and sustainability of the electrical system, particularly for areas where electricity extension is difficult. Despite this, the integration of hybrid RESs is accompanied by many problems as a result of the intermittent and unstable nature of RESs. The extant literature has discussed the integration of RESs, but it is not comprehensive enough to clarify all the factors that affect the integration of RESs. In this paper, a comprehensive review is made of the integration of RESs. This review includes various combinations of integrated systems, integration schemes, integration requirements, microgrid communication challenges, as well as artificial intelligence used in the integration. In addition, the review comprehensively presents the potential challenges arising from integrating renewable resources with the grid and the control strategies used. The classifications developed in this review facilitate the integration improvement process. This paper also discusses the various optimization techniques used to reduce the total cost of integrated energy sources. In addition, it examines the use of up-to-date methods to improve the performance of the electrical grid. A case study is conducted to analyze the impact of using artificial intelligence when integrating RESs. The results of the case study prove that the use of artificial intelligence helps to improve the accuracy of operation to provide effective and accurate prediction control of the integrated system. Various optimization techniques are combined with ANN to select the best hybrid model. PSO has the fast convergence rate for reaching to the minimum errors as the Normalized Mean Square Error (NMSE) percentage reaches 1.10\% in 3367.50 s.},
  archive      = {J_AIR},
  author       = {Talaat, M. and Elkholy, M. H. and Alblawi, Adel and Said, Taghreed},
  doi          = {10.1007/s10462-023-10410-w},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {10557-10611},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Artificial intelligence applications for microgrids integration and management of hybrid renewable energy sources},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid chimp optimization algorithm for degree reduction of
ball said–ball curves. <em>AIR</em>, <em>56</em>(9), 10465–10555. (<a
href="https://doi.org/10.1007/s10462-023-10416-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimal multi-degree reduction of ball Said–Ball curves is an unsolved and knotty important technique in computer aided design (CAD) and computer graphics (CG) and is potentially used in many engineering fields involving geometric modeling. In this paper, an improved chimp optimization algorithm (ICHOA, for short) is used to solve the degree reduction of BSB curves. Firstly, the multi-degree reduction of BSB curves is mathematically an optimization problem that can be efficiently dealt with by a swarm intelligence algorithm. In this regard, a novel enhanced version of CHOA called ICHOA, combined with the proportional weight, dimension learning-based hunting search and fractional order strategies, is developed to enhance its capability of jumping out of the local minima and improve the calculation accuracy of the native algorithm. Furthermore, the superiority of the ICHOA is verified by comparing it with standard CHOA, other improved CHOA and popular nature-inspired optimization algorithms on 23 classical benchmark functions, the CEC’17 test suite and five engineering optimization problems, respectively. Secondly, the optimization models of multi-degree reduction for the center curve and radius function of BSB curves are established, respectively; meanwhile, the proposed ICHOA is utilized to solve the established optimization models, and the optimal center curve and radius function with a minimum distance of the approximating BSB curves of lower degree are also obtained. Finally, experimental results illustrate the ability of the proposed ICHOA to effectively solve the optimization problems of multi-degree reduction of BSB curves in terms of precision, robustness, and convergence characteristics.},
  archive      = {J_AIR},
  author       = {Hu, Gang and Dou, Wanting and Wei, Guo and Abbas, Muhammad},
  doi          = {10.1007/s10462-023-10416-4},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {10465-10555},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Hybrid chimp optimization algorithm for degree reduction of ball Said–Ball curves},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Privacy-preserving data (stream) mining techniques and their
impact on data mining accuracy: A systematic literature review.
<em>AIR</em>, <em>56</em>(9), 10427–10464. (<a
href="https://doi.org/10.1007/s10462-023-10425-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates existing input privacy-preserving data mining (PPDM) methods and privacy-preserving data stream mining methods (PPDSM), including their strengths and weaknesses. A further analysis was carried out to determine to what extent existing PPDM/PPDSM methods address the trade-off between data mining accuracy and data privacy which is a significant concern in the area. The systematic literature review was conducted using data extracted from 104 primary studies from 5 reputed databases. The scope of the study was defined using three research questions and adequate inclusion and exclusion criteria. According to the results of our study, we divided existing PPDM methods into four categories: perturbation, non-perturbation, secure multi-party computation, and combinations of PPDM methods. These methods have different strengths and weaknesses concerning the accuracy, privacy, time consumption, and more. Data stream mining must face additional challenges such as high volume, high speed, and computational complexity. The techniques proposed for PPDSM are less in number than the PPDM. We categorized PPDSM techniques into three categories (perturbation, non-perturbation, and other). Most PPDM methods can be applied to classification, followed by clustering and association rule mining. It was observed that numerous studies have identified and discussed the accuracy-privacy trade-off. However, there is a lack of studies providing solutions to the issue, especially in PPDSM.},
  archive      = {J_AIR},
  author       = {Hewage, U. H. W. A. and Sinha, R. and Naeem, M. Asif},
  doi          = {10.1007/s10462-023-10425-3},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {10427-10464},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Privacy-preserving data (stream) mining techniques and their impact on data mining accuracy: A systematic literature review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Impact of word embedding models on text analytics in deep
learning environment: A review. <em>AIR</em>, <em>56</em>(9),
10345–10425. (<a
href="https://doi.org/10.1007/s10462-023-10419-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The selection of word embedding and deep learning models for better outcomes is vital. Word embeddings are an n-dimensional distributed representation of a text that attempts to capture the meanings of the words. Deep learning models utilize multiple computing layers to learn hierarchical representations of data. The word embedding technique represented by deep learning has received much attention. It is used in various natural language processing (NLP) applications, such as text classification, sentiment analysis, named entity recognition, topic modeling, etc. This paper reviews the representative methods of the most prominent word embedding and deep learning models. It presents an overview of recent research trends in NLP and a detailed understanding of how to use these models to achieve efficient results on text analytics tasks. The review summarizes, contrasts, and compares numerous word embedding and deep learning models and includes a list of prominent datasets, tools, APIs, and popular publications. A reference for selecting a suitable word embedding and deep learning approach is presented based on a comparative analysis of different techniques to perform text analytics tasks. This paper can serve as a quick reference for learning the basics, benefits, and challenges of various word representation approaches and deep learning models, with their application to text analytics and a future outlook on research. It can be concluded from the findings of this study that domain-specific word embedding and the long short term memory model can be employed to improve overall text analytics task performance.},
  archive      = {J_AIR},
  author       = {Asudani, Deepak Suresh and Nagwani, Naresh Kumar and Singh, Pradeep},
  doi          = {10.1007/s10462-023-10419-1},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {10345-10425},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Impact of word embedding models on text analytics in deep learning environment: A review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Concept of hidden classes in pattern classification.
<em>AIR</em>, <em>56</em>(9), 10327–10344. (<a
href="https://doi.org/10.1007/s10462-023-10430-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our paper presents a novel approach to pattern classification. The general disadvantage of a traditional classifier is in too different behaviour and optimal parameter settings during training on a given pattern set and the following cross-validation. We describe the term critical sensitivity, which means the lowest reached sensitivity for an individual class. This approach ensures a uniform classification quality for individual class classification. Therefore, it prevents outlier classes with terrible results. We focus on the evaluation of critical sensitivity, as a quality criterion. Our proposed classifier eliminates this disadvantage in many cases. Our aim is to present that easily formed hidden classes can significantly contribute to improving the quality of a classifier. Therefore, we decided to propose classifier will have a relatively simple structure. The proposed classifier structure consists of three layers. The first is linear, used for dimensionality reduction. The second layer serves for clustering and forms hidden classes. The third one is the output layer for optimal cluster unioning. For verification of the proposed system results, we use standard datasets. Cross-validation performed on standard datasets showed that our critical sensitivity-based classifier provides comparable sensitivity to reference classifiers.},
  archive      = {J_AIR},
  author       = {Hrebik, Radek and Kukal, Jaromir},
  doi          = {10.1007/s10462-023-10430-6},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {10327-10344},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Concept of hidden classes in pattern classification},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Software tools for learning artificial intelligence
algorithms. <em>AIR</em>, <em>56</em>(9), 10297–10326. (<a
href="https://doi.org/10.1007/s10462-023-10436-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, artificial intelligence has become an important discipline in the field of computer science. Students, in the absence of basic prior knowledge, may have difficulty tracking materials when they first encounter complex and abstract artificial intelligence algorithms. Numerous researchers and educators point out that the use of simulation systems and software tools to illustrate the dynamic behavior of the algorithm can prove to be an effective solution. The introduction and adoption of new technologies in learning and teaching has evolved rapidly. This conceptual review paper aims to explore the emergence of innovative educational technologies in the teaching and learning of artificial intelligence. The aim of this paper is to analyze the existing representative educational tools for learning topics in the field of artificial intelligence to highlight their characteristics and areas they cover, so that readers can more easily draw conclusions about the possible use of some of the analyzed systems.},
  archive      = {J_AIR},
  author       = {Stamenković, Srećko and Jovanović, Nenad and Vasović, Bojan and Cvjetković, Miloš and Jovanović, Zoran},
  doi          = {10.1007/s10462-023-10436-0},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {10297-10326},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Software tools for learning artificial intelligence algorithms},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spherical fuzzy TODIM method for MAGDM integrating
cumulative prospect theory and CRITIC method and its application to
commercial insurance selection. <em>AIR</em>, <em>56</em>(9),
10275–10296. (<a
href="https://doi.org/10.1007/s10462-023-10409-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In rent years, commercial insurance selection is a hot issue in multiple attribute group decision making (MAGDM). Spherical fuzzy sets (SFSs) can better express the vague factors to commercial insurance selection. In this paper, spherical fuzzy TODIM approach based on cumulative prospect theory (SF-CPT-TODIM) is presented for MAGDM issues. It can display the psychological perception of decision makers (DMs) very well. Furthermore, when the attribute weights are unknown, we obtain the attribute weights through CRITIC method under SFSs to heighten the reasonability of weight information. Finally, this article gives a practical example of the raised approach for the hot issue about commercial insurance selection to certify the availability and superiority for the raised method via comparing with some existing approaches.},
  archive      = {J_AIR},
  author       = {Zhang, Huiyuan and Wang, Hongjun and Wei, Guiwu},
  doi          = {10.1007/s10462-023-10409-3},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {10275-10296},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Spherical fuzzy TODIM method for MAGDM integrating cumulative prospect theory and CRITIC method and its application to commercial insurance selection},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Complex q-rung orthopair fuzzy 2-tuple linguistic group
decision-making framework with muirhead mean operators. <em>AIR</em>,
<em>56</em>(9), 10227–10274. (<a
href="https://doi.org/10.1007/s10462-023-10408-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we aim to develop a method for solving multi-attribute group decision-making (MAGDM) problems with complex q-rung orthopair fuzzy 2-tuple linguistic sets. First, a complex q-rung orthopair fuzzy 2-tuple linguistic set (Cq-ROFTLS) is presented by combining the idea of 2-tuple linguistic set (2TLS) with complex q-rung orthopair fuzzy set (Cq-ROFS). Cq-ROFTLS is the best mechanism to deal with the imprecise and uncertain data in decision-making problems, characterized by 2TL complex-valued membership degree and non-membership degree and deals with two-dimensional data in one set at the same time by using extra terms known as phase terms related to periodicity and providing more space for decision makers (DMs) to explain their opinions. Muirhead mean (MM) operator can capture the interrelationships among all input arguments by changing a parameter vector. Considering the benefits of MM operator, we propose some new aggregation operators, including complex q-rung orthopair fuzzy 2-tuple linguistic Muirhead mean (Cq-ROFTLMM) operator, weighted Muirhead mean (Cq-ROFTLWMM) operator, complex q-rung orthopair fuzzy 2-tuple linguistic dual Muirhead mean (Cq-ROFTLDMM) operator, and weighted dual Muirhead mean (Cq-ROFTLWDMM) operator under Cq-ROFTL environment to expand its applied fields. Some properties and special cases related to the parameter vector are also proposed asong with the aggregation operators. Furthermore, a method to MAGDM problem is developed, and the proposed aggregation operators are used to solve the MAGDM problems related to the best choice of medication for pneumonia with Cq-ROFTL numbers (Cq-ROFTLNs). Finally, comparative analysis is presented with some existing methods.},
  archive      = {J_AIR},
  author       = {Akram, Muhammad and Naz, Sumera and Abbas, Tahir},
  doi          = {10.1007/s10462-023-10408-4},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {10227-10274},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Complex q-rung orthopair fuzzy 2-tuple linguistic group decision-making framework with muirhead mean operators},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine translation and its evaluation: A study.
<em>AIR</em>, <em>56</em>(9), 10137–10226. (<a
href="https://doi.org/10.1007/s10462-023-10423-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine translation (namely MT) has been one of the most popular fields in computational linguistics and Artificial Intelligence (AI). As one of the most promising approaches, MT can potentially break the language barrier of people from all over the world. Despite a number of studies in MT, there are few studies in summarizing and comparing MT methods. To this end, in this paper, we principally focus on presenting the two mainstream MT schemes: statistical machine translation (SMT) and neural machine translation (NMT), including their basic rationales and developments. Meanwhile, the detailed translation models are also presented, such as the word-based model, syntax-based model, and phrase-based model in statistical machine translation. Similarly, approaches in NMT, such as the recurrent neural network-based, attention mechanism-based, and transformer-based models are presented. Last but not least, the evaluation approaches also play an important role in helping developers to improve their methods better in MT. The prevailing machine translation evaluation methodologies are also presented in this article.},
  archive      = {J_AIR},
  author       = {Mondal, Subrota Kumar and Zhang, Haoxi and Kabir, H. M. Dipu and Ni, Kan and Dai, Hong-Ning},
  doi          = {10.1007/s10462-023-10423-5},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {10137-10226},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Machine translation and its evaluation: A study},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ME-CCNN: Multi-encoded images and a cascade convolutional
neural network for breast tumor segmentation and recognition.
<em>AIR</em>, <em>56</em>(9), 10099–10136. (<a
href="https://doi.org/10.1007/s10462-023-10426-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast tumor segmentation and recognition from mammograms play a key role in healthcare and treatment services. As different tumors in mammography have dissimilar densities, shapes, sizes, and edges, the interpretation of mammograms can be time-consuming and prone to interpretation variability even for a highly trained radiologist or expert. In this study, several encoding approaches are first proposed to achieve an effective breast cancer recognition system as well as create new images from the input image. Each encoded image represents some unique features that are crucial for detecting the target texture properly. Subsequently, pectoral muscle is eliminated using obtained features from these encoded images. Moreover, 11 distinct images are then applied to a shallow and efficient cascade Convolutional Neural Network (CNN) for classifying each pixel inside the image. This network accepts 11 local patches as the input from 11 obtained encoded images. Next, all extracted features are concatenated to a vertical vector to apply to the fully connected layers. Using different representations of the input mammogram images, the suggested model is able to analyze the input texture more effectively without using a deep CNN model. Finally, comprehensive experiments are then conducted on two public datasets which then demonstrate that the proposed framework successfully is able to gain competitive outcomes compared to a number of baselines.},
  archive      = {J_AIR},
  author       = {Ranjbarzadeh, Ramin and Jafarzadeh Ghoushchi, Saeid and Tataei Sarshar, Nazanin and Tirkolaee, Erfan Babaee and Ali, Sadia Samar and Kumar, Teerath and Bendechache, Malika},
  doi          = {10.1007/s10462-023-10426-2},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {10099-10136},
  shortjournal = {Artif. Intell. Rev.},
  title        = {ME-CCNN: Multi-encoded images and a cascade convolutional neural network for breast tumor segmentation and recognition},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predicting total sediment load transport in rivers using
regression techniques, extreme learning and deep learning models.
<em>AIR</em>, <em>56</em>(9), 10067–10098. (<a
href="https://doi.org/10.1007/s10462-023-10422-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Total sediment load exerts control over the river channel morphology. Due to the non-linear and multi-dimensional behavior of the variables impacting total sediment load, the prediction is often complex and challenging. To handle this non-linearity and multi-dimensional behavior of total sediment load variables, various approaches like empirical equations, data mining techniques, genetic algorithms, and machine learning (ML) methods have been proposed in the literature. This study provides a substantially better prediction of total sediment load using various methods i.e., linear regression (LR), support vector regression (SVR), extreme learning machine (ELM), and deep neural network (DNN). To evaluate the models, several performance metrics have been used i.e., index of agreement ( $$I_d$$ ), Pearson correlation coefficient (PCC), mean square error (MSE), Nash-Sutcliffe efficiency (NSE), root mean square error (RMSE), R $$^2$$ , and discrepancy ratio (D $$_r$$ ). Results show that, the proposed DNN method predicted the total sediment load with significant accuracy and had the highest prediction accuracy (I $$_d$$ = 0.989, PCC = 0.979, MSE = 0.042, NSE = 0.958, RMSE = 0.204, R $$^2$$ = 0.959, D $$_r$$ = 91.91\%, respectively) followed by ELM, SVR, and LR. However, the performance of other proposed methods has been satisfactory when compared with the existing techniques. The proposed methods are compared with various well-known empirical equations available in the literature.},
  archive      = {J_AIR},
  author       = {Shakya, Deepti and Deshpande, Vishal and Kumar, Bimlesh and Agarwal, Mayank},
  doi          = {10.1007/s10462-023-10422-6},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {10067-10098},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Predicting total sediment load transport in rivers using regression techniques, extreme learning and deep learning models},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning algorithms to forecast air quality: A
survey. <em>AIR</em>, <em>56</em>(9), 10031–10066. (<a
href="https://doi.org/10.1007/s10462-023-10424-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Air pollution is a risk factor for many diseases that can lead to death. Therefore, it is important to develop forecasting mechanisms that can be used by the authorities, so that they can anticipate measures when high concentrations of certain pollutants are expected in the near future. Machine Learning models, in particular, Deep Learning models, have been widely used to forecast air quality. In this paper we present a comprehensive review of the main contributions in the field during the period 2011–2021. We have searched the main scientific publications databases and, after a careful selection, we have considered a total of 155 papers. The papers are classified in terms of geographical distribution, predicted values, predictor variables, evaluation metrics and Machine Learning model.},
  archive      = {J_AIR},
  author       = {Méndez, Manuel and Merayo, Mercedes G. and Núñez, Manuel},
  doi          = {10.1007/s10462-023-10424-4},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {10031-10066},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Machine learning algorithms to forecast air quality: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Chaotic electromagnetic field optimization. <em>AIR</em>,
<em>56</em>(9), 9989–10030. (<a
href="https://doi.org/10.1007/s10462-022-10324-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The search process in population-based metaheuristic algorithms (MAs) can be classified into two primary behaviours: diversification and intensification. In diversification behaviour, the search space will be explored considerably based on randomization. Whereas intensification alludes to the search for a promising region locally. The success of MAs relies on the balance between two search behaviours. Nonetheless, it is strenuous to get the right balance between these behaviours due to the scholastic nature of MAs. Chaotic maps are proven an excellent tool to enhance both behaviours. This work incorporates the Logistic chaotic map into the recently proposed population-based MA called Electromagnetic field optimization (EFO). This suggested algorithm is named chaotic EFO (CEFO). An improved diversification step with chaos in EFO is presented to efficiently control the global search and convergence to the global best solution. CEFO is tested on different case studies, 40 unconstrained CEC 2014 and CEC 2019 benchmark functions, seven real-world nonlinear systems and three mechanical engineering design frameworks. All experiments are compared with other recent and improved algorithms in the literature to show the performance and effectiveness of the proposed algorithm. Two nonparametric statistical tests, the Wilcoxon rank-sum and the Friedman test, are performed on CEFO and other compared algorithms to determine the significance of the results and show the efficiency of CEFO over other algorithms.},
  archive      = {J_AIR},
  author       = {Ibrahim, Abdelmonem M. and Tawhid, Mohamed A.},
  doi          = {10.1007/s10462-022-10324-z},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {9989-10030},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Chaotic electromagnetic field optimization},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic targetless LiDAR–camera calibration: A survey.
<em>AIR</em>, <em>56</em>(9), 9949–9987. (<a
href="https://doi.org/10.1007/s10462-022-10317-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent trend of fusing complementary data from LiDARs and cameras for more accurate perception has made the extrinsic calibration between the two sensors critically important. Indeed, to align the sensors spatially for proper data fusion, the calibration process usually involves estimating the extrinsic parameters between them. Traditional LiDAR–camera calibration methods often depend on explicit targets or human intervention, which can be prohibitively expensive and cumbersome. Recognizing these weaknesses, recent methods usually adopt the autonomic targetless calibration approach, which can be conducted at a much lower cost. This paper presents a thorough review of these automatic targetless LiDAR–camera calibration methods. Specifically, based on how the potential cues in the environment are retrieved and utilized in the calibration process, we divide the methods into four categories: information theory based, feature based, ego-motion based, and learning based methods. For each category, we provide an in-depth overview with insights we have gathered, hoping to serve as a potential guidance for researchers in the related fields.},
  archive      = {J_AIR},
  author       = {Li, Xingchen and Xiao, Yuxuan and Wang, Beibei and Ren, Haojie and Zhang, Yanyong and Ji, Jianmin},
  doi          = {10.1007/s10462-022-10317-y},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {9949-9987},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Automatic targetless LiDAR–camera calibration: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new hyper-heuristic based on ant lion optimizer and tabu
search algorithm for replica management in cloud environment.
<em>AIR</em>, <em>56</em>(9), 9837–9947. (<a
href="https://doi.org/10.1007/s10462-022-10309-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information can be shared across the Internet using cloud computing, a powerful paradigm for meeting the needs of individuals and organizations. To minimize access time and maximize load balancing for data nodes (DNs), a dynamic data replication algorithm is necessary. Even so, few of the existing algorithms consider each objective holistically during replication. An improved ant lion optimizer (ALO) algorithm and a fuzzy system are used in this paper to determine dynamically the number of replicas and the DNs for replication. Further, it balances the trade-offs among different objectives (e.g., service time, system availability, load, and monetary cost). The ALO algorithm has been widely applied to solve complex optimization problems due to its simplicity in implementation. However, ALO has premature convergence and can thus easily get trapped into the local optimum solution. In this paper, to overcome the shortcomings of ALO by balancing exploration and exploitation, a hybrid ant lion optimizer with Tabu search algorithm (ALO-Tabu) is proposed. There are several improvements of the ALO, in which the appropriate solutions are selected for the initial population based on chaotic maps (CMs) and opposition-based learning (OBL) strategies. On the other hand, there are many CMs, OBLs, and random walk strategies that make it difficult to select the best one for optimization. Generally, they are selected manually, which is time-consuming. As a result, this paper presents a hyper-heuristic ALO (HH-ALO-Tabu) that automatically chooses CMs, OBLs, and random walk strategies depending on the differential evolution (DE) algorithm. Based on 20 well-known test functions, the experiment results and statistical tests show that HH-ALO-Tabu can solve optimization problems effectively.},
  archive      = {J_AIR},
  author       = {Mohammad Hasani Zade, Behnam and Mansouri, Najme and Javidi, Mohammad Masoud},
  doi          = {10.1007/s10462-022-10309-y},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {9837-9947},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A new hyper-heuristic based on ant lion optimizer and tabu search algorithm for replica management in cloud environment},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An extensive survey on the use of supervised machine
learning techniques in the past two decades for prediction of drug side
effects. <em>AIR</em>, <em>56</em>(9), 9809–9836. (<a
href="https://doi.org/10.1007/s10462-023-10413-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approved drugs for sale must be effective and safe, implying that the drug’s advantages outweigh its known harmful side effects. Side effects (SE) of drugs are one of the common reasons for drug failure that may halt the whole drug discovery pipeline. The side effects might vary from minor concerns like a runny nose to potentially life-threatening issues like liver damage, heart attack, and death. Therefore, predicting the side effects of the drug is vital in drug development, discovery, and design. Supervised machine learning-based side effects prediction task has recently received much attention since it reduces time, chemical waste, design complexity, risk of failure, and cost. The advancement of supervised learning approaches for predicting side effects have emerged as essential computational tools. Supervised machine learning technique provides early information on drug side effects to develop an effective drug based on drug properties. Still, there are several challenges to predicting drug side effects. Thus, a near-exhaustive survey is carried out in this paper on the use of supervised machine learning approaches employed in drug side effects prediction tasks in the past two decades. In addition, this paper also summarized the drug descriptor required for the side effects prediction task, commonly utilized drug properties sources, computational models, and their performances. Finally, the research gap, open problems, and challenges for the further supervised learning-based side effects prediction task have been discussed.},
  archive      = {J_AIR},
  author       = {Das, Pranab and Mazumder, Dilwar Hussain},
  doi          = {10.1007/s10462-023-10413-7},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {9809-9836},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An extensive survey on the use of supervised machine learning techniques in the past two decades for prediction of drug side effects},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Games of GANs: Game-theoretical models for generative
adversarial networks. <em>AIR</em>, <em>56</em>(9), 9771–9807. (<a
href="https://doi.org/10.1007/s10462-023-10395-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) have recently attracted considerable attention in the AI community due to their ability to generate high-quality data of significant statistical resemblance to real data. Fundamentally, GAN is a game between two neural networks trained in an adversarial manner to reach a zero-sum Nash equilibrium profile. Despite the improvement accomplished in GANs in the last few years, several issues remain to be solved. This paper reviews the literature on the game-theoretic aspects of GANs and addresses how game theory models can address specific challenges of generative models and improve the GAN’s performance. We first present some preliminaries, including the basic GAN model and some game theory background. We then present a taxonomy to classify state-of-the-art solutions into three main categories: modified game models, modified architectures, and modified learning methods. The classification is based on modifications made to the basic GAN model by proposed game-theoretic approaches in the literature. We then explore the objectives of each category and discuss recent works in each class. Finally, we discuss the remaining challenges in this field and present future research directions.},
  archive      = {J_AIR},
  author       = {Mohebbi Moghaddam, Monireh and Boroomand, Bahar and Jalali, Mohammad and Zareian, Arman and Daeijavad, Alireza and Manshaei, Mohammad Hossein and Krunz, Marwan},
  doi          = {10.1007/s10462-023-10395-6},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {9771-9807},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Games of GANs: Game-theoretical models for generative adversarial networks},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of energy-efficient clustering routing protocols
for wireless sensor networks based on metaheuristic approaches.
<em>AIR</em>, <em>56</em>(9), 9699–9770. (<a
href="https://doi.org/10.1007/s10462-023-10402-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increase in proposed clustering routing protocols for Wireless Sensor Networks has motivated the development of survey studies that provide quick access to clear and meaningful information about state-of-the-art approaches. This review focuses on the most recent clustering routing protocols for WSNs based on metaheuristic techniques. Since there is a lack of survey studies that provide a comprehensive analysis of this field, we present a more in-depth study of different metaheuristic-based strategies mainly for selecting optimal cluster heads. The primary objective of the proposed work is to review approaches that have developed novel cluster-based routing protocols primarily for reducing the energy consumption of WSNs. In this survey, we examine every protocol considering its methodology and properties from the perspective of the metaheuristic community. Additionally, we present a comparative analysis of the reviewed approaches regarding the implemented network structure, the network characteristics, the metaheuristic algorithm used, the proposed search strategy, reported metrics, and the obtained results.},
  archive      = {J_AIR},
  author       = {Del-Valle-Soto, Carolina and Rodríguez, Alma and Ascencio-Piña, Cesar Rodolfo},
  doi          = {10.1007/s10462-023-10402-w},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {9699-9770},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of energy-efficient clustering routing protocols for wireless sensor networks based on metaheuristic approaches},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Community detection model for dynamic networks based on
hidden markov model and evolutionary algorithm. <em>AIR</em>,
<em>56</em>(9), 9665–9697. (<a
href="https://doi.org/10.1007/s10462-022-10383-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding communities of connected individuals in complex networks is challenging, yet crucial for understanding different real-world societies and their interactions. Recently attention has turned to discover the dynamics of such communities. However, detecting accurate community structures that evolve over time adds additional challenges. Almost all the state-of-the-art algorithms are designed based on seemingly the same principle while treating the problem as a coupled optimization model to simultaneously identify community structures and their evolution over time. Unlike all these studies, the current work aims to individually consider this three measures, i.e. intra-community score, inter-community score, and evolution of community over time. Here, we adopt a new perspective towards detecting the evolution of community structures. The proposed method realizes the decomposition of the problem into three essential components; searching in: intra-community connections, inter-community connections, and community evolution. A multi-objective optimization problem is defined to account for the different intra and inter community structures. Further, we formulate the community evolution problem as a Hidden Markov Model in an attempt to dexterously track the most likely sequence of communities. Then the new model, called Hidden Markov Model-based Multi-Objective evolutionary algorithm for Dynamic Community Detection (HMM-MODCD), uses a multi-objective evolutionary algorithm and Viterbi algorithm for formulating objective functions and providing temporal smoothness over time for clustering dynamic networks. The performance of the proposed algorithm is evaluated on synthetic and real-world dynamic networks and compared against several state-of-the-art algorithms. The results clearly demonstrate the effectiveness of the proposed algorithm to outperform other algorithms.},
  archive      = {J_AIR},
  author       = {Abbood, Amenah D. and Attea, Bara’a A. and Hasan, Ammar A. and Everson, Richard M. and Pizzuti, Clara},
  doi          = {10.1007/s10462-022-10383-2},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {9665-9697},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Community detection model for dynamic networks based on hidden markov model and evolutionary algorithm},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Advanced artificial intelligence system by intuitionistic
fuzzy <span class="math display"><em>Γ</em></span> -subring for
automotive robotic manufacturing. <em>AIR</em>, <em>56</em>(9),
9639–9664. (<a
href="https://doi.org/10.1007/s10462-023-10396-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, robotic engineering has been enriched with Artificial Intelligence (AI) technology, preparing the industries to enter the Industry 4.0 era. The powerful neoteric paradigm of AI can serve automotive industries (as one of the largest sectors in the world), to inevitably change their outdated manufacturing strategies. These industrial sectors are increasingly encountering mega data that inevitably carry uncertainty, for which the available methodologies are not capable to deal with that efficiently. To theoretically resolve this gap, a generalized intuitionistic fuzzy set (IFS) theory is proposed here as an efficient, fast, and flexible method. Based on the membership and non-membership degrees, multi-aspect $$\Gamma$$ -systems is developed to model the complex real systems. Inspired by multi-attribute $$\Gamma$$ -systems and IFS approach, a novel mathematical concept namely intuitionistic fuzzy $$\Gamma$$ -subring (IF $$\Gamma$$ R) method, is developed to establish an AI platform for robotic automotive manufacturing. Significant characteristics of IF $$\Gamma$$ R are developed, including the overlapping of elements with IF $$\Gamma$$ R property is IF $$\Gamma$$ R, also image and inverse image of elements with IF $$\Gamma$$ R property are IF $$\Gamma$$ R under $$\Gamma$$ -ring homomorphism. Additionally, the connection between upper and lower bound level cuts and image/inverse image property are parametrically discussed. With the effect of surjective homomorphism on upper and lower level cuts, there would be equivalent upper and lower level cuts of image/inverse image in IF $$\Gamma$$ R environment. The developed notion of IF $$\Gamma$$ I is obtained as the generalization of $$\Gamma$$ -ideal under $$\Gamma$$ -ring R along with the resultant fundamental properties of IF $$\Gamma$$ I, where the overlapping/intersection family of IF $$\Gamma$$ Is is proved to be IF $$\Gamma$$ I. Also, the upper and lower bound level cuts of elements with IF $$\Gamma$$ I property are $$\Gamma$$ -ideals. Finally, the proposed IF $$\Gamma$$ R method is utilized for automotive AI systems (AAIS) by means of mathematical algebraic notions of $$\Gamma$$ -ring, IFS, $$\Gamma$$ -ring isomorphism, and upper and lower bound levels. The developed methodology is validated using real dataset of industrial robots in supply chain and then, the elements are characterized in terms of metric overall factory effectiveness. With a systematic pattern of $$\Gamma$$ -ring structure, the IF $$\Gamma$$ R model is accomplished on elements, and the intercomponent correspondence of AAIS is established with the $$\Gamma$$ -ring isomorphism. Based on QC (quality criteria) and non-QC indexes, as the derivation of upper and lower bound level cuts, the analysis of parameters (robots) is simplified for the identification of effective and compatible components in AAIS. The generalized IFS-based method for complex systems has a potential to be used in different AI platforms.},
  archive      = {J_AIR},
  author       = {Firouzkouhi, Narjes and Amini, Abbas and Nazari, Marziyeh and Alkhatib, Fadi and Bordbar, Hashem and Cheng, Chun and Davvaz, Bijan and Rashidi, Maria},
  doi          = {10.1007/s10462-023-10396-5},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {9639-9664},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Advanced artificial intelligence system by intuitionistic fuzzy $$\Gamma$$ -subring for automotive robotic manufacturing},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning: Survey of environmental and camera impacts on
internet of things images. <em>AIR</em>, <em>56</em>(9), 9605–9638. (<a
href="https://doi.org/10.1007/s10462-023-10405-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) images are captivating growing attention because of their wide range of applications which requires visual analysis to drive automation. However, IoT images are predominantly captured from outdoor environments and thus are inherently impacted by the camera and environmental parameters which can adversely affect corresponding applications. Deep Learning (DL) has been widely adopted in the field of image processing and computer vision and can reduce the impact of these parameters on IoT images. Albeit, there are many DL-based techniques available in the current literature for analyzing and reducing the environmental and camera impacts on IoT images. However, to the best of our knowledge, no survey paper presents state-of-the-art DL-based approaches for this purpose. Motivated by this, for the first time, we present a Systematic Literature Review (SLR) of existing DL techniques available for analyzing and reducing environmental and camera lens impacts on IoT images. As part of this SLR, firstly, we reiterate and highlight the significance of IoT images in their respective applications. Secondly, we describe the DL techniques employed for assessing the environmental and camera lens distortion impacts on IoT images. Thirdly, we illustrate how DL can be effective in reducing the impact of environmental and camera lens distortion in IoT images. Finally, along with the critical reflection on the advantages and limitations of the techniques, we also present ways to address the research challenges of existing techniques and identify some further researches to advance the relevant research areas.},
  archive      = {J_AIR},
  author       = {Kaur, Roopdeep and Karmakar, Gour and Xia, Feng and Imran, Muhammad},
  doi          = {10.1007/s10462-023-10405-7},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {9605-9638},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep learning: Survey of environmental and camera impacts on internet of things images},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-domain decision making based on criterion weights and
risk attitudes for the diagnosis of breast lesions. <em>AIR</em>,
<em>56</em>(9), 9575–9603. (<a
href="https://doi.org/10.1007/s10462-023-10394-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a specific decision model for two decision problems faced by a decision maker, decision parameters can be learned from the accumulated historical data. In general, more accumulated data can better reflect the real preferences of the decision maker. The knowledge contained in more historical data for one decision problem may help improve parameter learning for the other decision problem with less historical data. Inspired by this idea, a cross-domain decision making method is proposed to improve the learning of parameters, namely criterion weights and risk attitudes of the decision maker, in the target decision problem with less historical data by using the parameters learned from more historical data in the source decision problem. A transferability measure is developed to evaluate whether the knowledge contained in the historical data from the source decision problem is beneficial for improving parameter learning in the target decision problem. When the transferability between the source and target decision problems is judged to work well, the parameter transfer strategy is designed to conduct the parameter learning in the target decision problem by using criterion weights and risk attitudes of the decision maker learned from historical data from the source decision problem. The effectiveness of the proposed method is validated by its application in helping diagnose breast lesions with the historical diagnostic data of seven radiologists collected from a tertiary hospital located in Hefei, Anhui, China.},
  archive      = {J_AIR},
  author       = {Fu, Chao and Wu, Zijian and Chang, Wenjun and Lin, Mingwei},
  doi          = {10.1007/s10462-023-10394-7},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {9575-9603},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Cross-domain decision making based on criterion weights and risk attitudes for the diagnosis of breast lesions},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). High-accuracy model-based reinforcement learning, a survey.
<em>AIR</em>, <em>56</em>(9), 9541–9573. (<a
href="https://doi.org/10.1007/s10462-022-10335-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning has shown remarkable success in the past few years. Highly complex sequential decision making problems from game playing and robotics have been solved with deep model-free methods. Unfortunately, the sample complexity of model-free methods is often high. Model-based reinforcement learning, in contrast, can reduce the number of environment samples, by learning an explicit internal model of the environment dynamics. However, achieving good model accuracy in high dimensional problems is challenging. In recent years, a diverse landscape of model-based methods has been introduced to improve model accuracy, using methods such as probabilistic inference, model-predictive control, latent models, and end-to-end learning and planning. Some of these methods succeed in achieving high accuracy at low sample complexity in typical benchmark applications. In this paper, we survey these methods; we explain how they work and what their strengths and weaknesses are. We conclude with a research agenda for future work to make the methods more robust and applicable to a wider range of applications.},
  archive      = {J_AIR},
  author       = {Plaat, Aske and Kosters, Walter and Preuss, Mike},
  doi          = {10.1007/s10462-022-10335-w},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {9541-9573},
  shortjournal = {Artif. Intell. Rev.},
  title        = {High-accuracy model-based reinforcement learning, a survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning in economics: A systematic and critical
review. <em>AIR</em>, <em>56</em>(9), 9497–9539. (<a
href="https://doi.org/10.1007/s10462-022-10272-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From the perspective of historical review, the methodology of economics develops from qualitative to quantitative, from a small sampling of data to a vast amount of data. Because of the superiority in learning inherent law and representative level, deep learning models assist in realizing intelligent decision-making in economics. After presenting some statistical results of relevant researches, this paper systematically investigates deep learning in economics, including a survey of frequently-used deep learning models in economics, several applications of deep learning models used in economics. Then, some critical reviews of deep learning in economics are provided, including models and applications, why and how to implement deep learning in economics, research gap and future challenges, respectively. It is obvious that several deep learning models and their variants have been widely applied in different subfields of economics, e.g., financial economics, macroeconomics and monetary economics, agricultural and natural resource economics, industrial organization, urban, rural, regional, real estate and transportation economics, health, education and welfare, business administration and microeconomics, etc. We are very confident that decision-making in economics will be more intelligent with the development of deep learning, because the research of deep learning in economics has become a hot and important topic recently.},
  archive      = {J_AIR},
  author       = {Zheng, Yuanhang and Xu, Zeshui and Xiao, Anran},
  doi          = {10.1007/s10462-022-10272-8},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {9497-9539},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep learning in economics: A systematic and critical review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint graph and reduced flexible manifold embedding for
scalable semi-supervised learning. <em>AIR</em>, <em>56</em>(9),
9471–9495. (<a
href="https://doi.org/10.1007/s10462-023-10397-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, graph-based semi-supervised learning (GSSL) has received much attention. On the other hand, less attention has been paid to the problem of large-scale GSSL for inductive multi-class classification. Existing scalable GSSL methods rely on a hard linear constraint. They cannot predict the labelling of test samples, or use predefined graphs, which limits their applications and performance. In this paper, we propose an inductive algorithm that can handle large databases by using anchors. The main contribution compared to existing scalable semi-supervised models is the integration of the anchor graph computation into the learned model. We develop a criterion to jointly estimate the unlabeled sample labels, the mapping of the feature space to the label space, and the affinity matrix of the anchor graph. Furthermore, the fusion of labels and features of anchors is used to construct the graph. Using the projection matrix, it can also predict the labels of the test samples by linear transformation. Experimental results on the large datasets NORB, RCV1 and Covtype show the effectiveness, scalability and superiority of the proposed method. The code of the proposed method can be found at the following link https://github.com/ZoulfikarIB/SGRFME .},
  archive      = {J_AIR},
  author       = {Ibrahim, Z. and Bosaghzadeh, A. and Dornaika, F.},
  doi          = {10.1007/s10462-023-10397-4},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {9471-9495},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Joint graph and reduced flexible manifold embedding for scalable semi-supervised learning},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of semi-supervised learning for text
classification. <em>AIR</em>, <em>56</em>(9), 9401–9469. (<a
href="https://doi.org/10.1007/s10462-023-10393-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A huge amount of data is generated daily leading to big data challenges. One of them is related to text mining, especially text classification. To perform this task we usually need a large set of labeled data that can be expensive, time-consuming, or difficult to be obtained. Considering this scenario semi-supervised learning (SSL), the branch of machine learning concerned with using labeled and unlabeled data has expanded in volume and scope. Since no recent survey exists to overview how SSL has been used in text classification, we aim to fill this gap and present an up-to-date review of SSL for text classification. We retrieve 1794 works from the last 5 years from IEEE Xplore, ACM Digital Library, Science Direct, and Springer. Then, 157 articles were selected to be included in this review. We present the application domain, datasets, and languages employed in the works. The text representations and machine learning algorithms. We also summarize and organize the works following a recent taxonomy of SSL. We analyze the percentage of labeled data used, the evaluation metrics, and obtained results. Lastly, we present some limitations and future trends in the area. We aim to provide researchers and practitioners with an outline of the area as well as useful information for their current research.},
  archive      = {J_AIR},
  author       = {Duarte, José Marcio and Berton, Lilian},
  doi          = {10.1007/s10462-023-10393-8},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {9401-9469},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review of semi-supervised learning for text classification},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exponential distribution optimizer (EDO): A novel
math-inspired algorithm for global optimization and engineering
problems. <em>AIR</em>, <em>56</em>(9), 9329–9400. (<a
href="https://doi.org/10.1007/s10462-023-10403-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous optimization problems can be addressed using metaheuristics instead of deterministic and heuristic approaches. This study proposes a novel population-based metaheuristic algorithm called the Exponential Distribution Optimizer (EDO). The main inspiration for EDO comes from mathematics based on the exponential probability distribution model. At the outset, we initialize a population of random solutions representing multiple exponential distribution models. The positions in each solution represent the exponential random variables. The proposed algorithm includes two methodologies for exploitation and exploration strategies. For the exploitation stage, the algorithm utilizes three main concepts, memoryless property, guiding solution and the exponential variance among the exponential random variables to update the current solutions. To simulate the memoryless property, we assume that the original population contains only the winners that obtain good fitness. We construct another matrix known as memoryless to retain the newly generated solutions regardless of their fitness compared to their corresponding winners in the original population. As a result, the memoryless matrix stores two types of solutions: winners and losers. According to the memoryless property, we disregard and do not memorize the previous history of these solutions because past failures are independent and have no influence on the future. The losers can thus contribute to updating the new solutions next time. We select two solutions from the original population derived from the exponential distributions to update the new solution throughout the exploration phase. Furthermore, EDO is tested against classical test functions in addition to the Congress on Evolutionary Computation (CEC) 2014, CEC 2017, CEC 2020 and CEC 2022 benchmarks, as well as six engineering design problems. EDO is compared with the winners of CEC 2014, CEC 2017 and CEC 2020, which are L-SHADE, LSHADE−cnEpSin and AGSK, respectively. EDO reveals exciting results and can be a robust tool for CEC competitions. Statistical analysis demonstrates the superiority of the proposed EDO at a 95\% confidence interval.},
  archive      = {J_AIR},
  author       = {Abdel-Basset, Mohamed and El-Shahat, Doaa and Jameel, Mohammed and Abouhawwash, Mohamed},
  doi          = {10.1007/s10462-023-10403-9},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {9329-9400},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Exponential distribution optimizer (EDO): A novel math-inspired algorithm for global optimization and engineering problems},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HG-SMA: Hierarchical guided slime mould algorithm for smooth
path planning. <em>AIR</em>, <em>56</em>(9), 9267–9327. (<a
href="https://doi.org/10.1007/s10462-023-10398-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The smooth path planning for mobile robots is attracted particular research attention. In this paper, an enhanced slime mould algorithm called HG-SMA is proposed to solve a new smooth path planning model based on the Said-Ball curve. Firstly, the enhanced algorithm is constructed by adding a hierarchical guided strategy. This strategy considers the characteristics of individuals with different fitness values, and divides the slime mould population into two hierarchies. And corresponding strategies are applied to different hierarchies to improve the quality of solutions. To validate the performance of the proposed HG-SMA algorithm, it is compared with other improved slime mould algorithms and classical meta-heuristic algorithms on test functions of CEC2017 and CEC2019 suites. Results show HG-SMA performs best on 74.36 and 79.49\% of all 39 functions when compared with other improved SMA algorithms and classical optimization algorithms, respectively, which illustrates it is superior to others in solution accuracy, stability and convergence speed. Secondly, by regarding the control points as variables, a novel smooth path planning model based on Said-Ball curve is established to generate the feasible path for mobile robots. Compared with other traditional path planning approaches (A*, RRT and Informed RRT*), the Said-Ball curve-based approach can construct paths with higher smoothness, and has advantages in calculation speed compared with Bézier curve-based approach. Finally, the proposed HG-SMA is employed to solve the established optimization model based on Said-Ball curve, named the Said-Ball + HG-SMA approach. In three designed workplaces, HG-SMA also has advantages in generating feasible paths with shorter lengths and higher smoothness when compared with the original SMA and other classical algorithms.},
  archive      = {J_AIR},
  author       = {Hu, Gang and Du, Bo and Wei, Guo},
  doi          = {10.1007/s10462-023-10398-3},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {9267-9327},
  shortjournal = {Artif. Intell. Rev.},
  title        = {HG-SMA: Hierarchical guided slime mould algorithm for smooth path planning},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Review and analysis of synthetic dataset generation methods
and techniques for application in computer vision. <em>AIR</em>,
<em>56</em>(9), 9221–9265. (<a
href="https://doi.org/10.1007/s10462-022-10358-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthetic datasets, for which we propose the term synthsets, are not a novelty but have become a necessity. Although they have been used in computer vision since 1989, helping to solve the problem of collecting a sufficient amount of annotated data for supervised machine learning, intensive development of methods and techniques for their generation belongs to the last decade. Nowadays, the question shifts from whether you should use synthetic datasets to how you should optimally create them. Motivated by the idea of discovering best practices for building synthetic datasets to represent dynamic environments (such as traffic, crowds, and sports), this study provides an overview of existing synthsets in the computer vision domain. We have analyzed the methods and techniques of synthetic datasets generation: from the first low-res generators to the latest generative adversarial training methods, and from the simple techniques for improving realism by adding global noise to those meant for solving domain and distribution gaps. The analysis extracts nine unique but potentially intertwined methods and reveals the synthsets generation diagram, consisting of 17 individual processes that synthset creators should follow and choose from, depending on the specific requirements of their task.},
  archive      = {J_AIR},
  author       = {Paulin, Goran and Ivasic‐Kos, Marina},
  doi          = {10.1007/s10462-022-10358-3},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {9221-9265},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Review and analysis of synthetic dataset generation methods and techniques for application in computer vision},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning-based 3D reconstruction: A survey.
<em>AIR</em>, <em>56</em>(9), 9175–9219. (<a
href="https://doi.org/10.1007/s10462-023-10399-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image-based 3D reconstruction is a long-established, ill-posed problem defined within the scope of computer vision and graphics. The purpose of image-based 3D reconstruction is to retrieve the 3D structure and geometry of a target object or scene from a set of input images. This task has a wide range of applications in various fields, such as robotics, virtual reality, and medical imaging. In recent years, learning-based methods for 3D reconstruction have attracted many researchers worldwide. These novel methods can implicitly estimate the 3D shape of an object or a scene in an end-to-end manner, eliminating the need for developing multiple stages such as key-point detection and matching. Furthermore, these novel methods can reconstruct the shapes of objects from a single input image. Due to rapid advancements in this field, as well as the multitude of opportunities to improve the performance of 3D reconstruction methods, a thorough review of algorithms in this area seems necessary. As a result, this research provides a complete overview of recent developments in the field of image-based 3D reconstruction. The studied methods are examined from several viewpoints, such as input types, model structures, output representations, and training strategies. A detailed comparison is also provided for the reader. Finally, unresolved challenges, underlying issues, and possible future work are discussed.},
  archive      = {J_AIR},
  author       = {Samavati, Taha and Soryani, Mohsen},
  doi          = {10.1007/s10462-023-10399-2},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {9175-9219},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep learning-based 3D reconstruction: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detection of cervical spondylotic myelopathy based on gait
analysis and deterministic learning. <em>AIR</em>, <em>56</em>(9),
9157–9173. (<a
href="https://doi.org/10.1007/s10462-023-10404-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cervical spondylotic myelopathy (CSM) is the main cause of cervical spinal cord dysfunction in adults, especially in middle-aged and elderly patients, which easily leads to gait disturbance. In the present study, we propose a dynamic method for the detection of CSM based on nonlinear dynamics of gait system and deterministic learning theory. First, a 3-dimensional (3D) gait analysis system is used to capture the walking locomotion from healthy controls (HCs) and patients with CSM. Discriminant kinematic gait features, including angles of hip and knee joints in the sagittal and coronal planes, are extracted based on statistical analysis and clinicians’ empirical investigation. Second, deterministic learning theory is used to model and identify nonlinear gait system dynamics of HCs and patients with CSM, which are approximated and stored in constant Radial Basis Function (RBF) neural networks (NN). The disparity of gait system dynamics between the two groups of participants is used for classification and detection of the presence of CSM by constructing a bank of dynamic estimators with constant RBF NN. Finally, experiments are carried out on the self-constructed CSM gait database to evaluate the performance of the proposed method, in which gait data from 45 CSM patients and 45 age-matched HCs are involved. By using 2-fold and leave-one-out cross-validation styles, the achieved average classification accuracy is reported to be 94.44 $$\%$$ and 95.56 $$\%$$ , respectively. The results demonstrate excellent performance and the proposed method has the potential to serve as a candidate for the automatic detection of CSM in clinical examination.},
  archive      = {J_AIR},
  author       = {Ji, Bing and Dai, Qihang and Ji, Xinyu and Wu, Weiming and Sun, Qinghua and Ma, Hecheng and Cong, Menglin and Cheng, Lei and Wang, Cong and Si, Meng and Zeng, Wei},
  doi          = {10.1007/s10462-023-10404-8},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {9157-9173},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Detection of cervical spondylotic myelopathy based on gait analysis and deterministic learning},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mind the gap: Challenges of deep learning approaches to
theory of mind. <em>AIR</em>, <em>56</em>(9), 9141–9156. (<a
href="https://doi.org/10.1007/s10462-023-10401-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Theory of Mind (ToM) is an essential ability of humans to infer the mental states of others. Here we provide a coherent summary of the potential, current progress, and problems of deep learning (DL) approaches to ToM. We highlight that many current findings can be explained through shortcuts. These shortcuts arise because the tasks used to investigate ToM in deep learning systems have been too narrow. Thus, we encourage researchers to investigate ToM in complex open-ended environments. Furthermore, to inspire future DL systems we provide a concise overview of prior work done in humans. We further argue that when studying ToM with DL, the research’s main focus and contribution ought to be opening up the network’s representations. We recommend researchers to use tools from the field of interpretability of AI to study the relationship between different network components and aspects of ToM.},
  archive      = {J_AIR},
  author       = {Aru, Jaan and Labash, Aqeel and Corcoll, Oriol and Vicente, Raul},
  doi          = {10.1007/s10462-023-10401-x},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {9141-9156},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Mind the gap: Challenges of deep learning approaches to theory of mind},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Time expression recognition and normalization: A survey.
<em>AIR</em>, <em>56</em>(9), 9115–9140. (<a
href="https://doi.org/10.1007/s10462-023-10400-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time information plays an important role in the areas of data mining, information retrieval, and natural language processing. Among the linguistic tasks related to time expressions, time expression recognition and normalization (TERN) is fundamental for other downstream tasks. Researchers from these areas have devoted considerable effort in the last two decades to define the problem of time expression analysis, design the standards for time expression annotation, build annotated corpora for time expressions, and develop methods to identify time expressions from free text. While there are some surveys concerned with the development of time information extraction, retrieval, and reasoning, to the best of our knowledge, there is no survey focusing on the TERN development. We fill in this blank. In this survey, we review previous researches, aiming to draw an overview of the development of time expression analysis and discuss the role that time expressions play in different areas. We focus on the task of recognizing and normalizing time expressions from free text and investigate three kinds of methods that researchers develop for TERN, namely rule-based methods, traditional machine-learning methods, and deep-learning methods. We will also discuss some factors about TERN development, including TIMEX type factor, language factor, and domain and textual factors. After that, we list some useful datasets and softwares for both tasks of TER and TEN as well as TERN and finally outline some potential directions of future research. We hope that this survey can help those researchers who are interested in TERN quickly gain a comprehensive understanding of the development of TERN and its potential research directions.},
  archive      = {J_AIR},
  author       = {Zhong, Xiaoshi and Cambria, Erik},
  doi          = {10.1007/s10462-023-10400-y},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {9115-9140},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Time expression recognition and normalization: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Navigating with chemometrics and machine learning in
chemistry. <em>AIR</em>, <em>56</em>(9), 9089–9114. (<a
href="https://doi.org/10.1007/s10462-023-10391-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chemometrics and machine learning are artificial intelligence-based methods stirring a transformative change in chemistry. Organic synthesis, drug discovery and analytical techniques are incorporating machine learning techniques at an accelerated pace. However, machine-assisted chemistry faces challenges while solving critical problems in chemistry due to complex relationships in data sets. Even with increasing publishing volumes on machine learning, its application in areas of chemistry is not a straightforward endeavour. A particular concern in applying machine learning in chemistry is data availability and reproducibility. The present review article discusses the various chemometric methods, expert systems, and machine learning techniques developed for solving problems of organic synthesis and drug discovery with selected examples. Further, a concise discussion on chemometrics and ML deployed in analytical techniques such as, spectroscopy, microscopy and chromatography are presented. Finally, the review reflects the challenges, opportunities and future perspectives on machine learning and automation in chemistry. The review concludes by pondering on some tough questions on applying machine learning and their possibility of navigation in the different terrains of chemistry.},
  archive      = {J_AIR},
  author       = {Joshi, Payal B.},
  doi          = {10.1007/s10462-023-10391-w},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {9089-9114},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Navigating with chemometrics and machine learning in chemistry},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gaussian bare-bone slime mould algorithm: Performance
optimization and case studies on truss structures. <em>AIR</em>,
<em>56</em>(9), 9051–9087. (<a
href="https://doi.org/10.1007/s10462-022-10370-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The slime mould algorithm (SMA) is a new meta-heuristic algorithm recently proposed. The algorithm is inspired by the foraging behavior of polycephalus slime moulds. It simulates the behavior and morphological changes of slime moulds during foraging through adaptive weights. Although the original SMA&#39;s performance is better than most swarm intelligence algorithms, it still has shortcomings, such as quickly falling into local optimal values and insufficient exploitation. This paper proposes a Gaussian barebone mutation enhanced SMA (GBSMA) to alleviate the original SMA’s shortcomings. First of all, the Gaussian function in the Gaussian barebone accelerates the convergence while also expanding the search space, which improves the algorithm exploration and exploitation capabilities. Secondly, the differential evolution (DE) update strategy in the Gaussian barebone, using $$\mathrm{rand}$$ as the guiding vector. It also enhances the algorithm’s global search performance to a certain extent. Also, the greedy selection is introduced on this basis, which prevents individuals from performing invalid position updates. In the IEEE CEC2017 test function, the proposed GBSMA is compared with a variety of meta-heuristic algorithms to verify the performance of GBSMA. Besides, GBSMA is applied to solve truss structure optimization problems. Experimental results show that the convergence speed and solution accuracy of the proposed GBSMA are significantly better than the original SMA and other similar products.},
  archive      = {J_AIR},
  author       = {Wu, Shubiao and Heidari, Ali Asghar and Zhang, Siyang and Kuang, Fangjun and Chen, Huiling},
  doi          = {10.1007/s10462-022-10370-7},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {9051-9087},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Gaussian bare-bone slime mould algorithm: Performance optimization and case studies on truss structures},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Logic programming for deliberative robotic task planning.
<em>AIR</em>, <em>56</em>(9), 9011–9049. (<a
href="https://doi.org/10.1007/s10462-022-10389-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last decade, the use of robots in production and daily life has increased. With increasingly complex tasks and interaction in different environments including humans, robots are required a higher level of autonomy for efficient deliberation. Task planning is a key element of deliberation. It combines elementary operations into a structured plan to satisfy a prescribed goal, given specifications on the robot and the environment. In this manuscript, we present a survey on recent advances in the application of logic programming to the problem of task planning. Logic programming offers several advantages compared to other approaches, including greater expressivity and interpretability which may aid in the development of safe and reliable robots. We analyze different planners and their suitability for specific robotic applications, based on expressivity in domain representation, computational efficiency and software implementation. In this way, we support the robotic designer in choosing the best tool for his application.},
  archive      = {J_AIR},
  author       = {Meli, Daniele and Nakawala, Hirenkumar and Fiorini, Paolo},
  doi          = {10.1007/s10462-022-10389-w},
  journal      = {Artificial Intelligence Review},
  number       = {9},
  pages        = {9011-9049},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Logic programming for deliberative robotic task planning},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Correction to: Deep learning on multi-view sequential data:
A survey. <em>AIR</em>, <em>56</em>(8), 9009. (<a
href="https://doi.org/10.1007/s10462-022-10367-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIR},
  author       = {Xie, Zhuyang and Yang, Yan and Zhang, Yiling and Wang, Jie and Du, Shengdong},
  doi          = {10.1007/s10462-022-10367-2},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {9009},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Correction to: deep learning on multi-view sequential data: a survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalized q-rung orthopair fuzzy interactive hamacher
power average and heronian means for MADM. <em>AIR</em>, <em>56</em>(8),
8955–9008. (<a
href="https://doi.org/10.1007/s10462-022-10376-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we establish a novel q-rung orthopair fuzzy (q-ROF) multi-attribute decision making (MADM) model on the basis of the proposed q-ROF interactive Hamacher weighted adjustable power average (q-ROFIHWAPA) and q-ROF interactive Hamacher weighted coordinated Heronian means (HMs), which (1) can reflect the correlations among multiple attributes; (2) weakens the impacts of the extreme evaluation values more reasonably; (3) considers the interactions between the membership degree (MD) and non-membership degree (N-MD) of different q-ROF numbers (q-ROFNs); (4) has the characteristic of generality (It can generate different methods by different operations). Firstly, the q-ROF interactive Hamacher operations, improved score function and new q-ROF entropy (q-ROFE) formula, which are the necessary raw materials for the implementation of MADM, are presented. Secondly, we introduce the adjustable power average (APA) and its weight form (WAPA) to remedy the deficiencies of the classical power averages (PAs). Afterwards we extend the WAPA to q-ROF circumstance and propose the q-ROF interactive Hamacher WAPA (q-ROFIHWAPA), and its basic properties are analyzed. Further, the entropy weight fitting method is presented to determine the parameter carried by the q-ROFIHWAPA. Thirdly, inspired by the evolutionary process of Bonferroni means (BMs), we define the weighted coordinated HM (WCHM) and weighted geometric coordinated HM (WGCHM) based on the traditional HMs, respectively, which eliminate the redundancy of the dual generalized weighted BM (DGWBM) and dual generalized weighted Bonferroni geometric mean (DGWBGM), i.e., the case of $$\tau_{1} &gt; \tau_{2} &gt; \cdots &gt; \tau_{n} .$$ Then we develop the q-ROF interactive Hamacher WCHM (q-ROFIHWCHM) and q-ROF interactive Hamacher WGCHM (q-ROFIHWGCHM) by combining them with the q-ROF interactive Hamacher operations, and the common properties and special cases are also investigated. Finally, we create a MADM algorithm relied on the q-ROFIHWAPA and q-ROFIHWCHM (resp. q-ROFIHWGCHM), and a practical example is introduced to illustrate the effectiveness and superiority of the proposed method.},
  archive      = {J_AIR},
  author       = {Li, Jinjun and Chen, Minghao and Pei, Shibing},
  doi          = {10.1007/s10462-022-10376-1},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {8955-9008},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Generalized q-rung orthopair fuzzy interactive hamacher power average and heronian means for MADM},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning pipelines for recognition of gait biometrics
with covariates: A comprehensive review. <em>AIR</em>, <em>56</em>(8),
8889–8953. (<a
href="https://doi.org/10.1007/s10462-022-10365-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a comprehensive exposition of deep learning architectures and pipelines for biometric applications using complex characteristics of human gait. The variety and complexity that we have come across encompass the majority of deep learning techniques. Recognizing humans by their walking patterns is a complicated biometric processing approach that identifies people without intervention and works well even with low-resolution images. Several covariates, such as footwear, heavy clothing and carry situations, view angle, occlusion, speed transition, and others, can affect the gait recognition rate. We provide an extensive literature review focusing on the performance of deep learning models in covariate conditions. It shall help researchers to understand specific aspects of deep learning pipelines in gait recognition. The discussion is done on data acquisition, input, dataset, preprocessing, feature extraction, transformation, activation function, classification and training parameters. We also demonstrate the most often used strategies for each parameter over the previous five years. The datasets used so far are compared with the accuracy achieved for each covariate condition. Finally, we listed the benefits and drawbacks of deep learning approaches in covariate conditions along with open problems in the identification based on behavioral traits and concluded the paper by highlighting important lessons.},
  archive      = {J_AIR},
  author       = {Parashar, Anubha and Parashar, Apoorva and Ding, Weiping and Shekhawat, Rajveer S. and Rida, Imad},
  doi          = {10.1007/s10462-022-10365-4},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {8889-8953},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep learning pipelines for recognition of gait biometrics with covariates: A comprehensive review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design and development of counting-based visual question
answering model using heuristic-based feature selection with deep
learning. <em>AIR</em>, <em>56</em>(8), 8859–8888. (<a
href="https://doi.org/10.1007/s10462-022-10385-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Question Answering (VQA) is the most significant area that adopts both computer vision techniques and natural language processing techniques. Among all the question types, the most challenging question type is said to be counting, such as “How many?” Still, VQA models consist of certain difficulties in counting the objects that are present in the natural images. The basic technique in the VQA involved either classifying answers according to a definite-length description of both the question and image or estimating summing fractional counts from every image segment. Soft attention in these methods is utilized to find these primary issues. To circumvent this problem, the main intention of this paper is to implement the latest visual question-answering system based on a counting scenario. At first, the standard benchmark datasets related to the visual question-answering system are gathered. This question-answering system dataset is usually incorporated with both images and questions. Hence, feature extraction is adopted for both questions and images. For the questions, the text pre-processing is initially employed by punctuation removal, stemming, and stop word removal and the word2vec features are extracted. Similarly, the deep features of the given images are extracted from the pooling layer of the Deep Convolutional Neural Network (DCNN). These two sets of features are integrated and are fed to the selection of optimal feature procedures for acquiring the most significant features that are giving unique information. The selection of optimal features is handled by the Optimized Deep Neural-Long Short-Term Memory (DN-LSTM). It needs less time and computational complexity and also can be applied to solving all engineering optimization problems. It also can tackle multilevel thresholding problems. These advantages in the Parameter Improved-Elephant Herding Optimization (PI-EHO) over the conventional optimization algorithms seek more attention for choosing the EHO in the designed method. Finally, the answer generation is done by hybrid deep learning with Long Short Term Memory (LSTM) and Deep Neural Network (DNN), for which the architecture is improvised by the proposed EHO. The given designed method is experimented on the different data sets, yielding promising results when compared to existing methods.},
  archive      = {J_AIR},
  author       = {Welde, Tesfayee Meshu and Liao, Lejian},
  doi          = {10.1007/s10462-022-10385-0},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {8859-8888},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Design and development of counting-based visual question answering model using heuristic-based feature selection with deep learning},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning approach for detecting and combating bring
your own device (BYOD) security threats and attacks: A systematic
mapping review. <em>AIR</em>, <em>56</em>(8), 8815–8858. (<a
href="https://doi.org/10.1007/s10462-022-10382-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bring your own device (BYOD) paradigm that permits employees to come with their own mobile devices to join the organizational network is rapidly changing the organizational operation method by enhancing flexibility, productivity, and efficiency. Despite these benefits, security issues remain a concern in organizational settings. A considerable number of studies have been conducted and published in this domain without a detailed review of the security solution mechanisms. Moreover, some reviews conducted focused more on conventional approaches such as mobile content management, and application content management. Hence, the implementation of security in BYOD using the conventional method is ineffective. Thus, machine learning approaches seem to be the promising approach, which provides a solution to the security problem in the BYOD environment. This study presents a comprehensive systematic mapping review that focused on the application of the machine learning approach for the mitigation of security threats and attacks in the BYOD environment by highlighting the current trends in the existing studies. Five academic databases were searched and a total of 753 of the primary studies published between 2012 and 2021 were initially retrieved. These studies were screened based on their title, abstract and full text to check their eligibility and relevance for the study. However, forty primary studies were included and analyzed in the systematic mapping review (SMR). Based on the analysis and bubble plot mapping, significant research trends were identified on security threats and attacks, machine learning approaches, datasets usage, and evaluation metrics. The SMR result demonstrates the rise in the number of investigations regarding malware and unauthorized access to existing security threats and attacks. The SMR study indicates that supervised learning approaches such as SVM, DT, and RF are the most employed learning model by the previous research. Thus, there is an open research issue in the application of unsupervised learning approaches such as clustering and deep learning approaches. Therefore, the SMR has set the pace for creating new ground research in the machine learning implementation in the BYOD environment, which will offer invaluable insight into the study field, and researchers can employ it to find a research gap in the research domain.},
  archive      = {J_AIR},
  author       = {Eke, Christopher Ifeanyi and Norman, Azah Anir and Mulenga, Mwenge},
  doi          = {10.1007/s10462-022-10382-3},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {8815-8858},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Machine learning approach for detecting and combating bring your own device (BYOD) security threats and attacks: A systematic mapping review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of bayesian network structure learning.
<em>AIR</em>, <em>56</em>(8), 8721–8814. (<a
href="https://doi.org/10.1007/s10462-022-10351-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian Networks (BNs) have become increasingly popular over the last few decades as a tool for reasoning under uncertainty in fields as diverse as medicine, biology, epidemiology, economics and the social sciences. This is especially true in real-world areas where we seek to answer complex questions based on hypothetical evidence to determine actions for intervention. However, determining the graphical structure of a BN remains a major challenge, especially when modelling a problem under causal assumptions. Solutions to this problem include the automated discovery of BN graphs from data, constructing them based on expert knowledge, or a combination of the two. This paper provides a comprehensive review of combinatoric algorithms proposed for learning BN structure from data, describing 74 algorithms including prototypical, well-established and state-of-the-art approaches. The basic approach of each algorithm is described in consistent terms, and the similarities and differences between them highlighted. Methods of evaluating algorithms and their comparative performance are discussed including the consistency of claims made in the literature. Approaches for dealing with data noise in real-world datasets and incorporating expert knowledge into the learning process are also covered.},
  archive      = {J_AIR},
  author       = {Kitson, Neville Kenneth and Constantinou, Anthony C. and Guo, Zhigao and Liu, Yang and Chobtham, Kiattikun},
  doi          = {10.1007/s10462-022-10351-w},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {8721-8814},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of bayesian network structure learning},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). H3O-LGBM: Hybrid harris hawk optimization based light
gradient boosting machine model for real-time trading. <em>AIR</em>,
<em>56</em>(8), 8697–8720. (<a
href="https://doi.org/10.1007/s10462-022-10323-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The gross domestic product (GDP) of a country is mainly dependent on its trade and external sector which improves the country&#39;s income. According to FY2021–2022, India&#39;s nominal GDP is estimated to be 3.12 trillion US dollars. Overall exports and imports have a year-over-year increase of 49.6\% and 68\% respectively. Machine learning techniques have the potential to improve India&#39;s Current gross value by up to 15\% by the year 2035. The integration of data, Technology, and talent helps to create intelligent models that enhance artificial intelligence growth. This paper presents an optimized light gradient boosting machine (Light GBM) model using the hybrid Harris hawk optimization (H3O) algorithm for trade forecasting. The overfitting problem in the conventional Harris Hawk Optimization is overcome using the exclusive feature bundling (EFB) and the gradient-based one-side sampling (GOSS) methodologies. The H3O optimization algorithm offers fast convergence by optimizing different lightGBM parameters such as a number of training iterations, maximum depth, minimal data in the leaf, etc. To improve the performance, one step further, the residual errors of the optimized lightGBM model are corrected using the Markov Chain model. The main aim of the optimized lightGBM model is to extract the crucial input values of certain variables such as imports and exports of goods and services, service trade, and merchandise trade and predict the price movement decision. The proposed model identifies the interrelationship with the external market and future market growth along with analyzing the variation in market conditions. The prediction decision is mainly to hold, but, or sell the stocks. When evaluated using the precious metal price forecast and stock market datasets, the proposed methodology shows that the hybrid approach can enhance the prediction performance. The results show that the input parameters were efficient in predicting the economic growth regarding the Intermarket trading system (ITS) and services with higher accuracy.},
  archive      = {J_AIR},
  author       = {Gupta, Vaishali and Kumar, Ela},
  doi          = {10.1007/s10462-022-10323-0},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {8697-8720},
  shortjournal = {Artif. Intell. Rev.},
  title        = {H3O-LGBM: Hybrid harris hawk optimization based light gradient boosting machine model for real-time trading},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Biometrics recognition using deep learning: A survey.
<em>AIR</em>, <em>56</em>(8), 8647–8695. (<a
href="https://doi.org/10.1007/s10462-022-10237-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past few years, deep learning-based models have been very successful in achieving state-of-the-art results in many tasks in computer vision, speech recognition, and natural language processing. These models seem to be a natural fit for handling the ever-increasing scale of biometric recognition problems, from cellphone authentication to airport security systems. Deep learning-based models have increasingly been leveraged to improve the accuracy of different biometric recognition systems in recent years. In this work, we provide a comprehensive survey of more than 150 promising works on biometric recognition (including face, fingerprint, iris, palmprint, ear, voice, signature, and gait recognition), which deploy deep learning models, and show their strengths and potentials in different applications. For each biometric, we first introduce the available datasets that are widely used in the literature and their characteristics. We will then talk about several promising deep learning works developed for that biometric, and show their performance on popular public benchmarks. We will also discuss some of the main challenges while using these models for biometric recognition, and possible future directions to which research in this area is headed.},
  archive      = {J_AIR},
  author       = {Minaee, Shervin and Abdolrashidi, Amirali and Su, Hang and Bennamoun, Mohammed and Zhang, David},
  doi          = {10.1007/s10462-022-10237-x},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {8647-8695},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Biometrics recognition using deep learning: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Novel consensus-reaching model in the social network
environment for large-group emergency decision-making: An approach to
managing non-cooperative behaviors. <em>AIR</em>, <em>56</em>(8),
8609–8645. (<a
href="https://doi.org/10.1007/s10462-022-10384-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the complexity and uncertainty of emergency decision-making for satellite emergency observation schemes, it often involves the participation of multiple decision makers (DMs), which results in difficulties with the implementation of large-group emergency decision-making (LGEDM). Meanwhile, LGEDM requires a high-quality emergency scheme within a limited period of time and thus rational treatment of non-cooperative behaviors is crucial to guarantee the performance and timeliness of the consensus-reaching process (CRP). To this end, this study proposes a novel consensus-reaching model in the social network environment for LGEDM, which aims at addressing non-cooperative behaviors. Firstly, we combine social network analysis and the modularity-based Louvain clustering algorithm to cluster DMs and reduce the complexity of LGEDM. Subsequently, we present a hierarchical feedback adjustment mechanism, where non-cooperative clusters and DMs undergo opinion adjustment without changing the clustering structure. In this way, a non-cooperative behavior management mechanism in CRP is established, which is capable of handling six different types of non-cooperative behaviors. Finally, a case study verifies the feasibility of the proposed model, and a comparative analysis illustrates the superiority of the model in clustering and managing non-cooperative behaviors in LGEDM.},
  archive      = {J_AIR},
  author       = {Yan, Bing and Wang, Yanjun and Xia, Wei and Hu, Xiaoxuan},
  doi          = {10.1007/s10462-022-10384-1},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {8609-8645},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Novel consensus-reaching model in the social network environment for large-group emergency decision-making: An approach to managing non-cooperative behaviors},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Low-carbon cities comprehensive evaluation method based on
fermatean fuzzy hybrid distance measure and TOPSIS. <em>AIR</em>,
<em>56</em>(8), 8591–8607. (<a
href="https://doi.org/10.1007/s10462-022-10387-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-carbon city (LCC) quality evaluation is getting increasingly attention in recent years. However, uncertainty decision-making processes and complicated indicators in LCC development have brought challenges to the evaluation, making it more difficult to reach a consensus during assessment. To address these issues, this study develops a novel comprehensive framework based technique for order of preference by similarity to ideal solution (TOPSIS) and Fermatean fuzzy hybrid weighted distance measure for LCC quality. Firstly, a new Fermatean fuzzy (FF) distance measure from hybrid weighted perspective, named as FF hybrid weighted distance (FFHWD) measured is proposed, and some of its merits and mathematical characteristics are also explored. An FFHWD–TOPSIS comprehensive evaluation framework is then presented, wherein the entropy model and best–worst method (BWM) are utilized to derive the weights of different indicators. In addition, based on the established LCC quality evaluation index system, the proposed FFHWD-TOPSIS approach is used to measure the level of development of LCC in five Chinese cities. Finally, a sensitivity and comparative analysis of the proposed framework are carried out in detail. This study not only contributes to enriching the evaluation index system for LCC development, but also to presenting researchers with a reference for scientific evaluation approach.},
  archive      = {J_AIR},
  author       = {Zeng, Shouzhen and Gu, Jiaxing and Peng, Xindong},
  doi          = {10.1007/s10462-022-10387-y},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {8591-8607},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Low-carbon cities comprehensive evaluation method based on fermatean fuzzy hybrid distance measure and TOPSIS},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on artificial intelligence techniques for security
event correlation: Models, challenges, and opportunities. <em>AIR</em>,
<em>56</em>(8), 8547–8590. (<a
href="https://doi.org/10.1007/s10462-022-10381-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information systems need to process a large amount of event monitoring data. The process of finding the relationships between events is called correlation, which creates a context between independent events and previously collected information in real time and normalizes it for subsequent processing. In cybersecurity, events can determine the steps of attackers and can be analyzed as part of a specific attack strategy. In this survey, we present the systematization of security event correlation models in terms of their representation in AI-based monitoring systems as: rule-based, semantic, graphical and machine learning based-models. We define the main directions of current research in the field of AI-based security event correlation and the methods used for the correlation of both single events and their sequences in attack scenarios. We also describe the prospects for the development of hybrid correlation models. In conclusion, we identify the existing problems in the field and possible ways to overcome them.},
  archive      = {J_AIR},
  author       = {Levshun, Diana and Kotenko, Igor},
  doi          = {10.1007/s10462-022-10381-4},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {8547-8590},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey on artificial intelligence techniques for security event correlation: Models, challenges, and opportunities},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Uncertain random portfolio optimization with non-dominated
sorting genetic algorithm-II and optimal solution criterion.
<em>AIR</em>, <em>56</em>(8), 8511–8546. (<a
href="https://doi.org/10.1007/s10462-022-10388-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complexity of the financial systems inevitably leads to the uncertain information and random information simultaneously. Because asset returns frequently show excessive kurtosis and tend to be skewed, we consider an uncertain random higher moments portfolio optimization problem in this paper, in which uncertain and random return rates exist simultaneously. First, the concept of kurtosis for uncertain random variable is defined and the deterministic expressions of kurtosis under three kinds of distributions are derived. Then, an uncertain random mean-variance-skewness-kurtosis-entropy model is formulated with two auxiliary models for portfolio optimization problem. After solving the equivalent deterministic model with NSGA-II algorithm, we propose a new optimal solution criterion for finding a single optimal solution in Pareto optimal solution set. Finally, we present a numerical simulation and obtain the following results: (i) the practicability and the validity of the proposed model, the NSGA-II algorithm and the optimal selection criterion have verified; (ii) the size of population has an obvious influence on the single optimal solution; (iii) the parameter adjustment has a significant impact on the results, and the results are in perfect agreement with the actual situation.},
  archive      = {J_AIR},
  author       = {Li, Xiangfa and Li, Bo and Jin, Ting and Zheng, Peiyao},
  doi          = {10.1007/s10462-022-10388-x},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {8511-8546},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Uncertain random portfolio optimization with non-dominated sorting genetic algorithm-II and optimal solution criterion},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Survey on sentiment analysis: Evolution of research methods
and topics. <em>AIR</em>, <em>56</em>(8), 8469–8510. (<a
href="https://doi.org/10.1007/s10462-022-10386-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis, one of the research hotspots in the natural language processing field, has attracted the attention of researchers, and research papers on the field are increasingly published. Many literature reviews on sentiment analysis involving techniques, methods, and applications have been produced using different survey methodologies and tools, but there has not been a survey dedicated to the evolution of research methods and topics of sentiment analysis. There have also been few survey works leveraging keyword co-occurrence on sentiment analysis. Therefore, this study presents a survey of sentiment analysis focusing on the evolution of research methods and topics. It incorporates keyword co-occurrence analysis with a community detection algorithm. This survey not only compares and analyzes the connections between research methods and topics over the past two decades but also uncovers the hotspots and trends over time, thus providing guidance for researchers. Furthermore, this paper presents broad practical insights into the methods and topics of sentiment analysis, while also identifying technical directions, limitations, and future work.},
  archive      = {J_AIR},
  author       = {Cui, Jingfeng and Wang, Zhaoxia and Ho, Seng-Beng and Cambria, Erik},
  doi          = {10.1007/s10462-022-10386-z},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {8469-8510},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Survey on sentiment analysis: Evolution of research methods and topics},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An EnGRFA control scheme based power system stabilizers
(PSS) for the stability analysis with wind energy integration.
<em>AIR</em>, <em>56</em>(8), 8437–8468. (<a
href="https://doi.org/10.1007/s10462-022-10368-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper presented a control scheme for optimization and adjustment of the parameters of the electrical system stabilizer for the stability analysis of integrated electrical network of wind energy. The proposed control system is the Garra Rufa fish optimization (GRFA) and artificial transgender longicorn algorithm (ATLA) called enhanced GRFA (EnGRFA). In the proposed control scheme, considering the minimum error objective function, the ATLA algorithm is used to improve the GRFA search process, which is why it is called the EnGRFA control scheme. The main idea of installing a power system stabilizer (PSS) is to give additional damping of synchronous motor for suppressing system oscillations by using an auxiliary stabilization signal to control the excitation of synchronous motor. The equivalent wind turbine generator parameters are optimized to use the EnGRFA control scheme to produce the smallest deviation from the detailed system response. To use eigenvalue analysis to adjust the controller parameters, the objective function is assessed against two sub-objective functions (SOF). The task of the first SOF is to minimize the real part of Eigen values, and second SOF objective is to exploit that damping ratio. Using this proposed control scheme, uncertainties and unbalance issues can be found accurately and quickly to eliminate stability issues under power system. The EnGRFA control scheme is employed to study that eigenvalue analysis of dynamic behavior of the integrated wind energy system under different natural frequencies. The proposed control scheme is accomplished on MATLAB/Simulink platform and its performance is estimated and compared with the existing techniques.},
  archive      = {J_AIR},
  author       = {Penchalaiah, G. and Ramya, R.},
  doi          = {10.1007/s10462-022-10368-1},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {8437-8468},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An EnGRFA control scheme based power system stabilizers (PSS) for the stability analysis with wind energy integration},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on narrative extraction from textual data.
<em>AIR</em>, <em>56</em>(8), 8393–8435. (<a
href="https://doi.org/10.1007/s10462-022-10338-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Narratives are present in many forms of human expression and can be understood as a fundamental way of communication between people. Computational understanding of the underlying story of a narrative, however, may be a rather complex task for both linguists and computational linguistics. Such task can be approached using natural language processing techniques to automatically extract narratives from texts. In this paper, we present an in depth survey of narrative extraction from text, providing a establishing a basis/framework for the study roadmap to the study of this area as a whole as a means to consolidate a view on this line of research. We aim to fulfill the current gap by identifying important research efforts at the crossroad between linguists and computer scientists. In particular, we highlight the importance and complexity of the annotation process, as a crucial step for the training stage. Next, we detail methods and approaches regarding the identification and extraction of narrative components, their linkage and understanding of likely inherent relationships, before detailing formal narrative representation structures as an intermediate step for visualization and data exploration purposes. We then move into the narrative evaluation task aspects, and conclude this survey by highlighting important open issues under the domain of narratives extraction from texts that are yet to be explored.},
  archive      = {J_AIR},
  author       = {Santana, Brenda and Campos, Ricardo and Amorim, Evelin and Jorge, Alípio and Silvano, Purificação and Nunes, Sérgio},
  doi          = {10.1007/s10462-022-10338-7},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {8393-8435},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey on narrative extraction from textual data},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An innovative time-varying particle swarm-based salp
algorithm for intrusion detection system and large-scale global
optimization problems. <em>AIR</em>, <em>56</em>(8), 8325–8392. (<a
href="https://doi.org/10.1007/s10462-022-10322-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle swarm optimization (PSO) suffers from delayed convergence and stagnation in the local optimal solution, as do most meta-heuristic algorithms. This study proposes a time-based leadership particle swarm-based Salp (TPSOSA) to address the PSO&#39;s limitations. The TPSOSA is a novel search technique that addresses population diversity, an imbalance between exploitation and exploration, and the premature convergence of the PSO algorithm. Hybridization in TPSOSA is divided into two stages: The PSO hierarchy of leaders and followers is first represented as a time-varying dynamic structure. Because we need much exploration at the beginning and many exploitative steps at the end, this method raises the number of leaders while decreasing the number of follower particles linearly. In the time-varying form of the PSO (TPSOSA), unlike the PSO, the number of leaders and followers changes over time. PSO&#39;s robust search strategy is used to update the leaders&#39; positions. Second, the SSA&#39;s powerful exploitation is utilized to update the followers&#39; swarm population position. The purpose of tweaking the particle swarm optimizer algorithm is to aid the fundamental method in avoiding premature convergence and quickly directing the search to the most promising likely search space. The proposed TPSOSA method is tested using the CEC 2017 benchmark, seven CEC2008lsgo test functions with 200, 500, and 1000 decision variables, and 19 datasets (including three high-dimensional datasets and the NSL-KDD Dataset for Intrusion Detection System). In each experiment, TPSOSA is compared to various state-of-the-art metaheuristics methods. Friedman and Wilcoxon rank-sum statistical tests are also used to analyze the data. Experimental data and statistical tests show that the TPSOSA algorithm is very competitive and often superior to the algorithms used in the studies. According to the results, TPSOSA can also find an optimal feature subset that enhances classification accuracy while reducing the number of features employed.},
  archive      = {J_AIR},
  author       = {Qaraad, Mohammed and Amjad, Souad and Hussein, Nazar K. and Mirjalili, Seyedali and Elhosseini, Mostafa A.},
  doi          = {10.1007/s10462-022-10322-1},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {8325-8392},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An innovative time-varying particle swarm-based salp algorithm for intrusion detection system and large-scale global optimization problems},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpretable decision trees through MaxSAT. <em>AIR</em>,
<em>56</em>(8), 8303–8323. (<a
href="https://doi.org/10.1007/s10462-022-10377-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an approach to improve the accuracy-interpretability trade-off of Machine Learning (ML) Decision Trees (DTs). In particular, we apply Maximum Satisfiability technology to compute Minimum Pure DTs (MPDTs). We improve the runtime of previous approaches and, show that these MPDTs can outperform the accuracy of DTs generated with the ML framework sklearn.},
  archive      = {J_AIR},
  author       = {Alòs, Josep and Ansótegui, Carlos and Torres, Eduard},
  doi          = {10.1007/s10462-022-10377-0},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {8303-8323},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Interpretable decision trees through MaxSAT},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The goat search algorithms. <em>AIR</em>, <em>56</em>(8),
8265–8301. (<a
href="https://doi.org/10.1007/s10462-022-10341-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article develops an evolutionary nature inspired algorithm based on the social behavior of the goat, a pet of a farmer in a village life. In village life, we generally see the shepherds keep their goats free/untie from collar thread for grazing in the early morning and receives them at the end of the day when they come back into the home with their own efforts. But some day the goats did not come back in due time because of overfeeding of grass causing unable to move any more after meeting their grasp and began to get rest there. The shepherd feels more tempted and began to search for his/her goat. After untie, the goat began to graze herself through the walk on the path of the cultivated land and bank of the village ponds. The search process is going on through that path until it is not finally got. To characterize this problem some definitions like false walk, uniform and non-uniform steps, goat’s jump, periodic walk and goodness of fit for various walk functions have been discussed here rigorously. Inspiring from this fact novel metaheuristic algorithms along with pseudocode and hardware specification have been discussed to optimize a benchmark multi-modal objective function having some singularity zones explicitly. Numerical results have been compared with some of the existing state- of -arts under 95\% confidence intervals. Also, graphical illustrations are performed to validate the proposed approach. Finally, a conclusion is made followed by scope of future work.},
  archive      = {J_AIR},
  author       = {De, Sujit Kumar},
  doi          = {10.1007/s10462-022-10341-y},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {8265-8301},
  shortjournal = {Artif. Intell. Rev.},
  title        = {The goat search algorithms},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comprehensive survey on hierarchical clustering algorithms
and the recent developments. <em>AIR</em>, <em>56</em>(8), 8219–8264.
(<a href="https://doi.org/10.1007/s10462-022-10366-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data clustering is a commonly used data processing technique in many fields, which divides objects into different clusters in terms of some similarity measure between data points. Comparing to partitioning clustering methods which give a flat partition of the data, hierarchical clustering methods can give multiple consistent partitions of the data at different levels for the same data without rerunning clustering, it can be used to better analyze the complex structure of the data. There are usually two kinds of hierarchical clustering methods: divisive and agglomerative. For the divisive clustering, the key issue is how to select a cluster for the next splitting procedure according to dissimilarity and how to divide the selected cluster. For agglomerative hierarchical clustering, the key issue is the similarity measure that is used to select the two most similar clusters for the next merge. Although both types of the methods produce the dendrogram of the data as output, the clustering results may be very different depending on the dissimilarity or similarity measure used in the clustering, and different types of methods should be selected according to different types of the data and different application scenarios. So, we have reviewed various hierarchical clustering methods comprehensively, especially the most recently developed methods, in this work. The similarity measure plays a crucial role during hierarchical clustering process, we have reviewed different types of the similarity measure along with the hierarchical clustering. More specifically, different types of hierarchical clustering methods are comprehensively reviewed from six aspects, and their advantages and drawbacks are analyzed. The application of some methods in real life is also discussed. Furthermore, we have also included some recent works in combining deep learning techniques and hierarchical clustering, which is worth serious attention and may improve the hierarchical clustering significantly in the future.},
  archive      = {J_AIR},
  author       = {Ran, Xingcheng and Xi, Yue and Lu, Yonggang and Wang, Xiangwen and Lu, Zhenyu},
  doi          = {10.1007/s10462-022-10366-3},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {8219-8264},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Comprehensive survey on hierarchical clustering algorithms and the recent developments},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Huber loss based distributed robust learning algorithm for
random vector functional-link network. <em>AIR</em>, <em>56</em>(8),
8197–8218. (<a
href="https://doi.org/10.1007/s10462-022-10362-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose two algorithms based on the random vector functional link network (RVFLN) and alternating direction method of multipliers algorithm to solve distributed learning (DL) problems with datasets containing outliers. In distributed scenarios, training datasets are separately divided and stored on each node of the communication network and cannot be shared or collected over the communication network due to privacy-preserving policy and network environmental restrictions. Thus, each node of the communication network only deals with local data and shares updated output weights of the global RVFLN model with its neighbors. However, the majority of existing DL algorithms are not robust enough when the dataset contain outliers. To overcome the this drawback, we intend to apply the $$L_1$$ norm and Huber based error terms to the global loss function and propose the corresponding distributed robust learning algorithms and denote them as the L1-DRVFL and Huber-DRVFL algorithms, respectively. The proposed algorithms work in fully distributed manner and are privacy-preserving methods. Experiments show that the proposed algorithms are robust and efficient in distributed learning with data including outliers. Moreover, the Huber-DRVFL algorithm is more stable than the L1-DRVFL algorithm when the parameters vary.},
  archive      = {J_AIR},
  author       = {Xie, Jin and Liu, Sanyang and Chen, Jiaxi and Jia, Jinping},
  doi          = {10.1007/s10462-022-10362-7},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {8197-8218},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Huber loss based distributed robust learning algorithm for random vector functional-link network},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning and deep learning for blood pressure
prediction: A methodological review from multiple perspectives.
<em>AIR</em>, <em>56</em>(8), 8095–8196. (<a
href="https://doi.org/10.1007/s10462-022-10353-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blood pressure (BP) estimation is one of the most popular and long-standing topics in health-care monitoring area. The utilization of machine learning (ML) and deep learning (DL) for BP prediction has made remarkable progress recently along with the development of ML and especially DL technologies, and the release of large-scale available datasets. In this survey, we present a comprehensive, systematic review about the recent advance of ML and DL for BP prediction. To start with, we systematically sort out the current progress from four perspectives. Then, we summarized commonly-used datasets, evaluation metrics as well as evaluation procedures (especially the usually ignored splitting strategy operation), which is followed by a critical analysis about the reported results. Next, we discussed several practical issues as well as newly-emerging techniques appeared in the research community of BP prediction. Also, we introduced the potential application of several advanced ML technologies in BP estimation. Last, we discussed the question of what a good BP estimator should look like?, and then a general proposal for an objective evaluation of model performance is given from the perspective of an ML researcher. Through this survey, we wish to provide a comprehensive, systematic, up-to-date (to Feb, 2022) review of related research on BP prediction using ML &amp; DL methods, which may be helpful to researchers in this area. We also appeal an objective view of the progress reported in the relevant literatures in a more systematic manner. The experimental data &amp; code and other useful resources are available at https://github.com/v3551G/BP-prediction-survey .},
  archive      = {J_AIR},
  author       = {Qin, Keke and Huang, Wu and Zhang, Tao and Tang, Shiqi},
  doi          = {10.1007/s10462-022-10353-8},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {8095-8196},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Machine learning and deep learning for blood pressure prediction: A methodological review from multiple perspectives},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on multi-objective hyperparameter optimization
algorithms for machine learning. <em>AIR</em>, <em>56</em>(8),
8043–8093. (<a
href="https://doi.org/10.1007/s10462-022-10359-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperparameter optimization (HPO) is a necessary step to ensure the best possible performance of Machine Learning (ML) algorithms. Several methods have been developed to perform HPO; most of these are focused on optimizing one performance measure (usually an error-based measure), and the literature on such single-objective HPO problems is vast. Recently, though, algorithms have appeared that focus on optimizing multiple conflicting objectives simultaneously. This article presents a systematic survey of the literature published between 2014 and 2020 on multi-objective HPO algorithms, distinguishing between metaheuristic-based algorithms, metamodel-based algorithms and approaches using a mixture of both. We also discuss the quality metrics used to compare multi-objective HPO procedures and present future research directions.},
  archive      = {J_AIR},
  author       = {Morales-Hernández, Alejandro and Van Nieuwenhuyse, Inneke and Rojas Gonzalez, Sebastian},
  doi          = {10.1007/s10462-022-10359-2},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {8043-8093},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey on multi-objective hyperparameter optimization algorithms for machine learning},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Heterogeneous graph neural networks analysis: A survey of
techniques, evaluations and applications. <em>AIR</em>, <em>56</em>(8),
8003–8042. (<a
href="https://doi.org/10.1007/s10462-022-10375-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have achieved excellent performance of graph representation learning and attracted plenty of attentions in recent years. Most of GNNs aim to learn embedding vectors of the homogeneous graph which only contains single type of nodes and edges. However, the entities and their interactions in real world always have multiple types and naturally form the heterogeneous graph with rich structural and semantic information. As a result of this, it is beneficial to advance heterogeneous graph representation learning that can effectively promote the performance of complex network analysis. Existing survey papers of heterogeneous graph representation learning summarize all possible embedding techniques for graphs and make insufficient analysis for deep neural network models. To tackle this issue, in this paper, we systematically summarize and analyze existing heterogeneous graph neural networks (HGNNs) and categorize them based on their neural network architecture. Meanwhile, we collect commonly used heterogeneous graph datasets and summarize their statistical information. In addition, we compare the performances between HGNNs and shallow embedding models to show the powerful feature learning ability of HGNNs. Finally, we conclude the application scenarios of HGNNs and some possible future research directions. We hope that this paper can provide a useful framework for researchers who interested in HGNNs.},
  archive      = {J_AIR},
  author       = {Bing, Rui and Yuan, Guan and Zhu, Mu and Meng, Fanrong and Ma, Huifang and Qiao, Shaojie},
  doi          = {10.1007/s10462-022-10375-2},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {8003-8042},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Heterogeneous graph neural networks analysis: A survey of techniques, evaluations and applications},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weakly-supervised learning method for the recognition of
potato leaf diseases. <em>AIR</em>, <em>56</em>(8), 7985–8002. (<a
href="https://doi.org/10.1007/s10462-022-10374-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a crucial food crop, potatoes are highly consumed worldwide, while they are also susceptible to being infected by diverse diseases. Early detection and diagnosis can prevent the epidemic of plant diseases and raise crop yields. To this end, this study proposed a weakly-supervised learning approach for the identification of potato plant diseases. The foundation network was applied with the lightweight MobileNet V2, and to enhance the learning ability for minute lesion features, we modified the existing MobileNet-V2 architecture using the fine-tuning approach conducted by transfer learning. Then, the atrous convolution along with the SPP module was embedded into the pre-trained networks, which was followed by a hybrid attention mechanism containing channel attention and spatial attention submodules to efficiently extract high-dimensional features of plant disease images. The proposed approach outperformed other compared methods and achieved a superior performance gain. It realized an average recall rate of 91.99\% for recognizing potato disease types on the publicly accessible dataset. In practical field scenarios, the proposed approach separately attained an average accuracy and specificity of 97.33\% and 98.39\% on the locally collected image dataset. Experimental results present a competitive performance and demonstrate the validity and feasibility of the proposed approach.},
  archive      = {J_AIR},
  author       = {Chen, Junde and Deng, Xiaofang and Wen, Yuxin and Chen, Weirong and Zeb, Adnan and Zhang, Defu},
  doi          = {10.1007/s10462-022-10374-3},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {7985-8002},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Weakly-supervised learning method for the recognition of potato leaf diseases},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predicting the compressive strength of eco-friendly and
normal concretes using hybridized fuzzy inference system and particle
swarm optimization algorithm. <em>AIR</em>, <em>56</em>(8), 7965–7984.
(<a href="https://doi.org/10.1007/s10462-022-10373-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of supplementary cementitious materials (SCMs) in the binder system of concrete mixtures can provide several environmental and technical benefits. Several previous studies have focused on evaluating the compressive strength (CS) of concretes containing SCMs using machine learning (ML) techniques. However, there have been a limited number of studies for modeling the CS of concretes using type-2 fuzzy inference system (FIS) in which the uncertainties in measuring the input variables and membership functions can be handled. This study serves the interval type-2 FIS (IT2FIS) to develop predictive models for the CS of concretes containing three types of SCMs, including blast furnace slag, fly ash, and silica fume. Particle swarm optimization (PSO) algorithm was also used to optimize the parameters of the IT2FIS. In addition, type-1 FIS (T1FIS) was served as the control ML technique. The dataset used in this study contains information on the mixture proportion and CS values of 3240 concrete mixtures. A total of 18 FIS models, including 6 T1FISs and 12 IT2FISs were developed. The results showed insignificant differences between the error metrics of the FIS models for the training and testing phases, which indicates the good generalization capabilities of the developed FIS models. To have more insight into the role of input variables on the CS of concrete, the relevancy factor (RF) analysis was carried out for the input variables of the best-developed FIS model. It was found that cement content had the most positive effect on the value of CS.},
  archive      = {J_AIR},
  author       = {Golafshani, Emadaldin Mohammadi and Behnood, Ali and Arashpour, Mehrdad},
  doi          = {10.1007/s10462-022-10373-4},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {7965-7984},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Predicting the compressive strength of eco-friendly and normal concretes using hybridized fuzzy inference system and particle swarm optimization algorithm},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nuclei and glands instance segmentation in histology images:
A narrative review. <em>AIR</em>, <em>56</em>(8), 7909–7964. (<a
href="https://doi.org/10.1007/s10462-022-10372-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Examination of tissue biopsy and quantification of the various characteristics of cellular processes are clinical benchmarks in cancer diagnosis. Nuclei and glands instance segmentation greatly assists the high-throughput quantification of cellular process and accurate appraisal of tissue biopsy. It subsequently makes a significant improvement to the computational pathology process for cancer diagnosis, treatment planning, and survival analysis. Recent advancements in the field of computer vision have automated the manual, laborious, and time-consuming histopathological analysis process. Automated image analysis of histopathological images for cells and tissues to trace the entirety of the ultrastructures, has been an active area of research in medical informatics for decades. The developments in computers, microscopy hardware, and the availability of large-scale public datasets have further fastened the development in this field. And the realization that scientific and diagnostic pathology calls for fresh ways to undertake, automated image analysis of histopathological images has captivated contemporary attention. In this survey, 126 papers illustrating the AI-based methods for nuclei and glands instance segmentation published in the last five years (2017–2022) are deeply analyzed, and the limitations of current approaches and the open challenges are discussed. Moreover, the potential future research direction is presented, and the contribution of state-of-the-art methods is summarized. Further, a generalized summary of publicly available datasets and detailed insights on the grand challenges illustrating the top-performing methods specific to each challenge is also provided. Besides, we intended to give the reader the current state of existing research and pointers to the future directions in developing methods that can be used in clinical practice enabling improved diagnosis, grading, prognosis, and treatment planning of cancer. To the best of our knowledge, no previous work has reviewed the instance segmentation in histology images focusing on nuclei and glands instance segmentation.},
  archive      = {J_AIR},
  author       = {Nasir, Esha Sadia and Parvaiz, Arshi and Fraz, Muhammad Moazam},
  doi          = {10.1007/s10462-022-10372-5},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {7909-7964},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Nuclei and glands instance segmentation in histology images: A narrative review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data quality issues in software fault prediction: A
systematic literature review. <em>AIR</em>, <em>56</em>(8), 7839–7908.
(<a href="https://doi.org/10.1007/s10462-022-10371-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software fault prediction (SFP) aims to improve software quality with a possible minimum cost and time. Various machine learning models have been proposed in the past for predicting software faults. The performance of those models depends on dataset quality and can be enhanced by identifying and eliminating data quality issues. In this paper, we present a systematic literature review on data quality issues existing in SFP datasets. We have selected 145 primary studies published until November 2021 and analyzed them from five perspectives—data quality issue, pre-processing technique, modeling technique, dataset and performance measures used. The findings indicate that data quality issues such as data dimensionality, class imbalance and their combination have been heavily considered in the literature. However, data quality issues such as class overlapping, missing data are pertinent to SFP datasets and need further investigation. The effect of resolving one data quality issue relative to others is an unexplored field. C4.5, naive Bayes, multilayer perceptron, support vector machine, and random forest are the most frequently used classifiers by the researchers. However, researchers should know the sensitiveness of those classifiers corresponding to a particular data quality issue and select them accordingly. The PROMISE datasets have been extensively used in SFP. Accuracy, precision, recall and area under curve are the common performance measures. It is suggested to employ unbiased and stable performance measures such as Mathew Co-relation Coefficient for the model evaluation. Our findings from the survey concluded that the existence of data quality issues in SFP datasets degrades the classifiers’ performance and there is a scope for further research on data quality issues.},
  archive      = {J_AIR},
  author       = {Bhandari, Kirti and Kumar, Kuldeep and Sangal, Amrit Lal},
  doi          = {10.1007/s10462-022-10371-6},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {7839-7908},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Data quality issues in software fault prediction: A systematic literature review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Connectivity indices of m-polar fuzzy network model, with an
application to a product manufacturing problem. <em>AIR</em>,
<em>56</em>(8), 7795–7838. (<a
href="https://doi.org/10.1007/s10462-022-10360-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Connectivity is among the most essential concerns in graph theory and its applications. We consider this issue in a framework that stems from the combination of m-polar fuzzy set theory with graphs. We introduce two measurements of connectedness of m-polar fuzzy graphs that we call their connectivity and average connectivity indices. Examples are given, and the theoretical performance of these concepts is investigated. Particularly, we are concerned with the effect of deleting a vertex or an edge from an m-polar fuzzy graph, on its connectivity and average connectivity indices. We also establish bounding expressions for the connectivity index in complete m-polar fuzzy graphs, complete bipartite m-polar fuzzy graphs, and wheel m-polar fuzzy graphs. Moreover, we introduce some special types of vertices called m-polar fuzzy connectivity reducing vertices, m-polar fuzzy connectivity enhancing vertices, and m-polar fuzzy connectivity neutral vertices. Our theoretical contribution is applied to a product manufacturing problem that takes advantage of multi-polar uncertain information. The justification for our application is systematized using an algorithm. Finally, we compare the proposed method to existing methodologies to demonstrate its feasibility and applicability.},
  archive      = {J_AIR},
  author       = {Akram, Muhammad and Siddique, Saba and Alcantud, José Carlos R.},
  doi          = {10.1007/s10462-022-10360-9},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {7795-7838},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Connectivity indices of m-polar fuzzy network model, with an application to a product manufacturing problem},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Time series forecasting using fuzzy cognitive maps: A
survey. <em>AIR</em>, <em>56</em>(8), 7733–7794. (<a
href="https://doi.org/10.1007/s10462-022-10319-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among various soft computing approaches for time series forecasting, fuzzy cognitive maps (FCMs) have shown remarkable results as a tool to model and analyze the dynamics of complex systems. FCMs have similarities to recurrent neural networks and can be classified as a neuro-fuzzy method. In other words, FCMs are a mixture of fuzzy logic, neural network, and expert system aspects, which act as a powerful tool for simulating and studying the dynamic behavior of complex systems. The most interesting features are knowledge interpretability, dynamic characteristics and learning capability. The goal of this survey paper is mainly to present an overview on the most relevant and recent FCM-based time series forecasting models proposed in the literature. In addition, this article considers an introduction on the fundamentals of FCM model and learning methodologies. Also, this survey provides some ideas for future research to enhance the capabilities of FCM in order to cover some challenges in the real-world experiments such as handling non-stationary data and scalability issues. Moreover, equipping FCMs with fast learning algorithms is one of the major concerns in this area.},
  archive      = {J_AIR},
  author       = {Orang, Omid and de Lima e Silva, Petrônio Cândido and Guimarães, Frederico Gadelha},
  doi          = {10.1007/s10462-022-10319-w},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {7733-7794},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Time series forecasting using fuzzy cognitive maps: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence for template-free protein structure
prediction: A comprehensive review. <em>AIR</em>, <em>56</em>(8),
7665–7732. (<a
href="https://doi.org/10.1007/s10462-022-10350-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein structure prediction (PSP) is a grand challenge in bioinformatics, drug discovery, and related fields. PSP is computationally challenging because of an astronomically large conformational space to be searched and an unknown very complex energy function to be minimised. To obtain a given protein’s structure, template-based PSP approaches adopt a similar protein’s known structure, while template-free PSP approaches work when no similar protein’s structure is known. Currently, proteins with known structures are greatly outnumbered by proteins with unknown structures. Template-free PSP has obtained significant progress recently via machine learning and search-based optimisation approaches. However, very accurate structures for complex proteins are yet to be achieved at a level suitable for effective drug design. Moreover, ab initio prediction of a protein’s structure only from its amino acid sequence remains unsolved. Furthermore, the number of protein sequences with unknown structures is growing rapidly. Hence, to make further progress in PSP, more sophisticated and advanced artificial intelligence (AI) approaches are needed. However, getting involved in PSP research is difficult for AI researchers because of the lack of a comprehensive understanding of the whole problem, along with the background and the literature of all related sub-problems. Unfortunately, existing PSP review papers cover PSP research at a very high level and only some parts of PSP and only from a particular singular viewpoint. Using a systematic approach, this review paper provides a comprehensive survey of the state-of-the-art template-free PSP research to fill this knowledge gap. Moreover, covering required PSP preliminaries and computational formulations, this paper presents PSP research from AI perspectives, discusses the challenges, provides our commentaries, and outlines future research directions.},
  archive      = {J_AIR},
  author       = {Mufassirin, M. M. Mohamed and Newton, M. A. Hakim and Sattar, Abdul},
  doi          = {10.1007/s10462-022-10350-x},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {7665-7732},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Artificial intelligence for template-free protein structure prediction: A comprehensive review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Greedy opposition-based learning for chimp optimization
algorithm. <em>AIR</em>, <em>56</em>(8), 7633–7663. (<a
href="https://doi.org/10.1007/s10462-022-10343-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The chimp optimization algorithm (ChOA) is a hunting-based model and can be utilized as a set of optimization rules to tackle optimization problems. Although ChOA has shown promising results on optimization functions, it suffers from a slow convergence rate and low exploration capability. Therefore, in this paper, a modified ChOA is proposed to improve the exploration and exploitation capabilities of the ChOA. This improvement is performed using greedy search and opposition-based learning (OBL), respectively. In order to investigate the efficiency of the OBLChOA, the OBLChOA’s performance is evaluated by twenty-three standard benchmark functions, ten suit tests of IEEE CEC06-2019, randomly generated landscape, and twelve real-world Constrained Optimization Problems (IEEE COPs-2020) from a variety of engineering fields, including industrial chemical producer, power system, process design and synthesis, mechanical design, power-electronic, and livestock feed ration. The results are compared to benchmark optimizers, including CMA-ES and SHADE as high-performance optimizers and winners of IEEE CEC competition; standard ChOA; OBL-GWO, OBL-SSA, and OBL-CSA as the best benchmark OBL-based algorithms. OBLChOA and CMA-ES rank first and second among twenty-seven numerical test functions, respectively, with forty and eleven best results. In the 100-digit challenge, jDE100 achieves the highest score of 100, followed by DISHchain1e + 12, and OBLChOA achieves the fourth-highest score of 93. In total, eighteen state-of-the-art algorithms achieved the highest score in seven out of ten issues. Finally, OBLChOA and CMA-ES achieve the best performance in five and four real-world engineering challenges, respectively.},
  archive      = {J_AIR},
  author       = {Khishe, Mohammad},
  doi          = {10.1007/s10462-022-10343-w},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {7633-7663},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Greedy opposition-based learning for chimp optimization algorithm},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of the static load test results of bridges based
on the dynamic load test and the kriging model. <em>AIR</em>,
<em>56</em>(8), 7613–7632. (<a
href="https://doi.org/10.1007/s10462-022-10369-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Faced with the structural performance evaluation of a large number of bridges, bridge management and maintenance departments have urgently sought a quick method for evaluating bridge performance. The load test is currently a direct and effective method for assessing the conditions of bridge structures. However, this method is costly, time-consuming, inefficient, requires closed traffic, and can cause damage to the structure itself. In response to this problem, this paper proposes a new low-cost method combined with the Kriging proxy model for fast and accurate prediction of bridge static behavior based on fast bridge dynamic load test data. To verify the correctness and feasibility of the method in this study, a three-span continuous reinforced concrete oblique-leg rigid frame bridge is considered as the engineering application test object. The research results reveal that the finite element model of the bridge can be updated based on the dynamic load test data of the bridge combined with the Kriging proxy model, and the static load test results can be accurately predicted. And the predicted results are consistent with the measured results in the field. The method proposed in this study is not associated with the negative impacts of the bridge static load test and uses more efficient, fast, and accurate means to comprehensively analyze and predict the static behavior of a large number of existing bridges. It could inform approaches for rapid evaluation of the structural performance of existing bridges and the decision-making of reinforcement and maintenance.},
  archive      = {J_AIR},
  author       = {Lu, Pengzhen and Li, Dengguo and Chen, Yangrui},
  doi          = {10.1007/s10462-022-10369-0},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {7613-7632},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Prediction of the static load test results of bridges based on the dynamic load test and the kriging model},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine reading comprehension combined with semantic
dependency for chinese zero pronoun resolution. <em>AIR</em>,
<em>56</em>(8), 7597–7612. (<a
href="https://doi.org/10.1007/s10462-022-10364-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pronoun-drop is a common phenomenon in Chinese, zero pronoun resolution aims to recover the pronoun and resolve the anaphora antecedent of the pronoun, which is important for NLP tasks such as machine translation, information extraction, etc. Most of the existing research methods predefined zero pronoun sets. Zero pronoun recovery is carried out through multi-classification, and then the coreference chains between each pronoun and the candidate antecedent are predicted in turn. However, most of the previous methods only focus on the relationship between pronouns and arguments, ignoring the deep semantic relationship between predicates and arguments as the core semantic component. In addition, the model takes the parse tree (gold tree) as a priori knowledge, which is costly in practical applications. In this paper, we propose a Machine Reading Comprehension model combined with Semantic Dependency (MRC-SD), which takes advantage of the feature that semantic dependencies can directly access deep semantic information across the surface syntactic structure of a sentence to capture the semantic relations between predicates and arguments, and enhance such semantic relations in the form of questions and answers through machine reading comprehension, to extract co-reference chains more accurately. In addition, we propose a method of combining semantic dependency with the language model to realize zero pronoun recovery from the deep semantic level. Experimental results on our self-constructed public opinion dataset (FS-PO) show that the MRC-SD model significantly outperforms the state-of-the-art zero-pronoun resolution model.},
  archive      = {J_AIR},
  author       = {Bi, Mingwen and Liu, Xinliang and Zhang, Qingchuan and Yang, Zhenghong},
  doi          = {10.1007/s10462-022-10364-5},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {7597-7612},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Machine reading comprehension combined with semantic dependency for chinese zero pronoun resolution},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Autonomous learning for fuzzy systems: A review.
<em>AIR</em>, <em>56</em>(8), 7549–7595. (<a
href="https://doi.org/10.1007/s10462-022-10355-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the three pillars in computational intelligence, fuzzy systems are a powerful mathematical tool widely used for modelling nonlinear problems with uncertainties. Fuzzy systems take the form of linguistic IF-THEN fuzzy rules that are easy to understand for human. In this sense, fuzzy inference mechanisms have been developed to mimic human reasoning and decision-making. From a data analytic perspective, fuzzy systems provide an effective solution to build precise predictive models from imprecise data with great transparency and interpretability, thus facilitating a wide range of real-world applications. This paper presents a systematic review of modern methods for autonomously learning fuzzy systems from data, with an emphasis on the structure and parameter learning schemes of mainstream evolving, evolutionary, reinforcement learning-based fuzzy systems. The main purpose of this paper is to introduce the underlying concepts, underpinning methodologies, as well as outstanding performances of the state-of-the-art methods. It serves as a one-stop guide for readers learning the representative methodologies and foundations of fuzzy systems or who desire to apply fuzzy-based autonomous learning in other scientific disciplines and applied fields.},
  archive      = {J_AIR},
  author       = {Gu, Xiaowei and Han, Jungong and Shen, Qiang and Angelov, Plamen P.},
  doi          = {10.1007/s10462-022-10355-6},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {7549-7595},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Autonomous learning for fuzzy systems: A review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of redundancy allocation problem for two decades:
Bibliometrics and future directions. <em>AIR</em>, <em>56</em>(8),
7457–7548. (<a
href="https://doi.org/10.1007/s10462-022-10363-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Redundancy allocation problem (RAP) has attracted many researchers in recent years as it is very important aspect in the field of reliability and system engineering. It plays an important role in high-tech industries. Present paper conducts a comprehensive literature review to classify, analyze and intercept the existing studies related to the RAP with respect to different systems, system configuration, methodology, constraints. The previous literature related to the RAP problems have been invested by the researchers such as Tillman in 1980, Kuo in 2007 and Soltani from 2000 to 2014. The objective of this paper is to cover the study over the past two decades starting from 2000. The present research has reviewed approximately 280 papers which are segregated on the basis of exact and heuristic techniques, meta-heuristic and mathematical programming methods, stochastic and interval uncertainty, intuitionistic fuzzy and vague set, robust approach. Further, a classification has been done on the basis of objectives as single and multi-objective. Finally, insights regarding the future direction, challenges and limitations are given. Main aim of this research paper is to summurise the developments including recent, research gap and future directions in the field of reliability optimization.},
  archive      = {J_AIR},
  author       = {Devi, Sarita and Garg, Harish and Garg, Deepika},
  doi          = {10.1007/s10462-022-10363-6},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {7457-7548},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review of redundancy allocation problem for two decades: Bibliometrics and future directions},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A variate brain tumor segmentation, optimization, and
recognition framework. <em>AIR</em>, <em>56</em>(7), 7403–7456. (<a
href="https://doi.org/10.1007/s10462-022-10337-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection and brain tumor (BT) segmentation and classification are mandatory steps before any radiotherapy or surgery. When performed manually, segmentation is time-consuming and exposed to human errors. Therefore, significant efforts have been made to automate the process. In this study, a proposed automatic discriminative learning-based approach for brain tumor classification and segmentation using a metaheuristic optimizer called Sparrow Search Algorithm (SpaSA). The segmentation process is performed using UNet models (i.e., U-Net, U-Net++, Attention U-Net, and V-net). Additionally, the learning and SpaSA optimization is performed using pre-trained CNN models (i.e., MobileNet, MobileNetV2, MobileNetV3Small, MobileNetV3Large, EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3, EfficientNetB4, EfficientNetB5,VGG16, and VGG19). To optimize the training hyperparameters, the SpaSA metaheuristic optimizer is used. The dataset is collected from 6 public sources. Two types of datasets are generated. One with 2-classes and the other with 4-classes. The best-reported scores by U-Net architecture are 99.73\% accuracy, 99.93\% specificity, 99.35\% AUC, 99.78\% IoU, and 99.80\% Dice for the whole tumor region. For the 2-classes dataset, the best reported overall accuracy from the applied CNN experiments is 99.99\% by the MobileNetV3 Large pre-trained model. The average accuracy is 99.92\%. Similarly, For the 4-classes dataset, the best reported overall accuracy from the applied CNN experiments is 99.73\% by the EfficientNetB2 pre-trained model. The average accuracy is 99.19\%. The suggested approach is compared with 11 related studies.},
  archive      = {J_AIR},
  author       = {Balaha, Hossam Magdy and Hassan, Asmaa El-Sayed},
  doi          = {10.1007/s10462-022-10337-8},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {7403-7456},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A variate brain tumor segmentation, optimization, and recognition framework},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Evolved distance measures for circular intuitionistic fuzzy
sets and their exploitation in the technique for order preference by
similarity to ideal solutions. <em>AIR</em>, <em>56</em>(7), 7347–7401.
(<a href="https://doi.org/10.1007/s10462-022-10318-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Circular intuitionistic fuzzy (C-IF) sets are an up-and-coming tool for enforcing indistinct and imprecise information in variable and convoluted decision-making situations. C-IF sets, as opposed to typical intuitionistic fuzzy sets, are better suited for identifying the evaluation data with uncertainty in intricate realistic decision situations. The architecture of the technique for order preference by similarity to ideal solutions (TOPSIS) provides powerful evaluation tools to aid decision-making in intuitionistic fuzzy conditions. To address appraisal issues associated with decision analysis involving extremely convoluted information, this paper propounds a novel C-IF TOPSIS approach in the context of C-IF uncertainty. This research makes three significant contributions. First, based on the three- and four-term operating rules, this research introduces C-IF Minkowski distance measures, which are new generalized representations of distance metrics applicable to C-IF values and C-IF sets. Such general C-IF distance metrics can alleviate the constraints of established C-IF distance measures, provide usage resiliency through parameter settings, and broaden the applicability of metric analysis. Second, unlike existing C-IF TOPSIS methods, this research fully utilizes C-IF information characteristics and extends the core structure of the classic TOPSIS to C-IF contexts. With the newly developed C-IF Minkowski metrics, this study faithfully demonstrates the trade-off evaluation and compromise decision rules in the TOPSIS framework. Third, this research builds on the core strengths of the pioneered C-IF Minkowski distance measures to create innovative C-IF TOPSIS techniques utilizing four different combinations, including displaced and fixed anchoring frameworks, as well as three- and four-term representations. Such a refined C-IF TOPSIS methodology can assist decision-makers in proactively addressing increasingly sophisticated decision-making problems in practical settings. Finally, this research employs two innovative prioritization algorithms to address a site selection issue of large-scale epidemic hospitals to illustrate the superior capabilities of the C-IF TOPSIS methodology over some current related approaches.},
  archive      = {J_AIR},
  author       = {Chen, Ting-Yu},
  doi          = {10.1007/s10462-022-10318-x},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {7347-7401},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Evolved distance measures for circular intuitionistic fuzzy sets and their exploitation in the technique for order preference by similarity to ideal solutions},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An approach to prevent weight manipulation by minimum
adjustment and maximum entropy method in social network group decision
making. <em>AIR</em>, <em>56</em>(7), 7315–7346. (<a
href="https://doi.org/10.1007/s10462-022-10361-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In social network group decision making (SN-GDM) problem, subgroup weights are mostly unknown, many approaches have been proposed to determine the subgroup weights. However, most of these methods ignore the weight manipulation behavior of subgroups. Some studies indicated that weight manipulation behavior hinders consensus efficiency. To deal with this issue, this paper proposes a theoretical framework to prevent weight manipulation in SN-GDM. Firstly, a community detection based method is used to cluster the large group. The power relations of subgroups are measured by the power index (PI), which depends on the subgroups size and cohesion. Then, a minimum adjustment feedback model with maximum entropy is proposed to prevent subgroups’ manipulation behavior. The minimum adjustment rule aims for ‘efficiency’ while the maximum entropy rule aims for ‘justice’. The experimental results show that the proposed model can guarantee the rationality of weight distribution to reach consensus efficiently, which is achieved by maintaining a balance between ‘efficiency’ and ‘justice’ in the mechanism of assigning weights. Finally, the detailed numerical and simulation analyses are carried out to verify the validity of the proposed method.},
  archive      = {J_AIR},
  author       = {Sun, Qi and Wu, Jian and Chiclana, Francisco and Wang, Sha and Herrera-Viedma, Enrique and Yager, Ronald R.},
  doi          = {10.1007/s10462-022-10361-8},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {7315-7346},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An approach to prevent weight manipulation by minimum adjustment and maximum entropy method in social network group decision making},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluating eXplainable artificial intelligence tools for
hard disk drive predictive maintenance. <em>AIR</em>, <em>56</em>(7),
7279–7314. (<a
href="https://doi.org/10.1007/s10462-022-10354-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last years, one of the main challenges in Industry 4.0 concerns maintenance operations optimization, which has been widely dealt with several predictive maintenance frameworks aiming to jointly reduce maintenance costs and downtime intervals. Nevertheless, the most recent and effective frameworks mainly rely on deep learning models, but their internal representations (black box) are too complex for human understanding making difficult explain their predictions. This issue can be challenged by using eXplainable artificial intelligence (XAI) methodologies, the aim of which is to explain the decisions of data-driven AI models, characterizing the strengths and weaknesses of the decision-making process by making results more understandable by humans. In this paper, we focus on explanation of the predictions made by a recurrent neural networks based model, which requires a tree-dimensional dataset because it exploits spatial and temporal features for estimating remaining useful life (RUL) of hard disk drives (HDDs). In particular, we have analyzed in depth as explanations about RUL prediction provided by different XAI tools, compared using different metrics and showing the generated dashboards, can be really useful for supporting predictive maintenance task by means of both global and local explanations. For this aim, we have realized an explanation framework able to investigate local interpretable model-agnostic explanations (LIME) and SHapley Additive exPlanations (SHAP) tools w.r.t. to the Backblaze Dataset and a long short-term memory (LSTM) prediction model. The achieved results show how SHAP outperforms LIME in almost all the considered metrics, resulting a suitable and effective solution for HDD predictive maintenance applications.},
  archive      = {J_AIR},
  author       = {Ferraro, Antonino and Galli, Antonio and Moscato, Vincenzo and Sperlì, Giancarlo},
  doi          = {10.1007/s10462-022-10354-7},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {7279-7314},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Evaluating eXplainable artificial intelligence tools for hard disk drive predictive maintenance},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fotomics: Fourier transform-based omics imagification for
deep learning-based cell-identity mapping using single-cell omics
profiles. <em>AIR</em>, <em>56</em>(7), 7263–7278. (<a
href="https://doi.org/10.1007/s10462-022-10357-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different omics profiles, depending on the underlying technology, encompass measurements of several hundred to several thousand molecules in a biological sample or a cell. This study develops upon the concept of “omics imagification” as a process of transforming a vector representing these numerical measurements into an image with a one-to-one relationship with the corresponding sample. The proposed imagification process transforms a high-dimensional vector of molecular measurements into a two-dimensional RGB image to enable holistic molecular representation of a biological sample and to improve the classification of different biological phenotypes using automated image recognition methods in computer vision. A transformed image represents 2D coordinates of molecules in a neighbour-embedded space representing molecular abundance and gene intensity. The proposed method was applied to a single-cell RNA sequencing (scRNA-seq) data to “imagify” gene expression profiles of individual cells. Our results show that a simple convolutional neural network trained on single-cell transcriptomics images accurately classifies diverse cell types outperforming the best-performing scRNA-seq classifiers such as support vector machine and random forest.},
  archive      = {J_AIR},
  author       = {Zandavi, Seid Miad and Liu, Derong and Chung, Vera and Anaissi, Ali and Vafaee, Fatemeh},
  doi          = {10.1007/s10462-022-10357-4},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {7263-7278},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Fotomics: Fourier transform-based omics imagification for deep learning-based cell-identity mapping using single-cell omics profiles},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-factor two-stage deep integration model for stock
price prediction based on intelligent optimization and feature
clustering. <em>AIR</em>, <em>56</em>(7), 7237–7262. (<a
href="https://doi.org/10.1007/s10462-022-10352-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock market fluctuations have a great impact on various economic and financial activities worldwide. Accurate prediction of stock prices plays a decisive role in constructing the investment decision or risk hedging. However, accurate prediction of the stock price is a thorny task, because stock price fluctuations are non-linear and chaotic. In order to promote the accuracy of stock price prediction, a multi-factor two-stage deep learning integrated prediction system based on intelligent optimization and feature clustering is proposed to predict stock price in this paper. Firstly, a multi-factor analysis is carried out to select a variety of factors that have an impact on the stock price, and adopt the extreme gradient boosting (XGBoost) algorithm to eliminate factors with low correlation. The second step is to apply the idea of classification prediction to cluster the filtered feature set. Further, multiple parameters of long short-term memory (LSTM) are optimized by genetic algorithm (GA), and multiple GA-LSTM models are obtained by training each clustering result. Finally, the results of each class predicted by the GA-LSTM model are nonlinearly integrated to acquire the final prediction model, which is applied to the prediction of the test set. The experimental results indicate that the performance of the proposed model outperforms other baseline models in China&#39;s two stock markets and the New York stock exchange. At the same time, these results fully prove that the prediction model proposed by us possesses more reliable and better predictive ability.},
  archive      = {J_AIR},
  author       = {Wang, Jujie and Zhu, Shuzhou},
  doi          = {10.1007/s10462-022-10352-9},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {7237-7262},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A multi-factor two-stage deep integration model for stock price prediction based on intelligent optimization and feature clustering},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). New challenges in reinforcement learning: A survey of
security and privacy. <em>AIR</em>, <em>56</em>(7), 7195–7236. (<a
href="https://doi.org/10.1007/s10462-022-10348-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning is one of the most important branches of AI. Due to its capacity for self-adaption and decision-making in dynamic environments, reinforcement learning has been widely applied in multiple areas, such as healthcare, data markets, autonomous driving, and robotics. However, some of these applications and systems have been shown to be vulnerable to security or privacy attacks, resulting in unreliable or unstable services. A large number of studies have focused on these security and privacy problems in reinforcement learning. However, few surveys have provided a systematic review and comparison of existing problems and state-of-the-art solutions to keep up with the pace of emerging threats. Accordingly, we herein present such a comprehensive review to explain and summarize the challenges associated with security and privacy in reinforcement learning from a new perspective, namely that of the Markov Decision Process (MDP). In this survey, we first introduce the key concepts related to this area. Next, we cover the security and privacy issues linked to the state, action, environment, and reward function of the MDP process, respectively. We further highlight the special characteristics of security and privacy methodologies related to reinforcement learning. Finally, we discuss the possible future research directions within this area.},
  archive      = {J_AIR},
  author       = {Lei, Yunjiao and Ye, Dayong and Shen, Sheng and Sui, Yulei and Zhu, Tianqing and Zhou, Wanlei},
  doi          = {10.1007/s10462-022-10348-5},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {7195-7236},
  shortjournal = {Artif. Intell. Rev.},
  title        = {New challenges in reinforcement learning: A survey of security and privacy},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A comprehensive review of task understanding of
command-triggered execution of tasks for service robots. <em>AIR</em>,
<em>56</em>(7), 7137–7193. (<a
href="https://doi.org/10.1007/s10462-022-10347-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotics is a cross-disciplinary branch of science and technology, and lays foundation on mechanics, control, computer science, artificial intelligence, and so on. With the developments of both softwares and hardwares, especially in the artificial intelligence technologies, robots have been widely applied in multiple areas in the society, and become more and more interactive in our daily life, such as the service robots in the museums, shopping malls, restaurants, etc. Though the ultimate goal for a service robot to behave like a human is not easy to be achieved, significant processes have been made during the past decades. Considering that it is universal that service robots are triggered to execute tasks specified by human users via commands (Comm-TET), and it is essential to process and understand human users’ commands correctly, we comprehensively overview the developments of the task understanding (TU) sub-process of Comm-TET for service robots. In order to organize the related literature in a reasonable manner, we abstracted the pipeline of Comm-TET and the generic framework of TU based on the existing researches. Following the abstracted framework, we present in-depth discussions on each of its building blocks over the past decades, and give some insights on the future research directions. Compared to other reviews on TU, this review emphasizes more on the technical developments and organizes the existing researches as an integrality.},
  archive      = {J_AIR},
  author       = {Xi, Xiangming and Zhu, Shiqiang},
  doi          = {10.1007/s10462-022-10347-6},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {7137-7193},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comprehensive review of task understanding of command-triggered execution of tasks for service robots},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A dive in white and grey shades of ML and non-ML literature:
A multivocal analysis of mathematical expressions. <em>AIR</em>,
<em>56</em>(7), 7047–7135. (<a
href="https://doi.org/10.1007/s10462-022-10330-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent and advancement of machine learning and deep learning techniques, machine-based recognition systems for mathematical text have captivated the attention of the research community for the last four decades. Mathematical Expression Recognition systems have been identified based on terms of their techniques, approach, dataset, and accuracies. This study majorly targets a rigorous review of both the published form of literature and the least attended literature, i.e., grey literature. Apart from the digital libraries, the papers and other instances of information have been gathered from the grey sources like google patents, archives, technical reports, app stores, etc., culminating in 262 instances. After the heedful filtration imposed on both white and grey literature, the final pool of studies has been investigated for eight formulated research questions. The answers extracted have been analyzed, providing both quantitative and qualitative insights. The analysis and surveys have systematically summed up the potentials of both white and grey shades of literature present on MER and brought exciting extractions out of 155 formal white literature and 107 grey sources. The survey extracts and brings out the highlighting observations after analysis, which sublimates the fact that 52\% of grey literature is composed of mobile applications and user interfaces, whereas the published 63\% of white data is presently concentrated in 39 different conferences, and the prominent conference is ICDAR (#30). A list of challenges and open issues has been extracted for directing future research dimensions.},
  archive      = {J_AIR},
  author       = {Sakshi and Kukreja, Vinay},
  doi          = {10.1007/s10462-022-10330-1},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {7047-7135},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A dive in white and grey shades of ML and non-ML literature: A multivocal analysis of mathematical expressions},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DptOIE: A portuguese open information extraction based on
dependency analysis. <em>AIR</em>, <em>56</em>(7), 7015–7046. (<a
href="https://doi.org/10.1007/s10462-022-10349-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is estimated that more than 80\% of the information on the Web is stored in textual form. As such, it has become increasingly difficult for humans to sort and extract useful information from the daily influx of data. In order to automate this process, open information extraction (OIE) methods have been proposed, which can extract facts from large textual bases. While most OIE methods were initially developed for the English language, the importance of developing methods for other languages, such as Portuguese, has been increasingly recognized in recent literature. OIE methods based on hand-crafted rules and shallow syntactic analysis have achieved good performances for the English language. Nevertheless, methods based on similar approaches in the Portuguese language have not achieved equivalent success. We believe that the shallow syntactic patterns previously explored in the literature do not cover important aspects of the Portuguese language syntax. For this reason, we propose the DptOIE method based on a new set of syntax-based rules using dependency parsers and a depth-first search (DFS) algorithm for OIE and a set of grammar-based rules to cover specific syntactic phenomena of the language. DptOIE was compared against the state-of-the-art OIE for the Portuguese language, obtaining favorable results both in our empirical evaluation and at the IberLEF evaluation track of OIE systems for the Portuguese language. Furthermore, we believe our method can be easily adapted to other Romance languages related to Portuguese.},
  archive      = {J_AIR},
  author       = {Oliveira, Leandro and Claro, Daniela Barreiro and Souza, Marlo},
  doi          = {10.1007/s10462-022-10349-4},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {7015-7046},
  shortjournal = {Artif. Intell. Rev.},
  title        = {DptOIE: A portuguese open information extraction based on dependency analysis},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Physical laws meet machine intelligence: Current
developments and future directions. <em>AIR</em>, <em>56</em>(7),
6947–7013. (<a
href="https://doi.org/10.1007/s10462-022-10329-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of technology including big data has allowed machine learning technology to strengthen its place in solving different science and engineering complex problems. Conventional deep machine learning algorithms work as a black box while dealing with various complex physics-driven problems. This problem can be reduced by integrating the physical laws with machine learning algorithms to ensure the developed models are complied with the physics and are potentially more explainable. This physics-informed machine learning (PIML) approach allows the integration of physical laws in the form of PDEs into the loss function of the neural network, hence, constraining the training of the complex problems based on both the physical, experimental, and mathematical boundaries. This, hence, allows the development of a more general predictive model for different science, engineering, and optimization tasks. Considering such advancements in the machine learning domain, this review presents the systematic progress in the development of integrating physics into the neural networks and recent applications in solving various forward and inverse problems in science and engineering. This paper can serve as a reference for the researchers, developers, and users to get all information they need before developing, implementing, and deploying AI models and smart systems that are equipped with the PIML methodology. It highlights the benefits and points out its limitations and recommendations for further development. The review also compares the traditional data-driven machine learning and PIML approach in dealing with the physics of complex problems. In general, the PIML has been found to provide consistent results with the exact solutions and physical nature of the system. However, similar to other AI system development, a more robust and complex AI algorithm requires more computational power which is also the case in PIML development and implementation. It should be noted that different terminologies such as physics-informed neural networks (PINN), science-informed neural networks, physics-inspired neural networks, and physics-constrained neural networks have been used in the literature that describes the very similar concept of integrating physical laws with machine intelligence. For consistency, we use the PIML term throughout this paper which covers all listed terminologies in this regard.},
  archive      = {J_AIR},
  author       = {Muther, Temoor and Dahaghi, Amirmasoud Kalantari and Syed, Fahad Iqbal and Van Pham, Vuong},
  doi          = {10.1007/s10462-022-10329-8},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {6947-7013},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Physical laws meet machine intelligence: Current developments and future directions},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid archimedes optimization algorithm enhanced with
mutualism scheme for global optimization problems. <em>AIR</em>,
<em>56</em>(7), 6885–6946. (<a
href="https://doi.org/10.1007/s10462-022-10340-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Archimedes optimization algorithm (AOA) is a recent metaheuristic method inspired by the Archimedes principle, which is the law of physics. Like other metaheuristic methods, it suffers from the disadvantages of being stuck in local areas, suffering from weak exploitation abilities, and an inability to maintain a balance between exploration and exploitation. To overcome these weaknesses, a new hybrid Mutualism Archimedes Optimization Algorithm (MAOA) method has been proposed by combining the AOA and the mutation phase in the Symbiosis organism search (SOS) method. SOS algorithm is known for its exploitation ability. With the mutation phase, it has been used to improve local search for swarm agents, help prevent premature convergence and increase population diversity. To verify the applicability and performance of the proposed algorithm, extensive analysis of standard benchmark functions, CEC’17 test suites, and engineering design problems were performed. The proposed method is compared with the recently emerged and popular AOA, SOS, Harris Hawks Optimization (HHO), COOT Optimization Algorithm (COOT), Aquila Optimizer (AO), Salp Swarm Algorithm (SSA), and Multi-Verse Optimization (MVO) methods, and statistical analyses were performed. The results obtained from the experiments show that the proposed MAOA method has superior global search performance and faster convergence speed compared to AOA, SOS, and other recently emerged and popular metaheuristic methods. Furthermore, this study compares MAOA to five well-established and recent algorithms constructed using various metaheuristic methodologies utilizing nine benchmark datasets to assess the general competence of MAOA in feature selection. Therefore, the proposed method is considered to be a promising optimization method for real-world engineering design problems, global optimization problems, and feature selection.},
  archive      = {J_AIR},
  author       = {Varol Altay, Elif},
  doi          = {10.1007/s10462-022-10340-z},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {6885-6946},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Hybrid archimedes optimization algorithm enhanced with mutualism scheme for global optimization problems},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rough sets models inspired by supra-topology structures.
<em>AIR</em>, <em>56</em>(7), 6855–6883. (<a
href="https://doi.org/10.1007/s10462-022-10346-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our aim of writing this manuscript is to found novel rough-approximation operators inspired by an abstract structure called “supra-topology”. This approach is more relaxed than topological ones and extends the scope of applications because an intersection condition of topology is dispensed. Firstly, we generate eight types of supra-topologies using $$N_k$$ -neighborhood systems induced from any arbitrary relation. We elucidate the relationships between them and investigate the conditions under which some of them are identical. Then, we create new rough sets models from these supra-topologies and present the main characterizations of their lower and upper approximations. We apply these approximations to classify the regions of the subset and compute its accuracy measures. The master merits of the current approach are to produce the highest accuracy values compared with all approaches given in the published literature under a reflexive relation as well as preserve the monotonicity property of accuracy and roughness measures. Moreover, we demonstrate the good performance of the followed technique through analysis of some data of dengue fever disease. Ultimately, we debate the advantages and disadvantages of the followed approach and make a plan for some upcoming work.},
  archive      = {J_AIR},
  author       = {Al-shami, Tareq M. and Alshammari, Ibtesam},
  doi          = {10.1007/s10462-022-10346-7},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {6855-6883},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Rough sets models inspired by supra-topology structures},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Arabic natural language processing for qur’anic research: A
systematic review. <em>AIR</em>, <em>56</em>(7), 6801–6854. (<a
href="https://doi.org/10.1007/s10462-022-10313-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Qur’an is a fourteen centuries old divine book in Arabic language that is read and followed by almost two billion Muslims globally as their sacred religious text. With the rise of Islam, the Arabic language gained popularity and became the lingua franca for large swaths of the old world. Devout Muslims read the Qur’an daily seeking guidance and comfort. Though the Qur’an, as a text, is short, there is a huge volume of supporting work filling tens of thousands of volumes, e.g., commentaries, exegesis, etc. Recently, there has been a renewed interest in such religious texts by non-specialists. Many of which were fueled by the recent advances in computational and natural language processing (NLP) techniques. These techniques help the development of tools that benefit common people to gain knowledge easily. This paper surveys the different efforts in the field of Qur’anic NLP, serving as a synthesized compendium of works (tools, data sets, approaches) covering the gamut from automated morphological analysis to correction of Qur’anic recitation via speech recognition. Multiple approaches are discussed for several tasks, where appropriate. Finally, we outline future research directions in this field.},
  archive      = {J_AIR},
  author       = {Bashir, Muhammad Huzaifa and Azmi, Aqil M. and Nawaz, Haq and Zaghouani, Wajdi and Diab, Mona and Al-Fuqaha, Ala and Qadir, Junaid},
  doi          = {10.1007/s10462-022-10313-2},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {6801-6854},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Arabic natural language processing for qur’anic research: A systematic review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Preparation process and performance of polyurethane modified
bitumen investigated using machine learning algorithm. <em>AIR</em>,
<em>56</em>(7), 6775–6800. (<a
href="https://doi.org/10.1007/s10462-022-10345-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the preparation of high-performance polyurethane (PU) modified bitumen, due to the different kinds of PU modifiers, the design parameters of the preparation process are numerous, and indexes of the performance response need to be selected. As a result, the preparation process of PU-modified bitumen is not universally applicable. Therefore, according to different application environments, how determining the process parameters of the PU-modified bitumen accurately and efficiently is a key problem to be solved urgently. Based on fthe Kriging-PSO hybrid optimization algorithm, this paper proposed a novel design method for the preparation process for the PU-modified bitumen. The response indicators with high relative sensitivity (softening point, rutting factor, Brookfield viscosity, and dispersion coefficient) were screened by using range and variance analysis to improve the fitting accuracy of the Kriging-PSO model after training. Among them, the dispersion coefficient was evaluated by fluorescence microscopy test using the Christiansen coefficient method to evaluate the uniformity of the dispersed phase of the PU modifier. Through the Kriging-PSO algorithm, the main process parameters for preparing PU-modified bitumen in the laboratory were determined as follows: shearing time 86 min, shearing speed 2450 rpm, shearing temperature 148, and PU content 18.6\%. The prepared PU-modified bitumen was placed in an oven at 100 for 2 h. The performance indicators of PU modified bitumen were: softening point 90, rutting factor 30 kPa, Brookfield viscosity 80,000 Pa·s, and dispersion coefficient 0.92. The PU-modified bitumen prepared by this optimal process met the expected performance indicators. The results of this paper showed that the Kriging-PSO algorithm provided a new idea for the design of a modified bitumen preparation process and achieve the purpose of designing the optimum process parameters of PU modified bitumen efficiently using fewer samples. Meanwhile, it created a new way for the application of machine deep learning algorithms in the civil engineering field.},
  archive      = {J_AIR},
  author       = {Lu, Pengzhen and Huang, Simin and Zhou, Chenhao and Xu, Zijie and Wu, Ying},
  doi          = {10.1007/s10462-022-10345-8},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {6775-6800},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Preparation process and performance of polyurethane modified bitumen investigated using machine learning algorithm},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generative adversarial networks based on optimal transport:
A survey. <em>AIR</em>, <em>56</em>(7), 6723–6773. (<a
href="https://doi.org/10.1007/s10462-022-10342-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal transport theory provides a distance to find the cheapest way to convey an object from one place to another, based on a certain cost. Optimal transport thus defines a set of geometric tools with interesting properties in terms of coupling and correspondence between probability distributions. Recent theoretical and algorithmic advances in this theory generate interesting methods for data science. Bearing this in mind, Wasserstein Generative Adversarial Networks (WGAN) make it possible to generate complex data with a high degree of realism in addition to real data which may be limited in certain contexts where their accessibility is restricted. This paper presents a literature review of recent developments in optimal transport-based data science in some practical and theoretical contexts, for solving machine learning problems. In the theoretical developments, we will appreciate the extension of WGANs coupled with conditions, autoencoders, and transfer learning. We made a critical evaluation of prevalent WGANs by synthesizing and comparing information between them to improve understanding of their respective impact. The practical context shows prominent applications in the fields of industry, health, and safety. Finally, challenges are discussed, and the conclusion presents the benefits of WGAN and prospective analyses.},
  archive      = {J_AIR},
  author       = {Kamsu-Foguem, Bernard and Msouobu Gueuwou, Shester Landry and Kounta, Cheick Abdoul Kadir A.},
  doi          = {10.1007/s10462-022-10342-x},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {6723-6773},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Generative adversarial networks based on optimal transport: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An IoT based smart menstrual cup using optimized adaptive
CNN model for effective menstrual hygiene management. <em>AIR</em>,
<em>56</em>(7), 6705–6722. (<a
href="https://doi.org/10.1007/s10462-022-10308-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Poor feminine hygiene leads to various infections such as hepatitis B, fungal infections, reproductive tract infections, urinary infections, etc. The main concern associated with the menstrual cup is the problem of disposal and hygiene management which is still a major concern in the whole world. To overcome this problem, this paper proposed a novel technique integrating the Internet of Things (IoT) and machine learning methodology. The chaos game (CG) optimized adaptive convolutional neural network (ACNN) architecture is used to detect the menstrual flow when it exceeds a specific mark (17 ml) in the menstrual cup. When the menstrual cup is prone to leakage the participant is alerted via a text message. The efficiency of the proposed methodology is evaluated by using the voltage data obtained from the different IoT devices of participants. The efficiency of the CG optimized ACNN architecture is evaluated using different performance metrics such as accuracy, Root means Square Error, sensitivity, specificity, and recall. The proposed methodology is both capable of identifying the abnormal menstrual flow and alerting the user for disposal. Our experimental findings illustrate the efficiency of this methodology in improving women’s menstrual hygiene in real time by analyzing the flow.},
  archive      = {J_AIR},
  author       = {Shiny Irene, D. and Indra Priyadharshini, S. and Tamizh Kuzhali, R. and Nancy, P.},
  doi          = {10.1007/s10462-022-10308-z},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {6705-6722},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An IoT based smart menstrual cup using optimized adaptive CNN model for effective menstrual hygiene management},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Deep learning on multi-view sequential data: A survey.
<em>AIR</em>, <em>56</em>(7), 6661–6704. (<a
href="https://doi.org/10.1007/s10462-022-10332-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the progress of human daily interaction activities and the development of industrial society, a large amount of media data and sensor data become accessible. Humans collect these multi-source data in chronological order, called multi-view sequential data (MvSD). MvSD has numerous potential application domains, including intelligent transportation, climate science, health care, public safety and multimedia, etc. However, as the volume and scale of MvSD increases, the traditional machine learning methods become difficult to withstand such large-scale data, and it is no longer appropriate to use hand-craft features to represent these complex data. In addition, there is no general framework in the process of mining multi-view relationships and integrating multi-view information. In this paper, We first introduce four common data types that constitute MvSD, including point data, sequence data, graph data, and raster data. Then, we summarize the technical challenges of MvSD. Subsequently, we review the recent progress in deep learning technology applied to MvSD. Meanwhile, we discuss how the network represents and learns features of MvSD. Finally, we summarize the applications of MvSD in different domains and give potential research directions.},
  archive      = {J_AIR},
  author       = {Xie, Zhuyang and Yang, Yan and Zhang, Yiling and Wang, Jie and Du, Shengdong},
  doi          = {10.1007/s10462-022-10332-z},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {6661-6704},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep learning on multi-view sequential data: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A consistency and consensus-driven approach for granulating
linguistic information in GDM with distributed linguistic preference
relations. <em>AIR</em>, <em>56</em>(7), 6627–6659. (<a
href="https://doi.org/10.1007/s10462-022-10344-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study considers the linguistic information granulation in GDM scenarios where both the outcomes of pairwise comparisons coming from decision makers (DMs) over alternatives and the relative importance of DMs are recalled by way of DLPRs. First, with the use of multiplicative consistency criterion, an information granulation model is proposed for achieving the operational realization of the linguistic information related to the DMs’ relative importance. Then, based on the expert weight derived from the results of the aforesaid model, a new performance index based on the multiplicative linear combination of consistency and consensus is defined and used to develop another information granulation model for the operational realization of linguistic information associated with the DMs’ preference over alternatives. Finally, the PSO approach to solve the two linguistic information granulation models is introduced, followed by the presentation of the framework of the proposed linguistic information granulation approach to address such GDM with DLPRs. A case study regarding commercial vehicle selection problem demonstrates how the proposals are applied in practical decision scenarios. Under an aeroengine risk assessment problem comparing with two linguistic quantization models shows the advantage of the proposals. Overall, the contributions of this study lie in two aspects: the development of two linguistic information granulation models, and the presentation of the framework of the linguistic information granulation approach to solve such GDM with DLPRs.},
  archive      = {J_AIR},
  author       = {Su, Han and Wu, Qi and Tang, Xiaoan and Huang, Ting},
  doi          = {10.1007/s10462-022-10344-9},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {6627-6659},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A consistency and consensus-driven approach for granulating linguistic information in GDM with distributed linguistic preference relations},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel prospect-theory-based three-way decision methodology
in multi-scale information systems. <em>AIR</em>, <em>56</em>(7),
6591–6625. (<a
href="https://doi.org/10.1007/s10462-022-10339-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an uncertain and complex decision-making environment, limited by the scope of human cognition, traditional utility decision-making has a certain deviation to actual decision-making. The revision of behavioral decision-making (BDM) to traditional rational decision-making theory makes the new model more universal. In light of this point, we reveal a new three-way decision (3WD) model by virtue of prospect theory (PT) on multi-scale information systems (MS-ISs) for persuing multi-attribute decision-making (MADM) problems. By utilizing an expected evaluation, our newly designed value function can not only reflect the relative position of the object but also avoid the drawbacks of the reference point being too subjective. Through the value function, we obtain a more reasonable avail function to replace the loss function in the traditional 3WD model. At the same time, the weighting function of the object in different states can be calculated, by synthesizing avail function and the weighting function under different decision attitudes. The comprehensive prospect value and classification conditions of the object are calculated. Then, through data selected from the UCI database, we verify the effectiveness of the constructed method. Comparative and experimental analyses are also used to illustrate the superiority and stability of our designed method.},
  archive      = {J_AIR},
  author       = {Deng, Jiang and Zhan, Jianming and Ding, Weiping and Liu, Peide and Pedrycz, Witold},
  doi          = {10.1007/s10462-022-10339-6},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {6591-6625},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A novel prospect-theory-based three-way decision methodology in multi-scale information systems},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data mining-based firefly algorithm for green vehicle
routing problem with heterogeneous fleet and refueling constraint.
<em>AIR</em>, <em>56</em>(7), 6557–6589. (<a
href="https://doi.org/10.1007/s10462-022-10336-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the major reasons for the importance of green vehicle routing is that current distribution systems are not sustainable in the long run. Because currently, only conventional economic costs are considered and environmental impacts of logistics strategies are not considered to be an important issue. Green vehicle routing emphasizes the use of clean fuels as an important factor in reducing the environmental pollution. However, due to the shortage of fuel stations providing these types of fuels, careful planning is needed considering the location and time of refueling of vehicles. In this regard, here, it is assumed that vehicles have limited fuel and should go to refueling stations and so fuel stations have also been added to the nodes of the classic vehicle routing problem. In this paper, a mathematical formulation is presented for a green heterogeneous vehicle routing problem and a firefly algorithm is developed to solve it in large-size instances. Two approaches have been used in applying the firefly algorithm. The first approach is the basic firefly algorithm and the second one is the firefly algorithm based on data mining in which the decision tree method reduces solution space and makes smarter fireflies movement. Finally, we have shown that using data mining has a significant effect on improving the performance of the firefly algorithm and by using a decision tree, the efficiency of the algorithm is significantly improved.},
  archive      = {J_AIR},
  author       = {Behnamian, J. and Ghadimi, M. and Farajiamiri, M.},
  doi          = {10.1007/s10462-022-10336-9},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {6557-6589},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Data mining-based firefly algorithm for green vehicle routing problem with heterogeneous fleet and refueling constraint},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RG-NBEO: A ReliefF guided novel binary equilibrium optimizer
with opposition-based s-shaped and v-shaped transfer functions for
feature selection. <em>AIR</em>, <em>56</em>(7), 6509–6556. (<a
href="https://doi.org/10.1007/s10462-022-10333-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In most data mining tasks, feature selection (FS) is a necessary preprocessing step that can reduce the dimensionality of the dataset while ensuring adequate classification accuracy. In this paper, a ReliefF-guided novel binary equilibrium optimizer (RG-NBEO) is proposed for feature selection. Based on the binary equilibrium optimizer, two novel mechanisms are employed to improve the evolution performance. First, two novel transfer functions (SSr and VVr) based on the concept of opposition learning are proposed to transform the continuous search space into a binary search space and achieve a good balance between exploration and exploitation. Second, a ReliefF bootstrapping strategy is proposed to add and remove features directionally in the iterative process according to the feature weights. The simulation experiments are first based on the equilibrium optimizer (EO) variants constructed from the classical S- and V-shaped transfer functions. The variant EO with the best performance is selected and compared with five superior swarm intelligence optimization algorithms and six classical filter feature selection algorithms. The performance of the proposed method was tested on 18 standard datasets, and the results of the different algorithms were statistically evaluated using the Wilcoxon rank sum test and the Freidman rank sum test. The results show that this method can effectively improve the classification accuracy in most cases.},
  archive      = {J_AIR},
  author       = {Zhang, Min and Wang, Jie-Sheng and Hou, Jia-Ning and Song, Hao-Ming and Li, Xu-Dong and Guo, Fu-Jun},
  doi          = {10.1007/s10462-022-10333-y},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {6509-6556},
  shortjournal = {Artif. Intell. Rev.},
  title        = {RG-NBEO: A ReliefF guided novel binary equilibrium optimizer with opposition-based S-shaped and V-shaped transfer functions for feature selection},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Boundary of a fuzzy set and its application in GIS: A
review. <em>AIR</em>, <em>56</em>(7), 6477–6507. (<a
href="https://doi.org/10.1007/s10462-022-10331-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The boundary of a fuzzy set is an important topic that is defined using the concepts of fuzzy topology. The inherent vagueness in the fuzzy sets allows researchers to construct various definitions of the fuzzy boundary. The fuzzy boundary is not only crucial for the theoretical purpose, it is also used to express uncertain geographical objects in geographical information systems (GIS). Specifically, the fuzzy boundary is used for constructing algebraic models such as fuzzy 9 and 16-intersection matrices, which evaluate the topological relation between two uncertain geographical objects. Considering that, this paper analyzes the concept of the fuzzy boundary of a set in the fuzzy topological space. Next, several algebraic models where the fuzzy boundary has been used for analyzing the spatial objects are discussed.},
  archive      = {J_AIR},
  author       = {Jana, Subhankar and Mahanta, Juthika},
  doi          = {10.1007/s10462-022-10331-0},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {6477-6507},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Boundary of a fuzzy set and its application in GIS: A review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data clustering: Application and trends. <em>AIR</em>,
<em>56</em>(7), 6439–6475. (<a
href="https://doi.org/10.1007/s10462-022-10325-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering has primarily been used as an analytical technique to group unlabeled data for extracting meaningful information. The fact that no clustering algorithm can solve all clustering problems has resulted in the development of several clustering algorithms with diverse applications. We review data clustering, intending to underscore recent applications in selected industrial sectors and other notable concepts. In this paper, we begin by highlighting clustering components and discussing classification terminologies. Furthermore, specific, and general applications of clustering are discussed. Notable concepts on clustering algorithms, emerging variants, measures of similarities/dissimilarities, issues surrounding clustering optimization, validation and data types are outlined. Suggestions are made to emphasize the continued interest in clustering techniques both by scholars and Industry practitioners. Key findings in this review show the size of data as a classification criterion and as data sizes for clustering become larger and varied, the determination of the optimal number of clusters will require new feature extracting methods, validation indices and clustering techniques. In addition, clustering techniques have found growing use in key industry sectors linked to the sustainable development goals such as manufacturing, transportation and logistics, energy, and healthcare, where the use of clustering is more integrated with other analytical techniques than a stand-alone clustering technique.},
  archive      = {J_AIR},
  author       = {Oyewole, Gbeminiyi John and Thopil, George Alex},
  doi          = {10.1007/s10462-022-10325-y},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {6439-6475},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Data clustering: Application and trends},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A three-way decision method with tolerance dominance
relations in decision information systems. <em>AIR</em>, <em>56</em>(7),
6403–6438. (<a
href="https://doi.org/10.1007/s10462-022-10311-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, various medical diagnosis problems have been addressed from the perspective of multi-attribute decision making. Among them, the three-way decision theory can provide a novel scheme to solve medical diagnosis issues under the framework of multi-attribute decision making via considering transforming relationships between loss functions and decision matrices. In this paper, we primarily explore a three-way decision method with tolerance dominance relations in ordered decision information systems. In existing three-way decision models, all objects can be divided into two states, we utilize decision attributes to obtain the set of two states in ordered decision information systems. Then, in order to improve the accuracy of patient classifications, the paper simultaneously considers the influence of loss and gain functions for each object, and uses loss and gain functions to obtain net profit functions as new measurement functions. Meanwhile, a class of three-way decisions in terms of multi-attribute decision making rules based on a tolerance dominance relation is established. In light of the proposed three-way decision method, we further construct a multi-attribute decision making method by using tolerance dominance relations and the constructed method is applied to a medical diagnosis issue of Lymphography. Finally, a comparison analysis and an experimental evaluation are performed to illustrate the feasibility and effectiveness of the presented methodology.},
  archive      = {J_AIR},
  author       = {Wang, Wenjie and Zhan, Jianming and Ding, Weiping and Wan, Shuping},
  doi          = {10.1007/s10462-022-10311-4},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {6403-6438},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A three-way decision method with tolerance dominance relations in decision information systems},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combining neural computation and genetic programming for
observational causality detection and causal modelling. <em>AIR</em>,
<em>56</em>(7), 6365–6401. (<a
href="https://doi.org/10.1007/s10462-022-10320-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A methodology, to determine the causal relations between time series and to derive the set of equations describing the interacting systems, has been developed. The techniques proposed are completely data driven and they are based on ensembles of Time Delay Neural Networks (TDNNs) and Symbolic Regression (SR) via Genetic Programming (GP). With regard to the detection of the causal influences and the identification of graphical causal networks, the developed tools have better performances than those reported in the literature. For example, the TDNN ensembles can cope with evolving systems, non-Markovianity, feedback loops and multicausality. In its turn, on the basis of the information derived from the TDNN ensembles, SR via GP permits to identify the set of equations, i.e. the detailed model of the interacting systems. Numerical tests and real life examples from various disciplines prove the power and versatility of the developed tools, capable of handling tens of time series and even images. The excellent results obtained emphasize the importance of recording the time evolution of signals, which would allow a much better understanding of many issues, ranging from the physical to the social and medical sciences.},
  archive      = {J_AIR},
  author       = {Murari, Andrea and Rossi, Riccardo and Gelfusa, Michela},
  doi          = {10.1007/s10462-022-10320-3},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {6365-6401},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Combining neural computation and genetic programming for observational causality detection and causal modelling},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of graph neural networks in various learning
paradigms: Methods, applications, and challenges. <em>AIR</em>,
<em>56</em>(7), 6295–6364. (<a
href="https://doi.org/10.1007/s10462-022-10321-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decade, deep learning has reinvigorated the machine learning field. It has solved many problems in computer vision, speech recognition, natural language processing, and other domains with state-of-the-art performances. In these domains, the data is generally represented in the Euclidean space. Various other domains conform to non-Euclidean space, for which a graph is an ideal representation. Graphs are suitable for representing the dependencies and inter-relationships between various entities. Traditionally, handcrafted features for graphs are incapable of providing the necessary inference for various tasks from this complex data representation. Recently, there has been an emergence of employing various advances in deep learning for graph-based tasks (called Graph Neural Networks (GNNs)). This article introduces preliminary knowledge regarding GNNs and comprehensively surveys GNNs in different learning paradigms—supervised, unsupervised, semi-supervised, self-supervised, and few-shot or meta-learning. The taxonomy of each graph-based learning setting is provided with logical divisions of methods falling in the given learning setting. The approaches for each learning task are analyzed from theoretical and empirical standpoints. Further, we provide general architecture design guidelines for building GNN models. Various applications and benchmark datasets are also provided, along with open challenges still plaguing the general applicability of GNNs.},
  archive      = {J_AIR},
  author       = {Waikhom, Lilapati and Patgiri, Ripon},
  doi          = {10.1007/s10462-022-10321-2},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {6295-6364},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of graph neural networks in various learning paradigms: Methods, applications, and challenges},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An introduction to grey causal modelling (GCM): Applications
to manufacturing, supply chains, resilience, and sustainability.
<em>AIR</em>, <em>56</em>(7), 6267–6293. (<a
href="https://doi.org/10.1007/s10462-022-10314-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantitative causal modelling techniques assumes great prominence in any manufacturing or supply chain environments. A novel causal modelling technique, the Grey Causal Modelling (GCM) is proposed in this research that can model complex causal relationships in a system. The GCM technique, as illustrated in this study can consider four features in a complex causal modelling situation, which are characterised as; the events, the outcomes, the objectives, and the effects. The implementation of the proposed methodology involves a two-phase approach and the same needs evaluation data from experts in two stages. We also propose the idea of magnitude plots to quantify and represent the cause-consequence (event-outcome) relations in GCM. The application of GCM technique is demonstrated with two numerical examples in manufacturing environment. Also, a practical problem for achieving resilience and sustainability objectives in a case supply chain is solved. The methodology is implemented following a seven step procedure for the case, which briefly include; identification of key factors, obtain the influence ratings, separate the events and outcomes, rank the event-outcome pairs for each objectives, calculate the effects for situation sets, obtain the magnitude of effects and make the magnitude plots, and build the causal magnitude table and prioritise the causal factors. From the analysis of results of the case, it is seen that redundancy and adaptability emerge as the critical causal factors for the supply chain in consideration of resilience and sustainability objectives, together. The GCM technique, as proposed in this research will be useful for practitioners in manufacturing, supply chains, and in other areas such as; management, social sciences, and natural sciences, as they can analyze complex cause-consequence relationships among factors in a system.},
  archive      = {J_AIR},
  author       = {Rajesh, R.},
  doi          = {10.1007/s10462-022-10314-1},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {6267-6293},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An introduction to grey causal modelling (GCM): Applications to manufacturing, supply chains, resilience, and sustainability},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge representation and reasoning using fuzzy petri
nets: A literature review and bibliometric analysis. <em>AIR</em>,
<em>56</em>(7), 6241–6265. (<a
href="https://doi.org/10.1007/s10462-022-10312-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy Petri nets (FPNs) are a powerful modeling tool for the knowledge representation and reasoning of expert systems. During the past decades, a variety of models and methods have been developed to improve the performance of FPNs. However, there is a lack of a comprehensive bibliometric analysis of the literature on the FPN topic. The objective of this paper is to conduct a bibliometric analysis of the FPN studies to generate a global picture of developments, focus areas, and research trends in this field. To achieve this goal, 272 journal articles extracted from the Web of Science over the period of 2000 to 2022 were analyzed with respect to cooperation network, co-citation network, and keyword co-occurrence network. The findings indicate that annual publication on the FPNs has increased rapidly since 2018. The cooperation network analysis shows that the most prolific authors in the area are Hu-Chen Liu from Tongji University and Victor R. L. Shen from National Taipei University. Via the co-citation network analysis, the influential authors are identified as Shyi-Ming Chen, Carl G. Looney, Tadao Murata, and the emerging research trends are obtained as “fault diagnosis”, “failure mode and effect analysis”, and “knowledge representation”. The keyword network analysis shows that the hot research topics in the FPN area are “expert system”, “knowledge representation”, “fault diagnosis” and “fuzzy reasoning”. Finally, according to the current research trends, possible future research directions concerning FPNs are revealed. This study provides important reference for both scholars and practitioners to grasp the research status, hot topics, and future research agenda of the FPN domain.},
  archive      = {J_AIR},
  author       = {Yu, Ya-Xuan and Gong, Hua-Ping and Liu, Hu-Chen and Mou, Xun},
  doi          = {10.1007/s10462-022-10312-3},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {6241-6265},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Knowledge representation and reasoning using fuzzy petri nets: A literature review and bibliometric analysis},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hardware implementation of SLAM algorithms: A survey on
implementation approaches and platforms. <em>AIR</em>, <em>56</em>(7),
6187–6239. (<a
href="https://doi.org/10.1007/s10462-022-10310-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous localization and mapping (SLAM) is an active research topic in machine vision and robotics. It has various applications in many different fields such as mobile robots, augmented and virtual reality, medical imaging, image-guided surgery systems, and unmanned aerial vehicles (UAVs). The computational complexity of SLAM algorithms is very high. Therefore, in many applications, it is necessary to implement them in real-time on platforms with low power consumption and small sizes. This paper reviews the implementation and the performance of SLAM algorithms on various platforms. Although there are various review studies on SLAM algorithms, the studies assessing the hardware implementation of these algorithms are very limited. This study attempts to fill this gap. It is shown that using the hardware–software (HW/SW) co-design approaches over mere Software (SW) or hardware (HW) approaches is currently the primary option for implementing SLAM algorithms on hardware platforms. A combination of a hardware accelerator and a software approach increases the speed of the implementation as well as the performance and the speed of the algorithm. Also, dividing different parts of the algorithm according to the structure and the nature of the algorithm between hardware and software in the HW/SW co-design approaches reduces the resource consumption and the cost. Furthermore, the design of hardware-compatible algorithms is one of the most critical gaps in the implementation of SLAM algorithms on hardware platforms.},
  archive      = {J_AIR},
  author       = {Eyvazpour, Reza and Shoaran, Maryam and Karimian, Ghader},
  doi          = {10.1007/s10462-022-10310-5},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {6187-6239},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Hardware implementation of SLAM algorithms: A survey on implementation approaches and platforms},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-spectral palmprint fuzzy commitment based on deep
hashing code with discriminative bit selection. <em>AIR</em>,
<em>56</em>(7), 6169–6186. (<a
href="https://doi.org/10.1007/s10462-022-10334-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Direct usage of original biometric features/templates definitely leads to serious privacy leakage. In biometric cryptosystems, a biometric key is generated and then strictly protected with a one-way function. However, it is highly difficult to balance the template size and accuracy. Palmprint has many remarkable strengths, so it is considered as a promising biometric modality. In our previous work, deep hashing network (DHN) was leveraged to extract discriminative deep hashing code (DHC) of palmprint. In this paper, a palmprint fuzzy commitment (FC) is proposed based on DHC. A palmprint FC is proposed based on DHC. The DHC has high accuracy, small size, strong robustness, and is free from shift-matching for dislocation problems, so the proposed palmprint FC can satisfactorily balance the accuracy, storage cost and computational complexity. In addition, the DHCs of multi-spectral palmprints are concatenated and the bits are selected according to discrimination power analysis, so the accuracy is further improved. The sufficient experimental results show that, when B, N and R spectrums are fused and only 292 bits are selected, EER can be 0.0001\%.},
  archive      = {J_AIR},
  author       = {Wu, Tengfei and Leng, Lu and Khan, Muhammad Khurram},
  doi          = {10.1007/s10462-022-10334-x},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {6169-6186},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A multi-spectral palmprint fuzzy commitment based on deep hashing code with discriminative bit selection},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on binary metaheuristic algorithms and their
engineering applications. <em>AIR</em>, <em>56</em>(7), 6101–6167. (<a
href="https://doi.org/10.1007/s10462-022-10328-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a comprehensively state-of-the-art investigation of the engineering applications utilized by binary metaheuristic algorithms. Surveyed work is categorized based on application scenarios and solution encoding, and describes these algorithms in detail to help researchers choose appropriate methods to solve related applications. It is seen that transfer function is the main binary coding of metaheuristic algorithms, which usually adopts Sigmoid function. Among the contributions presented, there were different implementations and applications of metaheuristic algorithms, or the study of engineering applications by different objective functions such as the single- and multi-objective problems of feature selection, scheduling, layout and engineering structure optimization. The article identifies current troubles and challenges by the conducted review, and discusses that novel binary algorithm, transfer function, benchmark function, time-consuming problem and application integration are need to be resolved in future.},
  archive      = {J_AIR},
  author       = {Pan, Jeng-Shyang and Hu, Pei and Snášel, Václav and Chu, Shu-Chuan},
  doi          = {10.1007/s10462-022-10328-9},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {6101-6167},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey on binary metaheuristic algorithms and their engineering applications},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Three-way conflict analysis based on interval-valued
pythagorean fuzzy sets and prospect theory. <em>AIR</em>,
<em>56</em>(7), 6061–6099. (<a
href="https://doi.org/10.1007/s10462-022-10327-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conflict analysis gives guidelines for conflict resolution, which has been thoroughly studied and received widespread interest. Three-way conflict analysis research has achieved remarkable results and has been extended to Pythagorean fuzzy information systems because the three-way decision coincides with three attitudes of agents on issues, where the positive and negative degrees of agents are depicted by the membership and non-membership degrees. However, agent’s opinions on issues must not be expressed only by real numbers, and the form of ranges can be used. Interval-valued Pythagorean fuzzy sets allow the membership and non-membership degrees of a given set to have interval values, which can effectively handle this problem. This work analyzes a three-way conflict analysis based on interval-valued Pythagorean fuzzy information systems. First, we introduce the concept of interval-valued Pythagorean fuzzy information systems and illustrate how to divide positive, neutral, and negative alliances by the measurement function and thresholds. Then, we focus on a three-way conflict analysis based on prospect theory by considering the subjective risk attitude and preference of decision-makers. Finally, we further investigate three-way conflict analysis based on interval-valued Pythagorean fuzzy sets and prospect theory with group decision theory, where the outcome matrices are provided by multiple experts. Several examples of software development project team conflicts are employed to illustrate the process of conducting a three-way conflict analysis based on interval-valued Pythagorean fuzzy information systems and prospect theory. The comparative analysis is utilized to show the effectiveness and superiority of the proposed three-way conflict analysis approach compared with other models and methods.},
  archive      = {J_AIR},
  author       = {Wang, Tianxing and Zhang, Libo and Huang, Bing and Zhou, Xianzhong},
  doi          = {10.1007/s10462-022-10327-w},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {6061-6099},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Three-way conflict analysis based on interval-valued pythagorean fuzzy sets and prospect theory},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detecting persian speaker-independent voice commands based
on LSTM and ontology in communicating with the smart home appliances.
<em>AIR</em>, <em>56</em>(7), 6039–6060. (<a
href="https://doi.org/10.1007/s10462-022-10326-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, various interfaces are used to control smart home appliances. The human and smart home appliances interaction may be based on input devices such as a mouse, keyboard, microphone, or webcam. The interaction between humans and machines can be established via speech using a microphone as one of the input modes. The Speech-based human and machine interaction is a more natural way of communication in comparison to other types of interfaces. Existing speech-based interfaces in the smart home domain suffer from some problems such as limiting the users to use a fixed set of pre-defined commands, not supporting indirect commands, requiring a large training set, or depending on some specific speakers. To solve these challenges, we proposed several approaches in this paper. We exploited ontology as a knowledge base to support indirect commands and remove user restrictions on expressing a specific set of commands. Moreover, Long Short-Term Memory (LSTM) has been exploited for detecting spoken commands more accurately. Additionally, due to the lack of Persian voice commands for interacting with smart home appliances, a dataset of speaker-independent Persian voice commands for communicating with TV, media player, and lighting system has been designed, recorded, and evaluated in this research. The experimental results show that the LSTM-based voice command detection system performed almost 1.5\% and 13\% more accurately than the Hidden Markov Model-based one, in scenarios ‘with’ and ‘without ontology’, respectively. Furthermore, using ontology in the LSTM-based method has improved the system performance by about 40\%.},
  archive      = {J_AIR},
  author       = {Kalkhoran, Leila Safarpoor and Tabibian, Shima and Homayounvala, Elaheh},
  doi          = {10.1007/s10462-022-10326-x},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {6039-6060},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Detecting persian speaker-independent voice commands based on LSTM and ontology in communicating with the smart home appliances},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning in drug discovery: An integrative review and
future challenges. <em>AIR</em>, <em>56</em>(7), 5975–6037. (<a
href="https://doi.org/10.1007/s10462-022-10306-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, using artificial intelligence (AI) in drug discovery has received much attention since it significantly shortens the time and cost of developing new drugs. Deep learning (DL)-based approaches are increasingly being used in all stages of drug development as DL technology advances, and drug-related data grows. Therefore, this paper presents a systematic Literature review (SLR) that integrates the recent DL technologies and applications in drug discovery Including, drug–target interactions (DTIs), drug–drug similarity interactions (DDIs), drug sensitivity and responsiveness, and drug-side effect predictions. We present a review of more than 300 articles between 2000 and 2022. The benchmark data sets, the databases, and the evaluation measures are also presented. In addition, this paper provides an overview of how explainable AI (XAI) supports drug discovery problems. The drug dosing optimization and success stories are discussed as well. Finally, digital twining (DT) and open issues are suggested as future research challenges for drug discovery problems. Challenges to be addressed, future research directions are identified, and an extensive bibliography is also included.},
  archive      = {J_AIR},
  author       = {Askr, Heba and Elgeldawi, Enas and Aboul Ella, Heba and Elshaier, Yaseen A. M. M. and Gomaa, Mamdouh M. and Hassanien, Aboul Ella},
  doi          = {10.1007/s10462-022-10306-1},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5975-6037},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep learning in drug discovery: An integrative review and future challenges},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Image denoising in the deep learning era. <em>AIR</em>,
<em>56</em>(7), 5929–5974. (<a
href="https://doi.org/10.1007/s10462-022-10305-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last decade, the number of digital images captured per day has increased exponentially, due to the accessibility of imaging devices. The visual quality of photographs captured by low cost or miniaturized imaging devices is often degraded by noise during image acquisition and data transmission. With the re-emergence of deep neural networks, the performance of image denoising techniques has been substantially improved in recent years. The objective of this paper is to provide a comprehensive survey of recent advances in image denoising techniques based on deep neural networks. We begin with a thorough description of the fundamental preliminaries of the image denoising problem, followed by an overview of the benchmark datasets and commonly used metrics for objective assessment of denoising algorithms. We study the existing deep denoisers in the supervised and unsupervised training paradigms and review the technical specifics of some representative methods within each category. We conclude the survey by remarking on trends and challenges in the development of state-of-the-art algorithms and future research.},
  archive      = {J_AIR},
  author       = {Izadi, Saeed and Sutton, Darren and Hamarneh, Ghassan},
  doi          = {10.1007/s10462-022-10305-2},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5929-5974},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Image denoising in the deep learning era},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). New constructions of decision evaluation functions in
three-way decision spaces based on uninorms. <em>AIR</em>,
<em>56</em>(7), 5881–5927. (<a
href="https://doi.org/10.1007/s10462-022-10316-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 2014, Hu introduced the concept of three-way decision spaces and axiomatic definition of decision evaluation functions. In three-way decision spaces, decision evaluation function satisfies minimum element axiom, monotonicity axiom and complement axiom. Since then, the research on construction method of decision evaluation functions from commonly used binary aggregation functions becomes a research hotspot. Meanwhile, uninorms, as one class of binary aggregation functions, have been successfully applied in various application problems, such as in decision making, image processing, data mining, etc. This paper continues to consider this research topic and mainly explores the new construction methods of decision evaluation functions based on uninorms. Firstly, we show two novel transformation methods from semi-decision evaluation functions to decision evaluation functions based on uninorms. Secondly, using known semi-decision evaluation functions, we give some new construction methods of semi-decision evaluation functions. Thirdly, we give some novel construction methods of decision evaluation functions and semi-decision evaluation functions related to fuzzy sets, interval-valued fuzzy sets, fuzzy relations and hesitant fuzzy sets. Based on them, decision maker can obtain more useful decision evaluation functions, thereby more choices can be used for realistic decision-making problems. Finally, we consider two real evaluation problems to illustrate the results obtained in this paper. The three-way decisions results of evaluation problem show that the construction method proposed in this paper is superior to some existing construction methods under some conditions.},
  archive      = {J_AIR},
  author       = {Jia, Zihang and Qiao, Junsheng},
  doi          = {10.1007/s10462-022-10316-z},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5881-5927},
  shortjournal = {Artif. Intell. Rev.},
  title        = {New constructions of decision evaluation functions in three-way decision spaces based on uninorms},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Conventional and contemporary approaches used in text to
speech synthesis: A review. <em>AIR</em>, <em>56</em>(7), 5837–5880. (<a
href="https://doi.org/10.1007/s10462-022-10315-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays speech synthesis or text to speech (TTS), an ability of system to produce human like natural sounding voice from the written text, is gaining popularity in the field of speech processing. For any TTS, intelligibility and naturalness are the two important measures for defining the quality of a synthesized sound which is highly dependent on the prosody modeling using acoustic model of synthesizer. The purpose of this review survey is firstly to study and analyze the various approaches used traditionally (articulatory synthesis, formant synthesis, concatenative speech synthesis and statistical parametric techniques based on hidden Markov model) and recently (statistical parametric based on deep learning approaches) for acoustic modeling with their pros and cons. The approaches based on deep learning to build the acoustic model has significantly contributed to the advancement of TTS as models based on deep learning are capable of modelling the complex context dependencies in the input data. Apart from these, this article also reviews the TTS approaches for generating speech with different voices and emotions to makes the TTS more realistic to use. It also addresses the subjective and objective metrics used to measure the quality of the synthesized voice. Various well known speech synthesis systems based on autoregressive and non-autoregressive models such as Tacotron, Deep Voice, WaveNet, Parallel WaveNet, Parallel Tacotron, FastSpeech by global tech-giant Google, Facebook, Microsoft employed the architecture of deep learning for end-to-end speech waveform generation and attained a remarkable mean opinion score (MOS).},
  archive      = {J_AIR},
  author       = {Kaur, Navdeep and Singh, Parminder},
  doi          = {10.1007/s10462-022-10315-0},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5837-5880},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Conventional and contemporary approaches used in text to speech synthesis: A review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application of machine learning methods in fault detection
and classification of power transmission lines: A survey. <em>AIR</em>,
<em>56</em>(7), 5799–5836. (<a
href="https://doi.org/10.1007/s10462-022-10296-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rising development of power systems and smart grids calls for advanced fault diagnosis techniques to prevent undesired interruptions and expenses. One of the most important part of such systems is transmission lines. This paper presents a survey on recent machine learning-based techniques for fault detection, classification, and location estimation in transmission lines. In order to provide reliable and resilient electrical power energy, faster and more accurate fault identification tools are required. Costly consequences of probable faults motivate the need for immediate actions to detect them using intelligent methods, especially emerging machine learning approaches that are powerful in solving diagnosis problems. This paper presents a comprehensive review of various machine learning methodologies including naive Bayesian classifier, decision tree, random forest, k-nearest neighbor, and support vector machine as well as artificial neural networks such as feedforward neural network, convolutional neural network, and adaptive neuro-fuzzy inference system that have been used to detect, classify, and locate faults in transmission lines.},
  archive      = {J_AIR},
  author       = {Shakiba, Fatemeh Mohammadi and Azizi, S. Mohsen and Zhou, Mengchu and Abusorrah, Abdullah},
  doi          = {10.1007/s10462-022-10296-0},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5799-5836},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Application of machine learning methods in fault detection and classification of power transmission lines: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A quantitative and qualitative hybrid attributes based
imbalanced group conflict analysis method and its application to
evaluation of clinical therapeutic effect. <em>AIR</em>, <em>56</em>(6),
5773–5798. (<a
href="https://doi.org/10.1007/s10462-022-10301-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The clinical decision-making is a group decision-making process given by the imbalanced decision-making groups, which has hybrid quantitative and qualitative attributes. Data-driven decision-making paradigm is a novel idea for constructing a clinical quantitative decision-making model. The conflict analysis provides an effective method for managing the imbalanced group decision-making problems with hybrid attributes. In this paper, we consider a kind of imbalanced group confilct problems with hybrid quantitative and qualitative attributes information given by large and small groups and use three-way conflict analysis to solve these problems. First, a hybrid information system is repersented the qualitative and quantitative hybrid attribute information given by large and small groups. Further, the real-value information system consisting of hybrid quantitative and qualitative attributes information given by this imbalanced group is transformed into a 19-scale conflict information system. Then, the optimal alternatives are derived by measuring group conflict degree, conflict function, and group conflict measurement in a three-way conflict framework. Finally, the clinical decision-making problem of rheumatoid arthritis treated with integrated TCM and Western medicine clinic as the research object, the conflict analysis process and steps of the theoretical model constructed in this paper are validated and explicitly applied based on the actual clinical data of Guangdong Provincial Hospital of Chinese Medicine, furthermore the quantitative conflict analysis simulated by actual clinical data is given, which obtains application results that are almost consistent with real clinical scenarios. On the one hand, the paper’s research extends a novel conflict analysis model and idea for the group conflict analysis with imbalanced, quantitative, and qualitative hybrid information attributes. On the other hand, it also provides a new attempt and exploration for applyling of three-way conflict analysis in clinical decisions.},
  archive      = {J_AIR},
  author       = {Chu, Xiaoli and Sun, Bingzhen and Chu, Xiaodong and Zhang, Yan and Huang, Qingchun and Cai, Jianxiong},
  doi          = {10.1007/s10462-022-10301-6},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {5773-5798},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A quantitative and qualitative hybrid attributes based imbalanced group conflict analysis method and its application to evaluation of clinical therapeutic effect},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Smart farming prediction models for precision agriculture: A
comprehensive survey. <em>AIR</em>, <em>56</em>(6), 5729–5772. (<a
href="https://doi.org/10.1007/s10462-022-10266-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the variability of the farming resources such as soil, fertilizer and weather conditions including crops. Proper utilization of these resources for high yield is paramount. Since practices based on human experience lead to low crop yield, especially the inconsistent climate condition. Though, the advent of smart farming and precision agriculture driven by machine learning provides an avenue for automated solutions to this problem. Therefore, this article provides a comprehensive survey of the existing smart farming models for precision agriculture. The survey focused on machine learning approaches such as supervised, unsupervised, deep learning and ensemble techniques employed in smart farming. In addition, smart farming innovations for predicting key agrarian practices such as soil, crop yield, and fertilizer including weather and irrigation models were reviewed. Thus, poor performance of some models is observed and attributed to the dataset used, negligence of pre-processing and feature extraction stages by some researchers. Consequently, the survey projected a machine learning procedure that if duly followed would prevent such limitations in smart farming models. This survey has demonstrated how machine learning can automate agricultural practices and enhance crop quantity and quality with minimal human labour. It finally outlined the challenges and prospects of smart farming models for researchers to explore.},
  archive      = {J_AIR},
  author       = {Kwaghtyo, Dekera Kenneth and Eke, Christopher Ifeanyi},
  doi          = {10.1007/s10462-022-10266-6},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {5729-5772},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Smart farming prediction models for precision agriculture: A comprehensive survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on syntactic processing techniques. <em>AIR</em>,
<em>56</em>(6), 5645–5728. (<a
href="https://doi.org/10.1007/s10462-022-10300-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational syntactic processing is a fundamental technique in natural language processing. It normally serves as a pre-processing method to transform natural language into structured and normalized texts, yielding syntactic features for downstream task learning. In this work, we propose a systematic survey of low-level syntactic processing techniques, namely: microtext normalization, sentence boundary disambiguation, part-of-speech tagging, text chunking, and lemmatization. We summarize and categorize widely used methods in the aforementioned syntactic analysis tasks, investigate the challenges, and yield possible research directions to overcome the challenges in future work.},
  archive      = {J_AIR},
  author       = {Zhang, Xulang and Mao, Rui and Cambria, Erik},
  doi          = {10.1007/s10462-022-10300-7},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {5645-5728},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey on syntactic processing techniques},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Algorithmic trading with directional changes. <em>AIR</em>,
<em>56</em>(6), 5619–5644. (<a
href="https://doi.org/10.1007/s10462-022-10307-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Directional changes (DC) is a recent technique that summarises physical time data (e.g. daily closing prices, hourly data) into events, offering traders a unique perspective of the market to create novel trading strategies. This paper proposes the use of a genetic algorithm (GA) to optimize the recommendations of multiple DC-based trading strategies. Each trading strategy uses a novel framework that combines classification and regression techniques to predict when a trend will reverse. We evaluate the performance of the proposed multiple DC-strategy GA algorithm against nine benchmarks: five single DC-based trading strategies, three technical analysis indicators, as well as buy-and-hold, which is a popular financial benchmark. We perform experiments using 200 monthly physical time datasets from 20 foreign exchange markets—these datasets were created from snapshots of 10 min intervals. Experimental results show that our proposed algorithm is able to statistically significantly outperform all DC and non-DC benchmarks in terms of both return and risk, and establish multi-threshold DCs as an effective algorithmic trading technique.},
  archive      = {J_AIR},
  author       = {Adegboye, Adesola and Kampouridis, Michael and Otero, Fernando},
  doi          = {10.1007/s10462-022-10307-0},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {5619-5644},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Algorithmic trading with directional changes},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence for suicide assessment using
audiovisual cues: A review. <em>AIR</em>, <em>56</em>(6), 5591–5618. (<a
href="https://doi.org/10.1007/s10462-022-10290-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Death by suicide is the seventh leading death cause worldwide. The recent advancement in Artificial Intelligence (AI), specifically AI applications in image and voice processing, has created a promising opportunity to revolutionize suicide risk assessment. Subsequently, we have witnessed fast-growing literature of research that applies AI to extract audiovisual non-verbal cues for mental illness assessment. However, the majority of the recent works focus on depression, despite the evident difference between depression symptoms and suicidal behavior non-verbal cues. In this paper, we review the recent works that study suicide ideation and suicide behavior detection through audiovisual feature analysis, mainly suicidal voice/speech acoustic features analysis and suicidal visual cues. Automatic suicide assessment is a promising research direction that is still in the early stages. Accordingly, there is a lack of large datasets that can be used to train machine leaning and deep learning models proven to be effective in other, similar tasks.},
  archive      = {J_AIR},
  author       = {Dhelim, Sahraoui and Chen, Liming and Ning, Huansheng and Nugent, Chris},
  doi          = {10.1007/s10462-022-10290-6},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {5591-5618},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Artificial intelligence for suicide assessment using audiovisual cues: A review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on ensemble learning under the era of deep
learning. <em>AIR</em>, <em>56</em>(6), 5545–5589. (<a
href="https://doi.org/10.1007/s10462-022-10283-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the dominant position of deep learning (mostly deep neural networks) in various artificial intelligence applications, recently, ensemble learning based on deep neural networks (ensemble deep learning) has shown significant performances in improving the generalization of learning system. However, since modern deep neural networks usually have millions to billions of parameters, the time and space overheads for training multiple base deep learners and testing with the ensemble deep learner are far greater than that of traditional ensemble learning. Though several algorithms of fast ensemble deep learning have been proposed to promote the deployment of ensemble deep learning in some applications, further advances still need to be made for many applications in specific fields, where the developing time and computing resources are usually restricted or the data to be processed is of large dimensionality. An urgent problem needs to be solved is how to take the significant advantages of ensemble deep learning while reduce the required expenses so that many more applications in specific fields can benefit from it. For the alleviation of this problem, it is essential to know about how ensemble learning has developed under the era of deep learning. Thus, in this article, we present discussions focusing on data analyses of published works, methodologies, recent advances and unattainability of traditional ensemble learning and ensemble deep learning. We hope this article will be helpful to realize the intrinsic problems and technical challenges faced by future developments of ensemble learning under the era of deep learning.},
  archive      = {J_AIR},
  author       = {Yang, Yongquan and Lv, Haijun and Chen, Ning},
  doi          = {10.1007/s10462-022-10283-5},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {5545-5589},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey on ensemble learning under the era of deep learning},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantum-inspired metaheuristic algorithms: Comprehensive
survey and classification. <em>AIR</em>, <em>56</em>(6), 5479–5543. (<a
href="https://doi.org/10.1007/s10462-022-10280-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristic algorithms are widely known as efficient solutions for solving problems of optimization. These algorithms supply powerful instruments with significant engineering, industry, and science applications. The Quantum-inspired metaheuristic algorithms were developed by integrating Quantum Computing (QC) concepts into metaheuristic algorithms. The QC-inspired metaheuristic algorithms solve combinational and numerical optimization problems to achieve higher-performing results than conventional metaheuristic algorithms. The QC is used more than any other strategy for accelerating convergence, enhancing exploration, and exploitation, significantly influencing metaheuristic algorithms’ performance. The QC is a new field of research that includes elements from mathematics, physics, and computing. QC has attracted increasing attention among scientists, technologists, and industrialists. During the current decade, it has provided a research platform for the scientific, technical, and industrial areas. In QC, metaheuristic algorithms can be improved by the parallel processing feature. This feature helps to find the best solutions for optimization problems. The Quantum-inspired metaheuristic algorithms have been used in the optimization fields. In this paper, a review of different usages of QC in metaheuristics has been presented. This review also shows a classification of the Quantum-inspired metaheuristic algorithms in optimization problems and discusses their applications in science and engineering. This review paper’s main aims are to give an overview and review the Quantum-inspired metaheuristic algorithms applications.},
  archive      = {J_AIR},
  author       = {Gharehchopogh, Farhad Soleimanian},
  doi          = {10.1007/s10462-022-10280-8},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {5479-5543},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Quantum-inspired metaheuristic algorithms: Comprehensive survey and classification},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tutorial on PCA and approximate PCA and approximate kernel
PCA. <em>AIR</em>, <em>56</em>(6), 5445–5477. (<a
href="https://doi.org/10.1007/s10462-022-10297-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Principal Component Analysis (PCA) is one of the most widely used data analysis methods in machine learning and AI. This manuscript focuses on the mathematical foundation of classical PCA and its application to a small-sample-size scenario and a large dataset in a high-dimensional space scenario. In particular, we discuss a simple method that can be used to approximate PCA in the latter case. This method can also help approximate kernel PCA or kernel PCA (KPCA) for a large-scale dataset. We hope this manuscript will give readers a solid foundation on PCA, approximate PCA, and approximate KPCA.},
  archive      = {J_AIR},
  author       = {Marukatat, Sanparith},
  doi          = {10.1007/s10462-022-10297-z},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {5445-5477},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Tutorial on PCA and approximate PCA and approximate kernel PCA},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Construction of multivalued cryptographic boolean function
using recurrent neural network and its application in image encryption
scheme. <em>AIR</em>, <em>56</em>(6), 5403–5443. (<a
href="https://doi.org/10.1007/s10462-022-10295-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The construction and development of new techniques for a nonlinear multivalued Boolean function is one of the important aspects of modern ciphers. These multivalued Boolean functions need to be defined over various algebraic structures which map multiple inputs on multiple outputs. Modern block ciphers are a combination of linear and nonlinear functions which adds diffusion and confusion capabilities. We have offered an innovative system for the construction of the confusion component of block cipher by using recurrent neural networks. Since the confusion component is a multivalued Boolean function, therefore, we need many to many types of recurrent networks with an equal number of inputs and outputs. With this scheme, we have achieved a standard benchmark nonlinear of 112 with balancednesss having low linear and differential probabilities. We evaluated some common and advanced measures for the eminence of randomness and cryptanalytics to observe the efficiency of the proposed methodology. These outcomes validated the generated nonlinear confusion components are effective for block ciphers and have better cryptographic strength in image encryption with a high signal-to-noise ratio in comparison to state-of-the-art techniques.},
  archive      = {J_AIR},
  author       = {Abughazalah, Nabilah and Latif, Asim and Hafiz, Muhammad Waseem and Khan, Majid and Alanazi, Ammar S. and Hussain, Iqtadar},
  doi          = {10.1007/s10462-022-10295-1},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {5403-5443},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Construction of multivalued cryptographic boolean function using recurrent neural network and its application in image encryption scheme},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LT-SMF: Long term stock market price trend prediction using
optimal hybrid machine learning technique. <em>AIR</em>, <em>56</em>(6),
5365–5402. (<a
href="https://doi.org/10.1007/s10462-022-10291-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock values are predicted using the market&#39;s biggest issues. Stock price data is hard to predict due to its distinct traits and volatility. Online news and comments reflect investor sentiment and thoughts on stocks, which may assist predict stock prices. Most authors lately recommended a statistical and environmental measurement-based technique for anticipating machine learning or stock price changes. These models struggle with changing data. We propose a hybrid machine learning technique for long-term stock market price trend prediction (LT-SMF). We employed improved butterfly optimization (IBO) to remove artefacts from input data. Scaling, polarising, and variation percentage are used to find valuable qualities. Second, a brown Planthopper optimization (BPO) approach reduces data dimensionality for optimal feature selection. To forecast stock market price variations, a hybrid FEL-DNN was utilized. Using 11 stock market indices and social media data, evaluate the LT-SMF model. Simulation performance was compared to state-of-the-art models for mean square error, mean bios error, mean absolute error, root mean square error, accuracy, precision, recall, and F-measure. The proposed FEL-DNN classifier outperforms the current state-of-the-art CNN3D, CNN3D − DR, LSTM − D, CNN3D + LSTM, CNN3D − D + LSTM, and CNN3D − DR + LSTM classifiers by 38.67\%, 41.71\%, 39.32\%, 36.04\%, 41.13\%, and 43.43\% respectively in terms of accuracy in the social media data.},
  archive      = {J_AIR},
  author       = {Venkateswararao, K. and Reddy, B. Venkata Ramana},
  doi          = {10.1007/s10462-022-10291-5},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {5365-5402},
  shortjournal = {Artif. Intell. Rev.},
  title        = {LT-SMF: Long term stock market price trend prediction using optimal hybrid machine learning technique},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Video restoration based on deep learning: A comprehensive
survey. <em>AIR</em>, <em>56</em>(6), 5317–5364. (<a
href="https://doi.org/10.1007/s10462-022-10302-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video restoration concerns the recovery of a clean video sequence starting from its degraded version. Different video restoration tasks exist, including denoising, deblurring, super-resolution, and reduction of compression artifacts. In this paper, we provide a comprehensive review of the main features of existing video restoration methods based on deep learning. We focus our attention on the main architectural components, strategies for motion handling, and loss functions. We analyze the standard benchmark datasets and use them to summarize the performance of video restoration methods, both in terms of effectiveness and efficiency. In conclusion, the main challenges and future research directions in video restoration using deep learning are highlighted.},
  archive      = {J_AIR},
  author       = {Rota, Claudio and Buzzelli, Marco and Bianco, Simone and Schettini, Raimondo},
  doi          = {10.1007/s10462-022-10302-5},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {5317-5364},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Video restoration based on deep learning: A comprehensive survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explainable AI for clinical and remote health applications:
A survey on tabular and time series data. <em>AIR</em>, <em>56</em>(6),
5261–5315. (<a
href="https://doi.org/10.1007/s10462-022-10304-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays Artificial Intelligence (AI) has become a fundamental component of healthcare applications, both clinical and remote, but the best performing AI systems are often too complex to be self-explaining. Explainable AI (XAI) techniques are defined to unveil the reasoning behind the system’s predictions and decisions, and they become even more critical when dealing with sensitive and personal health data. It is worth noting that XAI has not gathered the same attention across different research areas and data types, especially in healthcare. In particular, many clinical and remote health applications are based on tabular and time series data, respectively, and XAI is not commonly analysed on these data types, while computer vision and Natural Language Processing (NLP) are the reference applications. To provide an overview of XAI methods that are most suitable for tabular and time series data in the healthcare domain, this paper provides a review of the literature in the last 5 years, illustrating the type of generated explanations and the efforts provided to evaluate their relevance and quality. Specifically, we identify clinical validation, consistency assessment, objective and standardised quality evaluation, and human-centered quality assessment as key features to ensure effective explanations for the end users. Finally, we highlight the main research challenges in the field as well as the limitations of existing XAI methods.},
  archive      = {J_AIR},
  author       = {Di Martino, Flavio and Delmastro, Franca},
  doi          = {10.1007/s10462-022-10304-3},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {5261-5315},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Explainable AI for clinical and remote health applications: A survey on tabular and time series data},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Short text topic modelling approaches in the context of big
data: Taxonomy, survey, and analysis. <em>AIR</em>, <em>56</em>(6),
5133–5260. (<a
href="https://doi.org/10.1007/s10462-022-10254-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media platforms such as (Twitter, Facebook, and Weibo) are being increasingly embraced by individuals, groups, and organizations as a valuable source of information. This social media generated information comes in the form of tweets or posts, and normally characterized as short text, huge, sparse, and low density. Since many real-world applications need semantic interpretation of such short texts, research in Short Text Topic Modeling (STTM) has recently gained a lot of interest to reveal unique and cohesive latent topics. This article examines the current state of the art in STTM algorithms. It presents a comprehensive survey and taxonomy of STTM algorithms for short text topic modelling. The article also includes a qualitative and quantitative study of the STTM algorithms, as well as analyses of the various strengths and drawbacks of STTM techniques. Moreover, a comparative analysis of the topic quality and performance of representative STTM models is presented. The performance evaluation is conducted on two real-world Twitter datasets: the Real-World Pandemic Twitter (RW-Pand-Twitter) dataset and Real-world Cyberbullying Twitter (RW-CB-Twitter) dataset in terms of several metrics such as topic coherence, purity, NMI, and accuracy. Finally, the open challenges and future research directions in this promising field are discussed to highlight the trends of research in STTM. The work presented in this paper is useful for researchers interested in learning state-of-the-art short text topic modelling and researchers focusing on developing new algorithms for short text topic modelling.},
  archive      = {J_AIR},
  author       = {Murshed, Belal Abdullah Hezam and Mallappa, Suresha and Abawajy, Jemal and Saif, Mufeed Ahmed Naji and Al-ariki, Hasib Daowd Esmail and Abdulwahab, Hudhaifa Mohammed},
  doi          = {10.1007/s10462-022-10254-w},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {5133-5260},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Short text topic modelling approaches in the context of big data: Taxonomy, survey, and analysis},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of designing convolutional neural network using
evolutionary algorithms. <em>AIR</em>, <em>56</em>(6), 5095–5132. (<a
href="https://doi.org/10.1007/s10462-022-10303-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNN) are highly effective for image classification and computer vision activities. The accuracy of CNN architecture depends on the design and selection of optimal parameters. The number of parameters increases exponentially with every connected layer in deep CNN architecture. Therefore, the manual selection of efficient parameters entirely remains ad-hoc. To solve that problem, we must carefully examine the relationship between the depth of architecture, input parameters, and the model’s accuracy. The evolutionary algorithms are prominent in solving the challenges in architecture design and parameter selection. However, the adoption of evolutionary algorithms itself is a challenging task as the computation cost increases with its evolution. The performance of evolutionary algorithms depends on the type of encoding technique used to represent a CNN architecture. In this article, we presented a comprehensive study of the recent approaches involved in the design and training of CNN architecture. The advantages and disadvantages of selecting a CNN architecture using evolutionary algorithms are discussed. The manual architecture is compared against automated CNN architecture based on the accuracy and range of parameters in the existing benchmark datasets. Furthermore, we have discussed the ongoing issues and challenges involved in evolutionary algorithms-based CNN architecture design.},
  archive      = {J_AIR},
  author       = {Mishra, Vidyanand and Kane, Lalit},
  doi          = {10.1007/s10462-022-10303-4},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {5095-5132},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of designing convolutional neural network using evolutionary algorithms},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-dependence multi-label learning with double k for
missing labels. <em>AIR</em>, <em>56</em>(6), 5057–5094. (<a
href="https://doi.org/10.1007/s10462-022-10279-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label learning with missing labels is a challenging task, especially in text classification applications. Existing approaches considering label correlations are effective in recovering missing labels. However, they are often unstable because severely imbalanced positive and negative labels are treated in the same way. In this paper, we propose the self-dependence multi-label learning with a double k label recovery algorithm to address this issue. First, two label count matrices are constructed from the original label matrix from the perspective of positive and negative labels independently. This is done through statistics on the k nearest neighbors according to the input features. Second, positive and negative label matrices are decomposed and recovered using matrix factorization, namely double k (k nearest neighbors and k latent semantics). Third, new features are generated according to the recovered matrices by label concept. Fourth, we exploit the independence of the labels to guide the training process. Extensive experiments and analyses on multiple benchmark data sets illustrate the effectiveness of the proposed method. In addition, with the increase of missing labels, the stability of our algorithm becomes significantly better than the state-of-the-art ones.},
  archive      = {J_AIR},
  author       = {Qian, Kun and Min, Xue-Yang and Cheng, Yusheng and Song, Guojie and Min, Fan},
  doi          = {10.1007/s10462-022-10279-1},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {5057-5094},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Self-dependence multi-label learning with double k for missing labels},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep multiagent reinforcement learning: Challenges and
directions. <em>AIR</em>, <em>56</em>(6), 5023–5056. (<a
href="https://doi.org/10.1007/s10462-022-10299-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper surveys the field of deep multiagent reinforcement learning (RL). The combination of deep neural networks with RL has gained increased traction in recent years and is slowly shifting the focus from single-agent to multiagent environments. Dealing with multiple agents is inherently more complex as (a) the future rewards depend on multiple players’ joint actions and (b) the computational complexity increases. We present the most common multiagent problem representations and their main challenges, and identify five research areas that address one or more of these challenges: centralised training and decentralised execution, opponent modelling, communication, efficient coordination, and reward shaping. We find that many computational studies rely on unrealistic assumptions or are not generalisable to other settings; they struggle to overcome the curse of dimensionality or nonstationarity. Approaches from psychology and sociology capture promising relevant behaviours, such as communication and coordination, to help agents achieve better performance in multiagent settings. We suggest that, for multiagent RL to be successful, future research should address these challenges with an interdisciplinary approach to open up new possibilities in multiagent RL.},
  archive      = {J_AIR},
  author       = {Wong, Annie and Bäck, Thomas and Kononova, Anna V. and Plaat, Aske},
  doi          = {10.1007/s10462-022-10299-x},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {5023-5056},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep multiagent reinforcement learning: Challenges and directions},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AI-big data analytics for building automation and management
systems: A survey, actual challenges and future perspectives.
<em>AIR</em>, <em>56</em>(6), 4929–5021. (<a
href="https://doi.org/10.1007/s10462-022-10286-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In theory, building automation and management systems (BAMSs) can provide all the components and functionalities required for analyzing and operating buildings. However, in reality, these systems can only ensure the control of heating ventilation and air conditioning system systems. Therefore, many other tasks are left to the operator, e.g. evaluating buildings’ performance, detecting abnormal energy consumption, identifying the changes needed to improve efficiency, ensuring the security and privacy of end-users, etc. To that end, there has been a movement for developing artificial intelligence (AI) big data analytic tools as they offer various new and tailor-made solutions that are incredibly appropriate for practical buildings’ management. Typically, they can help the operator in (i) analyzing the tons of connected equipment data; and; (ii) making intelligent, efficient, and on-time decisions to improve the buildings’ performance. This paper presents a comprehensive systematic survey on using AI-big data analytics in BAMSs. It covers various AI-based tasks, e.g. load forecasting, water management, indoor environmental quality monitoring, occupancy detection, etc. The first part of this paper adopts a well-designed taxonomy to overview existing frameworks. A comprehensive review is conducted about different aspects, including the learning process, building environment, computing platforms, and application scenario. Moving on, a critical discussion is performed to identify current challenges. The second part aims at providing the reader with insights into the real-world application of AI-big data analytics. Thus, three case studies that demonstrate the use of AI-big data analytics in BAMSs are presented, focusing on energy anomaly detection in residential and office buildings and energy and performance optimization in sports facilities. Lastly, future directions and valuable recommendations are identified to improve the performance and reliability of BAMSs in intelligent buildings.},
  archive      = {J_AIR},
  author       = {Himeur, Yassine and Elnour, Mariam and Fadli, Fodil and Meskin, Nader and Petri, Ioan and Rezgui, Yacine and Bensaali, Faycal and Amira, Abbes},
  doi          = {10.1007/s10462-022-10286-2},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4929-5021},
  shortjournal = {Artif. Intell. Rev.},
  title        = {AI-big data analytics for building automation and management systems: A survey, actual challenges and future perspectives},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning, graph-based text representation and
classification: A survey, perspectives and challenges. <em>AIR</em>,
<em>56</em>(6), 4893–4927. (<a
href="https://doi.org/10.1007/s10462-022-10265-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, with the rapid developments of the Internet and social networks, there have been tremendous increase in the amount of complex-structured text resources. These information explosions require extensive studies as well as more advanced methods in order to better understand and effectively model/learn these high-dimensional/structure-complicated textual datasets. Moving along with the recent progresses in deep learning and textual representation learning approaches, many researchers in this domain have been attracted by utilizing different deep neural architectures for learning essential features from texts. These novel neural architectures must enable to handle complex textual feature engineering. Moreover, it also has to be able to extract deeper semantic and structural information from textual resources. Recently, there are several integrations between advanced deep learning architectures, such as recurrent neural networks (RNNs), sequence-to-sequence (seq2seq) and transformers in text classification have been proposed. These hybrid deep neural architectures have shed light on how computers can comprehensively process sequential information from texts to fine-tune for leveraging the performance of multiple tasks in natural language processing, including classification. However, most of recent RNN-based techniques still suffer from several limitations. These limitations are mainly related to the capability of capturing the global long-range dependent as well syntactical structures of the given text corpus. There are some recent studies have shown that a combination of graph-based text representation and graph neural network (GNN) approaches can cope with these challenges. In this survey works, we mainly focus on discussing about recent state-of-the-art studies which are mainly dedicated on the text graph representation learning through GNN, named as TG-GNN. In addition, beside the TG-GNN based models’ features and capability discussions, we also mentioned about the pros/cons. Extensive comparative studies of TG-GNN based techniques in benchmark datasets for text classification problem are also provided in this survey. Finally, we highlight existing challenges as well as identify perspectives which might be useful for future improvements in this research direction.},
  archive      = {J_AIR},
  author       = {Pham, Phu and Nguyen, Loan T. T. and Pedrycz, Witold and Vo, Bay},
  doi          = {10.1007/s10462-022-10265-7},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4893-4927},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep learning, graph-based text representation and classification: A survey, perspectives and challenges},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Non-rigid point set registration: Recent trends and
challenges. <em>AIR</em>, <em>56</em>(6), 4859–4891. (<a
href="https://doi.org/10.1007/s10462-022-10292-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-rigid point set registration has been used in a wide range of computer vision applications such as human movement tracking, medical image analysis, three dimensional (3D) object reconstruction and is a very challenging task. It has two fundamental tasks. One is to find correspondences between two or more point sets and another is to transform a point set so that it aligns with other point sets. There has been significant progress in the past two decades in the non-rigid registration field but it still has major challenges and is an active research area in the computer vision and pattern recognition community. In this review, we present a survey of non-rigid point set registration. Unlike recent surveys, we focus on the mathematical foundations of non-rigid registration methods, categorize the methods from several perspectives, and discuss open challenges. We categorize the methods according to correspondence models, motivations, and challenges such as deformation, data degradation, computational efficiency, and different constraints used in the methods to achieve accurate registration results. We present the publicly available data sets and different evaluation techniques employed in the methods. Further, we discuss open challenges, recent trends, and potential directions for future work in this area.},
  archive      = {J_AIR},
  author       = {Yuan, Xiaohui and Maharjan, Amar},
  doi          = {10.1007/s10462-022-10292-4},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4859-4891},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Non-rigid point set registration: Recent trends and challenges},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A comprehensive survey on the sine–cosine optimization
algorithm. <em>AIR</em>, <em>56</em>(6), 4801–4858. (<a
href="https://doi.org/10.1007/s10462-022-10277-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristic algorithms based on intelligent rules have been successfully developed and applied to solve many optimization areas over the past few decades. The sine–cosine algorithm (SCA) imitates the behaviour of transcendental functions while the sine and cosine functions are presented to explore and exploit the search space. SCA starts by random population and executes iterative evolution processes to update the standard evolutionary algorithm’s destination or the best location. SCA used linear transition rules to balance the exploration and exploitation searches while searching for the best or optimal solutions. Since Mirjalili proposed it in 2016, SCA has attracted many researchers’ attention to deal with several optimization problems in many fields due to its strengths in solving optimization tasks that include the simple concept, easiness of implementation, and rapid convergence. This paper aims to provide researchers with a relatively comprehensive and extensive overview of the Sine–Cosine optimization algorithm in the literature to inspire further research. It examines the available publications, including improvements, binary, chaotic, hybridizations, multi-objective variants, and different applications. Some optimization formulations regarding single-objective optimization problems, multi-objective optimization problems, binary-objective optimization problems, and more classifications regarding the optimization types are discussed. An extensive bibliography is also included.},
  archive      = {J_AIR},
  author       = {Rizk-Allah, Rizk M. and Hassanien, Aboul Ella},
  doi          = {10.1007/s10462-022-10277-3},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4801-4858},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comprehensive survey on the sine–cosine optimization algorithm},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recent advances in decision trees: An updated survey.
<em>AIR</em>, <em>56</em>(5), 4765–4800. (<a
href="https://doi.org/10.1007/s10462-022-10275-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision Trees (DTs) are predictive models in supervised learning, known not only for their unquestionable utility in a wide range of applications but also for their interpretability and robustness. Research on the subject is still going strong after almost 60 years since its original inception, and in the last decade, several researchers have tackled key matters in the field. Although many great surveys have been published in the past, there is a gap since none covers the last decade of the field as a whole. This paper proposes a review of the main recent advances in DT research, focusing on three major goals of a predictive learner: issues regarding the fitting of training data, generalization, and interpretability. Moreover, by organizing several topics that have been previously analyzed in isolation, this survey attempts to provide an overview of the field, its key concerns, and future trends, serving as a good entry point for both researchers and newcomers to the machine learning community.},
  archive      = {J_AIR},
  author       = {Costa, Vinícius G. and Pedreira, Carlos E.},
  doi          = {10.1007/s10462-022-10275-5},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4765-4800},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Recent advances in decision trees: An updated survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A scoping review on multi-fault diagnosis of industrial
rotating machines using multi-sensor data fusion. <em>AIR</em>,
<em>56</em>(5), 4711–4764. (<a
href="https://doi.org/10.1007/s10462-022-10243-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rotating machines is an essential part of any manufacturing industry. The sudden breakdown of such machines due to improper maintenance can also lead to the industries&#39; shutdown. The era of the 4th industrial revolution is taking its major shape concerning maintenance strategies, notable being in predictive maintenance. Fault prediction and diagnosis is the major concern in predictive maintenance as this is the major issue faced by all the maintenance engineers. Most of the bibliometric literature review studies that are accessible focus on fault diagnosis in rotating machines, mainly focusing on a single type of fault. However, there isn&#39;t a thorough analysis of the literature that focuses on the &quot;multi-fault diagnosis using multi-sensor data&quot; aspect of rotating machines. In this regard, this paper reviews the literature on the “multi-Fault diagnosis using multi-sensor data fusion” of Industrial Rotating Machines employing Machine learning/Deep learning techniques. A hybrid bibliometric approach was used to analyze articles from the “Web of Science” and “Scopus” Database for the last 10 years. The method for literature analysis used, is quantitative as well as qualitative, as not only the traditional approach (bibliometric and network analysis) but also a novel method named ProKnow-C is used, and it entails a number of phases, that includes intelligent and extensive filtering from the large set of results and finally selecting the articles that are more pertinent to the research theme. Based on available publications, an analysis is performed on year-by-year publication data, article types, linguistic distribution of articles, funding sponsors, affiliations, citation analysis and the relationship between keywords, authors, etc. to provide an in-depth vision of research trends in the related area. The paper also focuses on the maintenance strategies, predictive maintenance approaches, AI algorithms, Multi sensor data fusion, challenges, and future directions in “multi-fault diagnosis using multi-sensor data fusion” in rotating machines. The foundational work done in the field, the most prolific papers and the key research themes within the research area are all identified in this bibliometric survey.},
  archive      = {J_AIR},
  author       = {Gawde, Shreyas and Patil, Shruti and Kumar, Satish and Kotecha, Ketan},
  doi          = {10.1007/s10462-022-10243-z},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4711-4764},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A scoping review on multi-fault diagnosis of industrial rotating machines using multi-sensor data fusion},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recent advances in the application of deep learning for
fault diagnosis of rotating machinery using vibration signals.
<em>AIR</em>, <em>56</em>(5), 4667–4709. (<a
href="https://doi.org/10.1007/s10462-022-10293-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vibration measurement and monitoring are essential in a wide variety of applications. Vibration measurements are critical for diagnosing industrial machinery malfunctions because they provide information about the condition of the rotating equipment. Vibration analysis is considered the most effective method for predictive maintenance because it is used to troubleshoot instantaneous faults as well as periodic maintenance. Numerous studies conducted in this vein have been published in a variety of outlets. This review documents data-driven and recently published deep learning techniques for vibration-based condition monitoring. Numerous studies were obtained from two reputable indexing databases, Web of Science and Scopus. Following a thorough review, 59 studies were selected for synthesis. The selected studies are then systematically discussed to provide researchers with an in-depth view of deep learning-based fault diagnosis methods based on vibration signals. Additionally, a few remarks regarding future research directions are made, including graph-based neural networks, physics-informed ML, and a transformer convolutional network-based fault diagnosis method.},
  archive      = {J_AIR},
  author       = {Tama, Bayu Adhi and Vania, Malinda and Lee, Seungchul and Lim, Sunghoon},
  doi          = {10.1007/s10462-022-10293-3},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4667-4709},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Recent advances in the application of deep learning for fault diagnosis of rotating machinery using vibration signals},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An overview of violence detection techniques: Current
challenges and future directions. <em>AIR</em>, <em>56</em>(5),
4641–4666. (<a
href="https://doi.org/10.1007/s10462-022-10285-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Big Video Data generated in today’s smart cities has raised concerns from its purposeful usage perspective, where surveillance cameras, among many others are the most prominent resources to contribute to the huge volumes of data, making its automated analysis a difficult task in terms of computation and preciseness. Violence detection (VD), broadly plunging under action and activity recognition domain, is used to analyze Big Video data for anomalous actions incurred due to humans. The VD literature is traditionally based on manually engineered features, though advancements to deep learning based standalone models are developed for real-time VD analysis. This paper focuses on overview of deep sequence learning approaches along with localization strategies of the detected violence. This overview also dives into the initial image processing and machine learning-based VD literature and their possible advantages such as efficiency against the current complex models. Furthermore,the datasets are discussed, to provide an analysis of the current models, explaining their pros and cons with future directions in VD domain derived from an in-depth analysis of the previous methods.},
  archive      = {J_AIR},
  author       = {Mumtaz, Nadia and Ejaz, Naveed and Habib, Shabana and Mohsin, Syed Muhammad and Tiwari, Prayag and Band, Shahab S. and Kumar, Neeraj},
  doi          = {10.1007/s10462-022-10285-3},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4641-4666},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An overview of violence detection techniques: Current challenges and future directions},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Setback in ranking fuzzy numbers: A study in fuzzy risk
analysis in diabetes prediction. <em>AIR</em>, <em>56</em>(5),
4591–4639. (<a
href="https://doi.org/10.1007/s10462-022-10282-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevalence of diabetes is terribly increasing worldwide and every 5 s a person dies from this disease. (The IDF Diabetes Atlas, Tenth Edition ( https://diabetesatlas.org/ ) Last visit: 7.14.2022)). Hence, timely detection of diabetes is very vital to prevent or delay the complications. Many researchers have believed that to deal with the vagueness in knowledge and complexity of diabetes, fuzzy set needs to be incorporated into diabetes prediction models to provide more realistic results. In a fuzzy environment, ranking of fuzzy numbers is a crucial prerequisite to make a decision. In this paper, a new phenomenon in ranking fuzzy numbers that we call “setback” is introduced. In setback which indicates the most confusing state in fuzzy ranking, the ranking order of fuzzy numbers is completely reversed when a new ranking method is applied to the same problem. Also a fuzzy risk analysis problem in diabetes prediction is studied in which person with the highest risk of diabetes is replaced with the lowest one and vice versa. With this result in hand, we reveal that defective ranking results in a medical problem have the potential to lead to disastrous effects on human health. We expose some potential causes of “setback” and to alleviate this problem two evaluation criteria and a benchmark are suggested. These criteria help researchers avoid severe pitfalls when introducing their own ranking methods. To achieve this goal, we first address serious drawbacks of some fuzzy ranking methods which have been recently published by reputed journals. Although the aim of this paper is not to challenge the theoretical advances in ranking methods, this paper shows that this field requires deeper studies to be proper to apply in actual cases, particularly medical decision-making. Hence, if the users do not pay attention to various aspects of ranking methods, they may fall into the trap of paradoxical results. This paper is expected to be useful for the medical researchers working in this field and for the scholars thinking about realization of fuzzy sets and ranking fuzzy numbers for real world applications.},
  archive      = {J_AIR},
  author       = {Sotoudeh-Anvari, Maryam and Sotoudeh-Anvari, Alireza},
  doi          = {10.1007/s10462-022-10282-6},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4591-4639},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Setback in ranking fuzzy numbers: A study in fuzzy risk analysis in diabetes prediction},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Incremental learning with neural networks for computer
vision: A survey. <em>AIR</em>, <em>56</em>(5), 4557–4589. (<a
href="https://doi.org/10.1007/s10462-022-10294-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incremental learning is one of the most important abilities of human beings. In the age of artificial intelligence, it is the key task to make neural network models as powerful as human beings, to achieve the ability to continuously acquire, fine-tune, and accumulate knowledge while simultaneously avoid catastrophic forgetting. In recent years, by virtue of deep neural networks, incremental learning has been attracting a great deal of attention in the field of computer vision. In this paper, we systematically review the current development of incremental learning and give the overall taxonomy of the incremental learning methods. Specifically, three kinds of mainstream methods, i.e., parameter regularization-based approaches, knowledge distillation-based approaches, and dynamic architecture-based approaches, are surveyed, summarized, and discussed in detail. Furthermore, we comprehensively analyze the performance of data-permuted incremental learning, class-incremental learning, and multi-modal incremental learning on widely used datasets, covering a broad of incremental learning scenarios for image classification and semantic segmentation. Lastly, we point out some possible research directions and inspiring suggestions for incremental learning in the field of computer vision.},
  archive      = {J_AIR},
  author       = {Liu, Hao and Zhou, Yong and Liu, Bing and Zhao, Jiaqi and Yao, Rui and Shao, Zhiwen},
  doi          = {10.1007/s10462-022-10294-2},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4557-4589},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Incremental learning with neural networks for computer vision: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A proportional-integral iterative algorithm for time-variant
equality-constrained quadratic programming problem with applications.
<em>AIR</em>, <em>56</em>(5), 4535–4556. (<a
href="https://doi.org/10.1007/s10462-022-10284-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving the time-variant equality-constrained quadratic programming (TVECQP) problem extensively occurs in diverse applications, and thus many novel schemes have been developed, e.g., numerical algorithms and zeroing neural networks. However, few existing works consider the perturbations in a computing system which may cause inaccurate solution. To suppress the effect of perturbations, we try to employ the integral feedback control to design a new algorithm. Firstly, the control system model of the traditional algorithm, i.e., the Newton algorithm is presented. Hence, the correlation between the control system and algorithm has been established. Then, the integral control feedback is added to the system to construct the proportional-integral iterative (PII) algorithm. The PII algorithm is thus endowed with robustness against various perturbations that are proved in theory. Moreover, numerical simulations among the Newton algorithms, the zeroing neural network, and the proposed PII algorithm are performed for comparison, which verify the theoretical analyses and demonstrate the superior robustness of the PII algorithm. Finally, two applications are provided to illustrate the feasibility of the PII algorithm, where one investigating the distribution of surface water from satellite images and the other is about robotic manipulator control.},
  archive      = {J_AIR},
  author       = {Wang, Guancheng and Hao, Zhihao and Huang, Haoen and Zhang, Bob},
  doi          = {10.1007/s10462-022-10284-4},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4535-4556},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A proportional-integral iterative algorithm for time-variant equality-constrained quadratic programming problem with applications},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inference-based complete algorithms for asymmetric
distributed constraint optimization problems. <em>AIR</em>,
<em>56</em>(5), 4491–4534. (<a
href="https://doi.org/10.1007/s10462-022-10288-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Asymmetric distributed constraint optimization problems (ADCOPs) are an important framework for multiagent coordination and optimization, where each agent has its personal preferences. However, the existing inference-based complete algorithms that use local eliminations cannot be applied to ADCOPs, as the (pseudo) parents are required to transfer their private functions to their (pseudo) children to perform the local eliminations optimally. Rather than disclosing private functions explicitly to facilitate local eliminations, we solve the problem by enforcing delayed eliminations and propose the first inference-based complete algorithm for ADCOPs, named AsymDPOP. To solve the severe scalability problems incurred by delayed eliminations, we propose to reduce the memory consumption by propagating a set of smaller utility tables instead of a joint utility table, and the computation efforts by sequential eliminations instead of joint eliminations. To ensure the proposed algorithms can scale up to large-scale problems under the limited memory, we combine them with the memory-bounded inference by iteratively propagating the memory-bounded utility tables with the instantiation of cycle-cut (CC) nodes, where we propose to reduce the redundancy in bounded utility iterative propagation by enumerating CC nodes in different branches independently and propagating the utility tables within the memory limit only once. The empirical evaluation indicates that the proposed methods significantly outperform the state-of-the-art as well as the vanilla DPOP with PEAV formulation.},
  archive      = {J_AIR},
  author       = {Chen, Dingding and Chen, Ziyu and Deng, Yanchen and He, Zhongshi and Wang, Lulu},
  doi          = {10.1007/s10462-022-10288-0},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4491-4534},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Inference-based complete algorithms for asymmetric distributed constraint optimization problems},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Applications of deep learning into supply chain management:
A systematic literature review and a framework for future research.
<em>AIR</em>, <em>56</em>(5), 4447–4489. (<a
href="https://doi.org/10.1007/s10462-022-10289-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s complex and ever-changing world, Supply Chain Management (SCM) is increasingly becoming a cornerstone to any company to reckon with in this global era for all industries. The rapidly growing interest in the application of Deep Learning (a class of machine learning algorithms) in SCM, has urged the need for an up-to-date systematic review on the research development. The main purpose of this study is to provide a comprehensive vision by reviewing a set of 43 papers about applications of Deep Learning (DL) methods to the SCM, as well as the trends, perspectives, and potential research gaps. This review uses content analysis to answer three research questions namely: 1- What SCM problems have been solved by the use of DL techniques? 2- What DL algorithms have been used to solve these problems? 3- What alternative algorithms have been used to tackle the same problems? And do DL outperform these methods and through which evaluation metrics? This review also responds to this call by developing a conceptual framework in a value-adding perspective that provides a full picture of areas on where and how DL can be applied within the SCM context. This makes it easier to identify potential applications to corporations, in addition to potential future research areas to science. It might also provide businesses a competitive advantage over their competitors by allowing them to add value to their data by analyzing it quickly and precisely.},
  archive      = {J_AIR},
  author       = {Hosseinnia Shavaki, Fahimeh and Ebrahimi Ghahnavieh, Ali},
  doi          = {10.1007/s10462-022-10289-z},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4447-4489},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Applications of deep learning into supply chain management: A systematic literature review and a framework for future research},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Review on knowledge extraction from text and scope in
agriculture domain. <em>AIR</em>, <em>56</em>(5), 4403–4445. (<a
href="https://doi.org/10.1007/s10462-022-10239-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge extraction is meant by acquiring relevant information from the unstructured document in natural language and representing them in a structured form. Enormous information in various domains, including agriculture, is available in the natural language from several resources. The knowledge needs to be represented in a structured format to understand and process by a machine for automating various applications. This paper reviews different computational approaches like rule-based and learning-based methods and explores the various techniques, features, tools, datasets, and evaluation metrics adopted for knowledge extraction from the most relevant literature.},
  archive      = {J_AIR},
  author       = {Nismi Mol, E. A. and Santosh Kumar, M. B.},
  doi          = {10.1007/s10462-022-10239-9},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4403-4445},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Review on knowledge extraction from text and scope in agriculture domain},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Medical instrument detection in ultrasound: A review.
<em>AIR</em>, <em>56</em>(5), 4363–4402. (<a
href="https://doi.org/10.1007/s10462-022-10287-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical instrument detection is essential for computer-assisted interventions, since it facilitates clinicians to find instruments efficiently with a better interpretation, thereby improving clinical outcomes. This article reviews image-based medical instrument detection methods for ultrasound-guided (US-guided) operations. Literature is selected based on an exhaustive search in different sources, including Google Scholar, PubMed, and Scopus. We first discuss the key clinical applications of medical instrument detection in the US, including delivering regional anesthesia, biopsy taking, prostate brachytherapy, and catheterization. Then, we present a comprehensive review of instrument detection methodologies, including non-machine-learning and machine-learning methods. The conventional non-machine-learning methods were extensively studied before the era of machine learning methods. The principal issues and potential research directions for future studies are summarized for the computer-assisted intervention community. In conclusion, although promising results have been obtained by the current (non-) machine learning methods for different clinical applications, thorough clinical validations are still required.},
  archive      = {J_AIR},
  author       = {Yang, Hongxu and Shan, Caifeng and Kolen, Alexander F. and de With, Peter H. N.},
  doi          = {10.1007/s10462-022-10287-1},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4363-4402},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Medical instrument detection in ultrasound: A review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A comprehensive review on jaya optimization algorithm.
<em>AIR</em>, <em>56</em>(5), 4329–4361. (<a
href="https://doi.org/10.1007/s10462-022-10234-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Jaya Algorithm is a relatively new population-based optimization, which has become a progressively valuable tool in swarm intelligence. The Jaya algorithm incorporates the survival of the fittest principle alike evolutionary algorithm by its victorious nature as well as the ideal of an inducement towards a global optimal, which represents its swarm intelligence nature. Nevertheless, it has been applied in various areas of optimization, mainly in engineering practice, which is discussed and abridged based on each problem’s domain.The Jaya optimization’s vast applicability can be explained by its ability to work without any algorithm-specific parameters. The successfully solved problems may also use some of this meta-heuristic’s variants, in which the algorithm has been modified or hybridized. This paper focuses on a comprehensive review, as well as a bibliometric study of the Jaya algorithm, to imply its versatility. Hence, this study is likely to emphasize this optimization’s abilities, inspiring new researchers to make use of this simple and efficient algorithm for problem-solving.},
  archive      = {J_AIR},
  author       = {da Silva, Luiza Scapinello Aquino and Lúcio, Yan Lieven Souza and Coelho, Leandro dos Santos and Mariani, Viviana Cocco and Rao, Ravipudi Venkata},
  doi          = {10.1007/s10462-022-10234-0},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4329-4361},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comprehensive review on jaya optimization algorithm},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Swarm intelligence algorithms for multiple unmanned aerial
vehicles collaboration: A comprehensive review. <em>AIR</em>,
<em>56</em>(5), 4295–4327. (<a
href="https://doi.org/10.1007/s10462-022-10281-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, unmanned aerial vehicles (UAVs) have demonstrated increasing promise. In this context, we provide a review on swarm intelligence algorithms that play an extremely important role in multiple UAV collaborations. The study focuses on four aspects we consider relevant for the topic: collision avoidance, task assignment, path planning, and formation reconfiguration. A comprehensive investigation of selected typical algorithms that analyses their merits and demerits in the context of multi-UAV collaboration is presented. This research summarises the basic structure of swarm intelligence algorithms, which consists of several fundamental phases; and provides a comprehensive survey of swarm intelligence algorithms for the four aspects of multi-UAV collaboration. Besides, by analysing these key technologies and related applications, the research trends and challenges are highlighted. This broad review is an outline for scholars and professionals in the field of UAV swarms.},
  archive      = {J_AIR},
  author       = {Tang, Jun and Duan, Haibin and Lao, Songyang},
  doi          = {10.1007/s10462-022-10281-7},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4295-4327},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Swarm intelligence algorithms for multiple unmanned aerial vehicles collaboration: A comprehensive review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ADABA: Improving the balancing between runtime and accuracy
in a new distributed version of the alpha–beta algorithm. <em>AIR</em>,
<em>56</em>(5), 4255–4293. (<a
href="https://doi.org/10.1007/s10462-022-10269-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The satisfactory performance of the intelligent agents conceived to solve several real-life problems requires efficient decision-making algorithms. To address issues with high state-spaces within reasonable runtime limits, these algorithms are distributed according to some approaches that can be either synchronous or asynchronous, where the former guarantee the same results as their corresponding serial versions through synchronization points, which causes the undesirable effects of communication overhead and idle processors. To mitigate this, the asynchronous approaches reduce the message exchanges in such a way as to accelerate the runtime without too much compromising the response accuracy. The challenge of enhancing the minimax technique through pruning makes Alpha–Beta a relevant case study in parallelism research. Young Brothers Wait Concept (YBWC) and Asynchronous Parallel Hierarchical Iterative Deepening (APHID) are highlighted among the existing Alpha–Beta distributions. Knowing that APHID proved to be more suitable than YBWC to operate in distributed memory and that shared memory architectures are scarcely available due to their high costs, the primary motivation here is to implement the Asynchronous Distributed Alpha–Beta Algorithm (ADABA), which increases the accuracy and performance of APHID through the enhancement of the slaves’ task ordering policies, the communication process between the processors and the window’s updating strategy. Experiments fulfilled through tournaments involving ADABA-based and APHID-based Checkers agents proved that the player based on the best ADABA version reached, approximately, a victory rate 95\% superior and a runtime two times faster than the APHID-based player, keeping the same response accuracy level of its opponent.},
  archive      = {J_AIR},
  author       = {Tomaz, Lidia Bononi Paiva and Julia, Rita Maria Silva and Faria, Matheus Prado Prandini},
  doi          = {10.1007/s10462-022-10269-3},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4255-4293},
  shortjournal = {Artif. Intell. Rev.},
  title        = {ADABA: Improving the balancing between runtime and accuracy in a new distributed version of the alpha–beta algorithm},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Review of plant leaf recognition. <em>AIR</em>,
<em>56</em>(5), 4217–4253. (<a
href="https://doi.org/10.1007/s10462-022-10278-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plants can be seen everywhere in daily life and are closely connected with our lives. The recognition and classification of plants are of great significance to ecological and environmental protection. Traditional plant identification methods are complex, and experts cannot classify multiple plant species quickly. More and more researchers pay attention to image processing and pattern recognition and use them to identify and classify plant leaves quickly. Based on this, this paper summarizes and classifies the methods of plant leaf recognition in recent years. First, we analyze these studies and classify them using different features and classifiers, such as shape, texture, color features, support vector machines, K nearest neighbors, convolutional neural networks, and so on. Secondly, compare the recognition results of plant leaf recognition methods under different datasets. Finally, the recognition of plant leaves is summarized, and future research and development have prospected.},
  archive      = {J_AIR},
  author       = {Wang, Zhaobin and Cui, Jing and Zhu, Ying},
  doi          = {10.1007/s10462-022-10278-2},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4217-4253},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Review of plant leaf recognition},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An effective and efficient broad-based ensemble learning
model for moderate-large scale image recognition. <em>AIR</em>,
<em>56</em>(5), 4197–4215. (<a
href="https://doi.org/10.1007/s10462-022-10263-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning is a popular tool for image recognition due to its good feature learning capability. However, the training of most deep networks suffers from high computing costs and is time-consuming in image recognition. In this paper, we propose a broad-based ensemble learning model (BELM) that aims to provide a fast and efficient recognition approach for moderate-large scale image sets on an ordinary computer. This model is constructed in the form of a flat network, of which the flatted input consists of different feature nodes mapped from original inputs. The structure is expanded in a wide fashion in feature nodes and broad incremental learning algorithms are developed for the dynamic updating of feature nodes when the system deems to be expanded. Also, Lasso sparse autoencoder is considered for feature nodes to achieve compact and sparse features. Compared with most of the existing state-of-the-art networks, the structure of the proposed BELM is uncomplicated and few parameters need to be adjusted. Extensive experimental results on the classical data sets of the handwritten digital database (MNIST) and the object recognition dataset (NORB) demonstrate the effectiveness of the proposed model.},
  archive      = {J_AIR},
  author       = {Zhong, Xiurong and Duan, Shukai and Wang, Lidan},
  doi          = {10.1007/s10462-022-10263-9},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4197-4215},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An effective and efficient broad-based ensemble learning model for moderate-large scale image recognition},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An SOA-RBFNN approach for the system modelling of optimal
energy management in grid-connected smart grid system. <em>AIR</em>,
<em>56</em>(5), 4171–4196. (<a
href="https://doi.org/10.1007/s10462-022-10261-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A hybrid method for energy management on grid-connected MG system is proposed under this manuscript. Grid-connected MG system takes photovoltaic (PV), wind turbine (WT), battery. The proposed system is an integration of seagull optimization algorithm (SOA) and the radial basic functional neural network (RBFNN), thus it is named SOA-RBFNN. Here, in the grid-connected microgrid configuration, the necessary load demand is always monitored with RBFNN methodology. SOA optimizes the perfect match of the MG taking into account the predictable load requirement. The fuel cost, together with the power variation per hour of the electric grid, the operation and maintenance cost of microgrid system linked with grid, is described. The proposed model runs on the MATLAB/Simulink workstation and efficiency is investigated using existing techniques as AGO-RNN and MBFA-ANN. Statistical analysis, elapsed time, modeling metrics, and determination of optimal sample size for adjustment and validation of proposed and existing technique are evaluated. The efficiency values on the 100, 200, 500, and 1000 trails are 99.7673\%, 99.7609\%, 99.9099\%, and 99.9373\%.},
  archive      = {J_AIR},
  author       = {Kuppusamy, Karthikumar and Vairakannu, Senthil Kumar and Marimuthu, Karuppiah and Natarajan, Udhayaraj and Sekar, Krishnakumar},
  doi          = {10.1007/s10462-022-10261-x},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4171-4196},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An SOA-RBFNN approach for the system modelling of optimal energy management in grid-connected smart grid system},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An application of tournament differential evolution
algorithm in production inventory model with green level and expiry time
dependent demand. <em>AIR</em>, <em>56</em>(5), 4137–4170. (<a
href="https://doi.org/10.1007/s10462-022-10268-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present situation, environment is rapidly polluted by the manufacturing of non-eco-friendly products and carbon emission from production industries. So, to control this pollution as well as carbon emission, everyone should be aware to use eco-friendly products and reduce carbon emission. Motivating on this topic, a model on green manufacturing system has been formulated where the produced items are eco-friendly and have a fixed lifetime. Also, in this model, the green level of the produced items enhances the demand of the customers. The objective of this work is to determine the green level of the product and business period by maximizing the average profit of the system. To solve the corresponding maximization problems, a hybrid tournament differential evolution (TDE) algorithm is applied to obtain the best-found solutions along with the average profit of the system. To check the validity of the proposed model, a numerical example is considered and solved by the different variants of the said algorithm. Also, the simulated results obtained from the different variants of TDE algorithm are compared with the simulated results obtained from some of the existing algorithms reported in the literature. Then to test the performance and efficiency of the said hybrid algorithm, statistical comparisons, statistical tests are performed. Finally, sensitivity analyses are carried out in order to examine the effects of changes of parameters involved in the model on the average profit, green level of the product, business and production periods.},
  archive      = {J_AIR},
  author       = {Akhtar, Md and Duary, Avijit and Manna, Amalesh Kumar and Shaikh, Ali Akbar and Bhunia, Asoke Kumar},
  doi          = {10.1007/s10462-022-10268-4},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4137-4170},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An application of tournament differential evolution algorithm in production inventory model with green level and expiry time dependent demand},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Matrix-based fast granularity reduction algorithm of
multi-granulation rough set. <em>AIR</em>, <em>56</em>(5), 4113–4135.
(<a href="https://doi.org/10.1007/s10462-022-10276-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to overcome the limitation of low efficiency of existing granularity reduction algorithms in multi-granulation rough sets, based on matrix method, a fast granularity reduction algorithm is proposed and the time complexity is $$O({|U |}^{2} \cdot |A |+ |U|\cdot {|A |}^{2})$$ . First, the definitions of positive region matrix and granularity column matrix of multi-granulation space are proposed. Second, through the quantity product of these two matrices, the definition of positive region column matrix is presented. Based on the positive region column matrix, cut matrix and matrix norm are defined, respectively. Third, the matrix-based calculation methods of multi-granulation approximation quality and granularity significance are proposed. Finally, a heuristic rule is designed according to the granularity significance, and a matrix-based fast granularity reduction algorithm is proposed. Experimental results demonstrate the effectiveness of the proposed methods.},
  archive      = {J_AIR},
  author       = {Xu, Yi and Wang, Min and Hu, Shanzhong},
  doi          = {10.1007/s10462-022-10276-4},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4113-4135},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Matrix-based fast granularity reduction algorithm of multi-granulation rough set},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised feature selection based on incremental forward
iterative laplacian score. <em>AIR</em>, <em>56</em>(5), 4077–4112. (<a
href="https://doi.org/10.1007/s10462-022-10274-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection facilitates intelligent information processing, and the unsupervised learning of feature selection has become important. In terms of unsupervised feature selection, the Laplacian score (LS) provides a powerful measurement and optimization method, and good performance has been achieved using the recent forward iterative Laplacian score (FILS) algorithm. However, there is still room for advancement. The aim of this paper is to improve the FILS algorithm, and thus, feature significance (SIG) is mainly introduced to develop a high-quality selection method, i.e., the incremental forward iterative Laplacian score (IFILS) algorithm. Based on the modified LS, the metric difference in the incremental feature process motivates SIG. Therefore, SIG offers a dynamic characterization by considering initial and terminal states, and it promotes the current FILS measurement on only the terminal state. Then, both the modified LS and integrated SIG acquire granulation nonmonotonicity and uncertainty, especially on incremental feature chains, and the corresponding verification is achieved by completing examples and experiments. Furthermore, a SIG-based incremental criterion of minimum selection is designed to choose optimization features, and thus, the IFILS algorithm is naturally formulated to implement unsupervised feature selection. Finally, an in-depth comparison of the IFILS algorithm with the FILS algorithm is achieved using data experiments on multiple datasets, including a nominal dataset of COVID-19 surveillance. As validated by the experimental results, the IFILS algorithm outperforms the FILS algorithm and achieves better classification performance.},
  archive      = {J_AIR},
  author       = {Jiang, Jiefang and Zhang, Xianyong and Yang, Jilin},
  doi          = {10.1007/s10462-022-10274-6},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4077-4112},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Unsupervised feature selection based on incremental forward iterative laplacian score},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic captioning for medical imaging (MIC): A rapid
review of literature. <em>AIR</em>, <em>56</em>(5), 4019–4076. (<a
href="https://doi.org/10.1007/s10462-022-10270-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatically understanding the content of medical images and delivering accurate descriptions is an emerging field of artificial intelligence that combines skills in both computer vision and natural language processing fields. Medical image captioning is involved in various applications related to diagnosis, treatment, report generation and computer-aided diagnosis to facilitate the decision making and clinical workflows. Unlike generic image captioning, medical image captioning highlights the relationships between image objects and clinical findings, which makes it a very challenging task. Although few review papers have already been published in this field, their coverage is still quite limited and only particular problems are addressed. This motivates the current paper where a rapid review protocol was adopted to review the latest achievements in automatic medical image captioning from the medical domain perspective. We aim through this review to provide the reader with an up-to-date literature in this field by summarizing the key findings and approaches in this field, including the related datasets, applications and limitations as well as highlighting the main competitions, challenges and future directions.},
  archive      = {J_AIR},
  author       = {Beddiar, Djamila-Romaissa and Oussalah, Mourad and Seppänen, Tapio},
  doi          = {10.1007/s10462-022-10270-w},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {4019-4076},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Automatic captioning for medical imaging (MIC): A rapid review of literature},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-domain decision making based on TrAdaBoost for
diagnosis of breast lesions. <em>AIR</em>, <em>56</em>(5), 3987–4017.
(<a href="https://doi.org/10.1007/s10462-022-10267-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accumulated historical data are beneficial for generating solutions that are more satisfactory to decision makers because their preferences and experience are characterized by historical data. However, this might be infeasible when only few data are available. Suppose that the few data are collected from a domain called the target domain. There may be some domains correlated to the target domain, which are called source domains. The data from source domains might be useful for helping generate solutions to the problem in the target domain. Following this idea, this paper proposes a cross-domain decision making method based on the combination of TrAdaBoost, an instance-based transfer learning method, and a decision making method in the context of the evidential reasoning approach. This may be the first attempt to combine transfer learning with a decision making method to help generate high-quality solutions satisfactory to decision makers when only few data are available for the problem in the target domain. A data selection strategy is designed to increase the similarity between the data from source and target domains and a weight initialization strategy is designed based on the available gold standards. The two strategies are intended for improving the performance of the proposed method. With the two strategies, the process of the proposed method is presented. The effectiveness of the proposed method is validated by its application in helping diagnose breast lesions with the diagnostic data of five radiologists collected from a tertiary hospital located in Hefei, Anhui, China.},
  archive      = {J_AIR},
  author       = {Fu, Chao and Wu, Zijian and Xue, Min and Liu, Weiyong},
  doi          = {10.1007/s10462-022-10267-5},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3987-4017},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Cross-domain decision making based on TrAdaBoost for diagnosis of breast lesions},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Securing federated learning with blockchain: A systematic
literature review. <em>AIR</em>, <em>56</em>(5), 3951–3985. (<a
href="https://doi.org/10.1007/s10462-022-10271-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a promising framework for distributed machine learning that trains models without sharing local data while protecting privacy. FL exploits the concept of collaborative learning and builds privacy-preserving models. Nevertheless, the integral features of FL are fraught with problems, such as the disclosure of private information, the unreliability of uploading model parameters to the server, the communication cost, etc. Blockchain, as a decentralized technology, is able to improve the performance of FL without requiring a centralized server and also solves the above problems. In this paper, a systematic literature review on the integration of Blockchain in federated learning was considered with the analysis of the existing FL problems that can be compensated. Through carefully screening, most relevant studies are included and research questions cover the potential security and privacy attacks in traditional federated learning that can be solved by blockchain as well as the characteristics of Blockchain-based FL. In addition, the latest Blockchain-based approaches to federated learning have been studied in-depth in terms of security and privacy, records and rewards, and verification and accountability. Furthermore, open issues related to the combination of Blockchain and FL are discussed. Finally, future research directions for the robust development of Blockchain-based FL systems are proposed.},
  archive      = {J_AIR},
  author       = {Qammar, Attia and Karim, Ahmad and Ning, Huansheng and Ding, Jianguo},
  doi          = {10.1007/s10462-022-10271-9},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3951-3985},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Securing federated learning with blockchain: A systematic literature review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Population reduction with individual similarity for
differential evolution. <em>AIR</em>, <em>56</em>(5), 3887–3949. (<a
href="https://doi.org/10.1007/s10462-022-10264-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Choosing the appropriate population size for differential evolution (DE) is still a challenging task. Too large population size leads to slow convergence, while too small population size causes premature convergence and stagnation. To solve this problem, a population reduction with individual similarity (PRS) for DE is proposed in this paper. In the PRS, a linear differential decrease method is used to automatically determine the population size required in each generation. At the same time, the current population is divided into two subgroups with equal sizes according to individual similarity, and the individuals that need to be removed are determined from the subgroup with the lowest individual similarity in an effective manner, and thus the convergence is further accelerated without affecting the population diversity. In addition, an elite-oriented strategy is utilized to replace the random selection of individuals in the original mutation strategy of DE, which provides constructive guidance for individual evolution and improves the convergence quality. Five basic DE and six advanced DE algorithms are used to evaluate the effect of PRS, and it is further compared with four improved DE algorithms with population reduction strategy. The experimental results on CEC 2014 benchmark functions show that the proposed PRS can effectively enhance the performance of these five basic DE and six advanced DE algorithms, and is better than the four population reduction strategies.},
  archive      = {J_AIR},
  author       = {Li, Yuzhen and Wang, Shihao and Yang, Bo and Chen, Hu and Wu, Zhiqiang and Yang, Hongyu},
  doi          = {10.1007/s10462-022-10264-8},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3887-3949},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Population reduction with individual similarity for differential evolution},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A brief review of portfolio optimization techniques.
<em>AIR</em>, <em>56</em>(5), 3847–3886. (<a
href="https://doi.org/10.1007/s10462-022-10273-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Portfolio optimization has always been a challenging proposition in finance and management. Portfolio optimization facilitates in selection of portfolios in a volatile market situation. In this paper, different classical, statistical and intelligent approaches employed for portfolio optimization and management are reviewed. A brief study is performed to understand why portfolio is important for any organization and how recent advances in machine learning and artificial intelligence can help portfolio managers to take right decisions regarding allotment of portfolios. A comparative study of different techniques, first of its kind, is presented in this paper. An effort is also made to compile classical, intelligent, and quantum-inspired techniques that can be employed in portfolio optimization.},
  archive      = {J_AIR},
  author       = {Gunjan, Abhishek and Bhattacharyya, Siddhartha},
  doi          = {10.1007/s10462-022-10273-7},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3847-3886},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A brief review of portfolio optimization techniques},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Survey on aspect detection for aspect-based sentiment
analysis. <em>AIR</em>, <em>56</em>(5), 3797–3846. (<a
href="https://doi.org/10.1007/s10462-022-10252-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is an important tool to automatically understand the user-generated content on the Web. The most fine-grained sentiment analysis is concerned with the extraction and sentiment classification of aspects and has been extensively studied in recent years. In this work, we provide an overview of the first step in aspect-based sentiment analysis that assumes the extraction of opinion targets or aspects. We define a taxonomy for the extraction of aspects and present the most relevant works accordingly, with a focus on the most recent state-of-the-art methods. The three main classes we use to classify the methods designed for the detection of aspects are pattern-based, machine learning, and deep learning methods. Despite their differences, only a small number of works belong to a unique class of methods. All the introduced methods are ranked in terms of effectiveness. In the end, we highlight the main ideas that have led the research on this topic. Regarding future work, we deemed that the most promising research directions are the domain flexibility and the end-to-end approaches.},
  archive      = {J_AIR},
  author       = {Truşcǎ, Maria Mihaela and Frasincar, Flavius},
  doi          = {10.1007/s10462-022-10252-y},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3797-3846},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Survey on aspect detection for aspect-based sentiment analysis},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Density-based IFCM along with its interval valued and
probabilistic extensions, and a review of intuitionistic fuzzy
clustering methods. <em>AIR</em>, <em>56</em>(4), 3755–3795. (<a
href="https://doi.org/10.1007/s10462-022-10236-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy clustering has been useful in capturing the uncertainty present in the data during clustering. Most of the c-Means algorithms such as FCM (Fuzzy c-Means), IFCM (Intuitionistic Fuzzy c-Means), and the recently reported PIFCM (Probabilistic Intuitionistic Fuzzy c-means) randomly initialize cluster centroids. Performance of these techniques is very reliant on the initialized cluster centroids. So, a good initialization technique can significantly affect the cluster formation. Recently, density-based initialization technique for FCM (DFCM) was proposed, which initializes datapoints with high density as cluster centroids. In DFCM, points within some distance contribute in the density of the data points. In this paper, we propose a new way to compute fuzzy density of datapoints based on the distance measure. Uncertainty can be better captured by intuitionistic fuzzy set (IFS) and interval-valued IFS (IVIFS). Thus, we propose a new density-based initialization technique for IFCM, called ‘Density based Intuitionistic Fuzzy c-Means (DIFCM)﻿ Algorithm’. The proposed DIFCM has been further developed for IVIFS, which we term ‘Interval-valued Density based Intuitionistic Fuzzy c-Means (IVDIFCM)﻿ Algorithm’, is also introduced in this paper. PIFCM incorporates probabilistic weights between membership, non-membership and hesitancy component. In this paper, we also introduce the density based initialized cluster centroids for PIFCM algorithm to propose the ‘Density Based Probabilistic Intuitionistic Fuzzy c-Means (DPIFCM) Algorithm’. There were many clustering approaches based on IFSs but there do not exist any literature review on the IFS based clustering approaches. Therefore,  this article also provides a detailed review of the recently proposed clustering algorithms based on IFS theory. Experiments over various UCI datasets proves that our proposed algorithms has better clustering results than their existing counterparts.},
  archive      = {J_AIR},
  author       = {Varshney, Ayush K. and Muhuri, Pranab K. and Lohani, Q. M. Danish},
  doi          = {10.1007/s10462-022-10236-y},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3755-3795},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Density-based IFCM along with its interval valued and probabilistic extensions, and a review of intuitionistic fuzzy clustering methods},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of platforms for simulating embodied agents in 3D
virtual environments. <em>AIR</em>, <em>56</em>(4), 3711–3753. (<a
href="https://doi.org/10.1007/s10462-022-10253-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The unprecedented rise in research interest in artificial intelligence (AI) and related areas, such as computer vision, machine learning, robotics, and cognitive science, during the last decade has fuelled the development of software platforms that can simulate embodied agents in 3D virtual environments. A simulator that closely mimics the physics of a real-world environment with embodied agents can allow open-ended experimentation, and can circumvent the need for real-world data collection, which is time-consuming, expensive, and in some cases, impossible without privacy invasion, thereby playing a significant role in progressing AI research. In this article, we review 22 simulation platforms reported in the literature. We classify them based on visual environment and physics. We present a comparison of these simulators based on their properties and functionalities from a user’s perspective. While no simulator is better than the others in all respects, a few stand out based on a rubric that encompasses the simulators’ properties, functionalities, availability and support. This review will guide users to choose the appropriate simulator for their application and provide a baseline to researchers for developing state-of-the-art simulators.},
  archive      = {J_AIR},
  author       = {Kaur, Deepti Prit and Singh, Narinder Pal and Banerjee, Bonny},
  doi          = {10.1007/s10462-022-10253-x},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3711-3753},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review of platforms for simulating embodied agents in 3D virtual environments},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of artificial intelligence methods for engineering
prognostics and health management with implementation guidelines.
<em>AIR</em>, <em>56</em>(4), 3659–3709. (<a
href="https://doi.org/10.1007/s10462-022-10260-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The past decade has witnessed the adoption of artificial intelligence (AI) in various applications. It is of no exception in the area of prognostics and health management (PHM) where the capacity of AI has been highlighted through numerous studies. In this paper, we present a comprehensive review of AI-based solutions in engineering PHM. This review serves as a guideline for researchers and practitioners with varying levels of experience seeking to broaden their know-how about AI-based PHM. Specifically, we provide both a broad quantitative analysis and a comprehensive qualitative examination of the roles of AI in PHM. The quantitative analysis offers an insight into the research community’s interest in AI-based approaches, focusing on the evolution of research trends and their developments in different PHM application areas. The qualitative survey gives a complete picture on the employment of AI in each stage of the PHM process, from data preparation to decision support. Based on the strengths and weaknesses of existing methods, we derive a general guideline for choosing proper techniques for each specific PHM task, aiming to level up maintenance practitioners’ efficiency in implementing PHM solutions. Finally, the review discusses challenges and future research directions in the development of autonomous intelligent PHM solutions.},
  archive      = {J_AIR},
  author       = {Nguyen, Khanh T. P. and Medjaher, Kamal and Tran, Do T.},
  doi          = {10.1007/s10462-022-10260-y},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3659-3709},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review of artificial intelligence methods for engineering prognostics and health management with implementation guidelines},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning for compressive sensing: A ubiquitous systems
perspective. <em>AIR</em>, <em>56</em>(4), 3619–3658. (<a
href="https://doi.org/10.1007/s10462-022-10259-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compressive sensing (CS) is a mathematically elegant tool for reducing the sensor sampling rate, potentially bringing context-awareness to a wider range of devices. Nevertheless, practical issues with the sampling and reconstruction algorithms prevent further proliferation of CS in real world domains, especially among heterogeneous ubiquitous devices. Deep learning (DL) naturally complements CS for adapting the sampling matrix, reconstructing the signal, and learning from the compressed samples. While the CS–DL integration has received substantial research interest recently, it has not yet been thoroughly surveyed, nor has any light been shed on practical issues towards bringing the CS–DL to real world implementations in the ubiquitous computing domain. In this paper we identify main possible ways in which CS and DL can interplay, extract key ideas for making CS–DL efficient, outline major trends in the CS–DL research space, and derive guidelines for the future evolution of CS–DL within the ubiquitous computing domain.},
  archive      = {J_AIR},
  author       = {Machidon, Alina L. and Pejović, Veljko},
  doi          = {10.1007/s10462-022-10259-5},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3619-3658},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep learning for compressive sensing: A ubiquitous systems perspective},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multicriteria group decision making via generalized
trapezoidal intuitionistic fuzzy number-based novel similarity measure
and its application to diverse COVID-19 scenarios. <em>AIR</em>,
<em>56</em>(4), 3543–3617. (<a
href="https://doi.org/10.1007/s10462-022-10251-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Havoc, brutality, economic breakdown, and vulnerability are the terms that can be rightly associated with COVID-19, for the kind of impact it is having on the whole world for the last two years. COVID-19 came as a nightmare and it is still not over yet, changing its form factor with each mutation. Moreover, each unpredictable mutation causes more severeness. In the present article, we outline a decision support algorithm using Generalized Trapezoidal Intuitionistic Fuzzy Numbers (GTrIFNs) to deal with various facets of COVID-19 problems. Intuitionistic fuzzy sets (IFSs) and their continuous counterparts, viz., the intuitionistic fuzzy numbers (IFNs), have the flexibility and effectiveness to handle the uncertainty and fuzziness associated with real-world problems. Although a meticulous amount of research works can be found in the literature, a wide majority of them are based mainly on normalized IFNs rather than the more generalized approach, and most of them had several limitations. Therefore, we have made a sincere attempt to devise a novel Similarity Measure (SM) which considers the evaluation of two prominent features of GTrIFNs, which are their expected values and variances. Then, to establish the superiority of our approach we present a comparative analysis of our method with several other established similarity methods considering ten different profiles of GTrIFNs. The proposed SM is then validated for feasibility and applicability, by elaborating a Fuzzy Multicriteria Group Decision Making (FMCGDM) algorithm and it is supportedby a suitable illustrative example. Finally, the proposed SM approach is applied to tackle some significant concerns due to COVID-19. For instance, problems like the selection of best medicine for COVID-19 infected patients; proper healthcare waste disposal technique; and topmost government intervention measures to prevent the COVID-19 spread, are some of the burning issues which are handled with our newly proposed SM approach.},
  archive      = {J_AIR},
  author       = {Dutta, Palash and Borah, Gourangajit},
  doi          = {10.1007/s10462-022-10251-z},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3543-3617},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Multicriteria group decision making via generalized trapezoidal intuitionistic fuzzy number-based novel similarity measure and its application to diverse COVID-19 scenarios},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel technique for the detection of myocardial
dysfunction using ECG signals based on CEEMD, DWT, PSR and neural
networks. <em>AIR</em>, <em>56</em>(4), 3505–3541. (<a
href="https://doi.org/10.1007/s10462-022-10262-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cardiovascular disease is one of the most serious health problems around the world. Traditionally, detection of cardiac arrhythmia based on the visual inspection of electrocardiography (ECG) signals by cardiologists is tedious, laborious and subjective. To overcome such disadvantages, numerous arrhythmia detection techniques including signal processing and machine learning tools have been developed. However, there still remain the problems of automatic detection with high efficiency and accuracy in distinguishing different myocardial dysfunctions through ECG signals. In this study we propose a novel technique for automatic detection of cardiac arrhythmia in one-lead ECG signals based upon complete ensemble empirical mode decomposition (CEEMD), discrete wavelet transform (DWT), phase space reconstruction (PSR) and neural networks. First, ECG signals are decomposed into a series of Intrinsic Mode Functions (IMFs) by using the CEEMD method without the preprocessing of QRS detection. The IMF6 and IMF7 of the ECG signals are extracted, which contain the majority of the ECG signals’ energy and are considered to be the predominant IMFs. Second, four levels DWT is employed to decompose the predominant IMFs into different frequency bands, in which third-order Daubechies (db3) wavelet function is selected as reference variable for analysis. Third, phase space of the reference variable is reconstructed based on db3, in which the properties associated with the nonlinear ECG system dynamics are preserved. Three-dimensional (3D) PSR together with Euclidean distance (ED) has been utilized to derive features, which demonstrate significant difference in ECG system dynamics between normal versus abnormal individual heartbeats. Fourth, neural networks are then used to model, identify and classify ECG system dynamics between normal (healthy) and arrhythmia ECG signals. Finally, experiments are carried out on the MIT-BIH arrhythmia database to assess the effectiveness of the proposed method, in which 436 ECG signal fragments for one lead (MLII) from 28 persons of five classes of heart beats were extracted. By using the 10-fold cross-validation style, the achieved average classification accuracy is reported to be $$98.81\%$$ . Compared with various state-of-the-art methods, the results demonstrate superior performance and the proposed method can serve as a potential candidate for the automatic detection of myocardial dysfunction in the clinical application.},
  archive      = {J_AIR},
  author       = {Zeng, Wei and Yuan, Jian and Yuan, Chengzhi and Wang, Qinghui and Liu, Fenglin and Wang, Ying},
  doi          = {10.1007/s10462-022-10262-w},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3505-3541},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A novel technique for the detection of myocardial dysfunction using ECG signals based on CEEMD, DWT, PSR and neural networks},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A global taxonomy of interpretable AI: Unifying the
terminology for the technical and social sciences. <em>AIR</em>,
<em>56</em>(4), 3473–3504. (<a
href="https://doi.org/10.1007/s10462-022-10256-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since its emergence in the 1960s, Artificial Intelligence (AI) has grown to conquer many technology products and their fields of application. Machine learning, as a major part of the current AI solutions, can learn from the data and through experience to reach high performance on various tasks. This growing success of AI algorithms has led to a need for interpretability to understand opaque models such as deep neural networks. Various requirements have been raised from different domains, together with numerous tools to debug, justify outcomes, and establish the safety, fairness and reliability of the models. This variety of tasks has led to inconsistencies in the terminology with, for instance, terms such as interpretable, explainable and transparent being often used interchangeably in methodology papers. These words, however, convey different meanings and are “weighted&quot; differently across domains, for example in the technical and social sciences. In this paper, we propose an overarching terminology of interpretability of AI systems that can be referred to by the technical developers as much as by the social sciences community to pursue clarity and efficiency in the definition of regulations for ethical and reliable AI development. We show how our taxonomy and definition of interpretable AI differ from the ones in previous research and how they apply with high versatility to several domains and use cases, proposing a—highly needed—standard for the communication among interdisciplinary areas of AI.},
  archive      = {J_AIR},
  author       = {Graziani, Mara and Dutkiewicz, Lidia and Calvaresi, Davide and Amorim, José Pereira and Yordanova, Katerina and Vered, Mor and Nair, Rahul and Abreu, Pedro Henriques and Blanke, Tobias and Pulignano, Valeria and Prior, John O. and Lauwaert, Lode and Reijers, Wessel and Depeursinge, Adrien and Andrearczyk, Vincent and Müller, Henning},
  doi          = {10.1007/s10462-022-10256-8},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3473-3504},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A global taxonomy of interpretable AI: Unifying the terminology for the technical and social sciences},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cognitive motivations and foundations for building
intelligent decision-making systems. <em>AIR</em>, <em>56</em>(4),
3445–3472. (<a
href="https://doi.org/10.1007/s10462-022-10255-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concepts based on psychology fit well with current research trends related to robotics and artificial intelligence. Biology-inspired cognitive architectures are extremely useful in building agents and robots, and this is one of the most important challenges of modern science. Therefore, the widely viewed and far-reaching goal of systems research and engineering is virtual agents and autonomous robots that mimic human behavior in solving known and unknown problems. The article proposes, at a high level of generality, an operational cybernetic model of the human mind, developed with the use of carefully selected ideas taken from psychological knowledge. In particular, the work combines extensive knowledge drawn from both the theory of developmental cognitive psychology and the theory of motivation. The proposed mathematically developed operating blocks create a coherent and functional decision-making system containing all the elements necessary in autonomous robotics. The ISD system is under development. There is still a long way to go to full validation. However, as shown in several articles, the basic subsystems of the ISD system, i.e. motivational and emotional, have already been positively verified in operation. The overall purpose of this article is to show a blueprint of the overall concept of the entire ISD.},
  archive      = {J_AIR},
  author       = {Kowalczuk, Zdzisław and Czubenko, Michał},
  doi          = {10.1007/s10462-022-10255-9},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3445-3472},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Cognitive motivations and foundations for building intelligent decision-making systems},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of the literature on fuzzy-logic approaches for
collision-free path planning of manipulator robots. <em>AIR</em>,
<em>56</em>(4), 3369–3444. (<a
href="https://doi.org/10.1007/s10462-022-10257-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, a large number of manipulator robots have been deployed to replace or assist humans in many repetitive and dangerous tasks. Yet, these robots have complex mechanisms, resulting in their non-linearity of kinematics and dynamics as well as intensive computations. Therefore, relying on soft computing techniques are a common and alternative key to model and control these systems. In particular, fuzzy logic approaches have proven to be simple, efficient, and superior to relevant well-known methods and have sparked greater interest in robotic applications. To help researchers meet their needs easily and quickly in finding relevant research works on fuzzy-based solutions, this article adapted to provide an in-depth review of the currently updated fuzzy logic approaches for collision-free path planning of serial manipulator robots operating in complex and cluttered workspaces. In addition to a comprehensive description of fuzzy hybridization with other artificial intelligence techniques description. Further, this article attempts to present the main solutions with a summary and visualization of all basic approaches that path-planning problems may subtend in the decision-making process. Finally, the paper suggests some potential challenges and explores research issues for future work.},
  archive      = {J_AIR},
  author       = {Hentout, Abdelfetah and Maoudj, Abderraouf and Aouache, Mustapha},
  doi          = {10.1007/s10462-022-10257-7},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3369-3444},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review of the literature on fuzzy-logic approaches for collision-free path planning of manipulator robots},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Anomaly detection in surveillance videos: A thematic
taxonomy of deep models, review and performance analysis. <em>AIR</em>,
<em>56</em>(4), 3319–3368. (<a
href="https://doi.org/10.1007/s10462-022-10258-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of anomaly detection has recently gained much attention in the field of visual surveillance. Video surveillance data is often available in large quantities, but manual annotation of activities in video segments is tedious. Anomaly detection plays a crucial role in various indoor and outdoor surveillance applications. Video anomaly detection is highly challenging and provides a lot of scope and demand for improving detection performance in real-time scenarios. Recently, deep learning-based approaches are promising to detect single-scene video anomalies in real-time. This work starts by highlighting the over-view of deep learning-based video anomaly detection. A thematic taxonomy that includes four major categories and several sub-categories is presented. State-of-the-art deep learning approaches under these categories are reviewed. In addition, few recent one class model based deep learning approaches are evaluated and analyzed in terms of performance. Out of the approaches presented, Generative Adversarial Network (GAN) and Adversarial Autoencoder-based approaches provide a better detection rate. A few important directions are outlined for further research in the field of video surveillance applications.},
  archive      = {J_AIR},
  author       = {Chandrakala, S. and Deepak, K. and Revathy, G.},
  doi          = {10.1007/s10462-022-10258-6},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3319-3368},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Anomaly detection in surveillance videos: A thematic taxonomy of deep models, review and performance analysis},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An active deep learning method for diabetic retinopathy
detection in segmented fundus images using artificial bee colony
algorithm. <em>AIR</em>, <em>56</em>(4), 3291–3318. (<a
href="https://doi.org/10.1007/s10462-022-10231-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal fundus image analysis (RFIA) is frequently used in diabetic retinopathy (DR) scans to determine the risk of blindness in diabetic patients. Ophthalmologists receive support from various RFIA programs to cope with the detection of visual impairments. In this article, active deep learning (ADL) using new multi-layer architecture for automatic recognition of DR stages is presented. In order to facilitate the detection of retinal lesions in the ADL system preprocessing, the image is segmented using the artificial bee colony (ABC) algorithm with a threshold value determined according to the results of the image histogram. Besides, a tag-efficient convolutional neural networks (CNN) architecture known as ADL-CNN has been developed to automatically extract segmented retinal features. This model has a two-stage process. In the first, images are selected to learn simple or complex retinal features using basic accuracy labels in the training examples. Second, useful masks are provided with key lesion features and segment areas of interest within the retinal image. Performance evaluation of the proposed ADL-CNN model is made by comparing the most advanced methods using the same dataset. The efficiency of the system is made by measuring statistical metrics such as classification accuracy (ACC), sensitivity (SE), specificity (SP), and F-measure. The ADL-CNN model applied to the EyePacs dataset containing 35,122 retinal images yielded 99.66\% ACC, 93.76\% SE, 96.71\% SP, and 94.58\% F-measure. In this respect, it can be said that the proposed method shows high performance in detecting DR lesions from various fundus images and determining the severity level.},
  archive      = {J_AIR},
  author       = {Özbay, Erdal},
  doi          = {10.1007/s10462-022-10231-3},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3291-3318},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An active deep learning method for diabetic retinopathy detection in segmented fundus images using artificial bee colony algorithm},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Heuristic and metaheuristic methods for the parallel
unrelated machines scheduling problem: A survey. <em>AIR</em>,
<em>56</em>(4), 3181–3289. (<a
href="https://doi.org/10.1007/s10462-022-10247-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scheduling has an immense effect on various areas of human lives, be it though its application in manufacturing and production industry, transportation, workforce allocation, or others. The unrelated parallel machines scheduling problem (UPMSP), which is one of the various problem types that exist, found its application in many areas like manufacturing and distributed computing. Due to the complexity of the problem, heuristic and metaheuristic methods have dominantly been applied for solving it. Although this problem variant did not receive much attention as other models, recent years saw the increase of research dealing with the UPMSP. During that time, different problem variants, solution methods, and interesting research directions were considered. However, no study provided a systematic overview of the research in which heuristic methods are applied for solving the UPMSP. This comes as a problem since it is becoming difficult to keep track of all the relevant research directions and solution methods considered for this problem. Therefore, the goal of this study is to provide an extensive literature review on the application of heuristic and metaheuristic methods for solving the UPMSP. Each reviewed study is briefly described based on the considered problem and solution method. Additionally, studies dealing with similar problems are grouped together to outline the evolution of the research, and possible areas where further research can be carried out. All studies were systematised and classified into several categories to allow for an easy overview of different problem and solution variants. Finally, recent research trends and possible future directions are also outlined.},
  archive      = {J_AIR},
  author       = {Ɖurasević, Marko and Jakobović, Domagoj},
  doi          = {10.1007/s10462-022-10247-9},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3181-3289},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Heuristic and metaheuristic methods for the parallel unrelated machines scheduling problem: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge discovery and variable scale evaluation for long
series data. <em>AIR</em>, <em>56</em>(4), 3157–3180. (<a
href="https://doi.org/10.1007/s10462-022-10250-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge discovery and evaluation is a challenging but rewarding process of obtaining available information automatically from database. Due to the heterogeneity of the collected data, the connotative knowledge has the characteristics of uncertainty, random occurrence and variable scale. Therefore, an unsupervised knowledge discovery and variable scale evaluation model is presented in this paper based on a new multi-feature fusion method. Firstly, point at the multiple information features, an amplitude-frequency-shape based state description form is proposed in this paper. It could analyze the time series from the aspects of energy, phase, and knowledge similarity. In view of the variable number and scale of knowledge fragments, a piecewise linear segmentation criterion is put forward based on the complexity and accuracy of information representation. Then a model free knowledge discovery framework without samples labels is constructed to discover the knowledge quickly and effectively. Aimed at the variable knowledge scale, a variable scale evaluation method is first proposed to distinguish the multi-scale decision-making knowledge based on the indicators of system stability and security. It could optimize the knowledge base and guide the decision-making process. The experimental results on heterogeneous activity datasets indicate that the proposed method here could generally analysis the time series state and discover the knowledge efficiently from massive data. In addition, the knowledge discovery and evaluation at a continuous decision system show that the proposed framework could meet the needs of knowledge discovery in complex environment and effectively distinguish the knowledge to provide strong support for establishing a credible decision-making system.},
  archive      = {J_AIR},
  author       = {Zhai, Yanwei and Lv, Zheng and Zhao, Jun and Wang, Wei},
  doi          = {10.1007/s10462-022-10250-0},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3157-3180},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Knowledge discovery and variable scale evaluation for long series data},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recent advances in deep learning based dialogue systems: A
systematic survey. <em>AIR</em>, <em>56</em>(4), 3055–3155. (<a
href="https://doi.org/10.1007/s10462-022-10248-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dialogue systems are a popular natural language processing (NLP) task as it is promising in real-life applications. It is also a complicated task since many NLP tasks deserving study are involved. As a result, a multitude of novel works on this task are carried out, and most of them are deep learning based due to their outstanding performance. In this survey, we mainly focus on the deep learning based dialogue systems. We comprehensively review state-of-the-art research outcomes in dialogue systems and analyze them from two angles: model type and system type. Specifically, from the angle of model type, we discuss the principles, characteristics, and applications of different models that are widely used in dialogue systems. This will help researchers acquaint these models and see how they are applied in state-of-the-art frameworks, which is rather helpful when designing a new dialogue system. From the angle of system type, we discuss task-oriented and open-domain dialogue systems as two streams of research, providing insight into the hot topics related. Furthermore, we comprehensively review the evaluation methods and datasets for dialogue systems to pave the way for future research. Finally, some possible research trends are identified based on the recent research outcomes. To the best of our knowledge, this survey is the most comprehensive and up-to-date one at present for deep learning based dialogue systems, extensively covering the popular techniques. We speculate that this work is a good starting point for academics who are new to the dialogue systems or those who want to quickly grasp up-to-date techniques in this area.},
  archive      = {J_AIR},
  author       = {Ni, Jinjie and Young, Tom and Pandelea, Vlad and Xue, Fuzhao and Cambria, Erik},
  doi          = {10.1007/s10462-022-10248-8},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3055-3155},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Recent advances in deep learning based dialogue systems: A systematic survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human-in-the-loop machine learning: A state of the art.
<em>AIR</em>, <em>56</em>(4), 3005–3054. (<a
href="https://doi.org/10.1007/s10462-022-10246-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers are defining new types of interactions between humans and machine learning algorithms generically called human-in-the-loop machine learning. Depending on who is in control of the learning process, we can identify: active learning, in which the system remains in control; interactive machine learning, in which there is a closer interaction between users and learning systems; and machine teaching, where human domain experts have control over the learning process. Aside from control, humans can also be involved in the learning process in other ways. In curriculum learning human domain experts try to impose some structure on the examples presented to improve the learning; in explainable AI the focus is on the ability of the model to explain to humans why a given solution was chosen. This collaboration between AI models and humans should not be limited only to the learning process; if we go further, we can see other terms that arise such as Usable and Useful AI. In this paper we review the state of the art of the techniques involved in the new forms of relationship between humans and ML algorithms. Our contribution is not merely listing the different approaches, but to provide definitions clarifying confusing, varied and sometimes contradictory terms; to elucidate and determine the boundaries between the different methods; and to correlate all the techniques searching for the connections and influences between them.},
  archive      = {J_AIR},
  author       = {Mosqueira-Rey, Eduardo and Hernández-Pereira, Elena and Alonso-Ríos, David and Bobes-Bascarán, José and Fernández-Leal, Ángel},
  doi          = {10.1007/s10462-022-10246-w},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3005-3054},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Human-in-the-loop machine learning: A state of the art},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An extended EDAS approach based on cumulative prospect
theory for multiple attributes group decision making with probabilistic
hesitant fuzzy information. <em>AIR</em>, <em>56</em>(4), 2971–3003. (<a
href="https://doi.org/10.1007/s10462-022-10244-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Probabilistic Hesitant Fuzzy Sets (PHFS) based on the hesitant fuzzy sets has been paid great attention. Though numerous methods have been applied in this environment since the PHFS has been introduced, there are still new fields to be explored. The EDAS method which is the abbreviation of the evaluation based on distance from average solution is one of the practical methods in circumstances which is with contradictory attributes. Considering the uncertain character of the PHF condition and the psychological factors which influence decision makers’ behaviors such as the character and risk reference, the probabilistic hesitant fuzzy EDAS integrating with cumulative prospect theory (PHF-CPT-EDAS) is built for multiple attributes group decision making (MAGDM) problem. Meanwhile, the information of entropy is also utilized to calculate the unknown weighting vector of attributes. At last, we utilize two case studies to compare the designed method with other MADM methods. Through this article, we learn that the PHF-CPT-EDAS method is effective and stable to solve the MAGDM issues.},
  archive      = {J_AIR},
  author       = {Liao, Ningna and Gao, Hui and Lin, Rui and Wei, Guiwu and Chen, Xudong},
  doi          = {10.1007/s10462-022-10244-y},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2971-3003},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An extended EDAS approach based on cumulative prospect theory for multiple attributes group decision making with probabilistic hesitant fuzzy information},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning models and traditional automated techniques
for brain tumor segmentation in MRI: A review. <em>AIR</em>,
<em>56</em>(4), 2923–2969. (<a
href="https://doi.org/10.1007/s10462-022-10245-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain is an amazing organ that controls all activities of a human. Any abnormality in the shape of anatomical regions of the brain needs to be detected as early as possible to reduce the mortality rate. It is also beneficial for treatment planning and therapy. The most crucial task is to isolate abnormal areas from normal tissue regions. To identify abnormalities in the earlier stage, various medical imaging modalities were used by medical practitioners as part of the diagnosis. Magnetic Resonance Imaging (MRI) is a non-invasive diagnostic tool used for analyzing the internal structures owing to its capability to provide images with high resolution and better contrast for soft tissues. This survey focuses on studies done in brain MRI. Manual segmentation of abnormal tissues is a time-consuming task, and the performance depends on the expert’s efficiency. Hence automating tumor segmentation plays a vital role in medical imaging applications. This study aims to provide a comprehensive survey on recent works developed in brain tumor segmentation. In this paper, a systematic literature review is presented to the reader to understand three policies, namely classical scheme, machine learning strategy, and deep learning methodology meant for tumor segmentation. Our primary goal is to include classical methods like atlas-based strategy and statistical-based models employed for segmenting tumors from brain MRI. Few studies that utilized machine learning approaches for the segmentation and classification of brain structures are also discussed. After that, the study provides an overview of deep learning-based segmentation models for quantitative analysis of brain MRI. Deep learning plays a vital role in the automatic segmentation of brain tissues. Presently deep learning technique outshines traditional statistical methods and machine learning approaches. An effort is made to enclose the literature on patch-based and semantic-based tissue segmentation presented by researchers working in the discipline of medical imaging. The manuscript discusses the basic convolutional neural network architecture, Data Sets, and the existing deep learning techniques for tissue segmentation coupled with classification. This paper also attempts to summarize the current works in Convolutional Neural networks and Autoencoders that assist researchers in seeking future directions. Finally, this article is concluded with possible developments and open challenges in brain tumor segmentation.},
  archive      = {J_AIR},
  author       = {Jyothi, Parvathy and Singh, A. Robert},
  doi          = {10.1007/s10462-022-10245-x},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2923-2969},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep learning models and traditional automated techniques for brain tumor segmentation in MRI: A review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of transfer learning for machinery diagnostics and
prognostics. <em>AIR</em>, <em>56</em>(4), 2871–2922. (<a
href="https://doi.org/10.1007/s10462-022-10230-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industrial manufacturing systems, failures of machines caused by faults in their key components greatly influence operational safety and system reliability. Many data-driven methods have been developed for machinery diagnostics and prognostics. However, there lacks sufficient labeled data to train a high-performance data-driven model. Moreover, machinery datasets are usually collected from different operation conditions and mechanical components, leading to poor model generalization. To address these concerns, cross-domain transfer learning methods are applied to enhance the feasibility and accuracy of data-driven methods for machinery diagnostics and prognostics. This paper presents a comprehensive survey about how recent studies apply diverse transfer learning methods into machinery tasks including diagnostics and prognostics. Three types of commonly-used transfer methods, i.e., model and parameter transfer, feature matching and adversarial adaptation, are systematically summarized and elaborated on their main ideas, typical models and corresponding representative studies on machinery diagnostics and prognostics. In addition, ten widely-used open-source machinery datasets are presented. Based on recent research progress, this survey expounds emerging challenges and future research directions of transfer learning for industrial applications. This survey presents a systematic review of recent research with clear explanations as well as in-depth insights, thereby helping readers better understand transfer learning for machinery diagnostics and prognostics.},
  archive      = {J_AIR},
  author       = {Yao, Siya and Kang, Qi and Zhou, MengChu and Rawa, Muhyaddin J. and Abusorrah, Abdullah},
  doi          = {10.1007/s10462-022-10230-4},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2871-2922},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of transfer learning for machinery diagnostics and prognostics},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved moth flame optimization algorithm based on
modified dynamic opposite learning strategy. <em>AIR</em>,
<em>56</em>(4), 2811–2869. (<a
href="https://doi.org/10.1007/s10462-022-10218-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Moth flame optimization (MFO) algorithm is a relatively new nature-inspired optimization algorithm based on the moth’s movement towards the moon. Premature convergence and convergence to local optima are the main demerits of the algorithm. To avoid these drawbacks, a modified dynamic opposite learning-based MFO algorithm (m-DMFO) is presented in this paper, incorporating a modified dynamic opposite learning (DOL) strategy. To validate the performance of the proposed m-DMFO algorithm, it is tested via twenty-three benchmark functions, IEEE CEC’2014 test functions and compared with a wide range of optimization algorithms. Moreover, Friedman rank test, Wilcoxon rank test, convergence analysis, and diversity measurement have been conducted to measure the robustness of the proposed m-DMFO algorithm. The numerical results show that, the proposed m-DMFO algorithm achieved superior results in more than 90\% occasions. The proposed m-DMFO achieves the best rank in Friedman rank test and Wilcoxon rank test respectively. In addition, four engineering design problems have been solved by the suggested m-DMFO algorithm. According to the results, it achieves extremely impressive results, which also illustrates that the algorithm is qualified in solving real-world problems. Analyses of numerical results, diversity measure, statistical tests and convergence results ensure the enhanced performance of the proposed m-DMFO algorithm.},
  archive      = {J_AIR},
  author       = {Sahoo, Saroj Kumar and Saha, Apu Kumar and Nama, Sukanta and Masdari, Mohammad},
  doi          = {10.1007/s10462-022-10218-0},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2811-2869},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An improved moth flame optimization algorithm based on modified dynamic opposite learning strategy},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explainable recommendations with nonnegative matrix
factorization. <em>AIR</em>, <em>56</em>(3), 3927–3955. (<a
href="https://doi.org/10.1007/s10462-023-10619-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explicable recommendation system is proved to be conducive to improving the persuasiveness of the recommendation system, enabling users to trust the system more and make more intelligent decisions. Nonnegative Matrix Factorization (NMF) produces interpretable solutions for many applications including collaborative filtering as it’s nonnegativity. However, the latent features make it difficult to interpret recommendation results to users because we don’t know the specific meaning of features that users are interested in and the extent to which the items or users belong to these features. To overcome this difficulty, we develop a novel method called Partially Explainable Nonnegative Matrix Factorization (PE-NMF) by employing explicit data to replace part latent variables of item-feature matrix, by which users can learn more about the features of the items and then to make ideal decisions and recommendations. The objective function of PE-NMF is composed of two parts: one part corresponding to explicit features and the other part is about implicit features. We develop an iterative method to minimize the objective function and derive the iterative update rules, with which the objective function can be proved to be decreasing. Finally, the experiments are executed on Yelp, Amazon and Dianping datasets, and the experimental results demonstrate PE-NMF keeps a high prediction performance on both rating prediction and top-N recommendation that compare to fully explainable nonnegative matrix factorization (FE-NMF), which is obtained by using explicit opinions instead of item-feature matrix. Also PE-NMF holds almost the same recommendation ability as NMF.},
  archive      = {J_AIR},
  author       = {Zhang, Xiaoxia and Zhou, Xianjun and Chen, Lu and Liu, Yanjun},
  doi          = {10.1007/s10462-023-10619-9},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {3927-3955},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Explainable recommendations with nonnegative matrix factorization},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An enhanced salp swarm optimizer boosted by local search
algorithm for modelling prediction problems in software engineering.
<em>AIR</em>, <em>56</em>(3), 3877–3925. (<a
href="https://doi.org/10.1007/s10462-023-10618-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientific communities are still motivated to create novel approaches and methodologies for early estimation of software project development efforts and testing efforts in soft computing environments due to scheduling and budgetary concerns. Therefore, the software engineering prediction problems (SEPPs) are formulated as machine learning (ML) models with the aim of addressing these issues. In such methodologies that may exhibit significant limitations and drawbacks, efficient metaheuristic approaches are essential to improving prediction performance. Accordingly, this study aims to address software test effort prediction (STP) and software development effort prediction (SEP) with the aim of maximizing prediction accuracy, which in turn minimizes overall project costs and optimizes resource allocation. To achieve this goal, we developed several ML models composed of a backpropagation neural network (BPNN). The proposed models contain the Salp Swarm Algorithm (SSA), which is utilized to replace the traditional network training method and tackle its limitations. The models also contain the great deluge (GD) local search algorithm, which is hybridized with the SSA algorithm to enhance optimization capabilities by finding more balance between exploration and exploitation. During the validation stage of this study, fourteen benchmark datasets were utilized to evaluate the developed models for each of the respective problems. The obtained results were quantified using eight performance metrics and compared across two sections. In the first section, a comparison was made between the results of the hybrid-developed model (HSSA) and those of the standard SSA algorithm and BPNN. In the second comparison, the performance of the HSSA model was compared with several contemporary techniques that are considered state-of-the-art. The evaluation shows that the HSSA performs better than related approaches in most cases for both problems. Finally, additional analysis was performed on the collected results, including examinations of statistical significance, distribution through box plots, and model convergence behavior.},
  archive      = {J_AIR},
  author       = {Kassaymeh, Sofian and Abdullah, Salwani and Al-Betar, Mohammed Azmi and Alweshah, Mohammed and Salem, Amer Abu and Makhadmeh, Sharif Naser and Al-Ma’aitah, Mohammad Atwah},
  doi          = {10.1007/s10462-023-10618-w},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {3877-3925},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An enhanced salp swarm optimizer boosted by local search algorithm for modelling prediction problems in software engineering},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning for food security: Current status,
challenges, and future perspectives. <em>AIR</em>, <em>56</em>(3),
3853–3876. (<a
href="https://doi.org/10.1007/s10462-023-10617-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A significant amount of study has been conducted on food security forecasting, yet, few systematic reviews of the literature in this context are available. Recently, Machine Learning (ML) techniques have been widely applied to support food security using heterogeneous and complex data. The current manuscript exposes a systematic literature review to investigate various ML and Deep Learning (DL) models used in food security tasks (e.g. cropland mapping, crop type mapping, crop yield prediction and field delineation). This literature review identifies a clear end-to-end process of food security employing ML and DL models. Regular literature reviews and syntheses in food security are required to enable the researchers to expand on existing knowledge and identify key knowledge deficits and new research directions in this field. Eventually, it summarizes the challenges of using ML and DL in food security analysis in complex and heterogeneous data, computational analysis, evaluation challenges and future directions.},
  archive      = {J_AIR},
  author       = {Jarray, Noureddine and Abbes, Ali Ben and Farah, Imed Riadh},
  doi          = {10.1007/s10462-023-10617-x},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {3853-3876},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Machine learning for food security: Current status, challenges, and future perspectives},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). From multi-view data features to clusters: A unified
approach. <em>AIR</em>, <em>56</em>(3), 3821–3852. (<a
href="https://doi.org/10.1007/s10462-023-10616-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering data from multiple sources or views has become an important issue in real-world applications. Graph-based methods take advantage of graphs that encode the local and global structure of the data. Although graph-based methods provide good clustering performance, they need to estimate the view graphs or the consensus graph from the raw data in a separate step. Their performance may be affected by the noisy graphs. To overcome this limitation and promote end-to-end multi-view clustering solutions, this paper presents two end-to-end multi-view clustering solutions starting from the data or their kernel representations. The first proposed solution is based on a single objective function that allows the joint estimation of the graph of each view, the consensus graph, the spectral projection matrices for all views, the soft clustering assignments, and the weights of each view. The second solution uses a different objective function where the links and constraints for the soft clustering assignment matrix use the consensus graph matrix and the consensus spectral projection matrix. Both methods enforce the mutual similarity of each graph and provide a direct clustering result without any additional step. The two proposed methods are tested on several real image and text datasets, which prove their superiority.},
  archive      = {J_AIR},
  author       = {Dornaika, Fadi},
  doi          = {10.1007/s10462-023-10616-y},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {3821-3852},
  shortjournal = {Artif. Intell. Rev.},
  title        = {From multi-view data features to clusters: A unified approach},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-evolving reasoning for task-user relationships in
mobile crowdsensing via the autonomic knowledge graph. <em>AIR</em>,
<em>56</em>(3), 3789–3819. (<a
href="https://doi.org/10.1007/s10462-023-10615-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A self-evolving reasoning method for task-user relationships based on the autonomic knowledge graph is proposed for the problem of existing task assignment methods, which cannot cope with dynamic environment changes in mobile crowd sensing. In particular, with the idea of “self-reflection,” “self-configuration,” and “self-adjustment” from autonomic computing, the concept of the autonomic knowledge graph is proposed for the first time. We apply it to build the complete cycle of the knowledge graph, which ensures the dynamic mapping between the task-user relationships in the mobile crowdsensing system. “Self-reflection” generates real-time responses to changes in the internal and external environment of the system. “Self-configuration” selects high-quality sensing users and filters the mobile crowd sensing knowledge graph paths to ensure the reliability of sensing users. Based on the filtered paths, “self-adjustment” computes the neighbor weight matrix of nodes to update node embeddings and exploit potential connections between task-user nodes. Finally, link prediction between task-user nodes achieves accurate and effective task recommendations. This self-evolving reasoning method of nodal relationships we designed combines autonomic computing with the knowledge graph. It forms a continuously operating loop that the next moment of sensing quality is assured and enhanced in the mobile crowd sensing system. Experiments based on the real-world Gollowa dataset, the public Last-FM dataset, and the Amazon-book dataset show that the proposed method can effectively improve sensing data quality and the accuracy of task recommendations.},
  archive      = {J_AIR},
  author       = {Wang, Jian and Yan, Yuping and Zhao, Guosheng},
  doi          = {10.1007/s10462-023-10615-z},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {3789-3819},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Self-evolving reasoning for task-user relationships in mobile crowdsensing via the autonomic knowledge graph},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Conflict detection and elimination integrating agent’s
influence and conflict coefficient with incomplete trust relationship.
<em>AIR</em>, <em>56</em>(3), 3749–3787. (<a
href="https://doi.org/10.1007/s10462-023-10614-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conflict analysis and resolution provide effective decision support for management problems with uncertainty and inconsistency. Conflict refers to the multi-agents’ inconsistent attitudes towards issues of common concern. Conflict analysis aims to find the intrinsic causes of conflict to find consensus strategies. And agents in the conflict situation constitute a social network. Trust relationship plays a crucial role in the social network. In this paper, we introduce trust mechanism in the conflict analysis under the framework of granular computing to investigate the impact of trust relationship on the conflict situation. And we propose a theoretical model for conflict detection and elimination that integrates agent’s influence and conflict coefficient of quantitative three-way opinion subsets (CC–OS). We achieve conflict detection and elimination through four stages: trust propagation process, consensus willingness reaching, determine agent’s weight and conflict detection and elimination. We illustrate the proposed model and method by analyzing a realistic conflict problem and verify the effectiveness and superiority of the model. The main contribution of this paper is twofold. One is to make a new theoretical contribution to multi-agents conflict analysis from the perspective of trust social network. Another is to provide a more quantitative basis for specific conflict analysis and decision-making.},
  archive      = {J_AIR},
  author       = {Qin, Xiaoyan and Sun, Bingzhen and Ye, Jin and Bao, Qiang and Chu, Xiaoli},
  doi          = {10.1007/s10462-023-10614-0},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {3749-3787},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Conflict detection and elimination integrating agent’s influence and conflict coefficient with incomplete trust relationship},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Incorporating q-learning and gradient search scheme into
JAYA algorithm for global optimization. <em>AIR</em>, <em>56</em>(3),
3705–3748. (<a
href="https://doi.org/10.1007/s10462-023-10613-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many swarm intelligence techniques are facing rigorous challenges since they cannot exploit useful information well during the evolutionary procedure. To remedy this issue, this paper raises a reinforced JAYA algorithm (QLJAYA) that employs the Q-learning and gradient search scheme. In QLJAYA, to balance convergence and diversity, a modified search formula and gradient search scheme are adaptively selected to generate solutions under the control of Q-learning. In addition, to strengthen the rotational invariance of JAYA, the covariance matrix learning strategy is adopted to construct an eigen coordinate system for each solution. Experimental simulations on CEC2017 and CEC2019 test suites and application to identify parameters of photovoltaic systems suggest that QLJAYA can exhibit a better or at least competitive overall performance compared to several typical JAYA variants and other well-known metaheuristics. The source code of  QLJAYA is publicly available at https://github.com/denglingyun123/QLJAYA .},
  archive      = {J_AIR},
  author       = {Deng, Lingyun and Liu, Sanyang},
  doi          = {10.1007/s10462-023-10613-1},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {3705-3748},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Incorporating Q-learning and gradient search scheme into JAYA algorithm for global optimization},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep neural network techniques for monaural speech
enhancement and separation: State of the art analysis. <em>AIR</em>,
<em>56</em>(3), 3651–3703. (<a
href="https://doi.org/10.1007/s10462-023-10612-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNN) techniques have become pervasive in domains such as natural language processing and computer vision. They have achieved great success in tasks such as machine translation and image generation. Due to their success, these data driven techniques have been applied in audio domain. More specifically, DNN models have been applied in speech enhancement and separation to perform speech denoising, dereverberation, speaker extraction and speaker separation. In this paper, we review the current DNN techniques being employed to achieve speech enhancement and separation. The review looks at the whole pipeline of speech enhancement and separation techniques from feature extraction, how DNN-based tools models both global and local features of speech, model training (supervised and unsupervised) to how they address label ambiguity problem. The review also covers the use of domain adaptation techniques and pre-trained models to boost speech enhancement process. By this, we hope to provide an all inclusive reference of all the state of art DNN based techniques being applied in the domain of speech separation and enhancement. We further discuss future research directions. This survey can be used by both academic researchers and industry practitioners working in speech separation and enhancement domain.},
  archive      = {J_AIR},
  author       = {Ochieng, Peter},
  doi          = {10.1007/s10462-023-10612-2},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {3651-3703},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep neural network techniques for monaural speech enhancement and separation: State of the art analysis},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Projection based regret theory on three-way decision model
in probabilistic interval-valued q-rung orthopair hesitant fuzzy set and
its application to medicine company. <em>AIR</em>, <em>56</em>(3),
3617–3649. (<a
href="https://doi.org/10.1007/s10462-023-10611-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way decision (3WD) can be used to handle complexity and uncertainty in decision-making problems, and is compatible with human cognitive systems. For insufficient existing experiences, decision-makers (DMs) can select interval fuzzy information, as the information about medicine company is more hesitation, imprecision, and ambiguity. In the determination process, DMs may not take suitable decisions by choosing membership and non-membership degree of imprecise information. To improve fault-tolerance and validate the plausibility of DMs’ evaluation, the probabilistic interval-valued q-rung orthopair hesitant fuzzy set (PIVq-ROHFS) is introduced. Additionally, distinct psychological behaviours of DMs have an impact on the outcomes of decision-making. For this situation, we first develop a regret theory based 3WD model in PIVq-ROHFS to evaluate the utility value of the objects. The core focus of regret theory is to develop a new regret-rejoice function based on projection theory. Another core focus of this inquisition is to propose a novel multi-criteria decision making (MCDM) method for evaluating conditional probability in 3WD model. The criteria’s weight in MCDM method is evaluated by a newly proposed multi-objective optimization (MOO) problem. To solve the MOO problem, we utilize a hybrid technique by combining particle swarm optimization and multi-choice goal programming with utility function.},
  archive      = {J_AIR},
  author       = {Giri, Binoy Krishna and Roy, Sankar Kumar and Deveci, Muhammet},
  doi          = {10.1007/s10462-023-10611-3},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {3617-3649},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Projection based regret theory on three-way decision model in probabilistic interval-valued q-rung orthopair hesitant fuzzy set and its application to medicine company},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning for leaf disease classification: Data,
techniques and applications. <em>AIR</em>, <em>56</em>(3), 3571–3616.
(<a href="https://doi.org/10.1007/s10462-023-10610-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing demand for sustainable development brings a series of information technologies to help agriculture production. Especially, the emergence of machine learning applications, a branch of artificial intelligence, has shown multiple breakthroughs which can enhance and revolutionize plant pathology approaches. In recent years, machine learning has been adopted for leaf disease classification in both academic research and industrial applications. Therefore, it is enormously beneficial for researchers, engineers, managers, and entrepreneurs to have a comprehensive view about the recent development of machine learning technologies and applications for leaf disease detection. This study will provide a survey in different aspects of the topic including data, techniques, and applications. The paper will start with publicly available datasets. After that, we summarize common machine learning techniques, including traditional (shallow) learning, deep learning, and augmented learning. Finally, we discuss related applications. This paper would provide useful resources for future study and application of machine learning for smart agriculture in general and leaf disease classification in particular.},
  archive      = {J_AIR},
  author       = {Yao, Jianping and Tran, Son N. and Sawyer, Samantha and Garg, Saurabh},
  doi          = {10.1007/s10462-023-10610-4},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {3571-3616},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Machine learning for leaf disease classification: Data, techniques and applications},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Survey on video anomaly detection in dynamic scenes with
moving cameras. <em>AIR</em>, <em>56</em>(3), 3515–3570. (<a
href="https://doi.org/10.1007/s10462-023-10609-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing popularity of compact and inexpensive cameras, e.g. dash cameras, body cameras, and cameras equipped on robots, has sparked a growing interest in detecting anomalies within dynamic scenes recorded by moving cameras. However, existing reviews primarily concentrate on video anomaly detection (VAD) methods assuming static cameras. The VAD literature with moving cameras remains fragmented, lacking comprehensive reviews to date. To address this gap, we endeavor to present the first comprehensive survey on moving camera video anomaly detection (MC-VAD). We delve into the research papers related to MC-VAD, critically assessing their limitations and highlighting associated challenges. Our exploration encompasses three application domains: security, urban transportation, and marine environments, which in turn cover six specific tasks. We compile an extensive list of 25 publicly-available datasets spanning four distinct environments: underwater, water surface, ground, and aerial. We summarize the types of anomalies these datasets correspond to or contain, and present five main categories of approaches for detecting such anomalies. Lastly, we identify future research directions and discuss novel contributions that could advance the field of MC-VAD. With this survey, we aim to offer a valuable reference for researchers and practitioners striving to develop and advance state-of-the-art MC-VAD methods.},
  archive      = {J_AIR},
  author       = {Jiao, Runyu and Wan, Yi and Poiesi, Fabio and Wang, Yiming},
  doi          = {10.1007/s10462-023-10609-x},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {3515-3570},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Survey on video anomaly detection in dynamic scenes with moving cameras},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distance measures on intuitionistic fuzzy sets based on
cross-information dissimilarity and their diverse applications.
<em>AIR</em>, <em>56</em>(3), 3471–3514. (<a
href="https://doi.org/10.1007/s10462-023-10608-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, two new distance measures are introduced, which are used in various application problems in decision-making, pattern recognition, and clustering. Intuitionistic fuzzy sets are sources of information that contain both the membership and non-membership degrees of the elements in the set. As such, distance measures based on geometric concepts are sometimes misleading. Hence, six parameters are identified to construct the distance measures. These parameters are membership information dissimilarity, non-membership information dissimilarity, hesitancy information dissimilarity, product cross-information dissimilarity, maximum cross-information dissimilarity, and minimum cross-information dissimilarity. Among all the parameters, the product cross-information dissimilarity is newly introduced in this work. Compensations for the proposed distance measures are established by various counter-intuitive problems in decision-making and pattern recognition. Finally, validation of the proposed distance measures is established by diverse problems of applications in decision-making, pattern recognition, and clustering problems.},
  archive      = {J_AIR},
  author       = {Gogoi, Surabhi and Gohain, Brindaban and Chutia, Rituparna},
  doi          = {10.1007/s10462-023-10608-y},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {3471-3514},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Distance measures on intuitionistic fuzzy sets based on cross-information dissimilarity and their diverse applications},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Regret theory based three-way conflict analysis model under
q-rung orthopair fuzzy information: Studies with parameter and three-way
decision-making-based approaches. <em>AIR</em>, <em>56</em>(3),
3417–3469. (<a
href="https://doi.org/10.1007/s10462-023-10607-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In any conflict analysis model, agents are decision-makers (DMs). In reality, the regret psychology of DMs often influence decision outcomes due to uncertain risks. However, the existing conflict analysis model avoids DMs’ regret psychology. The q-rung orthopair fuzzy information (q-ROFIS) with regret theory (RT)-based conflict analysis in detail is a primary aim of this study to solve more complex and uncertain-conflict problems than possible within the confinement of current knowledge. First, we define RT-based q-rung orthopair fuzzy conflict distance (q-ROFCD) in a pair and show that our q-ROFCD holds symmetry and triangular inequality. Using q-ROFCD, we have studied pre-defined parameters and three-way decision (3WD) theory-based conflict analysis. In pre-defined parameters-based conflict analysis, we trisect the agents according to single and multiple issues, define q-rung orthopair fuzzy conflict of each issue and issue set, trisect issues, provide a feasible strategy for a conflict situation, define the conflict degree of each agent and agent set, and finally find out the intrinsic reasons for the conflict are. In 3WD theory based-conflict analysis, we trisect the agents according to single and multiple issues using Bayesian minimum cost theory, define conflict region, rank the issues, introduce three-way coalitions of agents and finally define maximal coalition of agents. At last, the stability and validity of the proposed model are verified via an application, sensitive analysis and comparative analysis with similar studies.},
  archive      = {J_AIR},
  author       = {Mandal, Prasenjit and Samanta, Sovan and Pal, Madhumangal and Ranadive, A. S.},
  doi          = {10.1007/s10462-023-10607-z},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {3417-3469},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Regret theory based three-way conflict analysis model under q-rung orthopair fuzzy information: Studies with parameter and three-way decision-making-based approaches},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Emotion quantification techniques for cognitive reappraisal:
A systematic review and scientometric analysis. <em>AIR</em>,
<em>56</em>(3), 3363–3416. (<a
href="https://doi.org/10.1007/s10462-023-10606-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive reappraisal intends to study the significance of an event concerning any emotional reaction. Understanding the efficacy of cognitive reappraisal in emotion regulation requires reliable and valid techniques for quantifying emotions. Sentiments and emotions are complex mental states that play a significant role in every aspect of human life. The analysis of relevant literature published from 2012 till June 2023 indicated the limited investigation into predicting quantifiable emotional states. The existing emotion recognition techniques use static labels for emotion quantization. This study investigates prominent techniques for dynamic emotion modelling along with associated challenges, shortcomings, and research gaps. Subsequently, a generic framework is proposed that may help researchers explore dynamic emotion modelling techniques and future directions.},
  archive      = {J_AIR},
  author       = {Hamid, Mir Aamir and Singh, Jaiteg},
  doi          = {10.1007/s10462-023-10606-0},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {3363-3416},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Emotion quantification techniques for cognitive reappraisal: A systematic review and scientometric analysis},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GDTRSET: A generalized decision-theoretic rough sets based
on evidence theory. <em>AIR</em>, <em>56</em>(3), 3341–3362. (<a
href="https://doi.org/10.1007/s10462-023-10605-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision-theoretic rough sets (DTRS), produced by Bayesian risk minimum principle and three-way decision theory, is a novel methodology to deal with risk decision problems. As one of the two basic concepts in DTRS, conditional probability is used for measuring the probability of objects belonging to different states. The calculation of condition probability needs a complete information system as prior information. However, we often encounter complicate scenario where prior information is lacking, it is more common that several agents may be involved in a decision process and give their opinion. To model uncertain information of experts’ assessment, a Generalized Decision-Theoretic Rough Sets based on Evidence Theory (GDTRSET) is put forward in this paper. The proposed GDTRSET extends the set of states by introducing a new uncertain state. Correspondingly, instead of using conditional probability in DTRS, basic probability assignment in evidence theory is utilized for describing the belief of objects belonging to different states. The proposed GDTRSET first discusses the determination of conditional probability without prior information, which can handle uncertain information efficiently and flexibly. Besides, a unified framework for classification based on the proposed GDTRSET is presented, taking advantage of three-way and risk decision perspectives for classification. A case study of the Iris dataset is finally illustrated the efficiency of the proposed GDTRSET.},
  archive      = {J_AIR},
  author       = {Chen, Luyuan and Deng, Yong},
  doi          = {10.1007/s10462-023-10605-1},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {3341-3362},
  shortjournal = {Artif. Intell. Rev.},
  title        = {GDTRSET: A generalized decision-theoretic rough sets based on evidence theory},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-population evolutionary algorithm for
multi-objective constrained portfolio optimization problem.
<em>AIR</em>, <em>56</em>(3), 3299–3340. (<a
href="https://doi.org/10.1007/s10462-023-10604-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the rapid development of the financial market, the portfolio selection problem has become of the most complex problem in finance. This paper proposes a new multi-objective evolutionary algorithm based on multi-population, called MP-MOEA, to handle the multi-objective constrained portfolio optimization problem (MOCPOP) in order to achieve an optimal trade-off between return and risk. MP-MOEA uses a multi-population strategy to improve the solution’s quality and considerably accelerate the convergence. Furthermore, two types of archives (local and global) are employed, where the archives local are used to store the non-dominated solutions corresponding to each subpopulation, and the external archive global is used to store the Pareto solutions. The external archive global is controlled using crowding distance to limit the archive size and avoid increasing the complexity of the MP-MOEA algorithm. Several experiments are conducted on two datasets of instances to compare our algorithm with three elevant state-of-art algorithms including AR-MOEA, MOEA/D-AGR, MOEA/D-GR, MOEA/D, MODEwAwL, and MOPSO. The first dataset consists of 5 instances from OR-Library, while other dataset consists 15 instances from NGINX. Statistical analysis of the comparative results obtained using ANOVA and Wilcoxon test demonstrate the merits and the outperformance of our MP-MOEA algorithm.},
  archive      = {J_AIR},
  author       = {Hemici, Meriem and Zouache, Djaafar},
  doi          = {10.1007/s10462-023-10604-2},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {3299-3340},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A multi-population evolutionary algorithm for multi-objective constrained portfolio optimization problem},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Emotion and personality analysis and detection using natural
language processing, advances, challenges and future scope.
<em>AIR</em>, <em>56</em>(3), 3273–3297. (<a
href="https://doi.org/10.1007/s10462-023-10603-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion detection from text is a relatively new sub-field of artificial intelligence closely related to Sentiment Analysis (SA). SA detects positive, neutral, or negative emotions in text. In contrast, emotion analysis detects and distinguishes certain types of emotions expressed in textbooks, such as disgust, fear, anger, happiness, surprise and sadness. Meanwhile, personality is a critical psychological concept that accounts for unique characteristics. Identifying and validating an individual’s personality efficiently and reliably is an admirable goal. This article aims to present a simultaneous review of Emotion and Personality detection from texts and elaborates upon approaches in developing text-based Emotion and Personality detection systems. The studies’ essential contributions, methodologies, datasets, conclusions drawn, strengths, and limitations are also explored. Additionally, this article discusses some of the field’s state-of-the-art ideas. In conclusion, the study delves into specific challenges and possible future research directions for detecting emotions and personalities from the text.},
  archive      = {J_AIR},
  author       = {Safari, Faezeh and Chalechale, Abdolah},
  doi          = {10.1007/s10462-023-10603-3},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {3273-3297},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Emotion and personality analysis and detection using natural language processing, advances, challenges and future scope},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). African vultures optimization algorithm based choquet fuzzy
integral for global optimization and engineering design problems.
<em>AIR</em>, <em>56</em>(3), 3205–3271. (<a
href="https://doi.org/10.1007/s10462-023-10602-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addressing complex optimization problems demands innovative solutions capable of navigating the interdependencies among variables, a reality often oversimplified by traditional metaheuristics. To address this challenge, this paper presents an enhanced African Vultures Optimization Algorithm, termed ci-AVOA, that incorporates the Choquet Integral, a powerful operator adept at considering criteria significance and interconnectedness in optimization scenarios. Unlike its predecessor, the ci-AVOA treats optimization problems in their true complexity by recognizing and accounting for the relationships between variables. The performance of ci-AVOA is evaluated on ten CEC2020 benchmark functions and four engineering design problems, pitted against other renowned optimization algorithms and the original AVOA. Across low and high dimensional benchmark functions, ci-AVOA consistently outperforms its counterparts, underpinning its superiority. This superior performance is further validated using non-parametric statistical tests, solidifying ci-AVOA as an effective and robust tool for tackling complex optimization problems. In essence, this study provides a significant contribution by augmenting a well-known metaheuristic with the Choquet Integral to devise a superior algorithm, ci-AVOA. This innovation extends the problem-solving capabilities of metaheuristics, promising more accurate and robust solutions for complex, real-world optimization problems.},
  archive      = {J_AIR},
  author       = {Nssibi, Maha and Manita, Ghaith and Faux, Francis and Korbaa, Ouajdi and Lamine, Elyes},
  doi          = {10.1007/s10462-023-10602-4},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {3205-3271},
  shortjournal = {Artif. Intell. Rev.},
  title        = {African vultures optimization algorithm based choquet fuzzy integral for global optimization and engineering design problems},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An extended EDAS method with circular intuitionistic fuzzy
value features and its application to multi-criteria decision-making
process. <em>AIR</em>, <em>56</em>(3), 3173–3204. (<a
href="https://doi.org/10.1007/s10462-023-10601-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper aims is to present a multi-criteria decision-making algorithm for solving decision-making problems with the utilization of the C-IFSs (circular intuitionistic fuzzy sets) features. In it, the uncertainties present in the data are handled with the help of C-IFSs in which we considers the circular rating of each object within a certain radius. Later on, we propose a novel algebraic framework for C-IFSs based on Archimedean t-norm operations, including addition, multiplication, subtraction, and division. These operations enable the aggregation of preferences from multiple experts into a single ranking. Also, we propose an extended EDAS (Evaluation Based on Distance from Average Solution) method, which utilizes weighted aggregation operators and defuzzification techniques to rank alternatives. To validate our approach, we provide a numerical example and compare the results with existing methods. Additionally, we discuss the time complexity of the algorithm. The proposed methodology offers decision-makers the flexibility to analyze the influence of different ratings on the final decision and select suitable parameters.},
  archive      = {J_AIR},
  author       = {Garg, Harish and Ünver, Mehmet and Olgun, Murat and Türkarslan, Ezgi},
  doi          = {10.1007/s10462-023-10601-5},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {3173-3204},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An extended EDAS method with circular intuitionistic fuzzy value features and its application to multi-criteria decision-making process},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Model free position-force control of environmental
constrained reconfigurable manipulators based on adaptive dynamic
programming. <em>AIR</em>, <em>56</em>(3), 3143–3171. (<a
href="https://doi.org/10.1007/s10462-023-10600-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a model free position-force control method for uncertain environmental constrained reconfigurable manipulators based on adaptive dynamic programming algorithm. Through the analysis of kinematic uncertainties, an adaptive estimation scheme is designed to obtain the approximate contacted torque. The contacted torque is generated due to the interaction of the manipulator’s end-effector with the uncertain environment. Then, the performance index function is defined by utilizing the joint position, contacted torque tracking errors and uncertain environmental factors. The presented neural network-based observer is utilized to learn the dynamic model. On the basis of policy iteration algorithm, the corresponding Hamiltonian–Jacobi–Bellman equation is addressing by employing the critic NN structure. Thus, the model free position-force control strategy is obtained. Based on Lyapunov stability theorem, the tracking error of the reconfigurable manipulator is proved to be ultimately uniformly bounded. Eventually, simulations and experiments are illustrated the effectiveness of the developed controller.},
  archive      = {J_AIR},
  author       = {Ma, Bing and Yao, Ximing and An, Tianjiao and Dong, Bo and Li, Yuanchun},
  doi          = {10.1007/s10462-023-10600-6},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {3143-3171},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Model free position-force control of environmental constrained reconfigurable manipulators based on adaptive dynamic programming},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-label feature selection via maximum dynamic
correlation change and minimum label redundancy. <em>AIR</em>,
<em>56</em>(3), 3099–3142. (<a
href="https://doi.org/10.1007/s10462-023-10599-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information-theoretic measures have been commonly applied to evaluate the relevance and redundancy in multi-label feature selection. However, the current multi-label feature selection methods based on information-theoretic measures neglect the dynamic changes in the relevance of selected features and candidate features. Furthermore, they also do not fully consider the influence of label redundancy on the relevance of candidate features. In this paper, we first propose a new feature relevance term named Dynamic Correlation Change (DCC), which uses two conditional mutual information terms to evaluate the dynamic changes in the relevance of selected features and candidate features. We then introduce a new label redundancy term named Label Redundancy with Interaction Information (LRII), which more accurately quantifies the influence of label redundancy on the relevance of candidate features. On this basis, we design a new multi-label feature selection method, called Maximum Dynamic Correlation Change and Minimum Label Redundancy (MDCCMLR), by combining DCC and LRII. Finally, we conduct extensive experiments in order to verify the performance of our method by comparing it with some state-of-the-art multi-label feature selection methods based on information-theoretic measures in terms of six evaluation metrics. The experimental results show that the MDCCMLR method outperforms the other comparison methods on all six evaluation metrics.},
  archive      = {J_AIR},
  author       = {Ma, Xi-Ao and Jiang, Wentian and Ling, Yun and Yang, Bailin},
  doi          = {10.1007/s10462-023-10599-w},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {3099-3142},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Multi-label feature selection via maximum dynamic correlation change and minimum label redundancy},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mobility trajectory generation: A survey. <em>AIR</em>,
<em>56</em>(3), 3057–3098. (<a
href="https://doi.org/10.1007/s10462-023-10598-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobility trajectory data is of great significance for mobility pattern study, urban computing, and city science. Self-driving, traffic prediction, environment estimation, and many other applications require large-scale mobility trajectory datasets. However, mobility trajectory data acquisition is challenging due to privacy concerns, commercial considerations, missing values, and expensive deployment costs. Nowadays, mobility trajectory data generation has become an emerging trend in reducing the difficulty of mobility trajectory data acquisition by generating principled data. Despite the popularity of mobility trajectory data generation, literature surveys on this topic are rare. In this paper, we present a survey for mobility trajectory generation by artificial intelligence from knowledge-driven and data-driven views. Specifically, we will give a taxonomy of the literature of mobility trajectory data generation, examine mainstream theories and techniques as well as application scenarios for generating mobility trajectory data, and discuss some critical challenges facing this area.},
  archive      = {J_AIR},
  author       = {Kong, Xiangjie and Chen, Qiao and Hou, Mingliang and Wang, Hui and Xia, Feng},
  doi          = {10.1007/s10462-023-10598-x},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {3057-3098},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Mobility trajectory generation: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Indic script family and its offline handwriting recognition
for characters/digits and words: A comprehensive survey. <em>AIR</em>,
<em>56</em>(3), 3003–3055. (<a
href="https://doi.org/10.1007/s10462-023-10597-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handwriting recognition has become an active area of research in pattern recognition and machine learning in recent years. Handwriting recognition systems have a variety of applications ranging from digital character conversion to signboard translation and scene image analysis. Extensive research work has been carried out for natural language processing of different scripts from all over the world, and the offline handwriting recognition of Indic scripts has also been drawing the major attention of pattern recognition researchers for the last two decades. The research for handwriting recognition has also gained further momentum because of planned funding by the Indian government towards technology development of Indian languages and scripts. These include work for Bangla, Devanagari, Gurmukhi, Tamil and Telugu, Gujarati, Kannada and other Indic scripts. In this study, we present an inclusive survey report of recent advances in Indic script offline handwriting recognition work, mainly focusing on the state-of-the-art work that appeared in the past 15 years, and it includes the following three related research areas in Indic scripts: (1) offline handwritten character recognition, (2) offline handwritten digit recognition and (3) offline handwritten word recognition. There is great work done for character and numeral handwriting recognition in Indic scripts, but the research for word and sentence handwriting recognition in Indic scripts is still an emerging research area. Finally, the present study is an important guide for future researchers, and there exists a great opportunity for further research in Indic script offline handwriting recognition.},
  archive      = {J_AIR},
  author       = {Singh, Sukhdeep and Sharma, Anuj and Chauhan, Vinod Kumar},
  doi          = {10.1007/s10462-023-10597-y},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {3003-3055},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Indic script family and its offline handwriting recognition for characters/digits and words: A comprehensive survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A middleware for providing communicability to embedded MAS
based on the lack of connectivity. <em>AIR</em>, <em>56</em>(3),
2971–3001. (<a
href="https://doi.org/10.1007/s10462-023-10596-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An Embedded multi-agent system (Embedded MAS) is an embedded cognitive system based on agents cooperating to control hardware devices. These agents are autonomous and proactive entities capable of decision-making and can constantly acquire new knowledge via interaction with other agents and the environment. Since the interaction between agents is relevant for acquiring new knowledge, issues such as the communicability and mobility of agents from different Embedded MAS must be highlighted. The classification of a MAS as Open or Closed only considers the mobility of agents, but communicability also needs to be considered. For this, we extend the notion of openness in these systems to consider the existence of Totally Closed and Limited Open MAS, to consider agents from an Embedded MAS without the ability to move or communicate or when they lose the ability to communicate but still can move to other systems. In cooperative missions where several devices adopt Embedded MAS, they should not become totally closed since they lose the ability to cooperate and could put the mission at risk. Some existent works considering Embedded MAS relies upon IoT infrastructures to guarantee communicability and mobility. But, in cases where these infrastructures are temporarily or permanently unavailable, the system becomes totally closed. Even when alternatives exist, they do not use cryptography. Therefore, we present a middleware for supporting the development of Embedded MAS, considering radiofrequency ad-hoc communication to reduce the dependency on centralized infrastructures. An extended protocol supports message exchange between devices using cryptography. We also present a proof of concept application and a formalization of our model.},
  archive      = {J_AIR},
  author       = {Jesus, Vinicius Souza de and Lazarin, Nilson Mori and Pantoja, Carlos Eduardo and Manoel, Fabian César Pereira Brandão and Alves, Gleifer Vaz and Viterbo, José},
  doi          = {10.1007/s10462-023-10596-z},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2971-3001},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A middleware for providing communicability to embedded MAS based on the lack of connectivity},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of the vision transformers and their
CNN-transformer based variants. <em>AIR</em>, <em>56</em>(3), 2917–2970.
(<a href="https://doi.org/10.1007/s10462-023-10595-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision transformers have become popular as a possible substitute to convolutional neural networks (CNNs) for a variety of computer vision applications. These transformers, with their ability to focus on global relationships in images, offer large learning capacity. However, they may suffer from limited generalization as they do not tend to model local correlation in images. Recently, in vision transformers hybridization of both the convolution operation and self-attention mechanism has emerged, to exploit both the local and global image representations. These hybrid vision transformers, also referred to as CNN-Transformer architectures, have demonstrated remarkable results in vision applications. Given the rapidly growing number of hybrid vision transformers, it has become necessary to provide a taxonomy and explanation of these hybrid architectures. This survey presents a taxonomy of the recent vision transformer architectures and more specifically that of the hybrid vision transformers. Additionally, the key features of these architectures such as the attention mechanisms, positional embeddings, multi-scale processing, and convolution are also discussed. In contrast to the previous survey papers that are primarily focused on individual vision transformer architectures or CNNs, this survey uniquely emphasizes the emerging trend of hybrid vision transformers. By showcasing the potential of hybrid vision transformers to deliver exceptional performance across a range of computer vision tasks, this survey sheds light on the future directions of this rapidly evolving architecture.},
  archive      = {J_AIR},
  author       = {Khan, Asifullah and Rauf, Zunaira and Sohail, Anabia and Khan, Abdul Rehman and Asif, Hifsa and Asif, Aqsa and Farooq, Umair},
  doi          = {10.1007/s10462-023-10595-0},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2917-2970},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of the vision transformers and their CNN-transformer based variants},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Uncertainty analysis in document publications using
single-valued neutrosophic set and collaborative entropy. <em>AIR</em>,
<em>56</em>(3), 2785–2809. (<a
href="https://doi.org/10.1007/s10462-022-10249-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent time characterization of domain based expert of given field is considered as one of the crucial tasks due to uncertainty and randomness in document publication. It becomes more crucial when interdisciplinary, collaborative and other uncertain papers are published by an author or institute only to receive the ranking. In this case precise characterization of founding author or institute of given domain generate uncertainty. This problem starts because document publications, collaboration or expert analysis of given field is totally dark data set which contains lots of unstructured, incomplete or uncertain data. Due to which, less attention has been paid towards this direction. However, it impacts more to recruitment process analysis, brain drain analysis, reviewer comment analysis, collaborative publication analysis, loyal or honest author analysis, or even conflict of interest analysis. To control this issue, a method is proposed in this paper to characterize the the document published by any institute or author in true, false or indeterminant zone of given domain using the properties of single–valued neutrosophic set. The expert of the given domain is classified based on defined ( $$\alpha, \beta, \gamma $$ )–cut. Same time another method is proposed to deal the case of higher randomness in publication due to multiple author or collaboration using Shannon entropy. The obtained results from both of the methods are compared with each other as well as recently available approaches for validation.},
  archive      = {J_AIR},
  author       = {Singh, Prem Kumar},
  doi          = {10.1007/s10462-022-10249-7},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2785-2809},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Uncertainty analysis in document publications using single-valued neutrosophic set and collaborative entropy},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). General optimization procedure of the hedge-algebras
controller for controlling dynamic systems. <em>AIR</em>,
<em>56</em>(3), 2749–2784. (<a
href="https://doi.org/10.1007/s10462-022-10242-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to investigate a general optimization procedure of the Hedge-algebras controller (HAC) for controlling dynamic systems. Based on the analysis of factors affecting the control efficiency of HAC, the optimization problem is established following a multi-objective approach. When optimizing HAC, the design variables contain tuning coefficients of control rules, selections of linguistic terms of each rule in the rule base, fuzziness measure parameters of linguistic variables, and variations of the reference range of state and control variables. In which the proposed tuning coefficients have been improved compared with the previous study. In particular, a new inference method is proposed based on the shape/interpolation function of the finite element method. A three-story building structure subjected to earthquake loads is used in the simulation as a case study to demonstrate the effectiveness of the proposed approach. Research results in the present work show that the proposed procedure is general and can be utilized to control different dynamic systems. Moreover, as mentioned above, a large number of the design variables will cause a significant variation in objective functions. It means that the optimum performance is improved compared to optimal cases of individual design variables.},
  archive      = {J_AIR},
  author       = {Nguyen, Tien-Duy and Bui, Hai-Le},
  doi          = {10.1007/s10462-022-10242-0},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2749-2784},
  shortjournal = {Artif. Intell. Rev.},
  title        = {General optimization procedure of the hedge-algebras controller for controlling dynamic systems},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning based single sample face recognition: A
survey. <em>AIR</em>, <em>56</em>(3), 2723–2748. (<a
href="https://doi.org/10.1007/s10462-022-10240-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face recognition has long been an active research area in the field of artificial intelligence, particularly since the rise of deep learning in recent years. In some practical situations, each identity has only a single sample available for training. Face recognition under this situation is referred to as single sample face recognition and poses significant challenges to the effective training of deep models. Therefore, in recent years, researchers have attempted to unleash more potential of deep learning and improve the model recognition performance in the single sample situation. While several comprehensive surveys have been conducted on traditional single sample face recognition approaches, emerging deep learning based methods are rarely involved in these reviews. Accordingly, we focus on the deep learning-based methods in this paper, classifying them into virtual sample methods and generic learning methods. In the former category, virtual images or virtual features are generated to benefit the training of the deep model. In the latter one, additional multi-sample generic sets are used. There are three types of generic learning methods: combining traditional methods and deep features, improving the loss function, and improving network structure, all of which are covered in our analysis. Moreover, we review face datasets that have been commonly used for evaluating single sample face recognition models and go on to compare the results of different types of models. Additionally, we discuss problems with existing single sample face recognition methods, including identity information preservation in virtual sample methods, domain adaption in generic learning methods. Furthermore, we regard developing unsupervised methods is a promising future direction, and point out that the semantic gap as an important issue that needs to be further considered.},
  archive      = {J_AIR},
  author       = {Liu, Fan and Chen, Delong and Wang, Fei and Li, Zewen and Xu, Feng},
  doi          = {10.1007/s10462-022-10240-2},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2723-2748},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep learning based single sample face recognition: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diabetes subtypes classification for personalized health
care: A review. <em>AIR</em>, <em>56</em>(3), 2697–2721. (<a
href="https://doi.org/10.1007/s10462-022-10202-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Healthcare is evolving from standard to personalized, driven by the patients’ needs. Personalized healthcare is a medical model based on genetics, genomics, and other biological information that helps to predict risk for disease. To date, machine learning and data mining are the fastest-growing healthcare field used to classify patient cohorts from a large dataset and its application for diabetes subtyping will be a breakthrough. In this review paper, we have identified, analyzed, and summarized how previous studies distinguished diabetes into subtypes besides implementing the methods for diabetes subtyping using data mining and various clustering algorithms. We have discovered that many studies have suggested diabetes can be differentiated into subtypes clinically based on the risk complications, genetically defined, using clinical features, and for treatment selection. As for clustering algorithms, k-means clustering and hierarchical clustering were shown to be widely used in determining sub-clusters of diabetes. To further investigate diabetes subtyping, understanding the specific objective and method of diabetes subtyping using clustering algorithms from a large dataset will be crucial which could contribute to novel knowledge and improvement for diabetes management.},
  archive      = {J_AIR},
  author       = {Omar, Nashuha and Nazirun, Nisha Nadhira and Vijayam, Bhuwaneswaran and Wahab, Asnida Abdul and Bahuri, Hana Ahmad},
  doi          = {10.1007/s10462-022-10202-8},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2697-2721},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Diabetes subtypes classification for personalized health care: A review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature selection for set-valued data based on d–s evidence
theory. <em>AIR</em>, <em>56</em>(3), 2667–2696. (<a
href="https://doi.org/10.1007/s10462-022-10241-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is one basic and critical technology for data mining, especially in current “big data era”. Rough set theory is sensitive to noise in feature selection due the stringent condition of an equivalence relation. However, D–S evidence theory is flexible to measure uncertainty of information. In this paper, we introduce robust feature evaluation metrics “belief function” and “plausibility function” into feature selection algorithm to avoid the defect that classification effect is affected by noise such as missing values, confusing data, etc. Firstly, similarity between information values in a set-valued information system (SVIS) is introduced and a variable parameter to control the similarity of samples is given. Secondly, $$\theta$$ -lower and $$\theta$$ -upper approximations in an SVIS are put forward. Then, the concepts of $$\theta$$ -belief function, $$\theta$$ -plausibility function, $$\theta$$ -belief reduction and $$\theta$$ -plausibility reduction are given. Moreover, several feature selection algorithms based on the D–S evidence theory in an SVIS are proposed. Experimental results and statistical test show that the proposed metric is insensitive to noise because it comprehensively considers the evidence at all levels, and the proposed algorithms are more robust than several state-of-the-art feature selection algorithms.},
  archive      = {J_AIR},
  author       = {Wang, Yini and Wang, Sichun},
  doi          = {10.1007/s10462-022-10241-1},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2667-2696},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Feature selection for set-valued data based on D–S evidence theory},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantum case-based reasoning (qCBR). <em>AIR</em>,
<em>56</em>(3), 2639–2665. (<a
href="https://doi.org/10.1007/s10462-022-10238-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Case-Based Reasoning (CBR) is an artificial intelligence approach to problem-solving with a good record of success. This article proposes using Quantum Computing to improve some of the key processes of CBR, such that a quantum case-based reasoning (qCBR) paradigm can be defined. The focus is set on designing and implementing a qCBR based on the variational principle that improves its classical counterpart in terms of average accuracy, scalability and tolerance to overlapping. A comparative study of the proposed qCBR with a classic CBR is performed for the case of the social workers’ problem as a sample of a combinatorial optimization problem with overlapping. The algorithm’s quantum feasibility is modelled with docplex and tested on IBMQ computers, and experimented on the Qibo framework.},
  archive      = {J_AIR},
  author       = {Adelomou, Parfait Atchade and Fauli, Daniel Casado and Ribé, Elisabet Golobardes and Vilasís-Cardona, Xavier},
  doi          = {10.1007/s10462-022-10238-w},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2639-2665},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Quantum case-based reasoning (qCBR)},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An external archive guided harris hawks optimization using
strengthened dominance relation for multi-objective optimization
problems. <em>AIR</em>, <em>56</em>(3), 2607–2638. (<a
href="https://doi.org/10.1007/s10462-022-10235-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, Multi-Objective Harris Hawks Optimization (MOHHO) is proposed based on strengthened dominance relation (SRD) to solve multi-objective optimization problems. Specifically, MOHHO uses an additional population archive to store the best non-dominated solutions generated so far by the exploration process at the aim to maintain the elitism concept. Moreover, the leader’s solutions are selected from the external archive to guide the main population of Hawks to interesting search regions. Furthermore, the strengthened dominance relation is adopted to provide a good compromise between coverage and convergence of the obtained Pareto set. The proposed algorithm is validated via five bi-objective and seven three-objective test functions, and it is compared with three well-known multi-objective meta-heuristics. The experimental results show that MOHHO algorithm outperforms its competitors by providing better convergence behaviour with more diversified solutions.},
  archive      = {J_AIR},
  author       = {Zouache, Djaafar and Got, Adel and Drias, Habiba},
  doi          = {10.1007/s10462-022-10235-z},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2607-2638},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An external archive guided harris hawks optimization using strengthened dominance relation for multi-objective optimization problems},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A velocity-guided harris hawks optimizer for function
optimization and fault diagnosis of wind turbine. <em>AIR</em>,
<em>56</em>(3), 2563–2605. (<a
href="https://doi.org/10.1007/s10462-022-10233-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Harris hawks optimizer (HHO) is a relatively novel meta-heuristic approach that mimics the behavior of Harris hawk over the process of predating the rabbits. The simplicity and easy implementation of HHO have attracted extensive attention of many researchers. However, owing to its capability to balance between exploration and exploitation is weak, HHO suffers from low precision and premature convergence. To tackle these disadvantages, an improved HHO called VGHHO is proposed by embedding three modifications. Firstly, a novel modified position search equation in exploitation phase is designed by introducing velocity operator and inertia weight to guide the search process. Then, a nonlinear escaping energy parameter E based on cosine function is presented to achieve a good transition from exploration phase to exploitation phase. Thereafter, a refraction-opposition-based learning mechanism is introduced to generate the promising solutions and helps the swarm to flee from the local optimal solution. The performance of VGHHO is evaluated on 18 classic benchmarks, 30 latest benchmark tests from CEC2017, 21 benchmark feature selection problems, fault diagnosis problem of wind turbine and PV model parameter estimation problem, respectively. The simulation results indicate that VHHO has higher solution quality and faster convergence speed than basic HHO and some well-known algorithms in the literature on most of the benchmark and real-world problems.},
  archive      = {J_AIR},
  author       = {Long, Wen and Jiao, Jianjun and Liang, Ximing and Xu, Ming and Wu, Tiebin and Tang, Mingzhu and Cai, Shaohong},
  doi          = {10.1007/s10462-022-10233-1},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2563-2605},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A velocity-guided harris hawks optimizer for function optimization and fault diagnosis of wind turbine},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Monte carlo tree search: A review of recent modifications
and applications. <em>AIR</em>, <em>56</em>(3), 2497–2562. (<a
href="https://doi.org/10.1007/s10462-022-10228-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monte Carlo Tree Search (MCTS) is a powerful approach to designing game-playing bots or solving sequential decision problems. The method relies on intelligent tree search that balances exploration and exploitation. MCTS performs random sampling in the form of simulations and stores statistics of actions to make more educated choices in each subsequent iteration. The method has become a state-of-the-art technique for combinatorial games. However, in more complex games (e.g. those with a high branching factor or real-time ones) as well as in various practical domains (e.g. transportation, scheduling or security) an efficient MCTS application often requires its problem-dependent modification or integration with other techniques. Such domain-specific modifications and hybrid approaches are the main focus of this survey. The last major MCTS survey was published in 2012. Contributions that appeared since its release are of particular interest for this review.},
  archive      = {J_AIR},
  author       = {Świechowski, Maciej and Godlewski, Konrad and Sawicki, Bartosz and Mańdziuk, Jacek},
  doi          = {10.1007/s10462-022-10228-y},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2497-2562},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Monte carlo tree search: A review of recent modifications and applications},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A state of art review on applications of multi-objective
evolutionary algorithms in chemicals production reactors. <em>AIR</em>,
<em>56</em>(3), 2435–2496. (<a
href="https://doi.org/10.1007/s10462-022-10219-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chemical reactors are employed to produce several materials, which are utilized in numerous applications. The wide use of these chemical engineering units shows their importance as their performance vastly affects the production process. Thus, improving these units will develop the process and/or the manufactured material. Multi-objective optimization (MOO) with evolutionary algorithms (EA’s) has been used to solve several real world complex problems for improving the performance of chemical reactors with conflicting objectives. These objectives are of different nature as they could be economy, environment, safety, energy, exergy and/or process related. In this review, a brief description for MOO and EA’s and their several types and applications is given. Then, MOO studies, which are related to the materials’ production via chemical reactors, those were conducted with EA’s are classified into different classes and discussed. The studies were classified according to the produced material to hydrogen and synthesis gas, petrochemicals and hydrocarbons, biochemical, polymerization and other general processes. Finally, some guidelines are given to help in deciding on future research.},
  archive      = {J_AIR},
  author       = {Al Ani, Zainab and Gujarathi, Ashish M. and Al-Muhtaseb, Ala’a H.},
  doi          = {10.1007/s10462-022-10219-z},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2435-2496},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A state of art review on applications of multi-objective evolutionary algorithms in chemicals production reactors},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised concept drift detection for multi-label data
streams. <em>AIR</em>, <em>56</em>(3), 2401–2434. (<a
href="https://doi.org/10.1007/s10462-022-10232-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world applications adopt multi-label data streams as the need for algorithms to deal with rapidly changing data increases. Changes in data distribution, also known as concept drift, cause existing classification models to rapidly lose their effectiveness. To assist the classifiers, we propose a novel algorithm called Label Dependency Drift Detector (LD3), an unsupervised concept drift detector using label dependencies within the data for multi-label data streams. Our study exploits the dynamic temporal dependencies between labels using a label influence ranking method, which leverages a data fusion algorithm and uses the produced ranking to detect concept drift. LD3 is the first unsupervised concept drift detection algorithm in the multi-label classification problem area. In this study, we perform an extensive evaluation of LD3 by comparing it with 14 prevalent supervised concept drift detection algorithms that we adapt to the problem area using 15 datasets and a baseline classifier. The results show that LD3 provides between 16.9 and 56\% better predictive performance than comparable detectors on both real-world and synthetic data streams.},
  archive      = {J_AIR},
  author       = {Gulcan, Ege Berkay and Can, Fazli},
  doi          = {10.1007/s10462-022-10232-2},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2401-2434},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Unsupervised concept drift detection for multi-label data streams},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluating conversational recommender systems. <em>AIR</em>,
<em>56</em>(3), 2365–2400. (<a
href="https://doi.org/10.1007/s10462-022-10229-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conversational recommender systems aim to interactively support online users in their information search and decision-making processes in an intuitive way. With the latest advances in voice-controlled devices, natural language processing, and AI in general, such systems received increased attention in recent years. Technically, conversational recommenders are usually complex multi-component applications and often consist of multiple machine learning models and a natural language user interface. Evaluating such a complex system in a holistic way can therefore be challenging, as it requires (i) the assessment of the quality of the different learning components, and (ii) the quality perception of the system as a whole by users. Thus, a mixed methods approach is often required, which may combine objective (computational) and subjective (perception-oriented) evaluation techniques. In this paper, we review common evaluation approaches for conversational recommender systems, identify possible limitations, and outline future directions towards more holistic evaluation practices.},
  archive      = {J_AIR},
  author       = {Jannach, Dietmar},
  doi          = {10.1007/s10462-022-10229-x},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2365-2400},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Evaluating conversational recommender systems},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Aspect-based sentiment analysis: An overview in the use of
arabic language. <em>AIR</em>, <em>56</em>(3), 2325–2363. (<a
href="https://doi.org/10.1007/s10462-022-10215-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis has become one of the most active research areas in natural language processing, and the Arabic language retains its importance in this field. It is so because of the increased use of Arabic on the internet that pushes many users to share their views or thoughts about certain products and services. Despite its crucial importance, most of the existing Arabic sentiment analysis studies have been performed on document or sentence levels with little attention to the aspect level. However, the aspect level’s main objective, also known as aspect-based sentiment analysis, is to extract the discussed aspects and identify their related sentiment polarities from a given review or text. The result is to provide more detailed information than general sentiment analysis. Therefore, this paper seeks to provide a comprehensive review of the Arabic aspect-based sentiment analysis studies and highlights the main challenges that face the different proposed approaches. The relevant gaps in the current literature and the future research directions in this area are also discussed. This survey can guide future researchers who want to contribute to the improvement of this domain.},
  archive      = {J_AIR},
  author       = {Bensoltane, Rajae and Zaki, Taher},
  doi          = {10.1007/s10462-022-10215-3},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2325-2363},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Aspect-based sentiment analysis: An overview in the use of arabic language},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Internet of low-altitude UAVs (IoLoUA): A methodical
modeling on integration of internet of “things” with “UAV” possibilities
and tests. <em>AIR</em>, <em>56</em>(3), 2279–2324. (<a
href="https://doi.org/10.1007/s10462-022-10225-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evidence of the IoT is expanding the number of connected devices, including UAVs. UAVs overcome the flaws in the physical IoT infrastructure already in place. Low-altitude views are expected to be dominant swiftly in urban areas. In a short period of time, they are able to cover a large area and distribute goods and information around the globe. Additionally, how to provide a safe and secure UAV operation in high-level traffic circumstances is also a topic of investigation. When operating an UAV in a limited area, the IoLoUA system is used to maintain order. Additionally, it aids with node exploration. Basic principles that can be used to create new structural designs are analysed for both networks (IoLoUA). There has been an explanation of the IoLoUA strategy’s approach to implementation so far. Among the issues covered in this article are UAV-generated IoT data collection and delivery, security threats, and typical workflow approaches. This work presents a theoretical model of future design evolution.},
  archive      = {J_AIR},
  author       = {Srivastava, Ashish and Prakash, Jay},
  doi          = {10.1007/s10462-022-10225-1},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2279-2324},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Internet of low-altitude UAVs (IoLoUA): A methodical modeling on integration of internet of “Things” with “UAV” possibilities and tests},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bimatrix games under dense fuzzy environment and its
application to natural disaster management. <em>AIR</em>,
<em>56</em>(3), 2241–2278. (<a
href="https://doi.org/10.1007/s10462-022-10220-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of dense fuzzy sets instigates decision-makers to reduce the fuzziness of information. Occasionally, players are bound to change their predefined strategies as per the requirements of the circumstances in bimatrix game problems. Such irregular incidents provoke decision-makers to modify the payoffs of a bimatrix game. So, to deal with such irregularities, in this paper, we consider the payoffs of a bimatrix game in the form of dense fuzzy lock sets. Initially, considering players’ confidence level towards the information, we define a new defuzzification function, viz., weighted average defuzzification function (WADF). Later, we execute an auxiliary dense fuzzy non-linear programming problem to find the nash equilibrium strategies along with the value of the game for each player. Utilizing the proposed WADF, we transform the dense fuzzy non-linear programming problem into an equivalent crisp non-linear programming problem. Then we solve the reduced problem for different trials using the software MATHEMATICA 9.0. There are two vital observations of the present problem. One of them is the gradual increment of the value of the game with the increment of players’ confidence level towards the information at a fixed trial. Another fact is the significant changes in the value of the game occurred with the number of trials at a certain confidence level. Finally, to check the efficacy and the cogency of the methodology, we discuss the natural disaster management problem in the dense fuzzy scenario.},
  archive      = {J_AIR},
  author       = {Karmakar, Shuvasree and Seikh, Mijanur Rahaman},
  doi          = {10.1007/s10462-022-10220-6},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2241-2278},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Bimatrix games under dense fuzzy environment and its application to natural disaster management},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on deep reinforcement learning for audio-based
applications. <em>AIR</em>, <em>56</em>(3), 2193–2240. (<a
href="https://doi.org/10.1007/s10462-022-10224-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (DRL) is poised to revolutionise the field of artificial intelligence (AI) by endowing autonomous systems with high levels of understanding of the real world. Currently, deep learning (DL) is enabling DRL to effectively solve various intractable problems in various fields including computer vision, natural language processing, healthcare, robotics, to name a few. Most importantly, DRL algorithms are also being employed in audio signal processing to learn directly from speech, music and other sound signals in order to create audio-based autonomous systems that have many promising applications in the real world. In this article, we conduct a comprehensive survey on the progress of DRL in the audio domain by bringing together research studies across different but related areas in speech and music. We begin with an introduction to the general field of DL and reinforcement learning (RL), then progress to the main DRL methods and their applications in the audio domain. We conclude by presenting important challenges faced by audio-based DRL agents and by highlighting open areas for future research and investigation. The findings of this paper will guide researchers interested in DRL for the audio domain.},
  archive      = {J_AIR},
  author       = {Latif, Siddique and Cuayáhuitl, Heriberto and Pervez, Farrukh and Shamshad, Fahad and Ali, Hafiz Shehbaz and Cambria, Erik},
  doi          = {10.1007/s10462-022-10224-2},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2193-2240},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey on deep reinforcement learning for audio-based applications},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluating new energy vehicles by picture fuzzy sets based
on sentiment analysis from online reviews. <em>AIR</em>, <em>56</em>(3),
2171–2192. (<a
href="https://doi.org/10.1007/s10462-022-10217-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New energy vehicles (NEVs) have beneficial effects on the energy conservation and environmental protection in the transportation sector. The governments have issued many policies to promote their development and adoption. But, how to evaluate the NEVs is still a noteworthy topic. In this paper, we focus on the evaluation of NEVs through online reviews. First, the online reviews are obtained from the websites by data crawling technology. After obtaining the data, a data-driven based method is developed to extract the attributes about the NEVs and sentiment analysis is conducted to discriminate the sentiment orientation of each review to each alternative under each attribute. Then, we define a new information transformation mechanism to realize the transformation from unstructured data to picture fuzzy numbers. Next, a weight determination method based on the proposed picture fuzzy entropy measure is defined to determine the weight of attributes. Finally, considering the bounded rationality of consumers in purchasing, a picture fuzzy set-based regret theory is proposed to quantify their psychological behavior. A case study about the evaluation of NEVs are presented to show the implementation process of this research. Discussions consisting of comparative analysis and parameter analysis are also conducted to explore the superiority and robustness of the proposed evaluation method.},
  archive      = {J_AIR},
  author       = {He, Shifan and Wang, Yingming},
  doi          = {10.1007/s10462-022-10217-1},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2171-2192},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Evaluating new energy vehicles by picture fuzzy sets based on sentiment analysis from online reviews},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An overview of mixing augmentation methods and augmentation
strategies. <em>AIR</em>, <em>56</em>(3), 2111–2169. (<a
href="https://doi.org/10.1007/s10462-022-10227-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Convolutional Neural Networks have made an incredible progress in many Computer Vision tasks. This progress, however, often relies on the availability of large amounts of the training data, required to prevent over-fitting, which in many domains entails significant cost of manual data labeling. An alternative approach is application of data augmentation (DA) techniques that aim at model regularization by creating additional observations from the available ones. This survey focuses on two DA research streams: image mixing and automated selection of augmentation strategies. First, the presented methods are briefly described, and then qualitatively compared with respect to their key characteristics. Various quantitative comparisons are also included based on the results reported in recent DA literature. This review mainly covers the methods published in the materials of top-tier conferences and in leading journals in the years 2017–2021.},
  archive      = {J_AIR},
  author       = {Lewy, Dominik and Mańdziuk, Jacek},
  doi          = {10.1007/s10462-022-10227-z},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2111-2169},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An overview of mixing augmentation methods and augmentation strategies},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning in the stock market—a systematic survey of
practice, backtesting, and applications. <em>AIR</em>, <em>56</em>(3),
2057–2109. (<a
href="https://doi.org/10.1007/s10462-022-10226-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread usage of machine learning in different mainstream contexts has made deep learning the technique of choice in various domains, including finance. This systematic survey explores various scenarios employing deep learning in financial markets, especially the stock market. A key requirement for our methodology is its focus on research papers involving backtesting. That is, we consider whether the experimentation mode is sufficient for market practitioners to consider the work in a real-world use case. Works meeting this requirement are distributed across seven distinct specializations. Most studies focus on trade strategy, price prediction, and portfolio management, with a limited number considering market simulation, stock selection, hedging strategy, and risk management. We also recognize that domain-specific metrics such as “returns” and “volatility” appear most important for accurately representing model performance across specializations. Our study demonstrates that, although there have been some improvements in reproducibility, substantial work remains to be done regarding model explainability. Accordingly, we suggest several future directions, such as improving trust by creating reproducible, explainable, and accountable models and emphasizing prediction of longer-term horizons—potentially via the utilization of supplementary data—which continues to represent a significant unresolved challenge.},
  archive      = {J_AIR},
  author       = {Olorunnimbe, Kenniy and Viktor, Herna},
  doi          = {10.1007/s10462-022-10226-0},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2057-2109},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep learning in the stock market—a systematic survey of practice, backtesting, and applications},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-strategy adaptive cuckoo search algorithm for
numerical optimization. <em>AIR</em>, <em>56</em>(3), 2031–2055. (<a
href="https://doi.org/10.1007/s10462-022-10222-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cuckoo search (CS) algorithm is a popular and efficient search technique for tackling numerical optimization problems. Nevertheless, CS algorithm is prone to premature convergence in solving complex multimode problems. Motivated by this observation, we propose a novel CS algorithm named multi-strategy adaptive CS (MACS). Specifically, in MACS, a parameter control strategy based on the Cauchy distribution and Lehmer mean is employed to dynamically update the step size. After that, three search strategies with different advantages are integrated to complement one another throughout the evolution process, which further strengthens the versatility and robustness. Besides, after every certain number of generations, a probability matching scheme is adopted to adaptively determine the best performing search strategy to produce more promising offspring. Extensive experiments are conducted on 42 benchmark problems from two different test suites. In comparison to seven advanced CS variants as well as other several popular algorithms, the experimental results indicate that MACS exhibits better overall performance.},
  archive      = {J_AIR},
  author       = {Cheng, Jiatang and Xiong, Yan},
  doi          = {10.1007/s10462-022-10222-4},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2031-2055},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Multi-strategy adaptive cuckoo search algorithm for numerical optimization},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical few-shot learning based on coarse- and
fine-grained relation network. <em>AIR</em>, <em>56</em>(3), 2011–2030.
(<a href="https://doi.org/10.1007/s10462-022-10223-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning plays an important role in the field of machine learning. Many existing methods based on relation network achieve satisfactory results. However, these methods assume that classes are independent of each other and ignore their relationship. In this paper, we propose a hierarchical few-shot learning model based on coarse- and fine-grained relation network (HCRN), which constructs a hierarchical structure by mining the relationship among different classes. Firstly, we extract deep and shallow features from different layers at a convolutional neural network. The shallow feature information contains more common features among similar classes, while the deep feature information is more specific. The complementary of these different types of data features can effectively construct coarse- and fine-grained structures by clustering. Secondly, we design coarse- and fine-grained relation networks to classify according to the guidance of the hierarchical structure. The hierarchical class structure learned from data is important auxiliary information for classification. Experimental results show that HCRN can outperform several state-of-the-art models on the Omniglot and miniImageNet datasets. Especially, HCRN obtains 6.47\% improvement over the next best under the 5-way 1-shot setting on the miniImageNet dataset.},
  archive      = {J_AIR},
  author       = {Wu, Zhiping and Zhao, Hong},
  doi          = {10.1007/s10462-022-10223-3},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2011-2030},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Hierarchical few-shot learning based on coarse- and fine-grained relation network},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An architecture-level analysis on deep learning models for
low-impact computations. <em>AIR</em>, <em>56</em>(3), 1971–2010. (<a
href="https://doi.org/10.1007/s10462-022-10221-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have made significant achievements in a wide variety of domains. For the deep learning tasks, multiple excellent hardware platforms provide efficient solutions, including graphics processing units (GPUs), central processing units (CPUs), field programmable gate arrays (FPGAs), and application-specific integrated circuit (ASIC). Nonetheless, CPUs outperform other solutions including GPUs in many cases for the inference workload of DNNs with the support of various techniques, such as the high-performance libraries being the basic building blocks for DNNs. Thus, CPUs have been a preferred choice for DNN inference applications, particularly in the low-latency demand scenarios. However, the DNN inference efficiency remains a critical issue, especially when low latency is required under conditions with limited hardware resources, such as embedded systems. At the same time, the hardware features have not been fully exploited for DNNs and there is much room for improvement. To this end, this paper conducts a series of experiments to make a thorough study for the inference workload of prominent state-of-the-art DNN architectures on a single-instruction-multiple-data (SIMD) CPU platform, as well as with widely applicable scopes for multiple hardware platforms. The study goes into depth in DNNs: the CPU kernel-instruction level performance characteristics of DNNs including branches, branch prediction misses, cache misses, etc, and the underlying convolutional computing mechanism at the SIMD level; The thorough layer-wise time consumption details with potential time-cost bottlenecks; And the exhaustive dynamic activation sparsity with exact details on the redundancy of DNNs. The research provides researchers with comprehensive and insightful details, as well as crucial target areas for optimising and improving the efficiency of DNNs at both the hardware and software levels.},
  archive      = {J_AIR},
  author       = {Li, Hengyi and Wang, Zhichen and Yue, Xuebin and Wang, Wenwen and Tomiyama, Hiroyuki and Meng, Lin},
  doi          = {10.1007/s10462-022-10221-5},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1971-2010},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An architecture-level analysis on deep learning models for low-impact computations},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of convolutional neural network architectures and
their optimizations. <em>AIR</em>, <em>56</em>(3), 1905–1969. (<a
href="https://doi.org/10.1007/s10462-022-10213-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The research advances concerning the typical architectures of convolutional neural networks (CNNs) as well as their optimizations are analyzed and elaborated in detail in this paper. This paper proposes a typical approach to classifying CNNs architecture based on modules in order to accommodate more new network architectures with multiple characteristics that make them difficult to rely on the original classification method. Through the pros and cons analysis of diverse network architectures and their performance comparisons, six types of typical CNNs architectures are analyzed and explained in detail. The CNNs architectures intrinsic characteristics is also explored. Moreover, this paper provides a comprehensive classification of network compression and accelerated network architecture optimization algorithms based on the mathematical principle of various optimization algorithms. Finally, this paper analyses the strategy of NAS algorithms, discusses the applications of CNNs, and sheds light on the challenges and prospects of the current CNNs architecture and its optimizations. The explanation of the advantages brought by optimizing different network architecture types, the basis for constructively choosing appropriate CNNs in specific designs and applications are provided. This paper will help the readers to choose constructively appropriate CNNs in specific designs and applications.},
  archive      = {J_AIR},
  author       = {Cong, Shuang and Zhou, Yang},
  doi          = {10.1007/s10462-022-10213-5},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1905-1969},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review of convolutional neural network architectures and their optimizations},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of artificial fish swarm algorithms: Recent
advances and applications. <em>AIR</em>, <em>56</em>(3), 1867–1903. (<a
href="https://doi.org/10.1007/s10462-022-10214-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Artificial Fish Swarm Algorithm (AFSA) is inspired by the ecological behaviors of fish schooling in nature, viz., the preying, swarming and following behaviors. Owing to a number of salient properties, which include flexibility, fast convergence, and insensitivity to the initial parameter settings, the family of AFSA has emerged as an effective Swarm Intelligence (SI) methodology that has been widely applied to solve real-world optimization problems. Since its introduction in 2002, many improved and hybrid AFSA models have been developed to tackle continuous, binary, and combinatorial optimization problems. This paper aims to present a concise review of the continuous AFSA, encompassing the original ASFA, its improvements and hybrid models, as well as their associated applications. We focus on articles published in high-quality journals since 2013. Our review provides insights into AFSA parameters modifications, procedure and sub-functions. The main reasons for these enhancements and the comparison results with other hybrid methods are discussed. In addition, hybrid, multi-objective and dynamic AFSA models that have been proposed to solve continuous optimization problems are elucidated. We also analyse possible AFSA enhancements and highlight future research directions for advancing AFSA-based models.},
  archive      = {J_AIR},
  author       = {Pourpanah, Farhad and Wang, Ran and Lim, Chee Peng and Wang, Xi-Zhao and Yazdani, Danial},
  doi          = {10.1007/s10462-022-10214-4},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1867-1903},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review of artificial fish swarm algorithms: Recent advances and applications},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Overview of behavior recognition based on deep learning.
<em>AIR</em>, <em>56</em>(3), 1833–1865. (<a
href="https://doi.org/10.1007/s10462-022-10210-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human behavior recognition has always been a hot spot for research in computer vision. With the wide application of behavior recognition in virtual reality and short video in recent years and the rapid development of deep learning algorithms, behavior recognition algorithms based on deep learning have emerged. Compared with traditional methods, behavior recognition algorithms based on deep learning have the advantages of strong robustness and high accuracy. This paper systemizes and introduces behavior recognition algorithms based on deep learning proposed in recent years, then focuses on a series of behavior recognition algorithms based on image and bone data; deeply analyzes their theories and performance, and finally, puts forward further prospects.},
  archive      = {J_AIR},
  author       = {Hu, Kai and Jin, Junlan and Zheng, Fei and Weng, Liguo and Ding, Yiwu},
  doi          = {10.1007/s10462-022-10210-8},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1833-1865},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Overview of behavior recognition based on deep learning},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence-assisted water quality index
determination for healthcare. <em>AIR</em>, <em>56</em>(2), 2893–2915.
(<a href="https://doi.org/10.1007/s10462-023-10594-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Groundwater resource analysis is an important technological means of avoiding disease and controlling water pollution. In this field of study, water quality assessments are conducted using sequential parametric values collected in real time. For evaluation reasons, several state-of-the-art water quality evolution mechanism typically employs a single time-invariant model to determine the quality of Water. As a result, it is challenging to illustrate the importance of randomness and contingency in the process of water quality assessment, leading to variations and errors in the procedure of quality assessment. In consideration of these limitations, this study proposes a Digital Twin inspired Hybrid System (DTHS) for water quality assessment in real time. In addition, the degree of water quality is offered as an indication for quantitatively assessing the health risk status. Observational data from a monitoring station in Chaheru, a locality in the Phagwara district of the Indian state of Punjab, are used to demonstrate the efficacy of the proposed approach. The experimental results demonstrate the effectiveness of the proposed framework in terms of water quality determination, computational cost, and stability. The framework has achieved higher prediction accuracy (94.14\%), sensitivity (93.74\%), specificity (91.47\%), and f-measure (92.37\%), indicating its ability to accurately determine water quality. Additionally, the framework offers reduced computational delay and improved reliability and stability, making it a trustworthy solution for timely predictions with respect to water quality.},
  archive      = {J_AIR},
  author       = {Manocha, Ankush and Sood, Sandeep Kumar and Bhatia, Munish},
  doi          = {10.1007/s10462-023-10594-1},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2893-2915},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Artificial intelligence-assisted water quality index determination for healthcare},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A comprehensive review of artificial intelligence-based
methods for predicting pan evaporation rate. <em>AIR</em>,
<em>56</em>(2), 2861–2892. (<a
href="https://doi.org/10.1007/s10462-023-10592-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This comprehensive study reviews the latest and most popular artificial intelligence (AI) techniques utilised for estimating pan evaporation (Ep), an essential parameter for water resource management and irrigation planning. Through an extensive evaluation of 76 papers published between 2006 and 2022, this study analyses the input data categories, time steps, properties, and capabilities of different AI models used for estimating Ep across various regions. The reviewed papers offer partial and comprehensive observations, providing valuable insights for researchers looking to model Ep in similar studies. Furthermore, this study proposes innovative theories and approaches to enhance the efficacy of Ep modelling in the relevant analysis domain. While hybrid AI techniques have gained popularity due to their perceived superiority over standalone deep learning and machine learning approaches, they often pose significant operational and computational challenges for Ep forecasting. As such, the study strongly recommends the use of transformer neural networks for Ep estimation, given their unique architecture and promising performance across various fields. Overall, this study presents a comprehensive and up-to-date overview of the latest AI-based techniques for estimating Ep and highlights the most promising approaches for future research.},
  archive      = {J_AIR},
  author       = {Abed, Mustafa and Imteaz, Monzur Alam and Ahmed, Ali Najah},
  doi          = {10.1007/s10462-023-10592-3},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2861-2892},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comprehensive review of artificial intelligence-based methods for predicting pan evaporation rate},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A practical utility-based but objective approach to model
selection for regression in scientific applications. <em>AIR</em>,
<em>56</em>(2), 2825–2859. (<a
href="https://doi.org/10.1007/s10462-023-10591-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many fields of science, various types of models are available to describe phenomena, observations and the results of experiments. In the last decades, given the enormous advances of information gathering technologies, also machine learning techniques have been systematically deployed to extract models from the large available databases. However, regardless of their origins, no universal criterion has been found so far to select the most appropriate model given the data. A unique solution is probably a chimera, particularly in applications involving complex systems. Consequently, in this work a utility-based approach is advocated. However, the solutions proposed are not purely subjective but all based on “objective” criteria, rooted in the properties of the data, to preserve generality and to allow comparative assessments of the results. Several methods have been developed and tested, to improve the discrimination capability of basic Bayesian and information theoretic criteria, with particular attention to the BIC (Bayesian Information Criterion) and AIC (Akaike Information Criterion) indicators. Both the quality of the fits and the evaluation of model complexity are aspects addressed by the advances proposed. The competitive advantages of the individual alternatives, for both cross sectional data and time series, are clearly identified, together with their most appropriate fields of application. The proposed improvements of the criteria allow selecting the right models more reliably, more efficiently in terms of data requirements and can be adjusted to very different circumstances and applications. Particular attention has been paid to ensure that the developed versions of the indicators are easy to implement in practice, in both confirmatory and exploratory settings. Extensive numerical tests have been performed to support the conceptual and theoretical considerations.},
  archive      = {J_AIR},
  author       = {Murari, Andrea and Rossi, Riccardo and Spolladore, Luca and Lungaroni, Michele and Gaudio, Pasquale and Gelfusa, Michela},
  doi          = {10.1007/s10462-023-10591-4},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2825-2859},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A practical utility-based but objective approach to model selection for regression in scientific applications},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application of deep learning in laser-induced breakdown
spectroscopy: A review. <em>AIR</em>, <em>56</em>(2), 2789–2823. (<a
href="https://doi.org/10.1007/s10462-023-10590-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to its remarkable element detection capability, laser-induced breakdown spectroscopy (LIBS) has been extensively utilized for element-related analysis. Although the spectral peaks corresponding to different elements can be manually identified by the LIBS spectra library, fully extracting information from LIBS spectra remains challenging due to measurement uncertainty interference. To improve the performance of LIBS analysis, various machine learning (ML) methods have been proposed to compensate for the measurement uncertainty. Among these, deep learning (DL), the most cutting-edge topic in artificial intelligence, has been applied in spectroscopy analysis in recent years. This work presents the first review of DL approaches in LIBS spectra analysis, where the principles and applications are introduced and summarized. A comprehensive discussion on current applications, challenges, and future perspectives is conducted to provide guidelines for future research and applications. The reviewed papers demonstrate that DL exhibits great potential and a promising future in LIBS analysis.},
  archive      = {J_AIR},
  author       = {Zhang, Chu and Zhou, Lei and Liu, Fei and Huang, Jing and Peng, Jiyu},
  doi          = {10.1007/s10462-023-10590-5},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2789-2823},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Application of deep learning in laser-induced breakdown spectroscopy: A review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). H1DBi-r net: Hybrid 1D bidirectional RNN for efficient
diabetic retinopathy detection and classification. <em>AIR</em>,
<em>56</em>(2), 2759–2787. (<a
href="https://doi.org/10.1007/s10462-023-10589-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays the eye disease that widely affects the visual impairment of humans is Diabetes Retinopathy (DR). The advanced stage of the disorder leads to cause complete vision loss and creates complex situations for treatment. So it is significant to treat prolonged diabetes at an initial stage. Therefore, the main reason for DR is the uncontrolled growth of blood glucose levels in the eye. If it reaches the severity level the bleeding is caused in the eye. However, the lesions generated due to DR are medicated based on fundus images. The significant purpose of affecting DR is the presence of high sugar in the blood and this damages the retina. Therefore proper screening of DR is essential to prevent it from affecting the blood vessels all over the body. Also, it unblocks blood vessels paves the way to function the new blood vessels grown in the eye. Therefore a novel hybrid oppositional fire-fly modified 1D bidirectional recurrent (HOF-M1DBR) method is proposed to detect the DR through fundus images accurately. The datasets Messidor-1 and APTOS-2019 are applied for performing the initial process of fundus images such as denoising, smoothing, cropping, and resizing. The M1DBR is used to validate the accuracy and optimize the weight function using the Opposition-Based Learning-FireFly (OBL-FF) algorithm. Thus prediction and classification of f DR from the fundus images are detected accurately and distinguished the four levels from the extracted features. The validation of the proposed method is performed based on accuracy, precision, recall, and F1-score. The experimental results revealed that the proposed HOF-M1DBR attained an accuracy of 98.9\% for the Messidor-1 and APTOS-2019 dataset, thus improving the performance. However, the existing DCNN-PCA-FF, DNN-MSO, SI-GWO, and DCNN-EMF methods diminished the performance by 79.9\%, 87\%, 83\%, and 89.1\% respectively.},
  archive      = {J_AIR},
  author       = {Krishnamoorthy, Sujatha and Weifeng, Yu and Luo, Jingling and Kardy, Seifedine},
  doi          = {10.1007/s10462-023-10589-y},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2759-2787},
  shortjournal = {Artif. Intell. Rev.},
  title        = {H1DBi-R net: Hybrid 1D bidirectional RNN for efficient diabetic retinopathy detection and classification},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic review of deep learning-based cervical cytology
screening: From cell identification to whole slide image analysis.
<em>AIR</em>, <em>56</em>(2), 2687–2758. (<a
href="https://doi.org/10.1007/s10462-023-10588-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cervical cancer is one of the most common cancers in daily life. Early detection and diagnosis can effectively help facilitate subsequent clinical treatment and management. With the growing advancement of artificial intelligence (AI) and deep learning (DL) techniques, an increasing number of computer-aided diagnosis (CAD) methods based on deep learning have been applied in cervical cytology screening. In this paper, we survey more than 80 publications since 2016 to provide a systematic and comprehensive review of DL-based cervical cytology screening. First, we provide a concise summary of the medical and biological knowledge pertaining to cervical cytology, since we hold a firm belief that a comprehensive biomedical understanding can significantly contribute to the development of CAD systems. Then, we collect a wide range of public cervical cytology datasets. Besides, image analysis approaches and applications including cervical cell identification, abnormal cell or area detection, cell region segmentation and cervical whole slide image diagnosis are summarized. Finally, we discuss the present obstacles and promising directions for future research in automated cervical cytology screening.},
  archive      = {J_AIR},
  author       = {Jiang, Peng and Li, Xuekong and Shen, Hui and Chen, Yuqi and Wang, Lang and Chen, Hua and Feng, Jing and Liu, Juan},
  doi          = {10.1007/s10462-023-10588-z},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2687-2758},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A systematic review of deep learning-based cervical cytology screening: From cell identification to whole slide image analysis},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reliability intelligence analysis of concrete arch bridge
based on kriging model and PSOSA hybrid algorithm. <em>AIR</em>,
<em>56</em>(2), 2667–2685. (<a
href="https://doi.org/10.1007/s10462-023-10587-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional probabilistic reliability analysis method has problems such as poor convergence, low calculation accuracy, and long time consumption in calculating the reliability of concrete arch bridges due to factors such as the uncertainty of the structural parameters and the performance function being highly nonlinear. This paper proposes a method for calculating the reliability of concrete arch bridges based on the Kriging model and particle swarm optimization algorithm (PSOSA) of the simulated annealing algorithm. This method takes advantage of the Kriging model in small samples and high-dimensional nonlinear data processing capabilities and establishes a response surface model to approximate the actual limit state function. The optimization of the PSO algorithm is realized through the self-adaptive and variable probability mutation operation of the SA algorithm, which enhances the ability of the PSO algorithm to get rid of the local minimum, effectively avoids falling into the local minimum, and finally makes the calculation result tend to the global optimum. It overcomes the problems of slow convergence speed and premature maturity of traditional PSO algorithms. The correctness and effectiveness of the method proposed in this paper are verified through the example analysis and the actual engineering application of a concrete arch bridge. The research results show that the method proposed in this paper has obvious advantages in sample size, calculation accuracy, and iteration times compared with the existing reliability calculation methods for concrete arch bridges. This paper provides a fast and effective method for the structural reliability calculation of concrete arch bridges.},
  archive      = {J_AIR},
  author       = {Li, Dengguo and Ye, Zhouling and Lu, Pengzhen and Wu, Ying and Yang, Liu and Wang, Jiahao},
  doi          = {10.1007/s10462-023-10587-0},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2667-2685},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Reliability intelligence analysis of concrete arch bridge based on kriging model and PSOSA hybrid algorithm},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial glial cells in artificial neuronal networks: A
systematic review. <em>AIR</em>, <em>56</em>(2), 2651–2666. (<a
href="https://doi.org/10.1007/s10462-023-10586-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of tripartite synapses has revolutionized the world of neuroscience and the way we understand how information is transmitted in the brain. Since its discovery, some research groups have incorporated into connectionist systems classically focused on the development of Artificial Neuron Networks (ANNs) as a single element, artificial astrocytes that try to optimize performance in problem solving.In this systematic review, we searched the ISI Web of Science for papers that focused on the development of such novel models and their comparison with classical ANNs. A total of 22 papers that satisfied the inclusion criteria were analyzed, showing three different ways of applying the neuromodulatory influence of artificial astrocytes on neural networks. Using Multilayer Perceptron Networks, Artificial Neuro-Glial Newtworks and Multilayer Perceptron with Self-Organizing Maps approaches, a detailed analysis of the incorporation of artificial astrocytic networks has been carried out, and the main differences between the different methods have been weighed up. Regardless of the type of inclusion performed, the greater the complexity of the problem to be solved, it has been observed that the influence of artificial astrocytes has improved the performance of classical ANNs, as occurs in the biological brain.},
  archive      = {J_AIR},
  author       = {Alvarez-Gonzalez, Sara and Cedron, Francisco and Pazos, Alejandro and Porto-Pazos, Ana B.},
  doi          = {10.1007/s10462-023-10586-1},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2651-2666},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Artificial glial cells in artificial neuronal networks: A systematic review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Soft computing techniques for biomedical data analysis: Open
issues and challenges. <em>AIR</em>, <em>56</em>(2), 2599–2649. (<a
href="https://doi.org/10.1007/s10462-023-10585-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, medical data analysis has become paramount in delivering accurate diagnoses for various diseases. The plethora of medical data sources, encompassing disease types, disease-related proteins, ligands for proteins, and molecular drug components, necessitates adopting effective disease analysis and diagnosis methods. Soft computing techniques, including swarm algorithms and machine learning (ML) methods, have emerged as superior approaches. While ML techniques such as classification and clustering have gained prominence, feature selection methods are crucial in extracting optimal features and reducing data dimensions. This review paper presents a comprehensive overview of soft computing techniques for tackling medical data problems through classifying and analyzing medical data. The focus lies mainly on the classification of medical data resources. A detailed examination of various techniques developed for classifying numerous diseases is provided. The review encompasses an in-depth exploration of multiple ML methods designed explicitly for disease detection and classification. Additionally, the review paper offers insights into the underlying biological disease mechanisms and highlights several medical and chemical databases that facilitate research in this field. Furthermore, the review paper outlines emerging trends and identifies the key challenges in biomedical data analysis. It sheds light on this research domain’s exciting possibilities and future directions. The enhanced understanding of soft computing techniques and their practical applications and limitations will contribute to advancing biomedical data analysis and support healthcare professionals in making accurate diagnoses.},
  archive      = {J_AIR},
  author       = {Houssein, Essam H. and Hosney, Mosa E. and Emam, Marwa M. and Younis, Eman M. G. and Ali, Abdelmgeid A. and Mohamed, Waleed M.},
  doi          = {10.1007/s10462-023-10585-2},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2599-2649},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Soft computing techniques for biomedical data analysis: Open issues and challenges},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An incremental approach to hierarchical feature selection by
applying fuzzy rough set technique. <em>AIR</em>, <em>56</em>(2),
2571–2598. (<a
href="https://doi.org/10.1007/s10462-023-10584-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the age of big data, the number of class labels is increasing rapidly and there exists a hierarchical structure between different class labels. In the present paper, we revisit the existing granular computing approach to hierarchical classification. By revealing some limitations of approximation capacity, we develop a novel model for hierarchical classification. Then, we present a formal approach to feature selection for hierarchical decision tables by using fuzzy rough set theory. Correspondingly, an algorithm using relative discernibility relation is designed to select relevant feature subsets. Considering the fact that real data may vary dynamically with time, we also propose an incremental approach to hierarchical feature selection by using fuzzy rough set technique. An incremental algorithm for hierarchical feature selection is provided based on the sibling strategy. The experimental results demonstrate that the proposed approach is feasible and valid.},
  archive      = {J_AIR},
  author       = {She, Yanhong and Wu, Jinlan and He, Xiaoli},
  doi          = {10.1007/s10462-023-10584-3},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2571-2598},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An incremental approach to hierarchical feature selection by applying fuzzy rough set technique},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of deep learning techniques for machine reading
comprehension. <em>AIR</em>, <em>56</em>(2), 2509–2569. (<a
href="https://doi.org/10.1007/s10462-023-10583-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reading comprehension involves the process of reading and understanding textual information in order to answer questions related to it. It finds practical applications in various domains such as domain-specific FAQs, search engines, and dialog systems. Resource-rich languages like English, Japanese, Chinese, and most European languages benefit from the availability of numerous datasets and resources, enabling the development of machine reading comprehension (MRC) systems. However, building MRC systems for low-resource languages (LRL) with limited datasets, such as Vietnamese, Urdu, Bengali, and Hindi, poses significant challenges. To address this issue, this study utilizes quantitative analysis to conduct a systematic literature review (SLR) with the aim of comprehending the recent global shift in MRC research from high-resource languages (HRL) to low-resource languages. Notably, existing literature reviews on MRC lack comprehensive studies that compare techniques specifically designed for rich and low-resource languages. Hence, this study provides a comprehensive overview of the MRC research landscape in low-resource languages, offering valuable insights and a list of suggestions to enhance LRL–MRC research.},
  archive      = {J_AIR},
  author       = {Kazi, Samreen and Khoja, Shakeel and Daud, Ali},
  doi          = {10.1007/s10462-023-10583-4},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2509-2569},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of deep learning techniques for machine reading comprehension},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). From task to evaluation: An automatic text summarization
review. <em>AIR</em>, <em>56</em>(2), 2477–2507. (<a
href="https://doi.org/10.1007/s10462-023-10582-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic summarization is attracting increasing attention as one of the most promising research areas. This technology has been tried in various real-world applications in recent years and achieved a good response. However, the applicability of conventional evaluation metrics cannot keep up with rapidly evolving summarization task formats and ensuing indicator. After recent years of research, automatic summarization task requires not only readability and fluency, but also informativeness and consistency. Diversified application scenarios also bring new challenges both for generative language models and evaluation metrics. In this review, we analysis and specifically focus on the difference between the task format and the evaluation metrics.},
  archive      = {J_AIR},
  author       = {Lu, Lingfeng and Liu, Yang and Xu, Weiqiang and Li, Huakang and Sun, Guozi},
  doi          = {10.1007/s10462-023-10582-5},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2477-2507},
  shortjournal = {Artif. Intell. Rev.},
  title        = {From task to evaluation: An automatic text summarization review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhanced golden jackal optimizer-based shape optimization of
complex CSGC-ball surfaces. <em>AIR</em>, <em>56</em>(2), 2407–2475. (<a
href="https://doi.org/10.1007/s10462-023-10581-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The geometric design and shape optimization of complex surfaces are pivotal and knotty techniques in computer aided geometric design (CAGD), and widely used in many complex product manufacturing fields involving surfaces modeling, e.g., for ships, aircraft wing, automobiles, etc. In this paper, an enhanced golden jackal optimization (GJO) algorithm is used to optimize the shape of complex composite shape-adjustable generalized cubic Ball (CSGC-Ball, for short) surfaces. Firstly, the shape design of CSGC-Ball surfaces is mathematically an optimization problem that can be efficiently dealt with by meta-heuristic algorithms. In this regard, an enhanced GJO (EGJO), combined with opposition-based learning, spring vibration-based adaptive mutation and binomial-based cross-evolution strategy, is developed to improve the convergence speed and calculation accuracy of the original GJO. The performance of EGJO is assessed on 23 benchmark test functions, IEEE CEC-2019 and 4 actual engineering optimization problems, and the competition and practicability of EGJO algorithm are confirmed. Secondly, the CSGC-Ball surfaces with global and local shape parameters is constructed based on a class of cubic generalized Ball basis functions, and then the conditions of G1 and G2 continuity for the surfaces are derived. The shapes of CSGC-Ball surfaces can be adjusted and optimized expediently by utilizing their shape parameters. Finally, the minimum energy-based shape optimization models of CSGC-Ball surfaces with 1th-order and 2th-order geometric continuity are established, respectively. Furthermore, the proposed EGJO is utilized to solve the established optimization models, and the CSGC-Ball surfaces with minimum energy are obtained. Four representative examples are given to demonstrate the excellence and effectiveness of EGJO in solving the shape optimization problems of complex CSGC-Ball surfaces.},
  archive      = {J_AIR},
  author       = {Hu, Gang and Chen, Liuxin and Wei, Guo},
  doi          = {10.1007/s10462-023-10581-6},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2407-2475},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Enhanced golden jackal optimizer-based shape optimization of complex CSGC-ball surfaces},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SCL-SKG: Software knowledge extraction with span-level
contrastive learning. <em>AIR</em>, <em>56</em>(2), 2383–2406. (<a
href="https://doi.org/10.1007/s10462-023-10580-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The text of software knowledge community contains abundant knowledge of software engineering field. The software knowledge entity and relation can be extracted automatically and efficiently to form the software knowledge graph, which is helpful for software knowledge-centric intelligent applications, such as intelligent question answering, automatic document generation and software expert recommendation. Most existing methods are confronted with problems of task dependence and entity overlap. In this paper, we propose a software knowledge extraction method based on span-level contrastive learning. From the level of sentence sequence modelling, we model the sentence sequence with span as a unit, and generate abundant positive and negative samples of entity span through the span representation layer to avoid the problem that the token-level method cannot select overlapping entities. From the level of feature learning, we propose supervised entity contrastive learning and relation contrastive learning, which obtain enhanced feature representation of entity span and entity pair through positive and negative sample enhancement and contrastive loss function construction. Experiments are conducted on the dataset which is constructed based on texts of the StackOverflow, and show that our approach achieves a better performance than baseline models.},
  archive      = {J_AIR},
  author       = {Tang, Mingjing and Zhang, Shu and Zheng, Ming and Ma, Zifei and Gao, Wei},
  doi          = {10.1007/s10462-023-10580-7},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2383-2406},
  shortjournal = {Artif. Intell. Rev.},
  title        = {SCL-SKG: Software knowledge extraction with span-level contrastive learning},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic review for class-imbalance in semi-supervised
learning. <em>AIR</em>, <em>56</em>(2), 2349–2382. (<a
href="https://doi.org/10.1007/s10462-023-10579-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This review aims to examine the state of the art of semi-supervised learning (SSL) techniques for addressing class imbalanced data. Class imbalance is inherent in many real-world applications and has been extensively investigated in supervised classification. In a semi-supervised scenario, this problem is even more interesting because of two possible situations: performance is affected and the error is propagated to the unlabeled data, worsening the final performance, or unlabeled data can help to represent the minority class and improve the results. However, as far as we know, no survey exists organizing the semi-supervised approaches to deal with class imbalance. Our goal is to fill this gap and present a systematic review, where we retrieved 444 articles from five years (2017–2021) from ACM Digital Library, IEEE Explore, Elsevier, Springer, and Google Scholar. After applying exclusion criteria, 47 articles were selected and presented in more detail. We collect important information to answer four research questions, such as the existence of pre/post-processing techniques, the applications, data sets explored, the metrics used to evaluate the approaches, and the developed techniques to deal with class imbalance. We propose eight categories (balancing, graph-based, loss, self-training, ensemble, active learning, post-processing, and other types of learning) to organize the different methodological approaches from the papers. Finally, we present some discussion and future trends in the area. Our review aims to provide an understanding of the most prominent and currently relevant work employing SSL for class imbalance.},
  archive      = {J_AIR},
  author       = {de Oliveira, Willian Dihanster Gomes and Berton, Lilian},
  doi          = {10.1007/s10462-023-10579-0},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2349-2382},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A systematic review for class-imbalance in semi-supervised learning},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Regret-based domination and prospect-based scoring in
three-way decision making using q-rung orthopair fuzzy mahalanobis
distance. <em>AIR</em>, <em>56</em>(2), 2311–2348. (<a
href="https://doi.org/10.1007/s10462-023-10578-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to an increase in decision making sophistication and risk, behavioural three-way decision making has replaced traditional two-way decision making. Accordingly, this study proposes a novus three-way multi-attribute decision making model by creating three-way decision rules in context of multi-attribute decision-making with two key behavioural theories, namely, regret and prospect theories. To capture uncertainty in the evaluation information, q-rung orthopair fuzzy set is implemented in the information system. After that, a new method is forwarded based on correlation coefficient and variance to calculate the weights of attributes. In light of the conventional Mahalanobis distance, q-rung orthopair fuzzy Mahalanobis distance is developed. Then, regret-based dominated relation and rejoice-based dominating relation are defined. Thereafter, a new procedure is developed to estimate the conditional probability according to two above-mentioned relations. Three kinds of scoring functions are developed with the help of prospect theory, based on which, despondent, expectant, and balanced tactics are developed to illustrate three mindsets of decision maker. Ultimately, three sizeable datasets gathered from the KEEL and UCI databases are used to demonstrate the legitimacy, resiliency, and supremacy of the constructed model.},
  archive      = {J_AIR},
  author       = {Mondal, Arijit and Roy, Sankar Kumar and Deveci, Muhammet},
  doi          = {10.1007/s10462-023-10578-1},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2311-2348},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Regret-based domination and prospect-based scoring in three-way decision making using q-rung orthopair fuzzy mahalanobis distance},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attention-based graph neural networks: A survey.
<em>AIR</em>, <em>56</em>(2), 2263–2310. (<a
href="https://doi.org/10.1007/s10462-023-10577-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) aim to learn well-trained representations in a lower-dimension space for downstream tasks while preserving the topological structures. In recent years, attention mechanism, which is brilliant in the fields of natural language processing and computer vision, is introduced to GNNs to adaptively select the discriminative features and automatically filter the noisy information. To the best of our knowledge, due to the fast-paced advances in this domain, a systematic overview of attention-based GNNs is still missing. To fill this gap, this paper aims to provide a comprehensive survey on recent advances in attention-based GNNs. Firstly, we propose a novel two-level taxonomy for attention-based GNNs from the perspective of development history and architectural perspectives. Specifically, the upper level reveals the three developmental stages of attention-based GNNs, including graph recurrent attention networks, graph attention networks, and graph transformers. The lower level focuses on various typical architectures of each stage. Secondly, we review these attention-based methods following the proposed taxonomy in detail and summarize the advantages and disadvantages of various models. A model characteristics table is also provided for a more comprehensive comparison. Thirdly, we share our thoughts on some open issues and future directions of attention-based GNNs. We hope this survey will provide researchers with an up-to-date reference regarding applications of attention-based GNNs. In addition, to cope with the rapid development in this field, we intend to share the relevant latest papers as an open resource at https://github.com/sunxiaobei/awesome-attention-based-gnns .},
  archive      = {J_AIR},
  author       = {Sun, Chengcheng and Li, Chenhao and Lin, Xiang and Zheng, Tianji and Meng, Fanrong and Rui, Xiaobin and Wang, Zhixiao},
  doi          = {10.1007/s10462-023-10577-2},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2263-2310},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Attention-based graph neural networks: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A picture fuzzy evaluation framework based on a novel
approach incorporating bidirectional projection measures and the VIKOR
method. <em>AIR</em>, <em>56</em>(2), 2235–2261. (<a
href="https://doi.org/10.1007/s10462-023-10576-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complexity of multi-criteria decision-making (MCDM) makes it challenging for decision-makers (DMs) to reach an optimal decision. Therefore, this study sought to develop a novel picture fuzzy MCDM framework with partially known criterion weight information to enable DMs to select the most appropriate alternatives. As such, this study made several key contributions. Firstly, this study defined a novel picture fuzzy bidirectional projection measure that simultaneously accounted for distance and direction, thus overcoming the inherent drawbacks of existing picture fuzzy projection measures. Secondly, both objectivity and subjectivity were taken into account in the decision-making process, thus avoiding the limitations of considering only a single subjective weight or an objective weight. Additionally, based on the proposed bidirectional projection measure, Jaynes’s maximum entropy principle, and minimal deviations, a nonlinear programming model was constructed to determine the comprehensive weight vector of the criteria. Thirdly, the existing VlseKriterijumska Optimizacija I Kompromisno Resenje (VIKOR) method always utilizes distance to measure the closeness degrees to the ideal solutions while ignoring the influence of the direction factor. Therefore, an improved picture fuzzy VIKOR method incorporating bidirectional projection was proposed to conduct selection process. Finally, a picture fuzzy evaluation framework was constructed by coupling bidirectional projection measures and the VIKOR method. The applicability of the proposed MCDM framework was then evaluated by solving a supplier selection problem, after which sensitivity and comparison analyses were performed to illustrate. its robustness and reliability.},
  archive      = {J_AIR},
  author       = {Peng, Juan Juan and Chen, Xin Ge and Long, Qing Qi and Zhang, Shu Zhu},
  doi          = {10.1007/s10462-023-10576-3},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2235-2261},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A picture fuzzy evaluation framework based on a novel approach incorporating bidirectional projection measures and the VIKOR method},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimization driven spike deep belief neural network
classifier: A deep-learning based multichannel spike sorting neural
signal processor (NSP) module for high-channel-count brain machine
interfaces (BMIs). <em>AIR</em>, <em>56</em>(2), 2207–2233. (<a
href="https://doi.org/10.1007/s10462-023-10575-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An Optimization Driven Spike Deep Belief Neural Networks is a type of neural network that is inspired by the functioning of the human brain. It is a variant of the more general class of Deep Belief Networks (DBNs), which are artificial neural networks composed of multiple layers of hidden units. Spike sorting is a critical process in neural signal processing that involves separating and identifying individual action potentials, spikes, from extracellular recordings of neuronal activity. This process is essential for understanding the behaviour of individual neurons and for decoding neural signals in various applications, such as Brain Machine Interfaces (BMIs) and neuro science research. Spike sorting is challenging due to the complexity of the recorded signals, including overlapping spikes and noise from other sources. This manuscript proposes A deep-learning based Multichannel Spike Sorting Neural Signal Processor (SSNSP) Module for High-Channel-Count Brain Machine Interfaces to record spike activity (SA) of brain neuron signals with less noise. Here first data acquisition is first step and the data’s are took form Neural Signal Processor (NSP). Then the collected features are stored in BMIs. After this process feature is extracted using Haar DWT. Haar DWT is a frequency based feature extractor used to extract the spike or noisy signals from the neuron signals. Then the extracted features are given to driven spike DBN, this is a combination of multi-layer perceptron (MLP) layer and DBN. To increase the accuracy, Adam-Cuckoo Search optimization is used, which optimize the driven spike DBN weight parameter. An FPGA was used to construct and test a prototype 32-channel SSNSP component based on this analysis. Synthesised signals are used at various signals to noise ratios. Then, human neurons are classified based on the channels containing neural spike data. The impact of busy as well as idle state prediction errors on the spectrum efficacy is examined. The proposed technique is implemented in MATLAB platform. Finally, the proposed technique attains better detection accuracy 22.86\%, 28.94\%, 31.11\% and 27.34\% compared to the existing models, like Deep Learning Laser Speckle Contrast ESNN (DL-LSC-ESNN), Highly Stretchable Hydro gels as Wearable with Implantable Sensors for Recording Physiological with Brain Neural Signals (HSN-WIS-RPBNS), Lower-power band of neuronal spiking action dominated through local single units enhances the Presentation of BMI (LPB-NSA-LSU-BMI) and Emotion Categorization Utilizing Feature Fusion of Multimodal Data along Deep Learning in Brain-Inspired Spiking Neural Network (EC-FFMD-BISNN) respectively.},
  archive      = {J_AIR},
  author       = {Reddy, Vanga Karunakar and Melingi, Sunil Babu and Kumar, Ch. V. M. S. N. Pavan and Kumar, K. Ashok and Mojjada, Ramesh Kumar},
  doi          = {10.1007/s10462-023-10575-4},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2207-2233},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Optimization driven spike deep belief neural network classifier: A deep-learning based multichannel spike sorting neural signal processor (NSP) module for high-channel-count brain machine interfaces (BMIs)},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detection and classification of sugarcane billet damage
using aquila sailfish optimizer based deep learning. <em>AIR</em>,
<em>56</em>(2), 2183–2206. (<a
href="https://doi.org/10.1007/s10462-023-10574-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the plantation of sugarcane is done in mechanized manner with billets that are short segments of sugarcane harvested. The automated harvesting procedure can destroy billets and reduces quality of billets. Deep convolution neural network is applied to diagnose sugarcane billet damage (DCNN). A novel technique, namely Aquila Sailfish Optimizer (ASO) algorithm is devised for weight update of neurons in training the DCNN and enhances the efficiency of DCNN. The ASO is obtained by incorporating Aquila Optimizer (AO) and Sailfish Optimizer (SFO). The classification of sugarcane billet damage is done by Chronological Aquila Sailfish Optimizer (CASO) algorithm trained Deep Quantum Neural Network (DQNN), which is trained with obtained by incorporating Chronological concept in ASO. Here, the sugarcane billet damage will be classified into five types, including Crushed (blue), Cracked (red), No buds (yellow), Two buds (green) and Single damaged bud (orange). The developed CASO-based DQNN presented highest precision of 91\%, recall of 93.3\%, F-measure of 92.1\%, and accuracy of 91.5\%.},
  archive      = {J_AIR},
  author       = {Nagapavithra, S. and Umamaheswari, S.},
  doi          = {10.1007/s10462-023-10574-5},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2183-2206},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Detection and classification of sugarcane billet damage using aquila sailfish optimizer based deep learning},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-knowledge resources-based semantic similarity models
with application for movie recommender system. <em>AIR</em>,
<em>56</em>(2), 2151–2182. (<a
href="https://doi.org/10.1007/s10462-023-10573-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, researchers have proposed several feature-based methods to measure semantic similarity using knowledge resources like Wikipedia and WordNet. While Wikipedia covers millions of concepts with multiple features, it has some limitations such as articles with limited content and concept ambiguity. Disambiguating these concepts remains a challenge. Conversely, WordNet offers unambiguous terms by covering all possible senses, making it a useful resource for disambiguating Wikipedia concepts. Additionally, WordNet can enrich the limited content of Wikipedia articles. Thus, we present a new approach that combines both resources to enhance previous feature-based methods of semantic similarity. We begin by analyzing the limitations of previous research, followed by introducing a novel method to disambiguate Wikipedia concepts using WordNet’s synonym structure, resulting in more effective disambiguation. Furthermore, we use WordNet to supplement the features in Wikipedia articles and redefine the feature similarity functions. Finally, we train non-linear fitting-based models to measure semantic similarity. Our approach outperforms other previous methods on various benchmarks. To further showcase our approach, we apply our models to develop a movie recommender system using the MovieLens dataset, which consistently outperforms other systems.},
  archive      = {J_AIR},
  author       = {Huang, Guangjian and Zhu, Xingtu and Wasti, Shahbaz Hassan and Jiang, Yuncheng},
  doi          = {10.1007/s10462-023-10573-6},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2151-2182},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Multi-knowledge resources-based semantic similarity models with application for movie recommender system},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). New staircase sinusoidal voltage synthesizer and optimal
interval type-2 fuzzy controller for dynamic voltage restorer to
compensate voltage disturbances. <em>AIR</em>, <em>56</em>(2),
2125–2150. (<a
href="https://doi.org/10.1007/s10462-023-10572-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new staircase sinusoidal voltage synthesizer based on dc-dc boost converter and dc-ac multilevel inverter is proposed for dynamic voltage restorer to accurately compensate the power quality issues. The dc-dc boost converter which is connected to photovoltaic-based power supply system can provide required energy and high-gain voltage [2*(1−K)−2] via tracking the maximum power for the compensation process. The dc-ac multilevel inverter which their dc power sources have followed septenary geometric progression can provide high step staircase sinusoidal voltage [7(Nsw/6)] with low switch count. In this regard, the proposed staircase sinusoidal voltage synthesizer can effectively compensate the voltage disturbance conditions. In view of the fact that the compensator control system must properly operate so that the proposed voltage synthesizer reveals its step creation capability, an interval type-2 fuzzy controller is implemented to assist the power electronic part. The controller parameters have been optimally extracted using multi-objective stochastic fractal search algorithm to ensure the control process accuracy. To verify and validate the compensation capability of the proposed compensator, the simulation results have been focused on asymmetrical voltage disturbance conditions. Finally, the comparison and simulation results have strongly confirmed the high step creation and compensation capabilities of the proposed DVR.},
  archive      = {J_AIR},
  author       = {Darvish Falehi, Ali and Torkaman, Hossein},
  doi          = {10.1007/s10462-023-10572-7},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2125-2150},
  shortjournal = {Artif. Intell. Rev.},
  title        = {New staircase sinusoidal voltage synthesizer and optimal interval type-2 fuzzy controller for dynamic voltage restorer to compensate voltage disturbances},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Conditional autoregressive-tunicate swarm algorithm based
generative adversarial network for violent crowd behavior recognition.
<em>AIR</em>, <em>56</em>(2), 2099–2123. (<a
href="https://doi.org/10.1007/s10462-023-10571-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Violent crowd behavior detection has gained significant attention in the computer vision system. Diverse crowd behavior detection approaches are introduced to detect violent behavior but enhancing the recognition rate poses a complex task due to different crowd diversity, mutual occlusion between crowds, and diversity of monitoring scene. Therefore, a crowd behavior recognition mechanism is introduced by Conditional Autoregressive-Tunicate Swarm Algorithm based Generative Adversarial Network (CA-TSA based GAN) to detect violent behavior. Accordingly, the developed CA-TSA is modeled by inheriting Conditional Autoregressive Value at Risk by Regression Quantiles with Tunicate Swarm Algorithm. Initially, the features, such as Tanimoto based Violence Flows descriptor, Local Ternary patterns, and Gray level co-occurrence matrix are extracted from the video frames. Then, the crowd behavior recognition is done by the GAN, which finds the abnormal and the normal crowd behaviors. Here, GAN is trained by the proposed CA-TSA. Moreover, the performance of the proposed method is analyzed using ASLAN challenge dataset. The developed model has the accuracy, sensitivity, and specificity values of 93.688\%, 94.261\%, and 94.051\%, respectively.},
  archive      = {J_AIR},
  author       = {Singh, Juginder Pal and Kumar, Manoj},
  doi          = {10.1007/s10462-023-10571-8},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2099-2123},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Conditional autoregressive-tunicate swarm algorithm based generative adversarial network for violent crowd behavior recognition},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computational deep air quality prediction techniques: A
systematic review. <em>AIR</em>, <em>56</em>(2), 2053–2098. (<a
href="https://doi.org/10.1007/s10462-023-10570-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The escalating population and rapid industrialization have led to a significant rise in environmental pollution, particularly air pollution. This has detrimental effects on both the environment and human health, resulting in increased morbidity and mortality. As a response to this pressing issue, the development of air quality prediction models has emerged as a critical research area. In this systematic literature review, we focused on reviewing 203 potential articles published between 2017 and May 2023 obtained from major databases. Our review specifically targeted keywords such as air quality prediction, air pollution prediction, and air quality classification. The review addressed five key research questions, including the types of deep learning (DL) models employed, the performance metrics considered, the best-performing models based on quantitative analysis, and the existing challenges and future prospects in the field. Additionally, we highlighted the limitations of current air quality prediction models and proposed various future research directions to foster further advancements in this area.},
  archive      = {J_AIR},
  author       = {Kaur, Manjit and Singh, Dilbag and Jabarulla, Mohamed Yaseen and Kumar, Vijay and Kang, Jusung and Lee, Heung-No},
  doi          = {10.1007/s10462-023-10570-9},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2053-2098},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Computational deep air quality prediction techniques: A systematic review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic literature review on AutoML for multi-target
learning tasks. <em>AIR</em>, <em>56</em>(2), 2013–2052. (<a
href="https://doi.org/10.1007/s10462-023-10569-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated machine learning (AutoML) aims to automate machine learning (ML) tasks, eliminating human intervention from the learning process as much as possible. However, most studies on AutoML are related to unique targets. This article aimed to identify and analyze studies on AutoML applied to multi-label classification and multi-target regression through a systematic literature review (SLR). Initially, we defined the research questions, the search string, the data sources for the search, and the inclusion and exclusion criteria. Then, we carried out the study selection process in four steps, with snowballing being the last stage. Altogether 12 studies were selected to compose SLR. All studies automated the task of ML model search of the pipeline, one study automated the task of feature engineering of the pipeline, all were related to Multi-label Classification, and only one addressed multi-target regression. The search space consisted of algorithms/neural operations and hyperparameters, the studies employed optimization algorithms (such as Genetic Algorithms and Hierarchical Task Networks) to produce increasingly better candidate solutions and one metric to assess the quality of candidate solutions. Only two studies employed Transfer Learning to contribute to AutoML. This article reviewed AutoML, multi-label classification, and multi-target regression and, by answering the SLR research questions, showed how current studies address these issues and gave insights into future directions for AutoML and multi-target tasks.},
  archive      = {J_AIR},
  author       = {Del Valle, Aline Marques and Mantovani, Rafael Gomes and Cerri, Ricardo},
  doi          = {10.1007/s10462-023-10569-2},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {2013-2052},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A systematic literature review on AutoML for multi-target learning tasks},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). RNN-AFOX: Adaptive FOX-inspired-based technique for
automated tuning of recurrent neural network hyper-parameters.
<em>AIR</em>, <em>56</em>(2), 1981–2011. (<a
href="https://doi.org/10.1007/s10462-023-10568-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The energy markets, particularly oil and gas, have been significantly affected by the outbreak of the COVID-19 pandemic in terms of price and availability. In addition to the pandemic, the Russia-Ukraine war has contributed to concerns about the reduction in the oil supply. AI techniques are widely employed for prediction oil prices as an alternative to traditional techniques. In this paper, an AI-based optimization model called adaptive fox-inspired optimization (AFOX) model is presented, then recurrent neural network (RNN) is combined with AFOX to form a hybrid model called recurrent neural network with adaptive fox-inspired (RNN-AFOX) model. The proposed model is used to predict Crude Oil Prices. In the proposed model, AFOX is used to find the best hyper-parameters of the RNN and employed these hyper-parameters to build best RNN structure and use it to forecast the closing price of the oil market. The results show that the RNN-AFOX model achieved a high accuracy prediction with very small error and the coefficient of determination (R-squared) equal to 0.99 outperforming the RNN model in terms of accuracy prediction by about 24\%, the FOX model by about 20\% and the AFOX model by about 14\%. Moreover, RNN-AFOX was evaluated under the impact of the COVID-19 pandemic and the Russia-Ukraine war. The results show the efficiency of RNN-AFOX in forecasting the closing prices of oil with high accuracy. In general, the proposed RNN-AFOX model overcomes other studied models in terms of Mean Absolute Percentage Error, Mean Absolute Error, Mean Square Error, Root Mean Square Error, coefficient of determination (R-squared) and consumption time.},
  archive      = {J_AIR},
  author       = {ALRahhal, Hosam and Jamous, Razan},
  doi          = {10.1007/s10462-023-10568-3},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1981-2011},
  shortjournal = {Artif. Intell. Rev.},
  title        = {RNN-AFOX: Adaptive FOX-inspired-based technique for automated tuning of recurrent neural network hyper-parameters},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Crayfish optimization algorithm. <em>AIR</em>,
<em>56</em>(2), 1919–1979. (<a
href="https://doi.org/10.1007/s10462-023-10567-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a meta heuristic optimization algorithm, called Crayfish Optimization Algorithm (COA), which simulates crayfish’s summer resort behavior, competition behavior and foraging behavior. The three behaviors are divided into three different stages to balance the exploration and exploitation of algorithm. The three stages are summer resort stage, competition stage and foraging stage. The summer resort stage represents the exploration stage of the COA. The competition stage and foraging stage represent the exploitation stage of the COA. Exploration and exploitation of COA are regulated by temperature. When the temperature is too high, crayfish will enter the cave for summer vacation or compete for the same cave. When the temperature is appropriate, crayfish have different foraging behaviors according to the size of food. Among them, the amount of food eaten by crayfish is related to food intake. Through temperature regulate exploration and exploitation process in COA, the COA has higher randomness and global optimization effect. To verify the optimization effect of COA, in the experimental part, 23 standard benchmark functions and CEC2014 benchmark functions are used to test, and 9 algorithms are selected for comparative experiments. The experimental results show that COA can balance the exploration and exploitation, and achieve good optimization effect. Finally, the COA is tested in five engineering problems, and finally achieves better results. The source code website for COA is https://github.com/rao12138/COA-s-code .},
  archive      = {J_AIR},
  author       = {Jia, Heming and Rao, Honghua and Wen, Changsheng and Mirjalili, Seyedali},
  doi          = {10.1007/s10462-023-10567-4},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1919-1979},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Crayfish optimization algorithm},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep neural network pruning method based on sensitive layers
and reinforcement learning. <em>AIR</em>, <em>56</em>(2), 1897–1917. (<a
href="https://doi.org/10.1007/s10462-023-10566-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is of great significance to compress neural network models so that they can be deployed on resource-constrained embedded mobile devices. However, due to the lack of theoretical guidance for non-salient network components, existing model compression methods are inefficient and labor-intensive. In this paper, we propose a new pruning method to achieve model compression. By exploring the rank ordering of the feature maps of convolutional layers, we introduce the concept of sensitive layers and treat layers with more low-rank feature maps as sensitive layers. We propose a new algorithm for finding sensitive layers while using reinforcement learning deterministic strategies to automate pruning for insensitive layers. Experimental results show that our method achieves significant improvements over the state-of-the-art in floating-point operations and parameter reduction, with lower precision loss. For example, using ResNet-110 on CIFAR-10 achieves a 62.2\% reduction in floating-point operations by removing 63.9\% of parameters. When testing ResNet-50 on ImageNet, our method reduces floating-point operations by 53.8\% by deleting 39.9\% of the parameters.},
  archive      = {J_AIR},
  author       = {Yang, Wenchuan and Yu, Haoran and Cui, Baojiang and Sui, Runqi and Gu, Tianyu},
  doi          = {10.1007/s10462-023-10566-5},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1897-1917},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep neural network pruning method based on sensitive layers and reinforcement learning},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on computational metaphor processing techniques:
From identification, interpretation, generation to application.
<em>AIR</em>, <em>56</em>(2), 1829–1895. (<a
href="https://doi.org/10.1007/s10462-023-10564-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaphors are figurative expressions frequently appearing daily. Given its significance in downstream natural language processing tasks such as machine translation and sentiment analysis, computational metaphor processing has led to an upsurge in the community. The progress of Artificial Intelligence has incentivized several technological tools and frameworks in this domain. This article aims to comprehensively summarize and categorize previous computational metaphor processing approaches regarding metaphor identification, interpretation, generation, and application. Though studies on metaphor identification have made significant progress, metaphor understanding, conceptual metaphor processing, and metaphor generation still need in-depth analysis. We hope to identify future directions for prospective researchers based on comparing the strengths and weaknesses of the previous works.},
  archive      = {J_AIR},
  author       = {Ge, Mengshi and Mao, Rui and Cambria, Erik},
  doi          = {10.1007/s10462-023-10564-7},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1829-1895},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey on computational metaphor processing techniques: From identification, interpretation, generation to application},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiple attributes group decision-making based on
trigonometric operators, particle swarm optimization and complex
intuitionistic fuzzy values. <em>AIR</em>, <em>56</em>(2), 1787–1831.
(<a href="https://doi.org/10.1007/s10462-022-10208-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes a novel multi-attribute group decision-making (MAGDM) algorithm based on complex intuitionistic fuzzy values (CIFVs). The present work is divided into three parts. In the first part, the uncertainties in the data are expressed in CIFVs with two membership degrees over the unit disc of the complex plane. The second part states some new operational laws based on tangential functions and the aggregation operators to aggregate the different CIFVs. The properties related to the proposed operations and operators are studied. A nonlinear multi-objective optimization model has been formulated by considering the maximizing and minimizing satisfaction and dissatisfaction degrees respectively to derive the attribute weights for the MAGDM problems. The model has been solved using the particle swarm optimization algorithm. Finally, a numerical example illustrates a MAGDM algorithm based on proposed operators. The reliability and effectiveness of the proposed method is explored by comparing it with several general studies.},
  archive      = {J_AIR},
  author       = {Rani, Dimple and Garg, Harish},
  doi          = {10.1007/s10462-022-10208-2},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1787-1831},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Multiple attributes group decision-making based on trigonometric operators, particle swarm optimization and complex intuitionistic fuzzy values},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic review of federated learning from clients’
perspective: Challenges and solutions. <em>AIR</em>, <em>56</em>(2),
1773–1827. (<a
href="https://doi.org/10.1007/s10462-023-10563-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a machine learning approach that decentralizes data and its processing by allowing clients to train intermediate models on their devices with locally stored data. It aims to preserve privacy as only model updates are shared with a central server rather than raw data. In recent years, many reviews have evaluated FL from the system (general challenges) or server’s perspectives, ignoring the importance of clients’ perspectives. Although FL helps users have control over their data, there are many challenges arising from decentralization, specifically from the perspectives of clients who are the main contributors to FL. Therefore, in response to the gap in the literature, this study intends to explore client-side challenges and available solutions by conducting a systematic literature review on 238 primary studies. Further, we analyze if a solution identified for one type of challenge is also applicable to other challenges and if there are impacts to consider. The conclusion of this survey reveals that servers and platforms have to work with clients to address client-side challenges.},
  archive      = {J_AIR},
  author       = {Shanmugarasa, Yashothara and Paik, Hye-young and Kanhere, Salil S. and Zhu, Liming},
  doi          = {10.1007/s10462-023-10563-8},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1773-1827},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A systematic review of federated learning from clients’ perspective: Challenges and solutions},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weakly supervised discriminate enhancement network for
visual sentiment analysis. <em>AIR</em>, <em>56</em>(2), 1763–1785. (<a
href="https://doi.org/10.1007/s10462-022-10212-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several methods employ weakly supervised technology to highlight the visual sentiment information in images, so as to improve the performance of sentiment analysis. However, the over-focusing of location technology leads to the neglect of the information of some discriminative sentiment regions. In this work, we propose a Weakly Supervised Discriminate Enhancement Network (WSDEN) for visual sentiment analysis to construct a prediction framework of image sentiment. To be specific, firstly, the proposed WSDEN learns sentiment maps with a weakly supervised technology, thus it significantly reduces the annotation burden and encourages features to convey more sentiment information. Secondly, to solve the problem of overemphasis on local information mentioned above, Discriminate Enhancement Map is constructed by spatial weighting and channel weighting, which combines the sentiment map to perform sentiment enhancement on the final deep features of images. Extensive experiments on three benchmark databases show that the proposed method outperforms the state-of-the-art methods of visual sentiment analysis.},
  archive      = {J_AIR},
  author       = {Li, Zhuoyi and Lu, Huibin and Zhao, Chuang and Feng, Linjing and Gu, Guanghua and Chen, Wenbai},
  doi          = {10.1007/s10462-022-10212-6},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1763-1785},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Weakly supervised discriminate enhancement network for visual sentiment analysis},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An effective control design approach based on novel enhanced
aquila optimizer for automatic voltage regulator. <em>AIR</em>,
<em>56</em>(2), 1731–1762. (<a
href="https://doi.org/10.1007/s10462-022-10216-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new metaheuristic algorithm by enhancing one of the recently proposed optimizers named Aquila optimizer (AO). The enhanced AO (enAO) algorithm is constructed by employing a novel modified opposition-based learning (OBL) mechanism and Nelder-Mead (NM) simplex search method. The novel modified OBL aids the AO in further diversification while the NM method increases the intensification. The enAO algorithm is first demonstrated to have more extraordinary ability than the original AO algorithm by employing challenging benchmark functions from the CEC 2019 test suite. The constructed enAO algorithm is proposed to design a PID plus second-order derivative (PIDD2) controller used in an automatic voltage regulator (AVR) system. To reach better efficiency, a novel objective function is also proposed in this paper. Initially, the proposed enAO-PIDD2 approach is demonstrated to be superior in terms of transient and frequency responses along with robustness and disturbance rejection compared to other available and best performing PID, fractional order PID (FOPID), PID acceleration (PIDA), and PIDD2 controllers tuned with different practical algorithms. Moreover, the superior performance of the proposed approach is also demonstrated comparatively using other available techniques for the AVR system reported in the last six years.},
  archive      = {J_AIR},
  author       = {Ekinci, Serdar and Izci, Davut and Eker, Erdal and Abualigah, Laith},
  doi          = {10.1007/s10462-022-10216-2},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1731-1762},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An effective control design approach based on novel enhanced aquila optimizer for automatic voltage regulator},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine and deep learning for longitudinal biomedical data:
A review of methods and applications. <em>AIR</em>, <em>56</em>(2),
1711–1771. (<a
href="https://doi.org/10.1007/s10462-023-10561-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploiting existing longitudinal data cohorts can bring enormous benefits to the medical field, as many diseases have a complex and multi-factorial time-course, and start to develop long before symptoms appear. With the increasing healthcare digitisation, the application of machine learning techniques for longitudinal biomedical data may enable the development of new tools for assisting clinicians in their day-to-day medical practice, such as for early diagnosis, risk prediction, treatment planning and prognosis estimation. However, due to the heterogeneity and complexity of time-varying data sets, the development of suitable machine learning models introduces major challenges for data scientists as well as for clinical researchers. This paper provides a comprehensive and critical review of recent developments and applications in machine learning for longitudinal biomedical data. Although the paper provides a discussion of clustering methods, its primary focus is on the prediction of static outcomes, defined as the value of the event of interest at a given instant in time, using longitudinal features, which has emerged as the most commonly employed approach in healthcare applications. First, the main approaches and algorithms for building longitudinal machine learning models are presented in detail, including their technical implementations, strengths and limitations. Subsequently, most recent biomedical and clinical applications are reviewed and discussed, showing promising results in a wide range of medical specialties. Lastly, we discuss current challenges and consider future directions in the field to enhance the development of machine learning tools from longitudinal biomedical data.},
  archive      = {J_AIR},
  author       = {Cascarano, Anna and Mur-Petit, Jordi and Hernández-González, Jerónimo and Camacho, Marina and de Toro Eadie, Nina and Gkontra, Polyxeni and Chadeau-Hyam, Marc and Vitrià, Jordi and Lekadir, Karim},
  doi          = {10.1007/s10462-023-10561-w},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1711-1771},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Machine and deep learning for longitudinal biomedical data: A review of methods and applications},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global bibliometric mapping of the frontier of knowledge in
the field of artificial intelligence for the period 1990–2019.
<em>AIR</em>, <em>56</em>(2), 1699–1729. (<a
href="https://doi.org/10.1007/s10462-022-10206-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) has emerged as a field of knowledge that is displacing and disrupting technologies, leading to changes in human life. Therefore, the purpose of this study is to scientifically map this topic and its ramifications, in order to analyze its growth. The study was developed under the bibliometric approach and considered the period 1990–2019. The steps followed were (i) Identification and selection of keyword terms in three methodological layers by a panel of experts. (ii) Design and application of an algorithm to identify these selected keywords in titles, abstracts, and keywords using terms in Web of Science to contrast them. (iii) Performing data processing based on the Journals of the Journal Citation Report during 2020. Knowing the evolution of a field of knowledge such as AI from a bibliometric study and subsequently establishing the ramifications of new research streams is in itself a relevant finding. Addressing a broad field of knowledge as AI from a multidisciplinary approach given the convergence it generates with other disciplines and specialties is of high strategic value for decision makers such as governments, academics, scientists, and entrepreneurs.},
  archive      = {J_AIR},
  author       = {De la Vega Hernández, Iván Manuel and Urdaneta, Angel Serrano and Carayannis, Elias},
  doi          = {10.1007/s10462-022-10206-4},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1699-1729},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Global bibliometric mapping of the frontier of knowledge in the field of artificial intelligence for the period 1990–2019},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Secure trust aware multi-objective routing protocol based on
battle competitive swarm optimization in IoT. <em>AIR</em>,
<em>56</em>(2), 1685–1709. (<a
href="https://doi.org/10.1007/s10462-023-10560-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A true routing system for the Internet of Things (IoT), Routing Protocol for Low Power and Lossy Networks (RPL) offers protection against many types of routing threats. The attacker can exploit the routing structure of RPL for launching devastating and destructive attacks counter to an IoT network. Moreover, Sybil and Rank attacks are most familiar among IoT attacks. Additionally, the resource-constrained design of IoT devices results in a routing protocol for RPL that is susceptible to a number of assaults. Even though the RPL condition offers encryption protection for controlling messages, RPL is susceptible to selfish behaviors and also internal attackers. In this research, the Battle Competitive Swarm Optimisation (BCSO) algorithm is developed to address the absence of reliable security measures in RPL. This approach principally encompasses two segments, namely IoT simulation and RPL routing, whereas Destination Oriented Directed Acyclic Graph is also applied in RPL. In this approach, different fitness functions, such as node energy, delay, trust, and distance are considered. The devised BCSO_RPL achieved better performance than other conventional techniques with energy consumption, throughput, delay, link quality, and packet loss of 0.7038 J, 0.2964Gbps, 0.6950 s, 2.178, and 0.0950, respectively.},
  archive      = {J_AIR},
  author       = {Rajeesh Kumar, N. V. and Jaya Lakshmi, N. and Mallala, Balasubbareddy and Jadhav, Vaishali},
  doi          = {10.1007/s10462-023-10560-x},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1685-1709},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Secure trust aware multi-objective routing protocol based on battle competitive swarm optimization in IoT},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust stability of dynamical neural networks with multiple
time delays: A review and new results. <em>AIR</em>, <em>56</em>(2),
1647–1684. (<a
href="https://doi.org/10.1007/s10462-023-10552-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust stability properties of continuous-time dynamical neural networks involving time delay parameters have been extensively studied, and many sufficient criteria for robust stability of various classes of delayed dynamical neural networks have been obtained in the past literature. The class of activation functions and the types of delay terms involved in the mathematical models of dynamical neural networks are two main parameters in the determination of stability conditions for these neural network models. In this article, we will analyse a neural network model of relatively having a more complicated mathematical form where the neural system has the multiple time delay terms and the activation functions satisfy the Lipschitz conditions. By deriving a new and alternative upper bound value for the $$l_2$$ -norm of uncertain intervalised matrices and constructing some various forms of the same type of a Lyapunov functional, this paper will first propose new results on global robust stability of dynamical Hopfield neural networks having multiple time delay terms in the presence of the Lipschitz activation functions. Then, we show that some simple modified changes in robust stability conditions proposed for multiple delayed Hopfield neural network model directly yield robust stability conditions of multiple delayed Cohen-Grossberg neural network model. We will also make a very detailed review of the previously published robust stability research results, which are basically in the nonsingular M-matrix or various algebraic inequalities forms. In particular, the robust stability results proposed in this paper are proved to generalize almost all previously reported robust stability conditions for multiple delayed neural network models. Some concluding remarks and future works regarding robust stability analysis of dynamical neural systems are addressed.},
  archive      = {J_AIR},
  author       = {Aktas, Ezgi and Faydasicok, Ozlem and Arik, Sabri},
  doi          = {10.1007/s10462-023-10552-x},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1647-1684},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Robust stability of dynamical neural networks with multiple time delays: A review and new results},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A state-of-the-art survey of object detection techniques in
microorganism image analysis: From classical methods to deep learning
approaches. <em>AIR</em>, <em>56</em>(2), 1627–1698. (<a
href="https://doi.org/10.1007/s10462-022-10209-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microorganisms play a vital role in human life. Therefore, microorganism detection is of great significance to human beings. However, the traditional manual microscopic detection methods have the disadvantages of long detection cycle, low detection accuracy in large orders, and great difficulty in detecting uncommon microorganisms. Therefore, it is meaningful to apply computer image analysis technology to the field of microorganism detection. Computer image analysis can realize high-precision and high-efficiency detection of microorganisms. In this review, first,we analyse the existing microorganism detection methods in chronological order, from traditional image processing and traditional machine learning to deep learning methods. Then, we analyze and summarize these existing methods and introduce some potential methods, including visual transformers. In the end, the future development direction and challenges of microorganism detection are discussed. In general, we have summarized 142 related technical papers from 1985 to the present. This review will help researchers have a more comprehensive understanding of the development process, research status, and future trends in the field of microorganism detection and provide a reference for researchers in other fields.},
  archive      = {J_AIR},
  author       = {Ma, Pingli and Li, Chen and Rahaman, Md Mamunur and Yao, Yudong and Zhang, Jiawei and Zou, Shuojia and Zhao, Xin and Grzegorzek, Marcin},
  doi          = {10.1007/s10462-022-10209-1},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1627-1698},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A state-of-the-art survey of object detection techniques in microorganism image analysis: From classical methods to deep learning approaches},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ESOA-HGRU: Egret swarm optimization algorithm-based hybrid
gated recurrent unit for classification of diabetic retinopathy.
<em>AIR</em>, <em>56</em>(2), 1617–1646. (<a
href="https://doi.org/10.1007/s10462-023-10532-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetes is a chronic disease that affects people all over the world and raises the glucose level in the blood as a result of a lack of insulin. Diabetic Retinopathy causes retinal eye disease, which impairs vision and eventually results in blindness. The two classifications of Diabetic Retinopathy based on retinal indicators are Non-Proliferative and Proliferative Diabetic Retinopathy. The Diabetic Retinopathy diagnosis is a time-consuming process for professionals. But the use of handcrafted features limits this method’s performance. To identify Diabetic Retinopathy at an early stage, we propose an Egret Swarm optimized hybrid Mask Region-Based Convolutional Neural Network-Bidirectional Gated Recurrent Unit approach which identifies the interdependencies between different Diabetic Retinopathy stages. Initially, the input samples are preprocessed using data augmentation and partitioned into training and testing data. The parameter of the Hybrid Mask Region-Based Convolutional Neural Network-Bidirectional Gated Recurrent Unit model is optimized through the Egret Swarm Optimization algorithm to minimize the loss of the classifier. Here, Egret Swarm optimized hybrid Hybrid Mask Region-Based Convolutional Neural Network-Bidirectional Gated Recurrent Unit architecture is utilized to classify various Diabetic Retinopathy stages. This paper uses three large baseline datasets: Idrid, APTOS 2019 blindness detection, and Zenodo dataset. The simulation results demonstrated that the proposed technique achieved improved precision, recall, and F-measure scores which are nearly equal to 99.1\%, 98.9\%, and 99\%.},
  archive      = {J_AIR},
  author       = {Alajlan, Abrar M. and Razaque, Abdul},
  doi          = {10.1007/s10462-023-10532-1},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1617-1646},
  shortjournal = {Artif. Intell. Rev.},
  title        = {ESOA-HGRU: Egret swarm optimization algorithm-based hybrid gated recurrent unit for classification of diabetic retinopathy},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Image forgery techniques: A review. <em>AIR</em>,
<em>56</em>(2), 1577–1625. (<a
href="https://doi.org/10.1007/s10462-022-10211-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image forensics is an investigation of digital images to identify manipulations that have been done on them. Nowadays, due to the availability of different low-cost devices for capturing images, digital images are gaining quite a bit of popularity. It occurs frequently that these images are manipulated by mistake or on purpose, resulting in inaccurate information being presented by the image. There is a need to develop techniques to identify forgeries present in digital images used by the media, in court trials, and for maintaining visual records, since digital images are commonly used as evidence through the media, in court, and for maintaining record keeping. A detailed review of various image forgery detection techniques is presented in this article including comparisons between the various methods, pros and cons, and results obtained during the experimentation.},
  archive      = {J_AIR},
  author       = {Kaur, Gurpreet and Singh, Navdeep and Kumar, Munish},
  doi          = {10.1007/s10462-022-10211-7},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1577-1625},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Image forgery techniques: A review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Survey on reinforcement learning for language processing.
<em>AIR</em>, <em>56</em>(2), 1543–1575. (<a
href="https://doi.org/10.1007/s10462-022-10205-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years some researchers have explored the use of reinforcement learning (RL) algorithms as key components in the solution of various natural language processing (NLP) tasks. For instance, some of these algorithms leveraging deep neural learning have found their way into conversational systems. This paper reviews the state of the art of RL methods for their possible use for different problems of NLP, focusing primarily on conversational systems, mainly due to their growing relevance. We provide detailed descriptions of the problems as well as discussions of why RL is well-suited to solve them. Also, we analyze the advantages and limitations of these methods. Finally, we elaborate on promising research directions in NLP that might benefit from RL.},
  archive      = {J_AIR},
  author       = {Uc-Cetina, Víctor and Navarro-Guerrero, Nicolás and Martin-Gonzalez, Anabel and Weber, Cornelius and Wermter, Stefan},
  doi          = {10.1007/s10462-022-10205-5},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1543-1575},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Survey on reinforcement learning for language processing},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review: Development of named entity recognition (NER)
technology for aeronautical information intelligence. <em>AIR</em>,
<em>56</em>(2), 1515–1542. (<a
href="https://doi.org/10.1007/s10462-022-10197-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of data and artificial intelligence technology has introduced new opportunities and challenges to aeronautical information intelligence. However, there are many obstacles in the sharing, reasoning and reusing aeronautical data due to the disunity of norms, the opacity of sharing and semantic ambiguity. To a large extent, as a basic method for processing, storing and deducing aeronautical data in the future, NER provides a new idea for the natural language processing of aeronautical information intelligence. In this paper, the problem with NER for aeronautical information is deeply analyzed, the relationship among the data model, the knowledge system and the named entity (NE) is combed, and the main characteristics of NE are summarized. At the same time, the resources that are useful to NER involving thematic databases, aviation domain ontology and evaluation indicators are described. Finally, two main directions of NER are suggested for further research, which is helpful in aviation development. This paper first provides a comprehensive survey of the approaches and directions of NER in a specific domain: aeronautical intelligence information.},
  archive      = {J_AIR},
  author       = {Baigang, Mi and Yi, Fan},
  doi          = {10.1007/s10462-022-10197-2},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1515-1542},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review: Development of named entity recognition (NER) technology for aeronautical information intelligence},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel perspective for q-neutrosophic soft relations and
their application in decision making. <em>AIR</em>, <em>56</em>(2),
1493–1513. (<a
href="https://doi.org/10.1007/s10462-022-10207-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although neutrosophic soft sets are quite successful in expressing neutral uncertain information, this mathematical approach is insufficient if the dimension of uncertain information increases. Therefore, in order to present a better approach to the uncertainty problems encountered, Q-neutrosophic soft sets (Abu Qamar in Entropy 20:172, 2018), which are a generalization of neutrosophic soft sets, are proposed for processing two-dimensional uncertain information. Moreover, relations are one of the methods preferred by researchers to explain the correspondences between objects in uncertain environments. The purpose of this paper is to explain the correspondence between objects in a better way. For this, the Q-neutrosophic soft set theory defined in Abu Qamar and Hassan (Entropy 20:172,2018) has been modified by taking inspiration from the definition of neutrosophic soft sets proposed by Deli and Broumi (J Intell Fuzzy Syst 28:2233–2241, 2015). In this way, it has been ensured that the two-dimensional information can be used more effectively in uncertainty problems encountered in many real-life problems. In this paper, Q-neutrosophic soft relations are defined by referring to the modified Q-neutrosophic soft set theory and analyzed in detail. Later, concepts related to Q-neutrosophic soft relations such as composition, inverse, functions, equivalence classes, and partitions are given. These concepts are especially exemplified by selecting uncertainty problems that can be encountered in real life and some related properties and theorems are presented. Finally, in an uncertainty problem, a decision-making algorithm is proposed by using the correspondence between objects and a comparison is given.},
  archive      = {J_AIR},
  author       = {Dalkılıç, Orhan and Demirtaş, Naime},
  doi          = {10.1007/s10462-022-10207-3},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1493-1513},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A novel perspective for Q-neutrosophic soft relations and their application in decision making},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). How to keep text private? A systematic review of deep
learning methods for privacy-preserving natural language processing.
<em>AIR</em>, <em>56</em>(2), 1427–1492. (<a
href="https://doi.org/10.1007/s10462-022-10204-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) models for natural language processing (NLP) tasks often handle private data, demanding protection against breaches and disclosures. Data protection laws, such as the European Union’s General Data Protection Regulation (GDPR), thereby enforce the need for privacy. Although many privacy-preserving NLP methods have been proposed in recent years, no categories to organize them have been introduced yet, making it hard to follow the progress of the literature. To close this gap, this article systematically reviews over sixty DL methods for privacy-preserving NLP published between 2016 and 2020, covering theoretical foundations, privacy-enhancing technologies, and analysis of their suitability for real-world scenarios. First, we introduce a novel taxonomy for classifying the existing methods into three categories: data safeguarding methods, trusted methods, and verification methods. Second, we present an extensive summary of privacy threats, datasets for applications, and metrics for privacy evaluation. Third, throughout the review, we describe privacy issues in the NLP pipeline in a holistic view. Further, we discuss open challenges in privacy-preserving NLP regarding data traceability, computation overhead, dataset size, the prevalence of human biases in embeddings, and the privacy-utility tradeoff. Finally, this review presents future research directions to guide successive research and development of privacy-preserving NLP models.},
  archive      = {J_AIR},
  author       = {Sousa, Samuel and Kern, Roman},
  doi          = {10.1007/s10462-022-10204-6},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1427-1492},
  shortjournal = {Artif. Intell. Rev.},
  title        = {How to keep text private? a systematic review of deep learning methods for privacy-preserving natural language processing},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Implementation of single-valued neutrosophic soft
hypergraphs on human nervous system. <em>AIR</em>, <em>56</em>(2),
1387–1425. (<a
href="https://doi.org/10.1007/s10462-022-10200-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-valued neutrosophic soft set simultaneously incorporates the attributes of both single-valued neutrosophic set as well as soft set. Corresponding to each parameter, it nominates a triplet $$(\mathfrak {t},\mathfrak {i},\mathfrak {f})$$ to a statement, where $$\mathfrak {t}$$ , $$\mathfrak {i}$$ and $$\mathfrak {f}$$ , respectively, describe the truthness, indeterminacy and falsity of that statement. In this article, we proceed in the framework of single-valued neutrosophic soft set by introducing single-valued neutrosophic soft hypergraphs which are effective to produce visual representation of connection among multiple objects of a system. Various fundamental operations such as union, join, Cartesian product and normal product of these graphical structures are suggested. We also discuss the construction of line graph and dual of single-valued neutrosophic soft hypergraphs with algorithms. The r-uniform single-valued neutrosophic soft hypergraphs with their operations like direct product, lexicographic product and costrong product is illustrated. In addition to this, we introduce the concept of regular, totally regular and perfectly regular single-valued neutrosophic soft hypergraphs and elaborate it with interesting results. Further, the single-valued neutrosophic soft directed hypergraphs together with some other interesting concepts have also been presented. At the end, it is explained that in what way, one can use the single-valued neutrosophic soft directed hypergraphs in the study of human nervous system. The proposed hypergraphs can be employed in artificial intelligence and decision-support systems effectively.},
  archive      = {J_AIR},
  author       = {Akram, Muhammad and Nawaz, Hafiza Saba},
  doi          = {10.1007/s10462-022-10200-w},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1387-1425},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Implementation of single-valued neutrosophic soft hypergraphs on human nervous system},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unbalanced double hierarchy linguistic group decision-making
method based on SWARA and s-ARAS for multiple attribute group
decision-making problems. <em>AIR</em>, <em>56</em>(2), 1349–1385. (<a
href="https://doi.org/10.1007/s10462-022-10198-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Curriculum evaluation shoulders the important task of measuring the realization of talent cultivation. Effective curriculum evaluation enables the school to optimally arrange courses and improve the overall quality of students. To implement the curriculum evaluation effectively, this paper constructs a multiple attribute group decision-making (MAGDM) method according to the characteristics of curriculum evaluation. In view of the nonlinearity and hesitation of decision maker’s cognition, unbalanced double hierarchy linguistic term sets (UDHLTSs) are utilized to fully represent the individual cognition of decision makers. Based on this, a novel MAGDM method with UDHLTSs is proposed. Firstly, to facilitate the analysis and treatment of UDHLTSs, the basic theories of UDHLTSs are perfected or complemented. Based on this, the unbalanced double hierarchy linguistic aggregation operator is defined and its properties are analyzed. Secondly, the weight determination method based on SWARA model is proposed to determinate the importance of each evaluation index under UDHLTSs environment. Thirdly, given the appetite of different decision-makers towards risk, an extended S-ARAS method is proposed based on S-utility function. Finally, to illustrate its effectiveness and rationality, the proposed method is applied in the case study of curriculum evaluation in university and compare with other methods.},
  archive      = {J_AIR},
  author       = {Teng, Fei and Shen, Mengjiao},
  doi          = {10.1007/s10462-022-10198-1},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1349-1385},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Unbalanced double hierarchy linguistic group decision-making method based on SWARA and S-ARAS for multiple attribute group decision-making problems},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved three phase h-7 transformerless inverter with DPWM
to reduce leakage current using CNN based deep learning technique.
<em>AIR</em>, <em>56</em>(2), 1319–1347. (<a
href="https://doi.org/10.1007/s10462-022-10187-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This investigation presents the three-phase Transformerless Inverters (TLI) for a solar photovoltaic (PV) system connected to a high power grid will be implement with better performance and lower cost. Many clamping topologies are developed in the single phase TLI solar PV system and have proven that they are better than the unclamped inverter topologies. In this proposed research, different DC decoupled transformerless inverter topologies with modified discontinuous PWM technique are derived from three phase H-7 transformerless inverter topologies respectively. Further, active switch and diode-based clamped topologies are proposed in addition. This topology certainly minimizes the fluctuations in the common mode voltage of the inverter during zero voltage state. Meanwhile it creates the path for leakage current flow in the off state grid voltage. Evaluations of leakage current and comparative analysis over the performance in terms of reactive power capability; switching and conduction losses of the device and total harmonic distortion are made for DC decoupled inverter and H-7 transformerless inverter. The validation of the proposed work is realized through the laboratory experiment and MATLAB/SIMULINK platform as well.},
  archive      = {J_AIR},
  author       = {Suganthi, R. and Pandi, Maruthu},
  doi          = {10.1007/s10462-022-10187-4},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1319-1347},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Improved three phase H-7 transformerless inverter with DPWM to reduce leakage current using CNN based deep learning technique},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the comparative performance of recent swarm intelligence
based algorithms for optimization of real-life sterling cycle operated
refrigeration/liquefaction system. <em>AIR</em>, <em>56</em>(2),
1297–1317. (<a
href="https://doi.org/10.1007/s10462-022-10201-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent past year of 2020–2021, researchers proposed many swarm intelligence based algorithms. In the present work, an effort has been made to compare the performance of these algorithms for the real-life constraint optimization problem. Swarm intelligence-based algorithms developed during 2020–2021 such as GEO, WHO, MPA, JSO, ChoA, MA, BWO, AO, COOT, and TSA are considered in the present work. These algorithms are implemented for the performance optimization of the Sterling cycle operated refrigeration/liquefaction system. Four operating variables and two output constraints of the Sterling cycle based system are considered for optimization. Comparative results are presented with statistical data to judge the performance of the algorithm and subsequently identify the statistical significance and rank of the algorithm. The effect of various constraint handling methods on the performance of algorithms is evaluated and presented. The behaviour of constraint handling methods is analyzed and presented with statistical data. Statistical analysis is also performed to observe whether the constraint handling methods produce a significant difference on the output of the considered algorithm. The effect of output constraints on the performance of algorithms is also evaluated and presented. Finally, the convergence behaviour of the competitive algorithms is obtained and demonstrated.},
  archive      = {J_AIR},
  author       = {Raja, Bansi D. and Patel, Vivek K. and Savsani, Vimal J. and Yıldız, Ali Rıza},
  doi          = {10.1007/s10462-022-10201-9},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1297-1317},
  shortjournal = {Artif. Intell. Rev.},
  title        = {On the comparative performance of recent swarm intelligence based algorithms for optimization of real-life sterling cycle operated refrigeration/liquefaction system},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Superiority of three-way decisions from the perspective of
probability. <em>AIR</em>, <em>56</em>(2), 1263–1295. (<a
href="https://doi.org/10.1007/s10462-022-10203-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way decisions (3WDs) is a typical method for dealing with uncertain issues. It is essentially an extension of two-way decisions (2WDs). What is the superiority of 3WDs/S3WDs over traditional 2WDs? Only a few studies have analyzed the theoretical superiority of 3WDs over traditional 2WDs. The motivation of this paper is to theoretically analyze the superiority of 3WDs over 2WDs in dealing with classification problems. From the perspective of probability, 3WDs is compared with 2WDs for a thorough discussion and analysis of the superiority of 3WDs in this paper. First, it is proved that increasing information can effectively improve classification precision in terms of the sample mean, misclassification probability, and interval of uncertain classification. Second, a novel 3WDs model/sequential three-way decisions model (3WDM-CLSM/S3WDM-CLSM) based on confidence level and sample mean is proposed, and the corresponding method for calculating the pair of thresholds based on the confidence level is presented. Third, the superiority of 3WDs compared to 2WDs is analyzed in terms of classification precision and cost of information acquisition (CIA). Finally, experiments are completed to show that the 3WDs model can effectively reduce the CIA, and its classification accuracy is close to that of the 2WDs model.},
  archive      = {J_AIR},
  author       = {Yin, Longjun and Zhang, Qinghua and Zhao, Fan and Liu, Dun and Wang, Guoyin},
  doi          = {10.1007/s10462-022-10203-7},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1263-1295},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Superiority of three-way decisions from the perspective of probability},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybridization of hybrid structures for time series
forecasting: A review. <em>AIR</em>, <em>56</em>(2), 1201–1261. (<a
href="https://doi.org/10.1007/s10462-022-10199-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving the desired accuracy in time series forecasting has become a binding domain, and developing a forecasting framework with a high degree of accuracy is one of the most challenging tasks in this area. Combining different forecasting methods to construct efficient hybrid models has been widely reported in the literature regarding this challenge. Various types of hybrid models have been developed and successfully employed to improve forecasting accuracy. The well-known hybrid models can be generally categorized into four classes: (1) preprocessing-based, (2) parameter optimization-based, (3) components combination-based, and (4) postprocessing-based hybrid models. Despite the significant successes of hybrid models, efforts to access more accurate results face continued growth. Hybridization of hybrid models is a novel idea proposed to obtain extreme accuracy in recent literature, in which two or more hybrid classes are combined instead of conjoining the conventional individual forecasting methods. Although, in many publications, the aforementioned classes of hybrid models have been reviewed and analyzed in a wide variety of forecasting fields; no study is conducted to review the hybridization of hybrid models. This paper’s main contribution is to fill this gap and provide classification and comprehensive review of the current endeavors done in the hybridization of hybrid models in time series forecasting areas. Our searches indicate that more than 250 papers have been published in recent years utilizing hybridization of hybrid models. In this paper, these published papers have been classified regarding their different used combination strategies into four main categories, including (1) Hybridization with preprocessing-based hybrid models (HPH), (2) Hybridization with parameter optimization-based hybrid models (HOH), (3) Hybridization with components combination-based hybrid models (HCH) and, (4) Hybridization with postprocessing-based hybrid models (HSH). Each hybridization of the hybrid class is evaluated regarding the usage frequency, specific merits, and limitations. It can be inferred from reviewing articles that the hybridization of the hybrid concept, as a recent advancement in time series forecasting, can significantly improve traditional hybrid models’ accuracy. Furthermore, each category’s research gaps and some future research directions are identified in this paper.},
  archive      = {J_AIR},
  author       = {Hajirahimi, Zahra and Khashei, Mehdi},
  doi          = {10.1007/s10462-022-10199-0},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1201-1261},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Hybridization of hybrid structures for time series forecasting: A review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on the use of association rules mining techniques
in textual social media. <em>AIR</em>, <em>56</em>(2), 1175–1200. (<a
href="https://doi.org/10.1007/s10462-022-10196-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The incursion of social media in our lives has been much accentuated in the last decade. This has led to a multiplication of data mining tools aimed at obtaining knowledge from these data sources. One of the greatest challenges in this area is to be able to obtain this knowledge without the need for training processes, which requires structured information and pre-labelled datasets. This is where unsupervised data mining techniques come in. These techniques can obtain value from these unstructured and unlabelled data, providing very interesting solutions to enhance the decision-making process. In this paper, we first address the problem of social media mining, as well as the need for unsupervised techniques, in particular association rules, for its treatment. We follow with a broad overview of the applications of association rules in the domain of social media mining, specifically, their application to the problems of mining textual entities, such as tweets. We also focus on the strengths and weaknesses of using association rules for solving different tasks in textual social media. Finally, the paper provides a perspective overview of the challenges that association rules must face in the next decade within the field of social media mining.},
  archive      = {J_AIR},
  author       = {Diaz-Garcia, Jose A. and Ruiz, M. Dolores and Martin-Bautista, Maria J.},
  doi          = {10.1007/s10462-022-10196-3},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1175-1200},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey on the use of association rules mining techniques in textual social media},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of spam email detection: Analysis of spammer
strategies and the dataset shift problem. <em>AIR</em>, <em>56</em>(2),
1145–1173. (<a
href="https://doi.org/10.1007/s10462-022-10195-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spam emails have been traditionally seen as just annoying and unsolicited emails containing advertisements, but they increasingly include scams, malware or phishing. In order to ensure the security and integrity for the users, organisations and researchers aim to develop robust filters for spam email detection. Recently, most spam filters based on machine learning algorithms published in academic journals report very high performance, but users are still reporting a rising number of frauds and attacks via spam emails. Two main challenges can be found in this field: (a) it is a very dynamic environment prone to the dataset shift problem and (b) it suffers from the presence of an adversarial figure, i.e. the spammer. Unlike classical spam email reviews, this one is particularly focused on the problems that this constantly changing environment poses. Moreover, we analyse the different spammer strategies used for contaminating the emails, and we review the state-of-the-art techniques to develop filters based on machine learning. Finally, we empirically evaluate and present the consequences of ignoring the matter of dataset shift in this practical field. Experimental results show that this shift may lead to severe degradation in the estimated generalisation performance, with error rates reaching values up to $$48.81\%$$ .},
  archive      = {J_AIR},
  author       = {Jáñez-Martino, Francisco and Alaiz-Rodríguez, Rocío and González-Castro, Víctor and Fidalgo, Eduardo and Alegre, Enrique},
  doi          = {10.1007/s10462-022-10195-4},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1145-1173},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review of spam email detection: Analysis of spammer strategies and the dataset shift problem},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the current state of deep learning for news
recommendation. <em>AIR</em>, <em>56</em>(2), 1101–1144. (<a
href="https://doi.org/10.1007/s10462-022-10191-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential outbreak of news articles makes it troublesome for the readers to find, select and read the most relevant ones and alleviate the resulting information and cognitive overload problems. In recent years, various deep learning (DL) models were developed to recommend personalized quality news articles and support readers. Yet, no survey paper highlights the strengths, weaknesses, and trends of news recommendation models employing DL methods. This survey fills this gap in the literature by identifying the current state of DL-based news recommendation methods. Specifically, it covers (1) the classification of DL-based news recommendation models, (2) their performance comparison, and (3) the essential issues faced by these models. It discusses the most commonly used datasets, evaluation methods, and implications for researchers working in this area.},
  archive      = {J_AIR},
  author       = {Amir, Nabila and Jabeen, Fouzia and Ali, Zafar and Ullah, Irfan and Jan, Asim Ullah and Kefalas, Pavlos},
  doi          = {10.1007/s10462-022-10191-8},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1101-1144},
  shortjournal = {Artif. Intell. Rev.},
  title        = {On the current state of deep learning for news recommendation},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). People versus machines: Introducing the HIRE framework.
<em>AIR</em>, <em>56</em>(2), 1071–1100. (<a
href="https://doi.org/10.1007/s10462-022-10193-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of Artificial Intelligence (AI) in the recruitment process is becoming a more common method for organisations to hire new employees. Despite this, there is little consensus on whether AI should have widespread use in the hiring process, and in which contexts. In order to bring more clarity to research findings, we propose the HIRE (Human, (Artificial) Intelligence, Recruitment, Evaluation) framework with the primary aim of evaluating studies which investigate how Artificial Intelligence can be integrated into the recruitment process with respect to gauging whether AI is an adequate, better, or worse substitute for human recruiters. We illustrate the simplicity of this framework by conducting a systematic literature review on the empirical studies assessing AI in the recruitment process, with 22 final papers included. The review shows that AI is equal to or better than human recruiters when it comes to efficiency and performance. We also find that AI is mostly better than humans in improving diversity. Finally, we demonstrate that there is a perception among candidates and recruiters that AI is worse than humans. Overall, we conclude based on the evidence, that AI is equal to or better to humans when utilised in the hiring process, however, humans hold a belief of their own superiority. Our aim is that future authors adopt the HIRE framework when conducting research in this area to allow for easier comparability, and ideally place the HIRE framework outcome of AI being better, equal, worse, or unclear in the abstract.},
  archive      = {J_AIR},
  author       = {Will, Paris and Krpan, Dario and Lordan, Grace},
  doi          = {10.1007/s10462-022-10193-6},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1071-1100},
  shortjournal = {Artif. Intell. Rev.},
  title        = {People versus machines: Introducing the HIRE framework},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Applications of artificial neural networks in microorganism
image analysis: A comprehensive review from conventional multilayer
perceptron to popular convolutional neural network and potential visual
transformer. <em>AIR</em>, <em>56</em>(2), 1013–1070. (<a
href="https://doi.org/10.1007/s10462-022-10192-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microorganisms are widely distributed in the human daily living environment. They play an essential role in environmental pollution control, disease prevention and treatment, and food and drug production. The analysis of microorganisms is essential for making full use of different microorganisms. The conventional analysis methods are laborious and time-consuming. Therefore, the automatic image analysis based on artificial neural networks is introduced to optimize it. However, the automatic microorganism image analysis faces many challenges, such as the requirement of a robust algorithm caused by various application occasions, insignificant features and easy under-segmentation caused by the image characteristic, and various analysis tasks. Therefore, we conduct this review to comprehensively discuss the characteristics of microorganism image analysis based on artificial neural networks. In this review, the background and motivation are introduced first. Then, the development of artificial neural networks and representative networks are presented. After that, the papers related to microorganism image analysis based on classical and deep neural networks are reviewed from the perspectives of different tasks. In the end, the methodology analysis and potential direction are discussed.},
  archive      = {J_AIR},
  author       = {Zhang, Jinghua and Li, Chen and Yin, Yimin and Zhang, Jiawei and Grzegorzek, Marcin},
  doi          = {10.1007/s10462-022-10192-7},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1013-1070},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Applications of artificial neural networks in microorganism image analysis: A comprehensive review from conventional multilayer perceptron to popular convolutional neural network and potential visual transformer},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-order texture features for palmprint recognition.
<em>AIR</em>, <em>56</em>(2), 995–1011. (<a
href="https://doi.org/10.1007/s10462-022-10194-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Palmprint attracts increasing attention thanks to its several advantages. 1st-order textures have been widely used for palmprint recognition; unfortunately, high-order textures, although they are also discriminative, were ignored in the existing works. 2nd-order textures are first employed for palmprint recognition in this paper. 1st-order textures are convolved with the filters to extract 2nd-order textures that can refine the texture information and improve the contrast of the feature map. Then 2nd-order textures are used to generate 2nd-order Texture Co-occurrence Code (2TCC). The sufficient experiments demonstrate that 2TCC yields satisfactory accuracy performance on four public databases, including contact, contactless and multi-spectral acquisition types. Moreover, in order to further improve the discrimination and robustness of 2TCC, we propose Multiple-order Texture Co-occurrence Code (MTCC), in which 1st-order Texture Co-occurrence Code (1TCC) and 2TCC are fused at score level. 1TCC is good at describing minor wrinkles; while 2TCC does well in describing principal textures. Thus the combination of both can describe the palmprint features more comprehensively. MTCC achieves remarkable accuracy performance when compared with the state-of-the-art methods on all public databases.},
  archive      = {J_AIR},
  author       = {Yang, Ziyuan and Leng, Lu and Wu, Tengfei and Li, Ming and Chu, Jun},
  doi          = {10.1007/s10462-022-10194-5},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {995-1011},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Multi-order texture features for palmprint recognition},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A two-phase ant colony optimization based approach for
single depot multiple travelling salesman problem in type-2 fuzzy
environment. <em>AIR</em>, <em>56</em>(2), 965–993. (<a
href="https://doi.org/10.1007/s10462-022-10190-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a two-phase ant colony optimization (ACO) based approach has been presented to solve a single depot multiple travelling salesmen problem (mTSP) in Type-2 Gaussian fuzzy environment. In the single depot mTSP, a set of nodes and a set of salesmen are present, and each of the cities must be visited exactly once by the salesmen such that all of them start and finish at a depot. In this paper, a two-phase algorithm has been devised with ACO algorithm and some features of genetic algorithm (GA) to solve the projected problem. The devised algorithm is working appropriately with single depot mTSP. Here, in the first phase, the ACO algorithm is used for creating complete paths, and after that in the second phase, the GA features are used for optimizing the paths of multiple travellers. Moreover, the travelling cost is considered as Type-2 Gaussian fuzzy in nature and is reduced to its approximate crisp value using the reduction method of critical values. Some benchmark instances from TSPLIB have been used for performance analysis of the proposed algorithm. Computated results show that the devised algorithm is a competitive one for solving mTSP. Computational results with different datasets have been presented and some sensitivity analysis has also been done for fuzzy instances.},
  archive      = {J_AIR},
  author       = {Changdar, Chiranjit and Mondal, Moumita and Giri, Pravash Kumar and Nandi, Utpal and Pal, Rajat Kumar},
  doi          = {10.1007/s10462-022-10190-9},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {965-993},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A two-phase ant colony optimization based approach for single depot multiple travelling salesman problem in type-2 fuzzy environment},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Developments in the detection of diabetic retinopathy: A
state-of-the-art review of computer-aided diagnosis and machine learning
methods. <em>AIR</em>, <em>56</em>(2), 915–964. (<a
href="https://doi.org/10.1007/s10462-022-10185-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential increase in the number of diabetics around the world has led to an equally large increase in the number of diabetic retinopathy (DR) cases which is one of the major complications caused by diabetes. Left unattended, DR worsens the vision and would lead to partial or complete blindness. As the number of diabetics continue to increase exponentially in the coming years, the number of qualified ophthalmologists need to increase in tandem in order to meet the demand for screening of the growing number of diabetic patients. This makes it pertinent to develop ways to automate the detection process of DR. A computer aided diagnosis system has the potential to significantly reduce the burden currently placed on the ophthalmologists. Hence, this review paper is presented with the aim of summarizing, classifying, and analyzing all the recent development on automated DR detection using fundus images from 2015 up to this date. Such work offers an unprecedentedly thorough review of all the recent works on DR, which will potentially increase the understanding of all the recent studies on automated DR detection, particularly on those that deploys machine learning algorithms. Firstly, in this paper, a comprehensive state-of-the-art review of the methods that have been introduced in the detection of DR is presented, with a focus on machine learning models such as convolutional neural networks (CNN) and artificial neural networks (ANN) and various hybrid models. Each AI will then be classified according to its type (e.g. CNN, ANN, SVM), its specific task(s) in performing DR detection. In particular, the models that deploy CNN will be further analyzed and classified according to some important properties of the respective CNN architectures of each model. A total of 150 research articles related to the aforementioned areas that were published in the recent 5 years have been utilized in this review to provide a comprehensive overview of the latest developments in the detection of DR.},
  archive      = {J_AIR},
  author       = {Selvachandran, Ganeshsree and Quek, Shio Gai and Paramesran, Raveendran and Ding, Weiping and Son, Le Hoang},
  doi          = {10.1007/s10462-022-10185-6},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {915-964},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Developments in the detection of diabetic retinopathy: A state-of-the-art review of computer-aided diagnosis and machine learning methods},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep neuro-fuzzy system application trends, challenges, and
future perspectives: A systematic survey. <em>AIR</em>, <em>56</em>(2),
865–913. (<a href="https://doi.org/10.1007/s10462-022-10188-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNN) have remarkably progressed in applications involving large and complex datasets but have been criticized as a black-box. This downside has recently become a motivation for the research community to pursue the ideas of hybrid approaches, resulting in novel hybrid systems classified as deep neuro-fuzzy systems (DNFS). Studies regarding the implementation of DNFS have rapidly increased in the domains of computing, healthcare, transportation, and finance with high interpretability and reasonable accuracy. However, relatively few survey studies have been found in the literature to provide a comprehensive insight into this domain. Therefore, this study aims to perform a systematic review to evaluate the current progress, trends, arising issues, research gaps, challenges, and future scope related to DNFS studies. A study mapping process was prepared to guide a systematic search for publications related to DNFS published between 2015 and 2020 using five established scientific directories. As a result, a total of 105 studies were identified and critically analyzed to address research questions with the objectives: (i) to understand the concept of DNFS; (ii) to find out DNFS optimization methods; (iii) to visualize the intensity of work carried out in DNFS domain; and (iv) to highlight DNFS application subjects and domains. We believe that this study provides up-to-date guidance for future research in the DNFS domain, allowing for more effective advancement in techniques and processes. The analysis made in this review proves that DNFS-based research is actively growing with a substantial implementation and application scope in the future.},
  archive      = {J_AIR},
  author       = {Talpur, Noureen and Abdulkadir, Said Jadid and Alhussian, Hitham and Hasan, Mohd Hilmi and Aziz, Norshakirah and Bamhdi, Alwi},
  doi          = {10.1007/s10462-022-10188-3},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {865-913},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep neuro-fuzzy system application trends, challenges, and future perspectives: A systematic survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards hybrid over- and under-sampling combination methods
for class imbalanced datasets: An experimental study. <em>AIR</em>,
<em>56</em>(2), 845–863. (<a
href="https://doi.org/10.1007/s10462-022-10186-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The skewed class distributions of many class imbalanced domain datasets often make it difficult for machine learning techniques to construct effective models. In such cases, data re-sampling techniques, such as under-sampling the majority class and over-sampling the minority class are usually employed. In related literatures, some studies have shown that hybrid combinations of under- and over-sampling methods with differ orders can produce better results. However, each study only compares with either under- or over-sampling methods to make the final conclusion. Therefore, the research objective of this paper is to find out which order of combining under- and over-sampling methods perform better. Experiments are conducted based on 44 different domain datasets using three over-sampling algorithms, including SMOTE, CTGAN, and TAN, and three under-sampling (i.e. instance selection) algorithms, including IB3, DROP3, and GA. The results show that if the under-sampling algorithm is chosen carefully, i.e. IB3, no significant performance improvement is obtained by further addition of the over-sampling step. Furthermore, with the IB3 algorithm, it is better to perform instance selection first and over-sampling second than the other combination order, which can allow the random forest classifier to provide the highest AUC rate.},
  archive      = {J_AIR},
  author       = {Lin, Cian and Tsai, Chih-Fong and Lin, Wei-Chao},
  doi          = {10.1007/s10462-022-10186-5},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {845-863},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Towards hybrid over- and under-sampling combination methods for class imbalanced datasets: An experimental study},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fuzzy-based missing value imputation technique for air
pollution data. <em>AIR</em>, <em>56</em>(2), 1–38. (<a
href="https://doi.org/10.1007/s10462-022-10168-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analysis and prediction on real time air quality data is a critical step in solving various problems related to pollution and finding a genuine solution. However, missing values in air pollution data is a serious issue that may greatly influence the performance of such analysis and prediction. In order to address this problem, a 2-step process is proposed, consisting of a data pre-processing stage using Q-FUZZY (Quantized Fuzzification) model and data imputation stage via a Fuzzy Imputation Model(FIM) to handle this complexity. We have validated the proposed approach using a real world dataset of Kolkata, India containing pollution levels of different air pollutants along with meteorological parameters. Various performance measures are used to determine the effectiveness of FIM. Moreover, the performance of the proposed model is also compared with the baselines namely, FLAR (Fuzzy Least Absolute Regression), ridge regression and EMD-SVR-SARIMA (Empirical Mode Decomposition-Support Vector Regressions-Seasonal Autoregressive Integrated Moving Average). On comparison, it is observed that FIM achieves an overall better performance in terms of distance measures, Mean Similarity Measures (MSM), Mean Inclusion Measures (MIM) and Mean Predictive Ability (MPA).},
  archive      = {J_AIR},
  author       = {Mustafi, Ayon and Middya, Asif Iqbal and Roy, Sarbani},
  doi          = {10.1007/s10462-022-10168-7},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1-38},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Fuzzy-based missing value imputation technique for air pollution data},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Early health prediction framework using XGBoost ensemble
algorithm in intelligent environment. <em>AIR</em>, <em>56</em>(1),
1591–1615. (<a
href="https://doi.org/10.1007/s10462-023-10565-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Amidst the COVID-19 humanitarian catastrophe, the Internet of Things and Artificial Intelligence (AI) are premier technologies in the healthcare domain that have emerged to a great extent. This global health emergency highlights the need to bolster current healthcare systems for future preparedness. Conspicuously, the current paper presents a non-invasive AI-empowered model for passive health monitoring and predicting viral C-19 infection in the home environment. It consists of four notable layers: fully automated data acquisition, data analysis and Bayesian probabilistic classification, temporal COVID-19 severity prediction, and communication layer. These layers include IoT sensors embedded in the intelligent toilet system to collect required data, processes and analyses of the urine parametric data at the fog layer, and forecasting the COVID-19 severity using the XGBoost machine learning model at the cloud layer. The model has been evaluated over 53,550 data instances in a simulated environment for implementation purposes. The results implied that the proposed AI framework outperformed state-of-the-art strategies in terms of temporal approximation (94.53 s), reliability (92.69\%), stability (0.89\%), and predictive performance analysis (95.26\%) metrics.},
  archive      = {J_AIR},
  author       = {Kumar, Dheeraj and Sood, Sandeep Kumar and Rawat, Keshav Singh},
  doi          = {10.1007/s10462-023-10565-6},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {1591-1615},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Early health prediction framework using XGBoost ensemble algorithm in intelligent environment},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of uncertainty in deep neural networks.
<em>AIR</em>, <em>56</em>(1), 1513–1589. (<a
href="https://doi.org/10.1007/s10462-023-10562-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last decade, neural networks have reached almost every field of science and become a crucial part of various real world applications. Due to the increasing spread, confidence in neural network predictions has become more and more important. However, basic neural networks do not deliver certainty estimates or suffer from over- or under-confidence, i.e. are badly calibrated. To overcome this, many researchers have been working on understanding and quantifying uncertainty in a neural network’s prediction. As a result, different types and sources of uncertainty have been identified and various approaches to measure and quantify uncertainty in neural networks have been proposed. This work gives a comprehensive overview of uncertainty estimation in neural networks, reviews recent advances in the field, highlights current challenges, and identifies potential research opportunities. It is intended to give anyone interested in uncertainty estimation in neural networks a broad overview and introduction, without presupposing prior knowledge in this field. For that, a comprehensive introduction to the most crucial sources of uncertainty is given and their separation into reducible model uncertainty and irreducible data uncertainty is presented. The modeling of these uncertainties based on deterministic neural networks, Bayesian neural networks (BNNs), ensemble of neural networks, and test-time data augmentation approaches is introduced and different branches of these fields as well as the latest developments are discussed. For a practical application, we discuss different measures of uncertainty, approaches for calibrating neural networks, and give an overview of existing baselines and available implementations. Different examples from the wide spectrum of challenges in the fields of medical image analysis, robotics, and earth observation give an idea of the needs and challenges regarding uncertainties in the practical applications of neural networks. Additionally, the practical limitations of uncertainty quantification methods in neural networks for mission- and safety-critical real world applications are discussed and an outlook on the next steps towards a broader usage of such methods is given.},
  archive      = {J_AIR},
  author       = {Gawlikowski, Jakob and Tassi, Cedrique Rovile Njieutcheu and Ali, Mohsin and Lee, Jongseok and Humt, Matthias and Feng, Jianxiang and Kruspe, Anna and Triebel, Rudolph and Jung, Peter and Roscher, Ribana and Shahzad, Muhammad and Yang, Wen and Bamler, Richard and Zhu, Xiao Xiang},
  doi          = {10.1007/s10462-023-10562-9},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {1513-1589},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of uncertainty in deep neural networks},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A comprehensive survey on deep learning-based approaches for
multimodal sentiment analysis. <em>AIR</em>, <em>56</em>(1), 1479–1512.
(<a href="https://doi.org/10.1007/s10462-023-10555-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is an important natural language processing issue that has many applications in various fields. The increasing popularity of social networks and growth and development of their related tools and technologies has led to share the users’ multimodal content and opinions in a hybrid form of different media, including texts, images, videos, audio and emojis. The increasing interest of users to share their content using a combination of several media has significantly increased the amount of multimodal data. Most of the comments that users post in the social media have emotional aspects and provide useful indicators for many purposes. Compared to single-modal data, such as text-only or image-only comments, multimodal data contain more useful information and leads to better understanding of the real sentiments of users. Many studies have been conducted in this area, each of which deals with one or some of the various common challenges of multimodal sentiment analysis methods, including incomplete data, heterogeneity of modals, fusion method of the results, interactions between modals, and existence of unrelated, insufficient and redundant data and information. The emergence of deep neural networks and the evolution of deep learning tools and techniques has led to the development of deep learning-based approaches to multimodal sentiment analysis to address its challenges and constraints. This paper is a comprehensive comparative survey of sentiment analysis approaches, challenges, applications, and trends, with a special focus on deep learning-based multimodal sentiment analysis methods. Examining the limitations of the recent studies, describing possible future solutions and evaluating existing challenges are also taken into consideration and future direction of the methods are evaluated.},
  archive      = {J_AIR},
  author       = {Ghorbanali, Alireza and Sohrabi, Mohammad Karim},
  doi          = {10.1007/s10462-023-10555-8},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {1479-1512},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comprehensive survey on deep learning-based approaches for multimodal sentiment analysis},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Siamese object tracking for unmanned aerial vehicle: A
review and comprehensive analysis. <em>AIR</em>, <em>56</em>(1),
1417–1477. (<a
href="https://doi.org/10.1007/s10462-023-10558-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicle (UAV)-based visual object tracking has enabled a wide range of applications and attracted increasing attention in the field of artificial intelligence (AI) because of its versatility and effectiveness. As an emerging force in the revolutionary trend of deep learning, Siamese networks shine in UAV-based object tracking with their promising balance of accuracy, robustness, and speed. Thanks to the development of embedded processors and the gradual optimization of deep neural networks, Siamese trackers receive extensive research and realize preliminary combinations with UAVs. However, due to the UAV’s limited onboard computational resources and the complex real-world circumstances, aerial tracking with Siamese networks still faces severe obstacles in many aspects. To further explore the deployment of Siamese networks in UAV-based tracking, this work presents a comprehensive review of leading-edge Siamese trackers, along with an exhaustive UAV-specific analysis based on the evaluation using a typical UAV onboard processor. Then, the onboard tests are conducted to validate the feasibility and efficacy of representative Siamese trackers in real-world UAV deployment. Furthermore, to better promote the development of the tracking community, this work analyzes the limitations of existing Siamese trackers and conducts additional experiments represented by low-illumination evaluations. In the end, prospects for the development of Siamese tracking for UAV-based AI systems are deeply discussed. The unified framework of leading-edge Siamese trackers, i.e., code library, and the results of their experimental evaluations are available at https://github.com/vision4robotics/SiameseTracking4UAV .},
  archive      = {J_AIR},
  author       = {Fu, Changhong and Lu, Kunhan and Zheng, Guangze and Ye, Junjie and Cao, Ziang and Li, Bowen and Lu, Geng},
  doi          = {10.1007/s10462-023-10558-5},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {1417-1477},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Siamese object tracking for unmanned aerial vehicle: A review and comprehensive analysis},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cyberbullying detection and machine learning: A systematic
literature review. <em>AIR</em>, <em>56</em>(1), 1375–1416. (<a
href="https://doi.org/10.1007/s10462-023-10553-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise in research work focusing on detection of cyberbullying incidents on social media platforms particularly reflect how dire cyberbullying consequences are, regardless of age, gender or location. This paper examines scholarly publications (i.e., 2011–2022) on cyberbullying detection using machine learning through a systematic literature review approach. Specifically, articles were sought from six academic databases (Web of Science, ScienceDirect, IEEE Xplore, Association for Computing Machinery, Scopus, and Google Scholar), resulting in the identification of 4126 articles. A redundancy check followed by eligibility screening and quality assessment resulted in 68 articles included in this review. This review focused on three key aspects, namely, machine learning algorithms used to detect cyberbullying, features, and performance measures, and further supported with classification roles, language of study, data source and type of media. The findings are discussed, and research challenges and future directions are provided for researchers to explore.},
  archive      = {J_AIR},
  author       = {Balakrisnan, Vimala and Kaity, Mohammed},
  doi          = {10.1007/s10462-023-10553-w},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {1375-1416},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Cyberbullying detection and machine learning: A systematic literature review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gradient leakage attacks in federated learning.
<em>AIR</em>, <em>56</em>(1), 1337–1374. (<a
href="https://doi.org/10.1007/s10462-023-10550-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) improves the privacy of local training data by exchanging model updates (e.g., local gradients or updated parameters). Gradients and weights of the model have been presumed to be safe for delivery. Nevertheless, some studies have shown that gradient leakage attacks can reconstruct the input images at the pixel level, which belong to deep leakage. In addition, well understanding gradient leakage attacks are beneficial to model inversion attacks. Furthermore, gradient leakage attacks can be performed in a covert way, which does not hamper the training performance. It is significant to study gradient leakage attacks deeply. In this paper, a systematic literature review on gradient leakage attacks and privacy protection strategies. Through carefully screening, existing works about gradient leakage attacks can be categorized into three groups: (i) bias attacks, (ii) optimization-based attacks, and (iii) linear equation solver attacks. We propose one privacy attack system, i.e., single-sample reconstruction attack system (SSRAS). Furthermore, rank analysis index (RA-I) can be introduced to provide an overall estimate of the security of the neural network. In addition, we propose an Improved R-GAP Algorithm, this improved algorithm can carry out image reconstruction regardless of whether the label can be determined. Finally, experimental results show the superiority of the attack system over some other state-of-the-art attack algorithms.},
  archive      = {J_AIR},
  author       = {Gong, Haimei and Jiang, Liangjun and Liu, Xiaoyang and Wang, Yuanqi and Gastro, Omary and Wang, Lei and Zhang, Ke and Guo, Zhen},
  doi          = {10.1007/s10462-023-10550-z},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {1337-1374},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Gradient leakage attacks in federated learning},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tackling class imbalance in computer vision: A contemporary
review. <em>AIR</em>, <em>56</em>(1), 1279–1335. (<a
href="https://doi.org/10.1007/s10462-023-10557-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance is a key issue affecting the performance of computer vision applications such as medical image analysis, objection detection and recognition, image segmentation, scene understanding, and many others. Class imbalance refers to the situation when the number of samples in the majority classes outnumber the minority class populations. The model might then get biased towards the majority classes while neglecting the minority classes, adversely affecting the classification performance. In this paper, an extensive literature survey has been conducted to discuss in depth about the class imbalance issues affecting various classification tasks in computer vision. The study analyzes the performance of several contemporary machine learning algorithms such as chi-square support vector machine and gradient boosted decision trees, and deep learning models such as deep pre-trained convolutional networks, generative adversarial networks and vision transformers, for effective learning from imbalanced computer vision datasets. Most of these models either perform data-level manipulation (data augmentation) or cost-sensitive learning (loss functions) or a combination of the two. This survey also includes a summary of novel deep learning frameworks customized to mitigate the effect of class imbalance. It has included recent advancement and new developments in this field such as Explainable AI. The scrutiny of various popular and benchmark imbalanced datasets in computer vision and performance evaluation metrics are also included as a part of this study. Along with that it has emphasized on the research gaps in contemporary literature which would contribute towards future artificial vision models that can learn effectively from imbalanced datasets.},
  archive      = {J_AIR},
  author       = {Saini, Manisha and Susan, Seba},
  doi          = {10.1007/s10462-023-10557-6},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {1279-1335},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Tackling class imbalance in computer vision: A contemporary review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Current studies and applications of krill herd and
gravitational search algorithms in healthcare. <em>AIR</em>,
<em>56</em>(1), 1243–1277. (<a
href="https://doi.org/10.1007/s10462-023-10559-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nature-Inspired Computing or NIC for short is a relatively young field that tries to discover fresh methods of computing by researching how natural phenomena function to find solutions to complicated issues in many contexts. As a consequence of this, ground-breaking research has been conducted in a variety of domains, including synthetic immune functions, neural networks, intelligence of swarm, as well as computing of evolutionary. In the domains of biology, physics, engineering, economics, and management, NIC techniques are used. In real-world classification, optimization, forecasting, and clustering, as well as engineering and science issues, meta-heuristics algorithms are successful, efficient, and resilient. There are two active NIC patterns: the gravitational search algorithm and the Krill herd algorithm. The study on using the Krill Herd Algorithm (KH) and the Gravitational Search Algorithm (GSA) in medicine and healthcare is given a worldwide and historical review in this publication. Comprehensive surveys have been conducted on some other nature-inspired algorithms, including KH and GSA. The various versions of the KH and GSA algorithms and their applications in healthcare are thoroughly reviewed in the present article. Nonetheless, no survey research on KH and GSA in the healthcare field has been undertaken. As a result, this work conducts a thorough review of KH and GSA to assist researchers in using them in diverse domains or hybridizing them with other popular algorithms. It also provides an in-depth examination of the KH and GSA in terms of application, modification, and hybridization. It is important to note that the goal of the study is to offer a viewpoint on GSA with KH, particularly for academics interested in investigating the capabilities and performance of the algorithm in the healthcare and medical domains.},
  archive      = {J_AIR},
  author       = {Hamad, Rebwar Khalid and Rashid, Tarik A.},
  doi          = {10.1007/s10462-023-10559-4},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {1243-1277},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Current studies and applications of krill herd and gravitational search algorithms in healthcare},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Privacy-preserving deep learning in medical informatics:
Applications, challenges, and solutions. <em>AIR</em>, <em>56</em>(1),
1199–1241. (<a
href="https://doi.org/10.1007/s10462-023-10556-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning (DL) has already shown tremendous potential in designing intelligent clinical support systems in biomedicine. Data privacy plays a significant role while training and testing DL models, especially for sensitive data. Privacy-Preserving Deep Learning (PPDL) applications in Healthcare are rapidly growing as medical informatics deals with sensitive data. This work reviews the recent advances in PPDL techniques in Healthcare. It first analyzes the need of PPDL in healthcare informatics using a threat model and then discusses privacy-preserving computation techniques for secure data processing and evaluation. Next, it focuses on DL applications over Healthcare in three categories: (i) PPDL in the private cloud, (ii) PPDL in the public cloud, and (iii) privacy based on modifications in DL architectures. Next, we examine data privacy at different stages of DL deployment in Healthcare, including input, model, training, and output. We also provide a summary of the evaluation outcomes of the solutions reviewed. Additionally, we highlight the unique challenges in PPDL for Healthcare and offer suggestions for future research directions.},
  archive      = {J_AIR},
  author       = {Naresh, Vankamamidi S. and Thamarai, M. and Allavarpu, V. V. L. Divakar},
  doi          = {10.1007/s10462-023-10556-7},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {1199-1241},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Privacy-preserving deep learning in medical informatics: Applications, challenges, and solutions},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of long short term memory and its associated models
in sustainable wind energy predictive analytics. <em>AIR</em>,
<em>56</em>(1), 1149–1198. (<a
href="https://doi.org/10.1007/s10462-023-10554-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sustainable energy is the new normal towards saving the environment, thus resources generating sustainable green energy have gained global attention. Out of all the predominant sustainable energy genres, wind energy is one of the promising and growing solutions to improve efficiency towards sustainability. To expand the area of wind power generation and install more wind farms in future; accurate predictive analytics is mandatory. Due to uncertainty and stochastic nature of wind power time series parameters and outputs, enormous data driven; various machine learning and deep learning approaches have been proposed for the simulation and predictions for wind power predictive analytics. Many approaches have been working towards using Long Short Term Memory (LSTM) and its variants to improve accuracy in wind power predictions. With an aim of easing researchers and applications working in the field of wind power predictive analytics, this study strives to provide critical insights on usage LSTM and associated model in wind power predictions. This study explores at the root level; hence a survey is first made to understand and explore requirements and benefits of time series predictive analytics. Second, a generic exploration of all the different models and performance metrics used over different time series data is performed. Third, a thorough review on WP predictive analysis, based on LSTM as a whole or part of the model is presented. This will also include decomposition techniques, normalization methods, performance metrics, experimented datasets and dependent variable used for wind power predictive analytics. These approaches have been thoroughly seeking to improve the results; however certain challenges still persist due to variability and uncertain nature of wind parameters. Therefore, the major objective of presenting this paper is to learn (i) requirements and benefits of time series predictive analytics, (ii) state of art models and metrics used in time series predictive analytics, (iii) role of LSTM and associated models in wind power predictive analytics, (iv) different decomposition techniques, normalization methods, performance metrics, experimented datasets and predictive frequency used in wind power predictive analytics; and (v) challenges persisting in wind power predictive analytics and usage of LSTM.},
  archive      = {J_AIR},
  author       = {Garg, Sherry and Krishnamurthi, Rajalakshmi},
  doi          = {10.1007/s10462-023-10554-9},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {1149-1198},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of long short term memory and its associated models in sustainable wind energy predictive analytics},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hierarchical sparrow search algorithm to solve numerical
optimization and estimate parameters of carbon fiber drawing process.
<em>AIR</em>, <em>56</em>(1), 1113–1148. (<a
href="https://doi.org/10.1007/s10462-023-10549-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sparrow search algorithm (SSA) is an efficient swarm-intelligence-based algorithm and has been widely studied in recent years. Nevertheless, as with other swarm intelligence optimization approaches, the SSA is prone to fall into local solutions, which weakens the exploration ability. In order to cope with this problem, in this paper, a novel hierarchical SSA, named the HSSA, is proposed. Specifically, by introducing the virtual individual strategy in each iteration, each scrounger can obtain more effective guidance information in the developed HSSA, thus contributing to a thorough search in the entire problem space. On the other hand, the proposed hierarchical strategy is employed to realize the information interaction among individuals according to the division layers (including top, medium and bottom layers) with the purpose of enhancing the diversity of the original SSA. In addition, the life cycle mechanism is introduced in order to avoid the current scrounger individuals being trapped in local optima positions as much as possible, which can further improve the solution accuracy of the traditional SSA. The developed HSSA is verified on a series of benchmark functions (i.e., IEEE CEC2022) and the parameter optimization problem of the carbon fiber drawing process. The proposed HSSA is compared with three classes of existing swarm-intelligence-based approaches: (1) CLSSA, C-SSA, and CSSA as popular SSA-based methods; (2) BWO, HGS, GJO, and DBO as state-of-the-art optimization techniques; and (3) GWO, WOA, HHO, MPA, WSO, and POA as highly-cited swarm intelligence algorithms. Results demonstrate that the HSSA exhibits the best performance among twelve test functions and one practical application in terms of solving accuracy and convergence speed. Finally, the overall experimental results indicate that the developed HSSA is an effective method to deal with the defects of the basic SSA and can obtain satisfactory solutions for different optimization problems.},
  archive      = {J_AIR},
  author       = {Xue, Jiankai and Shen, Bo and Pan, Anqi},
  doi          = {10.1007/s10462-023-10549-6},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {1113-1148},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A hierarchical sparrow search algorithm to solve numerical optimization and estimate parameters of carbon fiber drawing process},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Single sample face recognition using deep learning: A
survey. <em>AIR</em>, <em>56</em>(1), 1063–1111. (<a
href="https://doi.org/10.1007/s10462-023-10551-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face recognition has become popular in the last few decades among researchers across the globe due to its applicability in several domains. This problem becomes more challenging when only a single training image is available and is popularly known as single sample face recognition (SSFR) problem. SSFR becomes even more complex when images are captured under varying illumination conditions, different poses, occlusion, and expression. Further, deep learning methods have shown performance at par with humans recently. Due to the emergence of deep learning methods in the last decade, it has been made possible to recognize faces with excellent accuracy even in a single sample scenario. In this paper, we present a comprehensive survey of SSFR using deep learning. We also propose a novel taxonomy and broadly divide these methods into three categories viz. virtual sample generation, feature-based, and hybrid methods. Performance comparison of these methods as reported in the literature has also been performed. Finally, we review publicly available databases used by the researchers and give some important future research directions which will help aspiring researchers in this fascinating area.},
  archive      = {J_AIR},
  author       = {Tomar, Vivek and Kumar, Nitin and Srivastava, Ayush Raj},
  doi          = {10.1007/s10462-023-10551-y},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {1063-1111},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Single sample face recognition using deep learning: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature subset selection for data and feature streams: A
review. <em>AIR</em>, <em>56</em>(1), 1011–1062. (<a
href="https://doi.org/10.1007/s10462-023-10546-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world problems are commonly characterized by a high feature dimensionality, which hinders the modelling and descriptive analysis of the data. However, some of these data may be irrelevant or redundant for the learning process. Different approaches can be used to reduce this information, improving not only the speed of building models but also their performance and interpretability. In this review, we focus on feature subset selection (FSS) techniques, which select a subset of the original feature set without making any transformation on the attributes. Traditional batch FSS algorithms may not be adequate to efficiently handle large volumes of data, either because memory problems arise or data are received in a sequential manner. Thus, this article aims to survey the state of the art of incremental FSS algorithms, which can perform more efficiently under these circumstances. Different strategies are described, such as incrementally updating feature weights, applying information theory or using rough set-based FSS, as well as multiple supervised and unsupervised learning tasks where the application of FSS is interesting.},
  archive      = {J_AIR},
  author       = {Villa-Blanco, Carlos and Bielza, Concha and Larrañaga, Pedro},
  doi          = {10.1007/s10462-023-10546-9},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {1011-1062},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Feature subset selection for data and feature streams: A review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid human–AI tool for scientometric analysis.
<em>AIR</em>, <em>56</em>(1), 983–1010. (<a
href="https://doi.org/10.1007/s10462-023-10548-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solid research depends on systematic, verifiable and repeatable scientometric analysis. However, scientometric analysis is difficult in the current research landscape characterized by the increasing number of publications per year, intersections between research domains, and the diversity of stakeholders involved in research projects. To address this problem, we propose SciCrowd, a hybrid human–AI mixed-initiative system, which supports the collaboration between Artificial Intelligence services and crowdsourcing services. This work discusses the design and evaluation of SciCrowd. The evaluation is focused on attitudes, concerns and intentions towards use. This study contributes a nuanced understanding of the interplay between algorithmic and human tasks in the process of conducting scientometric analysis.},
  archive      = {J_AIR},
  author       = {Correia, António and Grover, Andrea and Jameel, Shoaib and Schneider, Daniel and Antunes, Pedro and Fonseca, Benjamim},
  doi          = {10.1007/s10462-023-10548-7},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {983-1010},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A hybrid human–AI tool for scientometric analysis},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Manifold transfer subspace learning based on double relaxed
discriminative regression. <em>AIR</em>, <em>56</em>(1), 959–981. (<a
href="https://doi.org/10.1007/s10462-023-10547-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By leveraging the labeled data samples of the source domain to learn the unlabeled data samples of the target domain, unsupervised domain adaptation (DA) has achieved promising performance. However, it is still a vital problem for unsupervised domain adaptation to deal with cross-domain distribution mismatch. Therefore, we present a new model framework for cross-domain image classification in the paper, which is termed manifold transfer subspace learning based on double relaxed discriminative regression (MTSL-DRDR). First, the global geometry information of the samples from the source and target domain can be preserved by utilizing the low-rank constraint. Second, the two transformation projections are employed to project both domains to a unified subspace, in which each data sample of the target domain can be represented by some samples from the source domain with the sparse and low-rank coefficient matrix. Third, the local structure information of the data points with the same semantics from the different domains is preserved by means of the adaptive weight graph based on the low-rank coefficient matrix. Last, for fully use the discriminative information of data from the source domain, the discriminant information of the source domain based on intra-class and inter-class graphs is encoded to the target domain. Our MTSL-DRDR algorithm is evaluated on challenging benchmark datasets, and a large number of experiment results show the superiority of the proposed method.},
  archive      = {J_AIR},
  author       = {Liu, Zhonghua and Zhu, Fa and Zhang, Kaibing and Lai, Zhihui and Huo, Hua},
  doi          = {10.1007/s10462-023-10547-8},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {959-981},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Manifold transfer subspace learning based on double relaxed discriminative regression},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combining deep subspace feature representation based
IKPCANet and jointly constraint multi-dictionary learning for facial
expression recognition. <em>AIR</em>, <em>56</em>(1), 937–958. (<a
href="https://doi.org/10.1007/s10462-023-10541-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The limitation of the small-scale expression samples generally causes the performance degradation for facial expression recognition-based methods. Also, the correlation between different expression is always ignored when performing feature extraction process. Given above, we propose a novel approach that develops multi-class differentiation feature representation guided joint dictionary learning for FER. The proposed approach mainly includes two steps: firstly, we construct multi-class differentiation feature dictionaries corresponding to different expressions of training samples, aiming to enlarge inter-expression distance to mitigate the problem of nonlinear distribution in training samples. Secondly, we joint learn the multiple feature dictionaries by optimizing the resolutions of each feature dictionary, aiming to establish the strong relationship and enhance the representation ability among multiple feature dictionaries. To sum up, the proposed approach has more discriminative ability from the representation perspective. Comprehensive experiments carried out using three public datasets, including JAFFE, CK+ , and KDEF datasets, demonstrate that the proposed approach has strong performance for small-scale samples compared to several state-of-the-art methods.},
  archive      = {J_AIR},
  author       = {Sun, Zhe and Bai, Jiatong and Wang, Panpan and Huang, Jiaxue},
  doi          = {10.1007/s10462-023-10541-0},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {937-958},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Combining deep subspace feature representation based IKPCANet and jointly constraint multi-dictionary learning for facial expression recognition},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Crime linkage and psychological profiling of offenders under
intuitionistic fuzzy environment using a novel resemblance measure.
<em>AIR</em>, <em>56</em>(1), 893–936. (<a
href="https://doi.org/10.1007/s10462-023-10538-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crime is a significant issue in society, with the causes of crime needing more attention and action from social, governmental, and judicial entities. Investigating crimes can be challenging due to uncertainties and unreliable evidence. Crime linkage helps investigators identify and solve crimes committed by the same individuals or groups. Fuzzy sets and intuitionistic fuzzy sets have been helpful in decision-making problems related to crime linkage due to the uncertainty involved. Similarity measures are essential in decision-making problems, but the existing measures must be revised when dealing with three or more intuitionistic fuzzy sets. The proposed resemblance measure based on intuitionistic fuzzy sets can find similarities between more than two sets and be used in the crime linkage. The proposed measure’s superiority is demonstrated through examples and applied to crime linkage through case studies. A methodology for the psychological profiling of offenders is also presented through case studies. These proposed methods can help law enforcement solve decision-making problems related to crime linkage and psychological profiling.},
  archive      = {J_AIR},
  author       = {Dutta, Palash and Banik, Abhilash Kangsha},
  doi          = {10.1007/s10462-023-10538-9},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {893-936},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Crime linkage and psychological profiling of offenders under intuitionistic fuzzy environment using a novel resemblance measure},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Radiomics and artificial intelligence in breast imaging: A
survey. <em>AIR</em>, <em>56</em>(1), 857–892. (<a
href="https://doi.org/10.1007/s10462-023-10543-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical imaging techniques, such as mammography, ultrasound and magnetic resonance imaging, plays an integral role in the detection and characterization of breast cancer. Although computers are believed to gain an important role in the assessment of medical images for breast evaluation for at least two decades, their impact on performance has not lived up to expectations yet. With the continuous and rapid development of computer science, artificial intelligence (AI) approaches, like machine learning and deep learning, have been introduced for the analysis of medical images. Because of the remarkable advances in data extraction and analysis in medical imaging compared to conventional feature-based techniques, AI has reignited the interest in automated breast image interpretation. Extensive research is conducted on accurate detection and classification of breast lesions, and more specifically, the predictive and prognostic features of breast cancer by radiomics. Radiomics exploits the fact that image data is nowadays numerical and can also be used to generate quantitative biomarkers. In this comprehensive review, we cover the progress, application and challenge of radiomics and AI in breast cancer diagnosis in recent years, as well as the impact and significance of AI on future breast cancer research.},
  archive      = {J_AIR},
  author       = {Zhang, Tianyu and Tan, Tao and Samperna, Riccardo and Li, Zhang and Gao, Yuan and Wang, Xin and Han, Luyi and Yu, Qifeng and Beets-Tan, Regina G. H. and Mann, Ritse M.},
  doi          = {10.1007/s10462-023-10543-y},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {857-892},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Radiomics and artificial intelligence in breast imaging: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Long-tailed image recognition through balancing discriminant
quality. <em>AIR</em>, <em>56</em>(1), 833–856. (<a
href="https://doi.org/10.1007/s10462-023-10544-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-tailed image recognition is a challenging task in real scenes with large-scale data. Popular strategies, such as loss reweighting and data resampling, aim to reduce the model bias toward head classes. Specifically, different loss reweighting approaches explore various endogenous or exogenous measures. In this paper, we study a new endogenous measure called discriminant quality (DQ) by considering validation accuracy and discriminant uncertainty. DQ takes advantage of continuous information over a period of time. It is more robust than instantaneous information because of the mitigation of measuring instability caused by random perturbations during training. Additionally, the weight of each class is automatically rebalanced based on DQ. Consequently, the class weight supports the design of a dynamic updating strategy for the significance of the DQ difference. Experiments on MNIST-LT, CIFAR-100-LT, ImageNet-LT, and Places-LT demonstrated the superiority of DQ over state-of-the-art ones in terms of prediction accuracy.},
  archive      = {J_AIR},
  author       = {Wu, Yan-Xue and Min, Fan and Zhang, Ben-Wen and Wang, Xian-Jie},
  doi          = {10.1007/s10462-023-10544-x},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {833-856},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Long-tailed image recognition through balancing discriminant quality},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved TOPSIS method for multi-criteria decision making
based on hesitant fuzzy β neighborhood. <em>AIR</em>, <em>56</em>(1),
793–831. (<a href="https://doi.org/10.1007/s10462-023-10510-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-criteria Decision Making (MCDM) plays a very vital role in many application fields. There are many classical methods to solve the MCDM problems if the available information is crisp. However, the uncertainty and ambiguity inherent in the MCDM often makes these methods unsuitable for solving this kind of problem. Aims at the failures of TOPSIS method that can not rank the alternatives completely in a Hesitant Fuzzy β-Covering Approximation Space (HFβCAS), we develop an improved TOPSIS method. First, we define two pairs of hesitant fuzzy relationship based on hesitant fuzzy β-neighborhood, and construct the corresponding hesitant fuzzy covering rough set models; further we discuss the properties and relationships between the models. Second, we introduce a new comprehensive weight determination method by using the precision degree of hesitant fuzzy covering rough set and the maximizing deviation method. Third, we construct a γ-βCHF-TOPSIS method to MCDM which generalizes the TOPSIS method in an HFβCAS. Finally, two real decision-making problems are used to illustrate the concrete implementation process of γ-βCHF-TOPSIS method, and demonstrate its effectiveness and reasonability.},
  archive      = {J_AIR},
  author       = {Jin, Chenxia and Mi, Jusheng and Li, Fachao and Liang, Meishe},
  doi          = {10.1007/s10462-023-10510-7},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {793-831},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An improved TOPSIS method for multi-criteria decision making based on hesitant fuzzy β neighborhood},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic detection of heart valve disorders using
teager–kaiser energy operator, rational-dilation wavelet transform and
convolutional neural networks with PCG signals. <em>AIR</em>,
<em>56</em>(1), 781–806. (<a
href="https://doi.org/10.1007/s10462-022-10184-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The heart sound signals (phonocardiogram, PCG) have been for decades a fundamental diagnostic tool to detect a potential cardiovascular pathology in clinical practice. Due to the lack of proper training, the medical practitioners may sometimes overlook some of the vital information either during the auscultation of the heart sound or visual inspection of the PCG signal. Therefore the need for an automated and accurate anomaly detection method based on PCG becomes urgent. The aim of this work is to design a reliable algorithm for the automatic detection of heart valve disorders (HVDs) without any segmentation of the heart sound signals. Teager–Kaiser energy operator (TKEO) and rational dilation wavelet transform (RDWT) are utilized to extract representative features in order to detect abnormal patterns in PCG signals with the employment of deep learning model. First, TKEO is used to extract the instantaneous energy of the source that generates the PCG signal rather than the energy of the signal itself. Then, RDWT is employed to decompose the instantaneous energy of the PCG signal into different sub-bands. The oscillatory characteristics of PCG has been retained in these sub-bands, which are served as discriminant features. Third, these features are fed to one-dimensional (1D) convolutional neural networks (CNN) for classification. Finally, experiments including two types of classification named binary classification (normal vs. abnormal) and multi-class classification (normal vs. aortic stenosis vs. mitral regurgitation vs. mitral stenosis vs. mitral valve prolapse), are carried out on a well-known and publicly available PCG database to verify the effectiveness of the proposed method. The overall average accuracy for binary (5 cases), four-class and five-class classification is reported to be 100\%, 99.00\%, 99.75\%, 99.75\%, 99.60\%, 98.87\% and 98.10\%, respectively. The proposed method has obtained superior accuracy in comparison to most of the state-of-the-art approaches using the same database. It can serve as a potential diagnostic tool for the automated detection of HVDs in routine auscultation examination.},
  archive      = {J_AIR},
  author       = {Zeng, Wei and Su, Bo and Yuan, Chengzhi and Chen, Yang},
  doi          = {10.1007/s10462-022-10184-7},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {781-806},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Automatic detection of heart valve disorders using Teager–Kaiser energy operator, rational-dilation wavelet transform and convolutional neural networks with PCG signals},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-source deep transfer learning algorithm based on
feature alignment. <em>AIR</em>, <em>56</em>(1), 769–791. (<a
href="https://doi.org/10.1007/s10462-023-10545-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the deepening of transfer learning research, researchers are no longer satisfied with the classification of knowledge in a single field but hope that the classification of knowledge in multiple fields can be realized, so as to simulate the behavior of human “analogy” and enable the machine to draw inferences”. However, the feature realization of multiple source domains often differs greatly, which brings a challenge to the traditional transfer learning scheme. In this paper, a multi-source deep transfer learning algorithm MDTLFA based on feature alignment is proposed to solve the problem that the data from multiple source domains often has different feature realizations. MDTLFA first reduces the difference in the marginal probability distribution between fields at the sample level by means of the maximum mean deviation MMD. Then, the feature alignment strategy is used at the feature level to further reduce the difference in the marginal probability distribution between the fields and maintain the unique data manifold structure while sharing similar features. On this basis, the conditional probability adaptation CPDA was constructed to reduce the difference in conditional probability distribution between domains and enhance the portability of source domain features. The CPTCNN model was constructed based on a convolutional neural network using CPDA. Finally, the CPTCNN model is trained in the subspace to obtain a classifier set, and the designed strategy is used to select the classifier with a small classification error in the target domain to form MDTLFA. Multiple source domains, marginal probability adaptation at the sample level and feature level, and the CPTCNN model constructed based on the minimization of conditional probability differences effectively improve the performance of data features in multiple domains, thus improving the classification effect. The experimental results on several real data sets show that the MDTLFA algorithm is effective and has some advantages compared with the advanced benchmark algorithm.},
  archive      = {J_AIR},
  author       = {Ding, Changhong and Gao, Peng and Li, Jingmei and Wu, Weifei},
  doi          = {10.1007/s10462-023-10545-w},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {769-791},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Multi-source deep transfer learning algorithm based on feature alignment},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). State of the art: A review of sentiment analysis based on
sequential transfer learning. <em>AIR</em>, <em>56</em>(1), 749–780. (<a
href="https://doi.org/10.1007/s10462-022-10183-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, sequential transfer learning emerged as a modern technique for applying the “pretrain then fine-tune” paradigm to leverage existing knowledge to improve the performance of various downstream NLP tasks, with no exception of sentiment analysis. Previous pieces of literature mostly focus on reviewing the application of various deep learning models to sentiment analysis. However, supervised deep learning methods are known to be data hungry, but insufficient training data in practice may cause the application to be impractical. To this end, sequential transfer learning provided a solution to alleviate the training bottleneck issues of data scarcity and facilitate sentiment analysis application. This study aims to discuss the background of sequential transfer learning, review the evolution of pretrained models, extend the literature with the application of sequential transfer learning to different sentiment analysis tasks (aspect-based sentiment analysis, multimodal sentiment analysis, sarcasm detection, cross-domain sentiment classification, multilingual sentiment analysis, emotion detection) and suggest future research directions on model compression, effective knowledge adaptation techniques, neutrality detection and ambivalence handling tasks.},
  archive      = {J_AIR},
  author       = {Chan, Jireh Yi-Le and Bea, Khean Thye and Leow, Steven Mun Hong and Phoong, Seuk Wai and Cheng, Wai Khuen},
  doi          = {10.1007/s10462-022-10183-8},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {749-780},
  shortjournal = {Artif. Intell. Rev.},
  title        = {State of the art: A review of sentiment analysis based on sequential transfer learning},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). An improved generalized normal distribution optimization
and its applications in numerical problems and engineering design
problems. <em>AIR</em>, <em>56</em>(1), 685–747. (<a
href="https://doi.org/10.1007/s10462-022-10182-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized normal distribution optimization (GNDO) inspired by the theory of normal distribution is a recently developed metaheuristic method for global optimization problems. This work presents a novel variant of GNDO, which is called elite-driven generalized normal distribution optimization (EDGNDO). EDGNDO enhances the global search ability of GNDO by the designed search mechanism consisting of three local search operators and three global search operators that are based on two built archives used to save elite individuals. Note that, EDGNDO only needs population size and termination criteria for optimization, which can distinguish it over the most reported metaheuristic methods. The performance of EDGNDO is investigated by the well-known CEC 2017 test suite including three unimodal functions and 27 multimodal functions. Experimental results demenstrate that EDGNDO is obviously better than GNDO and the other five powerful algorithms in terms of solution quality and computational efficiency. In addition, EDGNDO is also used for solving four challenging constrained engineering design problems. Experimental results support the superiority of EDGNDO in solving the four problems. The superiority of EDGNDO in solving complex optimization problems is proven. The source code can be loaded from https://github.com/jsuzyy/EDGNDO .},
  archive      = {J_AIR},
  author       = {Zhang, Yiying},
  doi          = {10.1007/s10462-022-10182-9},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {685-747},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An improved generalized normal distribution optimization and its applications in numerical problems and engineering design problems},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A critical review on applications of artificial intelligence
in manufacturing. <em>AIR</em>, <em>56</em>(1), 661–768. (<a
href="https://doi.org/10.1007/s10462-023-10535-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fourth industrial revolution, Industry 4.0, has brought internet, artificial intelligence (AI), and machine learning (ML) concepts into manufacturing. There is an  immediate need to understand the capabilities of AI and ML and how they can be implemented in manufacturing domains. This article presents a detailed survey of AI algorithms and their use in manufacturing. The article treats casting, forming, machining, welding, additive manufacturing (AM), and supply chain management (SCM) as six manufacturing verticals. The horizontals in each vertical are the descriptions including, the evolution of each process from the mechanization era to the present-day scenario, and developments in the automation of processes by processing signal and image information and applying ML and AI algorithms. The evolution of robotics and cloud-based technologies is also discussed. The critical review gives a realistic view of manufacturing automation and benefits of AI. Further, the article discusses several manufacturing use cases where AI and ML algorithms are deployed. As a future research direction, human-like intelligence is introduced highlighting the necessity of cognitive skills in manufacturing. In a nutshell, a reader can logically explain why, when, and how far AI will define complete manufacturing.},
  archive      = {J_AIR},
  author       = {Mypati, Omkar and Mukherjee, Avishek and Mishra, Debasish and Pal, Surjya Kanta and Chakrabarti, Partha Pratim and Pal, Arpan},
  doi          = {10.1007/s10462-023-10535-y},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {661-768},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A critical review on applications of artificial intelligence in manufacturing},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computational intelligence paradigms for UWB antennas: A
comprehensive review of analysis, synthesis and optimization.
<em>AIR</em>, <em>56</em>(1), 655–684. (<a
href="https://doi.org/10.1007/s10462-022-10181-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technological advancement in wireless communication systems has spurred a rapid growth in ultra-wideband (UWB) technology over the last decade. One of the key components of UWB system is the antenna. For modeling the antenna system, several analytical and numerical techniques are available; however, they are extensive computational effort. Computational intelligence (CI) techniques have gained enormous importance in the microwave community recently due to their ability to bypass the tedious and repeated analysis of conventional techniques. Over the last decade, notable research has been carried out on different CI techniques for modeling UWB antennas. In this article, a comprehensive investigation of CI modeling for the analysis, synthesis, and optimization of UWB antennas is presented. Widely used CI techniques in the open literature for UWB antenna modeling are artificial neural network, genetic algorithm, particle swarm optimization, and hybrid CI techniques. Therefore, the published articles are classified into these four CI techniques for an effective survey article. The objectives of this review article are to highlight the CI techniques adopted for modeling of the UWB antennas and to point out the open problems for future researchers. To the best of the author’s knowledge, such a review article has not been presented in the open literature.},
  archive      = {J_AIR},
  author       = {Sarkar, Debanjali and Khan, Taimoor and Talukdar, Fazal A. and Antar, Yahia M. M.},
  doi          = {10.1007/s10462-022-10181-w},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {655-684},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Computational intelligence paradigms for UWB antennas: A comprehensive review of analysis, synthesis and optimization},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Correction to: An approach to MCGDM based on
multi-granulation pythagorean fuzzy rough set over two universes and its
application to medical decision problem. <em>AIR</em>, <em>56</em>(1),
653. (<a href="https://doi.org/10.1007/s10462-022-10180-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIR},
  author       = {Sun, Bingzhen and Tong, Sirong and Ma, Weimin and Jiang, Chao},
  doi          = {10.1007/s10462-022-10180-x},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {653},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Correction to: An approach to MCGDM based on multi-granulation pythagorean fuzzy rough set over two universes and its application to medical decision problem},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Segmentation of prostate ultrasound images: The state of the
art and the future directions of segmentation algorithms. <em>AIR</em>,
<em>56</em>(1), 615–651. (<a
href="https://doi.org/10.1007/s10462-022-10179-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, prostate cancer has surpassed lung cancer as the most common type of cancer, segmentation of prostate ultrasound images is a critical step in the detection and planning treatment of prostate cancer. However, both ultrasound imaging characteristics and the physiology of the prostate make it difficult to determine the prostate boundaries in ultrasound images. In this paper, we provide a systematic review of advances in the field of ultrasound prostate image segmentation. In particular, three categories of algorithms are reviewed and compared, including edge-based segmentation, region-based segmentation, and those based on specific theoretical models. To understand the state of the art of different segmentations of the prostate ultrasound images, we conduct a literature analysis and a series of comparisons between different algorithms. The features and limitations of each category of segmentation algorithms are further discussed. Finally, we identified promising research directions in advancing the segmentation algorithms for the processing of ultrasound prostate images.},
  archive      = {J_AIR},
  author       = {Jiang, Jingang and Guo, Yafeng and Bi, Zhuming and Huang, Zhiyuan and Yu, Guang and Wang, Jinke},
  doi          = {10.1007/s10462-022-10179-4},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {615-651},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Segmentation of prostate ultrasound images: The state of the art and the future directions of segmentation algorithms},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Valid prediction intervals for regression problems.
<em>AIR</em>, <em>56</em>(1), 577–613. (<a
href="https://doi.org/10.1007/s10462-022-10178-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last few decades, various methods have been proposed for estimating prediction intervals in regression settings, including Bayesian methods, ensemble methods, direct interval estimation methods and conformal prediction methods. An important issue is the validity and calibration of these methods: the generated prediction intervals should have a predefined coverage level, without being overly conservative. So far, no study has analysed this issue whilst simultaneously considering these four classes of methods. In this independent comparative study, we review the above four classes of methods from a conceptual and experimental point of view in the i.i.d. setting. Results on benchmark data sets from various domains highlight large fluctuations in performance from one data set to another. These observations can be attributed to the violation of certain assumptions that are inherent to some classes of methods. We illustrate how conformal prediction can be used as a general calibration procedure for methods that deliver poor results without a calibration step.},
  archive      = {J_AIR},
  author       = {Dewolf, Nicolas and Baets, Bernard De and Waegeman, Willem},
  doi          = {10.1007/s10462-022-10178-5},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {577-613},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Valid prediction intervals for regression problems},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Systematic literature review on identifying influencers in
social networks. <em>AIR</em>, <em>56</em>(1), 567–660. (<a
href="https://doi.org/10.1007/s10462-023-10515-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the ever-increasing size and complexity of social networks, developing methods to extract meaningful knowledge and information from users’ vast amounts of data is crucial. Identifying influencers on social networks is one of the essential investigations on these networks and has many applications in marketing, advertising, sociology, behavior analysis, and security issues. In recent years, many studies have been conducted on analyzing and identifying influencers on social networks. Therefore, in this article, a Systematic Literature Review (SLR) has been performed on previous studies about the methods of identifying influencers. To this end, we review the definitions of influencers, the datasets used for evaluation purposes, the methods of identifying influencers, and the evaluation techniques. Furthermore, the quality assessment of the recently published papers also has been performed in different aspects to find whether research about identifying influencers has progressed. Finally, trends and opportunities for future studies about influencers’ identification are presented. The result of this SLR shows that the quantity and quality of articles in the field of identifying influencers in social networks are growing and progressive, which shows this field is a dynamic and active area of research.},
  archive      = {J_AIR},
  author       = {Seyfosadat, Seyed Farid and Ravanmehr, Reza},
  doi          = {10.1007/s10462-023-10515-2},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {567-660},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Systematic literature review on identifying influencers in social networks},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A trilevel analysis of uncertainty measuresin
partition-based granular computing. <em>AIR</em>, <em>56</em>(1),
533–575. (<a href="https://doi.org/10.1007/s10462-022-10177-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty measure is one of the most significant concepts and fundamental issues in granular computing. Nowadays, there have been extensive studies on various uncertainty measures for quantifying diverse properties and associations of granules and granular structures. However, there is a lack of a systematic study for uncertain measures. Based on a trilevel thinking framework, this paper presents a systematic review and analysis of uncertainty measures used in partition-based models of granular computing. At an object level, a granule level and a granular structure level, we categorize uncertainty measures for describing the properties and the associations of objects, granules, and partitions respectively. Moreover, we illustrate how to construct an uncertainty measure at a higher level from a lower level. At last, we discuss several potential directions to design other new uncertainty measures for partition-based granular computing.},
  archive      = {J_AIR},
  author       = {Wang, Baoli and Liang, Jiye and Yao, Yiyu},
  doi          = {10.1007/s10462-022-10177-6},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {533-575},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A trilevel analysis of uncertainty measuresin partition-based granular computing},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Battling voice spoofing: A review, comparative analysis, and
generalizability evaluation of state-of-the-art voice spoofing counter
measures. <em>AIR</em>, <em>56</em>(1), 513–566. (<a
href="https://doi.org/10.1007/s10462-023-10539-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of automated speaker verification (ASV) systems comes an equal and opposite development: malicious actors may seek to use voice spoofing attacks to fool those same systems. Various counter measures have been proposed to detect these spoofing attacks, but current offerings in this arena fall short of a unified and generalized approach applicable in real-world scenarios. For this reason, defensive measures for ASV systems produced in the last 6-7 years need to be classified, and qualitative and quantitative comparisons of state-of-the-art (SOTA) counter measures should be performed to assess the effectiveness of these systems against real-world attacks. Hence, in this work, we conduct a review of the literature on spoofing detection using hand-crafted features, deep learning, and end-to-end spoofing countermeasure solutions to detect logical access attacks, such as speech synthesis and voice conversion, and physical access attacks, i.e., replay attacks. Additionally, we review integrated and unified solutions to voice spoofing evaluation and speaker verification, and adversarial and anti-forensic attacks on both voice counter measures and ASV systems. In an extensive experimental analysis, the limitations and challenges of existing spoofing counter measures are presented, the performance of these counter measures on several datasets is reported, and cross-corpus evaluations are performed, something that is nearly absent in the existing literature, in order to assess the generalizability of existing solutions. For the experiments, we employ the ASVspoof2019, ASVspoof2021, and VSDC datasets along with GMM, SVM, CNN, and CNN-GRU classifiers. For reproducibility of the results, the code of the testbed can be found at our GitHub Repository ( https://github.com/smileslab/Comparative-Analysis-Voice-Spoofing ).},
  archive      = {J_AIR},
  author       = {Khan, Awais and Malik, Khalid Mahmood and Ryan, James and Saravanan, Mikul},
  doi          = {10.1007/s10462-023-10539-8},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {513-566},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Battling voice spoofing: A review, comparative analysis, and generalizability evaluation of state-of-the-art voice spoofing counter measures},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AO-HRCNN: Archimedes optimization and hybrid region-based
convolutional neural network for detection and classification of
diabetic retinopathy. <em>AIR</em>, <em>56</em>(1), 483–511. (<a
href="https://doi.org/10.1007/s10462-023-10516-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic Retinopathy (DR) primarily affects a set of lesions in the eyes, causing retinal degeneration and loss of vision. The DR features serve as a crucial component for ophthalmologists to diagnose DR at an earlier stage. This paper presents an automatic DR screening tool using a hybrid GAN-RCNN architecture formulated to categorize and identify different DR grades from the fundus images captured at various resolutions. The hybrid GAN-RCNN architecture is formulated by replacing the discriminator in the GAN with the RCNN classifier. The RCNN model can handle the complex inter-class and intra-class variations present in the fundus retina images and classify them into different classes such as mild, moderate, severe, and nonproliferative DR. The RCNN model not only extracts the pixels present in the fundus image but also focuses on the significant relationship that exists between different DR classes. The Archimedes optimization Algorithm (AOA) is used to optimize the different GAN and RCNN hyperparameters. When compared to the existing techniques the proposed model offers an accuracy of 99\%, 98.5\%, and 99.4\% in the APTOS, Kaggle, and Messidor datasets which is comparatively high. The experimental outcome reveals that the introduced model serves as a concrete baseline for the diagnosis and treatment of DR patients.},
  archive      = {J_AIR},
  author       = {Krishnamoorthy, Sujatha and Weifeng, yu and Luo, Jin and Kadry, Seifedine},
  doi          = {10.1007/s10462-023-10516-1},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {483-511},
  shortjournal = {Artif. Intell. Rev.},
  title        = {AO-HRCNN: Archimedes optimization and hybrid region-based convolutional neural network for detection and classification of diabetic retinopathy},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning for video object segmentation: A review.
<em>AIR</em>, <em>56</em>(1), 457–531. (<a
href="https://doi.org/10.1007/s10462-022-10176-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the fundamental problems in the field of video understanding, video object segmentation aims at segmenting objects of interest throughout the given video sequence. Recently, with the advancements of deep learning techniques, deep neural networks have shown outstanding performance improvements in many computer vision applications, with video object segmentation being one of the most advocated and intensively investigated. In this paper, we present a systematic review of the deep learning-based video segmentation literature, highlighting the pros and cons of each category of approaches. Concretely, we start by introducing the definition, background concepts and basic ideas of algorithms in this field. Subsequently, we summarise the datasets for training and testing a video object segmentation algorithm, as well as common challenges and evaluation metrics. Next, previous works are grouped and reviewed based on how they extract and use spatial and temporal features, where their architectures, contributions and the differences among each other are elaborated. At last, the quantitative and qualitative results of several representative methods on a dataset with many remaining challenges are provided and analysed, followed by further discussions on future research directions. This article is expected to serve as a tutorial and source of reference for learners intended to quickly grasp the current progress in this research area and practitioners interested in applying the video object segmentation methods to their problems. A public website is built to collect and track the related works in this field: https://github.com/gaomingqi/VOS-Review .},
  archive      = {J_AIR},
  author       = {Gao, Mingqi and Zheng, Feng and Yu, James J. Q. and Shan, Caifeng and Ding, Guiguang and Han, Jungong},
  doi          = {10.1007/s10462-022-10176-7},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {457-531},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep learning for video object segmentation: A review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The role of politeness in human–machine interactions: A
systematic literature review and future perspectives. <em>AIR</em>,
<em>56</em>(1), 445–482. (<a
href="https://doi.org/10.1007/s10462-023-10540-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing prevalence of interactions between humans and machines, coupled with the rapid development of intelligent and human-like features in technology, necessitates considering the potential implications that an increasingly inter-personal interaction style might have on human behavior. Particularly, since human–human interactions are fundamentally affected by politeness rules, several researchers are investigating if such social norms have some implications also within human–machine interactions. This paper reviews scientific works dealing with politeness issues within human–machine interactions by considering a variety of artificial intelligence systems, such as smart devices, robots, digital assistants, and self-driving cars. This paper aims to analyze scientific results to answer the questions of why technological devices should behave politely toward humans, but above all, why human beings should be polite toward a technological device. As a result of the analysis, this paper wants to outline future research directions for the design of more effective, socially competent, acceptable, and trustworthy intelligent systems.},
  archive      = {J_AIR},
  author       = {Ribino, Patrizia},
  doi          = {10.1007/s10462-023-10540-1},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {445-482},
  shortjournal = {Artif. Intell. Rev.},
  title        = {The role of politeness in human–machine interactions: A systematic literature review and future perspectives},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A probabilistic linguistic and dual trust network-based user
collaborative filtering model. <em>AIR</em>, <em>56</em>(1), 429–455.
(<a href="https://doi.org/10.1007/s10462-022-10175-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation models for network information that are generally based on user ratings fail to utilize user online behaviours such as reviews and likes, which indicate users’ opinions, attitudes, and emotions. To sufficiently represent user preferences and further enhance recommendation accuracy, a probabilistic linguistic and dual trust network-based user collaborative filtering (PLDTN-UCF) model is proposed in this paper. To reflect the uncertainty of user ratings, an easy-to-use function is proposed to transform the personalized semantics of online reviews into a probability distribution that corresponds to user ratings and construct a probabilistic linguistic rating matrix. Then, the calculation approach of traditional user ratings-based trust network is improved by integrating probabilities to represent the fuzziness of trust. Furthermore, a dual trust network is constructed to represent multi-source interpersonal trust based the on an online behaviours-based trust network and probabilistic linguistic rating matrix-based trust network. Finally, the proposed model is compared to state-of-the-art models using the Douban movie dataset to assess its performance.},
  archive      = {J_AIR},
  author       = {Chen, Sichao and Zhang, Chonghui and Zeng, Shouzhen and Wang, Yongheng and Su, Weihua},
  doi          = {10.1007/s10462-022-10175-8},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {429-455},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A probabilistic linguistic and dual trust network-based user collaborative filtering model},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SS-SSAN: A self-supervised subspace attentional network for
multi-modal medical image fusion. <em>AIR</em>, <em>56</em>(1), 421–443.
(<a href="https://doi.org/10.1007/s10462-023-10529-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal medical image fusion (MMIF) is used to merge multiple modes of medical images for better imaging quality and more comprehensive information, such that enhancing the reliability of clinical diagnosis. Since different types of medical images have different imaging mechanisms and focus on different pathological tissues, how to accurately fuse the information from various medical images has become an obstacle in image fusion research. In this paper, we propose a self-supervised subspace attentional framework for multi-modal image fusion, which is constructed by two sub-networks, i.e., the feature extract network and the feature fusion network. We implement a self-supervised strategy that facilitates the framework adaptively extracts the features of source images with the reconstruction of the fused image. Specifically, we adopt a subspace attentional Siamese Weighted Auto-Encoder as a feature extractor to extract the source image features including local and global features at first. Then, the extracted features are given into a weighted fusion decoding network to reconstruct the fused result, and the shallow features from the extractor are used to assist reconstruct the fused image. Finally, the feature extractor adaptively extracts the optimal features according to the fused results by simultaneously training the two sub-networks. Furthermore, to achieve better fusion results, we design a novel weight estimation in the weighted fidelity loss that measures the importance of each pixel by calculating a mixture of salient features and local contrast features of the image. Experiments demonstrate that our method gives the best results compared with other state-of-the-art fusion approaches.},
  archive      = {J_AIR},
  author       = {Zhang, Ying and Nie, Rencan and Cao, Jinde and Ma, Chaozhen and Wang, Chengchao},
  doi          = {10.1007/s10462-023-10529-w},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {421-443},
  shortjournal = {Artif. Intell. Rev.},
  title        = {SS-SSAN: A self-supervised subspace attentional network for multi-modal medical image fusion},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Visual language navigation: A survey and open challenges.
<em>AIR</em>, <em>56</em>(1), 365–427. (<a
href="https://doi.org/10.1007/s10462-022-10174-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the recent development of deep learning, AI models are widely used in various domains. AI models show good performance for definite tasks such as image classification and text generation. With the recent development of generative models (e.g., BigGAN, GPT-3), AI models also show impressive results for diverse generation tasks (e.g., photo-realistic image, paragraph generation). As the performance of each AI model improves, interest in comprehensive tasks, such as visual language navigation (VLN) which follows the language instruction with an egocentric view, is also growing. However, the model integration for VLN has a problem due to the model complexity, modal heterogeneity, and paired data shortage. This study provides a comprehensive survey on VLN with a systemic approach for reviewing recent trends. At first, we define a taxonomy for fundamental techniques which need to perform VLN. We analyze from four perspectives of VLN: representation learning, reinforcement learning, component, and evaluation. We investigate the pros and cons of each component and methodology that have been conducted recently. This survey categorizes major research institute&#39;s approaches with taxonomy defined in four perspectives, unlike other conventional surveys. Finally, we discuss current open challenges and conclude our study by giving possible future directions.},
  archive      = {J_AIR},
  author       = {Park, Sang-Min and Kim, Young-Gab},
  doi          = {10.1007/s10462-022-10174-9},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {365-427},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Visual language navigation: A survey and open challenges},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic literature review of clustering techniques for
patients with traumatic brain injury. <em>AIR</em>, <em>56</em>(1),
351–419. (<a href="https://doi.org/10.1007/s10462-023-10531-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the number of people suffering from traumatic brain injury (TBI) has increased considerably in recent years, the multiple deficits of these patients makes designing the rehabilitation process a challenge for practitioners. They need to group similar patients, due to their features and/ or diseases in order to assign them to the same clinically significant group to facilitate the design of appropriate rehabilitation activities. The information used to group the patients depends on the type of patient as well as the possible groups to be formed. This work focuses on studying how grouping patients with TBI has been carried out so far by means of clustering algorithms. The main interest in grouping TBI patients is the need to address this heterogeneity to create clinical guidelines or rehabilitation activities for individual groups and detect the characteristic features of each group. This study’s main aims are: (1) to determine the purposes of the clustering algorithms developed for TBI patients, (2) to identify the normally considered deficits, (3) to determine the most commonly used clustering algorithms, (4) to identify the types of features usually employed for TBI clustering, (5) to analyse the data pre-processing techniques applied, (5) to identify the parameters chosen when running a clustering algorithm for TBI patients, and (6) to determine the efficiency/effectiveness achieved by clustering algorithms.},
  archive      = {J_AIR},
  author       = {Moya, Alejandro and Pretel, Elena and Navarro, Elena and Jaén, Javier},
  doi          = {10.1007/s10462-023-10531-2},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {351-419},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A systematic literature review of clustering techniques for patients with traumatic brain injury},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fire hawk optimizer: A novel metaheuristic algorithm.
<em>AIR</em>, <em>56</em>(1), 287–363. (<a
href="https://doi.org/10.1007/s10462-022-10173-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes the Fire Hawk Optimizer (FHO) as a novel metaheuristic algorithm based on the foraging behavior of whistling kites, black kites and brown falcons. These birds are termed Fire Hawks considering the specific actions they perform to catch prey in nature, specifically by means of setting fire. Utilizing the proposed algorithm, a numerical investigation was conducted on 233 mathematical test functions with dimensions of 2–100, and 150,000 function evaluations were performed for optimization purposes. For comparison, a total of ten different classical and new metaheuristic algorithms were utilized as alternative approaches. The statistical measurements include the best, mean, median, and standard deviation of 100 independent optimization runs, while well-known statistical analyses, such as Kolmogorov–Smirnov, Wilcoxon, Mann–Whitney, Kruskal–Wallis, and Post-Hoc analysis, were also conducted. The obtained results prove that the FHO algorithm exhibits better performance than the compared algorithms from literature. In addition, two of the latest Competitions on Evolutionary Computation (CEC), such as CEC 2020 on bound constraint problems and CEC 2020 on real-world optimization problems including the well-known mechanical engineering design problems, were considered for performance evaluation of the FHO algorithm, which further demonstrated the superior capability of the optimizer over other metaheuristic algorithms in literature. The capability of the FHO is also evaluated in dealing with two of the real-size structural frames with 15 and 24 stories in which the new method outperforms the previously developed metaheuristics.},
  archive      = {J_AIR},
  author       = {Azizi, Mahdi and Talatahari, Siamak and Gandomi, Amir H.},
  doi          = {10.1007/s10462-022-10173-w},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {287-363},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Fire hawk optimizer: A novel metaheuristic algorithm},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Brain works principle followed by neural information
processing: A review of novel brain theory. <em>AIR</em>,
<em>56</em>(1), 285–350. (<a
href="https://doi.org/10.1007/s10462-023-10520-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The way the brain work and its principle of work has long been a big scientific question that scientists have dreamed of solving. However, as is known to all, the brain works at different levels, and the operation at different levels is interactional and mutually coupled. Unfortunately, until now, we still do not know how the nervous system at different levels is interacting and coupling with each other. This review provides some preliminary discussions on how to address these scientific questions, for which we propose a novel theory of the brain called neural energy. Such a theoretical and research approach can couple neural information with neural energy to address the interactions of the nervous system at various levels. Therefore, this review systematically summarizes the neural energy theories and methods proposed by our research in the field of brain science, as well as the internal relationship between mechanics and neural energy theory. Focuses on how to construct a Wang–Zhang (W–Z) neuron model equivalent to Hodgkin–Huxley (H–H) model by using the idea of analytical dynamics. Then, based on this model, we proposed a large-scale neural model and a theoretical framework of global neural coding of the brain in the field of neuroscience. It includes information processing of multiple sensory and perceptual nervous systems such as visual perception, neural mechanism of coupling between default mode network and functional network of brain, memory switching and brain state switching, brain navigation, prediction of new working mechanism of neurons, and interpretation of experimental phenomena that are difficult to be explained by neuroscience. It is proved that the new W–Z neuron model and neural energy theory have unique functions and advantages in neural modeling, neural information processing and methodology. The idea of large-scale neuroscience research with neural energy as the core will provide a potentially powerful research method for promoting the fusion of experimental neuroscience and theoretical neuroscience in the future, and propose a widely accepted brain theory system between experimental neuroscience and theoretical neuroscience. It is of great scientific significance to abandon the shortcomings of reductive and holism research methods in the field of neuroscience, and effectively integrate their respective advantages in methodology.},
  archive      = {J_AIR},
  author       = {Wang, Rubin and Wang, Yihong and Xu, Xuying and Li, Yuanxi and Pan, Xiaochuan},
  doi          = {10.1007/s10462-023-10520-5},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {285-350},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Brain works principle followed by neural information processing: A review of novel brain theory},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Additive consistency exploration of linguistic preference
relations with self-confidence. <em>AIR</em>, <em>56</em>(1), 257–285.
(<a href="https://doi.org/10.1007/s10462-022-10172-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preference relation is one of the most effective tools for decision makers (experts) to express their evaluation information in decision making. Recently, a new type of preference relation called linguistic preference relations with self-confidence (LPRs-SC) has been proposed. In an LPR-SC, experts can express multiple self-confidence levels when providing their preferences. Consistency of preference relations is an important premise for reliable and reasonable decision making. This research mainly focuses on the additive consistency exploration of LPRs-SC. To do that, some operational laws for LPRs-SC are introduced. Subsequently, an additive consistency index which considers both the linguistic preference values and the self-confidence is defined to measure the consistency level of LPR-SC. For an inconsistent LPR-SC, an optimization model and an iterative algorithm are developed to repair its consistency. It is worth noting that the inconsistency repairing methods proposed in this paper consider the acceptable adjustment range of experts, thereby increase their willingness to adjust the preference values and let the experts participate in the consistency improving process. Besides, the presented iterative algorithm is further extended to group decision making with LPRs-SC. Finally, two examples are furnished to demonstrate the feasibility and effectiveness of the proposed methods.},
  archive      = {J_AIR},
  author       = {Xu, Yejun and Zhu, Shennan and Liu, Xia and Huang, Jing and Herrera-Viedma, Enrique},
  doi          = {10.1007/s10462-022-10172-x},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {257-285},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Additive consistency exploration of linguistic preference relations with self-confidence},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Big data optimisation and management in supply chain
management: A systematic literature review. <em>AIR</em>,
<em>56</em>(1), 253–284. (<a
href="https://doi.org/10.1007/s10462-023-10505-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing interest from technology enthusiasts and organisational practitioners in big data applications in the supply chain has encouraged us to review recent research development. This paper proposes a systematic literature review to explore the available peer-reviewed literature on how big data is widely optimised and managed within the supply chain management context. Although big data applications in supply chain management appear to be often studied and reported in the literature, different angles of big data optimisation and management technologies in the supply chain are not clearly identified. This paper adopts the explanatory literature review involving bibliometric analysis as the primary research method to answer two research questions, namely: (1) How to optimise big data in supply chain management? and (2) What tools are most used to manage big data in supply chain management? A total of thirty-seven related papers are reviewed to answer the two research questions using the content analysis method. The paper also reveals some research gaps that lead to prospective future research directions.},
  archive      = {J_AIR},
  author       = {Alsolbi, Idrees and Shavaki, Fahimeh Hosseinnia and Agarwal, Renu and Bharathy, Gnana K and Prakash, Shiv and Prasad, Mukesh},
  doi          = {10.1007/s10462-023-10505-4},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {253-284},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Big data optimisation and management in supply chain management: A systematic literature review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). University admission process: A prescriptive analytics
approach. <em>AIR</em>, <em>56</em>(1), 233–256. (<a
href="https://doi.org/10.1007/s10462-022-10171-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Students typically do not have practical tools to help them choose their target universities to apply. This work proposes a comprehensive analytics framework as a decision support tool that assists students in their admission process. As an essential element of the developed framework, a prediction procedure is developed to precisely determine the student&#39;s chance of admission to each university using various machine learning methods. It is concluded that random forest combined with kernel principal component analysis outperforms other prediction models. Besides, an online survey is built to elicit the utility of the student regarding each university. A mathematical programming model is then proposed to determine the best universities to apply among the candidates considering the probable limitations; the most important is the student&#39;s budget. The model is also extended to consider multiple objectives for making decisions. Last, a case study is provided to show the practicality of the developed decision support tool.},
  archive      = {J_AIR},
  author       = {Kiaghadi, Mohammadreza and Hoseinpour, Pooya},
  doi          = {10.1007/s10462-022-10171-y},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {233-256},
  shortjournal = {Artif. Intell. Rev.},
  title        = {University admission process: A prescriptive analytics approach},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Safety-critical computer vision: An empirical survey of
adversarial evasion attacks and defenses on computer vision systems.
<em>AIR</em>, <em>56</em>(1), 217–251. (<a
href="https://doi.org/10.1007/s10462-023-10521-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the growing prominence of production-level AI and the threat of adversarial attacks that can poison a machine learning model against a certain label, evade classification, or reveal sensitive data about the model and training data to an attacker, adversaries pose fundamental problems to machine learning systems. Furthermore, much research has focused on the inverse relationship between robustness and accuracy, raising problems for real-time and safety-critical systems particularly since they are governed by legal constraints in which software changes must be explainable and every change must be thoroughly tested. While many defenses have been proposed, they are often computationally expensive and tend to reduce model accuracy. We have therefore conducted a large survey of attacks and defenses and present a simple and practical framework for analyzing any machine-learning system from a safety-critical perspective using adversarial noise to find the upper bound of the failure rate. Using this method, we conclude that all tested configurations of the ResNet architecture fail to meet any reasonable definition of ‘safety-critical’ when tested on even small-scale benchmark data. We examine state of the art defenses and attacks against computer vision systems with a focus on safety-critical applications in autonomous driving, industrial control, and healthcare. By testing a combination of attacks and defenses, their efficacy, and their run-time requirements, we provide substantial empirical evidence that modern neural networks consistently fail to meet established safety-critical standards by a wide margin.},
  archive      = {J_AIR},
  author       = {Meyers, Charles and Löfstedt, Tommy and Elmroth, Erik},
  doi          = {10.1007/s10462-023-10521-4},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {217-251},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Safety-critical computer vision: An empirical survey of adversarial evasion attacks and defenses on computer vision systems},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Risk assessment of coronary heart disease based on
cloud-random forest. <em>AIR</em>, <em>56</em>(1), 203–232. (<a
href="https://doi.org/10.1007/s10462-022-10170-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronary heart disease (CHD) is a major public health problem affecting a nation’s economic and social development. Risk assessing CHD in a timely manner helps to stop, reverse, and reduce the spread of many chronic diseases and health hazards. This paper proposes a cloud-random forest (C-RF) model combining cloud model and random forest to assess the risk of CHD. In this model, based on the traditional classification and regression trees (CART), a weight determining algorithm based on the cloud model and decision-making trial and evaluation laboratory is applied to obtain the weights of the evaluation attributes. The attribute weight and the gain value of the smallest Gini coefficient corresponding to the same attribute are weighted and summed. The weighted sum is then used to replace the original gain value. This value rule is used as a new CART node split criterion to construct a new decision tree, thus forming a new random forest, namely, the C-RF. The Framingham dataset of the Kaggle platform is the research sample for the empirical analysis. Comparing the C-RF model with CART, support vector machine (SVM), convolutional neural network (CNN), and random forest (RF) using standard performance evaluation indexes such as accuracy, error rates, ROC curve and AUC value. The result shows that the classification accuracy of the C-RF model is 85\%, which is improved by 8, 9, 4 and 3\% respectively compared with CART, SVM, CNN and RF. The error rate of the first type is 13.99\%, which is 6.99, 7.44, 4.47 and 3.02\% lower than CART, SVM, CNN and RF respectively. The AUC value is 0.85, which is also higher than other comparison models. Thus, the C-RF model is more superior on classification performance and classification effect in the risk assessment of CHD.},
  archive      = {J_AIR},
  author       = {Wang, Jing and Rao, Congjun and Goh, Mark and Xiao, Xinping},
  doi          = {10.1007/s10462-022-10170-z},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {203-232},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Risk assessment of coronary heart disease based on cloud-random forest},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of intelligent transmission line inspection based
on unmanned aerial vehicle. <em>AIR</em>, <em>56</em>(1), 173–201. (<a
href="https://doi.org/10.1007/s10462-022-10189-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of the new generation of information technology, artificial intelligence, cloud computing and big data are gradually becoming powerful engines of the smart grid. In recent years, people have been exploring how to reduce the dependence on human experience in the field of transmission line inspection. Therefore, transmission line inspection has attracted wide attention because of its high intelligence, flexibility and reliability. In this paper, we would like to present a survey on the intelligent transmission line inspection based on unmanned aerial vehicle (UAV). Firstly, the origin and development of intelligent electric power inspection are reviewed, and then the process of intelligent transmission line inspection and three key issues, i.e., path planning of UAV, trajectory tracking, and fault detection and diagnosis are presented in details. Finally, the challenges and future solutions are pointed out for power inspection.},
  archive      = {J_AIR},
  author       = {Luo, Yanhong and Yu, Xue and Yang, Dongsheng and Zhou, Bowen},
  doi          = {10.1007/s10462-022-10189-2},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {173-201},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of intelligent transmission line inspection based on unmanned aerial vehicle},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A chimp-inspired remora optimization algorithm for
multilevel thresholding image segmentation using cross entropy.
<em>AIR</em>, <em>56</em>(1), 159–216. (<a
href="https://doi.org/10.1007/s10462-023-10498-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multilevel thresholding is one of the most commonly used methods in image segmentation. However, the exhaustive search methods are costly in determining optimal thresholds and the conventional remora optimization algorithm (ROA) is prone to the premature convergence. This paper presents a chimp-inspired remora optimization algorithm (HCROA) to search optimal threshold levels, and the cross-entropy is employed as the objective function. In HCROA, the particles’ position are adjusted by the Chimp Optimization Algorithm (ChOA) because of its good exploitation ability and sufficient diversity. With this change, HCROA achieves both the intra-group diversity intelligence and a suitable balance between exploration and exploitation. To validate its performance, a series of experiments are performed. First, we test the HCROA’s segmentation accuracy by a set of natural gray-scale images with different thresholds. Second, HCROA is implemented for noisy image segmentation to evaluate its robustness. Several reference-based measurements including Peak Signal-to-Noise Ratio (PSNR), Structural Similarity (SSIM), Feature Similarity (FSIM), Quality Index based on Local Variance (QILV), Haar wavelet-based Perceptual Similarity Index (HPSI), Wilcoxon test, and CPU time have been considered for evaluating the proposed method. Additionally, eight well-known predecessors are injected for parallel comparison. The comparison results prove that the suggested method outperforms the existing approaches in terms of accuracy, convergence speed, noise robustness, and efficiency.},
  archive      = {J_AIR},
  author       = {Liu, Qingxin and Li, Ni and Jia, Heming and Qi, Qi and Abualigah, Laith},
  doi          = {10.1007/s10462-023-10498-0},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {159-216},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A chimp-inspired remora optimization algorithm for multilevel thresholding image segmentation using cross entropy},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human-centric and semantics-based explainable event
detection: A survey. <em>AIR</em>, <em>56</em>(1), 119–158. (<a
href="https://doi.org/10.1007/s10462-023-10525-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been a surge of interest in Artificial Intelligence (AI) systems that can provide human-centric explanations for decisions or predictions. No matter how good and efficient an AI model is, users or practitioners find it difficult to trust it if they cannot understand the AI model or its behaviours. Incorporating explainability that is human-centric in event detection systems is significant for building a decision-making process that is more trustworthy and sustainable. Human-centric and semantics-based explainable event detection will achieve trustworthiness, explainability, and reliability, which are currently lacking in AI systems. This paper provides a survey on human-centric explainable AI, explainable event detection, and semantics-based explainable event detection by answering some research questions that bother on the characteristics of human-centric explanations, the state of explainable AI, methods for human-centric explanations, the essence of human-centricity in explainable event detection, research efforts in explainable event solutions, and the benefits of integrating semantics into explainable event detection. The findings from the survey show the current state of human-centric explainability, the potential of integrating semantics into explainable AI, the open problems, and the future directions which can guide researchers in the explainable AI domain.},
  archive      = {J_AIR},
  author       = {Kolajo, Taiwo and Daramola, Olawande},
  doi          = {10.1007/s10462-023-10525-0},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {119-158},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Human-centric and semantics-based explainable event detection: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-organizing migrating algorithm: Review, improvements
and comparison. <em>AIR</em>, <em>56</em>(1), 101–172. (<a
href="https://doi.org/10.1007/s10462-022-10167-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The self-organizing migrating algorithm (SOMA) is a population-based meta-heuristic that belongs to swarm intelligence. In the last 20 years, we can observe two main streams in the publications. First, novel approaches contributing to the improvement of its performance. Second, solving the various optimization problems. Despite the different approaches and applications, there exists no work summarizing them. Therefore, this work reviews the research papers dealing with the principles and application of the SOMA. The second goal of this work is to provide additional information about the performance of the SOMA. This work presents the comparison of the selected algorithms. The experimental results indicate that the best-performing SOMAs provide competitive results comparing the recently published algorithms.},
  archive      = {J_AIR},
  author       = {Skanderova, Lenka},
  doi          = {10.1007/s10462-022-10167-8},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {101-172},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Self-organizing migrating algorithm: Review, improvements and comparison},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence-based approaches for improving the
diagnosis, triage, and prioritization of autism spectrum disorder: A
systematic review of current trends and open issues. <em>AIR</em>,
<em>56</em>(1), 53–117. (<a
href="https://doi.org/10.1007/s10462-023-10536-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The artificial intelligence (AI) trend to embrace Autism Spectrum Disorder (ASD) has dramatically transformed the landscape of medical diagnosis. People often exhibit fear and apprehension towards conditions they lack understanding of, and ASD being a complex affliction, poses challenges in comprehending its intricacies. Researchers have harnessed AI applications to improve the precision of disease diagnosis by utilizing Magnetic Resonance Imaging (MRI), Electroencephalography (EEG), genetic, sociodemographic, and medical data. However, the development of AI systems for early diagnosis and triage in healthcare is still in its nascent stages. In particular, studies have revealed a global increase in the prevalence of ASD, with an estimated 1 in 59 children being diagnosed. However, there is a lack of up-to-date information regarding the current status of ASD. This study aims to provide a systematic review of AI applications in early diagnosis and triage for ASD, supplementing the findings of previous studies and offering a comprehensive overview of the evidence. To achieve this, a rigorous literature search method and selection criteria were employed, resulting in the identification of 46 recent contributions on the applications of AI in ASD from various databases, including ScienceDirect (SD), IEEE Xplore digital library (IEEE), Web of Science (WOS), PubMed, and Scopus. The selected papers were categorized into three main categories: ASD triage levels, clinical diagnosis for ASD, and diagnosis based on telemedicine, with further subcategories under the clinical diagnosis category. Theoretical and practical aspects of AI methods used for ASD diagnosis, as well as the presentation utilizing data analytics, were presented. The paper presents a systematic and comprehensive analysis of previous studies, examining the challenges, motivations, and recommendations, thereby paving the way for potential future research. Additionally, the work provides decisive evidence for the use of AI in ASD healthcare diagnosis and triage, offering nine critical analyses of the current state-of-the-art and addressing relevant research gaps. To the best of our knowledge, this study is innovative in exploring the feasibility of using AI in ASD medical diagnosis and triage. It highlights essential pieces of information, including Explainable AI (XAI), Auto machine learning (AutoML), Internet of Things (IoT)-based AI, robot-assisted therapy-based AI, telemedicine, data fusion techniques, and available ASD datasets with different aspects. The analysis of the revised contributions reveals crucial implications for academics and practitioners. The paper also proposes potential methodological aspects to enhance the triage and prioritization of autistic patients using AI applications in the medical sector, as well as addressing theoretical and practical application aspects and five methodology phases using fuzzy Multi-Criteria Decision Making (MCDM) methods in ASD triage and prioritization.},
  archive      = {J_AIR},
  author       = {Joudar, Shahad Sabbar and Albahri, A. S. and Hamid, Rula A. and Zahid, Idrees A. and Alqaysi, M. E. and Albahri, O. S. and Alamoodi, A. H.},
  doi          = {10.1007/s10462-023-10536-x},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {53-117},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Artificial intelligence-based approaches for improving the diagnosis, triage, and prioritization of autism spectrum disorder: A systematic review of current trends and open issues},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Memory based hybrid crow search algorithm for solving
numerical and constrained global optimization problems. <em>AIR</em>,
<em>56</em>(1), 27–99. (<a
href="https://doi.org/10.1007/s10462-022-10164-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crow Search Algorithm (CSA) is a promising meta-heuristic method developed based on the intelligent conduct of crows in nature. This algorithm lacks a good representation of its individuals’ memory, and as with many other meta-heuristics it faces a problem in efficiently balancing exploration and exploitation. These defects may lead to early convergence to local optima. To cope with such issues, we proposed a Memory based Hybrid CSA (MHCSA) with the use of Particle Swarm Optimization (PSO) algorithm. This hybridization approach was proposed to reinforce the diversity ability of CSA and balance its search abilities for promising solutions to achieve robust search performance. The memory element of MHCSA was initialized with the best solution (pbest) of PSO to exploit the most promising search areas. The best positions of the CSA’s individuals are improved using the best solution found so far (gbest) and (pbest) of PSO. Another flaw of CSA is the use of fixed flight length and awareness probability for crows to control exploration and exploitation features, respectively. This issue was circumvented here by replacing these constants with adaptive functions in order to provide a better balance between exploration and exploitation over the course of iterations. The competence of MHCSA was revealed by testing it on seventy-three standard and computationally complex benchmark functions. Its applicability was substantiated by solving seven engineering design problems. The results showed that the problem of early convergence was eliminated by MHCSA and that the balance of exploration and exploitation was further improved. Further, MHCSA ranked first among CSA, PSO, robust variants of CSA and other strong competing methods in terms of accuracy and stability.},
  archive      = {J_AIR},
  author       = {Braik, Malik and Al-Zoubi, Hussein and Ryalat, Mohammad and Sheta, Alaa and Alzubi, Omar},
  doi          = {10.1007/s10462-022-10164-x},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {27-99},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Memory based hybrid crow search algorithm for solving numerical and constrained global optimization problems},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on physarum polycephalum intelligent foraging
behaviour and bio-inspired applications. <em>AIR</em>, <em>56</em>(1),
1–26. (<a href="https://doi.org/10.1007/s10462-021-10112-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, research on Physarum polycephalum has become more popular after Nakagaki (AIR 407: 6803-470, 2000) performed their famous experiment showing that Physarum was able to find the shortest route through a maze. Subsequent researches have confirmed the ability of Physarum-inspired algorithms to solve a wide range of real-world applications. In contrast to previous reviews that either focus on biological aspects or bio-inspired applications, here we present a comprehensive review that highlights recent Physarum polycephalum biological aspects, mathematical models, and Physarum bio-inspired algorithms and their applications. The novelty of this review stems from our exploration of Physarum intelligent behaviour in competition settings. Further, we have presented our new model to simulate Physarum in competition, where multiple Physarum interact with each other and with their environments. The bio-inspired Physarum in competition algorithms proved to have great potentials for future research.},
  archive      = {J_AIR},
  author       = {Awad, Abubakr and Pang, Wei and Lusseau, David and Coghill, George M.},
  doi          = {10.1007/s10462-021-10112-1},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey on physarum polycephalum intelligent foraging behaviour and bio-inspired applications},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integrated animal monitoring system with animal detection
and classification capabilities: A review on image modality, techniques,
applications, and challenges. <em>AIR</em>, <em>56</em>(1), 1–51. (<a
href="https://doi.org/10.1007/s10462-023-10534-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The continuous monitoring of animals is crucial for the well-being of both humans and animals. A comprehensive animal monitoring system must incorporate animal detection, classification, and deterrence techniques. This review paper addresses 8 research questions related to animal monitoring by presenting a comprehensive literature review of animal deterrence, monitoring, classification, and detection techniques. Additionally, it covers various animal image acquisition techniques, different image modalities, photogrammetry types, and unmanned vehicles used for animal studies. The paper also highlights the problems faced by animals and humans in co-existence and lists the challenges faced while capturing animal images in different modalities, such as visible, thermal, and aerial images. The conclusion includes a comparative study based on benchmark datasets and highlights future scope and areas that require further research in animal monitoring systems.},
  archive      = {J_AIR},
  author       = {Sundaram, N. and Meena, S. Divya},
  doi          = {10.1007/s10462-023-10534-z},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {1-51},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Integrated animal monitoring system with animal detection and classification capabilities: A review on image modality, techniques, applications, and challenges},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
