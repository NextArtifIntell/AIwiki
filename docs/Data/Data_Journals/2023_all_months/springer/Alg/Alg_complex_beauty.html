<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Alg_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="alg---137">Alg - 137</h2>
<ul>
<li><details>
<summary>
(2023). The subfield and extended codes of a subclass of optimal
three-weight cyclic codes. <em>Alg</em>, <em>85</em>(12), 3973–3995. (<a
href="https://doi.org/10.1007/s00453-023-01173-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A class of optimal three-weight $$[q^k-1,k+1,q^{k-1}(q-1)-1]$$ cyclic codes over $${\mathrm{I\!F}}_q$$ , with $$k\ge 2$$ , achieving the Griesmer bound, was presented by Heng and Yue (IEEE Trans Inf Theory 62(8):4501–4513, 2016. https://doi.org/10.1109/TIT.2016.2550029). In this paper we study some of the subfield codes of this class of optimal cyclic codes when $$k=2$$ . The weight distributions of the subfield codes are settled. It turns out that some of these codes are optimal and others have the best known parameters. The duals of the subfield codes are also investigated and found to be almost optimal with respect to the sphere-packing bound. In addition, the covering structure for the studied subfield codes is determined. Some of these codes are found to have the important property that any nonzero codeword is minimal, which is a desirable property that is useful in the design of a secret sharing scheme based on a linear code. Moreover, a specific example of a secret sharing scheme based on one of these subfield codes is given. Finally, a class of optimal two-weight linear codes over $${\mathrm{I\!F}}_q$$ , achieving the Griesmer bound, whose duals are almost optimal with respect to the sphere-packing bound is presented. Through a different approach, this class of optimal two-weight linear codes was reported very recently by Heng (IEEE Trans Inf Theory 69(2):978–994, 2023. https://doi.org/10.1109/TIT.2022.3203380). Furthermore, it is shown that these optimal codes can be used to construct strongly regular graphs.},
  archive      = {J_Alg},
  author       = {Hernández, Félix and Vega, Gerardo},
  doi          = {10.1007/s00453-023-01173-5},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3973-3995},
  shortjournal = {Algorithmica},
  title        = {The subfield and extended codes of a subclass of optimal three-weight cyclic codes},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comparison of matrix norm sparsification. <em>Alg</em>,
<em>85</em>(12), 3957–3972. (<a
href="https://doi.org/10.1007/s00453-023-01172-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A well-known approach in the design of efficient algorithms, called matrix sparsification, approximates a matrix A with a sparse matrix $$A&#39;$$ . Achlioptas and McSherry (J ACM 54(2):9-es, 2007) initiated a long line of work on spectral-norm sparsification, which aims to guarantee that $$\Vert A&#39;-A\Vert \le \epsilon \Vert A\Vert $$ for error parameter $$\epsilon &gt;0$$ . Various forms of matrix approximation motivate considering this problem with a guarantee according to the Schatten p-norm for general p, which includes the spectral norm as the special case $$p=\infty $$ . We investigate the relation between fixed but different $$p\ne q$$ , that is, whether sparsification in the Schatten p-norm implies (existentially and/or algorithmically) sparsification in the Schatten $$q\text {-norm}$$ with similar sparsity. An affirmative answer could be tremendously useful, as it will identify which value of p to focus on. Our main finding is a surprising contrast between this question and the analogous case of $$\ell _p$$ -norm sparsification for vectors: For vectors, the answer is affirmative for $$pq$$ , but for matrices we answer negatively for almost all sufficiently distinct $$p\ne q$$ . In addition, our explicit constructions may be of independent interest.},
  archive      = {J_Alg},
  author       = {Krauthgamer, Robert and Sapir, Shay},
  doi          = {10.1007/s00453-023-01172-6},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3957-3972},
  shortjournal = {Algorithmica},
  title        = {Comparison of matrix norm sparsification},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The online broadcast range-assignment problem. <em>Alg</em>,
<em>85</em>(12), 3928–3956. (<a
href="https://doi.org/10.1007/s00453-023-01166-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let $$P={p_0,\ldots ,p_{n-1}}$$ be a set of points in $${\mathbb R}^d$$ , modeling devices in a wireless network. A range assignment assigns a range $$r(p_i)$$ to each point $$p_i\in P$$ , thus inducing a directed communication graph $$\mathcal {G}_r$$ in which there is a directed edge $$(p_i,p_j)$$ iff $${{\,\textrm{dist}\,}}(p_i, p_j) \leqslant r(p_i)$$ , where $${{\,\textrm{dist}\,}}(p_i,p_j)$$ denotes the distance between $$p_i$$ and $$p_j$$ . The range-assignment problem is to assign the transmission ranges such that $$\mathcal {G}_r$$ has a certain desirable property, while minimizing the cost of the assignment; here the cost is given by $$\sum _{p_i\in P} r(p_i)^{\alpha }$$ , for some constant $$\alpha &gt;1$$ called the distance-power gradient. We introduce the online version of the range-assignment problem, where the points $$p_j$$ arrive one by one, and the range assignment has to be updated at each arrival. Following the standard in online algorithms, resources given out cannot be taken away—in our case this means that the transmission ranges will never decrease. The property we want to maintain is that $$\mathcal {G}_r$$ has a broadcast tree rooted at the first point $$p_0$$ . Our results include the following.},
  archive      = {J_Alg},
  author       = {de Berg, Mark and Markovic, Aleksandar and Umboh, Seeun William},
  doi          = {10.1007/s00453-023-01166-4},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3928-3956},
  shortjournal = {Algorithmica},
  title        = {The online broadcast range-assignment problem},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unique response roman domination: Complexity and algorithms.
<em>Alg</em>, <em>85</em>(12), 3889–3927. (<a
href="https://doi.org/10.1007/s00453-023-01171-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A function $$f :V(G) \rightarrow {0, 1, 2}$$ is called a Roman dominating function on $$G=(V(G),E(G))$$ if for every vertex v with $$f(v) = 0$$ , there exists a vertex $$u\in N_G(v)$$ such that $$f(u) = 2$$ . A function $$f :V(G) \rightarrow {0, 1, 2}$$ induces an ordered partition $$(V_0,V_1,V_2)$$ of V(G), where $$V_i={v\in V(G):f(v)=i}$$ for $$i\in {0,1,2}$$ . A function $$f :V(G) \rightarrow {0, 1, 2}$$ with ordered partition $$(V_0, V_1, V_2)$$ is called a unique response Roman function if for every vertex v with $$f(v)=0$$ , $$|N_G(v)\cap V_2|\le 1$$ , and for every vertex v with $$f(v)=1$$ or 2, $$|N_G(v)\cap V_2|= 0$$ . A function $$f :V(G) \rightarrow {0, 1, 2}$$ is called a unique response Roman dominating function (URRDF) on G if it is a unique response Roman function as well as a Roman dominating function on G. The weight of a unique response Roman dominating function f is the sum $$f(V(G))=\sum _{v\in V(G)}f(v)$$ , and the minimum weight of a unique response Roman dominating function on G is called the unique response Roman domination number of G and is denoted by $$u_{R}(G)$$ . Given a graph G, the Min-URRDF problem asks to find a unique response Roman dominating function of minimum weight on G. In this paper, we study the algorithmic aspects of Min-URRDF. We show that the decision version of Min-URRDF remains NP-complete for chordal graphs and bipartite graphs. We show that for a given graph with n vertices, Min-URRDF cannot be approximated within a ratio of $$n^{1-\varepsilon } $$ for any $$ \varepsilon &gt;0 $$ unless $$\mathsf {P=NP}$$ . We also show that Min-URRDF can be approximated within a factor of $$\varDelta +1$$ for graphs having maximum degree $$\varDelta $$ . On the positive side, we design a linear-time algorithm to solve Min-URRDF for distance-hereditary graphs. Also, we show that Min-URRDF is polynomial-time solvable for interval graphs, and strengthen the result by showing that Min-URRDF can be solved in linear-time for proper interval graphs, a proper subfamily of interval graphs.},
  archive      = {J_Alg},
  author       = {Banerjee, Sumanta and Chaudhary, Juhi and Pradhan, Dinabandhu},
  doi          = {10.1007/s00453-023-01171-7},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3889-3927},
  shortjournal = {Algorithmica},
  title        = {Unique response roman domination: Complexity and algorithms},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Opinion dynamics with limited information. <em>Alg</em>,
<em>85</em>(12), 3855–3888. (<a
href="https://doi.org/10.1007/s00453-023-01157-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study opinion formation games based on the famous model proposed by Friedkin and Johsen (FJ model). In today’s huge social networks the assumption that in each round agents update their opinions by taking into account the opinions of all their friends is unrealistic. So, we are interested in the convergence properties of simple and natural variants of the FJ model that use limited information exchange in each round and converge to the same stable point. As in the FJ model, we assume that each agent i has an intrinsic opinion $$s_i \in [0,1]$$ and maintains an expressed opinion $$x_i(t) \in [0,1]$$ in each round t. To model limited information exchange, we consider an opinion formation process where each agent i meets with one random friend j at each round t and learns only her current opinion $$x_j(t)$$ . The amount of influence j imposes on i is reflected by the probability $$p_{ij}$$ with which i meets j. Then, agent i suffers a disagreement cost that is a convex combination of $$(x_i(t) - s_i)^2$$ and $$(x_i(t) - x_j(t))^2$$ . An important class of dynamics in this setting are no regret dynamics, i.e. dynamics that ensure vanishing regret against the experienced disagreement cost to the agents. We show an exponential gap between the convergence rate of no regret dynamics and of more general dynamics that do not ensure no regret. We prove that no regret dynamics require roughly $$\varOmega (1/\varepsilon )$$ rounds to be within distance $$\varepsilon $$ from the stable point of the FJ model. On the other hand, we provide an opinion update rule that does not ensure no regret and converges to $$x^*$$ in $$\tilde{O}(\log ^2(1/\varepsilon ))$$ rounds. Finally, in our variant of the FJ model, we show that the agents can adopt a simple opinion update rule that ensures no regret to the experienced disagreement cost and results in an opinion vector that converges to the stable point $$x^*$$ of the FJ model within distance $$\varepsilon $$ in $$\textrm{poly}(1/\varepsilon )$$ rounds. In view of our lower bound for no regret dynamics this rate of convergence is close to best possible.},
  archive      = {J_Alg},
  author       = {Fotakis, Dimitris and Kandiros, Vardis and Kontonis, Vasilis and Skoulakis, Stratis},
  doi          = {10.1007/s00453-023-01157-5},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3855-3888},
  shortjournal = {Algorithmica},
  title        = {Opinion dynamics with limited information},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inapproximability of positive semidefinite permanents and
quantum state tomography. <em>Alg</em>, <em>85</em>(12), 3828–3854. (<a
href="https://doi.org/10.1007/s00453-023-01169-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matrix permanents are hard to compute or even estimate in general. It had been previously suggested that the permanents of Positive Semidefinite (PSD) matrices may have efficient approximations. By relating PSD permanents to a task in quantum state tomography, we show that PSD permanents are NP-hard to approximate within a constant factor, and so admit no polynomial-time approximation scheme (unless P = NP). We also establish that several natural tasks in quantum state tomography, even approximately, are NP-hard in the dimension of the Hilbert space. These state tomography tasks therefore remain hard even with only logarithmically few qubits.},
  archive      = {J_Alg},
  author       = {Meiburg, Alexander},
  doi          = {10.1007/s00453-023-01169-1},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3828-3854},
  shortjournal = {Algorithmica},
  title        = {Inapproximability of positive semidefinite permanents and quantum state tomography},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On colorful vertex and edge cover problems. <em>Alg</em>,
<em>85</em>(12), 3816–3827. (<a
href="https://doi.org/10.1007/s00453-023-01164-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study two generalizations of Vertex Cover and Edge Cover, namely Colorful Vertex Cover and Colorful Edge Cover. In the Colorful Vertex Cover problem, given an n-vertex edge-colored graph G with colors from $${1, \ldots , \omega }$$ and coverage requirements $$r_1, r_2, \ldots , r_\omega $$ , the goal is to find a minimum-sized set of vertices that are incident on at least $$r_i$$ edges of color i, for each $$1 \le i \le \omega $$ , i.e., we need to cover at least $$r_i$$ edges of color i. Colorful Edge Cover is similar to Colorful Vertex Cover, except here we are given a vertex-colored graph and the goal is to cover at least $$r_i$$ vertices of color i, for each $$1 \le i \le \omega $$ , by a minimum-sized set of edges. These problems have several applications in fair covering and hitting of geometric set systems involving points and lines that are divided into multiple groups. Here, “fairness” ensures that the coverage (resp. hitting) requirement of every group is fully satisfied. We obtain a $$(2+\epsilon )$$ -approximation for the Colorful Vertex Cover problem in time $$n^{O(\omega /\epsilon )}$$ . Thus, for a constant number of colors, the problem admits a $$(2+\epsilon )$$ -approximation in polynomial time. Next, for the Colorful Edge Cover problem, we design an $$O(\omega n^3)$$ time exact algorithm, via a chain of reductions to a matching problem. For all intermediate problems in this chain of reductions, we design polynomial-time algorithms, which might be of independent interest.},
  archive      = {J_Alg},
  author       = {Bandyapadhyay, Sayan and Banik, Aritra and Bhore, Sujoy},
  doi          = {10.1007/s00453-023-01164-6},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3816-3827},
  shortjournal = {Algorithmica},
  title        = {On colorful vertex and edge cover problems},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Probabilistic analysis of optimization problems on sparse
random shortest path metrics. <em>Alg</em>, <em>85</em>(12), 3793–3815.
(<a href="https://doi.org/10.1007/s00453-023-01167-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simple heuristics for (combinatorial) optimization problems often show a remarkable performance in practice. Worst-case analysis often falls short of explaining this performance. Because of this, “beyond worst-case analysis” of algorithms has recently gained a lot of attention, including probabilistic analysis of algorithms. The instances of many (combinatorial) optimization problems are essentially a discrete metric space. Probabilistic analysis for such metric optimization problems has nevertheless mostly been conducted on instances drawn from Euclidean space, which provides a structure that is usually heavily exploited in the analysis. However, most instances from practice are not Euclidean. Little work has been done on metric instances drawn from other, more realistic, distributions. Some initial results have been obtained in recent years, where random shortest path metrics generated from dense graphs (either complete graphs or Erdős–Rényi random graphs) have been used so far. In this paper we extend these findings to sparse graphs, with a focus on sparse graphs with ‘fast growing cut sizes’, i.e. graphs for which $$|\delta (U)|=\Omega (|U|^\varepsilon )$$ for some constant $$\varepsilon \in (0,1)$$ for all subsets U of the vertices, where $$\delta (U)$$ is the set of edges connecting U to the remaining vertices. A random shortest path metric is constructed by drawing independent random edge weights for each edge in the graph and setting the distance between every pair of vertices to the length of a shortest path between them with respect to the drawn weights. For such instances generated from a sparse graph with fast growing cut sizes, we prove that the greedy heuristic for the minimum distance maximum matching problem, and the nearest neighbor and insertion heuristics for the traveling salesman problem all achieve a constant expected approximation ratio. Additionally, for instances generated from an arbitrary sparse graph, we show that the 2-opt heuristic for the traveling salesman problem also achieves a constant expected approximation ratio.},
  archive      = {J_Alg},
  author       = {Klootwijk, Stefan and Manthey, Bodo},
  doi          = {10.1007/s00453-023-01167-3},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3793-3815},
  shortjournal = {Algorithmica},
  title        = {Probabilistic analysis of optimization problems on sparse random shortest path metrics},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Best-of-both-worlds analysis of online search. <em>Alg</em>,
<em>85</em>(12), 3766–3792. (<a
href="https://doi.org/10.1007/s00453-023-01165-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In search problems, a mobile searcher seeks to locate a target that hides in some unknown position of the environment. Such problems are typically considered to be of an on-line nature, in that the target’s position is unknown to the searcher, and the performance of a search strategy is usually analyzed by means of the standard framework of the competitive ratio, which compares the cost incurred by the searcher to an optimal strategy that knows the location of the target. However, one can argue that even for simple search problems, competitive analysis fails to distinguish between strategies which, intuitively, should have different performance in practice. Motivated by the above observation, in this work we introduce and study measures supplementary to competitive analysis in the context of search problems. In particular, we focus on the well-known problem of linear search, informally known as the cow-path problem, for which there is an infinite number of strategies that achieve an optimal competitive ratio equal to 9. We propose a measure that reflects the rate at which the line is being explored by the searcher, and which can be seen as an extension of the bijective ratio over an uncountable set of requests. Using this measure we show that a natural strategy that explores the line aggressively is optimal among all 9-competitive strategies. This provides, in particular, a strict separation from the competitively optimal doubling strategy, which is much more conservative in terms of exploration. We also provide evidence that this aggressiveness is requisite for optimality, by showing that any optimal strategy must mimic the aggressive strategy in its first few explorations.},
  archive      = {J_Alg},
  author       = {Angelopoulos, Spyros and Dürr, Christoph and Jin, Shendan},
  doi          = {10.1007/s00453-023-01165-5},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3766-3792},
  shortjournal = {Algorithmica},
  title        = {Best-of-both-worlds analysis of online search},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deterministic dynamic matching in worst-case update time.
<em>Alg</em>, <em>85</em>(12), 3741–3765. (<a
href="https://doi.org/10.1007/s00453-023-01151-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present deterministic algorithms for maintaining a $$(3/2 + \epsilon )$$ and $$(2 + \epsilon )$$ -approximate maximum matching in a fully dynamic graph with worst-case update times $${\hat{O}}(\sqrt{n})$$ and $${\tilde{O}}(1)$$ respectively. The fastest known deterministic worst-case update time algorithms for achieving approximation ratio $$(2 - \delta )$$ (for any $$\delta &gt; 0$$ ) and $$(2 + \epsilon )$$ were both shown by Roghani et al. (Beating the folklore algorithm for dynamic matching, 2021) with update times $$O(n^{3/4})$$ and $$O_\epsilon (\sqrt{n})$$ respectively. We close the gap between worst-case and amortized algorithms for the two approximation ratios as the best deterministic amortized update times for the problem are $$O_\epsilon (\sqrt{n})$$ and $${\tilde{O}}(1)$$ which were shown in Bernstein and Stein (in: Proceedings of the twenty-seventh annual ACM-SIAM symposium on discrete algorithms, 2016) and Bhattacharya and Kiss (in: 48th international colloquium on automata, languages, and programming, ICALP 2021, 12–16 July, Glasgow, 2021) respectively. The algorithm achieving $$(3/2 + \epsilon )$$ approximation builds on the EDCS concept introduced by the influential paper of Bernstein and Stein (in: International colloquium on automata, languages, and programming, Springer, Berlin, 2015). Say that H is a $$(\alpha , \delta )$$ -approximate matching sparsifier if at all times H satisfies that $$\mu (H) \cdot \alpha + \delta \cdot n \ge \mu (G)$$ (define $$(\alpha , \delta )$$ -approximation similarly for matchings). We show how to maintain a locally damaged version of the EDCS which is a $$(3/2 + \epsilon , \delta )$$ -approximate matching sparsifier. We further show how to reduce the maintenance of an $$\alpha $$ -approximate maximum matching to the maintenance of an $$(\alpha , \delta )$$ -approximate maximum matching building based on an observation of Assadi et al. (in: Proceedings of the twenty-seventh annual (ACM-SIAM) symposium on discrete algorithms, (SODA) 2016, Arlington, VA, USA, January 10–12, 2016). Our reduction requires an update time blow-up of $${\hat{O}}(1)$$ or $${\tilde{O}}(1)$$ and is deterministic or randomized against an adaptive adversary respectively. To achieve $$(2 + \epsilon )$$ -approximation we improve on the update time guarantee of an algorithm of Bhattacharya and Kiss (in: 48th International colloquium on automata, languages, and programming, ICALP 2021, 12–16 July, Glasgow, 2021). In order to achieve both results we explicitly state a method implicitly used in Nanongkai and Saranurak (in: Proceedings of the twenty-seventh annual ACM symposium on theory of computing, 2017) and Bernstein et al. (Fully-dynamic graph sparsifiers against an adaptive adversary, 2020) which allows to transform dynamic algorithms capable of processing the input in batches to a dynamic algorithms with worst-case update time.},
  archive      = {J_Alg},
  author       = {Kiss, Peter},
  doi          = {10.1007/s00453-023-01151-x},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3741-3765},
  shortjournal = {Algorithmica},
  title        = {Deterministic dynamic matching in worst-case update time},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Even more effort towards improved bounds and fixed-parameter
tractability for multiwinner rules. <em>Alg</em>, <em>85</em>(12),
3717–3740. (<a
href="https://doi.org/10.1007/s00453-023-01155-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiwinner elections have proven to be a fruitful research topic with many real-world applications. We contribute to this line of research by improving the state of the art regarding the computational complexity of computing good committees. More formally, given a set of candidates $$\mathcal{C}$$ , a set of voters $$\mathcal{V}$$ —each ranking the candidates according to their preferences, and an integer k; a multiwinner voting rule identifies a k-sized committee, based on these given voter preferences. In this paper we consider several utilitarian and egailitarian ordered weighted average scoring rules, which are an extensively-researched family of rules (and a subfamily of the family of committee scoring rules). First, we improve the result of Betzler et al. (JAIR 47:475–519, 2013), which gave a $${\mathcal {O}}(n^n)$$ algorithm for computing winner under the Chamberlin–Courant rule, where n is the number of voters; to a running time of $${\mathcal {O}}(2^n)$$ , which is optimal. Furthermore, we study the parameterized complexity of the Pessimist voting rule and describe a few tractable and intractable cases. Apart from such utilitarian voting rules, we extend our study and consider egalitarian median and egalitarian mean (both committee scoring rules), showing some tractable and intractable results, based on nontrivial structural observations.},
  archive      = {J_Alg},
  author       = {Gupta, Sushmita and Jain, Pallavi and Saurabh, Saket and Talmon, Nimrod},
  doi          = {10.1007/s00453-023-01155-7},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3717-3740},
  shortjournal = {Algorithmica},
  title        = {Even more effort towards improved bounds and fixed-parameter tractability for multiwinner rules},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A combinatorial cut-toggling algorithm for solving laplacian
linear systems. <em>Alg</em>, <em>85</em>(12), 3680–3716. (<a
href="https://doi.org/10.1007/s00453-023-01154-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last two decades, a significant line of work in theoretical algorithms has made progress in solving linear systems of the form $${{\textbf {L}}}{{\textbf {x}}} = {{\textbf {b}}}$$ , where $${{\textbf {L}}}$$ is the Laplacian matrix of a weighted graph with weights $${w(i,j)}&gt;{0}$$ on the edges. The solution $${{\textbf {x}}}$$ of the linear system can be interpreted as the potentials of an electrical flow in which the resistance on edge (i, j) is 1/w(i, j). Kelner et al. (in: Proceedings of the 45th Annual ACM Symposium on the Theory of Computing, pp 911–920, 2013. https://doi.org/10.1145/2488608.2488724 ) give a combinatorial, near-linear time algorithm that maintains the Kirchoff Current Law, and gradually enforces the Kirchoff Potential Law by updating flows around cycles (cycle toggling). In this paper, we consider a dual version of the algorithm that maintains the Kirchoff Potential Law, and gradually enforces the Kirchoff Current Law by cut toggling: each iteration updates all potentials on one side of a fundamental cut of a spanning tree by the same amount. We prove that this dual algorithm also runs in a near-linear number of iterations. We show, however, that if we abstract cut toggling as a natural data structure problem, this problem can be reduced to the online vector–matrix-vector problem, which has been conjectured to be difficult for dynamic algorithms (Henzinger et al., in: Proceedings of the 47th Annual ACM Symposium on the Theory of Computing, pp 21–30, 2015. https://doi.org/10.1145/2746539.2746609 ). The conjecture implies that the data structure does not have an $$O(n^{1-\epsilon })$$ time algorithm for any $$\epsilon &gt; 0$$ , and thus a straightforward implementation of the cut-toggling algorithm requires essentially linear time per iteration. To circumvent the lower bound, we batch update steps, and perform them simultaneously instead of sequentially. An appropriate choice of batching leads to an $${\widetilde{O}}(m^{1.5})$$ time cut-toggling algorithm for solving Laplacian systems. Furthermore, we show that if we sparsify the graph and call our algorithm recursively on the Laplacian system implied by batching and sparsifying, we can reduce the running time to $$O(m^{1 + \epsilon })$$ for any $$\epsilon &gt; 0$$ . Thus, the dual cut-toggling algorithm can achieve (almost) the same running time as its primal cycle-toggling counterpart.},
  archive      = {J_Alg},
  author       = {Henzinger, Monika and Jin, Billy and Peng, Richard and Williamson, David P.},
  doi          = {10.1007/s00453-023-01154-8},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3680-3716},
  shortjournal = {Algorithmica},
  title        = {A combinatorial cut-toggling algorithm for solving laplacian linear systems},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Peak demand minimization via sliced strip packing.
<em>Alg</em>, <em>85</em>(12), 3649–3679. (<a
href="https://doi.org/10.1007/s00453-023-01152-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the Non-preemptive Peak Demand Minimization (NPDM) problem, where we are given a set of jobs, specified by their processing times and energy requirements. The goal is to schedule all jobs within a fixed time period such that the peak load (the maximum total energy requirement at any time) is minimized. This problem has recently received significant attention due to its relevance in smart-grids. Theoretically, the problem is related to the classical strip packing problem (SP). In SP, a given set of axis-aligned rectangles must be packed into a fixed-width strip, such that the height of the strip is minimized. NPDM can be modeled as strip packing with slicing and stacking constraint: each rectangle may be cut vertically into multiple slices and the slices may be packed into the strip as individual pieces. The stacking constraint forbids solutions where two slices of the same rectangle are intersected by the same vertical line. Non-preemption enforces the slices to be placed in contiguous horizontal locations (but may be placed at different vertical locations). We obtain a $$(5/3+\varepsilon )$$ -approximation algorithm for the problem. We also provide an asymptotic efficient polynomial-time approximation scheme (AEPTAS) which generates a schedule for almost all jobs with energy consumption $$(1+\varepsilon ) {\textrm{OPT}}$$ . The remaining jobs fit into a thin container of height 1. This AEPTAS is used as a subroutine to acquire the $$(5/3+\varepsilon )$$ -approximation algorithm. The previous best result for NPDM was a 2.7-approximation based on FFDH (Ranjan et al., in: 2015 IEEE symposium on computers and communication (ISCC), pp 758–763, IEEE, 2015). One of our key ideas is providing several new lower bounds on the optimal solution of a geometric packing, which could be useful in other related problems. These lower bounds help us to obtain approximative solutions based on Steinberg’s algorithm in many cases. In addition, we show how to split schedules generated by the AEPTAS into few segments and to rearrange the corresponding jobs to insert the thin container mentioned above, such that it does not exceed the bound of $$(5/3+\varepsilon ) {\textrm{OPT}}$$ .},
  archive      = {J_Alg},
  author       = {Deppert, Max A. and Jansen, Klaus and Khan, Arindam and Rau, Malin and Tutas, Malte},
  doi          = {10.1007/s00453-023-01152-w},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3649-3679},
  shortjournal = {Algorithmica},
  title        = {Peak demand minimization via sliced strip packing},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Algebraic restriction codes and their applications.
<em>Alg</em>, <em>85</em>(12), 3602–3648. (<a
href="https://doi.org/10.1007/s00453-023-01150-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider the following problem: You have a device that is supposed to compute a linear combination of its inputs, which are taken from some finite field. However, the device may be faulty and compute arbitrary functions of its inputs. Is it possible to encode the inputs in such a way that only linear functions can be evaluated over the encodings? I.e., learning an arbitrary function of the encodings will not reveal more information about the inputs than a linear combination. In this work, we introduce the notion of algebraic restriction codes (AR codes), which constrain adversaries who might compute any function to computing a linear function. Our main result is an information-theoretic construction AR codes that restrict any class of function with a bounded number of output bits to linear functions. Our construction relies on a seed which is not provided to the adversary. While interesting and natural on its own, we show an application of this notion in cryptography. In particular, we show that AR codes lead to the first construction of rate-1 oblivious transfer with statistical sender security from the Decisional Diffie–Hellman assumption, and the first-ever construction that makes black-box use of cryptography. Previously, such protocols were known only from the LWE assumption, using non-black-box cryptographic techniques. We expect our new notion of AR codes to find further applications, e.g., in the context of non-malleability, in the future.},
  archive      = {J_Alg},
  author       = {Aggarwal, Divesh and Döttling, Nico and Dujmovic, Jesko and Hajiabadi, Mohammad and Malavolta, Giulio and Obremski, Maciej},
  doi          = {10.1007/s00453-023-01150-y},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3602-3648},
  shortjournal = {Algorithmica},
  title        = {Algebraic restriction codes and their applications},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finding geometric facilities with location privacy.
<em>Alg</em>, <em>85</em>(12), 3572–3601. (<a
href="https://doi.org/10.1007/s00453-023-01156-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine the problem of discovering the set P of points in a given topology that constitutes a k-median set for that topology, while maintaining location privacy. That is, there exists a set U of points in a d-dimensional topology for which a k-median set must be found by some algorithm A, without disclosing the location of points in U to the executor of A. We define a privacy preserving data model for a coordinate system we call a &quot;Topology Descriptor Grid&quot;, and show how it can be used to find the rectilinear 1-median of the system and a constant factor approximation for the Euclidean 1-median. We achieve a constant factor approximation for the rectilinear 2-median of a grid topology. Additionally we show upper and lower bounds for the k-center problem.},
  archive      = {J_Alg},
  author       = {Nussbaum, Eyal and Segal, Michael and Holembovskyy, Oles},
  doi          = {10.1007/s00453-023-01156-6},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3572-3601},
  shortjournal = {Algorithmica},
  title        = {Finding geometric facilities with location privacy},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Upward book embeddability of st-graphs: Complexity and
algorithms. <em>Alg</em>, <em>85</em>(12), 3521–3571. (<a
href="https://doi.org/10.1007/s00453-023-01142-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A k-page upward book embedding (kUBE) of a directed acyclic graph G is a book embeddings of G on k pages with the additional requirement that the vertices appear in a topological ordering along the spine of the book. The k UBE Testing problem, which asks whether a graph admits a kUBE, was introduced in 1999 by Heath, Pemmaraju, and Trenk (SIAM J Comput 28(4), 1999). In a companion paper, Heath and Pemmaraju (SIAM J Comput 28(5), 1999) proved that the problem is linear-time solvable for $$k=1$$ and NP-complete for $$k = 6$$ . Closing this gap has been a central question in algorithmic graph theory since then. In this paper, we make a major contribution towards a definitive answer to the above question by showing that k UBE Testing is NP-complete for $$k\ge 3$$ , even for st-graphs, i.e., acyclic directed graphs with a single source and a single sink. Indeed, our result, together with a recent work of Bekos et al. (Theor Comput Sci 946, 2023) that proves the NP-completeness of 2UBE for planar st-graphs, closes the question about the complexity of the kUBE problem for any k. Motivated by this hardness result, we then focus on the 2UBE Testing for planar st-graphs. On the algorithmic side, we present an $$O(f(\beta )\cdot n+n^3)$$ -time algorithm for 2UBE Testing, where $$\beta $$ is the branchwidth of the input graph and f is a singly-exponential function on $$\beta $$ . Since the treewidth and the branchwidth of a graph are within a constant factor from each other, this result immediately yields an FPT algorithm for st-graphs of bounded treewidth. Furthermore, we describe an O(n)-time algorithm to test whether a plane st-graph whose faces have a special structure admits a 2UBE that additionally preserves the plane embedding of the input st-graph. On the combinatorial side, we present two notable families of plane st-graphs that always admit an embedding-preserving $$2$$ UBE.},
  archive      = {J_Alg},
  author       = {Binucci, Carla and Da Lozzo, Giordano and Di Giacomo, Emilio and Didimo, Walter and Mchedlidze, Tamara and Patrignani, Maurizio},
  doi          = {10.1007/s00453-023-01142-y},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3521-3571},
  shortjournal = {Algorithmica},
  title        = {Upward book embeddability of st-graphs: Complexity and algorithms},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficiently approximating vertex cover on scale-free
networks with underlying hyperbolic geometry. <em>Alg</em>,
<em>85</em>(12), 3487–3520. (<a
href="https://doi.org/10.1007/s00453-023-01143-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding a minimum vertex cover in a network is a fundamental NP-complete graph problem. One way to deal with its computational hardness, is to trade the qualitative performance of an algorithm (allowing non-optimal outputs) for an improved running time. For the vertex cover problem, there is a gap between theory and practice when it comes to understanding this trade-off. On the one hand, it is known that it is NP-hard to approximate a minimum vertex cover within a factor of $$\sqrt{2}$$ . On the other hand, a simple greedy algorithm yields close to optimal approximations in practice. A promising approach towards understanding this discrepancy is to recognize the differences between theoretical worst-case instances and real-world networks. Following this direction, we narrow the gap between theory and practice by providing an algorithm that efficiently computes nearly optimal vertex cover approximations on hyperbolic random graphs; a network model that closely resembles real-world networks in terms of degree distribution, clustering, and the small-world property. More precisely, our algorithm computes a $$(1 + o(1))$$ -approximation, asymptotically almost surely, and has a running time of $${\mathcal {O}}(m \log (n))$$ . The proposed algorithm is an adaptation of the successful greedy approach, enhanced with a procedure that improves on parts of the graph where greedy is not optimal. This makes it possible to introduce a parameter that can be used to tune the trade-off between approximation performance and running time. Our empirical evaluation on real-world networks shows that this allows for improving over the near-optimal results of the greedy approach.},
  archive      = {J_Alg},
  author       = {Bläsius, Thomas and Friedrich, Tobias and Katzmann, Maximilian},
  doi          = {10.1007/s00453-023-01143-x},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3487-3520},
  shortjournal = {Algorithmica},
  title        = {Efficiently approximating vertex cover on scale-free networks with underlying hyperbolic geometry},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Traversability, reconfiguration, and reachability in the
gadget framework. <em>Alg</em>, <em>85</em>(11), 3453–3486. (<a
href="https://doi.org/10.1007/s00453-023-01140-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider an agent traversing a graph of “gadgets”, where each gadget has local state that changes with each traversal by the agent according to specified rules. Prior work has studied the computational complexity of deciding whether the agent can reach a specified location, a problem we call reachability. This paper introduces new goals for the agent, aiming to characterize when the computational complexity of these problems is the same or differs from that of reachability. First we characterize the complexity of universal traversal—where the goal is to traverse every gadget at least once—for DAG gadgets (partially), one-state gadgets, and reversible deterministic gadgets. Then we study the complexity of reconfiguration—where the goal is to bring the system of gadgets to a specified state. We prove many cases PSPACE-complete, and show in some cases that reconfiguration is strictly harder than reachability, while in other cases, reachability is strictly harder than reconfiguration.},
  archive      = {J_Alg},
  author       = {Ani, Joshua and Demaine, Erik D. and Diomidov, Yevhenii and Hendrickson, Dylan and Lynch, Jayson},
  doi          = {10.1007/s00453-023-01140-0},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3453-3486},
  shortjournal = {Algorithmica},
  title        = {Traversability, reconfiguration, and reachability in the gadget framework},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parameterized complexity of minimum membership dominating
set. <em>Alg</em>, <em>85</em>(11), 3430–3452. (<a
href="https://doi.org/10.1007/s00453-023-01139-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a graph $$G=(V,E)$$ and an integer k, the Minimum Membership Dominating Set (MMDS) problem seeks to find a dominating set $$S \subseteq V$$ of G such that for each $$v \in V$$ , $$\vert N[v] \cap S\vert $$ is at most k. We investigate the parameterized complexity of the problem and obtain the following results for the MMDS problem. First, we show that the MMDS problem is NP-hard even on planar bipartite graphs. Next, we show that the MMDS problem is W[1]-hard for the parameter pathwidth (and thus, for treewidth) of the input graph. Then, for split graphs, we show that the MMDS problem is W[2]-hard for the parameter k. Further, we complement the pathwidth lower bound by an FPT algorithm when parameterized by the vertex cover number of input graph. In particular, we design a $$2^{{\mathcal {O}}({\textbf {v}}{} {\textbf {c}})} \vert V\vert ^{{\mathcal {O}}(1)}$$ time algorithm for the MMDS problem where $$\textbf{vc}$$ is the vertex cover number of the input graph. Finally, we show that the running time lower bound based on ETH is tight for the vertex cover parameter.},
  archive      = {J_Alg},
  author       = {Agrawal, Akanksha and Choudhary, Pratibha and Narayanaswamy, N. S. and Nisha, K. K. and Ramamoorthi, Vijayaragunathan},
  doi          = {10.1007/s00453-023-01139-7},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3430-3452},
  shortjournal = {Algorithmica},
  title        = {Parameterized complexity of minimum membership dominating set},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The complexity of l(p, q)-edge-labelling. <em>Alg</em>,
<em>85</em>(11), 3406–3429. (<a
href="https://doi.org/10.1007/s00453-023-01120-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The L(p, q)-Edge-Labelling problem is the edge variant of the well-known L(p, q)-Labelling problem. It is equivalent to the L(p, q)-Labelling problem itself if we restrict the input of the latter problem to line graphs. So far, the complexity of L(p, q)-Edge-Labelling was only partially classified in the literature. We complete this study for all $$p,q\ge 0$$ by showing that whenever $$(p,q)\ne (0,0)$$ , the L(p, q)-Edge-Labelling problem is NP-complete. We do this by proving that for all $$p,q\ge 0$$ except $$p=q=0$$ , there is an integer k so that L (p ,  q)-Edge-k -Labelling is NP-complete.},
  archive      = {J_Alg},
  author       = {Berthe, Gaétan and Martin, Barnaby and Paulusma, Daniël and Smith, Siani},
  doi          = {10.1007/s00453-023-01120-4},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3406-3429},
  shortjournal = {Algorithmica},
  title        = {The complexity of l(p, q)-edge-labelling},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Immunization in the threshold model: A parameterized
complexity study. <em>Alg</em>, <em>85</em>(11), 3376–3405. (<a
href="https://doi.org/10.1007/s00453-023-01118-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of keeping under control the spread of harmful items in networks, such as the contagion proliferation of diseases or the diffusion of fake news. We assume the linear threshold model of diffusion where each node has a threshold that measures the node’s resistance to the contagion. We study the parameterized complexity of the problem: Given a network, a set of initially contaminated nodes, and two integers k and $$\ell $$ , is it possible to limit the diffusion to at most k other nodes of the network by immunizing at most $$\ell $$ nodes? We consider several parameters associated with the input, including the bounds k and $$\ell $$ , the maximum node degree $$\Delta $$ , the number $$\zeta $$ of initially contaminated nodes, the treewidth, and the neighborhood diversity of the network. We first give W[1] or W[2]-hardness results for each of the considered parameters. Then we give fixed-parameter algorithms for some parameter combinations.},
  archive      = {J_Alg},
  author       = {Cordasco, Gennaro and Gargano, Luisa and Rescigno, Adele A.},
  doi          = {10.1007/s00453-023-01118-y},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3376-3405},
  shortjournal = {Algorithmica},
  title        = {Immunization in the threshold model: A parameterized complexity study},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Path cover problems with length cost. <em>Alg</em>,
<em>85</em>(11), 3348–3375. (<a
href="https://doi.org/10.1007/s00453-023-01106-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a graph $$G=(V,E)$$ , a collection $$\mathcal {P}$$ of vertex-disjoint (simple) paths is called a path cover of G if every vertex $$v\in V$$ is contained in exactly one path of $$\mathcal {P}$$ . The Path Cover problem (PC for short) is to find a minimum cardinality path cover of G. In this paper, we introduce generalizations of PC, where each path is associated with a weight (cost or profit). Our problem, Minimum (Maximum) Weighted Path Cover [MinPC (MaxPC)], is defined as follows: Let $$U={0,1,\dots ,n-1}$$ . Given a graph $$G=(V,E)$$ and a weight function $$f:U\rightarrow \mathbb {R}\cup {+\infty , -\infty }$$ that defines a weight for each path based on its length, the objective of MinPC (MaxPC) is to find a path cover $$\mathcal {P}$$ of G such that the total weight of the paths in $$\mathcal {P}$$ is minimized (maximized). Let L be a subset of U, and $$P^{L}$$ be the set of paths such that each path is of length $$\ell \in L$$ . We consider Min $$P^{L}$$ PC with binary cost, i.e., the cost function is $$f(\ell ) = 1$$ if $$\ell \in L$$ ; otherwise, $$f(\ell ) = 0$$ . We also consider Max $$P^{L}$$ PC with $$f(\ell ) = \ell +1$$ , if $$\ell \in L$$ ; otherwise, $$f(\ell ) = 0$$ . Many well-known graph theoretic problems such as the Hamiltonian Path and the Maximum Matching problems can be modeled using Min $$P^{L}$$ PC and Max $$P^{L}$$ PC. In this paper, we first show that deciding whether Min $$P^{{0,1,2}}$$ PC has a 0-weight solution is NP-complete for planar bipartite graphs of maximum degree three, and consequently, (i) for any constant $$\sigma \ge 1$$ , there is no polynomial-time approximation algorithm with approximation ratio $$\sigma $$ for Min $$P^{{0,1,2}}$$ PC unless P $$=$$ NP, and (ii) Max $$P^{{3,\dots ,n-1}}$$ PC is NP-hard for the same graph class. Next, we present a polynomial-time algorithm for Min $$P^{{0,1,\dots ,k}}$$ PC on graphs with bounded treewidth for a fixed k. Lastly, we present a 4-approximation algorithm for Max $$P^{{3,\dots ,n-1}}$$ PC, which becomes a 2.5-approximation algorithm for subcubic graphs.},
  archive      = {J_Alg},
  author       = {Kobayashi, Kenya and Lin, Guohui and Miyano, Eiji and Saitoh, Toshiki and Suzuki, Akira and Utashima, Tadatoshi and Yagita, Tsuyoshi},
  doi          = {10.1007/s00453-023-01106-2},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3348-3375},
  shortjournal = {Algorithmica},
  title        = {Path cover problems with length cost},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Happy set problem on subclasses of co-comparability graphs.
<em>Alg</em>, <em>85</em>(11), 3327–3347. (<a
href="https://doi.org/10.1007/s00453-022-01081-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the complexity of the Maximum Happy Set problem on subclasses of co-comparability graphs. For a graph G and its vertex subset S, a vertex $$v \in S$$ is happy if all v’s neighbors in G are contained in S. Given a graph G and a non-negative integer k, Maximum Happy Set is the problem of finding a vertex subset S of G such that $$|S|= k$$ and the number of happy vertices in S is maximized. In this paper, we first show that Maximum Happy Set is NP-hard even for co-bipartite graphs. We then give an algorithm for n-vertex interval graphs whose running time is $$O(n^2 + k^3n)$$ ; this improves the best known running time $$O(kn^8)$$ for interval graphs. We also design algorithms for n-vertex permutation graphs and d-trapezoid graphs which run in $$O(n^2 + k^3n)$$ and $$O(n^2 + d^2(k+1)^{3d}n)$$ time, respectively. These algorithmic results provide a nice contrast to the fact that Maximum Happy Set remains NP-hard for chordal graphs, comparability graphs, and co-comparability graphs.},
  archive      = {J_Alg},
  author       = {Eto, Hiroshi and Ito, Takehiro and Miyano, Eiji and Suzuki, Akira and Tamura, Yuma},
  doi          = {10.1007/s00453-022-01081-0},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3327-3347},
  shortjournal = {Algorithmica},
  title        = {Happy set problem on subclasses of co-comparability graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Special issue dedicated to 16th international conference and
workshops on algorithms and computation, WALCOM 2022. <em>Alg</em>,
<em>85</em>(11), 3325–3326. (<a
href="https://doi.org/10.1007/s00453-023-01145-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_Alg},
  author       = {Rahman, Md. Saidur and Mutzel, Petra and Slamin},
  doi          = {10.1007/s00453-023-01145-9},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3325-3326},
  shortjournal = {Algorithmica},
  title        = {Special issue dedicated to 16th international conference and workshops on algorithms and computation, WALCOM 2022},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Publisher correction: Longest common substring with
approximately k mismatches. <em>Alg</em>, <em>85</em>(10), 3323. (<a
href="https://doi.org/10.1007/s00453-023-01119-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_Alg},
  author       = {Kociumaka, Tomasz and Radoszewski, Jakub and Starikovskaya, Tatiana},
  doi          = {10.1007/s00453-023-01119-x},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {3323},
  shortjournal = {Algorithmica},
  title        = {Publisher correction: Longest common substring with approximately k mismatches},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finding matching cuts in h-free graphs. <em>Alg</em>,
<em>85</em>(10), 3290–3322. (<a
href="https://doi.org/10.1007/s00453-023-01137-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The well-known NP-complete problem Matching Cut is to decide if a graph has a matching that is also an edge cut of the graph. We prove new complexity results for Matching Cut restricted to H-free graphs, that is, graphs that do not contain some fixed graph H as an induced subgraph. We also prove new complexity results for two recently studied variants of Matching Cut, on H-free graphs. The first variant requires that the matching cut must be extendable to a perfect matching of the graph. The second variant requires the matching cut to be a perfect matching. In particular, we prove that there exists a small constant $$r&gt;0$$ such that the first variant is NP-complete for $$P_r$$ -free graphs. This addresses a question of Bouquet and Picouleau (The complexity of the Perfect Matching-Cut problem. CoRR, arXiv:2011.03318 , (2020)). For all three problems, we give state-of-the-art summaries of their computational complexity for H-free graphs.},
  archive      = {J_Alg},
  author       = {Lucke, Felicia and Paulusma, Daniël and Ries, Bernard},
  doi          = {10.1007/s00453-023-01137-9},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {3290-3322},
  shortjournal = {Algorithmica},
  title        = {Finding matching cuts in H-free graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). A weight-scaling algorithm for f-factors of multigraphs.
<em>Alg</em>, <em>85</em>(10), 3214–3289. (<a
href="https://doi.org/10.1007/s00453-023-01127-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The challenge for graph matching algorithms is to extend known time bounds for bipartite graphs to general graphs. We discuss combinatorial algorithms for finding a maximum weight f-factor on an arbitrary multigraph, for given integral weights of magnitude at most W. (An f-factor is a subgraph whose degree function is the given function $$f:V\rightarrow {\mathbb {N}}$$ .) For simple bipartite graphs the best-known time bound for combinatorial algorithms is $$O(n^{2/3}\, m\, \log nW)$$ [Gabow and Tarjan, SIAM J Comput 18(5):1013–1036, 1989; n and m are respectively the number of vertices and edges.] A recent algorithm of Duan et al. [in: Proc. of the 47th International Colloquium on Automata, Languages, and Programming (ICALP 2020), 2020] for f-factors of simple general graphs comes within logarithmic factors of this bound, $${\widetilde{O}} (n^{2/3}\, m\, \log W)$$ . The best-known bound for bipartite multigraphs is $$O(\sqrt{\Phi }\, m\, \log \Phi W)$$ ( $$\Phi \le m$$ is the size of the f-factor, $$\Phi =\sum _{v\in V}f(v)/2$$ ). This bound is more general than the restriction to simple graphs, and is even superior on “small” simple graphs, i.e., $$\Phi =o(n^{4/3})$$ . We present an algorithm that comes within a $$\sqrt{\log \Phi }$$ factor of this bound, i.e., $$O(\sqrt{\Phi \log \Phi }\,m \,\log \Phi W)$$ . The algorithm is a direct generalization of the algorithm of Gabow and Tarjan [J ACM 38(4):815–853, 1991] for the special case of ordinary matching ( $$f\equiv 1$$ ). We present that algorithm first. Our analysis is a simplified and more concrete version of Gabow and Tarjan [J ACM 38(4):815–853, 1991] and has independent interest. Furthermore the algorithm and analysis are both incorporated, without modification, into the f-factor algorithm. To extend these ideas to f-factors, the first step is “expanding” edges (i.e., replacing an edge by a length 3 alternating path). Duan et al. [in: Proc. of the 47th International Colloquium on Automata, Languages, and Programming (ICALP 2020), 2020] uses a one-time expansion of the entire graph. In contrast, our algorithm keeps the graph small by only expanding selected edges (edges incident to blossoms, in “I(B) sets”). Expanded edges get “compressed” back to their source when no longer needed. Expansion necessitates using an alternate graph model for blossoms (we call them “e-blossoms”). Compression requires coordinating e-blossoms with standard blossoms.},
  archive      = {J_Alg},
  author       = {Gabow, Harold N.},
  doi          = {10.1007/s00453-023-01127-x},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {3214-3289},
  shortjournal = {Algorithmica},
  title        = {A weight-scaling algorithm for f-factors of multigraphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Blocking trails for f-factors of multigraphs. <em>Alg</em>,
<em>85</em>(10), 3168–3213. (<a
href="https://doi.org/10.1007/s00453-023-01126-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blocking flows were introduced by Dinic (Soviet Math Doklady 11: 1277–1280, 1970) to speed up the computation of maximum network flows. They have been used in algorithms for problems such as maximum cardinality matching of bipartite graphs Hopcroft and Karp (SIAM J Comput 2(4), 225–231, 1973) and general graphs Micali and Vazirani (in: Proceedings of the 21st Annual Symposium on Foundations of Computer Science, 17–27, 1980), maximum weight matching of general graphs Gabow and Tarjan (J ACM 38(4), 815–853, 1991), and many others. The blocking algorithm of Gabow and Tarjan (1991) for matching is based on depth-first search. We extend the depth-first search approach to find f-factors of general multigraphs. Here f is an arbitrary integral-valued function on vertices, an f-matching is a subgraph where every vertex x has degree $$\le f(x)$$ , an f-factor has equality in every degree bound. A set of blocking trails for an f-matching M is a maximal collection $$\mathcal{A}$$ of edge-disjoint augmenting trails such that $$M\bigoplus _{A\in {\mathcal{A}}} A $$ is a valid f-matching. Blocking trails are needed in efficient algorithms for maximum cardinality f-matching Huang and Pettie (Algorithmica 84(7): 1952–1992, 2022), maximum weight f-factors/matchings by scaling Duan et al. (In: Proceedings of the 47th International Colloquium on Automata, Languages, and Programming (ICALP 2020), Vol. 168 of LIPIcs, 41:1-41:17, 2020; Gabow (A weight-scaling algorithm for f-factors of multigraphs. arXiv:2010.01102 , 2020), and approximate maximum weight f-factors and f-edge covers Huang and Pettie (2022). Since these algorithms find many sets of blocking trails, the time to find blocking trails is a dominant factor in the running time. Our blocking trail algorithm runs in linear time O(m). In independent work and using a different approach, Huang and Pettie (2022) present a blocking trails algorithm using time $$O(m\alpha (m,n))$$ . As examples of the time bounds for the above applications, an approximate maximum weight f-factor is found in time $$O(m\,\alpha (m,n))$$ using Huang and Pettie (2022), and our algorithm eliminates the factor $$\alpha (m,n)$$ . Similarly a maximum weight f-factor is found in time $$O(\sqrt{\Phi \log \Phi }\, m\,\alpha (m,n)\, \log (\Phi W))\,$$ using Huang and Pettie (2022) , ( $$\Phi =\sum _{v\in V} f(v)$$ , W the maximum edge weight) and our algorithm eliminates the $$\alpha (m,n)$$ factor, making the time within a factor $$\sqrt{\log {\Phi }}$$ of the bound for bipartite multigraphs. The technical difficulty for this work stems from the fact that a fixed vertex can occur many times in a given search. This does not occur in ordinary matching or in algorithms for maximum cardinality or maximum weight f-matching. These multiple occurrences can create a new variant of blossom, the “skew blossom”. Also they can make blossoms become “incomplete”, i.e., partially processed yet still relevant in future searches.},
  archive      = {J_Alg},
  author       = {Gabow, Harold N.},
  doi          = {10.1007/s00453-023-01126-y},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {3168-3213},
  shortjournal = {Algorithmica},
  title        = {Blocking trails for f-factors of multigraphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). One-pass additive-error subset selection for <span
class="math display"><em>ℓ</em><sub><em>p</em></sub></span> subspace
approximation and (k, p)-clustering. <em>Alg</em>, <em>85</em>(10),
3144–3167. (<a
href="https://doi.org/10.1007/s00453-023-01124-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of subset selection for $$\ell _{p}$$ subspace approximation and (k, p)-clustering. Our aim is to efficiently find a small subset of data points such that solving the problem optimally for this subset gives a good approximation to solving the problem optimally for the original input. For $$\ell _{p}$$ subspace approximation, previously known subset selection algorithms based on volume sampling and adaptive sampling proposed in Deshpande and Varadarajan (STOC’07, 2007), for the general case of $$p \in [1, \infty )$$ , require multiple passes over the data. In this paper, we give a one-pass subset selection with an additive approximation guarantee for $$\ell _{p}$$ subspace approximation, for any $$p \in [1, \infty )$$ . Earlier subset selection algorithms that give a one-pass multiplicative $$(1+\epsilon )$$ approximation work under the special cases. Cohen et al. (SODA’17, 2017) gives a one-pass subset section that offers multiplicative $$(1+\epsilon )$$ approximation guarantee for the special case of $$\ell _{2}$$ subspace approximation. Mahabadi et al. (STOC’20, 2020) gives a one-pass noisy subset selection with $$(1+\epsilon )$$ approximation guarantee for $$\ell _{p}$$ subspace approximation when $$p \in {1, 2}$$ . Our subset selection algorithm gives a weaker, additive approximation guarantee, but it works for any $$p \in [1, \infty )$$ . We also focus on (k, p)-clustering, where the task is to group the data points into k clusters such that the sum of distances from points to cluster centers (raised to the power p) is minimized for $$p\in [1, \infty )$$ . The subset selection algorithms are based on $$D^p$$ sampling due to Wei (NIPS’16, 2016) which is an extension of $$D^2$$ sampling proposed in Arthur and Vassilvitskii (SODA’07, 2007). Due to the inherently adaptive nature of the $$D^p$$ sampling, these algorithms require taking multiple passes over the input. In this work, we suggest one pass subset selection for (k, p)-clustering that gives constant factor approximation with respect to the optimal solution with an additive approximation guarantee. Bachem et al. (NIPS’16, 2016) also gives one pass subset selection for k-means for $$p=2$$ ; however, our result gives a solution for a more generic problem when $$p \in [1,\infty )$$ . At the core, our contribution lies in showing a one-pass MCMC-based subset selection algorithm such that its cost incurred due to the sampled points closely approximates the corresponding optimal cost, with high probability.},
  archive      = {J_Alg},
  author       = {Deshpande, Amit and Pratap, Rameshwar},
  doi          = {10.1007/s00453-023-01124-0},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {3144-3167},
  shortjournal = {Algorithmica},
  title        = {One-pass additive-error subset selection for $$\ell _{p}$$ subspace approximation and (k, p)-clustering},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Almost universal anonymous rendezvous in the plane.
<em>Alg</em>, <em>85</em>(10), 3110–3143. (<a
href="https://doi.org/10.1007/s00453-023-01122-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two mobile agents represented by points freely moving in the plane and starting at two different positions, have to meet. The meeting, called rendezvous, occurs when agents are at distance at most r of each other and never move after this time, where r is a positive real unknown to them, called the visibility radius. Agents are anonymous and execute the same deterministic algorithm. Each agent has a set of private attributes, some or all of which can differ between agents. These attributes are: the initial position of the agent, its system of coordinates (orientation and chirality), the rate of its clock, its speed when it moves, and the time of its wake-up. If all attributes (except the initial positions) are identical and agents start at distance larger than r then they can never meet, as the distance between them can never change. However, differences between attributes make it sometimes possible to break the symmetry and accomplish rendezvous. Such instances of the rendezvous problem (formalized as lists of attributes), are called feasible. Our contribution is three-fold. We first give an exact characterization of feasible instances. Thus it is natural to ask whether there exists a single algorithm that guarantees rendezvous for all these instances. We give a strong negative answer to this question: we show two sets $$S_1$$ and $$S_2$$ of feasible instances such that none of them admits a single rendezvous algorithm valid for all instances of the set. On the other hand, we construct a single algorithm that guarantees rendezvous for all feasible instances outside of sets $$S_1$$ and $$S_2$$ . We observe that these exception sets $$S_1$$ and $$S_2$$ are geometrically very small, compared to the set of all feasible instances: they are included in low-dimension subspaces of the latter. Thus, our rendezvous algorithm handling all feasible instances other than these small sets of exceptions can be justly called almost universal.},
  archive      = {J_Alg},
  author       = {Dieudonné, Yoann and Pelc, Andrzej and Petit, Franck},
  doi          = {10.1007/s00453-023-01122-2},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {3110-3143},
  shortjournal = {Algorithmica},
  title        = {Almost universal anonymous rendezvous in the plane},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A tight <span class="math display">(3/2 + <em>ε</em>)</span>
-approximation for skewed strip packing. <em>Alg</em>, <em>85</em>(10),
3088–3109. (<a
href="https://doi.org/10.1007/s00453-023-01130-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Strip Packing problem, we are given a vertical half-strip $$[0,W]\times [0,+\infty )$$ and a collection of open rectangles of width at most W. Our goal is to find an axis-aligned (non-overlapping) packing of such rectangles into the strip such that the maximum height OPT spanned by the packing is as small as possible. It is NP-hard to approximate this problem within a factor $$(3/2-\varepsilon )$$ for any constant $$\varepsilon &gt;0$$ by a simple reduction from the Partition problem, while the current best approximation factor for it is $$(5/3+\varepsilon )$$ . It seems plausible that Strip Packing admits a $$(3/2+\varepsilon )$$ -approximation. We make progress in that direction by achieving such tight approximation guarantees for a special family of instances, which we call skewed instances. As standard in the area, for a given constant parameter $$\delta &gt;0$$ , we call large the rectangles with width at least $$\delta W$$ and height at least $$\delta OPT$$ , and skewed the remaining rectangles. If all the rectangles in the input are large, then one can easily compute the optimal packing in polynomial time (since the input can contain only a constant number of rectangles). We consider the complementary case where all the rectangles are skewed. This second case retains a large part of the complexity of the original problem; in particular, the skewed case is still NP-hard to approximate within a factor $$(3/2-\varepsilon )$$ , and we provide an (almost) tight $$(3/2+\varepsilon )$$ -approximation algorithm.},
  archive      = {J_Alg},
  author       = {Gálvez, Waldo and Grandoni, Fabrizio and Ameli, Afrouz Jabal and Jansen, Klaus and Khan, Arindam and Rau, Malin},
  doi          = {10.1007/s00453-023-01130-2},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {3088-3109},
  shortjournal = {Algorithmica},
  title        = {A tight $$(3/2+\varepsilon )$$ -approximation for skewed strip packing},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A polynomial kernel for 3-leaf power deletion. <em>Alg</em>,
<em>85</em>(10), 3058–3087. (<a
href="https://doi.org/10.1007/s00453-023-01129-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a non-negative integer $$\ell $$ , the $$\ell $$ -leaf power of a tree T is a simple graph G on the leaves of T such that two vertices are adjacent in G if and only if their distance in T is at most $$\ell $$ . We provide a polynomial kernel for the problem of deciding whether we can delete at most k vertices to make an input graph a 3-leaf power of some tree. More specifically, we present a polynomial-time algorithm for an input instance (G, k) for the problem to output an equivalent instance $$(G&#39;,k&#39;)$$ such that $$k&#39;\leqslant k$$ and $$G&#39;$$ has at most $$O(k^{14})$$ vertices.},
  archive      = {J_Alg},
  author       = {Ahn, Jungho and Eiben, Eduard and Kwon, O.-joung and Oum, Sang-il},
  doi          = {10.1007/s00453-023-01129-9},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {3058-3087},
  shortjournal = {Algorithmica},
  title        = {A polynomial kernel for 3-leaf power deletion},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Correlation clustering and two-edge-connected augmentation
for planar graphs. <em>Alg</em>, <em>85</em>(10), 3024–3057. (<a
href="https://doi.org/10.1007/s00453-023-01128-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study two problems. In correlation clustering, the input is a weighted graph, where every edge is labelled either $$\langle +\rangle $$ or $$\langle -\rangle $$ according to whether its endpoints are in the same category or in different categories. The goal is to produce a partition of the vertices into categories that tries to respect the labels of the edges. In two-edge-connected augmentation, the input is a weighted graph and a subset R of edges of the graph. The goal is to produce a minimum weight subset S of edges of the graph, such that for every edge in R, its endpoints are two-edge-connected in $$R\cup S$$ . In this paper, we study these problems under the restriction that the input graph must be planar. We give an approximation-preserving reduction from correlation clustering on planar graphs to two-edge-connected augmentation on planar graphs. We give a polynomial-time approximation scheme (PTAS) for the latter problem, yielding a PTAS for the former problem as well. The approximation scheme employs brick decompositions, which have been used in previous approximation schemes for planar graphs, but the way it uses brick decompositions is fundamentally different from previous uses.},
  archive      = {J_Alg},
  author       = {Klein, Philip N. and Mathieu, Claire and Zhou, Hang},
  doi          = {10.1007/s00453-023-01128-w},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {3024-3057},
  shortjournal = {Algorithmica},
  title        = {Correlation clustering and two-edge-connected augmentation for planar graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A general framework for enumerating equivalence classes of
solutions. <em>Alg</em>, <em>85</em>(10), 3003–3023. (<a
href="https://doi.org/10.1007/s00453-023-01131-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When a problem has more than one solution, it is often important, depending on the underlying context, to enumerate (i.e., to list) them all. Even when the enumeration can be done in polynomial delay, that is, spending no more than polynomial time to go from one solution to the next, this can be costly as the number of solutions themselves may be huge, including sometimes exponential. Furthermore, depending on the application, many of these solutions can be considered equivalent. The problem of an efficient enumeration of the equivalence classes or of one representative per class (without generating all the solutions), although identified as a need in many areas, has been addressed only for very few specific cases. In this paper, we provide a general framework that solves this problem in polynomial delay for a wide variety of optimization problems solvable by dynamic programming algorithms, and for certain types of equivalence relations between solutions.},
  archive      = {J_Alg},
  author       = {Wang, Yishu and Mary, Arnaud and Sagot, Marie-France and Sinaimeri, Blerina},
  doi          = {10.1007/s00453-023-01131-1},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {3003-3023},
  shortjournal = {Algorithmica},
  title        = {A general framework for enumerating equivalence classes of solutions},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On finding the best and worst orientations for the metric
dimension. <em>Alg</em>, <em>85</em>(10), 2962–3002. (<a
href="https://doi.org/10.1007/s00453-023-01132-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The (directed) metric dimension of a digraph D, denoted by $${{\,\mathrm{\overrightarrow{\textrm{MD}}}\,}}(D)$$ , is the size of a smallest subset S of vertices such that every two vertices of D are distinguished via their distances from the vertices in S. In this paper, we investigate the graph parameters $${{\,\textrm{BOMD}\,}}(G)$$ and $${{\,\textrm{WOMD}\,}}(G)$$ which are respectively the smallest and largest metric dimension over all orientations of G. We show that those parameters are related to several classical notions of graph theory and investigate the complexity of determining those parameters. We show that $${{\,\textrm{BOMD}\,}}(G)=1$$ if and only if G is hypotraceable (that is has a path spanning all vertices but one), and deduce that deciding whether $${{\,\textrm{BOMD}\,}}(G)\le k$$ is NP-complete for every positive integer k. We also show that $${{\,\textrm{WOMD}\,}}(G)\ge \alpha (G)-1$$ , where $$\alpha (G)$$ is the stability number of G. We then deduce that for every fixed positive integer k, we can decide in polynomial time whether $${{\,\textrm{WOMD}\,}}(G)\le k$$ . The most significant results deal with oriented forests. We provide a linear-time algorithm to compute the metric dimension of an oriented forest and a linear-time algorithm that, given a forest F, computes an orientation $$D^-$$ with smallest metric dimension (i.e. such that $${{\,\mathrm{\overrightarrow{\textrm{MD}}}\,}}(D^-)={{\,\textrm{BOMD}\,}}(F)$$ ) and an orientation $$D^+$$ with largest metric dimension (i.e. such that $${{\,\mathrm{\overrightarrow{\textrm{MD}}}\,}}(D^+)={{\,\textrm{WOMD}\,}}(F)$$ ).},
  archive      = {J_Alg},
  author       = {Araujo, Julio and Bensmail, Julien and Campos, Victor and Havet, Frédéric and Maia, A. Karolinna and Nisse, Nicolas and Silva, Ana},
  doi          = {10.1007/s00453-023-01132-0},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {2962-3002},
  shortjournal = {Algorithmica},
  title        = {On finding the best and worst orientations for the metric dimension},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parameterised counting in logspace. <em>Alg</em>,
<em>85</em>(10), 2923–2961. (<a
href="https://doi.org/10.1007/s00453-023-01114-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logarithmic space-bounded complexity classes such as $$\textbf{L} $$ and $$\textbf{NL} $$ play a central role in space-bounded computation. The study of counting versions of these complexity classes have lead to several interesting insights into the structure of computational problems such as computing the determinant and counting paths in directed acyclic graphs. Though parameterised complexity theory was initiated roughly three decades ago by Downey and Fellows, a satisfactory study of parameterised logarithmic space-bounded computation was developed only in the last decade by Elberfeld, Stockhusen and Tantau (IPEC 2013, Algorithmica 2015). In this paper, we introduce a new framework for parameterised counting in logspace, inspired by the parameterised space-bounded models developed by Elberfeld, Stockhusen and Tantau. They defined the operators $$\textbf{para}_{\textbf{W}}$$ and $$\textbf{para}_\beta $$ for parameterised space complexity classes by allowing bounded nondeterminism with multiple-read and read-once access, respectively. Using these operators, they characterised the parameterised complexity of natural problems on graphs. In the spirit of the operators $$\textbf{para}_{\textbf{W}}$$ and $$\textbf{para}_\beta $$ by Stockhusen and Tantau, we introduce variants based on tail-nondeterminism, $$\textbf{para}_{{\textbf{W}}[1]}$$ and $$\textbf{para}_{\beta {\textbf{tail}}}$$ . Then, we consider counting versions of all four operators and apply them to the class $$\textbf{L} $$ . We obtain several natural complete problems for the resulting classes: counting of paths in digraphs, counting first-order models for formulas, and counting graph homomorphisms. Furthermore, we show that the complexity of a parameterised variant of the determinant function for (0, 1)-matrices is $$\#\textbf{para}_{\beta {\textbf{tail}}}\textbf{L} $$ -hard and can be written as the difference of two functions in $$\#\textbf{para}_{\beta {\textbf{tail}}}\textbf{L} $$ . These problems exhibit the richness of the introduced counting classes. Our results further indicate interesting structural characteristics of these classes. For example, we show that the closure of $$\#\textbf{para}_{\beta {\textbf{tail}}}\textbf{L} $$ under parameterised logspace parsimonious reductions coincides with $$\#\textbf{para}_\beta \textbf{L} $$ . In other words, in the setting of read-once access to nondeterministic bits, tail-nondeterminism coincides with unbounded nondeterminism modulo parameterised reductions. Initiating the study of closure properties of these parameterised logspace counting classes, we show that all introduced classes are closed under addition and multiplication, and those without tail-nondeterminism are closed under parameterised logspace parsimonious reductions. Finally, we want to emphasise the significance of this topic by providing a promising outlook highlighting several open problems and directions for further research.},
  archive      = {J_Alg},
  author       = {Haak, Anselm and Meier, Arne and Prakash, Om and Rao, B. V. Raghavendra},
  doi          = {10.1007/s00453-023-01114-2},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {2923-2961},
  shortjournal = {Algorithmica},
  title        = {Parameterised counting in logspace},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Public bayesian persuasion: Being almost optimal and almost
persuasive. <em>Alg</em>, <em>85</em>(9), 2885–2921. (<a
href="https://doi.org/10.1007/s00453-023-01123-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study algorithmic Bayesian persuasion problems in which the principal (a.k.a. the sender) has to persuade multiple agents (a.k.a. receivers) by using public communication channels. Specifically, our model follows the multi-receiver model with no inter-agent externalities introduced by Arieli and Babichenko (J Econ Theory 182:185–217, 2019). It is known that the problem of computing a sender-optimal public persuasive signaling scheme is not approximable even in simple settings. Therefore, prior works usually focus on determining restricted classes of the problem for which efficient approximation is possible. Typically, positive results in this space amounts to finding bi-criteria approximation algorithms yielding an almost optimal and almost persuasive solution in polynomial time. In this paper, we take a different perspective and study the persuasion problem in the general setting where the space of the states of nature, the action space of the receivers, and the utility function of the sender can be arbitrary. We fully characterize the computational complexity of computing a bi-criteria approximation of an optimal public signaling scheme in such settings. In particular, we show that, assuming the Exponential Time Hypothesis, solving this problem requires at least a quasi-polynomial number of steps even in instances with simple utility functions and binary action spaces such as an election with the k-voting rule. In doing so, we prove that a relaxed version of the Maximum Feasible Subsystem of Linear Inequalities problem requires at least quasi-polynomial time to be solved. Finally, we close the gap by providing a quasi-polynomial time bi-criteria approximation algorithm for arbitrary public persuasion problems that, under mild assumptions, yields a QPTAS.},
  archive      = {J_Alg},
  author       = {Castiglioni, Matteo and Celli, Andrea and Gatti, Nicola},
  doi          = {10.1007/s00453-023-01123-1},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2885-2921},
  shortjournal = {Algorithmica},
  title        = {Public bayesian persuasion: Being almost optimal and almost persuasive},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A faster interior-point method for sum-of-squares
optimization. <em>Alg</em>, <em>85</em>(9), 2843–2884. (<a
href="https://doi.org/10.1007/s00453-023-01112-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a faster interior-point method for optimizing sum-of-squares (SOS) polynomials, which are a central tool in polynomial optimization and capture convex programming in the Lasserre hierarchy. Let $$p = \sum _i q^2_i$$ be an n-variate SOS polynomial of degree 2d. Denoting by $$L:= \left( {\begin{array}{c}n+d\\ d\end{array}}\right) $$ and $$U:= \left( {\begin{array}{c}n+2d\\ 2d\end{array}}\right) $$ the dimensions of the vector spaces in which $$q_i$$ ’s and p live respectively, our algorithm runs in time $${\tilde{O}}(LU^{1.87})$$ . This is polynomially faster than state-of-art SOS and semidefinite programming solvers, which achieve runtime $${\tilde{O}}(L^{0.5}\min {U^{2.37}, L^{4.24}})$$ . The centerpiece of our algorithm is a dynamic data structure for maintaining the inverse of the Hessian of the SOS barrier function under the polynomial interpolant basis, which efficiently extends to multivariate SOS optimization, and requires maintaining spectral approximations to low-rank perturbations of elementwise (Hadamard) products. This is the main challenge and departure from recent IPM breakthroughs using inverse-maintenance, where low-rank updates to the slack matrix readily imply the same for the Hessian matrix.},
  archive      = {J_Alg},
  author       = {Jiang, Shunhua and Natura, Bento and Weinstein, Omri},
  doi          = {10.1007/s00453-023-01112-4},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2843-2884},
  shortjournal = {Algorithmica},
  title        = {A faster interior-point method for sum-of-squares optimization},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MAX CUT in weighted random intersection graphs and
discrepancy of sparse random set systems. <em>Alg</em>, <em>85</em>(9),
2817–2842. (<a
href="https://doi.org/10.1007/s00453-023-01121-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let V be a set of n vertices, $${\mathcal M}$$ a set of m labels, and let $${\textbf{R}}$$ be an $$m \times n$$ matrix ofs independent Bernoulli random variables with probability of success p; columns of $${\textbf{R}}$$ are incidence vectors of label sets assigned to vertices. A random instance $$G(V, E, {\textbf{R}}^T {\textbf{R}})$$ of the weighted random intersection graph model is constructed by drawing an edge with weight equal to the number of common labels (namely $$[{\textbf{R}}^T {\textbf{R}}]_{v,u}$$ ) between any two vertices u, v for which this weight is strictly larger than 0. In this paper we study the average case analysis of Weighted Max Cut, assuming the input is a weighted random intersection graph, i.e. given $$G(V, E, {\textbf{R}}^T {\textbf{R}})$$ we wish to find a partition of V into two sets so that the total weight of the edges having exactly one endpoint in each set is maximized. In particular, we initially prove that the weight of a maximum cut of $$G(V, E, {\textbf{R}}^T {\textbf{R}})$$ is concentrated around its expected value, and then show that, when the number of labels is much smaller than the number of vertices (in particular, $$m=n^{\alpha }, \alpha &lt;1$$ ), a random partition of the vertices achieves asymptotically optimal cut weight with high probability. Furthermore, in the case $$n=m$$ and constant average degree (i.e. $$p = \frac{\Theta (1)}{n}$$ ), we show that with high probability, a majority type randomized algorithm outputs a cut with weight that is larger than the weight of a random cut by a multiplicative constant strictly larger than 1. Then, we formally prove a connection between the computational problem of finding a (weighted) maximum cut in $$G(V, E, {\textbf{R}}^T {\textbf{R}})$$ and the problem of finding a 2-coloring that achieves minimum discrepancy for a set system $$\Sigma $$ with incidence matrix $${\textbf{R}}$$ (i.e. minimum imbalance over all sets in $$\Sigma $$ ). We exploit this connection by proposing a (weak) bipartization algorithm for the case $$m=n, p = \frac{\Theta (1)}{n}$$ that, when it terminates, its output can be used to find a 2-coloring with minimum discrepancy in a set system with incidence matrix $${\textbf{R}}$$ . In fact, with high probability, the latter 2-coloring corresponds to a bipartition with maximum cut-weight in $$G(V, E, {\textbf{R}}^T {\textbf{R}})$$ . Finally, we prove that our (weak) bipartization algorithm terminates in polynomial time, with high probability, at least when $$p = \frac{c}{n}, c&lt;1$$ .},
  archive      = {J_Alg},
  author       = {Nikoletseas, Sotiris and Raptopoulos, Christoforos and Spirakis, Paul},
  doi          = {10.1007/s00453-023-01121-3},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2817-2842},
  shortjournal = {Algorithmica},
  title        = {MAX CUT in weighted random intersection graphs and discrepancy of sparse random set systems},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reconfiguration of spanning trees with degree constraints or
diameter constraints. <em>Alg</em>, <em>85</em>(9), 2779–2816. (<a
href="https://doi.org/10.1007/s00453-023-01117-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the complexity of finding a transformation from a given spanning tree in a graph to another given spanning tree in the same graph via a sequence of edge flips. The exchange property of the matroid bases immediately yields that such a transformation always exists if we have no constraints on spanning trees. In this paper, we wish to find a transformation which passes through only spanning trees satisfying some constraint. Our focus is bounding either the maximum degree or the diameter of spanning trees, and we give the following results. The problem with a lower bound on maximum degree is solvable in polynomial time, while the problem with an upper bound on maximum degree is PSPACE-complete. The problem with a lower bound on diameter is NP-hard, while the problem with an upper bound on diameter is solvable in polynomial time.},
  archive      = {J_Alg},
  author       = {Bousquet, Nicolas and Ito, Takehiro and Kobayashi, Yusuke and Mizuta, Haruka and Ouvrard, Paul and Suzuki, Akira and Wasa, Kunihiro},
  doi          = {10.1007/s00453-023-01117-z},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2779-2816},
  shortjournal = {Algorithmica},
  title        = {Reconfiguration of spanning trees with degree constraints or diameter constraints},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tight approximation algorithms for geometric bin packing
with skewed items. <em>Alg</em>, <em>85</em>(9), 2735–2778. (<a
href="https://doi.org/10.1007/s00453-023-01116-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Two-dimensional Bin Packing (2BP), we are given n rectangles as input and our goal is to find an axis-aligned nonoverlapping packing of these rectangles into the minimum number of unit square bins. 2BP admits no APTAS and the current best approximation ratio is 1.406 by Bansal and Khan (ACM-SIAM symposium on discrete algorithms (SODA), pp 13–25, 2014. https://doi.org/10.1137/1.9781611973402.2 ). A well-studied variant of 2BP is Guillotine Two-dimensional Bin Packing (G2BP), where rectangles must be packed in such a way that every rectangle in the packing can be obtained by applying a sequence of end-to-end axis-parallel cuts, also called guillotine cuts. Bansal et al. (Symposium on foundations of computer science (FOCS). IEEE, pp 657–666, 2005. https://doi.org/10.1109/SFCS.2005.10 ) gave an APTAS for G2BP. Let $$\lambda $$ be the smallest constant such that for every set I of items, the number of bins in the optimal solution to G2BP for I is upper bounded by $$\lambda {{\,\textrm{opt}\,}}(I) + c$$ , where $${{\,\textrm{opt}\,}}(I)$$ is the number of bins in the optimal solution to 2BP for I and c is a constant. It is known that $$4/3 \le \lambda \le 1.692$$ . Bansal and Khan (2014) conjectured that $$\lambda = 4/3$$ . The conjecture, if true, will imply a $$(4/3+\varepsilon )$$ -approximation algorithm for 2BP. Given a small constant $$\delta &gt; 0$$ , a rectangle is called large if both its height and width are at least $$\delta $$ , else it is called skewed. We make progress towards the conjecture by showing that $$\lambda = 4/3$$ when all input rectangles are skewed. We also give an APTAS for 2BP for skewed items, though general 2BP does not admit an APTAS.},
  archive      = {J_Alg},
  author       = {Khan, Arindam and Sharma, Eklavya},
  doi          = {10.1007/s00453-023-01116-0},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2735-2778},
  shortjournal = {Algorithmica},
  title        = {Tight approximation algorithms for geometric bin packing with skewed items},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Max-3-lin over non-abelian groups with universal factor
graphs. <em>Alg</em>, <em>85</em>(9), 2693–2734. (<a
href="https://doi.org/10.1007/s00453-023-01115-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The factor graph of an instance of a constraint satisfaction problem with n variables and m constraints is the bipartite graph between [m] and [n] describing which variable appears in which constraints. Thus, an instance of a CSP is completely determined by its factor graph and the list of predicates. We show optimal inapproximability of Max-3-LIN over non-Abelian groups (both in the perfect completeness case and in the imperfect completeness case), even when the factor graph is fixed. Previous reductions which proved similar optimal inapproximability results produced factor graphs that were dependent on the input instance. Along the way, we also show that these optimal hardness results hold even when we restrict the linear equations in the Max-3-LIN instances to the form $$x\cdot y\cdot z = g$$ , where x, y, z are the variables and g is a group element. We use representation theory and Fourier analysis over non-Abelian groups to analyze the reductions.},
  archive      = {J_Alg},
  author       = {Bhangale, Amey and Stanković, Aleksa},
  doi          = {10.1007/s00453-023-01115-1},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2693-2734},
  shortjournal = {Algorithmica},
  title        = {Max-3-lin over non-abelian groups with universal factor graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bitonic st-orderings for upward planar graphs: Splits and
bends in the variable embedding scenario. <em>Alg</em>, <em>85</em>(9),
2667–2692. (<a
href="https://doi.org/10.1007/s00453-023-01111-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bitonic st-orderings for st-planar graphs were introduced as a method to cope with several graph drawing problems. Notably, they have been used to obtain the best-known upper bound on the number of bends for upward planar polyline drawings with at most one bend per edge in polynomial area. For an st-planar graph that does not admit a bitonic st-ordering, one may split certain edges such that for the resulting graph such an ordering exists. Since each split is interpreted as a bend, one is usually interested in splitting as few edges as possible. While this optimization problem admits a linear-time algorithm in the fixed embedding setting, it remains open in the variable embedding setting. We close this gap in the literature by providing a linear-time algorithm that optimizes over all embeddings of the input st-planar graph. The best-known lower bound on the number of required splits of an st-planar graph with n vertices is $$n-3$$ . However, it is possible to compute a bitonic st-ordering without any split for the st-planar graph obtained by reversing the orientation of all edges. In terms of upward planar polyline drawings in polynomial area, the former translates into $$n-3$$ bends, while the latter into no bends. We show that this idea cannot always be exploited by describing an st-planar graph that needs at least $$n-5$$ splits in both orientations. We provide analogous bounds for graphs with small degree. Finally, we further investigate the relationship between splits in bitonic st-orderings and bends in upward planar polyline drawings with polynomial area, by providing bounds on the number of bends in such drawings.},
  archive      = {J_Alg},
  author       = {Angelini, Patrizio and Bekos, Michael A. and Förster, Henry and Gronemann, Martin},
  doi          = {10.1007/s00453-023-01111-5},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2667-2692},
  shortjournal = {Algorithmica},
  title        = {Bitonic st-orderings for upward planar graphs: Splits and bends in the variable embedding scenario},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computing bend-minimum orthogonal drawings of plane
series–parallel graphs in linear time. <em>Alg</em>, <em>85</em>(9),
2605–2666. (<a
href="https://doi.org/10.1007/s00453-023-01110-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A planar orthogonal drawing of a planar 4-graph G (i.e., a planar graph with vertex-degree at most four) is a crossing-free drawing that maps each vertex of G to a distinct point of the plane and each edge of G to a polygonal chain consisting of horizontal and vertical segments. A longstanding open question in Graph Drawing, dating back over 30 years, is whether there exists a linear-time algorithm to compute an orthogonal drawing of a plane 4-graph with the minimum number of bends. The term “plane” indicates that the input graph comes together with a planar embedding, which must be preserved by the drawing (i.e., the drawing must have the same set of faces as the input graph). In this paper we positively answer the question above for the widely-studied class of series–parallel graphs. Our linear-time algorithm is based on a characterization of the planar series–parallel graphs that admit an orthogonal drawing without bends. This characterization is given in terms of the orthogonal spirality that each type of triconnected component of the graph can take; the orthogonal spirality of a component measures how much that component is “rolled-up” in an orthogonal drawing of the graph.},
  archive      = {J_Alg},
  author       = {Didimo, Walter and Kaufmann, Michael and Liotta, Giuseppe and Ortali, Giacomo},
  doi          = {10.1007/s00453-023-01110-6},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2605-2666},
  shortjournal = {Algorithmica},
  title        = {Computing bend-minimum orthogonal drawings of plane Series–Parallel graphs in linear time},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Induced disjoint paths and connected subgraphs for h-free
graphs. <em>Alg</em>, <em>85</em>(9), 2580–2604. (<a
href="https://doi.org/10.1007/s00453-023-01109-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Paths $$P^1,\ldots ,P^k$$ in a graph $$G=(V,E)$$ are mutually induced if any two distinct $$P^i$$ and $$P^j$$ have neither common vertices nor adjacent vertices. The Induced Disjoint Paths problem is to decide if a graph G with k pairs of specified vertices $$(s_i,t_i)$$ contains k mutually induced paths $$P^i$$ such that each $$P^i$$ starts from $$s_i$$ and ends at $$t_i$$ . This is a classical graph problem that is NP-complete even for $$k=2$$ . We introduce a natural generalization, Induced Disjoint Connected Subgraphs: instead of connecting pairs of terminals, we must connect sets of terminals. We give almost-complete dichotomies of the computational complexity of both problems for H-free graphs, that is, graphs that do not contain some fixed graph H as an induced subgraph. Finally, we give a complete classification of the complexity of the second problem if the number k of terminal sets is fixed, that is, not part of the input.},
  archive      = {J_Alg},
  author       = {Martin, Barnaby and Paulusma, Daniël and Smith, Siani and van Leeuwen, Erik Jan},
  doi          = {10.1007/s00453-023-01109-z},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2580-2604},
  shortjournal = {Algorithmica},
  title        = {Induced disjoint paths and connected subgraphs for H-free graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Monotone arithmetic complexity of graph homomorphism
polynomials. <em>Alg</em>, <em>85</em>(9), 2554–2579. (<a
href="https://doi.org/10.1007/s00453-023-01108-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study homomorphism polynomials, which are polynomials that enumerate all homomorphisms from a pattern graph H to n-vertex graphs. These polynomials have received a lot of attention recently for their crucial role in several new algorithms for counting and detecting graph patterns, and also for obtaining natural polynomial families which are complete for algebraic complexity classes $$\textsf{VBP}$$ , $${{\textsf{V}}}{{\textsf{P}}}$$ , and $$\textsf{VNP}$$ . We discover that, in the monotone setting, the formula complexity, the ABP complexity, and the circuit complexity of such polynomial families are exactly characterized by the treedepth, the pathwidth, and the treewidth of the pattern graph respectively. Furthermore, we establish a single, unified framework, using our characterization, to collect several known results that were obtained independently via different methods. For instance, we attain superpolynomial separations between circuits, ABPs, and formulas in the monotone setting, where the polynomial families separating the classes all correspond to well-studied combinatorial problems. Moreover, our proofs rediscover fine-grained separations between these models for constant-degree polynomials.},
  archive      = {J_Alg},
  author       = {Komarath, Balagopal and Pandey, Anurag and Rahul, C. S.},
  doi          = {10.1007/s00453-023-01108-0},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2554-2579},
  shortjournal = {Algorithmica},
  title        = {Monotone arithmetic complexity of graph homomorphism polynomials},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transmitting once to elect a leader on wireless networks.
<em>Alg</em>, <em>85</em>(9), 2529–2553. (<a
href="https://doi.org/10.1007/s00453-023-01095-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed wireless network devices are mostly battery-powered. Transmitting a message on distributed wireless networks uses more energy than receiving one, which in turn uses more energy than internal computations. Therefore, in this paper, we study the problem of randomized leader election in synchronous distributed single-hop networks with a special focus on the energy complexity. We provide algorithmic solutions to the implicit version of leader election problem where non-leader nodes need not be aware of the identity of the leader. Because the size of a message impacts the energy consumption, we highlight that the solutions we propose consume very little energy: each device is allowed to send a single one-bit message only once and listen to the network during two time slots at most. We first consider four well-studied variants of the radio network (RN) model depending on the transmission and reception abilities of the participating devices: Next, we study the beeping network model. The time and energy complexities of all our algorithms are deterministic and they succeed in electing a unique leader with high probability even under the restriction that each node can only send once a single one-bit signal. When the nodes are aware of the total number n of the participants, our algorithm elects a leader in $$O(\log n)$$ rounds. When n is not known beforehand but an upper bound u on n with $$\log u = \varTheta (\log n)$$ is known by all participating nodes, we design a randomized algorithm with $$O(\log ^{2}{n})$$ time complexity for the RN models. For beeping networks, our algorithm has $$O(n^{\varepsilon })$$ time complexity ( $$0&lt;\varepsilon &lt;1$$ ). The parameter $$\varepsilon $$ can be tuned to increase the probability of success of the algorithms.},
  archive      = {J_Alg},
  author       = {Ravelomanana, Vlady and Andriambolamalala, Ny Aina},
  doi          = {10.1007/s00453-023-01095-2},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2529-2553},
  shortjournal = {Algorithmica},
  title        = {Transmitting once to elect a leader on wireless networks},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computing balanced convex partitions of lines. <em>Alg</em>,
<em>85</em>(8), 2515–2528. (<a
href="https://doi.org/10.1007/s00453-022-01082-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dujmović and Langerman (Discrete Comput Geom 49(1):74–88, 2013) proved a ham-sandwich cut theorem for an arrangement of lines in the plane. Recently, Xue and Soberón (Discrete Comput Geom 66:1150–1167, 2021) generalized it to balanced convex partitions of lines in the plane. In this paper, we study the computational problems of computing a ham-sandwich cut balanced convex partitions for an arrangement of lines in the plane. We show that both problems can be solved in polynomial time.},
  archive      = {J_Alg},
  author       = {Bereg, Sergey},
  doi          = {10.1007/s00453-022-01082-z},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2515-2528},
  shortjournal = {Algorithmica},
  title        = {Computing balanced convex partitions of lines},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Algorithms for p-faulty search on a half-line. <em>Alg</em>,
<em>85</em>(8), 2485–2514. (<a
href="https://doi.org/10.1007/s00453-022-01075-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study p-Faulty Search, a variant of the classic cow-path optimization problem, where a unit speed robot searches the half-line (or 1-ray) for a hidden item. The searcher is probabilistically faulty, and detection of the item with each visitation is an independent Bernoulli trial whose probability of success p is known. The objective is to minimize the worst case expected detection time, relative to the distance of the hidden item to the origin. A variation of the same problem was first proposed by Gal (Search games, Academic Press, New York, 1980). Alpern and Gal (The theory of search games and rendezvous, Springer, Berlin, 2003) proposed a so-called monotone solution for searching the line (2-rays); that is, a trajectory in which the newly searched space increases monotonically in each ray and in each iteration. Moreover, they conjectured that an optimal trajectory for the 2-rays problem must be monotone. We show that an analogous conjecture for the case where the search domain is the half-line cannot be correct. Indeed, we provide a lower bound for all monotone algorithms, which we also match with an upper bound. Our main contribution is the design and analysis of a sequence of refined search strategies, outside the family of monotone algorithms, which we call t-sub-monotone algorithms. Such algorithms induce performance that is strictly decreasing with t, and for all $$p \in (0,1)$$ . The value of t quantifies, in a certain sense, how much our algorithms deviate from being monotone, demonstrating that monotone algorithms are sub-optimal when searching the half-line.},
  archive      = {J_Alg},
  author       = {Bonato, Anthony and Georgiou, Konstantinos and MacRury, Calum and Prałat, Paweł},
  doi          = {10.1007/s00453-022-01075-y},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2485-2514},
  shortjournal = {Algorithmica},
  title        = {Algorithms for p-faulty search on a half-line},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Guest editorial: Special issue on theoretical informatics.
<em>Alg</em>, <em>85</em>(8), 2482–2484. (<a
href="https://doi.org/10.1007/s00453-023-01101-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_Alg},
  author       = {Kohayakawa, Yoshiharu and Miyazawa, Flávio K.},
  doi          = {10.1007/s00453-023-01101-7},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2482-2484},
  shortjournal = {Algorithmica},
  title        = {Guest editorial: Special issue on theoretical informatics},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Certifying fully dynamic algorithms for recognition and
hamiltonicity of threshold and chain graphs. <em>Alg</em>,
<em>85</em>(8), 2454–2481. (<a
href="https://doi.org/10.1007/s00453-023-01107-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving problems on graphs dynamically calls for algorithms to function under repeated modifications to the graph and to be more efficient than solving the problem for the whole graph from scratch after each modification. Dynamic algorithms have been considered for several graph properties, for example connectivity, shortest paths and graph recognition. In this paper we present fully dynamic algorithms for the recognition of threshold graphs and chain graphs, which are optimal in the sense that the costs per modification are linear in the number of modified edges. Furthermore, our algorithms also consider the addition and deletion of sets of vertices as well as edges. In the negative case, i.e., where the graph is not a threshold graph or chain graph anymore, our algorithms return a certificate of constant size. Additionally, we present optimal fully dynamic algorithms for the Hamiltonian cycle problem and the Hamiltonian path problem on threshold and chain graphs which return a vertex cutset as certificate for the non-existence of such a path or cycle in the negative case.},
  archive      = {J_Alg},
  author       = {Beisegel, Jesse and Köhler, Ekkehard and Scheffler, Robert and Strehler, Martin},
  doi          = {10.1007/s00453-023-01107-1},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2454-2481},
  shortjournal = {Algorithmica},
  title        = {Certifying fully dynamic algorithms for recognition and hamiltonicity of threshold and chain graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unique assembly verification in two-handed self-assembly.
<em>Alg</em>, <em>85</em>(8), 2427–2453. (<a
href="https://doi.org/10.1007/s00453-023-01103-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most fundamental and well-studied problems in Tile Self-Assembly is the Unique Assembly Verification (UAV) problem. This algorithmic problem asks whether a given tile system uniquely assembles a specific assembly. The complexity of this problem in the 2-Handed Assembly Model (2HAM) at a constant temperature is a long-standing open problem since the model was introduced. Previously, only membership in the class coNP was known and that the problem is in P if the temperature is one ( $$\tau =1$$ ). The problem is known to be hard for many generalizations of the model, such as allowing one step into the third dimension or allowing the temperature of the system to be a variable, but the most fundamental version has remained open. In this paper, we prove the UAV problem in the 2HAM is hard even with a small constant temperature ( $$\tau = 2$$ ), and finally answer the complexity of this problem (open since 2013). Further, this result proves that UAV in the staged self-assembly model is coNP-complete with a single bin and stage (open since 2007), and that UAV in the q-tile model is also coNP-complete (open since 2004). We reduce from Monotone Planar 3-SAT with Neighboring Variable Pairs, a special case of 3SAT recently proven to be NP-hard. We accompany this reduction with a positive result showing that UAV is solvable in polynomial time with the promise that the given target assembly will have a tree-shaped bond graph, i.e., contains no cycles. We provide a $$\mathcal {O}(n^5)$$ algorithm for UAV on tree-bonded assemblies when the temperature is fixed to 2, and a $$\mathcal {O}(n^5\log \tau )$$ time algorithm when the temperature is part of the input.},
  archive      = {J_Alg},
  author       = {Caballero, David and Gomez, Timothy and Schweller, Robert and Wylie, Tim},
  doi          = {10.1007/s00453-023-01103-5},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2427-2453},
  shortjournal = {Algorithmica},
  title        = {Unique assembly verification in two-handed self-assembly},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved merlin–arthur protocols for central problems in
fine-grained complexity. <em>Alg</em>, <em>85</em>(8), 2395–2426. (<a
href="https://doi.org/10.1007/s00453-023-01102-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a Merlin–Arthur proof system, the proof verifier (Arthur) accepts valid proofs (from Merlin) with probability 1, and rejects invalid proofs with probability arbitrarily close to 1. The running time of such a system is defined to be the length of Merlin’s proof plus the running time of Arthur. We provide new Merlin–Arthur proof systems for some key problems in fine-grained complexity. In several cases our proof systems have optimal running time. Our main results include: Due to the centrality of these problems in fine-grained complexity, our results have consequences for many other problems of interest. For example, our work implies that certifying there is no Subset Sum solution to n integers can be done in Merlin–Arthur time $$2^{n/3}\cdot \textrm{poly}(n)$$ , improving on the previous best protocol by Nederlof [IPL 2017] which took $$2^{0.49991n}\cdot \textrm{poly}(n)$$ time.},
  archive      = {J_Alg},
  author       = {Akmal, Shyan and Chen, Lijie and Jin, Ce and Raj, Malvika and Williams, Ryan},
  doi          = {10.1007/s00453-023-01102-6},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2395-2426},
  shortjournal = {Algorithmica},
  title        = {Improved Merlin–Arthur protocols for central problems in fine-grained complexity},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Resource-constrained scheduling algorithms for stochastic
independent tasks with unknown probability distribution. <em>Alg</em>,
<em>85</em>(8), 2363–2394. (<a
href="https://doi.org/10.1007/s00453-023-01100-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work introduces scheduling algorithms to maximize the expected number of independent tasks that can be executed on a parallel platform within a given budget and under a deadline constraint. The main motivation for this problem comes from imprecise computations, where each job has a mandatory part and an optional part, and the objective is to maximize the number of optional parts that are successfully executed, in order to improve the accuracy of the results. The optional parts of the jobs represent the independent tasks of our problem. Task execution times are not known before execution; instead, the only information available to the scheduler is that they obey some (unknown) probability distribution. The scheduler needs to acquire some information before deciding for a cutting threshold: instead of allowing all tasks to run until completion, one may want to interrupt long-running tasks at some point. In addition, the cutting threshold may be reevaluated as new information is acquired when the execution progresses further. This work presents several algorithms to determine a good cutting threshold, and to decide when to re-evaluate it. In particular, we use the Kaplan-Meier estimator to account for tasks that are still running when making a decision. The efficiency of our algorithms is assessed through an extensive set of simulations with various budget and deadline values, and ranging over 13 probability distributions. In particular, the AutoPerSurvival(40\%,0.005) strategy is proved to have a performance of 77\% compared to the upper bound even in the worst case. This shows the robustness of our strategy.},
  archive      = {J_Alg},
  author       = {Gao, Yiqin and Robert, Yves and Vivien, Frédéric},
  doi          = {10.1007/s00453-023-01100-8},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2363-2394},
  shortjournal = {Algorithmica},
  title        = {Resource-constrained scheduling algorithms for stochastic independent tasks with unknown probability distribution},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intersecting longest cycles in archimedean tilings.
<em>Alg</em>, <em>85</em>(8), 2348–2362. (<a
href="https://doi.org/10.1007/s00453-023-01104-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 1966 Gallai asked the following question: Do all longest paths (cycles) of a connected graph contain a common vertex? After a positive answer to Gallai’s question, another question has been raised, Is there any family of graphs without Gallai’s property? Menke found one such family, the square lattices. Embedding methods hold the promise to transform not just the way calculations are performed, but to significantly reduce computational costs and often used in quantum mechanics and material sciences. In this paper, we prove the existence of graphs with the empty intersection of their longest cycles as subgraphs of Archimedean lattices.},
  archive      = {J_Alg},
  author       = {Nadeem, Muhammad Faisal and Iqbal, Hamza and Siddiqui, Hafiz Muhammad Afzal and Azeem, Muhammad},
  doi          = {10.1007/s00453-023-01104-4},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2348-2362},
  shortjournal = {Algorithmica},
  title        = {Intersecting longest cycles in archimedean tilings},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A color-avoiding approach to subgraph counting in bounded
expansion classes. <em>Alg</em>, <em>85</em>(8), 2318–2347. (<a
href="https://doi.org/10.1007/s00453-023-01096-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an algorithm to count the number of occurrences of a pattern graph H on h vertices as an induced subgraph in a host graph G. If G belongs to a bounded expansion class, the algorithm runs in linear time, if G belongs to a nowhere dense class it runs in almost-linear time. Our design choices are motivated by the need for an approach that can be engineered into a practical implementation for sparse host graphs. Specifically, we introduce a decomposition of the pattern H called a counting dag $$\vec {C}(H)$$ which encodes an order-aware, inclusion-exclusion counting method for H. Given such a counting dag and a suitable linear ordering $$\mathbb {G}$$ of G as input, our algorithm can count the number of times H appears as an induced subgraph in G in time $$O(\Vert \vec {C}\Vert \cdot h {\text {wcol}}_{h} (\mathbb {G})^{h-1} |G|)$$ , where $$ {\text {wcol}}_{h} (\mathbb {G})$$ denotes the maximum size of the weakly h-reachable sets in $$\mathbb {G}$$ . This implies, combined with previous results, an algorithm with running time $$O((3h^2 {\text {wcol}}_{h} (G))^{h^2} |G|)$$ which only takes H and G as input. We note that with a small modification, our algorithm can instead use strongly h-reachable sets with running time $$O(\Vert \vec {C}\Vert \cdot h {\text {col}}_{h} (\mathbb {G})^{h-1} |G|)$$ , resulting in an overall complexity of $$O(h (3 {\text {col}}_{h} (G))^{h^2} |G|)$$ when only given H and G. Because orderings with small weakly/strongly reachable sets can be computed relatively efficiently in practice (Nadara et al.: in J Exp Algorithmics 103:14:1–14:16, 2018), our algorithm provides a promising alternative to algorithms using the traditional p-treedepth coloring framework (O’Brien and Sullivan in: Experimental evaluation of counting subgraph isomorphisms in classes of bounded expansion, CoRR, arXiv:1712.06690 , 2017). We describe preliminary experimental results from an initial open source implementation which highlight its potential.},
  archive      = {J_Alg},
  author       = {Reidl, Felix and Sullivan, Blair D.},
  doi          = {10.1007/s00453-023-01096-1},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2318-2347},
  shortjournal = {Algorithmica},
  title        = {A color-avoiding approach to subgraph counting in bounded expansion classes},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Near-optimal quantum algorithms for string problems.
<em>Alg</em>, <em>85</em>(8), 2260–2317. (<a
href="https://doi.org/10.1007/s00453-022-01092-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study quantum algorithms for several fundamental string problems, including Longest Common Substring, Lexicographically Minimal String Rotation, and Longest Square Substring. These problems have been widely studied in the stringology literature since the 1970s, and are known to be solvable by near-linear time classical algorithms. In this work, we give quantum algorithms for these problems with near-optimal query complexities and time complexities. Specifically, we show that: Longest Common Substring can be solved by a quantum algorithm in $$\tilde{O}(n^{2/3})$$ time, improving upon the recent $$\tilde{O}(n^{5/6})$$ -time algorithm by Le Gall and Seddighin (in: Proceedings of the 13th innovations in theoretical computer science conference (ITCS 2022), pp 97:1–97:23, 2022. https://doi.org/10.4230/LIPIcs.ITCS.2022.97 ). Our algorithm uses the MNRS quantum walk framework, together with a careful combination of string synchronizing sets (Kempa and Kociumaka, in: Proceedings of the 51st annual ACM SIGACT symposium on theory of computing (STOC 2019), ACM, pp 756–767, 2019. https://doi.org/10.1145/3313276.3316368 ) and generalized difference covers. Lexicographically Minimal String Rotation can be solved by a quantum algorithm in $$n^{1/2 + o(1)}$$ time, improving upon the recent $$\tilde{O}(n^{3/4})$$ -time algorithm by Wang and Ying (in: Quantum algorithm for lexicographically minimal string rotation. CoRR, 2020. arXiv:2012.09376 ). We design our algorithm by first giving a new classical divide-and-conquer algorithm in near-linear time based on exclusion rules, and then speeding it up quadratically using nested Grover search and quantum minimum finding. Longest Square Substring can be solved by a quantum algorithm in $$\tilde{O}(\sqrt{n})$$ time. Our algorithm is an adaptation of the algorithm by Le Gall and Seddighin (2022) for the Longest Palindromic Substring problem, but uses additional techniques to overcome the difficulty that binary search no longer applies. Our techniques naturally extend to other related string problems, such as Longest Repeated Substring, Longest Lyndon Substring, and Minimal Suffix.},
  archive      = {J_Alg},
  author       = {Akmal, Shyan and Jin, Ce},
  doi          = {10.1007/s00453-022-01092-x},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2260-2317},
  shortjournal = {Algorithmica},
  title        = {Near-optimal quantum algorithms for string problems},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online minimization of the maximum starting time: Migration
helps. <em>Alg</em>, <em>85</em>(8), 2238–2259. (<a
href="https://doi.org/10.1007/s00453-023-01097-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider non-preemptive load balancing on m identical machines where the cost of a machine is defined as the maximum starting time of a job assigned to the machine, and the goal is to find a partition of the jobs that minimizes the maximum machine cost. In our variant the last job on each machine is the smallest job assigned to that machine. The online model for this problem is too restrictive as a trivial example shows that there is no competitive algorithm for the problem. We show that a constant migration factor is sufficient to guarantee a $$(\frac{3}{2} +\varepsilon )$$ -competitive algorithm for all $$\varepsilon &gt;0$$ , and using a constant migration factor cannot lead to a better than a $$\frac{3}{2}$$ -competitive algorithm. We also show that for this problem, constant amortized migration factor is strictly more powerful and allows us to obtain a polynomial time approximation scheme with a constant amortized migration factor. Thus, the ability to move some limited set of jobs on each step allows the algorithm to be much better than in the pure online settings.},
  archive      = {J_Alg},
  author       = {Levin, Asaf},
  doi          = {10.1007/s00453-023-01097-0},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2238-2259},
  shortjournal = {Algorithmica},
  title        = {Online minimization of the maximum starting time: Migration helps},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Farthest-point voronoi diagrams in the presence of
rectangular obstacles. <em>Alg</em>, <em>85</em>(8), 2214–2237. (<a
href="https://doi.org/10.1007/s00453-022-01094-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an algorithm to compute the geodesic $$L_1$$ farthest-point Voronoi diagram of m point sites in the presence of n rectangular obstacles in the plane. It takes $$O(nm+n \log n + m\log m)$$ construction time using O(nm) space. This is the first optimal algorithm for constructing the farthest-point Voronoi diagram in the presence of obstacles. We can construct a data structure in the same construction time and space that answers a farthest-neighbor query in $$O(\log (n+m))$$ time.},
  archive      = {J_Alg},
  author       = {Kim, Mincheol and Seo, Chanyang and Ahn, Taehoon and Ahn, Hee-Kap},
  doi          = {10.1007/s00453-022-01094-9},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2214-2237},
  shortjournal = {Algorithmica},
  title        = {Farthest-point voronoi diagrams in the presence of rectangular obstacles},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the complexity of binary polynomial optimization over
acyclic hypergraphs. <em>Alg</em>, <em>85</em>(8), 2189–2213. (<a
href="https://doi.org/10.1007/s00453-022-01086-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we advance the understanding of the fundamental limits of computation for binary polynomial optimization (BPO), which is the problem of maximizing a given polynomial function over all binary points. In our main result we provide a novel class of BPO that can be solved efficiently both from a theoretical and computational perspective. In fact, we give a strongly polynomial-time algorithm for instances whose corresponding hypergraph is $$\beta $$ -acyclic. We note that the $$\beta $$ -acyclicity assumption is natural in several applications including relational database schemes and the lifted multicut problem on trees. Due to the novelty of our proving technique, we obtain an algorithm which is interesting also from a practical viewpoint. This is because our algorithm is very simple to implement and the running time is a polynomial of very low degree in the number of nodes and edges of the hypergraph. Our result completely settles the computational complexity of BPO over acyclic hypergraphs, since the problem is NP-hard on $$\alpha $$ -acyclic instances. Our algorithm can also be applied to any general BPO problem that contains $$\beta $$ -cycles. For these problems, the algorithm returns a smaller instance together with a rule to extend any optimal solution of the smaller instance to an optimal solution of the original instance.},
  archive      = {J_Alg},
  author       = {Del Pia, Alberto and Di Gregorio, Silvia},
  doi          = {10.1007/s00453-022-01086-9},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2189-2213},
  shortjournal = {Algorithmica},
  title        = {On the complexity of binary polynomial optimization over acyclic hypergraphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Computing dense and sparse subgraphs of weakly closed
graphs. <em>Alg</em>, <em>85</em>(7), 2156–2187. (<a
href="https://doi.org/10.1007/s00453-022-01090-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A graph G is weakly $$\gamma $$ -closed if every induced subgraph of G contains one vertex v such that for each non-neighbor u of v it holds that $$ \vert N(u)\cap N(v) \vert &lt;\gamma $$ . The weak closure $$\gamma (G)$$ of a graph, recently introduced by Fox et al. (SIAM J Comput 49(2):448–464, 2020), is the smallest number such that G is weakly $$\gamma $$ -closed. This graph parameter is never larger than the degeneracy (plus one) and can be significantly smaller. Extending the work of Fox et al. (2020) on clique enumeration, we show that several problems related to finding dense subgraphs, such as the enumeration of bicliques and s-plexes, are fixed-parameter tractable with respect to $$\gamma (G)$$ . Moreover, we show that the problem of determining whether a weakly $$\gamma $$ -closed graph G has a subgraph on at least k vertices that belongs to a graph class $$\mathcal {G}$$ which is closed under taking subgraphs admits a kernel with at most $$\gamma k^2$$ vertices. Finally, we provide fixed-parameter algorithms for Independent Dominating Set and Dominating Clique when parameterized by $$\gamma +k$$ where k is the solution size. Furthermore, we show that Independent Dominating Set does not admit a polynomial kernel for constant $$\gamma $$ under standard assumptions.},
  archive      = {J_Alg},
  author       = {Koana, Tomohiro and Komusiewicz, Christian and Sommer, Frank},
  doi          = {10.1007/s00453-022-01090-z},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {2156-2187},
  shortjournal = {Algorithmica},
  title        = {Computing dense and sparse subgraphs of weakly closed graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Algorithms and lower bounds for comparator circuits from
shrinkage. <em>Alg</em>, <em>85</em>(7), 2131–2155. (<a
href="https://doi.org/10.1007/s00453-022-01091-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we initiate the study of average-case complexity and circuit analysis algorithms for comparator circuits. Departing from previous approaches, we exploit the technique of shrinkage under random restrictions to obtain a variety of new results for this model. Among them, we show},
  archive      = {J_Alg},
  author       = {Cavalar, Bruno P. and Lu, Zhenjian},
  doi          = {10.1007/s00453-022-01091-y},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {2131-2155},
  shortjournal = {Algorithmica},
  title        = {Algorithms and lower bounds for comparator circuits from shrinkage},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Social distancing network creation. <em>Alg</em>,
<em>85</em>(7), 2087–2130. (<a
href="https://doi.org/10.1007/s00453-022-01089-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During a pandemic people have to find a trade-off between meeting others and staying safely at home. While meeting others is pleasant, it also increases the risk of infection. We consider this dilemma by introducing a game-theoretic network creation model in which selfish agents can form bilateral connections. They benefit from network neighbors, but at the same time, they want to maximize their distance to all other agents. This models the inherent conflict that social distancing rules impose on the behavior of selfish agents in a social network. Besides addressing this familiar issue, our model can be seen as the inverse to the well-studied Network Creation Game by Fabrikant et al. (in: PODC 2003, pp 347–351, 2003. https://doi.org/10.1145/872035.872088 ), where agents aim at being as central as possible in the created network. We look at two variants of network creation governed by social distancing. Firstly, a variant without connection restrictions, where we characterize optimal and equilibrium networks, and derive asymptotically tight bounds on the Price of Anarchy and Price of Stability. The second variant allows connection restrictions. As our main result, we prove that Swap-Maximal Routing-Cost Spanning Trees, an efficiently computable weaker variant of Maximum Routing-Cost Spanning Trees, actually resemble equilibria for a significant range of the parameter space. Moreover, we give almost tight bounds on the Price of Anarchy and Price of Stability. These results imply that under social distancing the agents’ selfishness has a strong impact on the quality of the equilibria.},
  archive      = {J_Alg},
  author       = {Friedrich, Tobias and Gawendowicz, Hans and Lenzner, Pascal and Melnichenko, Anna},
  doi          = {10.1007/s00453-022-01089-6},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {2087-2130},
  shortjournal = {Algorithmica},
  title        = {Social distancing network creation},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sub-exponential time parameterized algorithms for graph
layout problems on digraphs with bounded independence number.
<em>Alg</em>, <em>85</em>(7), 2065–2086. (<a
href="https://doi.org/10.1007/s00453-022-01093-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fradkin and Seymour (J Comb Theory Ser B 110:19–46, 2015) defined the class of digraphs of bounded independence number as a generalization of the class of tournaments. They argued that the class of digraphs of bounded independence number is structured enough to be exploited algorithmically. In this paper, we further strengthen this belief by showing that several cut problems that admit sub-exponential time parameterized algorithms (a trait uncommon to parameterized algorithms) on tournaments, including Directed Feedback Arc Set, Directed Cutwidth and Optimal Linear Arrangement, also admit such algorithms on digraphs of bounded independence number. Towards this, we rely on the generic approach of Fomin and Pilipczuk (in: Proceedings of the Algorithms—ESA 2013—21st Annual European Symposium, Sophia Antipolis, France, September 2–4, 2013, pp. 505–516, 2013), where to get the desired algorithms, it is enough to bound the number of k-cuts in digraphs of bounded independence number by a sub-exponential FPT function (Fomin and Pilipczuk bounded the number of k-cuts in transitive tournaments). Specifically, our main technical contribution is a combinatorial result that proves that the yes-instances of the problems (defined above) have a sub-exponential number of k-cuts. We prove this bound by using a combination of chromatic coding, inductive reasoning and exploiting the structural properties of these digraphs.},
  archive      = {J_Alg},
  author       = {Misra, Pranabendu and Saurabh, Saket and Sharma, Roohani and Zehavi, Meirav},
  doi          = {10.1007/s00453-022-01093-w},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {2065-2086},
  shortjournal = {Algorithmica},
  title        = {Sub-exponential time parameterized algorithms for graph layout problems on digraphs with bounded independence number},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multistage s–t path: Confronting similarity with
dissimilarity. <em>Alg</em>, <em>85</em>(7), 2028–2064. (<a
href="https://doi.org/10.1007/s00453-022-01077-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addressing a quest by Gupta et al. (in: Proceedings of the 41st international colloquium on automata, languages, and programming (ICALP 2014), vol 8572 of LNCS. Springer, pp 563–575, 2014), we provide a first, comprehensive study of finding a short s–t path in the multistage graph model, referred to as the Multistage s–t Path problem. Herein, given a sequence of graphs over the same vertex set but changing edge sets, the task is to find short s–t paths in each graph (“snapshot”) such that in the found path sequence the consecutive s–t paths are “similar”. We measure similarity by the size of the symmetric difference of either the vertex set (vertex-similarity) or the edge set (edge-similarity) of any two consecutive paths. We prove that these two variants of Multistage s–t Path are already $${\text {NP}}$$ -hard for an input sequence of only two snapshots and maximum vertex degree four. Motivated by this fact and natural applications of this scenario e.g. in traffic route planning, we perform a parameterized complexity analysis. Among other results, for both variants, vertex- and edge-similarity, we prove parameterized hardness ( $${\text {W[1]}}$$ -hardness) regarding the parameter path length (solution size). As a further conceptual investigation, we then modify the multistage model by asking for dissimilar consecutive paths. As one of the main technical results (employing so-called representative sets known from non-temporal settings), we prove that dissimilarity allows for fixed-parameter tractability for the parameter solution size, contrasting with our W[1]-hardness proof of the corresponding similarity case. We also provide partially positive results concerning efficient and effective data reduction (kernelization).},
  archive      = {J_Alg},
  author       = {Fluschnik, Till and Niedermeier, Rolf and Schubert, Carsten and Zschoche, Philipp},
  doi          = {10.1007/s00453-022-01077-w},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {2028-2064},
  shortjournal = {Algorithmica},
  title        = {Multistage s–t path: Confronting similarity with dissimilarity},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Competitive vertex recoloring. <em>Alg</em>, <em>85</em>(7),
2001–2027. (<a
href="https://doi.org/10.1007/s00453-022-01076-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by placement of jobs in physical machines, we introduce and analyze the problem of online recoloring, or online disengagement. In this problem, we are given a set of n weighted vertices and a k-coloring of the vertices (vertices represent jobs, and colors represent physical machines). Edges, representing conflicts between jobs, are inserted in an online fashion. After every edge insertion, the algorithm must output a proper k-coloring of the vertices. The cost of recoloring a vertex is the vertex’s weight. Our aim is to minimize the competitive ratio of the algorithm, i.e., the ratio between the cost paid by the online algorithm and the cost paid by an optimal, offline algorithm. We consider a couple of polynomially-solvable coloring variants. Specifically, for 2-coloring bipartite graphs we present an $$O(\log n)$$ -competitive deterministic algorithm and an $$\Omega (\log n)$$ lower bound on the competitive ratio of randomized algorithms. For $$(\Delta +1)$$ -coloring, where $$\Delta $$ is the maximal node degree, we present tight bounds of $$\Theta (\Delta )$$ and $$\Theta (\log \Delta )$$ on the competitive ratios of deterministic and randomized algorithms, respectively (where $$\Delta $$ denotes the maximum degree). We also consider the fully dynamic case which allows edge deletions as well as insertions. All our algorithms are applicable to the case where vertices are arbitrarily weighted, and all our lower bounds hold even in the uniform weights (unweighted) case.},
  archive      = {J_Alg},
  author       = {Azar, Yossi and Machluf, Chay and Patt-Shamir, Boaz and Touitou, Noam},
  doi          = {10.1007/s00453-022-01076-x},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {2001-2027},
  shortjournal = {Algorithmica},
  title        = {Competitive vertex recoloring},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Minmax centered k-partitioning of trees and applications to
sink evacuation with dynamic confluent flows. <em>Alg</em>,
<em>85</em>(7), 1948–2000. (<a
href="https://doi.org/10.1007/s00453-022-01083-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let $$T=(V,E)$$ be a tree with associated costs on its subtrees. A minmax k-partition of T is a partition into k subtrees, minimizing the maximum cost of a subtree over all possible partitions. In the centered version of the problem, the cost of a subtree is defined as the minimum cost of “servicing” that subtree using a center located within it. The problem motivating this work was the sink-evacuation problem on trees, i.e., finding a collection of k-sinks that minimize the time required by a confluent dynamic network flow to evacuate all supplies to sinks. This paper provides the first polynomial-time algorithm for solving this problem, running in $$O\Bigl ( \max (k \log k,\log n) k^2 n \log ^4 n\Bigr )$$ time. The technique developed can be used to solve any Minmax Centered k-Partitioning problem on trees in which the servicing costs satisfy some very general conditions. Solutions can be found for both the discrete case, in which centers must be on vertices, and the continuous case, in which centers may also be placed on edges. The technique developed also improves previous results for solving the sink evacuation problem on a tree, given the location of the sinks in advance.},
  archive      = {J_Alg},
  author       = {Chen, Di and Golin, Mordecai},
  doi          = {10.1007/s00453-022-01083-y},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {1948-2000},
  shortjournal = {Algorithmica},
  title        = {Minmax centered k-partitioning of trees and applications to sink evacuation with dynamic confluent flows},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Structural parameterizations for equitable coloring:
Complexity, FPT algorithms, and kernelization. <em>Alg</em>,
<em>85</em>(7), 1912–1947. (<a
href="https://doi.org/10.1007/s00453-022-01085-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An n-vertex graph is equitably k-colorable if there is a proper coloring of its vertices such that each color is used either $$\left\lfloor n/k\right\rfloor $$ or $$\left\lceil n/k\right\rceil $$ times. While classic Vertex Coloring is fixed parameter tractable under well established parameters such as pathwidth and feedback vertex set, equitable coloring is W[1]-hard. We present an extensive study of structural parameterizations of Equitable Coloring, tackling both tractability and kernelization questions. We begin by showing that the problem is fixed parameter tractable when parameterized by distance to cluster or by distance to co-cluster—improving on the FPT algorithm of Fiala et al. (Theor Comput Sci 412(23):2513–2523, 2011) parameterized by vertex cover—and also when parameterized by distance to disjoint paths of bounded length. To justify the latter result, we adapt a proof of Fellows et al. (Inf Comput 209(2):143–153, 2011) to show that Equitable Coloring is W[1]-hard when simultaneously parameterized by distance to disjoint paths and number of colors. In terms of kernelization, on the positive side we present a linear kernel for the distance to clique parameter and a cubic kernel when parameterized by the maximum leaf number; on the other hand, we show that, unlike Vertex Coloring, Equitable Coloring does not admit a polynomial kernel when jointly parameterized by vertex cover and number of colors, unless $$\textsf {NP}\subseteq \textsf {coNP}/\textsf {poly}$$ . We also revisit the literature and derive other results on the parameterized complexity of the problem through minor reductions or other observations.},
  archive      = {J_Alg},
  author       = {Gomes, Guilherme C. M. and Guedes, Matheus R. and dos Santos, Vinicius F.},
  doi          = {10.1007/s00453-022-01085-w},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {1912-1947},
  shortjournal = {Algorithmica},
  title        = {Structural parameterizations for equitable coloring: Complexity, FPT algorithms, and kernelization},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Constant-factor approximation algorithms for
parity-constrained facility location and k-center. <em>Alg</em>,
<em>85</em>(7), 1883–1911. (<a
href="https://doi.org/10.1007/s00453-022-01060-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facility location is a prominent optimization problem that has inspired a large quantity of both theoretical and practical studies in combinatorial optimization. Although the problem has been investigated under various settings reflecting typical structures within the optimization problems of practical interest, little is known on how the problem behaves in conjunction with parity constraints. This shortfall of understanding was rather discouraging when we consider the central role of parity in the field of combinatorics. In this paper, we present the first constant-factor approximation algorithm for the facility location problem with parity constraints. We are given as the input a metric on a set of facilities and clients, the opening cost of each facility, and the parity requirement– $$\textsf{odd}$$ , $$\textsf{even}$$ , or $$\textsf{unconstrained}$$ –of every facility in this problem. The objective is to open a subset of facilities and assign every client to an open facility so as to minimize the sum of the total opening costs and the assignment distances, but subject to the condition that the number of clients assigned to each open facility must have the same parity as its requirement. Although the unconstrained facility location problem as a relaxation for this parity-constrained generalization has unbounded gap, we demonstrate that it yields a structured solution whose parity violation can be corrected at small cost. This correction is prescribed by a T-join on an auxiliary graph constructed by the algorithm. This auxiliary graph does not satisfy the triangle inequality, but we show that a carefully chosen set of shortcutting operations leads to a cheap and sparse T-join. Finally, we bound the correction cost by exhibiting a combinatorial multi-step construction of an upper bound. We also consider the parity-constrained k-center problem, the bottleneck optimization variant of parity-constrained facility location. We present the first constant-factor approximation algorithm also for this problem.},
  archive      = {J_Alg},
  author       = {Kim, Kangsan and Shin, Yongho and An, Hyung-Chan},
  doi          = {10.1007/s00453-022-01060-5},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {1883-1911},
  shortjournal = {Algorithmica},
  title        = {Constant-factor approximation algorithms for parity-constrained facility location and k-center},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Complexity and approximation for discriminating and
identifying code problems in geometric setups. <em>Alg</em>,
<em>85</em>(7), 1850–1882. (<a
href="https://doi.org/10.1007/s00453-022-01073-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study geometric variations of the discriminating code problem. In the discrete version of the problem, a finite set of points P and a finite set of objects S are given in $$\mathbb {R}^d$$ . The objective is to choose a subset $$S^* \subseteq S$$ of minimum cardinality such that for each point $$p_i \in P$$ , the subset $$S_i^* \subseteq S^*$$ covering $$p_i$$ satisfies $$S_i^*\ne \emptyset $$ , and each pair $$p_i,p_j \in P$$ , $$i \ne j$$ , we have $$S_i^* \ne S_j^*$$ . In the continuous version of the problem, the solution set $$S^*$$ can be chosen freely among a (potentially infinite) class of allowed geometric objects. In the 1-dimensional case ( $$d=1$$ ), the points in P are placed on a horizontal line L, and the objects in S are finite-length line segments aligned with L (called intervals). We show that the discrete version of this problem is NP-complete. This is somewhat surprising as the continuous version is known to be polynomial-time solvable. This is also in contrast with most geometric covering problems, which are usually polynomial-time solvable in one dimension. Still for the 1-dimensional discrete version, we design a polynomial-time 2-approximation algorithm. We also design a PTAS for both discrete and continuous versions in one dimension, for the restriction where the intervals are all required to have the same length. We then study the 2-dimensional case ( $$d=2$$ ) for axis-parallel unit square objects. We show that both continuous and discrete versions are NP-complete, and design polynomial-time approximation algorithms that produce $$(16\cdot OPT+1)$$ -approximate and $$(64\cdot OPT+1)$$ -approximate solutions respectively, using rounding of suitably defined integer linear programming problems. Finally, we apply our techniques to a related variant of the discrete problem, where instead of points and geometric objects we just have a set S of objects. The goal is to select a small subset $$S^*$$ of objects so that all objects of S are discriminated by their intersection with the objects of $$S^*$$ . This problem can be viewed as a graph problem by stating it in terms of the vertices of the geometric intersection graph of S. Under this graph-theoretical form, it is known as the identifying code problem. We show that the identifying code problem for axis-parallel unit square intersection graphs (in $$d=2$$ ) can be solved in the same manner as for the discrete version of the discriminating code problem for unit square objects described above, and all our positive approximation results still hold in this setting.},
  archive      = {J_Alg},
  author       = {Dey, Sanjana and Foucaud, Florent and Nandy, Subhas C. and Sen, Arunabha},
  doi          = {10.1007/s00453-022-01073-0},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {1850-1882},
  shortjournal = {Algorithmica},
  title        = {Complexity and approximation for discriminating and identifying code problems in geometric setups},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved bounds for metric capacitated covering problems.
<em>Alg</em>, <em>85</em>(7), 1825–1849. (<a
href="https://doi.org/10.1007/s00453-022-01084-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Metric Capacitated Covering (MCC) problem, given a set of balls $${\mathcal {B}}$$ in a metric space P with metric d and a capacity parameter U, the goal is to find a minimum sized subset $${{\mathcal {B}}}&#39;\subseteq {\mathcal {B}}$$ and an assignment of the points in P to the balls in $${\mathcal {B}}&#39;$$ such that each point is assigned to a ball that contains it and each ball is assigned with at most U points. MCC achieves an $$O(\log |P|)$$ -approximation using a greedy algorithm. On the other hand, it is hard to approximate within a factor of $$o(\log |P|)$$ even with $$\beta &lt; 3$$ factor expansion of the balls. Bandyapadhyay et al. [Discrete and Computational Geometry 2019] showed that one can obtain an O(1)-approximation for the problem with 6.47 factor expansion of the balls. An open question left by their work is to reduce the gap between the lower bound 3 and the upper bound 6.47. In this current work, we show that it is possible to obtain an O(1)-approximation with only 4.24 factor expansion of the balls. Moreover, we show a similar upper bound of 5 for a more generalized version of MCC for which the best previously known bound was 9. We also study a closely related problem where instead of the upper bound, one needs to satisfy a lower bound on the number of points assigned to each ball in the solution. For this problem, we give an exact algorithm with only 5.83 factor expansion of the balls. All of our algorithms are based on LP rounding schemes that heavily exploit structure of fractional optimal solution.},
  archive      = {J_Alg},
  author       = {Bandyapadhyay, Sayan},
  doi          = {10.1007/s00453-022-01084-x},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {1825-1849},
  shortjournal = {Algorithmica},
  title        = {Improved bounds for metric capacitated covering problems},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Better distance labeling for unweighted planar graphs.
<em>Alg</em>, <em>85</em>(6), 1805–1823. (<a
href="https://doi.org/10.1007/s00453-023-01133-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A distance labeling scheme is an assignment of labels, that is, binary strings, to all nodes of a graph, so that the distance between any two nodes can be computed from their labels without any additional information about the graph. The goal is to minimize the maximum length of a label as a function of the number of nodes. A major open problem in this area is to determine the complexity of distance labeling in unweighted planar (undirected) graphs. It is known that, in such a graph on n nodes, some labels must consist of $$\varOmega (n^{1/3})$$ bits, but the best known labeling scheme constructs labels of length $$O(\sqrt{n}\log n)$$ (Gavoille, Peleg, Pérennes, and Raz in J Algorithms 53:85–112, 2004). For weighted planar graphs with edges of length polynomial in n, we know that labels of length $$\varOmega (\sqrt{n}\log n)$$ are necessary (Abboud and Dahlgaard in FOCS, 2016). Surprisingly, we do not know if distance labeling for weighted planar graphs with edges of length polynomial in n is harder than distance labeling for unweighted planar graphs. We prove that this is indeed the case by designing a distance labeling scheme for unweighted planar graphs on n nodes with labels consisting of $$O(\sqrt{n})$$ bits with a simple and (in our opinion) elegant method. We also show how to extend this to graphs with small weight and (unweighted) graphs with bounded genus. We augment the construction for unweighted planar graphs with a mechanism (based on Voronoi diagrams) that allows us to compute the distance between two nodes in only polylogarithmic time while increasing the length to $$O(\sqrt{n\log n})$$ . The previous scheme required $$\varOmega (\sqrt{n})$$ time to answer a query in this model.},
  archive      = {J_Alg},
  author       = {Gawrychowski, Paweł and Uznański, Przemysław},
  doi          = {10.1007/s00453-023-01133-z},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1805-1823},
  shortjournal = {Algorithmica},
  title        = {Better distance labeling for unweighted planar graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic dictionaries for multisets and counting filters with
constant time operations. <em>Alg</em>, <em>85</em>(6), 1786–1804. (<a
href="https://doi.org/10.1007/s00453-022-01057-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We resolve the open problem posed by Arbitman, Naor, and Segev [FOCS 2010] of designing a dynamic dictionary for multisets in the following setting: (1) The dictionary supports multiplicity queries and allows insertions and deletions to the multiset. (2) The dictionary is designed to support multisets of cardinality at most n (i.e., including multiplicities). (3) The space required for the dictionary is $$(1+o(1))\cdot n\log \frac{u}{n} + \varTheta (n)$$ bits, where u denotes the cardinality of the universe of the elements. This space is $$1+o(1)$$ times the information-theoretic lower bound for static dictionaries over multisets of cardinality n if $$u=\omega (n)$$ . (4) All operations are completed in constant time in the worst case with high probability in the word RAM model. A direct consequence of our construction is the first dynamic counting filter (i.e., a dynamic data structure that supports approximate multiplicity queries with a one-sided error) that, with high probability, supports operations in constant time and requires space that is $$1+o(1)$$ times the information-theoretic lower bound for filters plus O(n) bits. The main technical component of our solution is based on efficiently storing variable-length bounded binary counters and its analysis via weighted balls-into-bins experiments in which the weight of a ball is logarithmic in its multiplicity.},
  archive      = {J_Alg},
  author       = {Bercea, Ioana O. and Even, Guy},
  doi          = {10.1007/s00453-022-01057-0},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1786-1804},
  shortjournal = {Algorithmica},
  title        = {Dynamic dictionaries for multisets and counting filters with constant time operations},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Constructing the first (and coolest) fixed-content universal
cycle. <em>Alg</em>, <em>85</em>(6), 1754–1785. (<a
href="https://doi.org/10.1007/s00453-022-01047-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explicitly construct the first universal cycles for strings with fixed-content—also known as strings with the same Parikh vector, or multiset permutations—using their shorthand encoding, which omits the final symbol as it is redundant. For example, 112312131132 is a universal cycle for content $$S = {1,1,2,3}$$ . Its first three windows—112, 123, and 231—are the shorthand representatives of 1123, 1231, and 2311, respectively. Our first construction $$\mathcal {V}(S)$$ applies the classic cycle-joining approach on the first-inversion tree of necklace cycles with content S. For example, when $$S = {1,1,2,3}$$ the root is the necklace cycle 1123 and its children are $$1\underline{21}3$$ and $$11\underline{32}$$ by swapping their first (i.e., leftmost) inversions. From this construction, we derive a successor rule to generate successive symbols of $$\mathcal {V}(S)$$ in O(n)-time, where $$n=|S|$$ is the cardinality of S. Our second construction $$\mathcal {U}(S)$$ concatenates fixed-content necklaces together in a cool-lex order using the necklace-prefix algorithm. For example, $$\mathcal {U}(S) = 1123 \cdot 1213 \cdot 1132$$ for $$S = {1,1,2,3}$$ . Central to this construction is the first shift Gray code for fixed-content necklaces, and a new efficient algorithm for generating these strings. From this construction, we can generate successive symbols of $$\mathcal {U}(S)$$ in O(1)-amortized time while using O(n)-space. We complete our investigation with a pleasant surprise: $$\mathcal {V}(S) = \mathcal {U}(S)$$ . Our new results simultaneously generalize universal cycle constructions of shorthand permutations by Ruskey et al. (Algorithmica 64, 2012) and shorthand fixed-weight binary strings by Ruskey et al. (SIAM J Disc Math 26(2):605–617, 2012). They also provide a prefix-shift Gray code for multiset permutations in which the first symbol moves into the last or second-last position, which tightens the previous prefix-shift Gray code by Williams (Proceedings of the Twentieth Annual ACM-SIAM Symposium on Discrete Algorithms, 2009). Finally, we draw parallels between our constructions and the well-known granddaddy de Bruijn sequence for binary strings.},
  archive      = {J_Alg},
  author       = {Sawada, Joe and Williams, Aaron},
  doi          = {10.1007/s00453-022-01047-2},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1754-1785},
  shortjournal = {Algorithmica},
  title        = {Constructing the first (and coolest) fixed-content universal cycle},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A stronger lower bound on parametric minimum spanning trees.
<em>Alg</em>, <em>85</em>(6), 1738–1753. (<a
href="https://doi.org/10.1007/s00453-022-01024-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove that, for an undirected graph with n vertices and m edges, each labeled with a linear function of a parameter $$\lambda $$ , the number of different minimum spanning trees obtained as the parameter varies can be $$\Omega (m\log n)$$ .},
  archive      = {J_Alg},
  author       = {Eppstein, David},
  doi          = {10.1007/s00453-022-01024-9},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1738-1753},
  shortjournal = {Algorithmica},
  title        = {A stronger lower bound on parametric minimum spanning trees},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Preface to the special issue on the 17th algorithms and data
structures symposium (WADS 2021). <em>Alg</em>, <em>85</em>(6),
1736–1737. (<a
href="https://doi.org/10.1007/s00453-023-01113-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_Alg},
  author       = {He, Meng and Lubiw, Anna and Salavatipour, Mohammad},
  doi          = {10.1007/s00453-023-01113-3},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1736-1737},
  shortjournal = {Algorithmica},
  title        = {Preface to the special issue on the 17th algorithms and data structures symposium (WADS 2021)},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Essentially tight kernels for (weakly) closed graphs.
<em>Alg</em>, <em>85</em>(6), 1706–1735. (<a
href="https://doi.org/10.1007/s00453-022-01088-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study kernelization of classic hard graph problems when the input graphs fulfill triadic closure properties. More precisely, we consider the recently introduced parameters closure number c and weak closure number $$\gamma $$ (Fox et al. SIAM J Comput 49(2):448–464, 2020) in addition to the standard parameter solution size k. The weak closure number $$\gamma $$ of a graph is upper-bounded by the minimum of its closure number c and its degeneracy d. For Capacitated Vertex Cover, Connected Vertex Cover, and Induced Matching we obtain the first kernels of size $$k^{\mathcal {O}(\gamma )}$$ , $$k^{\mathcal {O}(\gamma )}$$ , and $$(\gamma k)^{\mathcal {O}(\gamma )}$$ , respectively. This extends previous results on the kernelization of these problems on degenerate graphs. These kernels are essentially tight as these problems are unlikely to admit kernels of size $$k^{o(\gamma )}$$ by previous results on their kernelization complexity on degenerate graphs (Cygan et al. ACM Trans Algorithms 13(3):43:1–43:22, 2017). For Capacitated Vertex Cover, we show that even a kernel of size $$k^{o(c)}$$ is unlikely. In contrast, for Connected Vertex Cover, we obtain a kernel with $$\mathcal {O}(ck^2)$$ vertices. Moreover, we prove that searching for an induced subgraph of order at least k belonging to a hereditary graph class $$\mathcal {G}$$ admits a kernel of size $$k^{\mathcal {O}(\gamma )}$$ when $$\mathcal {G}$$ contains all complete and all edgeless graphs. Finally, we provide lower bounds for the kernelization of Independent Set on graphs with constant closure number c and kernels for Dominating Set on weakly closed split graphs and weakly closed bipartite graphs.},
  archive      = {J_Alg},
  author       = {Koana, Tomohiro and Komusiewicz, Christian and Sommer, Frank},
  doi          = {10.1007/s00453-022-01088-7},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1706-1735},
  shortjournal = {Algorithmica},
  title        = {Essentially tight kernels for (Weakly) closed graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Shortest beer path queries in outerplanar graphs.
<em>Alg</em>, <em>85</em>(6), 1679–1705. (<a
href="https://doi.org/10.1007/s00453-022-01045-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A beer graph is an undirected graph G, in which each edge has a positive weight and some vertices have a beer store. A beer path between two vertices u and v in G is any path in G between u and v that visits at least one beer store. We show that any outerplanar beer graph G with n vertices can be preprocessed in O(n) time into a data structure of size O(n), such that for any two query vertices u and v, (i) the weight of the shortest beer path between u and v can be reported in $$O(\alpha (n))$$ time (where $$\alpha (n)$$ is the inverse Ackermann function), and (ii) the shortest beer path between u and v can be reported in O(L) time, where L is the number of vertices on this path. Note that the running time for (ii) does not depend on the number of vertices of G. Both results are optimal, even when G is a beer tree (i.e., a beer graph whose underlying graph is a tree).},
  archive      = {J_Alg},
  author       = {Bacic, Joyce and Mehrabi, Saeed and Smid, Michiel},
  doi          = {10.1007/s00453-022-01045-4},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1679-1705},
  shortjournal = {Algorithmica},
  title        = {Shortest beer path queries in outerplanar graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Clique-based separators for geometric intersection graphs.
<em>Alg</em>, <em>85</em>(6), 1652–1678. (<a
href="https://doi.org/10.1007/s00453-022-01041-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let F be a set of n objects in the plane and let $$\mathcal {G}^{\times }(F)$$ be its intersection graph. A balanced clique-based separator of $$\mathcal {G}^{\times }(F)$$ is a set $$\mathcal {\mathcal {S}}$$ consisting of cliques whose removal partitions $$\mathcal {G}^{\times }(F)$$ into components of size at most $$\delta n$$ , for some fixed constant $$\delta &lt;1$$ . The weight of a clique-based separator is defined as $$\sum _{C\in \mathcal {\mathcal {S}}}\log (|C|+1)$$ . Recently De Berg et al. (SIAM J. Comput. 49: 1291-1331. 2020) proved that if S consists of convex fat objects, then $$\mathcal {G}^{\times }(F)$$ admits a balanced clique-based separator of weight $$O(\sqrt{n})$$ . We extend this result in several directions, obtaining the following results. (i) Map graphs admit a balanced clique-based separator of weight $$O(\sqrt{n})$$ , which is tight in the worst case. (ii) Intersection graphs of pseudo-disks admit a balanced clique-based separator of weight $$O(n^{2/3}\log n)$$ . If the pseudo-disks are polygonal and of total complexity O(n) then the weight of the separator improves to $$O(\sqrt{n}\log n)$$ . (iii) Intersection graphs of geodesic disks inside a simple polygon admit a balanced clique-based separator of weight $$O(n^{2/3}\log n)$$ . (iv) Visibility-restricted unit-disk graphs in a polygonal domain with r reflex vertices admit a balanced clique-based separator of weight $$O(\sqrt{n}+r\log (n/r))$$ , which is tight in the worst case. These results immediately imply sub-exponential algorithms for Maximum Independent Set (and, hence, Vertex Cover), for Feedback Vertex Set, and for q-Coloring for constant q in these graph classes.},
  archive      = {J_Alg},
  author       = {de Berg, Mark and Kisfaludi-Bak, Sándor and Monemizadeh, Morteza and Theocharous, Leonidas},
  doi          = {10.1007/s00453-022-01041-8},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1652-1678},
  shortjournal = {Algorithmica},
  title        = {Clique-based separators for geometric intersection graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Resilient level ancestor, bottleneck, and lowest common
ancestor queries in dynamic trees. <em>Alg</em>, <em>85</em>(6),
1624–1651. (<a
href="https://doi.org/10.1007/s00453-022-01046-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of designing a resilient data structure maintaining a tree under the Faulty-RAM model [Finocchi and Italiano, STOC’04] in which up to $$\delta $$ memory words can be corrupted by an adversary. Our data structure stores a rooted dynamic tree that can be updated via the addition of new leaves, requires linear size, and supports resilient (weighted) level ancestor queries, lowest common ancestor queries, and bottleneck vertex queries in $$O(\delta )$$ worst-case time per operation.},
  archive      = {J_Alg},
  author       = {Gualà, Luciano and Leucci, Stefano and Ziccardi, Isabella},
  doi          = {10.1007/s00453-022-01046-3},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1624-1651},
  shortjournal = {Algorithmica},
  title        = {Resilient level ancestor, bottleneck, and lowest common ancestor queries in dynamic trees},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Algorithms and complexity on indexing founder graphs.
<em>Alg</em>, <em>85</em>(6), 1586–1623. (<a
href="https://doi.org/10.1007/s00453-022-01007-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of matching a string in a labeled graph. Previous research has shown that unless the Orthogonal Vectors Hypothesis (OVH) is false, one cannot solve this problem in strongly sub-quadratic time, nor index the graph in polynomial time to answer queries efficiently (Equi et al. ICALP 2019, SOFSEM 2021). These conditional lower-bounds cover even deterministic graphs with binary alphabet, but there naturally exist also graph classes that are easy to index: For example, Wheeler graphs (Gagie et al. Theor. Comp. Sci. 2017) cover graphs admitting a Burrows-Wheeler transform -based indexing scheme. However, it is NP-complete to recognize if a graph is a Wheeler graph (Gibney, Thankachan, ESA 2019). We propose an approach to alleviate the construction bottleneck of Wheeler graphs. Rather than starting from an arbitrary graph, we study graphs induced from multiple sequence alignments (MSAs). Elastic degenerate strings (Bernadini et al. SPIRE 2017, ICALP 2019) can be seen as such graphs, and we introduce here their generalization: elastic founder graphs. We first prove that even such induced graphs are hard to index under OVH. Then we introduce two subclasses, repeat-free and semi-repeat-free graphs, that are easy to index. We give a linear time algorithm to construct a repeat-free (non-elastic) founder graph from a gapless MSA, and (parameterized) near-linear time algorithms to construct a semi-repeat-free (repeat-free, respectively) elastic founder graph from general MSA. Finally, we show that repeat-free founder graphs admit a reduction to Wheeler graphs in polynomial time.},
  archive      = {J_Alg},
  author       = {Equi, Massimo and Norri, Tuukka and Alanko, Jarno and Cazaux, Bastien and Tomescu, Alexandru I. and Mäkinen, Veli},
  doi          = {10.1007/s00453-022-01007-w},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1586-1623},
  shortjournal = {Algorithmica},
  title        = {Algorithms and complexity on indexing founder graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine covering in the random-order model. <em>Alg</em>,
<em>85</em>(6), 1560–1585. (<a
href="https://doi.org/10.1007/s00453-022-01011-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Online Machine Covering problem, jobs, defined by their sizes, arrive one by one and have to be assigned to m parallel and identical machines, with the goal of maximizing the load of the least-loaded machine. Unfortunately, the classical model allows only fairly pessimistic performance guarantees: The best possible deterministic ratio of m is achieved by the Greedy-strategy, and the best known randomized algorithm has competitive ratio $${\tilde{O}}(\sqrt{m})$$ , which cannot be improved by more than a logarithmic factor. Modern results try to mitigate this by studying semi-online models, where additional information about the job sequence is revealed in advance or extra resources are provided to the online algorithm. In this work, we study the Machine Covering problem in the recently popular random-order model. Here, no extra resources are present but, instead, the adversary is weakened in that it can only decide upon the input set while jobs are revealed uniformly at random. It is particularly relevant to Machine Covering where lower bounds are usually associated to highly structured input sequences. We first analyze Graham’s Greedy-strategy in this context and establish that its competitive ratio decreases slightly to $$\Theta \left( \frac{m}{\log (m)}\right) $$ , which is asymptotically tight. Then, as our main result, we present an improved $${\tilde{O}}(\root 4 \of {m})$$ -competitive algorithm for the problem. This result is achieved by exploiting the extra information coming from the random order of the jobs, using sampling techniques to devise an improved mechanism to distinguish jobs that are relatively large from small ones. We complement this result with a first lower bound, showing that no algorithm can have a competitive ratio of $$O\left( \frac{\log (m)}{\log \log (m)}\right) $$ in the random-order model. This lower bound is achieved by studying a novel variant of the Secretary problem, which could be of independent interest.},
  archive      = {J_Alg},
  author       = {Albers, Susanne and Gálvez, Waldo and Janke, Maximilian},
  doi          = {10.1007/s00453-022-01011-0},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1560-1585},
  shortjournal = {Algorithmica},
  title        = {Machine covering in the random-order model},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the kernel and related problems in interval digraphs.
<em>Alg</em>, <em>85</em>(6), 1522–1559. (<a
href="https://doi.org/10.1007/s00453-022-01010-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a digraph G, a set $$X\subseteq V(G)$$ is said to be an absorbing set (resp. dominating set) if every vertex in the graph is either in X or is an in-neighbour (resp. out-neighbour) of a vertex in X. A set $$S\subseteq V(G)$$ is said to be an independent set if no two vertices in S are adjacent in G. A kernel (resp. solution) of G is an independent and absorbing (resp. dominating) set in G. The problem of deciding if there is a kernel (or solution) in an input digraph is known to be NP-complete. Similarly, the problems of computing a minimum cardinality dominating set or absorbing set or kernel, and the problems of computing a maximum cardinality independent set or kernel, are all known to be NP-hard for general digraphs. We explore the algorithmic complexity of these problems in the well known class of interval digraphs. A digraph G is an interval digraph if a pair of intervals $$(S_u,T_u)$$ can be assigned to each vertex u of G such that $$(u,v)\in E(G)$$ if and only if $$S_u\cap T_v\ne \emptyset $$ . Many different subclasses of interval digraphs have been defined and studied in the literature by restricting the kinds of pairs of intervals that can be assigned to the vertices. We observe that several of these classes, like interval catch digraphs, interval nest digraphs, adjusted interval digraphs and chronological interval digraphs, are subclasses of the more general class of reflexive interval digraphs—which arise when we require that the two intervals assigned to a vertex have to intersect. We see as our main contribution the identification of the class of reflexive interval digraphs as an important class of digraphs. We show that while the problems mentioned above are NP-complete, and even hard to approximate, on interval digraphs (even on some very restricted subclasses of interval digraphs called point-point digraphs, where the two intervals assigned to each vertex are required to be degenerate), they are all efficiently solvable, in most of the cases linear-time solvable, in the class of reflexive interval digraphs. The results we obtain improve and generalize several existing algorithms and structural results for subclasses of reflexive interval digraphs. In particular, we obtain a vertex ordering characterization of reflexive interval digraphs that implies the existence of an $$O(n+m)$$ time algorithm for computing a maximum cardinality independent set in a reflexive interval digraph, improving and generalizing the earlier known O(nm) time algorithm for the same problem for the interval nest digraphs. (Here m denotes the number of edges in the digraph not counting the self-loops.) We also show that reflexive interval digraphs are kernel-perfect and that a kernel in such digraphs can be computed in linear time. This generalizes and improves an earlier result that interval nest digraphs are kernel-perfect and that a kernel can be computed in such digraphs in O(nm) time. The structural characterizations that we show for point-point digraphs, apart from helping us construct the NP-completeness/APX-hardness reductions, imply that these digraphs can be recognized in linear time. We also obtain some new results for undirected graphs along the way: (a) We describe an $$O(n(n+m))$$ time algorithm for computing a minimum cardinality (undirected) independent dominating set in cocomparability graphs, which slightly improves the existing $$O(n^3)$$ time algorithm for the same problem by Kratsch and Stewart; and (b) We show that the Red-Blue Dominating Set problem, which is NP-complete even for planar bipartite graphs, is linear-time solvable on interval bigraphs, which is a class of bipartite (undirected) graphs closely related to interval digraphs.},
  archive      = {J_Alg},
  author       = {Francis, Mathew C. and Hell, Pavol and Jacob, Dalu},
  doi          = {10.1007/s00453-022-01010-1},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1522-1559},
  shortjournal = {Algorithmica},
  title        = {On the kernel and related problems in interval digraphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Special issue on algorithms and computation (ISAAC 2021).
<em>Alg</em>, <em>85</em>(6), 1521. (<a
href="https://doi.org/10.1007/s00453-023-01134-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_Alg},
  doi          = {10.1007/s00453-023-01134-y},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1521},
  shortjournal = {Algorithmica},
  title        = {Special issue on algorithms and computation (ISAAC 2021)},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Approximate nearest neighbor for curves: Simple, efficient,
and deterministic. <em>Alg</em>, <em>85</em>(5), 1490–1519. (<a
href="https://doi.org/10.1007/s00453-022-01080-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the $$(1+{\varepsilon },r)$$ -approximate near-neighbor problem for curves (ANNC) under some similarity measure $$\delta $$ , the goal is to construct a data structure for a given set $$\mathcal {C}$$ of curves that supports approximate near-neighbor queries: Given a query curve Q, if there exists a curve $$C\in \mathcal {C}$$ such that $$\delta (Q,C)\le r$$ , then return a curve $$C&#39;\in \mathcal {C}$$ with $$\delta (Q,C&#39;)\le (1+{\varepsilon })r$$ . There exists an efficient reduction from the $$(1+{\varepsilon })$$ -approximate nearest-neighbor problem to ANNC, where in the former problem the answer to a query is a curve $$C\in \mathcal {C}$$ with $$\delta (Q,C)\le (1+{\varepsilon })\cdot \delta (Q,C^*)$$ , where $$C^*$$ is the curve of $$\mathcal {C}$$ most similar to Q. Given a set $$\mathcal {C}$$ of n curves, each consisting of m points in d dimensions, we construct a data structure for ANNC that uses $$n\cdot O(\frac{1}{{\varepsilon }})^{md}$$ storage space and has O(md) query time (for a query curve of length m), where the similarity measure between two curves is their discrete Fréchet or dynamic time warping distance. Our method is simple to implement, deterministic, and results in an exponential improvement in both query time and storage space compared to all previous bounds. Further, we also consider the asymmetric version of ANNC, where the length of the query curves is $$k \ll m$$ , and obtain essentially the same storage and query bounds as above, except that m is replaced by k. Finally, we apply our method to a version of approximate range counting for curves and achieve similar bounds.},
  archive      = {J_Alg},
  author       = {Filtser, Arnold and Filtser, Omrit and Katz, Matthew J.},
  doi          = {10.1007/s00453-022-01080-1},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1490-1519},
  shortjournal = {Algorithmica},
  title        = {Approximate nearest neighbor for curves: Simple, efficient, and deterministic},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fair allocation of indivisible items with conflict graphs.
<em>Alg</em>, <em>85</em>(5), 1459–1489. (<a
href="https://doi.org/10.1007/s00453-022-01079-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the fair allocation of indivisible items to several agents and add a graph theoretical perspective to this classical problem. Namely, we introduce an incompatibility relation between pairs of items described in terms of a conflict graph. Every subset of items assigned to one agent has to form an independent set in this graph. Thus, the allocation of items to the agents corresponds to a partial coloring of the conflict graph. Every agent has its own profit valuation for every item. Aiming at a fair allocation, our goal is the maximization of the lowest total profit of items allocated to any one of the agents. The resulting optimization problem contains, as special cases, both Partition and Independent Set. In our contribution we derive complexity and algorithmic results depending on the properties of the given graph. We show that the problem is strongly NP-hard for bipartite graphs and their line graphs, and solvable in pseudo-polynomial time for the classes of chordal graphs, cocomparability graphs, biconvex bipartite graphs, and graphs of bounded treewidth. Each of the pseudo-polynomial algorithms can also be turned into a fully polynomial approximation scheme (FPTAS).},
  archive      = {J_Alg},
  author       = {Chiarelli, Nina and Krnc, Matjaž and Milanič, Martin and Pferschy, Ulrich and Pivač, Nevena and Schauer, Joachim},
  doi          = {10.1007/s00453-022-01079-8},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1459-1489},
  shortjournal = {Algorithmica},
  title        = {Fair allocation of indivisible items with conflict graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online bin packing of squares and cubes. <em>Alg</em>,
<em>85</em>(5), 1415–1458. (<a
href="https://doi.org/10.1007/s00453-022-01078-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the d-dimensional online bin packing problem, d-dimensional cubes of positive sizes no larger than 1 are presented one by one to be assigned to positions in d-dimensional unit cube bins. In this work, we provide improved upper bounds on the asymptotic competitive ratio for square and cube bin packing problems, where our bounds do not exceed 2.0885 and 2.5735 for square and cube packing, respectively. To achieve these results, we adapt and improve a previously designed harmonic-type algorithm, and apply a different method for defining weight functions. We detect deficiencies in the state-of-the-art results by providing counter-examples to the current best algorithms and their analysis, where the claimed bounds were 2.1187 for square packing and 2.6161 for cube packing.},
  archive      = {J_Alg},
  author       = {Epstein, Leah and Mualem, Loay},
  doi          = {10.1007/s00453-022-01078-9},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1415-1458},
  shortjournal = {Algorithmica},
  title        = {Online bin packing of squares and cubes},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved bounds for open online dial-a-ride on the line.
<em>Alg</em>, <em>85</em>(5), 1372–1414. (<a
href="https://doi.org/10.1007/s00453-022-01061-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the open, non-preemptive online Dial-a-Ride problem on the real line, where transportation requests appear over time and need to be served by a single server. We give a lower bound of 2.0585 on the competitive ratio, which is the first bound that strictly separates open online Dial-a-Ride on the line from open online TSP on the line in terms of competitive analysis, and is the best currently known lower bound even for general metric spaces. On the other hand, we present an algorithm that improves the best known upper bound from 2.9377 to 2.6662. The analysis of our algorithm is tight.},
  archive      = {J_Alg},
  author       = {Birx, Alexander and Disser, Yann and Schewior, Kevin},
  doi          = {10.1007/s00453-022-01061-4},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1372-1414},
  shortjournal = {Algorithmica},
  title        = {Improved bounds for open online dial-a-ride on the line},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Practical budgeted submodular maximization. <em>Alg</em>,
<em>85</em>(5), 1332–1371. (<a
href="https://doi.org/10.1007/s00453-022-01071-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of maximizing a non-negative monotone submodular function subject to a knapsack constraint, which is also known as the Budgeted Submodular Maximization (BSM) problem. Sviridenko (Operat Res Lett 32:41–43, 2004) showed that by guessing 3 appropriate elements of an optimal solution, and then executing a greedy algorithm, one can obtain the optimal approximation ratio of $$\alpha =1-{1}/{e} \approx 0.632$$ for BSM. However, the need to guess (by enumeration) 3 elements makes the algorithm of Sviridenko (Operat Res Lett 32:41–43, 2004) impractical as it leads to a time complexity of roughly $$O(n^5)$$ (this time complexity can be slightly improved using the thresholding technique of Badanidiyuru &amp; Vondrák (in: SODA, 1497–1514, 2014) but only to roughly $$O(n^4)$$ ). Our main results in this paper show that fewer guesses suffice. Specifically, by making only 2 guesses (and using the thresholding technique of Badanidiyuru &amp; Vondrák (in: SODA, 1497–1514, 2014), we get the same optimal approximation ratio of $$\alpha $$ with an improved time complexity of roughly $$O(n^3)$$ . Furthermore, by making only a single guess, we get an almost as good approximation ratio of $$0.6174 &gt; 0.9767\alpha $$ in roughly $$O(n^2)$$ time. Prior to our work, the only approximation algorithms that were known to obtain an approximation ratio close to $$\alpha $$ for BSM were the algorithm of Sviridenko (Operat Res Lett 32:41–43, 2004) and an algorithm of Ene &amp; Nguyen (in: ICALP, 53:1–53:12, 2019) that achieves $$(\alpha -\varepsilon )$$ -approximation. However, the algorithm of Ene &amp; Nguyen (in: ICALP, 53:1–53:12, 2019) requires $${(1/\varepsilon )}^{O(1/\varepsilon ^4)}n\log ^2 n$$ time, and hence, is of theoretical interest only since $${(1/\varepsilon )}^{O(1/\varepsilon ^4)}$$ is huge even for moderate values of $$\varepsilon $$ . In contrast, all the algorithms we analyze are simple and parallelizable, which makes them good candidates for practical use. Recently, Tang et al. (in: Proc ACM Meas Anal Comput Syst, 5(1): 08:1–08:22, 2021) studied a simple greedy algorithm that already has a long research history, and proved that it admits an approximation ratio of at least 0.405 (without any guesses). The last part of this paper improves over the result of Tang et al. (in: Proc ACM Meas Anal Comput Syst, 5(1): 08:1–08:22, 2021) and shows that the approximation ratio of this algorithm is within the range [0.427, 0.462].},
  archive      = {J_Alg},
  author       = {Feldman, Moran and Nutov, Zeev and Shoham, Elad},
  doi          = {10.1007/s00453-022-01071-2},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1332-1371},
  shortjournal = {Algorithmica},
  title        = {Practical budgeted submodular maximization},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Maximizing coverage while ensuring fairness: A tale of
conflicting objectives. <em>Alg</em>, <em>85</em>(5), 1287–1331. (<a
href="https://doi.org/10.1007/s00453-022-01072-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring fairness in computational problems has emerged as a key topic during recent years, buoyed by considerations for equitable resource distributions and social justice. It is possible to incorporate fairness in computational problems from several perspectives, such as using optimization, game-theoretic or machine learning frameworks. In this paper we address the problem of incorporation of fairness from a combinatorial optimization perspective. We formulate a combinatorial optimization framework, suitable for analysis by researchers in approximation algorithms and related areas, that incorporates fairness in maximum coverage problems as an interplay between two conflicting objectives. Fairness is imposed in coverage by using coloring constraints that minimizes the discrepancies between number of elements of different colors covered by selected sets; this is in contrast to the usual discrepancy minimization problems studied extensively in the literature where (usually two) colors are not given a priori but need to be selected to minimize the maximum color discrepancy of each individual set. Our main results are a set of randomized and deterministic approximation algorithms that attempts to simultaneously approximate both fairness and coverage in this framework.},
  archive      = {J_Alg},
  author       = {Asudeh, Abolfazl and Berger-Wolf, Tanya and DasGupta, Bhaskar and Sidiropoulos, Anastasios},
  doi          = {10.1007/s00453-022-01072-1},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1287-1331},
  shortjournal = {Algorithmica},
  title        = {Maximizing coverage while ensuring fairness: A tale of conflicting objectives},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantum meets fine-grained complexity: Sublinear time
quantum algorithms for string problems. <em>Alg</em>, <em>85</em>(5),
1251–1286. (<a
href="https://doi.org/10.1007/s00453-022-01066-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Longest common substring (LCS), longest palindrome substring (LPS), and Ulam distance (UL) are three fundamental string problems that can be classically solved in near linear time. In this work, we present sublinear time quantum algorithms for these problems along with quantum lower bounds. Our results shed light on a very surprising fact: Although the classic solutions for LCS and LPS are almost identical (via suffix trees), their quantum computational complexities are different. While we give an exact $${{\tilde{O}}}(\sqrt{n})$$ time algorithm for LPS, we prove that LCS needs at least time $$\tilde{\Omega }(n^{2/3})$$ even for 0/1 strings.},
  archive      = {J_Alg},
  author       = {Le Gall, François and Seddighin, Saeed},
  doi          = {10.1007/s00453-022-01066-z},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1251-1286},
  shortjournal = {Algorithmica},
  title        = {Quantum meets fine-grained complexity: Sublinear time quantum algorithms for string problems},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The complexity of routing problems in forbidden-transition
graphs and edge-colored graphs. <em>Alg</em>, <em>85</em>(5), 1202–1250.
(<a href="https://doi.org/10.1007/s00453-022-01064-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The notion of forbidden-transition graphs allows for a robust generalization of walks in graphs. In a forbidden-transition graph, every pair of edges incident to a common vertex is permitted or forbidden; a walk is compatible if all pairs of consecutive edges on the walk are permitted. Forbidden-transition graphs and related models have found applications in a variety of fields, such as routing in optical telecommunication networks, road networks, and bio-informatics. A widely-studied special case are edge-colored graphs, where a compatible walk is forbidden to take two edges of the same color in a row. We initiate the study of fundamental problems on finding paths, cycles and walks in forbidden-transition graphs from the point of view of parameterized complexity, including an in-depth study of tractability with regards to various graph-width parameters. Among several results, we prove that finding a simple compatible path between given endpoints in a forbidden-transition graph is W[1]-hard when parameterized by the vertex-deletion distance to a linear forest (so it is also hard when parameterized by pathwidth or treewidth). On the other hand, we show an algebraic trick that yields tractability when parameterized by treewidth for finding a compatible Hamiltonian cycle in the edge-colored graph setting.},
  archive      = {J_Alg},
  author       = {Bellitto, Thomas and Li, Shaohua and Okrasa, Karolina and Pilipczuk, Marcin and Sorge, Manuel},
  doi          = {10.1007/s00453-022-01064-1},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1202-1250},
  shortjournal = {Algorithmica},
  title        = {The complexity of routing problems in forbidden-transition graphs and edge-colored graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lazy queue layouts of posets. <em>Alg</em>, <em>85</em>(5),
1176–1201. (<a
href="https://doi.org/10.1007/s00453-022-01067-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the queue number of posets in terms of their width, that is, the maximum number of pairwise incomparable elements. A long-standing conjecture of Heath and Pemmaraju asserts that every poset of width w has queue number at most w. The conjecture has been confirmed for posets of width $$w=2$$ via so-called lazy linear extension. We extend and thoroughly analyze lazy linear extensions for posets of width $$w &gt; 2$$ . Our analysis implies an upper bound of $$(w-1)^2 +1$$ on the queue number of width-w posets, which is tight for the strategy and yields an improvement over the previously best-known bound. Further, we provide an example of a poset that requires at least $$w+1$$ queues in every linear extension, thereby disproving the conjecture for posets of width $$w &gt; 2$$ .},
  archive      = {J_Alg},
  author       = {Alam, Jawaherul Md. and Bekos, Michael A. and Gronemann, Martin and Kaufmann, Michael and Pupyrev, Sergey},
  doi          = {10.1007/s00453-022-01067-y},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1176-1201},
  shortjournal = {Algorithmica},
  title        = {Lazy queue layouts of posets},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Drawing partial 2-trees with few slopes. <em>Alg</em>,
<em>85</em>(5), 1156–1175. (<a
href="https://doi.org/10.1007/s00453-022-01065-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The planar slope number of a planar graph G is the minimum integer k such that G admits a planar drawing with vertices as points and edges as straight-line segments with k distinct slopes. Similarly, a plane slope number is defined for a plane graph, where a fixed combinatorial embedding of the graph is given and the output must respect the given embedding. We prove tight bounds (up to a small multiplicative or additive constant) for the plane and the planar slope numbers of partial 2-trees of bounded degree. We also answer a long standing question by Garg and Tamassia (In: van Leeuwen J (eds) Proceedings of the Second Annual European Symposium on Algorithms (ESA), LNCS, vol 855, pp 12–23, Springer, 1994) on the angular resolution of the planar straight-line drawings of series-parallel graphs of bounded degree.},
  archive      = {J_Alg},
  author       = {Lenhart, William and Liotta, Giuseppe and Mondal, Debajyoti and Nishat, Rahnuma Islam},
  doi          = {10.1007/s00453-022-01065-0},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1156-1175},
  shortjournal = {Algorithmica},
  title        = {Drawing partial 2-trees with few slopes},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Group activity selection with few agent types. <em>Alg</em>,
<em>85</em>(5), 1111–1155. (<a
href="https://doi.org/10.1007/s00453-022-01058-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we establish the complexity map for the Group Activity Selection Problem (GASP), along with two of its prominent variants called sGASP and gGASP, focusing on the case when the number of types of agents is the parameter. In all these problems, one is given a set of agents (each with their own preferences) and a set of activities, and the aim is to assign agents to activities in a way which satisfies certain global as well as preference-based conditions. Our positive results, consisting of one fixed-parameter algorithm and one XP algorithm, rely on a combination of novel Subset Sum machinery (which may be of general interest) and identifying certain compression steps that allow us to focus on solutions with a simpler, well-defined structure (in particular, they are “acyclic”). These algorithms are complemented by matching lower bounds, which among others close a gap to a recently obtained tractability result of Gupta et al. (in: Algorithmic game theory—10th international symposium, SAGT 2017, vol 10504 of lecture notes in computer science, Springer, 2017). In this direction, the techniques used to establish W[1]-hardness of sGASP are of particular interest: as an intermediate step, we use Sidon sequences to show the W[1]-hardness of a highly restricted variant of multi-dimensional Subset Sum, which may find applications in other settings as well.},
  archive      = {J_Alg},
  author       = {Ganian, Robert and Ordyniak, Sebastian and Rahul, C. S.},
  doi          = {10.1007/s00453-022-01058-z},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1111-1155},
  shortjournal = {Algorithmica},
  title        = {Group activity selection with few agent types},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A cubic vertex-kernel for trivially perfect editing.
<em>Alg</em>, <em>85</em>(4), 1091–1110. (<a
href="https://doi.org/10.1007/s00453-022-01070-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the Trivially Perfect Editing problem, where one is given an undirected graph $$G = (V,E)$$ and a parameter $$k \in {\mathbb {N}}$$ and seeks to edit (add or delete) at most k edges from G to obtain a trivially perfect graph. The related Trivially Perfect Completion and Trivially Perfect Deletion problems are obtained by only allowing edge additions or edge deletions, respectively. Trivially perfect graphs are both chordal and cographs, and have applications related to the tree-depth width parameter and to social network analysis. All variants of the problem are known to be NP-complete (Burzyn et al., in Discret Appl Math 154(13):1824–1844, 2006; Nastos and Gao, in Soc Netw 35(3):439–450, 2013) and to admit so-called polynomial kernels (Drange and Pilipczuk, in Algorithmica 80(12):3481–3524, 2018; Guo, in: Tokuyama, (ed) Algorithms and Computation, 18th International Symposium, ISAAC. Lecture Notes in Computer Science, Springer, Sendai, 2007. https://doi.org/10.1007/978-3-540-77120-3_79 ; Bathie et al., in Algorithmica 1–27, 2022). More precisely, Drange and Pilipczuk (Algorithmica 80(12):3481–3524, 2018) provided $$O(k^7)$$ vertex-kernels for these problems and left open the existence of cubic vertex-kernels. In this work, we answer positively to this question for all three variants of the problem. Notice that a quadratic vertex-kernel was recently obtained for Trivially Perfect Completion by Bathie et al. (Algorithmica 1–27, 2022).},
  archive      = {J_Alg},
  author       = {Dumas, Maël and Perez, Anthony and Todinca, Ioan},
  doi          = {10.1007/s00453-022-01070-3},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {1091-1110},
  shortjournal = {Algorithmica},
  title        = {A cubic vertex-kernel for trivially perfect editing},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The complexity of two colouring games. <em>Alg</em>,
<em>85</em>(4), 1067–1090. (<a
href="https://doi.org/10.1007/s00453-022-01069-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider two variants of orthogonal colouring games on graphs. In these games, two players alternate colouring uncoloured vertices (from a choice of $$m\in {\mathbb {N}}$$ colours) of a pair of isomorphic graphs while respecting the properness and the orthogonality of the partial colourings. In the normal play variant, the first player unable to move loses. In the scoring variant, each player aims to maximise their score, which is the number of coloured vertices in their copy of the graph. We prove that, given an instance with partial colourings, both the normal play and the scoring variant of the game are PSPACE-complete. An involution $$\sigma $$ of a graph G is strictly matched if its fixed point set induces a clique and $$v\sigma (v)\in E(G)$$ for any non-fixed point $$v\in V(G)$$ . Andres et al. (Theor Comput Sci 795:312–325, 2019) gave a solution of the normal play variant played on graphs that admit a strictly matched involution. We prove that recognising graphs that admit a strictly matched involution is NP-complete.},
  archive      = {J_Alg},
  author       = {Andres, Stephan Dominique and Dross, François and Huggan, Melissa A. and Mc Inerney, Fionn and Nowakowski, Richard J.},
  doi          = {10.1007/s00453-022-01069-w},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {1067-1090},
  shortjournal = {Algorithmica},
  title        = {The complexity of two colouring games},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Leader election in well-connected graphs. <em>Alg</em>,
<em>85</em>(4), 1029–1066. (<a
href="https://doi.org/10.1007/s00453-022-01068-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we look at the problem of randomized leader election in synchronous distributed networks with a special focus on the message complexity. We provide an algorithm that solves the implicit version of leader election (where non-leader nodes need not be aware of the identity of the leader) in any general network with $$O(\sqrt{n} \log ^{7/2} n \cdot t_{mix})$$ messages and in $$O(t_{mix}\log ^2 n)$$ time, where n is the number of nodes and $$t_{mix}$$ refers to the mixing time of a random walk in the network graph G. For several classes of well-connected networks (that have a large conductance or alternatively small mixing times e.g., expanders, hypercubes, etc), the above result implies extremely efficient (sublinear running time and messages) leader election algorithms. Correspondingly, we show that any substantial improvement is not possible over our algorithm, by presenting an almost matching lower bound for randomized leader election. We show that $$\varOmega (\sqrt{n}/\phi ^{3/4})$$ messages are needed for any leader election algorithm that succeeds with probability at least $$1-o(1)$$ , where $$\phi $$ refers to the conductance of a graph. To the best of our knowledge, this is the first work that shows a dependence between the time and message complexity to solve leader election and the connectivity of the graph G, which is often characterized by the graph’s conductance $$\phi $$ . Apart from the $$\varOmega (m)$$ bound in Kutten et al. (J ACM 62(1):7:1–7:27, 2015) (where m denotes the number of edges of the graph), this work also provides one of the first non-trivial lower bounds for leader election in general networks.},
  archive      = {J_Alg},
  author       = {Gilbert, Seth and Robinson, Peter and Sourav, Suman},
  doi          = {10.1007/s00453-022-01068-x},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {1029-1066},
  shortjournal = {Algorithmica},
  title        = {Leader election in well-connected graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the tractability of covering a graph with 2-clubs.
<em>Alg</em>, <em>85</em>(4), 992–1028. (<a
href="https://doi.org/10.1007/s00453-022-01062-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Covering a graph with cohesive subgraphs is a classical problem in theoretical computer science, for example when the cohesive subgraph model considered is a clique. In this paper, we consider as a model of cohesive subgraph the 2-clubs, which are induced subgraphs of diameter at most 2. We prove new complexity results on the $$\mathsf {Min~2\text {-}Club~Cover}$$ problem, a variant recently introduced in the literature which asks to cover the vertices of a graph with a minimum number of 2-clubs. First, we answer an open question on the decision version of $$\mathsf {Min~2\text {-}Club~Cover}$$ that asks if it is possible to cover a graph with at most two 2-clubs, and we prove that it is W[1]-hard when parameterized by the distance to a 2-club. Then, we consider the complexity of $$\mathsf {Min~2\text {-}Club~Cover}$$ on some graph classes. We prove that $$\mathsf {Min~2\text {-}Club~Cover}$$ remains NP-hard on subcubic planar graphs, W[2]-hard on bipartite graphs when parameterized by the number of 2-clubs in a solution, and fixed-parameter tractable on graphs having bounded treewidth.},
  archive      = {J_Alg},
  author       = {Dondi, Riccardo and Lafond, Manuel},
  doi          = {10.1007/s00453-022-01062-3},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {992-1028},
  shortjournal = {Algorithmica},
  title        = {On the tractability of covering a graph with 2-clubs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rare siblings speed-up deterministic detection and counting
of small pattern graphs. <em>Alg</em>, <em>85</em>(4), 976–991. (<a
href="https://doi.org/10.1007/s00453-022-01063-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a class of pattern graphs on $$q\ge 4$$ vertices that have $$q-2$$ distinguished vertices with equal neighborhood in the remaining two vertices. Two pattern graphs in this class are siblings if they differ by some edges connecting the distinguished vertices. In particular, we show that if induced copies of siblings to a pattern graph in such a class are rare in the host graph then one can detect the pattern graph relatively efficiently. For an example, we infer that if there are $$N_d$$ induced copies of a diamond (i.e., a graph on four vertices missing a single edge to be complete) in the host graph, then an induced copy of the complete graph on four vertices, $$K_4,$$ as well as an induced copy of the cycle on four vertices, $$C_4,$$ can be deterministically detected in $$O(n^{2.75}+N_d)$$ time. Note that the fastest known algorithm for $$K_4$$ and the fastest known deterministic algorithm for $$C_4$$ run in $$O(n^{3.257})$$ time. By using random bits, we can speed up our method such that the number of induced copies of the siblings is replaced by the ratio of this number to the number of induced copies of the pattern graph plus 1 in the upper time bound. We also show that if there is a family of siblings whose induced copies in the host graph are rare then there are good chances to determine the numbers of occurrences of induced copies for all pattern graphs on q vertices relatively efficiently.},
  archive      = {J_Alg},
  author       = {Kowaluk, Mirosław and Lingas, Andrzej},
  doi          = {10.1007/s00453-022-01063-2},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {976-991},
  shortjournal = {Algorithmica},
  title        = {Rare siblings speed-up deterministic detection and counting of small pattern graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Few cuts meet many point sets. <em>Alg</em>, <em>85</em>(4),
965–975. (<a href="https://doi.org/10.1007/s00453-022-01059-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of how to split many point sets in $$\mathbb {R}^d$$ into smaller parts using a few (shared) splitting hyperplanes. This problem is related to the classical Ham-Sandwich Theorem. We provide a logarithmic approximation to the optimal solution using the greedy algorithm for submodular optimization.},
  archive      = {J_Alg},
  author       = {Har-Peled, Sariel and Jones, Mitchell},
  doi          = {10.1007/s00453-022-01059-y},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {965-975},
  shortjournal = {Algorithmica},
  title        = {Few cuts meet many point sets},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Faster cut sparsification of weighted graphs. <em>Alg</em>,
<em>85</em>(4), 929–964. (<a
href="https://doi.org/10.1007/s00453-022-01053-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A cut sparsifier is a reweighted subgraph that maintains the weights of the cuts of the original graph up to a multiplicative factor of $$(1\pm \epsilon )$$ . This paper considers computing cut sparsifiers of weighted graphs of size $$O(n\log (n)/\epsilon ^2)$$ . Our algorithm computes such a sparsifier in time $$O(m\cdot \min (\alpha (n)\log (m/n),\log (n)))$$ , both for graphs with polynomially bounded and unbounded integer weights, where $$\alpha (\cdot )$$ is the functional inverse of Ackermann’s function. This improves upon the state of the art by Benczúr and Karger (SICOMP, 2015), which takes $$O(m\log ^2 (n))$$ time. For unbounded weights, this directly gives the best known result for cut sparsification. Together with preprocessing by an algorithm of Fung et al. (SICOMP, 2019), this also gives the best known result for polynomially-weighted graphs. Consequently, this implies the fastest approximate min-cut algorithm, both for graphs with polynomial and unbounded weights. In particular, we show that it is possible to adapt the state of the art algorithm of Fung et al. for unweighted graphs to weighted graphs, by letting the partial maximum spanning forest (MSF) packing take the place of the Nagamochi–Ibaraki forest packing. MSF packings have previously been used by Abraham et al. (FOCS, 2016) in the dynamic setting, and are defined as follows: an M-partial MSF packing of G is a set $$\mathcal {F}={F_1, \ldots , F_M}$$ , where $$F_i$$ is a maximum spanning forest in $$G{\setminus } \bigcup _{j=1}^{i-1}F_j$$ . Our method for computing (a sufficient estimation of) the MSF packing is the bottleneck in the running time of our sparsification algorithm.},
  archive      = {J_Alg},
  author       = {Forster, Sebastian and de Vos, Tijn},
  doi          = {10.1007/s00453-022-01053-4},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {929-964},
  shortjournal = {Algorithmica},
  title        = {Faster cut sparsification of weighted graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parameterized inapproximability of independent set in h-free
graphs. <em>Alg</em>, <em>85</em>(4), 902–928. (<a
href="https://doi.org/10.1007/s00453-022-01052-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the Independent Set problem in H-free graphs, i.e., graphs excluding some fixed graph H as an induced subgraph. We prove several inapproximability results both for polynomial-time and parameterized algorithms. Halldórsson [SODA 1995] showed that for every $$\delta &gt;0$$ the Independent Set problem has a polynomial-time $$(\frac{d-1}{2}+\delta )$$ -approximation algorithm in $$K_{1,d}$$ -free graphs. We extend this result by showing that $$K_{a,b}$$ -free graphs admit a polynomial-time $${\mathcal {O}}(\alpha (G)^{1-1/a})$$ -approximation, where $$\alpha (G)$$ is the size of a maximum independent set in G. Furthermore, we complement the result of Halldórsson by showing that for some $$\gamma =\Theta (d/\log d),$$ there is no polynomial-time $$\gamma $$ -approximation algorithm for these graphs, unless NP  = ZPP. Bonnet et al. [Algorithmica 2020] showed that Independent Set parameterized by the size k of the independent set is W[1]-hard on graphs which do not contain (1) a cycle of constant length at least 4, (2) the star $$K_{1,4}$$ , and (3) any tree with two vertices of degree at least 3 at constant distance. We strengthen this result by proving three inapproximability results under different complexity assumptions for almost the same class of graphs (we weaken conditions (1) and (2) that G does not contain a cycle of constant length at least 5 or $$K_{1,5}$$ ). First, under the ETH, there is no $$f(k) \cdot n^{o(k/\log k)}$$ algorithm for any computable function f. Then, under the deterministic Gap-ETH, there is a constant $$\delta &gt;0$$ such that no $$\delta $$ -approximation can be computed in $$f(k) \cdot n^{O(1)}$$ time. Also, under the stronger randomized Gap-ETH there is no such approximation algorithm with runtime $$f(k) \cdot n^{o(\sqrt{k})}$$ . Finally, we consider the parameterization by the excluded graph H, and show that under the ETH, Independent Set has no $$n^{o(\alpha (H))}$$ algorithm in H-free graphs. Also, we prove that there is no $$d/k^{o(1)}$$ -approximation algorithm for $$K_{1,d}$$ -free graphs with runtime $$f(d,k) \cdot n^{{\mathcal {O}}(1)}$$ , under the deterministic Gap-ETH.},
  archive      = {J_Alg},
  author       = {Dvořák, Pavel and Feldmann, Andreas Emil and Rai, Ashutosh and Rzążewski, Paweł},
  doi          = {10.1007/s00453-022-01052-5},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {902-928},
  shortjournal = {Algorithmica},
  title        = {Parameterized inapproximability of independent set in H-free graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gapped indexing for consecutive occurrences. <em>Alg</em>,
<em>85</em>(4), 879–901. (<a
href="https://doi.org/10.1007/s00453-022-01051-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classic string indexing problem is to preprocess a string S into a compact data structure that supports efficient pattern matching queries. Typical queries include existential queries (decide if the pattern occurs in S), reporting queries (return all positions where the pattern occurs), and counting queries (return the number of occurrences of the pattern). In this paper we consider a variant of string indexing, where the goal is to compactly represent the string such that given two patterns $$P_1$$ and $$P_2$$ and a gap range $${[}\alpha , \beta ]$$ we can quickly find the consecutive occurrences of $$P_1$$ and $$P_2$$ with distance in $${[}\alpha , \beta ]$$ , i.e., pairs of subsequent occurrences with distance within the range. We present data structures that use linear space and query time $${\widetilde{O}}(|P_1|+|P_2|+n^{2/3})$$ for existence and counting and $${\widetilde{O}}(|P_1|+|P_2|+n^{2/3}\hbox {occ}^{1/3})$$ for reporting. We complement this with a conditional lower bound based on the set intersection problem showing that any solution using $${\widetilde{O}}(n)$$ space must use $${\widetilde{\Omega }}(|P_1| + |P_2| + \sqrt{n})$$ query time. To obtain our results we develop new techniques and ideas of independent interest including a new suffix tree decomposition and hardness of a variant of the set intersection problem.},
  archive      = {J_Alg},
  author       = {Bille, Philip and Gørtz, Inge Li and Pedersen, Max Rishøj and Steiner, Teresa Anna},
  doi          = {10.1007/s00453-022-01051-6},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {879-901},
  shortjournal = {Algorithmica},
  title        = {Gapped indexing for consecutive occurrences},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Trade-offs in dynamic coloring for bipartite and general
graphs. <em>Alg</em>, <em>85</em>(4), 854–878. (<a
href="https://doi.org/10.1007/s00453-022-01050-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamic coloring problem has gained attention in the recent past. The focus has largely been on obtaining efficient update time algorithms using $$\Delta +1$$ or more colors and the trade-offs between update time and query time. Another important parameter in dynamic coloring is the number of recolorings per update which is addressed by the works of Barba et al. in WADS’17, and Solomon and Wein in ESA’18. In SODA’18, Bhattacharya et al. presented a randomized algorithm that uses $$\Delta +1$$ colors and achieves amortized $$O(\log \Delta )$$ update time. In STACS’20, Henzinger and Peng presented a randomized $$(\Delta +1)$$ -coloring algorithm with amortized O(1) update time. Independently on arXiv, Bhattacharya et al. also presented a randomized $$(\Delta +1)$$ -coloring algorithm with amortized O(1) update time. While works of Bhattacharya et al., and Henzinger and Peng are very efficient in terms of update time, they do not address the number of recolorings per update. We bridge this gap by providing efficient update time algorithms with constant number of recolorings. Moreover our algorithm is deterministic as opposed to the works of Bhattacharya et al. in SODA’18, and Henzinger and Peng in STACS’20. Next, we study bipartite graphs which can be optimally colored in the static setting. We show that even in the incremental setting (where edges are added to the graph and no edge can be deleted), there is a bad update sequence which forces the update time to be at least $$\Omega (\log {n})$$ in the amortized setting and $$\Omega (n)$$ in the worst case. This possibly explains the lack of any results on dynamic coloring specific to bipartite graphs. We circumvent this lower bound by proposing two approaches. Firstly, we allow the use of more than two colors and obtain significantly better update time. Second, we introduce the idea of implicit coloring. If the color of a vertex is explicitly stored in a data structure and updated at end of every update then we call such an algorithm as explicit coloring algorithm. All prior work on dynamic coloring uses explicit coloring algorithms. We show that using implicit coloring we can obtain near constant update time and query time for incremental coloring for bipartite case. We also bound the number of recolorings to near constant. We also show an efficient implicit fully dynamic algorithm for bipartite graphs. All our algorithms are deterministic and use simple data structures. Hence, we believe that our algorithms are of practical importance.},
  archive      = {J_Alg},
  author       = {Kashyop, Manas Jyoti and Narayanaswamy, N. S. and Nasre, Meghana and Potluri, Sai Mohith},
  doi          = {10.1007/s00453-022-01050-7},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {854-878},
  shortjournal = {Algorithmica},
  title        = {Trade-offs in dynamic coloring for bipartite and general graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 3-colouring <span
class="math display"><em>P</em><sub><em>t</em></sub></span> -free graphs
without short odd cycles. <em>Alg</em>, <em>85</em>(4), 831–853. (<a
href="https://doi.org/10.1007/s00453-022-01049-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For any odd $$t\ge 9$$ , we present a polynomial-time algorithm that solves the 3-colouring problem, and finds a 3-colouring if one exists, in $$P_{t}$$ -free graphs of odd girth at least $$t-2$$ . In particular, our algorithm works for $$(P_9, C_3, C_5)$$ -free graphs, thus making progress towards determining the complexity of 3-colouring in $$P_t$$ -free graphs, which is open for $$t\ge 8$$ .},
  archive      = {J_Alg},
  author       = {Rojas Anríquez, Alberto and Stein, Maya},
  doi          = {10.1007/s00453-022-01049-0},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {831-853},
  shortjournal = {Algorithmica},
  title        = {3-colouring $$P_t$$ -free graphs without short odd cycles},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Eulerian walks in temporal graphs. <em>Alg</em>,
<em>85</em>(3), 805–830. (<a
href="https://doi.org/10.1007/s00453-022-01021-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An Eulerian walk (or Eulerian trail) is a walk (resp. trail) that visits every edge of a graph G at least (resp. exactly) once. This notion was first discussed by Leonhard Euler while solving the famous Seven Bridges of Königsberg problem in 1736. But what if Euler had to take a bus? In a temporal graph $$\varvec{(G,\lambda )}$$ , with $$\varvec{\lambda : E(G)}\varvec{\rightarrow } \varvec{2}^{\varvec{[\tau ]}}$$ , an edge $$\varvec{e}\varvec{\in } \varvec{E(G)}$$ is available only at the times specified by $$\varvec{\lambda (e)}\varvec{\subseteq } \varvec{[\tau ]}$$ , in the same way the connections of the public transportation network of a city or of sightseeing tours are available only at scheduled times. In this paper, we deal with temporal walks, local trails, and trails, respectively referring to edge traversal with no constraints, constrained to not repeating the same edge in a single timestamp, and constrained to never repeating the same edge throughout the entire traversal. We show that, if the edges are always available, then deciding whether $$\varvec{(G,\lambda )}$$ has a temporal walk or trail is polynomial, while deciding whether it has a local trail is $$\varvec{\texttt {NP}}$$ -complete even if $$\varvec{\tau = 2}$$ . In contrast, in the general case, solving any of these problems is $$\varvec{\texttt {NP}}$$ -complete, even under very strict hypotheses. We finally give $$\varvec{\texttt {XP}}$$ algorithms parametrized by $$\varvec{\tau }$$ for walks, and by $$\varvec{\tau +tw(G)}$$ for trails and local trails, where $$\varvec{tw(G)}$$ refers to the treewidth of $$\varvec{G}$$ .},
  archive      = {J_Alg},
  author       = {Marino, Andrea and Silva, Ana},
  doi          = {10.1007/s00453-022-01021-y},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {805-830},
  shortjournal = {Algorithmica},
  title        = {Eulerian walks in temporal graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Non-preemptive tree packing. <em>Alg</em>, <em>85</em>(3),
783–804. (<a href="https://doi.org/10.1007/s00453-022-01026-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An instance of the non-preemptive tree packing problem consists of an undirected graph $$G=(V,E)$$ together with a weight w(e) for every edge $$e\in E$$ . The goal is to activate every edge e for some time interval of length w(e), such that the activated edges keep G connected for the longest possible overall time. We derive a variety of results on this problem. The problem is strongly NP-hard even on graphs of treewidth¬†2, and it does not allow a polynomial time approximation scheme (unless P=NP). Furthermore, we discuss the performance of a simple greedy algorithm, and we construct and analyze a number of parameterized and exact algorithms.},
  archive      = {J_Alg},
  author       = {Lendl, Stefan and Woeginger, Gerhard and Wulf, Lasse},
  doi          = {10.1007/s00453-022-01026-7},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {783-804},
  shortjournal = {Algorithmica},
  title        = {Non-preemptive tree packing},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Minimum eccentricity shortest path problem with respect to
structural parameters. <em>Alg</em>, <em>85</em>(3), 762–782. (<a
href="https://doi.org/10.1007/s00453-022-01006-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Minimum Eccentricity Shortest Path Problem consists in finding a shortest path with minimum eccentricity in a given undirected graph. The problem is known to be NP-complete and W[2]-hard with respect to the desired eccentricity. We present fpt-algorithms for the problem parameterized by the modular width, distance to cluster graph, the combination of treewidth with the desired eccentricity, and maximum leaf number.},
  archive      = {J_Alg},
  author       = {Kučera, Martin and Suchý, Ondřej},
  doi          = {10.1007/s00453-022-01006-x},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {762-782},
  shortjournal = {Algorithmica},
  title        = {Minimum eccentricity shortest path problem with respect to structural parameters},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Structure and complexity of 2-intersection graphs of
3-hypergraphs. <em>Alg</em>, <em>85</em>(3), 745–761. (<a
href="https://doi.org/10.1007/s00453-022-00990-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a 3-uniform hypergraph H having a set V of vertices, and a set of hyperedges $$T\subset \mathcal {P}(V)$$ , whose elements have cardinality three each, a null labelling is an assignment of $$\pm 1$$ to the hyperedges such that each vertex belongs to the same number of hyperedges labelled $$+1$$ and $$-1$$ . A sufficient condition for the existence of a null labelling of H (proved in Di Marco et al. Lect Notes Comput Sci 12757:282–294, 2021) is a Hamiltonian cycle in its 2-intersection graph. The notion of 2-intersection graph generalizes that of intersection graph of an (hyper)graph and extends its effectiveness. The present study first shows that this sufficient condition for the existence of a null labelling in H can not be weakened by requiring only the connectedness of the 2-intersection graph. Then some interesting properties related to their clique configurations are proved. Finally, the main result is proved, the NP-completeness of this characterization and, as a consequence, of the construction of the related 3-hypergraphs.},
  archive      = {J_Alg},
  author       = {Di Marco, Niccoló and Frosini, Andrea and Kocay, William Lawrence and Pergola, Elisa and Tarsissi, Lama},
  doi          = {10.1007/s00453-022-00990-4},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {745-761},
  shortjournal = {Algorithmica},
  title        = {Structure and complexity of 2-intersection graphs of 3-hypergraphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hamiltonicity of k-sided pancake networks with fixed-spin:
Efficient generation, ranking, and optimality. <em>Alg</em>,
<em>85</em>(3), 717–744. (<a
href="https://doi.org/10.1007/s00453-022-01022-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a Hamilton cycle in the k-sided pancake network and four combinatorial algorithms to traverse the cycle. The network’s vertices are coloured permutations $$\pi = p_1p_2\cdots p_n$$ , where each $$p_i$$ has an associated colour in $${0,1,\ldots , k{-}1}$$ . There is a directed edge $$(\pi _1,\pi _2)$$ if $$\pi _2$$ can be obtained from $$\pi _1$$ by a “flip” of length $$\ell $$ , which reverses the first $$\ell $$ elements and increments their colour modulo k. Our particular cycle is created using a greedy min-flip strategy, and the average flip length of the edges we use is bounded by a constant. By reinterpreting the order recursively, we can generate successive coloured permutations in O(1)-amortized time, or each successive flip by a loop-free algorithm. We also show how to compute the successor of any coloured permutation in O(n) time. Our greedy min-flip construction generalizes known Hamilton cycles for the pancake network (where $$k=1$$ ) and the burnt pancake network (where $$k=2$$ ). Interestingly, a greedy max-flip strategy works on the pancake and burnt pancake networks, but it does not work on the k-sided network when $$k&gt;2$$ . In addition to our generation results, we provide ranking and unranking algorithms for our Hamiltion cycle that run in $$O(n^2)$$ time, and show that the cycle is globally optimal in terms of minimizing the total number of pancakes that are flipped. Finally, we characterize the Hamiltonicity of k-sided pancake networks with any fixed “spin” s.},
  archive      = {J_Alg},
  author       = {Cameron, Ben and Sawada, Joe and Therese, Wei and Williams, Aaron},
  doi          = {10.1007/s00453-022-01022-x},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {717-744},
  shortjournal = {Algorithmica},
  title        = {Hamiltonicity of k-sided pancake networks with fixed-spin: Efficient generation, ranking, and optimality},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Edge exploration of temporal graphs. <em>Alg</em>,
<em>85</em>(3), 688–716. (<a
href="https://doi.org/10.1007/s00453-022-01018-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a natural temporal analogue of Eulerian circuits and prove that, in contrast to the static case, it is $${\textsc {NP}}$$ -hard to determine whether a given temporal graph is temporally Eulerian even if strong restrictions are placed on the structure of the underlying graph and each edge is active at only three times. However, we do obtain an $${\textsc {FPT}}$$ -algorithm with respect to a new parameter called interval-membership-width which restricts the times assigned to different edges; we believe that this parameter will be of independent interest for other temporal graph problems. Our techniques also allow us to resolve two open questions of Akrida, Mertzios and Spirakis [CIAC 2019] concerning a related problem of exploring temporal stars.},
  archive      = {J_Alg},
  author       = {Bumpus, Benjamin Merlin and Meeks, Kitty},
  doi          = {10.1007/s00453-022-01018-7},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {688-716},
  shortjournal = {Algorithmica},
  title        = {Edge exploration of temporal graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Composed degree-distance realizations of graphs.
<em>Alg</em>, <em>85</em>(3), 665–687. (<a
href="https://doi.org/10.1007/s00453-022-01055-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network realization problems require, given a specification $$\pi $$ for some network parameter (such as degrees, distances or connectivity), to construct a network G conforming to $$\pi $$ , or to determine that no such network exists. In this paper we study composed profile realization, where the given instance consists of two or more profile specifications that need to be realized simultaneously. To gain some understanding of the problem, we focus on two classical profile types, namely, degrees and distances, which were (separately) studied extensively in the past. We investigate a wide spectrum of variants of the composed distance and degree realization problem. For each variant we either give a polynomial-time realization algorithm or establish NP hardness. In particular:},
  archive      = {J_Alg},
  author       = {Bar-Noy, Amotz and Peleg, David and Perry, Mor and Rawitz, Dror},
  doi          = {10.1007/s00453-022-01055-2},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {665-687},
  shortjournal = {Algorithmica},
  title        = {Composed degree-distance realizations of graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combinatorics and algorithms for quasi-chain graphs.
<em>Alg</em>, <em>85</em>(3), 642–664. (<a
href="https://doi.org/10.1007/s00453-022-01019-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The class of quasi-chain graphs is an extension of the well-studied class of chain graphs. This latter class enjoys many nice and important properties, such as bounded clique-width, implicit representation, well-quasi-ordering by induced subgraphs, etc. The class of quasi-chain graphs is substantially more complex. In particular, this class is not well-quasi-ordered by induced subgraphs, and the clique-width is not bounded in it. In the present paper, we show that the universe of quasi-chain graphs is at least as complex as the universe of permutations by establishing a bijection between the class of all permutations and a subclass of quasi-chain graphs. This implies, in particular, that the induced subgraph isomorphism problem is NP-complete for quasi-chain graphs. On the other hand, we propose a decomposition theorem for quasi-chain graphs that implies an implicit representation for graphs in this class and efficient solutions for some algorithmic problems that are generally intractable.},
  archive      = {J_Alg},
  author       = {Alecu, Bogdan and Atminas, Aistis and Lozin, Vadim and Malyshev, Dmitriy},
  doi          = {10.1007/s00453-022-01019-6},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {642-664},
  shortjournal = {Algorithmica},
  title        = {Combinatorics and algorithms for quasi-chain graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Selected papers of the 32nd international workshop on
combinatorial algorithms, IWOCA 2021. <em>Alg</em>, <em>85</em>(3),
639–641. (<a href="https://doi.org/10.1007/s00453-022-01054-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_Alg},
  author       = {Flocchini, Paola and Moura, Lucia},
  doi          = {10.1007/s00453-022-01054-3},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {639-641},
  shortjournal = {Algorithmica},
  title        = {Selected papers of the 32nd international workshop on combinatorial algorithms, IWOCA 2021},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integer feasibility and refutations in UTVPI constraints
using bit-scaling. <em>Alg</em>, <em>85</em>(2), 610–637. (<a
href="https://doi.org/10.1007/s00453-022-01048-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the design and analysis of a bit-scaling based algorithm for the problem of checking integer feasibility in a system of unit two variable per inequality (UTVPI) constraints (IF). The insights developed during algorithm design result in new techniques for extracting refutations of integer feasibility in such systems. Recall that a UTVPI constraint is a linear constraint of the form: $$a_i\cdot x_i+a_j \cdot x_j \le b_{ij}$$ , where $$a_i, a_j \in {0,1,-1}$$ and $$b_{ij} \in {\mathbb {Z}}$$ . These constraints arise in a number of application domains including but not limited to program verification (array bounds checking and abstract interpretation), operations research (packing and covering), and logic programming. Over the years, several algorithms have been proposed for the IF problem. Most of these algorithms are based on two inference rules, viz. the transitive rule and the tightening rule. None of these algorithms are bit-scaling. In other words, the running times of these algorithms are parameterized only by the number of variables and the number of constraints in the UTVPI constraint system (UCS) and not by the sizes of input constants. We introduce a novel algorithm for the IF problem, which is based on a collection of new insights. These insights are used to design a new bit-scaling algorithm for IF that runs in $$O(\sqrt{n}\cdot m \cdot \log _2 C)$$ time, where n denotes the number of variables, m denotes the number of constraints, and C denotes the absolute value of the most negative constant defining the UCS. An interesting consequence of our research is the development of techniques for extracting refutations of integer infeasibility in UCSs that are linearly feasible. If the UCS is linearly feasible, then our algorithm creates a 2CNF formula. The UCS has an integer refutation (i.e., does not have a lattice point) if and only if the created 2CNF formula has a resolution refutation (i.e., is unsatisfiable).},
  archive      = {J_Alg},
  author       = {Subramani, K. and Wojciechowski, Piotr},
  doi          = {10.1007/s00453-022-01048-1},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {610-637},
  shortjournal = {Algorithmica},
  title        = {Integer feasibility and refutations in UTVPI constraints using bit-scaling},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Faster graph coloring in polynomial space. <em>Alg</em>,
<em>85</em>(2), 584–609. (<a
href="https://doi.org/10.1007/s00453-022-01034-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a polynomial-space algorithm that computes the number of independent sets of any input graph in time $$O(1.1389^n)$$ for graphs with maximum degree 3 and in time $$O(1.2356^n)$$ for general graphs, where n is the number of vertices in the input graph. Together with the inclusion-exclusion approach of Björklund, Husfeldt, and Koivisto [SIAM J. Comput. 2009], this leads to a faster polynomial-space algorithm for the graph coloring problem with running time $$O(2.2356^n)$$ as well as an exponential-space $$O(1.2330^n)$$ time algorithm for counting independent sets. Our main algorithm counts independent sets in graphs with maximum degree at most 3 and no vertex with three neighbors of degree 3. This polynomial-space algorithm is designed and analyzed using the recently introduced Separate, Measure and Conquer approach [Gaspers &amp; Sorkin, ICALP 2015]. Using Wahlström’s compound measure approach, this improvement in running time for small degree graphs is then bootstrapped to larger degrees, giving the improvement for general graphs. Combining both approaches leads to some inflexibility in choosing vertices to branch on for the small-degree cases, which we counter by structural graph properties.},
  archive      = {J_Alg},
  author       = {Gaspers, Serge and Lee, Edward J.},
  doi          = {10.1007/s00453-022-01034-7},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {584-609},
  shortjournal = {Algorithmica},
  title        = {Faster graph coloring in polynomial space},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved algorithms for scheduling unsplittable flows on
paths. <em>Alg</em>, <em>85</em>(2), 563–583. (<a
href="https://doi.org/10.1007/s00453-022-01043-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate offline and online algorithms for $$\mathsf {Round}\text {-}\mathsf {UFPP}$$ , the problem of minimizing the number of rounds required to schedule a set of unsplittable flows of non-uniform size on a given path with heterogeneous edge capacities. $$\mathsf {Round}\text {-}\mathsf {UFPP}$$ is known to be NP-hard and there are constant-factor approximation algorithms under the no bottleneck assumption (NBA), which stipulates that maximum size of any flow is at most the minimum global edge capacity. In this work, we present improved online and offline algorithms for $$\mathsf {Round}\text {-}\mathsf {UFPP}$$ without the NBA. We first study offline $$\mathsf {Round}\text {-}\mathsf {UFPP}$$ for a restricted class of instances, called $$\alpha $$ -small, where the size of each flow is at most $$\alpha $$ times the capacity of its bottleneck edge, and present an $$O(\log (1/(1-\alpha )))$$ -approximation algorithm. Next, our main result is an online $$O(\log \log c_{\max })$$ -competitive algorithm for $$\mathsf {Round}\text {-}\mathsf {UFPP}$$ where $$c_{\max }$$ is the largest edge capacity, improving upon the previous best bound of $$O(\log c_{\max })$$ due to Epstein et al. (SIAM J Discrete Math 23(2):822–841, 2009). These new results lead to an offline $$O(\min (\log n, \log m, \log \log c_{\max }))$$ -approximation algorithm and an online $$O(\min (\log m, \log \log c_{\max }))$$ -competitive algorithm for $$\mathsf {Round}\text {-}\mathsf {UFPP}$$ , where n is the number of flows and m is the number of edges.},
  archive      = {J_Alg},
  author       = {Jahanjou, Hamidreza and Kantor, Erez and Rajaraman, Rajmohan},
  doi          = {10.1007/s00453-022-01043-6},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {563-583},
  shortjournal = {Algorithmica},
  title        = {Improved algorithms for scheduling unsplittable flows on paths},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved upper bound on the queue number of planar
graphs. <em>Alg</em>, <em>85</em>(2), 544–562. (<a
href="https://doi.org/10.1007/s00453-022-01037-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A k-queue layout is a special type of a linear layout, in which the linear order avoids $$(k+1)$$ -rainbows, that is, $$k+1$$ independent edges that pairwise form a nested pair. The optimization goal is to determine the queue number of a graph, which is defined as the minimum value of k for which a k-queue layout is feasible. Recently, Dujmović et al. [J. ACM, 67(4), 22:1–38, 2020] showed that the queue number of planar graphs is at most 49, thus settling in the positive a long-standing conjecture by Heath, Leighton and Rosenberg. To achieve this breakthrough result, their approach involves three different techniques: (1) an algorithm to obtain 2-queue layouts of outerplanar graphs, (2) an algorithm to obtain 5-queue layouts of planar 3-trees, and (3) a decomposition of a planar graph into so-called tripods. In this work, we push further each of these techniques to obtain the first non-trivial improvement of the upper bound on the queue number of planar graphs from 49 to $$42 $$ .},
  archive      = {J_Alg},
  author       = {Bekos, Michael and Gronemann, Martin and Raftopoulou, Chrysanthi N.},
  doi          = {10.1007/s00453-022-01037-4},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {544-562},
  shortjournal = {Algorithmica},
  title        = {An improved upper bound on the queue number of planar graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Succinct permutation graphs. <em>Alg</em>, <em>85</em>(2),
509–543. (<a href="https://doi.org/10.1007/s00453-022-01039-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a succinct data structure for permutation graphs, and their superclass of circular permutation graphs, i.e., data structures using optimal space up to lower order terms. Unlike concurrent work on circle graphs (Acan et al. in Theor Comput Sci, https://doi.org/10.1016/j.tcs.2022.06.022 , 2022), our data structure also supports distance and shortest-path queries, as well as adjacency and neighborhood queries, all in optimal time. We present in particular the first succinct exact distance oracle for (circular) permutation graphs. A second succinct data structure also supports degree queries in time independent of the neighborhood’s size at the expense of an $$O(\log n/\log \log n)$$ -factor overhead in all running times. Furthermore, we develop a succinct data structure for the class of bipartite permutation graphs. We demonstrate how to run algorithms directly over our succinct representations for several problems on permutation graphs: Clique, Coloring, Independent Set, Hamiltonian Cycle, All-Pair Shortest Paths, and others. Finally, we initiate the study of semi-distributed graph representations; a concept that smoothly interpolates between distributed (labeling schemes) and centralized (standard data structures). We show how to turn some of our data structures into semi-distributed representations by storing only $$O(n)$$ bits of additional global information, circumventing the lower bound on distance labeling schemes for permutation graphs.},
  archive      = {J_Alg},
  author       = {Tsakalidis, Konstantinos and Wild, Sebastian and Zamaraev, Viktor},
  doi          = {10.1007/s00453-022-01039-2},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {509-543},
  shortjournal = {Algorithmica},
  title        = {Succinct permutation graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast exact dynamic time warping on run-length encoded time
series. <em>Alg</em>, <em>85</em>(2), 492–508. (<a
href="https://doi.org/10.1007/s00453-022-01038-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic Time Warping (DTW) is a well-known similarity measure for time series. The standard dynamic programming approach to compute the DTW distance of two length-n time series, however, requires $$O(n^2)$$ time, which is often too slow for real-world applications. Therefore, many heuristics have been proposed to speed up the DTW computation. These are often based on lower bounding techniques, approximating the DTW distance, or considering special input data such as binary or piecewise constant time series. In this paper, we present a first exact algorithm to compute the DTW distance of two run-length encoded time series whose running time only depends on the encoding lengths of the inputs. The worst-case running time is cubic in the encoding length. In experiments we show that our algorithm is indeed fast for time series with short encoding lengths.},
  archive      = {J_Alg},
  author       = {Froese, Vincent and Jain, Brijnesh and Rymar, Maciej and Weller, Mathias},
  doi          = {10.1007/s00453-022-01038-3},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {492-508},
  shortjournal = {Algorithmica},
  title        = {Fast exact dynamic time warping on run-length encoded time series},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parameterized complexity of computing maximum minimal
blocking and hitting sets. <em>Alg</em>, <em>85</em>(2), 444–491. (<a
href="https://doi.org/10.1007/s00453-022-01036-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A blocking set in a graph G is a subset of vertices that intersects every maximum independent set of G. Let $$\textsf {mmbs} (G)$$ be the size of a maximum (inclusion-wise) minimal blocking set of G. This parameter has recently played an important role in the kernelization of Vertex Cover with structural parameterizations. We provide a panorama of the complexity of computing $$\textsf {mmbs} $$ parameterized by the natural parameter and the independence number of the input graph. We also consider the closely related parameter $$\textsf {mmhs} $$ , which is the size of a maximum minimal hitting set of a hypergraph. Finally, we consider the problem of computing $$\textsf {mmbs} $$ parameterized by treewidth, especially relevant in the context of kernelization. Since a blocking set intersects every maximum-sized independent set of a given graph and properties involving counting the sizes of arbitrarily large sets are typically non-expressible in monadic second-order logic, its tractability does not seem to follow from Courcelle’s theorem. Our main technical contribution is a fixed-parameter tractable algorithm for this problem.},
  archive      = {J_Alg},
  author       = {Araújo, Júlio and Bougeret, Marin and Campos, Victor A. and Sau, Ignasi},
  doi          = {10.1007/s00453-022-01036-5},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {444-491},
  shortjournal = {Algorithmica},
  title        = {Parameterized complexity of computing maximum minimal blocking and hitting sets},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Round-competitive algorithms for uncertainty problems with
parallel queries. <em>Alg</em>, <em>85</em>(2), 406–443. (<a
href="https://doi.org/10.1007/s00453-022-01035-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In computing with explorable uncertainty, one considers problems where the values of some input elements are uncertain, typically represented as intervals, but can be obtained using queries. Previous work has considered query minimization in the settings where queries are asked sequentially (adaptive model) or all at once (non-adaptive model). We introduce a new model where k queries can be made in parallel in each round, and the goal is to minimize the number of query rounds. Using competitive analysis, we present upper and lower bounds on the number of query rounds required by any algorithm in comparison with the optimal number of query rounds for the given instance. Given a set of uncertain elements and a family of m subsets of that set, we study the problems of sorting all m subsets and of determining the minimum value (or the minimum element(s)) of each subset. We also study the selection problem, i.e., the problem of determining the i-th smallest value and identifying all elements with that value in a given set of uncertain elements. Our results include 2-round-competitive algorithms for sorting and selection and an algorithm for the minimum value problem that uses at most $$(2+\varepsilon ) \cdot \mathrm {opt}_k+\mathrm {O}\left( \frac{1}{\varepsilon } \cdot \lg m\right) $$ query rounds for every $$0&lt;\varepsilon &lt;1$$ , where $$\mathrm {opt}_k$$ is the optimal number of query rounds.},
  archive      = {J_Alg},
  author       = {Erlebach, Thomas and Hoffmann, Michael and de Lima, Murilo Santos},
  doi          = {10.1007/s00453-022-01035-6},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {406-443},
  shortjournal = {Algorithmica},
  title        = {Round-competitive algorithms for uncertainty problems with parallel queries},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving target set selection with bounded thresholds faster
than <span class="math display">2<sup><em>n</em></sup></span>.
<em>Alg</em>, <em>85</em>(2), 384–405. (<a
href="https://doi.org/10.1007/s00453-022-01031-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider the Target Set Selection problem. The problem naturally arises in many fields like economy, sociology, medicine. In the Target Set Selection problem one is given a graph G with a function $${{\,\mathrm{thr}\,}}: V(G) \rightarrow {\mathbb {N}} \cup {0}$$ and two integers $$k, \ell $$ . The goal of the problem is to activate at most k vertices initially so that at the end of the activation process there are at least $$\ell $$ activated vertices. The activation process occurs in the following way: (i) once activated, a vertex stays activated forever; (ii) a vertex v becomes activated if at least $${{\,\mathrm{thr}\,}}(v)$$ of its neighbours are activated. The problem and its different special cases were extensively studied from the approximation and parameterized points of view. For example, parameterizations by the following parameters were studied: treewidth, feedback vertex set, diameter, size of target set, vertex cover, cluster editing number and others. Despite the extensive study of the problem it is still unknown whether the problem can be solved in $${\mathcal {O}}^*\left( (2-\epsilon )^n\right) $$ time for some $$\epsilon &gt;0$$ . We partially answer this question by presenting several faster-than-trivial algorithms that work in cases of constant thresholds, constant dual thresholds or when the threshold value of each vertex is bounded by one-third of its degree. Also, we show that the problem parameterized by $$\ell $$ is W[1]-hard even when all thresholds are constant.},
  archive      = {J_Alg},
  author       = {Bliznets, Ivan and Sagunov, Danil},
  doi          = {10.1007/s00453-022-01031-w},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {384-405},
  shortjournal = {Algorithmica},
  title        = {Solving target set selection with bounded thresholds faster than $$2^n$$},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient isomorphism for <span
class="math display"><em>S</em><sub><em>d</em></sub></span> -graphs and
t-graphs. <em>Alg</em>, <em>85</em>(2), 352–383. (<a
href="https://doi.org/10.1007/s00453-022-01033-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An H-graph is one representable as the intersection graph of connected subgraphs of a suitable subdivision of a fixed graph H, introduced by Biró et al. (Discrete Mathematics 100:267–279, 1992). An H-graph is proper if the representing subgraphs of H can be chosen incomparable by the inclusion. In this paper, we focus on the isomorphism problem for $$S_d$$ -graphs and T-graphs, where $$S_d$$ is the star with d rays and T is an arbitrary fixed tree. Answering an open problem of Chaplick et al. (2016, personal communication), we provide an FPT-time algorithm for testing isomorphism and computing the automorphism group of $$S_d$$ -graphs when parameterized by d, which involves the classical group-computing machinery by Furst et al. (in Proceedings of 11th southeastern conference on combinatorics, graph theory, and computing, congressum numerantium 3, 1980). We also show that the isomorphism problem of $$S_d$$ -graphs is at least as hard as the isomorphism problem of posets of bounded width, for which no efficient combinatorial-only algorithm is known to date. Then we extend our approach to an XP-time algorithm for isomorphism of T-graphs when parameterized by the size of T. Lastly, we contribute an FPT-time combinatorial algorithm for isomorphism testing in the special case of proper $$S_d$$ - and T-graphs.},
  archive      = {J_Alg},
  author       = {Ağaoğlu Çağırıcı, Deniz and Hliněný, Petr},
  doi          = {10.1007/s00453-022-01033-8},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {352-383},
  shortjournal = {Algorithmica},
  title        = {Efficient isomorphism for $$S_d$$ -graphs and T-graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parameterized complexity of diameter. <em>Alg</em>,
<em>85</em>(2), 325–351. (<a
href="https://doi.org/10.1007/s00453-022-01032-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diameter—the task of computing the length of a longest shortest path—is a fundamental graph problem. Assuming the Strong Exponential Time Hypothesis, there is no $$O(n^{1.99})$$ -time algorithm even in sparse graphs (Roditty L, Williams, VV in Fast approximation algorithms for the diameter and radius of sparse graphs. In: Proceedings of the 45th Symposium on Theory of Computing Conference (STOC ’13), pp 515–524. ACM, 2013). To circumvent this lower bound, we investigate which parameters allow for running times of the form $$f(k) (n+m)$$ where k is the respective parameter and f is a computable function. To this end, we systematically explore a hierarchy of structural graph parameters.},
  archive      = {J_Alg},
  author       = {Bentert, Matthias and Nichterlein, André},
  doi          = {10.1007/s00453-022-01032-9},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {325-351},
  shortjournal = {Algorithmica},
  title        = {Parameterized complexity of diameter},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parallel online algorithms for the bin packing problem.
<em>Alg</em>, <em>85</em>(1), 296–323. (<a
href="https://doi.org/10.1007/s00453-022-01030-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study parallel online algorithms: For some fixed integer k, a collective of k parallel processes that perform online decisions on the same sequence of events forms a k-copy algorithm. For any given time and input sequence, the overall performance is determined by the best of the k individual total results. Problems of this type have been considered for online makespan minimization; they are also related to optimization with advice on future events, i.e., a number of bits available in advance. Parallel online algorithms are also of interest in practical scenarios in which redundancy is used for hedging against undesired outcomes. We develop Predictive Harmonic $$_3$$ (PH3), a relatively simple family of k-copy algorithms for the online Bin Packing Problem, whose joint competitive factor converges to 1.5 for increasing k. In particular, we show that $$k=6$$ suffices to guarantee a factor of 1.5714 for PH3, which is better than 1.57829, the performance of the best known 1-copy algorithm Advanced Harmonic, while $$k=11$$ suffices to achieve a factor of 1.5406, beating the known lower bound of 1.54278 for a single online algorithm. In the context of online optimization with advice, our approach implies that 4 bits suffice to achieve a factor better than this bound of 1.54278, which is considerably less than the previous bound of 15 bits.},
  archive      = {J_Alg},
  author       = {Fekete, Sándor P. and Grosse-Holz, Jonas and Keldenich, Phillip and Schmidt, Arne},
  doi          = {10.1007/s00453-022-01030-x},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {296-323},
  shortjournal = {Algorithmica},
  title        = {Parallel online algorithms for the bin packing problem},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A simple algorithm for higher-order delaunay mosaics and
alpha shapes. <em>Alg</em>, <em>85</em>(1), 277–295. (<a
href="https://doi.org/10.1007/s00453-022-01027-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a simple algorithm for computing higher-order Delaunay mosaics that works in Euclidean spaces of any finite dimensions. The algorithm selects the vertices of the order-k mosaic from incrementally constructed lower-order mosaics and uses an algorithm for weighted first-order Delaunay mosaics as a black-box to construct the order-k mosaic from its vertices. Beyond this black-box, the algorithm uses only combinatorial operations, thus facilitating easy implementation. We extend this algorithm to compute higher-order $$\alpha $$ -shapes and provide open-source implementations. We present experimental results for properties of higher-order Delaunay mosaics of random point sets.},
  archive      = {J_Alg},
  author       = {Edelsbrunner, Herbert and Osang, Georg},
  doi          = {10.1007/s00453-022-01027-6},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {277-295},
  shortjournal = {Algorithmica},
  title        = {A simple algorithm for higher-order delaunay mosaics and alpha shapes},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-stabilizing and private distributed shared atomic
memory in seldomly fair message passing networks. <em>Alg</em>,
<em>85</em>(1), 216–276. (<a
href="https://doi.org/10.1007/s00453-022-01023-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of privately emulating shared memory in message-passing networks. The system includes clients that store and retrieve replicated information on N servers, out of which e are data-corrupting malicious. When a client accesses a data-corrupting malicious server, the data field of that server response might be different from the value it originally stored. However, all other control variables in the server reply and protocol actions are according to the server algorithm. For the coded atomic storage algorithms by Cadambe et al., we present an enhancement that ensures no information leakage and data-corrupting malicious fault-tolerance. We also consider recovery after the occurrence of transient faults that violate the assumptions according to which the system was designed to operate. After their last occurrence, transient faults leave the system in an arbitrary state (while the program code stays intact). We present a self-stabilizing algorithm, which recovers after the occurrence of transient faults. This addition to Cadambe et al. considers asynchronous settings as long as no transient faults occur. The recovery from transient faults that bring the system counters (close) to their maximal values may include the use of a global reset procedure, which requires the system run to be controlled by a fair scheduler. After the recovery period, the safety properties are provided for asynchronous system runs that are not necessarily controlled by fair schedulers. Since the recovery period is bounded and the occurrence of transient faults is extremely rare, we call this design criteria self-stabilization in the presence of seldom fairness. Our self-stabilizing algorithm uses a bounded amount of storage during asynchronous executions (that are not necessarily controlled by fair schedulers). To the best of our knowledge, we are the first to address privacy, data-corrupting malicious behavior, and self-stabilization in the context of emulating atomic shared memory in message-passing systems.},
  archive      = {J_Alg},
  author       = {Dolev, Shlomi and Petig, Thomas and Schiller, Elad M.},
  doi          = {10.1007/s00453-022-01023-w},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {216-276},
  shortjournal = {Algorithmica},
  title        = {Self-stabilizing and private distributed shared atomic memory in seldomly fair message passing networks},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). General lower bounds and improved algorithms for
infinite–domain CSPs. <em>Alg</em>, <em>85</em>(1), 188–215. (<a
href="https://doi.org/10.1007/s00453-022-01017-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the fine-grained complexity of NP-complete, infinite-domain constraint satisfaction problems (CSPs) parameterised by a set of first-order definable relations (with equality). Such CSPs are of central importance since they form a subclass of any infinite-domain CSP parameterised by a set of first-order definable relations over a relational structure (possibly containing more than just equality). We prove that under the randomised exponential-time hypothesis it is not possible to find $$c &gt; 1$$ such that a CSP over an arbitrary finite equality language is solvable in $$O(c^n)$$ time (n is the number of variables). Stronger lower bounds are possible for infinite equality languages where we rule out the existence of $$2^{o(n \log n)}$$ time algorithms; a lower bound which also extends to satisfiability modulo theories solving for an arbitrary background theory. Despite these lower bounds we prove that for each $$c &gt; 1$$ there exists an NP-hard equality CSP solvable in $$O(c^n)$$ time. Lower bounds like these immediately ask for closely matching upper bounds, and we prove that a CSP over a finite equality language is always solvable in $$O(c^n)$$ time for a fixed c, and manage to extend this algorithm to the much broader class of CSPs where constraints are formed by first-order formulas over a unary structure.},
  archive      = {J_Alg},
  author       = {Jonsson, Peter and Lagerkvist, Victor},
  doi          = {10.1007/s00453-022-01017-8},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {188-215},
  shortjournal = {Algorithmica},
  title        = {General lower bounds and improved algorithms for Infinite–Domain CSPs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Double string tandem repeats. <em>Alg</em>, <em>85</em>(1),
170–187. (<a href="https://doi.org/10.1007/s00453-022-01016-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A tandem repeat is an occurrence of two adjacent identical substrings. In this paper, we introduce the notion of a double string, which consists of two parallel strings, and we study the problem of locating all tandem repeats in a double string. The problem introduced here has applications beyond actual double strings, as we illustrate by solving two different problems with the algorithm of the double string tandem repeats problem. The first problem is that of finding all corner-sharing tandems in a 2-dimensional text, defined by Apostolico and Brimkov. The second problem is that of finding all scaled tandem repeats in a 1d text, where a scaled tandem repeat is defined as a string $$UU&#39;$$ such that $$U&#39;$$ is discrete scale of U. In addition to the algorithms for exact tandem repeats, we also present algorithms that solve the problem in the inexact sense, allowing up to k mismatches. We believe that this framework will open a new perspective for other problems in the future.},
  archive      = {J_Alg},
  author       = {Amir, Amihood and Butman, Ayelet and Landau, Gad M. and Marcus, Shoshana and Sokol, Dina},
  doi          = {10.1007/s00453-022-01016-9},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {170-187},
  shortjournal = {Algorithmica},
  title        = {Double string tandem repeats},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combination algorithms for steiner tree variants.
<em>Alg</em>, <em>85</em>(1), 153–169. (<a
href="https://doi.org/10.1007/s00453-022-01009-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We give better approximation ratios for two Steiner Tree variants by combining known algorithms: the optimum $$\mathbf{3}$$ -decomposition and iterative randomized rounding. The first problem is Steiner Tree with minimum number of Steiner points and bounded edge length problem ( $${\varvec{SMT-MSP}}$$ ). The input consists of a set of terminals $${\varvec{R}}$$ in the Euclidean space $${\mathbb {R}}^{\mathbf{2}}$$ . A feasible solution is a Steiner tree $${\varvec{\tau }}$$ spanning $${\varvec{R}}$$ with Steiner points $${\varvec{S}}$$ such that every edge in $${\varvec{\tau }}$$ has length at most $$\mathbf{1}$$ . The objective is to minimize $$\mathtt{S}$$ . Previously, the best approximation ratio for $${\varvec{SMT-MSP}}$$ was $$\mathbf{1} +$$ ln $$(\mathbf{4}) + {\varvec{\epsilon }} \approx \mathbf{2.386}$$ . We present a polynomial time algorithm with ratio $$\mathbf{2.277}$$ . The second problem is Steiner Tree in quasi-bipartite graphs. It is a Steiner Tree problem on graph $${\varvec{G}}=({\varvec{V}},{\varvec{E}},{\varvec{c}})$$ with terminal set $${\varvec{R}}$$ when the edge set $${\varvec{E}}$$ does not include any edge between two vertices in $${\varvec{V}} \setminus {\varvec{R}}$$ . The best-known approximation ratio for this problem is $$ \frac{\mathbf{73}}{\mathbf{60}}$$ , We improve this ratio to $$\frac{\mathbf{298}}{\mathbf{245}}$$ .},
  archive      = {J_Alg},
  author       = {Călinescu, Gruia and Wang, Xiaolang},
  doi          = {10.1007/s00453-022-01009-8},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {153-169},
  shortjournal = {Algorithmica},
  title        = {Combination algorithms for steiner tree variants},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parameterized study of steiner tree on unit disk graphs.
<em>Alg</em>, <em>85</em>(1), 133–152. (<a
href="https://doi.org/10.1007/s00453-022-01020-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the Steiner Tree problem on unit disk graphs. Given a n vertex unit disk graph G, a subset $$R\subseteq V(G)$$ of t vertices and a positive integer k, the objective is to decide if there exists a tree T in G that spans over all vertices of R and uses at most k vertices from $$V\setminus R$$ . The vertices of R are referred to as terminals and the vertices of $$V(G)\setminus R$$ as Steiner vertices. First, we show that the problem is NP-hard. Next, we prove that the Steiner Tree problem on unit disk graphs can be solved in $$n^{O(\sqrt{t+k})}$$ time. We also show that the Steiner Tree problem on unit disk graphs parameterized by k has an FPT algorithm with running time $$2^{O(k)}n^{O(1)}$$ . In fact, the algorithms are designed for a more general class of graphs, called clique-grid graphs Fomin (Discret. Comput. Geometry 62(4):879–911, 2019). We mention that the algorithmic results can be made to work for Steiner Tree problem on disk graphs with bounded aspect ratio. Finally, we prove that Steiner Tree problem on disk graphs parameterized by k, is W[1]-hard.},
  archive      = {J_Alg},
  author       = {Bhore, Sujoy and Carmi, Paz and Kolay, Sudeshna and Zehavi, Meirav},
  doi          = {10.1007/s00453-022-01020-z},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {133-152},
  shortjournal = {Algorithmica},
  title        = {Parameterized study of steiner tree on unit disk graphs},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A constant–factor approximation algorithm for red–blue set
cover with unit disks. <em>Alg</em>, <em>85</em>(1), 100–132. (<a
href="https://doi.org/10.1007/s00453-022-01012-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main contribution of this paper is the first constant factor approximation algorithm for red-blue set cover problem with unit disks. To achieve this, we first give a polynomial time algorithm for line-separable red-blue set cover problem with unit disks. We next obtain a factor 2 approximation algorithm for strip-separable red-blue set cover problem with unit disks. Finally, we obtain a constant factor approximation algorithm for red-blue set cover problem with unit disks by combining our algorithm for the strip-separable problem with the results of Ambühl et al. [1]. Our methods involve a novel decomposition of the optimal solution to line-separable problem into blocks with special structure and extensions of the sweep-line technique of Erlebach and van Leeuwen [9].},
  archive      = {J_Alg},
  author       = {Madireddy, Raghunath Reddy and Mudgal, Apurva},
  doi          = {10.1007/s00453-022-01012-z},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {100-132},
  shortjournal = {Algorithmica},
  title        = {A Constant–Factor approximation algorithm for Red–Blue set cover with unit disks},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Algorithms for counting minimum-perimeter lattice animals.
<em>Alg</em>, <em>85</em>(1), 75–99. (<a
href="https://doi.org/10.1007/s00453-022-01008-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A 2-dimensional lattice animal is a set of edge-connected cells on some lattice. In this paper, we address the problem of counting minimum-perimeter lattice animals, that is, animals that have the minimum possible perimeter of all animals of the same area. We provide two types of algorithms for counting minimum-perimeter animals on two lattices, namely, the square and hexagonal lattices, and analyze and compare the algorithms.},
  archive      = {J_Alg},
  author       = {Barequet, Gill and Ben-Shachar, Gil},
  doi          = {10.1007/s00453-022-01008-9},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {75-99},
  shortjournal = {Algorithmica},
  title        = {Algorithms for counting minimum-perimeter lattice animals},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Empty squares in arbitrary orientation among points.
<em>Alg</em>, <em>85</em>(1), 29–74. (<a
href="https://doi.org/10.1007/s00453-022-01002-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies empty squares in arbitrary orientation among a set P of n points in the plane. We prove that the number of empty squares with four contact pairs is between $$\Omega (n)$$ and $$O(n^2)$$ , and that these bounds are tight, provided P is in general position. A contact pair of a square is a pair of a point $$p\in P$$ and a side $$\ell $$ of the square with $$p\in \ell $$ . The upper bound $$O(n^2)$$ also applies to the number of empty squares with four contact points. Meanwhile, the lower bound becomes 0 as we can construct a point set among which there is no square of four contact points. These combinatorial results are based on new observations on the $$L_\infty $$ Voronoi diagram with the axes rotated and its close connection to empty squares in arbitrary orientation. We then present an algorithm that maintains a combinatorial structure of the $$L_\infty $$ Voronoi diagram of P, while the axes of the plane continuously rotate by 90 degrees, and simultaneously reports all empty squares with four contact pairs among P in an output-sensitive way within $$O(s\log n)$$ time and O(n) space, where s denotes the number of reported squares. Several new algorithmic results are also obtained: a largest empty square among P and a square annulus of minimum width or minimum area that encloses P over all orientations can be computed in worst-case $$O(n^2 \log n)$$ time.},
  archive      = {J_Alg},
  author       = {Bae, Sang Won and Yoon, Sang Duk},
  doi          = {10.1007/s00453-022-01002-1},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {29-74},
  shortjournal = {Algorithmica},
  title        = {Empty squares in arbitrary orientation among points},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Grundy coloring and friends, half-graphs, bicliques.
<em>Alg</em>, <em>85</em>(1), 1–28. (<a
href="https://doi.org/10.1007/s00453-022-01001-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The first-fit coloring is a heuristic that assigns to each vertex, arriving in a specified order $$\sigma $$ , the smallest available color. The problem Grundy Coloring asks how many colors are needed for the most adversarial vertex ordering $$\sigma $$ , i.e., the maximum number of colors that the first-fit coloring requires over all possible vertex orderings. Since its inception by Grundy in 1939, Grundy Coloring has been examined for its structural and algorithmic aspects. A brute-force $$f(k)n^{2^{k-1}}$$ -time algorithm for Grundy Coloring on general graphs is not difficult to obtain, where k is the number of colors required by the most adversarial vertex ordering. It was asked several times whether the dependency on k in the exponent of n can be avoided or reduced, and its answer seemed elusive until now. We prove that Grundy Coloring is W[1]-hard and the brute-force algorithm is essentially optimal under the Exponential Time Hypothesis, thus settling this question by the negative. The key ingredient in our W[1]-hardness proof is to use so-called half-graphs as a building block to transmit a color from one vertex to another. Leveraging the half-graphs, we also prove that $$b$$ -Chromatic Core is W[1]-hard, whose parameterized complexity was posed as an open question by Panolan et al. [JCSS ’17]. A natural follow-up question is, how the parameterized complexity changes in the absence of (large) half-graphs. We establish fixed-parameter tractability on $$K_{t,t}$$ -free graphs for $$b$$ -Chromatic Core and Partial Grundy Coloring, making a step toward answering this question. The key combinatorial lemma underlying the tractability result might be of independent interest.},
  archive      = {J_Alg},
  author       = {Aboulker, Pierre and Bonnet, Édouard and Kim, Eun Jung and Sikora, Florian},
  doi          = {10.1007/s00453-022-01001-2},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Algorithmica},
  title        = {Grundy coloring and friends, half-graphs, bicliques},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
