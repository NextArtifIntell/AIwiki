<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>PAAA_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="paaa---115">PAAA - 115</h2>
<ul>
<li><details>
<summary>
(2023). AdaHOSVD: An adaptive higher-order singular value
decomposition method for point cloud denoising. <em>PAAA</em>,
<em>26</em>(4), 1847–1862. (<a
href="https://doi.org/10.1007/s10044-023-01191-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Higher-Order Singular Value Decomposition (HOSVD) is an effective method for point cloud denoising, however how to preserve the global and local structure during the denoising process and how to balance the denoising performance and its inherent large computational burden are still open questions in the field. To tackle these problems, an adaptive higher-order singular value decomposition method, AdaHOSVD including two sub-algorithms HOSVD-1 and HOSVD-2, is proposed in this work by adaptively setting the threshold value to truncate the kernel tensor, and by limiting the patch similarity searching within a search radius. Since point cloud is in 3D space rather than a 2D plane as in image cases, we extend the patch similarity detection in 3D space up to a 3D rigid motion; hence, more similar 3D patches could be detected, which in turn boosts its performance. We validate our method on two datasets. One is the 3D benchmark dataset including the ShapeNetCore and the 3D scanning repository of Stanford University, which contains a large body of diverse high quality shapes to assess its noise sensitivity, and the other is the Golden Temple and the Electric hook, which contains a large temple structure with abundant local repeated textural and shape patterns.},
  archive      = {J_PAAA},
  author       = {Hu, Lihua and Liang, Wenhao and Bai, Yuting and Zhang, Jifu},
  doi          = {10.1007/s10044-023-01191-7},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1847-1862},
  shortjournal = {Pattern Anal. Appl.},
  title        = {AdaHOSVD: An adaptive higher-order singular value decomposition method for point cloud denoising},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EMTNet: Efficient mobile transformer network for real-time
monocular depth estimation. <em>PAAA</em>, <em>26</em>(4), 1833–1846.
(<a href="https://doi.org/10.1007/s10044-023-01205-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating depth from a single image presents a formidable challenge due to the inherently ill-posed and ambiguous nature of deriving depth information from a 3D scene. Prior approaches to monocular depth estimation have mainly relied on Convolutional Neural Networks (CNNs) or Vision Transformers (ViTs) as the primary feature extraction methods. However, striking a balance between speed and accuracy for real-time tasks has proven to be a formidable hurdle with these methods. In this study, we proposed a new model called EMTNet, which extracts feature information from images at both local and global scales by combining CNN and ViT. To reduce the number of parameters, EMTNet introduces the mobile transformer block (MTB), which reuses parameters from self-attention. High-resolution depth maps are generated by fusing multi-scale features in the decoder. Through comprehensive validation on the NYU Depth V2 and KITTI datasets, the results demonstrate that EMTNet outperforms previous real-time monocular depth estimation models based on CNNs and hybrid architecture. In addition, we have done the corresponding generalizability tests and ablation experiments to verify our conjectures. The depth map output from EMTNet exhibits intricate details and attains a real-time frame rate of 32 FPS, achieving a harmonious balance between real-time and accuracy.},
  archive      = {J_PAAA},
  author       = {Yan, Long and Yu, Fuyang and Dong, Chao},
  doi          = {10.1007/s10044-023-01205-4},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1833-1846},
  shortjournal = {Pattern Anal. Appl.},
  title        = {EMTNet: Efficient mobile transformer network for real-time monocular depth estimation},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bel: Batch equalization loss for scene graph generation.
<em>PAAA</em>, <em>26</em>(4), 1821–1831. (<a
href="https://doi.org/10.1007/s10044-023-01199-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since scene graph can be used as the basis of many high-level vision semantic tasks, scene graph generation has attracted more and more attention of researchers, but most works are limited by the long-tail distribution of dataset, tend to predict those frequent but uninformative predicates such as “on” and “of.” From a novel perspective, we found that in the training process, the model would promote the categories included in the batch, while suppressing the categories not in the batch. The long-tailed distribution of the data leads to the continuous suppression of tail categories, thus results in the model bias. In order to solve the problem above, we propose a novel simple and effective method named Batch Equalization Loss, which can be applied to most of the existing models and can bring effective improvement with only a few changes. It is worth noting that our method can achieve a more significant improvement on small batches than on big batches. Extensive experiments on the VG150 dataset show that our work can bring significant improvement on the basis of existing works. Code will be available at GitHub in the near future.},
  archive      = {J_PAAA},
  author       = {Li, Huihui and Liu, Baorong and Wu, Dongqing and Liu, Hang and Guo, Lei},
  doi          = {10.1007/s10044-023-01199-z},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1821-1831},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Bel: Batch equalization loss for scene graph generation},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ViT-PGC: Vision transformer for pedestrian gender
classification on small-size dataset. <em>PAAA</em>, <em>26</em>(4),
1805–1819. (<a
href="https://doi.org/10.1007/s10044-023-01196-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian gender classification (PGC) is a key task in full-body-based pedestrian image analysis and has become an important area in applications like content-based image retrieval, visual surveillance, smart city, and demographic collection. In the last decade, convolutional neural networks (CNN) have appeared with great potential and with reliable choices for vision tasks, such as object classification, recognition, detection, etc. But CNN has a limited local receptive field that prevents them from learning information about the global context. In contrast, a vision transformer (ViT) is a better alternative to CNN because it utilizes a self-attention mechanism to attend to a different patch of an input image. In this work, generic and effective modules such as locality self-attention (LSA), and shifted patch tokenization (SPT)-based vision transformer model are explored for the PGC task. With the use of these modules in ViT, it is successfully able to learn from stretch even on small-size (SS) datasets and overcome the lack of locality inductive bias. Through extensive experimentation, we found that the proposed ViT model produced better results in terms of overall and mean accuracies. The better results confirm that ViT outperformed state-of-the-art (SOTA) PGC methods.},
  archive      = {J_PAAA},
  author       = {Abbas, Farhat and Yasmin, Mussarat and Fayyaz, Muhammad and Asim, Usman},
  doi          = {10.1007/s10044-023-01196-2},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1805-1819},
  shortjournal = {Pattern Anal. Appl.},
  title        = {ViT-PGC: Vision transformer for pedestrian gender classification on small-size dataset},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised multimodal learning for image-text relation
classification in tweets. <em>PAAA</em>, <em>26</em>(4), 1793–1804. (<a
href="https://doi.org/10.1007/s10044-023-01204-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies show that the use of multimodality can effectively enhance the understanding of social media content. The relations between texts and images become an important basis for developing multimodal data and models. Some studies have attempted to label image-text relation (ITR) and build supervised learning models. However, manually labeling ITR is a challenging task and incurs many controversial labels because of disagreements among the annotators. In this paper, we present a novel unsupervised multimodal method called ITR pseudo-labeling (ITRp) that learns multimodal representations for various ITR types using different finetuning strategies. Our ITRp method generates pseudo-labels by clustering and uses them as supervision to train the classifier and encoders. We evaluate the ITRp method on the ITR dataset and the effects of the samples with incorrect labels on both the supervised and unsupervised models. The code and data are available on the website https://github.com/SuYindu/ITRp .},
  archive      = {J_PAAA},
  author       = {Sun, Lin and Li, Qingyuan and Liu, Long and Su, Yindu},
  doi          = {10.1007/s10044-023-01204-5},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1793-1804},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Unsupervised multimodal learning for image-text relation classification in tweets},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid ABC and black hole algorithm with genetic operators
optimized SVM ensemble based diagnosis of breast cancer. <em>PAAA</em>,
<em>26</em>(4), 1771–1791. (<a
href="https://doi.org/10.1007/s10044-023-01203-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forever and a day, breast cancer has caused significant negative impacts on the quality of lives of number of women, more often than not turning into a fatal disease. The growth in the number of such cases has constantly been a major concern for the community as well as medical experts. To prevent irreversible damages caused by the disease, early identification of breast cancer is essential. Various researches and techniques have been devised in the past as an attempt to achieve this task with appreciable accuracy. As an advancement to these pre-existing algorithms and methods, we have devised a model by exploiting the techniques of nature-inspired metaheuristics in order to efficiently detect breast cancer at an early stage while maintaining acceptable levels of accuracy. In this paper, we propose a hybrid model, namely “hybrid artificial bee colony and black hole with genetic operators (GBHABC)”, for the early detection of breast cancer. In the proposed model, we employed a support vector machine (SVM) ensemble technique, optimized using the proposed GBHABC model. This model combines the techniques of two major algorithms, namely artificial bee colony (ABC) and black hole (BH), guided through crossover and mutation genetic operators. Datasets from the well-known UCI breast cancer repository have been used to train the models and evaluate test result. For a fair and accurate evaluation of the model, a number of metrics have been examined including accuracy, sensitivity, specificity, F1-score and precision. An impeccable accuracy of 99.42% was obtained on the UCI dataset, clearly outperforming any literature in the same field.},
  archive      = {J_PAAA},
  author       = {Singh, Indu and Srinivasa, K. G. and Maurya, Mridul and Aggarwal, Aditya and Sheokand, Himanshu and Gunwant, Harsh and Dhalwal, Mohit},
  doi          = {10.1007/s10044-023-01203-6},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1771-1791},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Hybrid ABC and black hole algorithm with genetic operators optimized SVM ensemble based diagnosis of breast cancer},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised open-world human action recognition.
<em>PAAA</em>, <em>26</em>(4), 1753–1770. (<a
href="https://doi.org/10.1007/s10044-023-01202-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open-world recognition (OWR) is an important field of research that strives to develop machine learning models capable of identifying and learning new classes as they appear. Concurrently, human action recognition (HAR) has received increasing attention from the research community. We approach Open-World HAR in the unsupervised setting. In unsupervised OWR, class labels are available for the initial classes but not for new ones. Hence, we propose a clustering method to label unknown classes automatically for incremental learning (IL). Our framework consists of an Initial Learning phase for initializing the models, an open-set recognition phase for identifying unknown classes, an Automatic Clustering phase for estimating the number of clusters and generating labels, and an IL phase for incorporating new knowledge. The proposed framework was evaluated at each phase separately in eleven experimental settings of the UCF-101 dataset. We also presented parameter sensitivity studies of the main parameters and visual analysis of misclassified videos, revealing interesting visual similarities between overlapped classes. Experiments have shown promising results in all phases of Open-World HAR, even without labels, which closely resembles real-world problems.},
  archive      = {J_PAAA},
  author       = {Gutoski, Matheus and Lazzaretti, André Eugenio and Lopes, Heitor Silvério},
  doi          = {10.1007/s10044-023-01202-7},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1753-1770},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Unsupervised open-world human action recognition},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive frequency-based fully hyperbolic graph neural
networks. <em>PAAA</em>, <em>26</em>(4), 1741–1751. (<a
href="https://doi.org/10.1007/s10044-023-01201-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Convolutional Networks (GCNs) have attracted broad attention from industry and academia, for their excellent expressive power in terms of modeling the irregular data, e.g., skeletal data and graph-structured data. The most effective existing model may be the fully hyperbolic graph neural network. However, it involves a large number of parameters, thus consuming considerable computing resources. In this paper, we propose a model based on adaptive frequency filter and corresponding optimizer in hyperbolic space. The adaptive frequency can learn the different frequency components of the embeddings of the nodes in graph, which adaptively adjust the beneficial signals of high-frequency and low-frequency. And the optimizer is based on a subset of the orthogonal constraint, which is dedicated for the adaptive frequency with less parameters. Moreover, our model bridges the gap of hyperbolic space and the spectral space for exploring the underlying semantics of the node and relation embeddings of graph. Consequently, our model needs only to optimize the less parameters in hyperbolic space and meanwhile prevent the distortion caused by conventional manifold GCN. Experimental results show that our method achieves substantial improvements and outperforms the state-of-the-art performance in terms of node classification.},
  archive      = {J_PAAA},
  author       = {Wei, FeiFei and Ping, MingZhu and Mei, KuiZhi},
  doi          = {10.1007/s10044-023-01201-8},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1741-1751},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Adaptive frequency-based fully hyperbolic graph neural networks},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SAFPN: A full semantic feature pyramid network for object
detection. <em>PAAA</em>, <em>26</em>(4), 1729–1739. (<a
href="https://doi.org/10.1007/s10044-023-01200-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enhance the performance of object detection algorithm, this paper proposes segmentation attention feature pyramid network (SAFPN) to address the issue of semantic information loss. Compared to prior works, SAFPN discards the original $$1\times 1$$ convolutions and achieves feature dimension reduction through a segmentation and accumulation architecture, thereby preserving the semantic information of high-dimensional features completely. To capture fine-grained semantic details, it integrates channel attention and spatial attention mechanisms to enhance the network’s focus on important information. Extensive experimental validation demonstrates that SAFPN achieves favorable results on multiple public datasets, and can better complete the target detection task.},
  archive      = {J_PAAA},
  author       = {Wang, Gaihua and Li, Qi and Wang, Nengyuan and Liu, Hong},
  doi          = {10.1007/s10044-023-01200-9},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1729-1739},
  shortjournal = {Pattern Anal. Appl.},
  title        = {SAFPN: A full semantic feature pyramid network for object detection},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Applying unsupervised keyphrase methods on concepts
extracted from discharge sheets. <em>PAAA</em>, <em>26</em>(4),
1715–1727. (<a
href="https://doi.org/10.1007/s10044-023-01198-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical notes contain valuable patient information. These notes are written by health care providers with various scientific levels and writing styles. It might be helpful for clinicians and researchers to understand what information is essential when dealing with extensive electronic medical records. Entities recognizing them and mapping them to standard terminologies is crucial to reducing ambiguity in processing clinical notes. Although named entity recognition and entity linking are critical steps in clinical natural language processing, they can produce repetitive and low-value concepts. On the other hand, all parts of a clinical text do not share the same importance or content in predicting the patient&#39;s condition. As a result, it is necessary to identify the section in which each content item is recorded and critical concepts to extract meaning from clinical texts. In this study, these challenges have been addressed by using clinical natural language processing techniques. In addition, a set of unsupervised essential phrase extraction methods has been verified and evaluated to identify key concepts. Considering that most clinical concepts are in the form of multi-word expressions and their accurate identification requires the user to specify an n-gram range, we have proposed a shortcut method to preserve the structure of the term based on TF-IDF (Term Frequency Inverse Document Frequency). To evaluate, we have designed two types of downstream tasks (multiple and binary classification) using the capabilities of transformer-based models. The results show the proposed method&#39;s superiority in combination with the SciBERT model. Also, they offer an insight into the efficacy of general methods for extracting essential phrases from clinical notes.},
  archive      = {J_PAAA},
  author       = {Memarzadeh, Hoda and Ghadiri, Nasser and Samwald, Matthias and Lotfi Shahreza, Maryam},
  doi          = {10.1007/s10044-023-01198-0},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1715-1727},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Applying unsupervised keyphrase methods on concepts extracted from discharge sheets},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A semantic-aware monocular projection model for accurate
pose measurement. <em>PAAA</em>, <em>26</em>(4), 1703–1714. (<a
href="https://doi.org/10.1007/s10044-023-01197-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monocular vision system is widely used in many fields due to its simple structure, faster speed, and lower cost for object measurement. However, most of the current monocular methods have complicated mathematical models or require artificial markers to achieve accurate measurement results. In addition, it is not easy to precisely extract the features of objects in the captured image which are affected by many factors. In this paper, we present a semantic-aware monocular projection model for accurate pose measurement. Our mathematical model is simple and neat, and we use deep learning network to extract the semantic features in images. Finally, the relevant parameters of the projection model are further optimized with Kalman filter to make the measurement results more accurate and stable. The extensive experiments demonstrate that the proposed method is robust with high performance and accuracy. As a few constraints are required on the measured object and environment, our method is easy for installation.},
  archive      = {J_PAAA},
  author       = {Weng, Libo and Chen, Xiuqi and Qiu, Qi and Zhuang, Yaozhong and Gao, Fei},
  doi          = {10.1007/s10044-023-01197-1},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1703-1714},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A semantic-aware monocular projection model for accurate pose measurement},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Expanded relative density peak clustering for image
segmentation. <em>PAAA</em>, <em>26</em>(4), 1685–1701. (<a
href="https://doi.org/10.1007/s10044-023-01195-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The density peak clustering (DPC) is one of the most popular algorithms for segmenting images due to its simplicity and efficiency. Since DPC and its variants are not specifically designed for image segmentation, their segmentation results do not necessarily meet both subjective and objective metrics. We propose an expanded relative density-based clustering algorithm as a solution to the above problems, which can automatically determine the cluster number and make the image segmentation results more consistent with subjective criteria. First, the image is pre-segmented into superpixels using the simple linear iterative clustering algorithm, and the superpixels are represented by feature vectors containing color and texture information. Secondly, the expanded relative density of the data point is obtained by comparing the tightness of a mini-cluster with its neighboring mini-clusters. The Sigmoid function is then applied to the data point with small density but large relative distance to further adjust its relative distance so that the distribution of cluster centers matches the characteristics of the image. Next, the optimal cluster number is determined by the rate of change of the sum of squared errors. Finally, the cluster center pairs with smaller distances are merged using the cluster center merging algorithm. The experiments conducted on synthetic and real datasets demonstrate that the performance of the proposed algorithm outperforms the compared algorithms.},
  archive      = {J_PAAA},
  author       = {Li, Miao and Ma, Yan and Huang, Hui and Wang, Bin},
  doi          = {10.1007/s10044-023-01195-3},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1685-1701},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Expanded relative density peak clustering for image segmentation},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). <span class="math display">ℒ𝒪<sup>2</sup></span> net:
Global–local semantics coupled network for scene-specific video
foreground extraction with less supervision. <em>PAAA</em>,
<em>26</em>(4), 1671–1683. (<a
href="https://doi.org/10.1007/s10044-023-01193-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video foreground extraction has been widely applied to quantitative fields and attracts great attention all over the world. Nevertheless, the performance of a such method can be easily reduced due to the dizzy environment. To tackle this problem, the global semantics (e.g., background statistics) and the local semantics (e.g., boundary areas) can be utilized to better distinguish foreground objects from the complex background. In this paper, we investigate how to effectively leverage the above two kinds of semantics. For global semantics, two convolutional modules are designed to take advantage of data-level background priors and feature-level multi-scale characteristics, respectively; for local semantics, another module is further put forward to be aware of the semantic edges between foreground and background. The three modules are intertwined with each other, yielding a simple yet effective deep framework named g $$\mathcal{L}\mathcal{O}$$ bal– $$\mathcal{L}\mathcal{O}$$ cal Semantics Coupled Network ( $$\mathcal{L}\mathcal{O}^2$$ Net), which is end-to-end trainable in a scene-specific manner. Benefiting from the $$\mathcal{L}\mathcal{O}^2$$ Net, we achieve superior performance on multiple public datasets, with less supervision trained against several state-of-the-art methods.},
  archive      = {J_PAAA},
  author       = {Ruan, Tao and Wei, Shikui and Zhao, Yao and Guo, Baoqing and Yu, Zujun},
  doi          = {10.1007/s10044-023-01193-5},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1671-1683},
  shortjournal = {Pattern Anal. Appl.},
  title        = {$$\mathcal{L}\mathcal{O}^2$$ net: Global–Local semantics coupled network for scene-specific video foreground extraction with less supervision},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The improved deep plug-and-play super-resolution with
residual-in-residual dense block for arbitrary blur kernels.
<em>PAAA</em>, <em>26</em>(4), 1657–1670. (<a
href="https://doi.org/10.1007/s10044-023-01192-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-image super-resolution (SISR) reconstruction has highly academic and practical values. The deep plug-and-play super-resolution (DPSR) framework has been proposed to super-resolve low-resolution (LR) images with arbitrary blur kernels. However, DPSR does not make full use of hierarchical features from original LR images, thereby achieving relatively-low performance, such as getting low average peak signal to noise ratio (PSNR) and structural similarity (SSIM) values. Considering residual-in-residual dense block (RRDB) can exploit hierarchical features, in this paper, firstly, RRDB is introduced to design an improved DPSR (IDPSR) framework with RRDB for arbitrary blur kernels. Secondly, the RRDB is adopted to replace the deep feature extraction part in DPSR in order to extract abundant local features, which makes the network capacity higher benefiting from the dense connections. The residual learning in different levels in RRDB can obtain high quality images. Finally, the test experiments are based on Set5, Set14, Urban100 and BSD100 datasets. The experimental results show that, under different blur kernels and different scale factors, PSNR and SSIM values of our proposed method increase by 0.34dB and 0.68%, respectively; under different noise levels, the average PSNR and SSIM values increase by 0.27dB and 1.01%, respectively.},
  archive      = {J_PAAA},
  author       = {Xu, Chao and Yang, Xiaoling and Li, Shan and Huang, Xiangdong and Pan, Hongguang and Lei, Xinyu},
  doi          = {10.1007/s10044-023-01192-6},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1657-1670},
  shortjournal = {Pattern Anal. Appl.},
  title        = {The improved deep plug-and-play super-resolution with residual-in-residual dense block for arbitrary blur kernels},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DWT-CompCNN: Deep image classification network for high
throughput JPEG 2000 compressed documents. <em>PAAA</em>,
<em>26</em>(4), 1641–1655. (<a
href="https://doi.org/10.1007/s10044-023-01190-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For any digital application with document images such as retrieval, the classification of document images becomes an essential stage. Conventionally for the purpose, the full versions of the documents, that is the uncompressed document images make the input dataset, which poses a threat due to the big volume required to accommodate the full versions of the documents. Therefore, it would be novel, if the same classification task could be accomplished directly (with some partial decompression) with the compressed representation of documents in order to make the whole process computationally more efficient. In this research work, a novel deep learning model—DWT-CompCNN—is proposed for classification of documents that are compressed using High Throughput JPEG 2000 (HTJ2K) algorithm. The proposed DWT-CompCNN comprises of five convolutional layers with filter sizes of 16, 32, 64, 128, and 256 consecutively for each increasing layer to improve learning from the wavelet coefficients extracted from the compressed images. Experiments are performed on two benchmark datasets, Tobacco-3482 and RVL-CDIP, which demonstrate that the proposed model is time and space efficient, and also achieves a better classification accuracy in compressed domain.},
  archive      = {J_PAAA},
  author       = {Bisen, Tejasvee and Javed, Mohammed and Kirtania, Shashank and Nagabhushan, P.},
  doi          = {10.1007/s10044-023-01190-8},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1641-1655},
  shortjournal = {Pattern Anal. Appl.},
  title        = {DWT-CompCNN: Deep image classification network for high throughput JPEG 2000 compressed documents},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CInf-FS <span
class="math display"><sub><em>S</em></sub></span>: An efficient infinite
feature selection method using k-means clustering to partition large
feature spaces. <em>PAAA</em>, <em>26</em>(4), 1631–1639. (<a
href="https://doi.org/10.1007/s10044-023-01189-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a new feature selection algorithm for supervised problems. We build our algorithm upon recently proposed infinite feature selection (Inf-FS) method where features are ranked based on path integrals and the centrality concept on a feature adjacency graph. The proposed algorithm firstly clusters the feature space into a predefined number of subspaces. Then ranks the features in each subspace using Inf-FS method. Finally merges the resultant subranks using a combined measure of information theory and clusters size. We extensively evaluate our algorithm on six benchmark datasets, and show that our method outperforms Inf-FS in terms of the accuracy, running time, and memory consumption. The codes are available at https://github.com/Sadegh28/CInf-FS .},
  archive      = {J_PAAA},
  author       = {Hassani Ziabari, Seyyedeh Faezeh and Eskandari, Sadegh and Salahi, Maziar},
  doi          = {10.1007/s10044-023-01189-1},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1631-1639},
  shortjournal = {Pattern Anal. Appl.},
  title        = {CInf-FS $$_S$$: An efficient infinite feature selection method using K-means clustering to partition large feature spaces},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-metric small sphere large margin method for
classification. <em>PAAA</em>, <em>26</em>(4), 1615–1629. (<a
href="https://doi.org/10.1007/s10044-023-01188-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-metric learning is important for improving performance of learners. For complex data, multi metric learning algorithms need intensive research. Moreover, the existing multi-metric learning methods may lead to the distance not being comparable. To solve these shortcomings and characterize better complexity data, we propose a novel multi-metric learning framework, where each class is divided into several clusters, and then a local metric and two concentric hypers-pheres are trained jointly in a cluster, such that the samples of the same cluster distribute within one hypersphere, and the classification margin are as large as possible simultaneously. This will leads to intra-class compactness and inter-class dispersion. During the test phase, the relative distance in learned metric space is designed to make classification decisions. A new example is classified to the class of its closest hyper-sphere center. This ensures that the comparison of distances is meaningful and avoids effectively the limitation of k-nearest neighbors (kNN) classifiers. Moreover,some important properties the proposed algorithm are analyzed theoretically. Further, an alternating iterative algorithm is developed to solve the problem. Numerical experiments are carried out on different scales and types datasets. Experiment results confirm the feasibility and effectiveness of the proposed method.},
  archive      = {J_PAAA},
  author       = {Zhao, Yifeng and Yang, Liming},
  doi          = {10.1007/s10044-023-01188-2},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1615-1629},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A multi-metric small sphere large margin method for classification},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interactive machine translation for the language
modernization and spelling normalization of historical documents.
<em>PAAA</em>, <em>26</em>(4), 1601–1614. (<a
href="https://doi.org/10.1007/s10044-023-01164-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Historical documents are an important part of our cultural heritage. Among other task related to their processing, it is important to modernize their language in order to make them accessible to a broader audience and to achieve an orthography consistency to reduce the linguistic variation inherent in them. Language modernization and spelling normalization have those goals in mind. However, they still have a long way to go. Thus, in order to help scholars generate error-free modernizations/normalizations when the quality is essential, we propose an interactive framework based on interactive machine translation. In this work, we deployed two different interactive protocols into these tasks. We evaluated our proposal under simulated environments, observing significant reductions of the human effort.},
  archive      = {J_PAAA},
  author       = {Domingo, Miguel and Casacuberta, Francisco},
  doi          = {10.1007/s10044-023-01164-w},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1601-1614},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Interactive machine translation for the language modernization and spelling normalization of historical documents},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep spatial and tonal data optimisation for homogeneous
diffusion inpainting. <em>PAAA</em>, <em>26</em>(4), 1585–1600. (<a
href="https://doi.org/10.1007/s10044-023-01162-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion-based inpainting can reconstruct missing image areas with high quality from sparse data, provided that their location and their values are well optimised. This is particularly useful for applications such as image compression, where the original image is known. Selecting the known data constitutes a challenging optimisation problem, that has so far been only investigated with model-based approaches. So far, these methods require a choice between either high quality or high speed since qualitatively convincing algorithms rely on many time-consuming inpaintings. We propose the first neural network architecture that allows fast optimisation of pixel positions and pixel values for homogeneous diffusion inpainting. During training, we combine two optimisation networks with a neural network-based surrogate solver for diffusion inpainting. This novel concept allows us to perform backpropagation based on inpainting results that approximate the solution of the inpainting equation. Without the need for a single inpainting during test time, our deep optimisation accelerates data selection by more than four orders of magnitude compared to common model-based approaches. This provides real-time performance with high quality results.},
  archive      = {J_PAAA},
  author       = {Peter, Pascal and Schrader, Karl and Alt, Tobias and Weickert, Joachim},
  doi          = {10.1007/s10044-023-01162-y},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1585-1600},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Deep spatial and tonal data optimisation for homogeneous diffusion inpainting},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Discriminative estimation of probabilistic context-free
grammars for mathematical expression recognition and retrieval.
<em>PAAA</em>, <em>26</em>(4), 1571–1584. (<a
href="https://doi.org/10.1007/s10044-023-01158-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a discriminative learning algorithm for the probabilistic estimation of two-dimensional probabilistic context-free grammars (2D-PCFG) for mathematical expressions recognition and retrieval. This algorithm is based on a generalization of the H-criterion as the objective function and the growth transformations as the optimization method. For the development of the discriminative estimation algorithm, the N-best interpretations provided by the 2D-PCFG have been considered. Experimental results are reported on two available datasets: Im2Latex and IBEM. The first experiment compares the proposed discriminative estimation method with the classic Viterbi-based estimation method. The second one studies the performance of the estimated models depending on the length of the mathematical expressions and the number of admissible errors in the metric used.},
  archive      = {J_PAAA},
  author       = {Noya, Ernesto and Benedí, José Miguel and Sánchez, Joan Andreu and Anitei, Dan},
  doi          = {10.1007/s10044-023-01158-8},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1571-1584},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Discriminative estimation of probabilistic context-free grammars for mathematical expression recognition and retrieval},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Kurcuma: A kitchen utensil recognition collection for
unsupervised domain adaptation. <em>PAAA</em>, <em>26</em>(4),
1557–1569. (<a
href="https://doi.org/10.1007/s10044-023-01147-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of deep learning makes it possible to achieve extraordinary results in all kinds of tasks related to computer vision. However, this performance is strongly related to the availability of training data and its relationship with the distribution in the eventual application scenario. This question is of vital importance in areas such as robotics, where the targeted environment data are barely available in advance. In this context, domain adaptation (DA) techniques are especially important to building models that deal with new data for which the corresponding label is not available. To promote further research in DA techniques applied to robotics, this work presents Kurcuma (Kitchen Utensil Recognition Collection for Unsupervised doMain Adaptation), an assortment of seven datasets for the classification of kitchen utensils—a task of relevance in home-assistance robotics and a suitable showcase for DA. Along with the data, we provide a broad description of the main characteristics of the dataset, as well as a baseline using the well-known domain-adversarial training of neural networks approach. The results show the challenge posed by DA on these types of tasks, pointing to the need for new approaches in future work.},
  archive      = {J_PAAA},
  author       = {Rosello, Adrian and Valero-Mas, Jose J. and Gallego, Antonio Javier and Sáez-Pérez, Javier and Calvo-Zaragoza, Jorge},
  doi          = {10.1007/s10044-023-01147-x},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1557-1569},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Kurcuma: A kitchen utensil recognition collection for unsupervised domain adaptation},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An effective DeepWINet CNN model for off-line
text-independent writer identification. <em>PAAA</em>, <em>26</em>(3),
1539–1556. (<a
href="https://doi.org/10.1007/s10044-023-01186-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Writer identification based on handwriting recognition is considered one of the most common research areas in pattern recognition and biometrics. It has attracted much attention in recent decades due to the urgent need to develop biometric systems for many security applications. In this paper, Deep Writer Identification Network (DeepWINet), an effective deep Convolutional Neural Network (CNN) for writer identification, is proposed. The proposed model is evaluated in two different ways. In the first scenario, DeepWINet’s CNN activation features, computed from the connected components of the writing, are passed to a customized nearest neighbor classifier for writer identification. In the second scenario, DeepWINet is evaluated as an end-to-end CNN network where the predicted results are averaged using an efficient strategy, Score Averaging Component-Decision Combiner. The proposed approach achieves competitive or the highest State-Of-The-Art performance on eight challenging handwritten databases with different languages.},
  archive      = {J_PAAA},
  author       = {Chahi, Abderrazak and El-merabet, Youssef and Ruichek, Yassine and Touahni, Raja},
  doi          = {10.1007/s10044-023-01186-4},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1539-1556},
  shortjournal = {Pattern Anal. Appl.},
  title        = {An effective DeepWINet CNN model for off-line text-independent writer identification},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global–local transformer for single-image rain removal.
<em>PAAA</em>, <em>26</em>(3), 1527–1538. (<a
href="https://doi.org/10.1007/s10044-023-01184-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, convolutional neural networks (CNNs) have achieved remarkable success on single-image rain removal task. However, due to the intrinsic locality of convolution operations, CNN-based models generally demonstrate limitations in explicitly modeling long-range dependency. Transformer has achieved milestones in many artificial intelligence fields by mitigating the shortcomings of CNNs but can result in limited localization abilities and high computational cost. To this end, we propose a novel global–local transformer, termed GLFormer to model long-range dependencies for rain removal while remaining efficient. Specifically, we use a window-based local transformer block to build the shallow layers of GLFormer for processing high-resolution feature maps, which greatly reduces the computational complexity. And a global transformer block is designed to construct deep layers which can model long-range dependencies with global self-attention. Powered by these designs, GLFormer avoids the limitation of computing self-attention within a local window that lacks global feature inference and reduces the computational effort to a large extent. Considering that local details are crucial for the recovery of degraded images, we further employ convolution operation in both global and local transformer blocks to improve its potential for capturing local context. In addition, a self-supervised pre-training strategy is further introduced to mining sufficient image priors by utilizing ultra-large unlabeled image datasets. Our proposed method is extensively evaluated on several benchmark datasets, and the results show GLFormer to be superior than the state-of-the-art approaches built upon convolution.},
  archive      = {J_PAAA},
  author       = {Wan, Yecong and Shao, Mingwen and Bao, Zhiyuan and Cheng, Yuanshuo},
  doi          = {10.1007/s10044-023-01184-6},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1527-1538},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Global–local transformer for single-image rain removal},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiple kernel k-means clustering with block diagonal
property. <em>PAAA</em>, <em>26</em>(3), 1515–1526. (<a
href="https://doi.org/10.1007/s10044-023-01183-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple kernel k-means clustering (MKKC) is proposed to efficiently incorporate multiple base kernels to generate an optimal kernel. However, many existing MKKC methods all involve two stages: learning a clustering indicator matrix and performing clustering on it. This cannot ensure the ultimate clustering results are optimal because the optimal values of two steps are not equivalent to those of the original problem. To address this issue, in this paper, we propose a novel method named multiple kernel k-means clustering with block diagonal property (MKKC-BD). It is the first time to find the relationship between an indicator matrix and Laplacian matrix of the graph theory and get a block diagonal (BD) representation of the indicator matrix. By imposing the BD constraint on the indicator matrix, the BD property of the indicator matrix is ensured. Further, the explicit clustering results are generated directly from the unified framework integrating the three processes of learning an optimal kernel, an indicator matrix and clustering results, which shows the clustering task is executed just by one step. In addition, a simple kernel weight strategy is used in this framework to obtain the optimal kernel, where the value of each kernel weight directly reveals the relationship of each base kernel and the optimal kernel. Finally, by extensive experiments on ten data sets and comparison of clustering results with eight state-of-the-art multiple kernel clustering methods, it is concluded that MKKC-BD is effective. Our code is available at https://github.com/mathchen-git/MKKC-BD .},
  archive      = {J_PAAA},
  author       = {Chen, Cuiling and Wei, Jian and Li, Zhi},
  doi          = {10.1007/s10044-023-01183-7},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1515-1526},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Multiple kernel k-means clustering with block diagonal property},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-label correction for image classification with noisy
labels. <em>PAAA</em>, <em>26</em>(3), 1505–1514. (<a
href="https://doi.org/10.1007/s10044-023-01180-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label noise is inevitable in image classification. Existing methods usually lack the reliability of selecting clean data samples and rely on an auxiliary model to correct clean samples, which quality has a great impact on the classification results. In this paper, we propose the Dual-model and Self-Label Correction (DSLC) method to select clean samples and correct labels without auxiliary models. First, we use a dual-model structure combining contrastive learning to select clean samples. Then, we design a novel label correction method to modify the noisy labels. Finally, we propose a joint loss to improve the generalization ability of our models. In the experiment, we demonstrate the effectiveness of DSLC on various datasets, which achieves comparable performance to state-of-the-art methods.},
  archive      = {J_PAAA},
  author       = {Zhang, Yu and Lin, Fan and Mi, Siya and Bian, Yali},
  doi          = {10.1007/s10044-023-01180-w},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1505-1514},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Self-label correction for image classification with noisy labels},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multimodal fusion-based deep learning framework combined
with keyframe extraction and spatial and channel attention for group
emotion recognition from videos. <em>PAAA</em>, <em>26</em>(3),
1493–1503. (<a
href="https://doi.org/10.1007/s10044-023-01178-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video-based group emotion recognition is an important research area in computer vision and is of great significance for the intelligent understanding of videos and human–computer interactions. Previous studies have adopted the traditional two-stage shallow pipeline to extract visual or audio features and train classifiers. A single feature or two are insufficient to comprehensively represent video information. In addition, sparse expression of emotions has not been addressed effectively. Therefore, in this study, we propose a novel deep convolutional neural networks (CNNs) architecture for video-based group emotion recognition that fuses multimodal feature information such as vision, audio, optical flow, and face. To address the problem of sparse emotional expressions in videos, we constructed an improved keyframe extraction algorithm for a visual stream to extract keyframes with more emotional features. A subnetwork incorporating spatial and channel attention was designed to automatically concentrate on the regions and channels carrying distinctive information in each keyframe to more accurately represent the emotional features of the visual stream. The proposed model was used to conduct extensive experiments on a video group affect dataset. It outperformed other video-based group emotion recognition methods.},
  archive      = {J_PAAA},
  author       = {Qi, Shubao and Liu, Baolin},
  doi          = {10.1007/s10044-023-01178-4},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1493-1503},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A multimodal fusion-based deep learning framework combined with keyframe extraction and spatial and channel attention for group emotion recognition from videos},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph-based fine-grained model selection for multi-source
domain. <em>PAAA</em>, <em>26</em>(3), 1481–1492. (<a
href="https://doi.org/10.1007/s10044-023-01176-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prosperity of datasets and model architectures has led to the development of pretrained source models, which simplified the learning process in multi-domain transfer learning. However, challenges such as data complexity, domain shifts, and performance limitations make it difficult to determine which source model to transfer. To meet these challenges, source model selection has emerged as a promising approach for choosing the best model for a given target domain. Most literature utilizes transferability estimation combined with statistical methods to deduce the model selection probability, which is a coarse-grained method that selects a single model with limited accuracy and applicability in multi-source domains. To break through this limitation, we propose a graph-based fine-grained multi-source model selection method (GFMS) that aims to adaptively select the best source model for any single target domain data. Specifically, our proposed method comprises three main components: building a source model library through cross-training; generating the selection strategy by exploring the similarities among the data features, the associations between the features and models based on graph neural networks; blending the selected models using a weighted approach to obtain the best model adaptively. Experimental results demonstrate that the proposed adaptive method achieves higher accuracy in both model selection and image classification than the current state-of-the-art methods on compared datasets.},
  archive      = {J_PAAA},
  author       = {Hu, Zhigang and Huang, Yuhang and Zheng, Hao and Zheng, Meiguang and Liu, JianJun},
  doi          = {10.1007/s10044-023-01176-6},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1481-1492},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Graph-based fine-grained model selection for multi-source domain},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DStab: Estimating clustering quality by distance stability.
<em>PAAA</em>, <em>26</em>(3), 1463–1479. (<a
href="https://doi.org/10.1007/s10044-023-01175-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most commonly, stability analyses are performed using an external validation measure. For example, the Jaccard index is one of the indexes of choice for stability measurement. The index is wrapped around a resampling method to sense the model’s stability. Other methods use classifiers to look for stable partitions instead. In these cases, a resampling method is also used with an external index, an error measure driven by a classifier, and a clustering algorithm aiming to find stable clustering model configurations. Contrary to previous stability-based methods, we propose a novel validation procedure consisting of an internal validation index within a resampling strategy. We propose an index based on the distance between cluster centroids coupled with a twofold cross-validation resampling approach. Moreover, we use a threshold based on a null hypothesis to detect meaningful clustering partitions. As part of our experimental study, we have selected the K-means algorithm because of its simplicity but primarily for its instability compared to other algorithms, such as Hierarchical methods. Finally, we compare our approach with several known validation indexes and discuss the results. Our findings show that our method cannot only find meaningful clustering partitions but is also helpful as an unsupervised data analysis tool.},
  archive      = {J_PAAA},
  author       = {Bayá, Ariel E. and Larese, Mónica G.},
  doi          = {10.1007/s10044-023-01175-7},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1463-1479},
  shortjournal = {Pattern Anal. Appl.},
  title        = {DStab: Estimating clustering quality by distance stability},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exponential filtering technique for euclidean
norm-regularized extreme learning machines. <em>PAAA</em>,
<em>26</em>(3), 1453–1462. (<a
href="https://doi.org/10.1007/s10044-023-01174-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extreme Learning Machine (ELM) is a feedforward neural network that utilizes a single hidden layer to effectively tackle the learning speed challenges commonly associated with conventional gradient-based neural networks. ELM has been reported to achieve faster learning rates and better performance than traditional neural networks. However, it is susceptible to unreliable solutions when applied to real-world input data with inconsistent noise, resulting in overfitting. To mitigate these limitations, we investigate various regularization techniques that can be employed in conjunction with ELM, including Tikhonov regularization, a well-established method in the field. However, one of the main drawbacks of Tikhonov regularization is its assumption of the input data’s noise to be white and Gaussian, which may not be the case in real-world applications. This assumption can lead to suboptimal regularization and poor generalization performance of the model. Therefore, we propose using an exponential filtering method in conjunction with ELM to overcome this limitation and improve the model’s reliability. We compare our approach with Tikhonov regularization and other existing methods to evaluate its efficacy. Our experimental results demonstrate that our proposed strategy achieves superior accuracy and generalization capability compared to the other methods. Moreover, we provide statistical evidence to support the significance of our findings.},
  archive      = {J_PAAA},
  author       = {Naik, Shraddha M. and Subramani, Chinnamuthu and Jagannath, Ravi Prasad K. and Paul, Anand},
  doi          = {10.1007/s10044-023-01174-8},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1453-1462},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Exponential filtering technique for euclidean norm-regularized extreme learning machines},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CB-FPN: Object detection feature pyramid network based on
context information and bidirectional efficient fusion. <em>PAAA</em>,
<em>26</em>(3), 1441–1452. (<a
href="https://doi.org/10.1007/s10044-023-01173-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature pyramid network (FPN) is a typical structure in object detection. It can improve the accuracy of detection results by fusing feature information at different resolutions and enhancing the expression ability of different levels of features. Among them, the mismatch between the resolution of feature information and the receptive field and the limited way of feature fusion hinder the full exchange of feature information. To solve the above problems, this paper designs a new structure called an object detection feature pyramid network based on context information and an efficient bidirectional fusion (CB-FPN): (1) Before feature fusion, this study designs a context enhancement module with cross stage partial network (CSPNet) module (CEM-CSP). By using carefully designed dilated convolutions on high-level features, rich context information and receptive fields are obtained to match appropriate feature information. (2) In feature fusion, this study designed a bidirectional efficient feature pyramid network (BE-FPN) module to fuse features efficiently. After adding these two modified architectures to Faster R-CNN with ResNet-50, the average precision (AP) improves from 37.5 to 39.2 on COCO val-2017 data set. In addition, extensive experiments show the effectiveness of our methods on one-stage, two-stage, and anchor-free models.},
  archive      = {J_PAAA},
  author       = {Liu, Zhibo and Cheng, Jian},
  doi          = {10.1007/s10044-023-01173-9},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1441-1452},
  shortjournal = {Pattern Anal. Appl.},
  title        = {CB-FPN: Object detection feature pyramid network based on context information and bidirectional efficient fusion},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RKHS subspace domain adaption via minimum distribution gap.
<em>PAAA</em>, <em>26</em>(3), 1425–1439. (<a
href="https://doi.org/10.1007/s10044-023-01170-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subspace learning of Reproducing Kernel Hilbert Space (RKHS) is most popular among domain adaption applications. The key goal is to embed the source and target domain samples into a common RKHS subspace where their distributions could match better. However, most existing domain adaption measures are either based on the first-order statistics that can’t accurately qualify the difference of distributions for non-Guassian distributions or complicated co-variance matrix that is difficult to be used and optimized. In this paper, we propose a neat and effective RKHS subspace domain adaption measure: Minimum Distribution Gap (MDG), where the rigorous mathematical formula can be derived to learn the weighting matrix of the optimized orthogonal Hilbert subspace basis via the Lagrange Multiplier Method. To show the efficiency of the proposed MDG measure, extensive numerical experiments with different datasets have been performed and the comparisons with four other state-of-the-art algorithms in the literature show that the proposed MDG measure is very promising.},
  archive      = {J_PAAA},
  author       = {Qiu, Yanzhen and Zhang, Chuangfeng and Xiong, Chenkui and Ma, Zhengming and Liao, Shaolin},
  doi          = {10.1007/s10044-023-01170-y},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1425-1439},
  shortjournal = {Pattern Anal. Appl.},
  title        = {RKHS subspace domain adaption via minimum distribution gap},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-view confidence-aware method for adaptive siamese
tracking with shrink-enhancement loss. <em>PAAA</em>, <em>26</em>(3),
1407–1424. (<a
href="https://doi.org/10.1007/s10044-023-01169-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many Siamese tracking algorithms attempt to enhance the target representation through target aware. However, the tracking results are often disturbed by the target-like background. In this paper, we propose a multi-view confidence-aware method for adaptive Siamese tracking. Firstly, a shrink-enhancement loss is designed to select channel features that are more sensitive to the target, which reduces the effect of simple background negative samples and enhances the contribution of difficult background negative samples, so as to achieve the balance of the sample data. Secondly, to enhance the reliability of the confidence map, a multi-view confidence-aware method is constructed. It integrates the response maps of template, foreground, and background through Multi-view Confidence Guide to highlight target features and suppress background interference, thus obtaining a more discriminative target response map. Finally, to better accommodate variable tracking scenarios, we design a state estimation criterion for tracking results and adaptive update the template. Experimental results show that the present tracking approach performs well, especially on six benchmark datasets, including OTB-2015, TC-128, UAV-123, DTB, VOT2016, and VOT-2019.},
  archive      = {J_PAAA},
  author       = {Zhang, Huanlong and Ma, Zonghao and Zhang, Jie and Chen, Fuguo and Song, Xiaohui},
  doi          = {10.1007/s10044-023-01169-5},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1407-1424},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Multi-view confidence-aware method for adaptive siamese tracking with shrink-enhancement loss},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-view clustering indicator learning with scaled
similarity. <em>PAAA</em>, <em>26</em>(3), 1395–1406. (<a
href="https://doi.org/10.1007/s10044-023-01167-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The similarity of data plays an important role in clustering task, and good clustering performance often requires a reliable similarity matrix. A variety of metrics are used to define a similarity matrix in the past, and great achievements are obtained. However, due to the noise and outliers of data in the real world, the quality of the similarity matrix is often poor. Besides, the similarity matrix is often inflexible, which will degrade the clustering performance. To solve this problem, in this paper, we proposed a novel Multi-view Clustering Indicator Learning with Scaled Similarity (MCILSS). Our model uses the self-representation method to reconstruct the data matrix, and then obtain the similarity matrix by minimizing the reconstruction error. More importantly, in our model, we can adjust s $$\left( {0 &lt; s \le 1} \right)$$ to constrain the similarity matrix to gain the best clustering indicator matrix. In addition, the rank constraint is further used to improve the clustering performance. Finally, the indicator matrix is applied to obtain clustering results by k-means. Considering the nonlinear relationship in the data, we also proposed the kernel MCILSS which maps the original data to the kernel space. To solve the proposed models, two efficient optimization algorithms based on Augmented Lagrange Method (ALM) are also designed. The experimental results on some data sets show that our algorithm has better clustering performance than some representative algorithms.},
  archive      = {J_PAAA},
  author       = {Yao, Liang and Lu, Gui-Fu},
  doi          = {10.1007/s10044-023-01167-7},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1395-1406},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Multi-view clustering indicator learning with scaled similarity},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TSRN: Two-stage refinement network for temporal action
segmentation. <em>PAAA</em>, <em>26</em>(3), 1375–1393. (<a
href="https://doi.org/10.1007/s10044-023-01166-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In high-level video semantic understanding, continuous action segmentation is a challenging task aimed at segmenting an untrimmed video and labeling each segment with predefined labels over time. However, the accuracy of segment predictions is limited by confusing information in video sequences, such as ambiguous frames during action boundaries or over-segmentation errors due to the lack of semantic relations. In this work, we present a two-stage refinement network (TSRN) to improve temporal action segmentation. We first capture global relations over an entire video sequence using a multi-head self-attention mechanism in the novel transformer temporal convolutional network and model temporal relations in each action segment. Then, we introduce a dual-attention spatial pyramid pooling network to fuse features from macroscale and microscale perspectives, providing more accurate classification results from the initial prediction. In addition, a joint loss function mitigates over-segmentation. Compared with state-of-the-art methods, the proposed TSRN substantially improves temporal action segmentation on three challenging datasets (i.e., 50Salads, Georgia Tech Egocentric Activities, and Breakfast).},
  archive      = {J_PAAA},
  author       = {Tian, Xiaoyan and Jin, Ye and Tang, Xianglong},
  doi          = {10.1007/s10044-023-01166-8},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1375-1393},
  shortjournal = {Pattern Anal. Appl.},
  title        = {TSRN: Two-stage refinement network for temporal action segmentation},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MPF6D: Masked pyramid fusion 6D pose estimation.
<em>PAAA</em>, <em>26</em>(3), 1363–1373. (<a
href="https://doi.org/10.1007/s10044-023-01165-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object pose estimation has multiple important applications, such as robotic grasping and augmented reality. We present a new method to estimate the 6D pose of objects that improves upon the accuracy of current proposals and can still be used in real-time. Our method uses RGB-D data as input to segment objects and estimate their pose. It uses a neural network with multiple heads to identify the objects in the scene, generate the appropriate masks and estimate the values of the translation vectors and the quaternion that represents the objects’ rotation. These heads leverage a pyramid architecture used during feature extraction and feature fusion. We conduct an empirical evaluation using the two most common datasets in the area, and compare against state-of-the-art approaches, illustrating the capabilities of MPF6D. Our method can be used in real-time with its low inference time and high accuracy.},
  archive      = {J_PAAA},
  author       = {Pereira, Nuno and Alexandre, Luís A.},
  doi          = {10.1007/s10044-023-01165-9},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1363-1373},
  shortjournal = {Pattern Anal. Appl.},
  title        = {MPF6D: Masked pyramid fusion 6D pose estimation},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DEC-transformer: Deep embedded clustering with transformer
on chinese long text. <em>PAAA</em>, <em>26</em>(3), 1349–1362. (<a
href="https://doi.org/10.1007/s10044-023-01161-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long text clustering is of great significance and practical value in data mining, such as information retrieval, text integration, and data compression. Compared with short text clustering, long text clustering involves more semantic information representation and processing, making it a challenging problem. Most recent techniques merely rely on dynamic word embeddings from pre-training as a transfer learning or only based on a simple combination of transformers and traditional clustering methods, which still need to be expanded to short text due to the quadratic computational complexity. In this paper, a novel model combining transfer learning and dynamic feedback called deep embedded clustering with transformer(DEC-transformer) is proposed. To better capture the semantic relationships between sentences in documents, a novel transfer learning technology is firstly applied to long text clustering tasks for pre-training. Unlike previous papers, a two-stage training task is designed by treating semantic representation and text clustering as a united process, and the parameter is dynamically optimized by adaptive feedback to further improve efficiency. Experimental results on the test set show that the proposed model has made great progress in accuracy compared with several benchmarks. Furthermore, it also has good robustness and can get good performance on noisy datasets.},
  archive      = {J_PAAA},
  author       = {Zou, Ao and Hao, Wenning and Chen, Gang and Jin, Dawei},
  doi          = {10.1007/s10044-023-01161-z},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1349-1362},
  shortjournal = {Pattern Anal. Appl.},
  title        = {DEC-transformer: Deep embedded clustering with transformer on chinese long text},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NSIWD: New statistical image watermark detector.
<em>PAAA</em>, <em>26</em>(3), 1317–1348. (<a
href="https://doi.org/10.1007/s10044-023-01159-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For any image watermarking algorithm, how to achieve the trade-off among robustness, imperceptibility, and watermark capacity is a challenging problem because of their mutually constrained relationship. In this paper, we design a statistical-based image watermarking detection system to solve the trade-off problem. In embedding process, consider the imperceptibility and the robustness, we inventively combine the undecimated discrete wavelet transforms (UDWT) difference domain and the polar harmonic Fourier moments (PHFMs) to obtain the UDWT difference domain PHFMs magnitudes as the watermark carriers, and we embed watermark signals in multiplicative manner. In modeling phase, by analyzing the statistical property and the strong inter-orientation correlations of the UDWT difference domain PHFMs magnitudes in horizontal direction and vertical direction, we model the magnitude coefficients with the bivariate generalized exponential distribution so that we can capture accurately the marginal characteristics and the strong inter-orientation dependencies at the same time. Moreover, we obtain the model parameters with the modified maximum likelihood estimation. Benefit from the reliable modeling result, we finally employ the locally most powerful decision rule to derive a novel specific locally optimum image watermark detector with a closed-form expression to blindly detect the existence of the watermarks. Extensive experiment results declare the designed statistical image watermarking system can accurately detect the existence of the watermarks, and it achieves the better balance among imperceptibility, robustness, and payload.},
  archive      = {J_PAAA},
  author       = {Wang, Xiangyang and Lin, Yupan and Gong, Qingzhuo and Niu, Panpan},
  doi          = {10.1007/s10044-023-01159-7},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1317-1348},
  shortjournal = {Pattern Anal. Appl.},
  title        = {NSIWD: New statistical image watermark detector},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-scale spatial–temporal convolutional neural network
for skeleton-based action recognition. <em>PAAA</em>, <em>26</em>(3),
1303–1315. (<a
href="https://doi.org/10.1007/s10044-023-01156-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The skeleton data convey significant information for action recognition since they can robustly against cluttered backgrounds and illumination variation. In recent years, due to the limited ability to extract spatial–temporal features from skeleton data, the methods based on convolutional neural network (CNN) or recurrent neural network are inferior in recognition accuracy. A series of methods based on graph convolutional networks (GCN) have achieved remarkable performance and gradually become dominant. However, the computational cost of GCN-based methods is quite heavy, several works even over 100 GFLOPs. This is contrary to the highly condensed attributes of skeleton data. In this paper, a novel multi-scale spatial–temporal convolutional (MSST) module is proposed to take the implicit complementary advantages across spatial–temporal representations with different scales. Instead of converting skeleton data into pseudo-images like some previous CNN-based methods or using complex graph convolution, we take full use of multi-scale convolutions on temporal and spatial dimensions to capture comprehensive dependencies of skeleton joints. Unifying the MSST module, a multi-scale spatial–temporal convolutional neural network (MSSTNet) is proposed to capture high-level spatial–temporal semantic features for action recognition. Unlike previous methods which boost performance at the cost of computation, MSSTNet can be easily implemented with light model size and fast inference. Moreover, MSSTNet is used in a four-stream framework to fuse data of different modalities, providing notable improvement to recognition accuracy. On NTU RGB+D 60, NTU RGB+D 120, UAV-Human and Northwestern-UCLA datasets, the proposed MSSTNet achieves competitive performance with much less computational cost than state-of-the-art methods.},
  archive      = {J_PAAA},
  author       = {Cheng, Qin and Cheng, Jun and Ren, Ziliang and Zhang, Qieshi and Liu, Jianming},
  doi          = {10.1007/s10044-023-01156-w},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1303-1315},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Multi-scale spatial–temporal convolutional neural network for skeleton-based action recognition},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SE-MD: A single-encoder multiple-decoder deep network for
point cloud reconstruction from 2D images. <em>PAAA</em>,
<em>26</em>(3), 1291–1302. (<a
href="https://doi.org/10.1007/s10044-023-01155-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D model reconstruction from single 2D RGB images is a challenging and actively researched computer vision task. Several techniques based on conventional network architectures have been proposed for the same. However, the body of research work is limited and there are some issues like using inefficient 3D representation formats, weak 3D model reconstruction backbones, inability to reconstruct dense point clouds, dependence of post-processing for reconstruction of dense point clouds and dependence on silhouettes in RGB images. In this paper, a new 2D RGB image to point cloud conversion technique is proposed, which improves the state-of-the-art in the field due to its efficient, robust and simple model by using the concept of parallelization in network architecture. It not only uses efficient and rich 3D representation of point clouds, but also uses a new robust point cloud reconstruction backbone to address the prevalent issues. This involves using a single-encoder multiple-decoder deep network architecture wherein each decoder reconstructs certain fixed viewpoints. This is followed by fusing all the viewpoints to reconstruct a dense point cloud. Various experiments are conducted to evaluate the proposed technique and to compare its performance with those of the state-of-the-arts and impressive gains in performance are demonstrated.},
  archive      = {J_PAAA},
  author       = {Hafiz, Abdul Mueed and Bhat, Rouf Ul Alam and Parah, Shabir Ahmad and Hassaballah, M.},
  doi          = {10.1007/s10044-023-01155-x},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1291-1302},
  shortjournal = {Pattern Anal. Appl.},
  title        = {SE-MD: A single-encoder multiple-decoder deep network for point cloud reconstruction from 2D images},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 2D MRI registration using glowworm swarm optimization with
partial opposition-based learning for brain tumor progression.
<em>PAAA</em>, <em>26</em>(3), 1265–1290. (<a
href="https://doi.org/10.1007/s10044-023-01153-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic resonance imaging (MRI) registration is important in detection, diagnosis, treatment planning, determining radiographic progression, functional studies, computer-guided surgeries, and computer-guided therapies. The registration process is the way to solve the correspondence problem between features on MRI scans acquired at different time-points to study the changes while analyzing the brain tumor progression. Registration method generally requires a search strategy (optimizer) to search the transformation parameters of the registration to optimize some similarity metric between images. Metaheuristic algorithms are becoming more popular recently for image registration. In this paper, at the outset, a metaheuristic algorithm, namely glowworm swarm optimization (GSO), is improved by incorporating partial opposition-based learning (POBL) strategy. The improved GSO is applied to register the pre- and post-treatment MR images for brain tumor progression. A comparative study has been made with basic GSO, GSO with generalized opposition-based learning (GOBL-GSO), and existing particle swarm optimizer (PSO)-based registration method. The experimental results demonstrate that the proposed method has an extremely higher statistical significance in performance than others in brain MRI registration.},
  archive      = {J_PAAA},
  author       = {Si, Tapas},
  doi          = {10.1007/s10044-023-01153-z},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1265-1290},
  shortjournal = {Pattern Anal. Appl.},
  title        = {2D MRI registration using glowworm swarm optimization with partial opposition-based learning for brain tumor progression},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A two-phase projective dictionary pair learning-based
classification scheme for positive and unlabeled learning.
<em>PAAA</em>, <em>26</em>(3), 1253–1263. (<a
href="https://doi.org/10.1007/s10044-023-01151-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the recent surge of interest in machine learning, Positive and Unlabeled learning (PU learning) has also attracted much attention of scholars. A key bottleneck for addressing PU classification is the absence of training negative data, and thus many popular approaches belonging to the “two-step” strategy have been proposed. However, almost none of the existing two-step methods can thoroughly learn the feature information of samples, which makes the extracted negative samples unreliable and easily leads to undesirable results. Therefore, in this paper, we propose a two-phase projective dictionary pair learning (TPDPL) method for PU learning. The first phase of TPDPL determines reliable negatives by exploiting the reconstruction residuals and the second phase trains the DPL-based classifier with the extracted reliable negative and original positive samples to perform classification. Our experimental results demonstrate that the TPDPL approach can achieve highly competitive classification performance when compared with conventional and state-of-the-art PU learning algorithms. More importantly, due to the special dictionary pair learning framework, the computational complexity of TPDPL is extraordinarily low.},
  archive      = {J_PAAA},
  author       = {Wang, Yijin and Peng, Yali and Liu, Shigang and Ge, Bao and Li, Jun},
  doi          = {10.1007/s10044-023-01151-1},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1253-1263},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A two-phase projective dictionary pair learning-based classification scheme for positive and unlabeled learning},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bounded multivariate generalized gaussian mixture model
using ICA and IVA. <em>PAAA</em>, <em>26</em>(3), 1223–1252. (<a
href="https://doi.org/10.1007/s10044-023-01148-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A bounded multivariate generalized Gaussian mixture model with a full covariance matrix is proposed for modeling data in a bounded support region. For model selection, we propose minimum message length criterion. Furthermore, this paper proposes a bounded multivariate generalized Gaussian mixture model with independent component analysis. By employing the mixture model with independent component analysis, the assumed independence of the sources can be relaxed. For data with multiple sources such as functional magnetic resonance imaging and electroencephalogram databases, we propose the bounded multivariate generalized Gaussian mixture model with independent vector analysis as a generalized technique for the independent component analysis-based one. For a more insightful model analysis, we validate the proposed mixture model in data clustering through a variety of medical applications. We also propose the application of the independent component analysis-based model in speech (Romanian read-speech corpus), electrocardiogram, and electroencephalogram databases. For validation of the independent vector analysis-based model performance, different medical and speech databases are used. The results presented in the paper demonstrate the effectiveness of the proposed approaches for modeling different types of data.},
  archive      = {J_PAAA},
  author       = {Algumaei, Ali and Azam, Muhammad and Najar, Fatma and Bouguila, Nizar},
  doi          = {10.1007/s10044-023-01148-w},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1223-1252},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Bounded multivariate generalized gaussian mixture model using ICA and IVA},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detecting dynamic patterns in dynamic graphs using subgraph
isomorphism. <em>PAAA</em>, <em>26</em>(3), 1205–1221. (<a
href="https://doi.org/10.1007/s10044-023-01145-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs have been used in different fields of research for performing structural analysis of various systems. In order to compare the structure of two systems, the correspondence between their graphs has to be verified. The problem of graph matching, especially subgraph isomorphism (SI), has been well studied in case of static graphs. However, many applications require incorporating temporal information, making the corresponding graphs dynamic. In this paper, we apply SI to detect dynamic patterns in dynamic graphs. We propose an algorithm for induced SI to detect all the matchings for a given pattern graph while considering snapshot-based representation of dynamic graphs and taking into account the chronological order of these snapshots. This is the novelty of the proposed approach since the existing state-of-the-art algorithms model dynamic graphs using an aggregated model with time-stamped edges. To the best of our knowledge, there does not exist another approach which considers snapshot-based representation of dynamic pattern and dynamic target graphs for this problem. We discussed the time complexity of our algorithm and tested its performance while comparing it with two existing algorithms using the real-world datasets. It was found that our algorithm is the second best overall in terms of the execution time. The results are promising given the fact that the choice of dynamic graph model affects the algorithmic design for solving the problem of SI. For the applications where aggregated model of dynamic graphs is not applicable and snapshot-based representation is indispensable, our algorithm can be directly applied as opposed to the existing ones.},
  archive      = {J_PAAA},
  author       = {Oberoi, Kamaldeep Singh and Del Mondo, Géraldine and Gaüzère, Benoît and Dupuis, Yohan and Vasseur, Pascal},
  doi          = {10.1007/s10044-023-01145-z},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1205-1221},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Detecting dynamic patterns in dynamic graphs using subgraph isomorphism},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new multidimensional discriminant representation for
robust person re-identification. <em>PAAA</em>, <em>26</em>(3),
1191–1204. (<a
href="https://doi.org/10.1007/s10044-023-01144-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person Re-Identification (PRe-ID) or person retrieval is a challenging task of computer vision, aiming to identify a specific person across disjoint cameras distributed over different locations. Designing discriminant features parts as well as learning distance metrics are critical issues for improving the performances of the PRe-ID system. To deal with these critical problems, this paper proposes a new semi-supervised subspace approach named Multilinear Cross-view Quadratic Discriminant Analysis based on Cholesky decomposition (MXQDA-CD). In which, a new multidimensional discriminant representation is designed to increase the discrimination between different persons using third order tensor data that combines several features parts. Since the matching process yields heterogeneous scores, resulting from subjects captured through multiple cameras under different conditions, score normalization is applied to map these scores into a common space which led to improved performances of our approach. Experimental results achieved on four challenging person re-identification datasets, namely, PRID450S , CUHK01, GRID and VIPeR, show high competitiveness of the proposed method.},
  archive      = {J_PAAA},
  author       = {Chouchane, Ammar and Bessaoudi, Mohcene and Boutellaa, Elhocine and Ouamane, Abdelmalik},
  doi          = {10.1007/s10044-023-01144-0},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1191-1204},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A new multidimensional discriminant representation for robust person re-identification},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ABSLearn: A GNN-based framework for aliasing and buffer-size
information retrieval. <em>PAAA</em>, <em>26</em>(3), 1171–1189. (<a
href="https://doi.org/10.1007/s10044-023-01142-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inferring aliasing and buffer-size information is important to understanding a C program&#39;s memory layout, which is critical to program analysis and security-related tasks. However, traditional static and dynamic program analysis methods suffer from certain limitations: static alias analysis methods suffer from precision loss and have poor scalability. Meanwhile, although dynamic analysis can achieve high precision, there is no soundness guarantee, and an online analysis may cause non-negligible runtime overhead. Besides, the current methods can only capture aliasing information. As for the buffer-size relational information, which is the specific variable storing the size of the buffer pointed by the pointers, it is tough to analyze by traditional methods. Moreover, we observe that most methods are designed for specific information. To address these limitations, we present ABSLearn, a deep learning framework that is capable of retrieving both aliasing and buffer-size information from C programs. The core idea of ABSLearn is to formulate the information retrieval as a link prediction problem, where a Graph Neural Network (GNN) model is applied to solve the problem. We developed the first related dataset that contains 285 C program samples to train ABSLearn. Then, the trained model is applied to infer the information on three practical benchmarks: Gzip-1.2.4, Make-3.80, and Tar-1.15.1. The results show that ABSLearn achieves comparable performance and excellent runtime performance. As the first attempt at applying GNN to infer aliasing and buffer-size information, ABSLearn can potentially benefit future program analysis frameworks.},
  archive      = {J_PAAA},
  author       = {Liang, Ke and Tan, Jim and Zeng, Dongrui and Huang, Yongzhe and Huang, Xiaolei and Tan, Gang},
  doi          = {10.1007/s10044-023-01142-2},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1171-1189},
  shortjournal = {Pattern Anal. Appl.},
  title        = {ABSLearn: A GNN-based framework for aliasing and buffer-size information retrieval},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weighted edit distance optimized using genetic algorithm for
SMILES-based compound similarity. <em>PAAA</em>, <em>26</em>(3),
1161–1170. (<a
href="https://doi.org/10.1007/s10044-023-01141-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A method for developing new drugs is the ligand-based approach, which requires intermolecular similarity computation. The simplified molecular input line entry system (SMILES) is primarily used to represent the molecular structure in one dimension. It is a representation of molecular structure; the properties can be completely different even if only one character is changed. Applying the conventional edit distance method makes it difficult to obtain optimal results, because the insertion, deletion, and substitution of molecules are considered the same in calculating the distance. This study proposes a novel edit distance using an optimal weight set for three operations. To determine the optimal weight set, we present a genetic algorithm with suitable hyperparameters. To emphasize the impact of the proposed genetic algorithm, we compare it with the exhaustive search algorithm. The experiments performed with four well-known datasets showed that the weighted edit distance optimized with the genetic algorithm resulted in an average performance improvement in approximately 20%.},
  archive      = {J_PAAA},
  author       = {Choi, In-Hyuk and Oh, Il-Seok},
  doi          = {10.1007/s10044-023-01141-3},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1161-1170},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Weighted edit distance optimized using genetic algorithm for SMILES-based compound similarity},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep fuzzy SegNet-based lung nodule segmentation and
optimized deep learning for lung cancer detection. <em>PAAA</em>,
<em>26</em>(3), 1143–1159. (<a
href="https://doi.org/10.1007/s10044-023-01135-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Globally, lung cancer has a high fatality rate and is a lethal disease. Since lung cancer affects both men and women, it requires extra consideration when evaluating various diseases. Furthermore, early detection is even more important in order to increase the survival percentage of affected patients. There are many methods for detecting lung cancer, but it can be difficult to locate the affected area due to low visibility of the tumor section and imaging failure rates. Due to poor image quality, which distorts the segmentation process, the standard strategies failed to increase the accuracy rate. In order to diagnose lung cancer disease, this research created an approach known as Bat Deer Hunting Optimization Algorithm-based Deep Convolutional Neural Network (BDHOA-based DCNN). Here, Computed Tomography pictures are used to predict the presence of lung cancer. The Bat Algorithm (BA) and Deer Hunting Optimization Algorithm have been integrated into the newly developed BDHOA algorithm (DHOA). To execute the lung cancer detection and classification, the lung lobe and nodule region is segmented from the lung picture. With accuracy, sensitivity, and specificity scores of 0.9243, 0.9421, and 0.8915, the suggested approach performed better.},
  archive      = {J_PAAA},
  author       = {Navaneethakrishnan, M. and Anand, M. Vijay and Vasavi, G. and Rani, V. Vasudha},
  doi          = {10.1007/s10044-023-01135-1},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1143-1159},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Deep fuzzy SegNet-based lung nodule segmentation and optimized deep learning for lung cancer detection},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiview meta-metric learning for sign language recognition
using triplet loss embeddings. <em>PAAA</em>, <em>26</em>(3), 1125–1141.
(<a href="https://doi.org/10.1007/s10044-023-01134-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiview video processing for recognition is a hard problem if the subject is in continuous motion. Especially the problem becomes even tougher when the subject in question is a human being and the actions to be recognized from the video data are a complex set of actions called sign language. Although many deep learning models have been successfully applied for sign language recognition (SLR), very few models have considered multiple views in their training set. In this work, we propose to apply meta-metric learning for video-based SLR. Contrasting to traditional metric learning where the triplet loss is constructed on the sample-based distances, the meta-metric learns on the set-based distances. Consequently, we construct meta-cells on the entire multiview dataset and perform a task-based learning approach with respect to support cells and query sets. Additionally, we propose a maximum view pooled distance on sub-tasks for binding intra class views. Experiments conducted on the multiview sign language dataset and four human action recognition datasets show that the proposed multiview meta-metric learning model (MVDMML) achieves higher accuracies than the baselines.},
  archive      = {J_PAAA},
  author       = {Mopidevi, Suneetha and Prasad, M. V. D. and Kishore, Polurie Venkata Vijay},
  doi          = {10.1007/s10044-023-01134-2},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1125-1141},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Multiview meta-metric learning for sign language recognition using triplet loss embeddings},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A single defocused image depth recovery with superpixel
segmentation. <em>PAAA</em>, <em>26</em>(3), 1113–1123. (<a
href="https://doi.org/10.1007/s10044-023-01133-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the depth restoration algorithms are complicated for a single defocused image, the restoration effect is poor on the image edges, complex textures and shadow areas. In this paper, the depth of a scene is recovered by a single image defocus cue, a novel approach of single defocused image depth restoration is proposed based on superpixel segmentation. First, the simple linear iterative cluster (SLIC) is used to divide the original image into several superpixel modules. Then, the defocus blur amount of each superpixel module is obtained according to the Gaussian–Cauchy mixed model, so as to obtain the superpixel-level sparse depth map. Finally, the cellular automata model is used to optimize the obtained sparse depth map and to restore the true and accurate panoramic depth map. Compared with other methods, the algorithm not only minimizes the error, but also simplifies the process of extending the edge defocus blur to the global. The experimental results on real data show that the method is not only less time-consuming, but also can effectively improve the depth recovery effect in areas with unclear edges, complex textures and shadows. These demonstrate the effectiveness of the method in providing reliable estimates of scene depth.},
  archive      = {J_PAAA},
  author       = {Chen, Yanli and Wang, Haitao and Gao, Jinding},
  doi          = {10.1007/s10044-023-01133-3},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1113-1123},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A single defocused image depth recovery with superpixel segmentation},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Anomalous human activity detection in videos using
bag-of-adapted-models-based representation. <em>PAAA</em>,
<em>26</em>(3), 1101–1112. (<a
href="https://doi.org/10.1007/s10044-023-01177-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomalous human activity detection is highly essential due to its numerous uses in both public and private safety. Autoencoders-based normality modeling approaches detect some anomalous events as normal activities. We propose an effective strategy Bag-of-Adapted-Model (BoAM)-based approaches that utilize multiple Adapted Gaussian Mixture Models (AGMMs). In the first approach, two base class GMMs are constructed for normal and anomalous event classes. Then, adapted GMMs are constructed using training snippets of normal and anomalous events by adapting the corresponding base class GMMs to derive class-specific characteristics in AGMM. For a given video segment, likelihood-based embeddings provide improved discrimination between normal and anomalous event classes. BoAM can also be created using only normal occurrences of training data, and then, the representations fed to OC-SVM in order to detect outliers. Another variant of BoAM that used Universal Background Model (UBM) as a base model (BoAM_UBM) for adaptation gives comparable performance. Results over three standard datasets proved the consistent improvement. The proposed embeddings are suitable for detecting abnormalities even with smaller amount of anomalous training data.},
  archive      = {J_PAAA},
  author       = {Chandrakala, S.},
  doi          = {10.1007/s10044-023-01177-5},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1101-1112},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Anomalous human activity detection in videos using bag-of-adapted-models-based representation},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-level distance embedding learning for robust acoustic
scene classification with unseen devices. <em>PAAA</em>, <em>26</em>(3),
1089–1099. (<a
href="https://doi.org/10.1007/s10044-023-01172-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acoustic scene classification (ASC) aims to analyse the recording scene of a piece of audio. In real life, ASC has to deal with audio data from various recording devices, even those recorded by devices that did not appear during the training phase. Audio data recorded by different devices, especially unseen devices, have differences in sampling rate, amplitude, data distribution, etc. These differences can greatly interfere with the feature learning process of CNNs and lead to degradation of the performance of the ASC model. In order to learn advanced features that are less susceptible to differences in device information from manual features that contain device information, we propose an ASC method based on multi-level distance embedding space, called multi-level distance embedding learning (MDEL). There is a hierarchical relationship among the categories of acoustic scene, that is, from the three coarse-grained categories of indoor, outdoor, and transportation to more fine-grained categories. This relation corresponds to a similarity relation between categories of different granularity. MDEL exploits this hierarchical relationship of similarity between acoustic scene classes to construct embedding space containing multi-level distance. During the learning process, the model is guided to focus more on common features of the same scene classes and learn an advanced feature that is more robust to the device, thus improving the robustness of the model to data from unseen devices. Our method was evaluated on the audio dataset provided by the DCASE2020 Challenge for Task1a, and the overall classification accuracy was improved by 1.2 $$\%$$ . For audio data from unseen devices, the classification accuracy was improved by 2.3 $$\%$$ .},
  archive      = {J_PAAA},
  author       = {Jiang, Gang and Ma, Zhongchen and Mao, Qirong and Zhang, Jianming},
  doi          = {10.1007/s10044-023-01172-w},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1089-1099},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Multi-level distance embedding learning for robust acoustic scene classification with unseen devices},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Body condition scoring network based on improved YOLOX.
<em>PAAA</em>, <em>26</em>(3), 1071–1087. (<a
href="https://doi.org/10.1007/s10044-023-01171-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the process of pig growth, key biological indicators, especially body condition scoring can accurately reflect the body condition of pigs, which has great essentiality. However, the existing manual scoring is time-consuming and labor-intensive and is readily influenced by the operator’s subjective, resulting in large deviations. At present, the automatic measurement network for pig body condition scoring has not been popularized, so it is necessary to research and develop an automatic, efficient and accurate pig body condition scoring (BCS) algorithm. We extracted a total of 21,943 rear and upper images of 1674 pigs from videos in the piggery and then devised an automatic labeling method for the dataset. After being scored and processed by professionals, the dataset is fed into a YOLOX-based improved object detection and measurement network. In order to further improve the BCS estimation accuracy, we introduce an attention mechanism in the measurement network and design a dynamic loss weight optimizer. Compared with the basic YOLOX network, the improved network has got promising test results. We conduct experiments on 380 pictures completely independent of the training set. The model experiment result demonstrates that the accuracy rate of the pig body condition scoring algorithm proposed in this paper can achieve a AP of 80.06%. After deployed on the jetson NX, the accuracy of model drops by only 1.53%, and the inference speed is able to reach 29FPS. This means that it have access to be applied to actual pig breeding.},
  archive      = {J_PAAA},
  author       = {He, Hengxiang and Chen, Chunyu and Zhang, Weiwei and Wang, Zhiwen and Zhang, Xingfu},
  doi          = {10.1007/s10044-023-01171-x},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1071-1087},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Body condition scoring network based on improved YOLOX},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MVDet: Multi-view multi-class object detection without
ground plane assumption. <em>PAAA</em>, <em>26</em>(3), 1059–1070. (<a
href="https://doi.org/10.1007/s10044-023-01168-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although many state-of-the-art methods of object detection in a single image have achieved great success in the last few years, they still suffer from the false positives in crowd scenes of the real-world applications like automatic checkout. In order to address the limitations of single-view object detection in complex scenes, we propose MVDet, an end-to-end learnable approach that can detect and re-identify multi-class objects in multiple images captured by multiple cameras (multi-view). Our approach is based on the premise that incorrect detection results in a specific view can be eliminated using precise cues from other views, given the availability of multi-view images. Unlike most existing multi-view detection algorithms, which assume that objects belong to a single class on the ground plane, our approach can classify multi-class objects without such assumptions and is thus more practical. To classify multi-class objects, we propose an integrated architecture for region proposal, re-identification, and classification. Additionally, we utilize the epipolar geometry constraint to devise a novel re-identification algorithm that does not require assumptions about ground plane assumption. Our model demonstrates competitive performance compared to several baselines on the challenging MessyTable dataset.},
  archive      = {J_PAAA},
  author       = {Park, Sola and Yang, Seungjin and Lee, Hyuk-Jae},
  doi          = {10.1007/s10044-023-01168-6},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1059-1070},
  shortjournal = {Pattern Anal. Appl.},
  title        = {MVDet: Multi-view multi-class object detection without ground plane assumption},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Shape completion using orthogonal views through a
multi-input–output network. <em>PAAA</em>, <em>26</em>(3), 1045–1057.
(<a href="https://doi.org/10.1007/s10044-023-01154-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowing the shape of objects is essential to many robotics tasks. However, this is not always feasible. Recent approaches based on point clouds and voxel cubes have been proposed for shape completion from a single-depth view. However, they tend to be computationally expensive and require the tuning of many weights. This paper presents a novel architecture for shape completion based on six orthogonal views obtained from a point cloud (they can be seen as the six faces of a dice). Our network uses one branch for each orthogonal view as input–output and mixes them in the middle of the architecture. By using orthogonal views, the number of required parameters is significantly reduced. We also introduce a novel method to filter the output of networks based on orthogonal views and describe algorithms to convert an orthogonal view to voxel cube and point cloud. We compared our approach against state-of-the-art approaches on the YCB and ShapeNet datasets using the Chamfer distance and mean square error measures and showed very competitive performance with less than 5% of their parameters.},
  archive      = {J_PAAA},
  author       = {Delgado, Leonardo and Morales, Eduardo F.},
  doi          = {10.1007/s10044-023-01154-y},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1045-1057},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Shape completion using orthogonal views through a multi-input–output network},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Regularized denoising latent subspace based linear
regression for image classification. <em>PAAA</em>, <em>26</em>(3),
1027–1044. (<a
href="https://doi.org/10.1007/s10044-023-01149-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel method, called Regularized Denoising Latent Subspace based Linear Regression (RDLSLR), for noisy image classification. RDLSLR model divides the traditional subspace learning model into two steps. The first step is adding a denoising latent space between the vision space and label space to obtain clean data by an undercomplete autoencoder and the second step is using another transformation matrix to learn regression target by clean data. In order to further optimize the distribution of data in subspace, an additional Laplacian Regularization is introduced to label space with the help of manifold learning. In addition, $$\epsilon$$ -dragging technique is used in the label space to make the RDLSLR model more discriminative. In the RDLSLR model, data denoising, local structure, and label relaxation are considered at the same time. A joint optimization model is constructed, and an efficient iterative algorithm is designed to solve the proposed model. In order to verify the effectiveness of the RDLSLR model, several experiments involving the face, biometric, object, and deep feature recognition have been conducted. The experimental results show that the proposed RDLSLR model is achieved compared with many state-of-the-art methods.},
  archive      = {J_PAAA},
  author       = {Su, Ziyi and Wenbo, Wang and Zhang, Weibin},
  doi          = {10.1007/s10044-023-01149-9},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1027-1044},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Regularized denoising latent subspace based linear regression for image classification},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning-based cutting force prediction for machining
process using monitoring data. <em>PAAA</em>, <em>26</em>(3), 1013–1025.
(<a href="https://doi.org/10.1007/s10044-023-01143-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machining is a critical process in manufacturing industries. With the increase in the complexity and precision of machining, computer systems, such as computerized numerical control, machining monitoring systems (MMSs), and virtual machining (VM), have been incorporated in modern machining processes. In this study, a deep learning-based cutting force prediction method was proposed. MMS and VM data were collected from real-world machining processes. Next, the prediction of the cutting force using five deep learning-based methods, including the long short-term memory (LSTM) and temporal convolutional networks, were analyzed and compared with values measured with a tool dynamometer. The experimental results revealed that the proposed LSTM model, including bidirectional and residual structures, outperformed other benchmark models in terms of predicting the cutting force. Furthermore, the proposed method trained only with MMS data exhibited excellent performance with a root-mean-square error of 12.55 and $$R^{2}$$ of 0.99 on average. Thus, the cutting force required at each point can be predicted accurately, and the method can become a reference for further studies.},
  archive      = {J_PAAA},
  author       = {Lee, Soomin and Jo, Wonkeun and Kim, Hyein and Koo, Jeongin and Kim, Dongil},
  doi          = {10.1007/s10044-023-01143-1},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1013-1025},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Deep learning-based cutting force prediction for machining process using monitoring data},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detection, tracking, and recognition of isolated
multi-stroke gesticulated characters. <em>PAAA</em>, <em>26</em>(3),
987–1012. (<a href="https://doi.org/10.1007/s10044-023-01137-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection and tracking of the bare hand are the most vital stages in the bare hand gesticulated character recognition system. Applying detection and tracking in an uncontrolled environment is quite challenging due to the variations in pose, position, illumination, occlusion, scale, rotation, speed, and bare hand-like impostors in the background or foreground. The motion blur due to speed variation makes it more complex. A computationally efficient object localization approach, i.e., region-based convolutional neural network on the selective region (RCNN-SR), is introduced in this work to detect the bare hand by overcoming these challenges at a certain level. To handle the motion blur and computational complexity, the paper presents a motion information-based detection and tracking approach using RCNN-SR, point tracker, and Kalman filter. The trajectory of the gesticulated characters is formed by mapping all the centroid points of the localized bare hand. To recognize this gesticulated trajectory, the original-existence-based gesticulated character recognition model is designed in this work by utilizing prior information about the characters. In this, we have tried to overcome the variations in pattern, style, scale, rotation, and illumination. In addition, we have addressed the case sensitivity between the English lowercase and uppercase alphabets by incorporating the boundary information. We have also proposed NITS R-Net, NITS hand gesture database VIIIB, and NITS Gesture image databases in this work. To evaluate proposed models, several benchmark databases are considered.},
  archive      = {J_PAAA},
  author       = {Yadav, Kuldeep Singh and Kirupakaran, Anish Monsley and Laskar, Rabul Hussain and Bhuyan, M. K.},
  doi          = {10.1007/s10044-023-01137-z},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {987-1012},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Detection, tracking, and recognition of isolated multi-stroke gesticulated characters},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prioritized air light and transmittance extraction (PATE)
using dual weighted deep channel and spatial attention based model for
image dehazing. <em>PAAA</em>, <em>26</em>(3), 969–985. (<a
href="https://doi.org/10.1007/s10044-023-01187-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The image dehazing is a complicated dilemma to resolve the haze density influence on the object depth. Though many pixel-based or color space-based algorithms are used by many researchers for resolving this issue, due to lack of utilizing the prominent information makes the objective not achieved properly. The main objective if this work is to dehaze an image with fine-tuned parameters. The proposed research work prioritized air light and transmittance extraction (PATE) using a novel dual weighted deep channel and spatial attention (DWDCA)-based model helps to give proper weightage for the color information to restore the prominent color. The loss information calculation framework is proposed in this model to further enhance the output. The performance analysis is done with the benchmark datasets such as i-haze, o-haze and SOTS datasets where the proposed algorithm gives significant improvements in the metrics such as PSNR, SSIM and CIEDE2000 than the state-of-the-art algorithms. The proposed dehazing model with dual weighted channel and spatial attention block effectively preserves the data and improves the vision of the image.},
  archive      = {J_PAAA},
  author       = {Suganthi, M. and Akila, C.},
  doi          = {10.1007/s10044-023-01187-3},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {969-985},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Prioritized air light and transmittance extraction (PATE) using dual weighted deep channel and spatial attention based model for image dehazing},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid two-stage cascade for instance segmentation of
overlapping objects. <em>PAAA</em>, <em>26</em>(3), 957–967. (<a
href="https://doi.org/10.1007/s10044-023-01185-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although two-stage methods of instance segmentation achieve better performance than one-stage counterparts, the segmentation results on overlapping objects are unsatisfactory. We found that occlusion significantly impacts the location of adjacent objects and produces coarse masks without adequate  refinements. To circumvent the issue, we propose a hybrid model for instance segmentation called HTCIS, which iteratively forms the detection and segmentation. The main idea is to improve overall performance by optimizing every component based on a two-stage cascade structure. Compared with existing models, our approach decreases the loss of feature information, including semantic and detailed features. The detection branch prioritizes location accuracy when ranking bounding boxes, while the segmentation branch explores more contextual information and segments pixels in a multi-view fashion with the guide of an attention mechanism. Experimental results demonstrate that HTCIS is capable of processing occlusion. We conclude that multi-refinement of two-stage cascade is essential for accurate segmentation of overlapping objects, and our optimization is efficient in achieving this goal.},
  archive      = {J_PAAA},
  author       = {Yang, Yakun and Luo, Wenjie and Tian, Xuedong},
  doi          = {10.1007/s10044-023-01185-5},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {957-967},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Hybrid two-stage cascade for instance segmentation of overlapping objects},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep neural networks for rank-consistent ordinal regression
based on conditional probabilities. <em>PAAA</em>, <em>26</em>(3),
941–955. (<a href="https://doi.org/10.1007/s10044-023-01181-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, deep neural networks achieved outstanding predictive performance on various classification and pattern recognition tasks. However, many real-world prediction problems have ordinal response variables, and this ordering information is ignored by conventional classification losses such as the multi-category cross-entropy. Ordinal regression methods for deep neural networks address this. One such method is the CORAL method, which is based on an earlier binary label extension framework and achieves rank consistency among its output layer tasks by imposing a weight-sharing constraint. However, while earlier experiments showed that CORAL’s rank consistency is beneficial for performance, it is limited by a weight-sharing constraint in a neural network’s fully connected output layer, which may restrict the expressiveness and capacity of a network trained using CORAL. We propose a new method for rank-consistent ordinal regression without this limitation. Our rank-consistent ordinal regression framework (CORN) achieves rank consistency by a novel training scheme. This training scheme uses conditional training sets to obtain the unconditional rank probabilities through applying the chain rule for conditional probability distributions. Experiments on various datasets demonstrate the efficacy of the proposed method to utilize the ordinal target information, and the absence of the weight-sharing restriction improves the performance substantially compared to the CORAL reference approach. Additionally, the suggested CORN method is not tied to any specific architecture and can be utilized with any deep neural network classifier to train it for ordinal regression tasks.},
  archive      = {J_PAAA},
  author       = {Shi, Xintong and Cao, Wenzhi and Raschka, Sebastian},
  doi          = {10.1007/s10044-023-01181-9},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {941-955},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Deep neural networks for rank-consistent ordinal regression based on conditional probabilities},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatial–temporal gated graph attention network for
skeleton-based action recognition. <em>PAAA</em>, <em>26</em>(3),
929–939. (<a href="https://doi.org/10.1007/s10044-023-01179-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human body skeleton, acting as a spatiotemporal graph, is the key inspiration for researchers to implement a GCN-based method for action recognition. Most recently proposed GCN-based techniques combine convolutions with a self-attention mechanism to extract the most informative joint of a human skeleton and increase the model accuracy. However, the traditional multi-head attention method absorbed all attention heads equally, whereas in most situations, especially for extended skeleton sequences, not all attention heads are expected. Therefore, we present a spatial–temporal gated graph attention network (ST-GGANet) to learn the spatial–temporal patterns of skeleton sequences. The proposed approach uses a lightweight self-attention-based gate layer to pay attention to the important body parts or joints of human skeleton sequences. Experiments show that by introducing an additional gate layer, which controls the significance of each attention head, the proposed model achieved better action classification results while keeping computational cost low. The proposed framework has been evaluated on well-known publicly available large-scale datasets NTU60, NTU120, and Kinetics-400, which notably outperforms state-of-the-art (SOTA) results with an accuracy of 96.5%, 87.3%, and 60.4%, respectively.},
  archive      = {J_PAAA},
  author       = {Rahevar, Mrugendrasinh and Ganatra, Amit},
  doi          = {10.1007/s10044-023-01179-3},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {929-939},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Spatial–Temporal gated graph attention network for skeleton-based action recognition},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). The object migration automata: Its field, scope,
applications, and future research challenges. <em>PAAA</em>,
<em>26</em>(3), 917–928. (<a
href="https://doi.org/10.1007/s10044-023-01163-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partitioning, in and of itself, is an NP-hard problem. Prior to the Artificial Intelligence (AI)-based solutions, it was solved in the 1970s by optimization-based strategies. However, AI-based solutions appeared in the 1980s in a pioneering way, by using a Learning Automaton (LA)-motivated strategy known as the so-called Object Migrating Automaton (OMA). Although the OMA and its derivatives have been used in numerous applications since then, the basic kernel has remained the same. Because the number of possible partitions in a partitioning problem can be combinatorially exponential and the underlying tasks are NP-hard, the most advanced OMA algorithms could, until recently, only solve issues involving equally sized groups. Due to our recent innovations cited in the body of this paper, the enhanced OMA now also handles non-equally sized groups. Earlier, we had presented in Omslandseter (Pattern Anal Appl, 2023), a comprehensive survey of the state-of-the-art enhancements of the best-known OMA. We believe that these results will be the benchmark for a few decades and that it will be very hard to beat these results. This is a companion paper, intended to augment the contents of Omslandseter (Pattern Anal Appl, 2023). In this paper, we first discuss the OMA’s prior applications, its historical and current innovations, and the OMA-based algorithms’ relevance to societal needs. We also provide well-specified guidelines for future researchers so that they can use them for unresolved tasks, and also develop further advancements.},
  archive      = {J_PAAA},
  author       = {Oommen, B. John and Omslandseter, Rebekka Olsson and Jiao, Lei},
  doi          = {10.1007/s10044-023-01163-x},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {917-928},
  shortjournal = {Pattern Anal. Appl.},
  title        = {The object migration automata: Its field, scope, applications, and future research challenges},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A self-adaptive graph-based clustering method with noise
identification. <em>PAAA</em>, <em>26</em>(3), 907–916. (<a
href="https://doi.org/10.1007/s10044-023-01160-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based clustering methods offer competitive performance in dealing with complex and nonlinear data patterns. The outstanding characteristic of such methods is the capability to mine the internal topological structure of a dataset. However, most graph-based clustering algorithms are vulnerable to parameters. In this paper, we propose a self-adaptive graph-based clustering method (SAGC) with noise identification based on directed natural neighbor graph to auto identify the desired number of clusters and simultaneously obtain reliable clustering results without prior knowledge and parameter setting. This method adopts parameter adaptive process to deal with specific data patterns and can identify clusters with diverse shapes and detect noises. We use synthetic and UCI real-world datasets to prove the validity of the innovatory method by comparing it to k-means, DBSCAN, OPTICS, AP, SC, CutPC, and WC algorithms in terms of clustering Accuracy, Adjusted Rand index, Normalized Mutual Information and Fowlkes–Mallows index. The experimental results confirm that the proposed method contributes to the progress of graph-based clustering algorithms.},
  archive      = {J_PAAA},
  author       = {Li, Lin and Chen, Xiang and Song, Chengyun},
  doi          = {10.1007/s10044-023-01160-0},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {907-916},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A self-adaptive graph-based clustering method with noise identification},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Visual object tracking via adaptive deep feature matching
and overlap maximization. <em>PAAA</em>, <em>26</em>(3), 889–906. (<a
href="https://doi.org/10.1007/s10044-023-01157-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual object tracking using deep features has achieved great success, particularly when object appearances change in the presence of illumination variation, occlusion, in-plane rotation, scaling, and fast motion. In the state-of-the-art approaches, the common model for object tracking is developed to address appearance variations with coexisting challenges. When the object features differ from appearance variations, the common model approach is ineffective, with simultaneous challenges. To alleviate these limitations, in this paper, a visual object tracking framework is proposed that relies on an adaptive object appearance feature update and template overlap maximization. The tracked object location is identified by performing feature matching between the previous frame’s tracked template and the scaled templates’ feature vectors in the current frame. Feature vectors are formed using template color and pretrained deep features. To adapt to appearance variations, the proposed tracking model updates the tracked template feature vector and the spatial information for target tracking in the successive frames. The experimental results on challenging video sequences in object tracking benchmarks demonstrate that the proposed tracking model can track objects with precision of 88.7% at a 12 frames/second tracking speed. The qualitative analysis shows that the proposed tracking model outperforms the related conventional trackers.},
  archive      = {J_PAAA},
  author       = {Aklak, Annis Fathima and Vadamala, Purandhar Reddy},
  doi          = {10.1007/s10044-023-01157-9},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {889-906},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Visual object tracking via adaptive deep feature matching and overlap maximization},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DDNSR: A dual-input degradation network for real-world
super-resolution. <em>PAAA</em>, <em>26</em>(3), 875–888. (<a
href="https://doi.org/10.1007/s10044-023-01150-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Real-World Super-Resolution has become one of the most popular research fields in the scope of Single Image Super-Resolution, as it focuses on real-world applications. Due to the lack of paired training data, developing real-world super-resolution is considered a more challenging problem. Previous works intended to model the real image degradation process so that paired training images could be obtained. Specifically, some methods attempt to explicitly estimate degradation kernels and noise patterns, while others introduce degradation networks to learn maps from high-resolutions (HRs) to low-resolutions (LRs), which is a more direct and practical way. However, previous degradation networks take only one HR image as an input and therefore can hardly learn the real sensor noise contained in LR samples. In this paper, we propose a novel dual-input degradation network that takes a real LR image as an additional input to better learn the real sensor noise. Furthermore, we propose an effective self-supervised learning method to synchronously train the degradation network along with the reconstruction network. Extensive experiments showed that our dual-input degradation network can better simulate the real degradation process, thereby indicating that the reconstruction network outperforms state-of-the-art methods. Original codes and most of the testing data can be found on our website.},
  archive      = {J_PAAA},
  author       = {Li, Yizhi and Chen, Haixin and Li, Tao and Liu, Binbing},
  doi          = {10.1007/s10044-023-01150-2},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {875-888},
  shortjournal = {Pattern Anal. Appl.},
  title        = {DDNSR: A dual-input degradation network for real-world super-resolution},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep neural network watermarking based on a reversible image
hiding network. <em>PAAA</em>, <em>26</em>(3), 861–874. (<a
href="https://doi.org/10.1007/s10044-023-01140-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, many researchers have proposed deep neural network (DNN) watermarking technologies, DNN watermarking approaches can be divided into two categories: static watermarking and dynamic watermarking methods. A static watermark is embedded into the internal parameters of a DNN model, but a dynamic watermark relies on the specific training data of the DNN model and uses the associated neuron activation map or the output result by the DNN model to extract the watermark information. Dynamic watermarks mostly use DNN application programming interfaces(APIs) to remotely access DNN models and extract their watermarks to prove their copyright, so dynamic watermarking technology is more popular. According to the distribution inconsistency between a dynamic watermark and training data, an attacker can detect the dynamic watermark, so that the model owner cannot obtain the desired prediction results and then verify the copyright of the suspect model. To this end, we propose a dynamic watermarking approach based on a reversible image hiding network, which improved the undetectability of a DNN watermark, and it can perfectly reconstruct the secret image as the copyright logo of a DNN model. We perform our work on the MNIST, Fashion-MNIST, CIFAR-10, CIFAR-100, and Caltech-101 datasets. The experimental results show that our method has higher DNN watermarking accuracy and higher undetectability with no significant side effects on the main functions of the host DNN model.},
  archive      = {J_PAAA},
  author       = {Wang, Linna and Song, Yunfei and Xia, Daoxun},
  doi          = {10.1007/s10044-023-01140-4},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {861-874},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Deep neural network watermarking based on a reversible image hiding network},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-modal face recognition with illumination-invariant
local discrete cosine transform binary pattern (LDCTBP). <em>PAAA</em>,
<em>26</em>(3), 847–859. (<a
href="https://doi.org/10.1007/s10044-023-01139-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the ever-increasing security threats in recent years, biometric authentication has become omnipresent. Among all biometric characteristics, face recognition research has gained traction lately. This paper proposes a new face image descriptor named Local Discrete Cosine Transform Binary Pattern (LDCTBP) for illumination- and modality-invariant face recognition. Utilizing the frequency segregation behavior of Discrete Cosine Transform (DCT), an effective cross-modal illumination-agnostic local feature descriptor has been formulated. Eventually, by encoding the illumination-normalized DCT coefficients into a binary pattern, Local Discrete Cosine Transform Binary Pattern has been generated. Qualitative and quantitative analysis performed on the Extended Yale-B, CUFSF, and TUFTS dataset depict the supremacy of the proposed framework over other state-of-the-arts. Moreover, the proposed LDCTBP has been integrated with a light-weight Convolutional Neural Network (CNN) to prove the importance of handcrafted features in CNN training.},
  archive      = {J_PAAA},
  author       = {Koley, Subhadeep and Roy, Hiranmoy and Dhar, Soumyadip and Bhattacharjee, Debotosh},
  doi          = {10.1007/s10044-023-01139-x},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {847-859},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Cross-modal face recognition with illumination-invariant local discrete cosine transform binary pattern (LDCTBP)},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of natural language processing in contact centre
automation. <em>PAAA</em>, <em>26</em>(3), 823–846. (<a
href="https://doi.org/10.1007/s10044-023-01182-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contact centres have been highly valued by organizations for a long time. However, the COVID-19 pandemic has highlighted their critical importance in ensuring business continuity, economic activity, and quality customer support. The pandemic has led to an increase in customer inquiries related to payment extensions, cancellations, and stock inquiries, each with varying degrees of urgency. To address this challenge, organizations have taken the opportunity to re-evaluate the function of contact centres and explore innovative solutions. Next-generation platforms that incorporate machine learning techniques and natural language processing, such as self-service voice portals and chatbots, are being implemented to enhance customer service. These platforms offer robust features that equip customer agents with the necessary tools to provide exceptional customer support. Through an extensive review of existing literature, this paper aims to uncover research gaps and explore the advantages of transitioning to a contact centre that utilizes natural language solutions as the norm. Additionally, we will examine the major challenges faced by contact centre organizations and offer recommendations for overcoming them, ultimately expediting the pace of contact centre automation.},
  archive      = {J_PAAA},
  author       = {Shah, Shariq and Ghomeshi, Hossein and Vakaj, Edlira and Cooper, Emmett and Fouad, Shereen},
  doi          = {10.1007/s10044-023-01182-8},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {823-846},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A review of natural language processing in contact centre automation},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Script identification of ancient books by chinese ethnic
minorities using multi-branch DCNN and SPP. <em>PAAA</em>,
<em>26</em>(2), 809–821. (<a
href="https://doi.org/10.1007/s10044-023-01146-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic classification of ancient books is an important component of the digital platform of ancient books, while automatic classification of ancient books is more challenging. In view of the ancient books script identification task of different ethnic minorities in China, this paper proposes a deep convolutional neural network (CNN) ancient books script identification method with multi-branch structure and spatial pyramid pooling (SPP), called MbSPPVGG. We build a dataset of Chinese ethnic ancient handwritten books, and crop and standardize preprocessing images of ancient books. In order to improve the identification accuracy of ancient books and ability of CNN to perceive multi-scale changes in image, bottom-level and high-level features of CNN are merged by multi-branch structure to enhance the networks expression ability, and then use SPP to multi-scale de-dimensionality of convolutional features, increase the spatial scale invariance of CNN. The introduction of multi-branch structure and SPP in the CNN model constitutes a new ancient books identification model. The experimental results show that the precision, recall and F1-score of MbSPPVGG model are all 99.94%. As demonstrated by comparison experiments, the classification accuracy of MbSPPVGG model is better than that of state-of-the-art GhostNet, CSPDenseNet, MixNet and other deep learning methods, and its effectiveness is verified on multiple datasets.},
  archive      = {J_PAAA},
  author       = {Guo, Hai and Yang, Doudou and Liu, Yifan and Zhao, Jingying},
  doi          = {10.1007/s10044-023-01146-y},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {809-821},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Script identification of ancient books by chinese ethnic minorities using multi-branch DCNN and SPP},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual autoencoder based zero shot learning in special domain.
<em>PAAA</em>, <em>26</em>(2), 797–808. (<a
href="https://doi.org/10.1007/s10044-022-01109-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot learning aims to learn a visual classifier for a category which has no training samples leveraging its semantic information and its relationship to other categories. It is common, yet vital, in practical visual scenarios, and particularly prominent in the uncharted ocean field. Phytoplankton plays an important part in the marine ecological environment. It is common to encounter the zero-shot recognition problem during the in situ observation. Therefore, we propose a dual autoencoder model, which contains two similar encoder–decoder structures, to tackle the zero-shot recognition problem. The first one is used for the projection from the visual feature space to a latent space, then to the semantic space. Inversely, the second one projects from the semantic space to another latent space, then back to the visual feature space. This structure guarantees the projection from the visual feature space to the semantic space to be more effective, through the stable mutual mapping. Experimental results on four benchmarks demonstrate that the proposed dual autoencoder model achieves competitive performance compared with six recent state-of-the-art methods. Furthermore, we apply our algorithm to phytoplankton classification. We manually annotated phytoplankton attributes to develop a practical dataset for this real and special domain application, i.e., Zero-shot learning dataset for PHYtoplankton (ZeroPHY). Experiment results show that our method achieves the best performance on this real-world application.},
  archive      = {J_PAAA},
  author       = {Li, Qiong and Rigall, Eric and Sun, Xin and Lam, Kin Man and Dong, Junyu},
  doi          = {10.1007/s10044-022-01109-9},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {797-808},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Dual autoencoder based zero shot learning in special domain},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EEG-based emotion recognition with cascaded convolutional
recurrent neural networks. <em>PAAA</em>, <em>26</em>(2), 783–795. (<a
href="https://doi.org/10.1007/s10044-023-01136-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning has gradually become a prevailing way in EEG-based emotion recognition research because it can extract features and classify emotions automatically. To fully exploit the underlying information in EEG signals, we propose an emotion recognition method based on cascaded convolutional recurrent neural networks. Firstly, the differential entropy features of each channel signal are transformed into four-dimensional structure data, which are able to contain temporal-spatial-frequency information integratively. Then, the cascaded VGG16 and long short-term memory (LSTM) networks are applied to learn the spatiotemporal information of the samples, and the hidden layer of the last node of LSTM is output to a linear transformation classifier to perform classification. On DEAP dataset, the proposed method gives out an average accuracy of 94.43% and 94.85% in arousal-based and valence-based classification, respectively. On SEED dataset, the method achieves average accuracy of 94.16%. Compared with the existing methods, our method demonstrates superior performances in emotion recognition.},
  archive      = {J_PAAA},
  author       = {Meng, Ming and Zhang, Yu and Ma, Yuliang and Gao, Yunyuan and Kong, Wanzeng},
  doi          = {10.1007/s10044-023-01136-0},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {783-795},
  shortjournal = {Pattern Anal. Appl.},
  title        = {EEG-based emotion recognition with cascaded convolutional recurrent neural networks},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LBP and CNN feature fusion for face anti-spoofing.
<em>PAAA</em>, <em>26</em>(2), 773–782. (<a
href="https://doi.org/10.1007/s10044-023-01132-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face anti-spoofing has been attracting attention because of its prominent role in the security of face recognition systems. A face spoofing attack is launched on the authentication system by the attacker using the picture or video of the genuine user to get access to the services or information. This paper proposes local binary pattern (LBP) and convolutional neural network (CNN) based feature fusion model for classifying spoof face images. Initially, the images are pre-processed to remove the effect of the background in the feature extraction. The Viola-Jones algorithm is used for detecting and cropping the faces from the images. The color features of the pre-processed RGB images and LBP features are provided to the CNN. This feature combination reduces the requirement of a CNN-based deep learning architecture for providing a good classification performance. To validate the proposed model, it is trained and tested on NUAA and MSU-MFSD datasets. The experiment recorded the ACER of 0.21 and 0.20 on the MSU-MFSD and NUAA datasets, respectively.},
  archive      = {J_PAAA},
  author       = {Singh, Ravi Pratap and Dash, Ratnakar and Mohapatra, Ramesh Kumar},
  doi          = {10.1007/s10044-023-01132-4},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {773-782},
  shortjournal = {Pattern Anal. Appl.},
  title        = {LBP and CNN feature fusion for face anti-spoofing},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Learning automata-based partitioning algorithms for
stochastic grouping problems with non-equal partition sizes.
<em>PAAA</em>, <em>26</em>(2), 751–772. (<a
href="https://doi.org/10.1007/s10044-023-01131-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is very fascinating that the principles of Artificial Intelligence, that were proposed many decades ago, have remained to be the foundations of many of the modern-day techniques, and a brief summary of these principles is given in the paper itself. While this truism is valid for problem solving and game playing, in the context of this paper, we emphasize that it is also pertinent for the so-called partitioning problems. In this paper, we consider the general partitioning problem that has been studied for decades. Unlike the heuristic and search strategies, our attention focuses on learning automata (LA) and reinforcement learning methods, and their powerful ability to solve problems in stochastic environments. These render the latter tools to be applicable to various complex tasks. As we shall explain, LA have been employed for partitioning, and in particular, the paradigm of Object Migration Automata (OMA) has offered state-of-the-art adaptive methods for solving grouping and partitioning problems. However, because the number of possible partitions is combinatorially exponential, and of the NP-hardness of the underlying tasks, the existing state-of-the-art OMA algorithms can only solve problems of equal-sized groups. To resolve this, in this paper, we propose two new OMA variants that can solve both equally and unequally sized partitioning problems. The key here is to provide additional information to the algorithms, and in doing so, to expand the solution space. The first variant, the Greatest Common Divisor OMA (GCD-OMA), relaxes the constraint of having equally sized groups by mapping the actions onto a larger state space, and thus permitting it to solve problems where the group sizes have a GCD that is greater than unity. Subsequently, we propose a second variant named the Partition Size Required OMA (PSR-OMA) to make the algorithm more versatile. The PSR-OMA can handle groups of arbitrary sizes when the group sizes are known a priori. We demonstrate the proposed algorithms’ strength in solving stochastic grouping problems through extensive simulations, even with high noise levels. The GCD-OMA and the PSR-OMA represent the current state-of-the-art when it concerns resolving the extremely complex problem of partitioning and can be used in any of the numerous applications in which the OMA itself has been utilized .},
  archive      = {J_PAAA},
  author       = {Oommen, B. John and Omslandseter, Rebekka Olsson and Jiao, Lei},
  doi          = {10.1007/s10044-023-01131-5},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {751-772},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Learning automata-based partitioning algorithms for stochastic grouping problems with non-equal partition sizes},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Instance hardness and multivariate gaussian
distribution-based oversampling technique for imbalance classification.
<em>PAAA</em>, <em>26</em>(2), 735–749. (<a
href="https://doi.org/10.1007/s10044-022-01129-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalance classification has received great attention due to its various real-world applications. Data-level approaches are the most convenient to address data imbalance, whereas oversampling is the most deeply explored. However, most previous studies used distance-based factors to select minority class instances for oversampling. Thus, the synthetic instances often did not follow the distribution of the original minority class instances. In this work, we propose a novel oversampling method based on instance hardness and multivariate Gaussian distribution. First, a fused feature set including k-disagree value and classification error is used for selecting and weighting minority class instances for oversampling. Here, the k-disagree value is also used to filter majority class instances. Then, multivariate Gaussian distribution is fitted to the subset of selected minority class instances, where the selection of subset is based on closest- and cluster-based methods. Next, new instances are generated based on the subset distribution. Finally, Euclidean distance-based instance selection is investigated for improved imbalance classification performance. Experimental results on the KEEL dataset repository show that our proposed method can outperform the other compared oversamplers in terms of both AUC and G-mean.},
  archive      = {J_PAAA},
  author       = {Xie, Jie and Zhu, Mingying and Hu, Kai and Zhang, Jinglan},
  doi          = {10.1007/s10044-022-01129-5},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {735-749},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Instance hardness and multivariate gaussian distribution-based oversampling technique for imbalance classification},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Consensus similarity graph construction for clustering.
<em>PAAA</em>, <em>26</em>(2), 703–733. (<a
href="https://doi.org/10.1007/s10044-022-01116-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A similarity graph represents the local characteristics of a data set, and it is used as input to various clustering methods including spectral, graph-based, and hierarchical clustering. Several similarity graphs exist in the literature; however, there is not a single similarity graph that can handle all kinds of cluster shapes and structures. In this study, motivated by the successful applications of ensemble approaches to clustering, a generic method for consensus similarity graph construction is proposed. The proposed approach first constructs multiple similarity graphs using bootstrap aggregating (bagging). Then, these graphs are fused into a consensus similarity graph using the normalized co-association matrix. We use k-nearest neighbor, $$\varepsilon$$ -neighborhood, fully connected graph, and proximity graphs as the base similarity graphs. Moreover, the proposed approach is coupled with various clustering algorithms including spectral, graph-based, and hierarchical clustering. The experimental results with various spatial and real data sets demonstrate the effectiveness of the consensus similarity graphs in clustering. The proposed approach is also robust to local noise.},
  archive      = {J_PAAA},
  author       = {İnkaya, Tülin},
  doi          = {10.1007/s10044-022-01116-w},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {703-733},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Consensus similarity graph construction for clustering},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Event prediction with rough-fuzzy sets. <em>PAAA</em>,
<em>26</em>(2), 691–701. (<a
href="https://doi.org/10.1007/s10044-022-01119-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a new methodology of unsupervised event prediction from videos. Detecting events from videos without prior information is a challenging task, as there are no well-accepted definitions about events in a video. It is commonly known that the presence of moving elements in a video scene could be considered as part of an event. The possibility of an event occurring becomes higher if there is an abrupt change in the motion patterns of different object(s) present in that video scene. In this paper, we defined a method to model this phenomenon of object motion. Since we have not considered any prior information while modeling it, the initial event and nonevent classification is carried out with rough set-based approximations, namely positive, boundary, and negative, in the incomplete knowledge base, resulting in an event-nonevent rough sets. We generate three regions with rough sets. Negative class labels are assigned for static objects and those moving with predictable paths. The objects with a huge change in motion are labeled to be positive events. The remaining objects are kept in the boundary region. However, if there is a gradual change in the motion pattern, there arises some possibility of an event occurring. To define the terms, like possible events and must be event, we have fuzzified the boundary region of event-nonevent rough set and assigned different degrees of possibility of an event to occur if there is a change in motion patterns in the trajectory of the objects. That is, the event, nonevent regions are classified with rough sets, and the boundary region is fuzzified with fuzzy sets. We have validated this newly defined event-nonevent rough-fuzzy sets with experimental demonstrations where the proposed method successfully predicted the events to occur in video sequences.},
  archive      = {J_PAAA},
  author       = {Chakraborty, Debarati B. and Yao, JingTao},
  doi          = {10.1007/s10044-022-01119-7},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {691-701},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Event prediction with rough-fuzzy sets},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parkinsonian gait patterns quantification from principal
geodesic analysis. <em>PAAA</em>, <em>26</em>(2), 679–689. (<a
href="https://doi.org/10.1007/s10044-022-01115-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson is a neuromotor disease caused by dopamine deficiency that produces progressive alterations in locomotion. Gait analysis is a primary alternative to observe, quantify and follow Parkinson’s disease (PD). Nonetheless, these patterns are coarsely captured from marker-based setups which alter natural gestures and limit the sensibility to describe disease progression. This work, from a markerless video analysis, built a Riemmanian geometry gait representation to analyze principal geodesic variations and quantify alteration on locomotor patterns. The proposed approach project walking markerless videos into a bank of deep features. These deep activations are coded into compact covariance matrices, which coexist in a special Riemmanian manifold. A video gait descriptor is then formulated as the geometric mean and the principal geodesic directions with greatest variance. These descriptors are finally used in an automatic supervised PD classification task. Experiments were carried out in a dataset with 22 patients, equally distributed between control and Parkinson’s disease. Following a leave-one-patient-out cross-validation, the proposed video gait descriptor achieves an average accuracy of 99% and a true positive rate of 97%. Besides, the resultant geometry descriptor space was projected in a low-dimensional version, as an alternative to carried out observational gait analysis. This space shows a robust clustering among the evaluated classes. The proposed approach takes advantage of greatest geodesic variance to quantify abnormal locomotion PD patterns. The validation suggests that the strategy could be potentially implemented as an alternative to support diagnosis and following of the disease.},
  archive      = {J_PAAA},
  author       = {Niño, Santiago and Olmos, Juan A. and Galvis, Juan C. and Martínez, Fabio},
  doi          = {10.1007/s10044-022-01115-x},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {679-689},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Parkinsonian gait patterns quantification from principal geodesic analysis},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-supervised transformable architecture search for
feature distillation. <em>PAAA</em>, <em>26</em>(2), 669–677. (<a
href="https://doi.org/10.1007/s10044-022-01122-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The designed method aims to perform image classification tasks efficiently and accurately. Different from the traditional CNN-based image classification methods, which are greatly affected by the number of labels and the depth of the network. Although the deep network can improve the accuracy of the model, the training process is usually time-consuming and laborious. We explained how to use only a few of labels, design a more flexible network architecture and combine feature distillation method to improve model efficiency while ensuring high accuracy. Specifically, we integrate different network structures into independent individuals to make the use of network structures more flexible. Based on knowledge distillation, we extract the channel features and establish a feature distillation connection from the teacher network to the student network. By comparing the experimental results with other related popular methods on commonly used data sets, the effectiveness of the method is proved. The code can be found at https://github.com/ZhangXinba/Semi_FD.},
  archive      = {J_PAAA},
  author       = {Zhang, Man and Zhou, Yong and Liu, Bing and Zhao, Jiaqi and Yao, Rui and Shao, Zhiwen and Zhu, Hancheng and Chen, Hao},
  doi          = {10.1007/s10044-022-01122-y},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {669-677},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Semi-supervised transformable architecture search for feature distillation},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantum convolutional neural network for image
classification. <em>PAAA</em>, <em>26</em>(2), 655–667. (<a
href="https://doi.org/10.1007/s10044-022-01113-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose two scale-inspired local feature extraction methods based on Quantum Convolutional Neural Network (QCNN) in the Tensorflow quantum framework for binary image classification. The image data is properly downscaled with Multi-scale Entanglement Renormalization Ansatz and Box-counting based fractal features before fed into the QCNN’s quantum circuits for state preparation, quantum convolution and quantum pooling. Quantum classifiers with one QCNN and two hybrid Quantum-classical QCNN models have been trained with a breast cancer dataset, and their performance are compared against that of a classic CNN. The results show that the proposed QCNN with the proposed feature extraction methods outperformed the classic CNN in terms of recognition accuracy. It is interesting to find that image bit-plane slicing has a similar internal mechanism to that of the Ising phase transition. This observation motivates us to explore the correlation between the chaotic nature of image and the classification performance enhancement by QCNN classifiers. It also implies that the pixels of the image and the Ising chaology particles share some similar patterns and are apt to classification.},
  archive      = {J_PAAA},
  author       = {Chen, Guoming and Chen, Qiang and Long, Shun and Zhu, Weiheng and Yuan, Zeduo and Wu, Yilin},
  doi          = {10.1007/s10044-022-01113-z},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {655-667},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Quantum convolutional neural network for image classification},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature fusion based on joint sparse representations and
wavelets for multiview classification. <em>PAAA</em>, <em>26</em>(2),
645–653. (<a href="https://doi.org/10.1007/s10044-022-01110-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature-level-based fusion has attracted much interest. Generally, a dataset can be created in different views, features, or modalities. To improve the classification rate, local information is shared among different views by various fusion methods. However, almost all the methods use the views without considering their common aspects. In this paper, wavelet transform is considered to extract high and low frequencies of the views as common aspects to improve the classification rate. The fusion method for the decomposed parts is based on joint sparse representation in which a number of scenarios can be considered. The presented approach is tested on three datasets. The results obtained by this method prove competitive performance in terms of the datasets compared to the state-of-the-art results.},
  archive      = {J_PAAA},
  author       = {Akbari, Younes and Elharrouss, Omar and Al-Maadeed, Somaya},
  doi          = {10.1007/s10044-022-01110-2},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {645-653},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Feature fusion based on joint sparse representations and wavelets for multiview classification},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature selection using max dynamic relevancy and min
redundancy. <em>PAAA</em>, <em>26</em>(2), 631–643. (<a
href="https://doi.org/10.1007/s10044-023-01138-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection algorithms based on three-way interaction information have been widely studied. However, most of these traditional algorithms only consider class-dependent redundancy, which can lead to an underestimation of redundancy. To address this issue, a feature selection algorithm based on maximum dynamic relevancy minimum redundancy is proposed. The algorithm first proposes a quality coefficient to estimate the feature relevancy. Then we introduce class-independent redundancy to solve the issue of not fully considering redundancy, and propose adaptive coefficients to optimize the algorithm. To ensure the effectiveness of the algorithm, experimental comparisons are carried on 19 benchmark data sets with six algorithms. The results show that the proposed algorithm outperforms other algorithms in terms of performance.},
  archive      = {J_PAAA},
  author       = {Yin, Kexin and Zhai, Junren and Xie, Aifeng and Zhu, Jianqi},
  doi          = {10.1007/s10044-023-01138-y},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {631-643},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Feature selection using max dynamic relevancy and min redundancy},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature enhancement modules applied to a feature pyramid
network for object detection. <em>PAAA</em>, <em>26</em>(2), 617–629.
(<a href="https://doi.org/10.1007/s10044-023-01152-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A feature pyramid network (FPN) improves the ability of an object detection model to detect multiscale targets. However, the simple upsampling used in an FPN is not conducive to the propagation of deep semantic information, and redundant background information is not conducive to object detection. In this paper, we propose two plug-and-play modules for preexisting FPN-based architectures: a channel filtering module (CFM) and a spatial filtering module (SFM). The CFM learns the correlations between channels to improve the feature maps obtained via upsampling. The SFM introduces global information to improve the detection performance of the network. With the CFM and SFM, we improve the average precision (AP) of Faster R-CNN with an FPN by 0.9% to 1.3% on COCO, and we boost the AP of YOLOv5s with PANet by 2.8%.},
  archive      = {J_PAAA},
  author       = {Liu, Min and Lin, Kun and Huo, Wujie and Hu, Lanlan and He, Zhizi},
  doi          = {10.1007/s10044-023-01152-0},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {617-629},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Feature enhancement modules applied to a feature pyramid network for object detection},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the learning of vague languages for syntactic pattern
recognition. <em>PAAA</em>, <em>26</em>(2), 605–615. (<a
href="https://doi.org/10.1007/s10044-022-01120-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The method of the learning of vague languages which represent distorted/ambiguous patterns is proposed in the paper. The goal of the method is to infer the quasi-context-sensitive string grammar which is used in our model as the generator of patterns. The method is an important component of the multi-derivational model of the parsing of vague languages used for syntactic pattern recognition.},
  archive      = {J_PAAA},
  author       = {Flasiński, Mariusz and Jurek, Janusz and Peszek, Tomasz},
  doi          = {10.1007/s10044-022-01120-0},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {605-615},
  shortjournal = {Pattern Anal. Appl.},
  title        = {On the learning of vague languages for syntactic pattern recognition},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MSRT: Multi-scale representation transformer for
regression-based human pose estimation. <em>PAAA</em>, <em>26</em>(2),
591–603. (<a href="https://doi.org/10.1007/s10044-023-01130-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we are interested in the human pose estimation problem with a focus on leveraging discriminative pose features. Recent pose estimation works concentrate on extracting high-level features but ignore the low-level details, thus reducing the prediction accuracy. To mitigate the above issues, we propose an end-to-end method called multi-scale representation transformer network (MSRT). Our network consists of two key components: feature aggregation module (FAM) and transformers. The FAM splits and stacks feature maps of different scales, then fuses them to achieve multi-scale representation learning. This module makes up for the lack of detailed information in the high-level features. Furthermore, we utilize Transformers to identify long-range interactions among feature maps, and capture implicit body structure information, which allows the proposed network to refine the locations of terminal and occluded joints. Compared with existing regression-based methods, MSRT achieves superior results on the COCO2017 and MPII datasets.},
  archive      = {J_PAAA},
  author       = {Shan, Beiguang and Shi, Qingxuan and Yang, Fang},
  doi          = {10.1007/s10044-023-01130-6},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {591-603},
  shortjournal = {Pattern Anal. Appl.},
  title        = {MSRT: Multi-scale representation transformer for regression-based human pose estimation},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual image-based reversible fragile watermarking scheme for
tamper detection and localization. <em>PAAA</em>, <em>26</em>(2),
571–590. (<a href="https://doi.org/10.1007/s10044-022-01104-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes an efficient dual image-based reversible fragile watermarking scheme (DI-RFWS) that can accurately detect and locate the tampering regions from an image. The proposed scheme embeds two secret bits in each host image (HI) pixel using a pixel readjustment strategy to obtain dual watermarked images (WIs). The pixel readjustment strategy performs a maximum modification of ± 1 to the non-boundary pixels of an image based on the watermark information. The results of the study suggest that in addition to reversibility, the proposed scheme offers triple objective of high capacity, better perceptual transparency, and robustness. Experimental results also show that the proposed scheme achieves a superior peak signal-to-noise ratio (PSNR) of above 52 dB for both the WIs. Further, the proposed scheme can efficiently detect and locate the tampering regions from an image with a high true positive rate, low false positive and negative rate for various tampering rates. Additionally, the proposed scheme shows superior resistance against various intentional and unintentional attacks.},
  archive      = {J_PAAA},
  author       = {Sahu, Aditya Kumar and Sahu, Monalisa and Patro, Pramoda and Sahu, Gupteswar and Nayak, Soumya Ranjan},
  doi          = {10.1007/s10044-022-01104-0},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {571-590},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Dual image-based reversible fragile watermarking scheme for tamper detection and localization},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On improvability of hash clustering data from different
sources by bipartite graph. <em>PAAA</em>, <em>26</em>(2), 555–570. (<a
href="https://doi.org/10.1007/s10044-022-01125-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is a long-standing challenging task in pattern recognition and computer vision. In recent years, with development of multimedia technologies and explosive growth of data, the access to data is various. Clustering data from different feature sources has attracted considerable attentions for the remarkable clustering performance due to exploiting complementary information from data of different features. However, in fact, existing work often suffers from heavy computational load that restricts their capacity for large-scale datasets and most existing methods about fusing multi-view data are not perfect enough, namely, the quality of the joint matrix learned from multiple sources is not high enough. In this paper, we propose an efficient and effective clustering approach which combines sparse subspace learning with a bipartite graph for binary/hash codes produced from data of different sources by a collaborative discrete representation learning model that is an efficient and effective data fusion and binary code learning method. The bipartite graph that owns low time complexity is constructed to extract local geometric structure information for improving clustering performance. Extensive experiments performed on four benchmark datasets validate the efficiency and effectiveness of the proposed approach in comparison with ten state-of-the-art methods.},
  archive      = {J_PAAA},
  author       = {Zhao, Jianxi and Wang, Xiaonan and Zou, Qingrong and Kang, Fangyuan and Peng, Jingfu and Wang, Fan},
  doi          = {10.1007/s10044-022-01125-9},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {555-570},
  shortjournal = {Pattern Anal. Appl.},
  title        = {On improvability of hash clustering data from different sources by bipartite graph},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using attention LSGB network for facial expression
recognition. <em>PAAA</em>, <em>26</em>(2), 543–553. (<a
href="https://doi.org/10.1007/s10044-022-01124-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Both the multiple sources of the available in-the-wild datasets and noisy information of images lead to huge challenges for discriminating subtle distinctions between combinations of regional expressions in facial expression recognition (FER). Although deep learning-based approaches have made substantial progresses in FER in recent years, small-scale datasets result in over-fitting during training. To this end, we propose a novel LSGB method which focuses on discriminative attention regions accurately and pretrain the model on ImageNet with the aim of alleviating the problem of over-fitting. Specifically, a more efficient manner combined with a key map, multiple partial maps and a position map is presented in local relation (LR) module to construct higher-level entities through compositional relationship of local pixel pairs. A compact global weighted representation is aggregated by region features, of which the weight is obtained by putting original and regional images to the sequential layer of self-attention module. Finally, extensive experiments are conducted to verify the effectiveness of our proposal. The experimental results on three popular benchmarks demonstrate the superiority of our network with 88.8% on FERplus, 58.68% on AffectNet and 94.9% on JAFFE.},
  archive      = {J_PAAA},
  author       = {Su, Chan and Wei, Jianguo and Lin, Deyu and Kong, Linghe},
  doi          = {10.1007/s10044-022-01124-w},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {543-553},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Using attention LSGB network for facial expression recognition},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Polar radius moment with application for affine invariants.
<em>PAAA</em>, <em>26</em>(2), 529–542. (<a
href="https://doi.org/10.1007/s10044-022-01128-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image moment is an important technique for pattern recognition. But, invariants constructed with high-order moments are sensitive to noise. Only a few invariants with low-order moments can be used in practice. In this paper, the definition of traditional moment is reviewed in polar coordinate system. Polar radius moment (PRM), which is defined by a linear combination of integrals on the symmetrical polar radiuses in an image, is proposed. Traditional moment is only a special case of PRM. Algorithm is developed to construct affine invariants with PRMs. In particular, the first-degree PRM is considered as the generalization of the zero-order moment. It can be used to construct affine invariants directly. The third-degree PRM can be viewed as the generalization of the second-order moment. Consequently, more invariants can be constructed with low-order (degree) moments. The experimental results also show that invariants with low-degree PRMs are more robust to noise.},
  archive      = {J_PAAA},
  author       = {Yang, Jianwei and Liu, Chunyan and Li, Fei},
  doi          = {10.1007/s10044-022-01128-6},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {529-542},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Polar radius moment with application for affine invariants},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fuzzy and non-fuzzy k-quantile clustering for high-variance
data. <em>PAAA</em>, <em>26</em>(2), 517–528. (<a
href="https://doi.org/10.1007/s10044-022-01127-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering methods are algorithms that identify similar data, and dissimilarity measures are essential in clustering algorithms. Also, most clustering algorithms do not perform properly due to sensitivity to the variance of data. In this paper, we introduce a new asymmetric dissimilarity measure based on generalized Manhattan dissimilarity for fuzzy and non-fuzzy clustering. The performance of our proposed clustering algorithms is flexible to the variance of data. Whether the variance is high or low, the results are acceptable by selecting the appropriate asymmetric parameter of the proposed dissimilarity measure. Finally, we compare our proposed algorithms with other popular clustering methods on synthetic and real datasets.},
  archive      = {J_PAAA},
  author       = {Seidpisheh, Mohammad and Bamdadi, Rana},
  doi          = {10.1007/s10044-022-01127-7},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {517-528},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Fuzzy and non-fuzzy k-quantile clustering for high-variance data},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On error reduction by the symmetric rejection method in
multi-stage biometric verification systems. <em>PAAA</em>,
<em>26</em>(2), 505–516. (<a
href="https://doi.org/10.1007/s10044-022-01118-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multi-stage biometric verification system serially activates its verifiers and improves performance-cost trade-off by allowing users to submit a subset of the available biometrics. In the heart of a verifier in multi-stage systems lies the concept of ‘reject option’ where a reject region is used to identify a bad quality test sample. If the match-score falls inside the reject region, no binary (genuine/impostor) decision is made in the current stage and the verifier in the next stage is activated. Recent studies have demonstrated a significant promise of the ‘symmetric rejection method’ in choosing a suitable reject region for multi-stage verification systems. In this paper, we delve into the symmetric rejection method to gain more insights into its error reduction capabilities. Specifically, we develop a theory which mathematically proves that the symmetric rejection method reduces the false accept rate and false reject rate. Then, we empirically validate our theory. Results show that the symmetric rejection method significantly reduces the error rates, both the false accept rate and false reject rate.},
  archive      = {J_PAAA},
  author       = {Hossain, Md Shafaeat and Chen, Jundong and Rahman, Khandaker},
  doi          = {10.1007/s10044-022-01118-8},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {505-516},
  shortjournal = {Pattern Anal. Appl.},
  title        = {On error reduction by the symmetric rejection method in multi-stage biometric verification systems},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Occluded person re-identification based on embedded graph
matching network for contrastive feature relation. <em>PAAA</em>,
<em>26</em>(2), 487–503. (<a
href="https://doi.org/10.1007/s10044-022-01123-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main goal of person re-identification (ReID) is to identify human images captured by different cameras. However, people are often occluded by various obstacles. To solve the occlusion problem, this paper proposes a novel method that occluded person re-identification based on embedded graph matching network for contrastive feature relation. It involves three modules. In the contrast feature construction (C) module, we use the trained pose estimation (PE) model to extract the local features shown by the key points of person image. In addition, we propose the global discrepant contrastive pooling (GDCP) layer to capture global features after noise removal. At this point, the extracted features are only the node feature information,and what is not connected is a single one. In the adaptive node relationship (R) module, the node relation learning (NRL) layer is proposed to establish the contrast feature relationship between the individual information of feature extraction and the joint structure of monitoring the key points of the feature relationship, so as to automatically update the relationship between features, promote the transmission of meaningful features and inhibit the transmission of meaningless features. In this way, the relationship between the feature information can also be extracted. In the embedded graph matching (M) module, the embedded feature alignment (EFA) layer is proposed to directly predict the similarity score of each feature of the two images. In addition, the information collected from the non-occluded part of one image is used to compensate the occluded part corresponding to the other image, which reduces the dispersion of image information. We avoid using a sensitive one-to-one hard alignment instead of many-to-many soft alignment to enhance robustness. On Occluded_Duke, DukeMTMC and Market1501,this method is superior to the existing person re-identification methods. Particularly on Occluded_Duke, the Rank-1 reaches 60.5%, and mAP reaches 49.2%.},
  archive      = {J_PAAA},
  author       = {Zhou, Shuren and Zhang, Mengsi},
  doi          = {10.1007/s10044-022-01123-x},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {487-503},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Occluded person re-identification based on embedded graph matching network for contrastive feature relation},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A large-scale performance study of entropy-based image
thresholding techniques using new SAD metric. <em>PAAA</em>,
<em>26</em>(2), 473–486. (<a
href="https://doi.org/10.1007/s10044-022-01121-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents a novel method to measure the performance of entropy-based image thresholding techniques using a new Sum of Absolute value of Differences (SAD) metric in the absence of ground-truth images. The metric is further applied to estimate the parameters of generalized Renyi, Tsallis, Masi entropy measures and the optimal threshold automatically from the image histogram. This leads to a new entropy-based image thresholding algorithm with three variants—one for each generalized entropy. The SAD metric and proposed method are first validated using ground-truth images HYTA dataset. The SAD metric is compared with misclassification error metric, Jaccard and SSIM indices and is found to exhibit consistent behavior. It is further observed that the proposed new method with SAD metric produces same or less misclassification errors than the older algorithms. Inspired by the success of the results, a large-scale performance analysis of 8 image thresholding algorithms over diverse datasets containing 621 images is carried out. The investigation reveals that the variant of the new algorithm with Tsallis, Renyi and Masi entropies segment images better than others.},
  archive      = {J_PAAA},
  author       = {Mohammadi, Hadi and Gupta, Sargam and Sharma, Shachi},
  doi          = {10.1007/s10044-022-01121-z},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {473-486},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A large-scale performance study of entropy-based image thresholding techniques using new SAD metric},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved swarm-optimization-based filter-wrapper gene
selection from microarray data for gene expression tumor classification.
<em>PAAA</em>, <em>26</em>(2), 455–472. (<a
href="https://doi.org/10.1007/s10044-022-01117-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A typical microarray dataset usually contains thousands of genes, but only a small number of samples. It is in fact that most genes in a DNA microarray dataset are not relevant for classification. Identifying highly discriminating genes, known as biomarkers, is a challenging task for machine learning-based tumor classification. This study focuses on swarm-optimization-based filter-wrapper gene selection. In general, this type of hybrid gene selection consists of two steps: The first step is the filter step, which selects a small top-n percentage of genes and obtains reduced data; then, the second step searches for the optimal gene subset based on a wrapper model from the remaining genes by using a swarm-optimization-based algorithm. However, the second step of the existing swarm-optimization-based filter-wrapper gene selection is to search only from the remaining genes without using the ranking information of the remaining genes. This new study attempts to fill the gap that has been neglected in the area of swarm-optimization-based filter-wrapper gene selection. In this study, population initialization based on ranking criteria (PIRC) is proposed to transform the population initialization of genetic algorithm (GA) and ant colony optimization (ACO), which are called PIRCGA and PIRCACO, respectively. The experiment was carried out on 17 microarray expression datasets, and the two groups of IG-GA vs. IG-PIRCGA and IG-ACO vs. IG-PIRCACO were compared, respectively. The experimental results prove the efficiency of our proposed methods.},
  archive      = {J_PAAA},
  author       = {Ke, Lin and Li, Min and Wang, Lei and Deng, Shaobo and Ye, Jun and Yu, Xiang},
  doi          = {10.1007/s10044-022-01117-9},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {455-472},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Improved swarm-optimization-based filter-wrapper gene selection from microarray data for gene expression tumor classification},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved frequent pattern tree: The child structured
frequent pattern tree CSFP-tree. <em>PAAA</em>, <em>26</em>(2), 437–454.
(<a href="https://doi.org/10.1007/s10044-022-01111-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequent itemsets are itemsets that occur frequently in a dataset. Frequent itemset mining extracts specific itemsets with supports higher than or equal to a minimum support threshold. Many mining methods have been proposed but Apriori and FP-growth are still regarded as two prominent algorithms. The performance of the frequent itemset mining depends on many factors; one of them is searching the nodes while constructing the tree. This paper introduces a new prefix-tree structure called child structured frequent pattern tree (CSFP-tree),  an FP-tree attached with a child search subtree to each node. The experimental results reveal that the CSFP-tree is superior to the FP-tree and its new variations for any kind of datasets.},
  archive      = {J_PAAA},
  author       = {Jamsheela, O. and Raju, G.},
  doi          = {10.1007/s10044-022-01111-1},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {437-454},
  shortjournal = {Pattern Anal. Appl.},
  title        = {An improved frequent pattern tree: The child structured frequent pattern tree CSFP-tree},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Autoencoder-based improved deep learning approach for
schizophrenic EEG signal classification. <em>PAAA</em>, <em>26</em>(2),
403–435. (<a href="https://doi.org/10.1007/s10044-022-01107-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, deep-stacked error minimized extreme learning machine autoencoder (DSEMELMAE) and sine–cosine monarch butterfly optimization-based minimum variance multikernel random vector functional link network are integrated to recognize the schizophrenia electroencephalogram (EEG) data. The unconventional DSEMELMAE network is modelled to derive very unique unsupervised attributes out of the brain signals and employ as inputs to the proposed supervised SCAMBO-MVMKRVFLN classification methodology to recognize accurately by minimizing the mean-square error for identifying schizophrenia data with encouraging accuracy. The DSEMELMAE-SCAMBO-MVMKRVFLN integrated approach is assessed over benchmark EEG databases. The proposed approach is compared with many related RVFLN-based deep learning approaches and many state-of-the-art methods and found to be the outperformer among all the methods, and this approach is highly accepted owing to faster learning speed, better computational simplicity, good generalization capability, outstanding classification accuracy, and small event identification time. The classifier MVMKRVFLN is unique as it classifies the signal with advantages such as the regularization of the randomization, computational economy, less training expenses, the direct inverse along with minimum reconstruction error. The KRVFLN uses multiple kernels such as wavelet, tan hyperbolic and multiquadric to improve the classification performance. The effectiveness of the proposed method is verified by examining three publicly available schizophrenic EEG datasets such as Poland, Kaggle and Moscow datasets and achieved classification accuracies with 99.989%, 95.012% and 96.69%, respectively. The recognition capability, simplicity and robustness of the proposed methodology prove the outstanding overall performances of schizophrenia recognition and diagnosis in comparison with other state-of-the-art approaches and different learning approaches.},
  archive      = {J_PAAA},
  author       = {Parija, Sebamai and Sahani, Mrutyunjaya and Bisoi, Ranjeeta and Dash, P. K.},
  doi          = {10.1007/s10044-022-01107-x},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {403-435},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Autoencoder-based improved deep learning approach for schizophrenic EEG signal classification},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast facial expression recognition using boosted histogram
of oriented gradient (BHOG) features. <em>PAAA</em>, <em>26</em>(1),
381–402. (<a href="https://doi.org/10.1007/s10044-022-01112-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Systems for automatic facial expression recognition (FER) have an enormous need in advanced human-computer interaction (HCI) and human-robot interaction (HRI) applications. Over the years, researchers developed many handcrafted feature descriptors for the FER task. These descriptors delivered good accuracy on publicly available FER benchmark datasets. However, these descriptors generate high dimensional features that increase the computational time of the classifiers. Also, a significant proportion of the features are irrelevant and do not provide additional information for facial expression analysis. Adversely, these redundant features degrade the classification accuracy of the FER algorithm. This study presents an alternate, simple, and efficient scheme for FER in static images using the Boosted Histogram of Oriented Gradient (BHOG) descriptor. The proposed BHOG descriptor employs the AdaBoost feature selection algorithm to select important facial features from the original high-dimensional Histogram of Oriented Gradient (HOG) features. The BHOG descriptor with a reduced feature dimension decreases the computational cost without diminishing the recognition accuracy. The proposed FER pipeline tuned on the optimal values of different hyperparameters achieves competitive recognition accuracy on five benchmark FER datasets, namely CK+, JAFFE, RaFD, TFE, and RAF-DB. Also, the cross-dataset experiments confirm the superior generalization performance of the proposed FER pipeline. Finally, the comparative analysis results with existing FER techniques revealed the effectiveness of the pipeline. The proposed FER scheme is computationally efficient and classifies facial expressions in real time.},
  archive      = {J_PAAA},
  author       = {Saurav, Sumeet and Saini, Ravi and Singh, Sanjay},
  doi          = {10.1007/s10044-022-01112-0},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {381-402},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Fast facial expression recognition using boosted histogram of oriented gradient (BHOG) features},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An intelligent approach using boosted support vector machine
based arithmetic optimization algorithm for accurate detection of plant
leaf disease. <em>PAAA</em>, <em>26</em>(1), 367–379. (<a
href="https://doi.org/10.1007/s10044-022-01086-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leaf disease is considered a serious threat which affects agricultural productivity and ultimately reduces the GDP of the Indian economy. The precise detection and timely analysis of foliar diseases can mitigate the spread of the disease to other parties. However, certain complications such as low precision, high calculation cost, and low recognition speed are raised when detecting leaf diseases. Therefore, to overcome these limitations, we proposed a novel technique called Boosted support vector machine-based Arithmetic optimization algorithm (BSVM-AOA) for accurate detection of plant leaf disease. In this case, image segmentation is done using the vector value active contour model, and feature extraction is done using the greyscale co-occurrence matrix. Furthermore, the performance of the proposed approach is determined by performance parameters such as accuracy, accuracy, recall, specificity, and f-rating. Finally, the comparative analysis is conducted between the different existing techniques and the proposed technique. The comparative results showed that the proposed BSVM-AOA approach is about 98.6% more accurate than other existing techniques.},
  archive      = {J_PAAA},
  author       = {Prabu, M. and Chelliah, Balika J.},
  doi          = {10.1007/s10044-022-01086-z},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {367-379},
  shortjournal = {Pattern Anal. Appl.},
  title        = {An intelligent approach using boosted support vector machine based arithmetic optimization algorithm for accurate detection of plant leaf disease},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SSGNet: Semi-supervised multi-path grid network for
diagnosing melanoma. <em>PAAA</em>, <em>26</em>(1), 357–366. (<a
href="https://doi.org/10.1007/s10044-022-01100-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early diagnosis of melanoma can help patients receive timely treatment, thereby increasing the cure rate of the patient. Dermoscopy is an important way for checking melanoma, and in order to precisely diagnose melanoma in dermoscopy images, based on the advantages of multi-scale method and multi-task collaboration in deep learning, a novel semi-supervised multi-path grid network (SSGNet) was constructed. The SSGNet includes a colorization network and a classification network, and these two networks share the encoder part. The classification network can use the colorized network to regularize its own encoder, thereby improving its ability to extract features. In the construction of the SSGNet, firstly, a layer correction block was designed to extract sufficient image features, which used spatial self-attention mechanism and belongs to a residual structure. Secondly, in order to make full use of the multi-scale information of the image, the features of different inputs under the same scale were densely connected to form a novel grid structure. Thirdly, the classification network and the colorization network share the encoder to perform their own tasks. The form of multi-scale input greatly reduces the effect of the lesion’s size in the image on the result, and the grid structure can enable the SSGNet model to make maximum use of features at different scales. We evaluated our proposed SSGNet on the ISIC 2020 dataset, and experiments showed that the SSGNet achieved better results than existing deep learning models.},
  archive      = {J_PAAA},
  author       = {Dong, Baoping and Fu, Xu and Kang, Xiufeng},
  doi          = {10.1007/s10044-022-01100-4},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {357-366},
  shortjournal = {Pattern Anal. Appl.},
  title        = {SSGNet: Semi-supervised multi-path grid network for diagnosing melanoma},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Correlation-based and content-enhanced network for video
style transfer. <em>PAAA</em>, <em>26</em>(1), 343–355. (<a
href="https://doi.org/10.1007/s10044-022-01106-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artistic style transfer aims to migrate the style pattern from a referenced style image to a given content image, which has achieved significant advances in recent years. However, producing temporally coherent and visually pleasing stylized frames is still challenging. Although existing works have made some effort, they rely on the inefficient optical flow or other cumbersome operations to model spatiotemporal information. In this paper, we propose an arbitrary video style transfer network that can generate consistent results with reasonable style patterns and clear content structure. We adopt multi-channel correlation module to render the input images stably according to cross-domain feature correlation. Meanwhile, Earth Movers’ Distance is used to capture the main characteristics of style images. To maintain the semantic structure during the stylization, we also employ the AdaIN-based skip connections and self-similarity loss, which can further improve the temporal consistency. Qualitative and quantitative experiments have demonstrated the effectiveness of our framework.},
  archive      = {J_PAAA},
  author       = {Lin, Honglin and Wang, Mengmeng and Liu, Yong and Kou, Jiaxin},
  doi          = {10.1007/s10044-022-01106-y},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {343-355},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Correlation-based and content-enhanced network for video style transfer},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Latent block diagonal representation for subspace
clustering. <em>PAAA</em>, <em>26</em>(1), 333–342. (<a
href="https://doi.org/10.1007/s10044-022-01101-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral-type subspace clustering algorithms have attracted wide attention because of their excellent performance displayed in a great deal of applications in machine learning domain. It is critical for spectral-type subspace clustering algorithms to obtain suitable coefficient matrices which could reflect the subspace structures of data sets. In this paper, we propose a latent block diagonal representation clustering algorithm (LBDR). For a data set, the goal of LBDR is to construct a block diagonal and dense coefficient matrix and settle the noise adaptively within the original data set by using dimension reduction technique concurrently. In brief, by seeking the solution of a joint optimization problem, LBDR is capable of finding a suitable coefficient matrix and a projection matrix. Furthermore, a series of experiments conducted on several benchmark databases show that LBDR dominates the related methods.},
  archive      = {J_PAAA},
  author       = {Guo, Jie and Wei, Lai},
  doi          = {10.1007/s10044-022-01101-3},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {333-342},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Latent block diagonal representation for subspace clustering},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Segmentation of retinal blood vessel using generalized
extreme value probability distribution function(pdf)-based matched
filter approach. <em>PAAA</em>, <em>26</em>(1), 307–332. (<a
href="https://doi.org/10.1007/s10044-022-01108-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal vessels’ segmentation is challenging to detect blood vessels for diagnosing diseases such as hypertension, diabetes, and glaucoma. Retinal vessel blood segmentation literature shows that various matched filter approaches are a low profile performance of the kernel template of the intensity of vessel profile. A new matched filter based on the generalized extreme value probability distribution function was proposed to overcome this problem. The proposed retinal blood vessel segmentation approach is divided into stages: preprocessing, generalized extreme value probability distribution function (pdf)-matched filter, and postprocessing. In the preprocessing stage, converting color retinal images into a grayscale retinal image using principle component analysis and enhancing the greyscale retinal image using CLAHE followed by Toggle contrast. In the generalized extreme value, pdf is designed as a new matched filter kernel. The experiment is tested to choose the appropriate parameter values for accurate blood vessel extraction to generate the MFR (matched filtered response) image. In postprocessing, the MFR image of the proposed matched filter is applied on an entropy-based optimal threshold to extract binary-segmented retinal blood vessel image, followed by length filtering to remove the artifact and generate the accurate segment blood vessel. The quantitative performance of the proposed approach is to work on five datasets: DRIVE dataset, STARE dataset, HRF Group-HRF Healthy, HRF- Glaucoma, and HRF-Diabetic Retinopathy to measure in terms of average specificity, average sensitivity, average accuracy, and root-mean-square deviation. The results for the DRIVE database are (98.51%, 65.58%, 95.61%), whereas for STARE database (98.35%, 53.14%, 95.04%). The result of HRF-Healthy database are (98.67%, 39.59%, 93.19%), whereas the HRF-Glaucoma database obtained results (99.20%, 27.13%, 94.28%) and the HRF-Diabetic Retinopathy database obtained results (98.74%, 23.62% 93.56%), respectively.},
  archive      = {J_PAAA},
  author       = {Kumar, K Susheel and Singh, Nagendra Pratap},
  doi          = {10.1007/s10044-022-01108-w},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {307-332},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Segmentation of retinal blood vessel using generalized extreme value probability distribution function(pdf)-based matched filter approach},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Threshold prediction for detecting rare positive samples
using a meta-learner. <em>PAAA</em>, <em>26</em>(1), 289–306. (<a
href="https://doi.org/10.1007/s10044-022-01103-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Threshold-moving is one of the several techniques employed in correcting the bias of binary classifiers towards the majority class. In this approach, the decision threshold is adjusted to detect the minority class at the cost of increased misclassification of the majority. In practice, selecting a good threshold using cross-validation on the training data is not feasible in some problems since there are only a few minority samples. In this study, building a meta-learner for threshold prediction to tackle the threshold estimation problem in the case of rare positive samples is addressed. Novel meta-features are suggested to quantify the imbalance characteristics of the data sets and the patterns among the prediction scores. A random forest-based threshold prediction model is constructed using these meta-features extracted from the score space of external data. The models obtained are then employed to estimate the optimal thresholds for previously unseen datasets. The random forest-based meta-learner that employs implicitly selected subset of the proposed meta-features and encodes information from multiple external sources in the form of different trees is evaluated by using 52 imbalanced datasets. In the first set of experiments, the best-fitting thresholds are computed for SVM and logistic regression classifiers that are trained using the original imbalanced training sets. The experiments are repeated by using ensembles of multiple learners, each trained using a different balanced data set. It is observed that the proposed approach provides better F-score when compared to alternative threshold-moving and balancing techniques.},
  archive      = {J_PAAA},
  author       = {Ghaderi Zefrehi, Hossein and Sheikhi, Ghazaal and Altınçay, Hakan},
  doi          = {10.1007/s10044-022-01103-1},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {289-306},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Threshold prediction for detecting rare positive samples using a meta-learner},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Statistical image watermark decoder by modeling local
NSST-PHFMs magnitudes with morgenstern-type bivariate-generalized
exponential distribution. <em>PAAA</em>, <em>26</em>(1), 255–288. (<a
href="https://doi.org/10.1007/s10044-022-01105-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For any image watermarking system, there are three indispensable and mutually constrained requirements, namely robustness, invisibility, and payload. Recently, to achieve the trade-off among three requirements, statistical watermarking schemes have gained a lot of attention. Despite their powerfulness and effectiveness, most existing statistical image watermarking approaches bear a number of drawbacks, in particular: (i) They all employ directly transform coefficients, which are always fragile to some attacks, for watermark embedding and statistical modeling; (ii) The adopted statistical model cannot capture accurately the marginal distributions of the transform coefficients. Moreover, the significant coefficients dependencies are ignored. To deal with these issues, this paper introduces a new statistical image watermarking method in non-subsampled shearlet transform (NSST)-polar harmonic Fourier moments (PHFMs) magnitude domain, wherein a PDF based on the bivariate-generalized exponential distribution (MTBGED) is employed, in view of the fact that this PDF provides a better statistical match to the empirical PDF of the robust NSST-PHFMs magnitudes of the image. In watermark embedding, we first perform the NSST on the carrier image. We then select the maximum energy subband and divide it into blocks and compute the PHFMs for each block. Finally, we embed watermark in NSST-PHFMs magnitudes using multiplicative approach. In the decoding process, we first analyze the robustness and statistical characteristics of local NSST-PHFMs magnitudes. We then observe that, with a small number of parameters, the new MTBGED model can capture accurately the statistical distributions of the robust NSST-PHFMs magnitudes of the image. Meanwhile, statistical model parameters can be estimated effectively by using the method of logarithmic cumulants (MoLC). Motivated by our modeling results, we finally develop a new statistical image watermark decoder using the MTBGED distribution and maximum likelihood (ML) decision rule. Experimental results on extensive test images demonstrate that the proposed blind watermark decoder provides a performance better than that of most of the state-of-the-art statistical methods and deep learning approaches recently proposed in the literature.},
  archive      = {J_PAAA},
  author       = {Wang, Xiangyang and Lin, Yupan and Shen, Yixuan and Niu, Panpan and Yang, Hongying},
  doi          = {10.1007/s10044-022-01105-z},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {255-288},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Statistical image watermark decoder by modeling local NSST-PHFMs magnitudes with morgenstern-type bivariate-generalized exponential distribution},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Novel color image steganalysis method based on RGB channel
empirical modes to expose stego images with diverse payloads.
<em>PAAA</em>, <em>26</em>(1), 239–253. (<a
href="https://doi.org/10.1007/s10044-022-01102-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of technology in the modern digital world, covert communication of secret information as a payload without instigating visible attention by using steganography emerged as a possible threat. Steganographic methods select either image contents like edges or random regions of image for hiding payload. Steganalysis methods generally concentrate on content-adaptive algorithms of grayscale images but only few works concentrate on color image steganalysis. To address this issue, a generalized steganalyzer that can identify suspicious content created using steganography methods in digital color images is a need of the hour. In this paper, a novel FroFeat feature extracted from decomposed components of three color channels using empirical mode decomposition process is proposed to augment the existing color rich model features to detect stego images created using five content—adaptive and eight non-content—adaptive steganography methods. These empirical mode decomposed components eliminate the image content including edges and pave way to model the subtle stego noise hidden inside stego images. The proposed method is validated by comparing the performance metrics with existing state-of-the-art steganalysis models. Based on the experimental results, the proposed method achieves an average of 0.484 decrease in detection error for low-volume payload detection compared to the existing methods. Also in this paper, mixed generic color image steganalysis is performed to showcase the generalization ability of the proposed steganalysis method.},
  archive      = {J_PAAA},
  author       = {Amrutha, E. and Arivazhagan, S. and Jebarani, W. Sylvia Lilly},
  doi          = {10.1007/s10044-022-01102-2},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {239-253},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Novel color image steganalysis method based on RGB channel empirical modes to expose stego images with diverse payloads},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nonlocal ultrasound image despeckling via improved
statistics and rank constraint. <em>PAAA</em>, <em>26</em>(1), 217–237.
(<a href="https://doi.org/10.1007/s10044-022-01088-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrasound images are often contaminated by speckle noise during the acquisition process, which influences the performance of subsequent applications. Hence, it is necessary to design an effective algorithm for despeckling to obtain a clearer ultrasound image. According to the low-rank property of ultrasound images and the statistical property of similar image patch matrices, a nonlocal low-rank model with an improved data fidelity function (LRDF) is introduced in this paper, which integrates the weighted nuclear norm minimization (WNNM) and an improved data fidelity term. The advantage of WNNM is that it can adaptively assign weights on different singular values to preserve more details in restored images. The fidelity term deduced from log-compressed images fits better to ultrasonic data. We adopt the alternating direction method of multipliers (ADMM) to solve this nonconvex optimization problem. The experimental results on simulated images and real medical ultrasound images verify the reweighting strategy is helpful in this application and demonstrate the excellent performance of the proposed method compared with other five state-of-the-art methods.},
  archive      = {J_PAAA},
  author       = {Yang, Hanmei and Lu, Jian and Luo, Ye and Zhang, Guokai and Zhang, Heng and Liang, Yiwen and Lu, Jianwei},
  doi          = {10.1007/s10044-022-01088-x},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {217-237},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Nonlocal ultrasound image despeckling via improved statistics and rank constraint},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Segmentation of breast lesion in DCE-MRI by multi-level
thresholding using sine cosine algorithm with quasi opposition-based
learning. <em>PAAA</em>, <em>26</em>(1), 201–216. (<a
href="https://doi.org/10.1007/s10044-022-01099-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, the high prevalence of breast cancer in women has increased significantly. Breast cancer diagnosis and detection employing computerized algorithms for feature extraction and segmentation can be aided by a physician’s expertise in the field. To separate breast lesions from other tissue types in Dynamic Contrast-Enhanced Magnetic Resonance Imaging (DCE-MRI) for segmentation and lesion detection in breast DCE-MRI, radiologists think that multi-level thresholding optimization is efficient. In this article, a lesion segmentation method for breast DCE-MRI using the opposition-based Sine Cosine Algorithm (SCA) is proposed. For breast DCE-MRI segmentation utilizing multilevel thresholding, this work provides an upgraded version of the SCA with Quasi Opposition-based Learning (QOBL). SCAQOBL is the name given to the suggested method in this paper. The Anisotropic Diffusion Filter (ADF) is used to de-noise MR images, and subsequently, Intensity Inhomogeneities (IIHs) are corrected in the preprocessing stage. The lesions are then retrieved from the segmented images and located in MR images. On 100 sagittal T2-weighted fat-suppressed DCE-MRI images, the proposed approach is examined. The proposed method is compared to Opposition-based SCA (OBSCA), SCA, Particle Swarm Optimizer (PSO), Slime Mould Algorithm (SMA), Hidden Markov Random Field (HMRF), and Improved Markov Random Field (IMRF) algorithms. The proposed technique achieves a high accuracy of 99.11 percent, sensitivity of 97.78 percent, and Dice Similarity Coefficient (DSC) of 95.42 percent. The analysis of results is conducted using a one-way ANOVA test followed by a Tukey-HSD test, and Multi-Criteria Decision Analysis (MCDA). The proposed strategy surpasses other examined methods in both quantitative and qualitative findings.},
  archive      = {J_PAAA},
  author       = {Si, Tapas and Patra, Dipak Kumar and Mondal, Sukumar and Mukherjee, Prakash},
  doi          = {10.1007/s10044-022-01099-8},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {201-216},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Segmentation of breast lesion in DCE-MRI by multi-level thresholding using sine cosine algorithm with quasi opposition-based learning},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Body landmark detection with an extremely small dataset
using transfer learning. <em>PAAA</em>, <em>26</em>(1), 163–199. (<a
href="https://doi.org/10.1007/s10044-022-01098-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new landmark detection problem on the upper body of a clothed person for tailoring purposes. This is a landmark detection problem unknown in the literature, which is in the same domain as, but different to the ‘fashion’ landmark detection problem where the landmarks are for classifying clothing. An existing ‘attentive fashion network’ (AFN) was trained using 800,000 annotated images of the DeepFashion dataset, with a base network of VGG16 pre-trained on the ImageNet dataset, to provide initial weights. To train a network for ‘body’ landmark detection would require a similar sized dataset. We propose a deep neural network for body landmark detection where the knowledge from an existing network was transferred and trained with an extremely small dataset of just 99 images, annotated with body landmarks. A baseline model was tested where only the fashion landmark branch was used, but retrained for body landmarks. This produced a testing error of 0.068 (normalised mean distance between the predicted landmarks and ground-truth). The error was significantly reduced by adopting the fashion landmark branch and the attention unit of AFN, but substituting the classification branch with a new body landmark detection branch for the proposed Attention-based Fashion-to-Body landmark Network (AFBN). We tested 6 variants of the proposed AFBN model with different convolutional block designs and auto-encoders for enforcing landmark relations. The trained model had a low testing error ranging from 0.022 to 0.028 over these variants. The variant with an increased number of channels and inception units with residual connections, had the best overall performance. Although AFBN and its variants were trained with a limited dataset, the performance exceeds the state-of-the-art attentive fashion network AFN (0.0534). The principle of transfer learning demonstrated here is relevant where labelled domain data are scarce providing a low solution cost of faster training of a deep neural network with a significantly small dataset.},
  archive      = {J_PAAA},
  author       = {Liao, Iman Yi and Hermawan, Eric Savero and Zaman, Munir},
  doi          = {10.1007/s10044-022-01098-9},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {163-199},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Body landmark detection with an extremely small dataset using transfer learning},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Separable robust data hiding in encrypted image based on
continuous quadrant tree and 2Bin n-nary. <em>PAAA</em>, <em>26</em>(1),
123–161. (<a href="https://doi.org/10.1007/s10044-022-01096-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data hiding is a noteworthy research topic in digital technology for years. It can be used for copyright protection, authentication, content-ownership verification, and sending patient information. Focusing on how to improve the security, capacity, visual quality and robustness, a separable robust data hiding in encrypted image based on Continuous Quadrant Tree (CQT) and 2Bin N-nary is proposed. In this work, the definition of CQT, constraints of the sub-tree roots, generation and traversal of CQT are proposed for the first time. To achieve security, matrix traversal, CQT and rotation encryption are combined. When select embedding interval, a histogram preprocessing algorithm based on pixel fluctuation is presented. This paper achieves separable decryption and extraction. Experimental results demonstrate that the capacity has been improved by 50–70% compared with the similar scheme. It not only achieves high security and high visual quality, but also is robust to various attacks.},
  archive      = {J_PAAA},
  author       = {Hui, Shi and Baoyue, Hu and Meihan, Chen and Yanni, Li and Yonggong, Ren},
  doi          = {10.1007/s10044-022-01096-x},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {123-161},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Separable robust data hiding in encrypted image based on continuous quadrant tree and 2Bin N-nary},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning for location prediction on noisy trajectories.
<em>PAAA</em>, <em>26</em>(1), 107–122. (<a
href="https://doi.org/10.1007/s10044-022-01095-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise tracking of a point-target on a nonlinear trajectory is challenging and has applications ranging from traffic analysis to microscopic particle tracking. To solve such a problem, we developed an algorithm which is independent of statistical-probabilistic and mechanical modeling, and free of analytical extrapolation methods. Our main objective was, to predict target’s future location using its previous locations by a deep neural network, trained on a large data set of linear and nonlinear trajectories. To design our data-driven prediction approach, we developed a freely available database of up to second-order algebraic curves uniformly distributed in a given domain. This database could be used for training and testing point-target tracking algorithms. Simulated noisy test sets of trajectories were produced using Gaussian noise for analyzing the forecasting performance and noise sensitivity of our model. Further, the newly designed long short-term memory-based network that uses polar coordinates for its training is capable of predicting the target’s future locations on real-world smooth trajectories. We compared the proposed predictor network to classical and state-of-the-art predictors based on average absolute and relative errors. The experimental results demonstrated that our novel predictor achieved up to 47% improvement on test data sets. The observed area under the noise response curve has improved by up to 11%.},
  archive      = {J_PAAA},
  author       = {Kandhare, Pravinkumar Gangadharrao and Nakhmani, Arie and Sirakov, Nikolay Metodiev},
  doi          = {10.1007/s10044-022-01095-y},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {107-122},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Deep learning for location prediction on noisy trajectories},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel minorization–maximization framework for simultaneous
feature selection and clustering of high-dimensional count data.
<em>PAAA</em>, <em>26</em>(1), 91–106. (<a
href="https://doi.org/10.1007/s10044-022-01094-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Count data are commonly exploited in machine learning and computer vision applications; however, they often suffer from the well-known curse of dimensionality, which declines the performance of clustering algorithms dramatically. Feature selection is a major technique for handling a large number of features, which most are often redundant and noisy. In this paper, we propose a probabilistic approach for count data based on the concept of feature saliency in the context of mixture-based clustering using the generalized Dirichlet multinomial distribution. The saliency of irrelevant features is reduced toward zero by minimizing the message length, which equates to doing feature and model selection simultaneously. It is proved that the developed approach is effective in identifying both the optimal number of clusters and the most important features, and so enhancing clustering performance significantly, using a range of challenging applications including text and image clustering.},
  archive      = {J_PAAA},
  author       = {Zamzami, Nuha and Bouguila, Nizar},
  doi          = {10.1007/s10044-022-01094-z},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {91-106},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A novel minorization–maximization framework for simultaneous feature selection and clustering of high-dimensional count data},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multiple classifiers system with roulette-based feature
subspace selection for one-vs-one scheme. <em>PAAA</em>, <em>26</em>(1),
73–90. (<a href="https://doi.org/10.1007/s10044-022-01089-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification is one of the most important topics in machine learning. However, most of these works focus on the two-class classification (i.e., classification into ‘positive’ and ‘negative’), whereas studies on multi-class classification are far from enough. In this study, we develop a novel methodology of multiple classifier systems (MCS) with one-vs-one (OVO) scheme for the multi-class classification task. First, the multi-class classification problem is divided into as many pairs of easier-to-solve binary sub-problems as possible. Subsequently, an optimal MCS is generated for each sub-problem using a roulette-based feature subspace selection and validation procedure. Finally, to identify the final class of a query sample, an OVO aggregation strategy is employed to obtain the class from the confidence score matrix derived from the MCS. To verify the effectiveness and robustness of the proposed approach, a thorough experimental study is performed. The extracted findings supported by the proper statistical analysis indicate the strength of the proposed method with respect to the state-of-the-art methods for multi-class classification problems.},
  archive      = {J_PAAA},
  author       = {Zhang, Zhong-Liang and Zhang, Chen-Yue and Luo, Xing-Gang and Zhou, Qing},
  doi          = {10.1007/s10044-022-01089-w},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {73-90},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A multiple classifiers system with roulette-based feature subspace selection for one-vs-one scheme},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Edge detection and characterization of digitized images.
<em>PAAA</em>, <em>26</em>(1), 61–72. (<a
href="https://doi.org/10.1007/s10044-022-01097-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a method for determining which of a large set of pixels are inside or on the boundary of a polygon. The method works much quicker than the standard method used for points in general and also provides an ordering of the boundary pixels. Once the edge pixels have been chosen and ordered, we move on to the characterization of the edge. We present a method for characterizing the edge slope of digitized images, which is—to a desired tolerance—invariant to rotation. We demonstrate that this characterization is good enough for subsequent use in edge identification and matching algorithms. This allows us to continue, e.g., to juxtaposing corresponding pieces of a jigsaw puzzle, or “sewing” back together, ripped pieces of material, paper or glass.},
  archive      = {J_PAAA},
  author       = {Naiman, Aaron and Farber, Eliav and Stein, Yossi},
  doi          = {10.1007/s10044-022-01097-w},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {61-72},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Edge detection and characterization of digitized images},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interval regression model adequacy checking and its
application to estimate school dropout in brazilian municipality
educational scenario. <em>PAAA</em>, <em>26</em>(1), 39–59. (<a
href="https://doi.org/10.1007/s10044-022-01093-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval-valued data have been commonly encountered in practice, and Symbolic Data Analysis provides a solution to the statistical treatment of these data. Regression analysis for interval-valued symbolic data is a topic that has been widely investigated in the literature of symbolic data analysis, and several models from different paradigms have been proposed. There are basic regression assumptions, and it is essential to validate them. This paper introduces an approach to check interval regression model adequacy based on residual analysis. Concepts of ordinary and standardized interval residual are presented, and graphical analysis of these residuals is also proposed. To show the usefulness of the proposed approach, an application for estimating school dropout in the scenario of Brazilian municipalities is performed. We observed some outliers from the interval residuals analysis, and interval robust regression models are more suitable for estimating school dropout.},
  archive      = {J_PAAA},
  author       = {do Nascimento, Rafaella L. S. and Fagundes, Roberta A. de A. and de Souza, Renata M. C. R. and Cysneiros, Francisco José A.},
  doi          = {10.1007/s10044-022-01093-0},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {39-59},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Interval regression model adequacy checking and its application to estimate school dropout in brazilian municipality educational scenario},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Earthquake pattern analysis using subsequence time series
clustering. <em>PAAA</em>, <em>26</em>(1), 19–37. (<a
href="https://doi.org/10.1007/s10044-022-01092-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a subsequence time-series clustering algorithm is proposed to identify the strongly coupled aftershocks sequences and Poissonian background activity from earthquake catalogs of active regions. The proposed method considers the inter-event time statistics between the successive pair of events for characterizing the nature of temporal sequences and observing their relevance with earthquake epicenters and magnitude information simultaneously. This approach categorizes the long-earthquake time series into the finite meaningful temporal sequences and then applies the clustering mechanism to the selective sequences. The proposed approach is built on two phases: (1) a Gaussian kernel-based density estimation for finding the optimal subsequence of given earthquake time-series, and (2) inter-event time ( $$\varDelta t$$ ) and distance-based observation of each subsequence for checking the presence of highly correlated aftershock sequences (hot-spots) in it. The existence of aftershocks is determined based on the coefficient of variation (COV). A sliding temporal window on $$\varDelta t$$ with earthquake’s magnitude M is applied on the selective subsequence to filter out the presence of time-correlated events and make the meaningful time stationary Poissonian subsequences. This proposed approach is applied to the regional Sumatra-Andaman (2000–2021) and worldwide ISC-GEM (2000–2016) earthquake catalog. Simulation results indicate that meaningful subsequences (background events) can be modeled by a homogeneous Poisson process after achieving a linear cumulative rate and time-independent $$\lambda$$ in the exponential distribution of $$\varDelta t$$ . The relations $$COV_{a}(T)&gt;COV_{o}(T)&gt; (COV_{b}(T)\approx 1)$$ and $$COV_{a}(d)&gt;COV_{o}(d)&gt;COV_{b}(d)$$ are achieved for both studied catalogs. Comparative analysis justifies the competitive performance of the proposed approach to the state-of-art approaches and recently introduced methods.},
  archive      = {J_PAAA},
  author       = {Vijay, Rahul Kumar and Nanda, Satyasai Jagannath},
  doi          = {10.1007/s10044-022-01092-1},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {19-37},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Earthquake pattern analysis using subsequence time series clustering},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). User grouping and power allocation in NOMA systems: A novel
semi-supervised reinforcement learning-based solution. <em>PAAA</em>,
<em>26</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s10044-022-01091-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a pioneering solution to the problem of user grouping and power allocation in non-orthogonal multiple access (NOMA) systems. The problem is highly pertinent because NOMA is a well-recognized technique for future mobile radio systems. The salient and difficult issues associated with NOMA systems involve the task of grouping users together into the pre-specified time slots, which are augmented with the question of determining how much power should be allocated to the respective users. This problem is, in and of itself, NP-hard. Our solution is the first reported reinforcement learning (RL)-based solution, which attempts to resolve parts of this issue. In particular, we invoke the object migration automaton (OMA) and one of its variants to resolve the grouping in NOMA systems. Furthermore, unlike the solutions reported in the literature, we do not assume prior knowledge of the channels’ distributions, nor of their coefficients, to achieve the grouping/partitioning. Thereafter, we use the consequent groupings to heuristically infer the power allocation. The simulation results that we have obtained confirm that our learning scheme can follow the dynamics of the channel coefficients efficiently, and that the solution is able to resolve the issue dynamically.},
  archive      = {J_PAAA},
  author       = {Omslandseter, Rebekka Olsson and Jiao, Lei and Liu, Yuanwei and John Oommen, B.},
  doi          = {10.1007/s10044-022-01091-2},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Pattern Anal. Appl.},
  title        = {User grouping and power allocation in NOMA systems: A novel semi-supervised reinforcement learning-based solution},
  volume       = {26},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
