<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>KIS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="kis---190">KIS - 190</h2>
<ul>
<li><details>
<summary>
(2023). Concise and interpretable multi-label rule sets.
<em>KIS</em>, <em>65</em>(12), 5657–5694. (<a
href="https://doi.org/10.1007/s10115-023-01930-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label classification is becoming increasingly ubiquitous, but not much attention has been paid to interpretability. In this paper, we develop a multi-label classifier that can be represented as a concise set of simple “if-then” rules, and thus, it offers better interpretability compared to black-box models. Notably, our method is able to find a small set of relevant patterns that lead to accurate multi-label classification, while existing rule-based classifiers are myopic and wasteful in searching rules, requiring a large number of rules to achieve high accuracy. In particular, we formulate the problem of choosing multi-label rules to maximize a target function, which considers not only discrimination ability with respect to labels, but also diversity. Accounting for diversity helps to avoid redundancy, and thus, to control the number of rules in the solution set. To tackle the said maximization problem, we propose a 2-approximation algorithm, which circumvents the exponential-size search space of rules using a novel technique to sample highly discriminative and diverse rules. In addition to our theoretical analysis, we provide a thorough experimental evaluation and a case study, which indicate that our approach offers a trade-off between predictive performance and interpretability that is unmatched in previous work.},
  archive      = {J_KIS},
  author       = {Ciaperoni, Martino and Xiao, Han and Gionis, Aristides},
  doi          = {10.1007/s10115-023-01930-6},
  journal      = {Knowledge and Information Systems},
  month        = {12},
  number       = {12},
  pages        = {5657-5694},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Concise and interpretable multi-label rule sets},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Community-aware graph embedding via multi-level attribute
integration. <em>KIS</em>, <em>65</em>(12), 5635–5655. (<a
href="https://doi.org/10.1007/s10115-023-01928-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph embedding has been extensively studied in the literature and is widely used in various applications such as drug discovery, social network analysis, and natural language processing. However, existing approaches ignore the attribute information or are limited to learning graph representations at certain graph scales without considering the layer-wise community structure to improve embedding learning. To tackle these problems, we propose a Community-aware graph Embedding method with Multi-level attribute integration, a novel attributed graph embedding framework. It first coarsens the topological structure and attributes information alternating in a parallel strategy. Then in each coarsened layer, a self-attention mechanism is adopted to naturally integrate node attributes and obtain node embedding representations. Next, we introduce neighbor propagation at the same layer, cross-layer community propagation, and consider community information of nodes in the coarsening process to modify the embedding representation. Compared with the previous graph embedding methods, experimental results in different application scenarios on real-world datasets demonstrate the effectiveness of our proposed algorithm.},
  archive      = {J_KIS},
  author       = {Li, Yafang and Wang, Wenbo and Wei, Jianwen and Zu, Baokai},
  doi          = {10.1007/s10115-023-01928-0},
  journal      = {Knowledge and Information Systems},
  month        = {12},
  number       = {12},
  pages        = {5635-5655},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Community-aware graph embedding via multi-level attribute integration},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dimensionality selection for hyperbolic embeddings using
decomposed normalized maximum likelihood code-length. <em>KIS</em>,
<em>65</em>(12), 5601–5634. (<a
href="https://doi.org/10.1007/s10115-023-01934-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph embedding methods are effective techniques for representing nodes and their relations in a continuous space. Specifically, the hyperbolic space is more effective than the Euclidean space for embedding graphs with tree-like structures. Thus, it is critical how to select the best dimensionality for the hyperbolic space in which a graph is embedded. This is because we cannot distinguish nodes well with dimensionality that is considerably low, whereas the embedded relations are affected by irregularities in data with excessively high dimensionality. We consider this problem from the viewpoint of statistical model selection for latent variable models. Thereafter, we propose a novel methodology for dimensionality selection based on the minimum description length principle. We aim to introduce a latent variable modeling of hyperbolic embeddings and apply the decomposed normalized maximum likelihood code-length to latent variable model selection. We empirically demonstrated the effectiveness of our method using both synthetic and real-world datasets.},
  archive      = {J_KIS},
  author       = {Yuki, Ryo and Ike, Yuichi and Yamanishi, Kenji},
  doi          = {10.1007/s10115-023-01934-2},
  journal      = {Knowledge and Information Systems},
  month        = {12},
  number       = {12},
  pages        = {5601-5634},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Dimensionality selection for hyperbolic embeddings using decomposed normalized maximum likelihood code-length},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A smart alzheimer’s patient monitoring system with
IoT-assisted technology through enhanced deep learning approach.
<em>KIS</em>, <em>65</em>(12), 5561–5599. (<a
href="https://doi.org/10.1007/s10115-023-01890-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Earlier detection of Alzheimer’s disease is more significant for improving the quality of the patient’s life. This aspect may reduce the fatality rate among the population and also maximize the average life expectancy. Thus, this paper introduces a new Alzheimer&#39;s prediction model using IoT and deep structured architectures. A new smart Alzheimer’s patient monitoring system is developed by processing healthcare data using IoT devices. Initially, Alzheimer’s patients are detected from the set of patients using “enhanced deep residual network–long short-term memory (DRN-LSTM).” Here, the detection process is done with the data associated with the patients. The optimal feature selection phase and enhanced deep convolutional network (DCN) and deep residual network (DRN)-based detection are accomplished by parameter-improved horse herd optimization algorithm (PI-HHO). The monitored data involve audio, data, and video from the sensors based on the location and movements of patients. Next, the gathered data are forwarded to the optimal feature selection with the same algorithm and predicted the abnormalities through enhanced DNN + LSTM using PI-HHO. Thirdly, the abnormal patients are alerted to the nearby hospital for appropriate treatment and monitoring. All through the result evaluation, the accuracy and precision rate of the recommended Alzheimer’s patient monitoring system attain 98% and 97%. Thus, this smart patient prediction model ensures the high-quality results in terms of standard performance metrics while evaluating with other algorithms.},
  archive      = {J_KIS},
  author       = {Arunachalam, Rajesh and Sunitha, Gurram and Shukla, Surendra Kumar and pandey, Surya Nath and Urooj, Shabana and Rawat, Seema},
  doi          = {10.1007/s10115-023-01890-x},
  journal      = {Knowledge and Information Systems},
  month        = {12},
  number       = {12},
  pages        = {5561-5599},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A smart alzheimer’s patient monitoring system with IoT-assisted technology through enhanced deep learning approach},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recommender systems in cybersecurity. <em>KIS</em>,
<em>65</em>(12), 5523–5559. (<a
href="https://doi.org/10.1007/s10115-023-01906-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growth of CyberTerrorism, enterprises worldwide have been struggling to stop intruders from obtaining private data. Despite the efforts made by Cybersecurity experts, the shortage of skillful security teams and the usage of intelligent attacks have slowed down the enhancement of defense mechanisms. Furthermore, the pandemic in 2020 forced organizations to work in remote environments with poor security, leading to increased cyberattacks. One possible solution for these problems is the implementation of Recommender Systems to assist Cybersecurity human operators. Our goal is to survey the application of Recommender Systems in Cybersecurity architectures. These decision-support tools deal with information overload through filtering and prioritization methods, allowing businesses to increase revenue, achieve better user satisfaction, and make faster and more efficient decisions in various domains (e-commerce, healthcare, finance, and other fields). Several reports demonstrate the potential of using these recommendation structures to enhance the detection and prevention of cyberattacks and aid Cybersecurity experts in treating client incidents. This survey discusses several studies where Recommender Systems are implemented in Cybersecurity with encouraging results. One promising direction explored by the community is using Recommender Systems as attack predictors and navigation assistance tools. As contributions, we show the recent efforts in this area and summarize them in a table. Furthermore, we provide an in-depth analysis of potential research lines. For example, the inclusion of Recommender Systems in security information event management systems and security orchestration, automation, and response applications could decrease their complexity and information overload.},
  archive      = {J_KIS},
  author       = {Ferreira, Leonardo and Silva, Daniel Castro and Itzazelaia, Mikel Uriarte},
  doi          = {10.1007/s10115-023-01906-6},
  journal      = {Knowledge and Information Systems},
  month        = {12},
  number       = {12},
  pages        = {5523-5559},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Recommender systems in cybersecurity},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ontology extension with NLP-based concept extraction for
domain experts in catalytic sciences. <em>KIS</em>, <em>65</em>(12),
5503–5522. (<a
href="https://doi.org/10.1007/s10115-023-01919-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ontologies store semantic knowledge in a machine-readable way and represent domain knowledge in controlled vocabulary. In this work, a workflow is set up to derive classes from a text dataset using natural language processing (NLP) methods. Furthermore, ontologies and thesauri are browsed for those classes and corresponding existing textual definitions are extracted. A base ontology is selected to be extended with knowledge from catalysis science, while word similarity is used to introduce new classes to the ontology based on the class candidates. Relations are introduced to automatically reference them to already existing classes in the selected ontology. The workflow is conducted for a text dataset related to catalysis research on methanation of CO $$_2$$ and seven semantic artifacts assisting ontology extension by domain experts. Undefined concepts and unstructured relations can be more easily introduced automatically into existing ontologies. Domain experts can then revise the resulting extended ontology by choosing the best fitting definition of a class and specifying suggested relations between concepts of catalyst research. A structured extension of ontologies supported by NLP methods is made possible to facilitate a Findable, Accessible, Interoperable, Reusable (FAIR) data management workflow.},
  archive      = {J_KIS},
  author       = {Behr, Alexander S. and Völkenrath, Marc and Kockmann, Norbert},
  doi          = {10.1007/s10115-023-01919-1},
  journal      = {Knowledge and Information Systems},
  month        = {12},
  number       = {12},
  pages        = {5503-5522},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Ontology extension with NLP-based concept extraction for domain experts in catalytic sciences},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Node classification across networks via category-level
domain adaptive network embedding. <em>KIS</em>, <em>65</em>(12),
5479–5502. (<a
href="https://doi.org/10.1007/s10115-023-01942-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the performance of classifying nodes on unlabeled or scarcely-labeled networks, the task of node classification across networks is proposed for transferring knowledge from similar networks with rich labels. As data distribution shift exists across networks, domain adaptive network embedding is proposed to overcome such challenge by learning network-invariant and discriminative node embeddings, in which domain adaptation technique is applied to network embedding for reducing domain discrepancy. However, existing works merely discuss category-level domain discrepancy which is crucial to better adaptation and classification. In this paper, we propose category-level domain adaptive network embedding. The key idea is minimizing intra-class domain discrepancy and maximizing inter-class domain discrepancy between source and target networks simultaneously. To further enhance classification performance on target network, we reduce embedding variation inside each class and enlarge it between different classes. Graph attention network is adopted for learning network embeddings. In addition, a novel pseudo-labeling strategy for target network is developed to better compute category-level information. Theoretical analysis guarantees the effectiveness of our model. Furthermore, extensive experiments on real-world datasets show that our model achieves the state-of-art performance, in particular, outperforming existing domain adaptive network embedding models by up to 32%.},
  archive      = {J_KIS},
  author       = {Shi, Boshen and Wang, Yongqing and Shao, Jiangli and Shen, Huawei and Li, Yangyang and Cheng, Xueqi},
  doi          = {10.1007/s10115-023-01942-2},
  journal      = {Knowledge and Information Systems},
  month        = {12},
  number       = {12},
  pages        = {5479-5502},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Node classification across networks via category-level domain adaptive network embedding},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel quasi-oppositional chaotic student psychology-based
optimization algorithm for deciphering global complex optimization
problems. <em>KIS</em>, <em>65</em>(12), 5387–5477. (<a
href="https://doi.org/10.1007/s10115-023-01931-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research work projects a novel quasi-oppositional chaotic student psychology-based optimization (SPBO) (QOCSPBO) algorithm for solving global optimization problems. To tackle the identified flaws of the standard SPBO, the proffered QOCSPBO algorithm combines two search strategies within the standard SPBO framework. The obtained outcomes exhibit that the proposed QOCSPBO algorithm outperforms SPBO and recently published algorithms in optimizing a set of well-known benchmark test functions. The projected QOCSPBO attains the optimal site and size of distributed generation and shunt capacitors in two radial distribution systems contemplating different types load models at three load levels. The obtained results prove that the recommended method can be highly suitable in solving real-time power system optimization problems with constrained and unknown search space.},
  archive      = {J_KIS},
  author       = {Balu, Korra and Mukherjee, V.},
  doi          = {10.1007/s10115-023-01931-5},
  journal      = {Knowledge and Information Systems},
  month        = {12},
  number       = {12},
  pages        = {5387-5477},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A novel quasi-oppositional chaotic student psychology-based optimization algorithm for deciphering global complex optimization problems},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Entropic principal component analysis using cauchy–schwarz
divergence. <em>KIS</em>, <em>65</em>(12), 5375–5385. (<a
href="https://doi.org/10.1007/s10115-023-01940-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern pattern recognition applications are frequently associated with high-dimensional datasets. In the last decades, different approaches have been proposed to address the curse of dimensionality phenomena present in this kind of data. Principal component analysis is a classic method that even today is widely used for this purpose. However, its procedure is based in the covariance matrix, which is built by the feature vectors scalar product in a point-wise fashion. This makes it very sensible to noise and outliers. This work presents a patch-based mapping to an entropic space. Given a data sample neighborhood, each feature value set is mapped to an univariate Gaussian distribution described by its parameters. Then, each scalar coordinate of a data sample is replaced by the parameter tuple that describes each feature. The difference between two data sample vectors in the entropic space is defined as the vector where each scalar coordinate is given by the stochastic divergence between two probability distributions. The covariance matrix is still defined by the scalar product between the difference vector of a data sample and the average sample, so it can be used with transparency in the original PCA algorithm. This patch mapping in the entropic space aims to mitigate the effect of noise and outliers. Experiments adopting the Cauchy–Schwarz divergence show that the new framework can outperform several existing dimensionality reduction algorithms in cluster analysis tasks in multiple real datasets.},
  archive      = {J_KIS},
  author       = {Nakao, Eduardo K. and Levada, Alexandre L. M.},
  doi          = {10.1007/s10115-023-01940-4},
  journal      = {Knowledge and Information Systems},
  month        = {12},
  number       = {12},
  pages        = {5375-5385},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Entropic principal component analysis using Cauchy–Schwarz divergence},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A representation learning model based on stochastic
perturbation and homophily constraint. <em>KIS</em>, <em>65</em>(12),
5353–5373. (<a
href="https://doi.org/10.1007/s10115-023-01941-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The network representation learning task of fusing node multi-dimensional classification information aims to effectively combine node multi-dimensional classification information and network structure information for representation learning, thereby improving the performance of network representation. However, the existing methods only consider multi-dimensional classification information as priori features, which assists the representation learning of the network structure information, lacks the coping mechanism in the case of missing data, and have low robustness in the case of incomplete information. To address these issues, in this paper, we propose a representation learning model based on stochastic perturbation and homophily constraint, called IMCIN. On the one hand, the data transformation is carried out through the random perturbation strategy to improve the adaptability of the model to incomplete information. On the other hand, in the process of learning fusion representation vectors, an attribute similarity retention method based on the principle of homogeneity is designed to further mine the effective semantic information in the incomplete information. Experiments show that our method can effectively deal with the problem of incomplete information and improve the performance of node classification and link prediction tasks.},
  archive      = {J_KIS},
  author       = {Li, Qi and Jiang, Ming},
  doi          = {10.1007/s10115-023-01941-3},
  journal      = {Knowledge and Information Systems},
  month        = {12},
  number       = {12},
  pages        = {5353-5373},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A representation learning model based on stochastic perturbation and homophily constraint},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fuzzy clustering analysis for the loan audit short texts.
<em>KIS</em>, <em>65</em>(12), 5331–5351. (<a
href="https://doi.org/10.1007/s10115-023-01943-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In China, post-loan management is usually executed in the form of a visit survey conducted by a credit manager. Through a quarterly visit survey, a large number of loan audit short texts, which contain valuable information for evaluating the credit status of small and micro-enterprises, are collected. However, methods for analysing this type of short text remain lacking. This study proposes a method for processing short loan audit texts called fuzzy clustering analysis (FCA). This method first transforms short texts into a fuzzy matrix through lexical analysis; it then calculates the similarity between records based on each fuzzy matrix and constructs an association graph with this similarity. Finally, it uses a prism minimum spanning tree to extract clusters based on different $${\alpha }$$ cuts. Experiments using actual data from a commercial bank in China revealed that the FCA yields suitable clustering results when handling loan audit briefs. Moreover, it exhibited superior performance compared to BIRCH, k-means, and fuzzy c-means.},
  archive      = {J_KIS},
  author       = {Han, Lu and Liu, Zhidong and Qiang, Jipeng and Zhang, Zhuangyi},
  doi          = {10.1007/s10115-023-01943-1},
  journal      = {Knowledge and Information Systems},
  month        = {12},
  number       = {12},
  pages        = {5331-5351},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Fuzzy clustering analysis for the loan audit short texts},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EcoLight+: A novel multi-modal data fusion for enhanced
eco-friendly traffic signal control driven by urban traffic noise
prediction. <em>KIS</em>, <em>65</em>(12), 5309–5329. (<a
href="https://doi.org/10.1007/s10115-023-01938-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban traffic congestion is of utmost importance for modern societies due to population and economic growth. Thus, it contributes to environmental problems like increasing greenhouse gas emissions and noise pollution. Improved traffic flow in urban networks relies heavily on traffic signal control. Hence, optimizing cycle timing at many intersections is paramount to reducing congestion and increasing sustainability. This paper introduces an alternative to conventional traffic signal control, EcoLight+, which incorporates future noise predictions with the deep dueling Q-network reinforcement Learning algorithm to reduce noise levels, CO $${_{2}}$$ emissions, and fuel consumption. An innovative data fusion approach is also proposed to improve our LSTM-based noise prediction model by integrating heterogeneous data from different sources. Our proposed solution allows the system to achieve higher efficiency than its competitors based on real-world data from Tallinn, Estonia.},
  archive      = {J_KIS},
  author       = {Ounoughi, Chahinez and Ounoughi, Doua and Ben Yahia, Sadok},
  doi          = {10.1007/s10115-023-01938-y},
  journal      = {Knowledge and Information Systems},
  month        = {12},
  number       = {12},
  pages        = {5309-5329},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {EcoLight+: A novel multi-modal data fusion for enhanced eco-friendly traffic signal control driven by urban traffic noise prediction},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Drug-CoV: A drug-origin knowledge graph discovering drug
repurposing targeting COVID-19. <em>KIS</em>, <em>65</em>(12),
5289–5308. (<a
href="https://doi.org/10.1007/s10115-023-01923-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug repurposing is a technique for probing new usages of existing medicines, but its traditional methods, such as computational approaches, can be time-consuming and laborious. Recently, knowledge graphs (KGs) have emerged as a powerful approach for graph-based representation in drug repurposing, encoding entities and relations to predict new connections and facilitate drug discovery. As COVID-19 has become a major public health concern, it is critical to establish an appropriate COVID-19 KG for drug repurposing to combat the spread of the virus. However, most publicly available COVID-19 KGs lack support for multi-relations and comprehensive entity types. Moreover, none of them originates from COVID-19-related drugs, making it challenging to identify effective treatments. To tackle these issues, we developed Drug-CoV, a drug-origin and multi-relational COVID-19 KG. We evaluated the quality of Drug-CoV by performing link prediction and comparing the results to another publicly available COVID-19 KG. Our results showed that Drug-CoV outperformed the comparing KG in predicting new links between entities. Overall, Drug-CoV represents a valuable resource for COVID-19 drug repurposing efforts and demonstrates the potential of KGs for facilitating drug discovery.},
  archive      = {J_KIS},
  author       = {Li, Sirui and Wong, Kok Wai and Zhu, Dengya and Fung, Chun Che},
  doi          = {10.1007/s10115-023-01923-5},
  journal      = {Knowledge and Information Systems},
  month        = {12},
  number       = {12},
  pages        = {5289-5308},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Drug-CoV: A drug-origin knowledge graph discovering drug repurposing targeting COVID-19},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fuzzy twin support vector machine based on affinity and
class probability for class imbalance learning. <em>KIS</em>,
<em>65</em>(12), 5259–5288. (<a
href="https://doi.org/10.1007/s10115-023-01904-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently a robust and efficient classifier termed affinity and class probability-based fuzzy support vector machine (ACFSVM) was proposed to address the binary class imbalance and noisy data classification problems. Despite the excellent generalization ability of ACFSVM, there is a scope to improve its classification ability. To enhance the classification performance of ACFSVM, this work suggests a novel fuzzy twin support vector machine based on affinity and class probability (ACFTSVM). In ACFTSVM, regularization terms are added to the primal problems which diminish the negative influence of noise. The affinity (AF) of the majority (MJ) class datapoints is measured using the support vector data description model trained in kernel space using only the MJ class training samples. The k-nearest neighbour method is used to estimate the class probability (CP) of the MJ class datapoints in the same kernel space as before to decrease the potential of noises. Lower CP samples are prone to noise, and their contribution to learning appears to be harmed by their low memberships, which are calculated by adding the AFs and the CPs. ACFTSVM, like ACFSVM, will give preference to MJ class datapoints with higher AFs and CPs, while minimizing the influence of minority class samples with lower AFs and CPs. As a result, the decision boundary is skewed towards the MJ class. Five artificially imbalanced datasets and a few notable real-world datasets are used in numerical simulations.},
  archive      = {J_KIS},
  author       = {Hazarika, Barenya Bikash and Gupta, Deepak and Borah, Parashjyoti},
  doi          = {10.1007/s10115-023-01904-8},
  journal      = {Knowledge and Information Systems},
  month        = {12},
  number       = {12},
  pages        = {5259-5288},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Fuzzy twin support vector machine based on affinity and class probability for class imbalance learning},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adversarial-example generation method for chinese
sentiment tendency classification based on audiovisual confusion and
contextual association. <em>KIS</em>, <em>65</em>(12), 5231–5258. (<a
href="https://doi.org/10.1007/s10115-023-01946-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generation methods of adversarial examples have been more explored on English data, while the research papers on Chinese adversarial examples are very limited. At the same time, the existing Chinese adversarial attack methods are often characterized by a single form of generation and not rich enough expression. And the attack effect of these methods still has room for improvement. Therefore, this paper proposes SentiAttack, a method to introduce 6 perturbations from two perspectives, according to the characteristics of Chinese. The 6 types of perturbation were obtained from both audiovisual deception (words with similar sound, Chinese characters with similar form, horizontal splitting of Chinese character and reverse order of adjacent Chinese characters within word) and contextualized generation (WoBERT-MLM (Su in Wobert: Word-based chinese bert model - zhuiyiai. Technical report, 2020. https://github.com/ZhuiyiTechnology/WoBERT ) word generation and LongLM (Guan et al. in Trans Assoc Comput Linguist 10:434–451, 2022. https://doi.org/10.1162/tacl_a_00469 ) sentence-piece generation), respectively. In addition, a “fluency” metric is added to further measure the quality of the adversarial examples. We conducted experiments on five datasets (CH-SIMS 3, ChnSentiCorp, online shopping, waimai, and weibo8). With the effective constraints of semantic similarity, expression fluency and perturbation, we obtained 74.40%, 49.10%, 42.90%, 39.90% and 66.20% accuracy decrease, respectively.},
  archive      = {J_KIS},
  author       = {Ou, Hongxu and Yu, Long and Tian, Shengwei and Chen, Xin and Shi, Chen and Wang, Bo and Zhou, Tiejun},
  doi          = {10.1007/s10115-023-01946-y},
  journal      = {Knowledge and Information Systems},
  month        = {12},
  number       = {12},
  pages        = {5231-5258},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {An adversarial-example generation method for chinese sentiment tendency classification based on audiovisual confusion and contextual association},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributional constraint discovery for intelligent
auditing. <em>KIS</em>, <em>65</em>(12), 5195–5229. (<a
href="https://doi.org/10.1007/s10115-023-01929-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constraint discovery in relational databases aims to find constraints that express dependency relationships among a set of attributes and has witnessed remarkable success in the applications of data cleaning, detecting data errors, and enhancing police and security operations. In this paper, we propose a new type of constraint, called distributional constraints (DCs), which leverages the attribute value distribution feature for intelligent auditing and security analysis. The constraint, which specifies the range of attribute values that most data follow, enables financial auditors, law enforcement, and security analysts to identify data with anomalous distributions and explain the reasons for such data anomalies. In the context of police and security applications, distributional constraints can help detect potential criminal activities, fraud, and other security threats by identifying unusual patterns in data. To efficiently discover distributional constraints, we propose an inference system to find the minimum coverage of a set of DCs. The efficient optimization technique BitVector indexing is also proposed to further speed up the distributional constraint discovery. We conduct experiments on 12 real datasets such as medical bills and credit card statements to validate the efficiency and effectiveness of our solution. We show the performance of the discovery DCs and the effectiveness of using DCs for detecting abnormal data in different audit datasets.},
  archive      = {J_KIS},
  author       = {Hu, Wentao and Jiang, Dawei and Wu, Sai and Chen, Ke and Chen, Gang},
  doi          = {10.1007/s10115-023-01929-z},
  journal      = {Knowledge and Information Systems},
  month        = {12},
  number       = {12},
  pages        = {5195-5229},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Distributional constraint discovery for intelligent auditing},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Temporal word embedding with predictive capability.
<em>KIS</em>, <em>65</em>(12), 5159–5194. (<a
href="https://doi.org/10.1007/s10115-023-01920-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantics in natural language processing is largely dependent on contextual relationships between words and entities in a document collection. The context of a word may evolve. For example, the word “apple” currently has two contexts—a fruit and a technology company. The changes in the context of words or entities in text data such as scientific publications and news articles can help us understand the evolution of innovation or events of interest. In this work, we present a new diffusion-based temporal word embedding model that can capture short- and long-term changes in the semantics of entities in different domains. Our model captures how the context of each entity shifts over time. Existing temporal word embeddings capture semantic evolution at a discrete/granular level, aiming to study how a language developed over a long period. Unlike existing temporal embedding methods, our approach provides temporally smooth embeddings, facilitating prediction and trend analysis better than those of existing models. Extensive evaluations demonstrate that our proposed temporal embedding model performs better in sense-making and predicting relationships between words and entities in the future compared to other existing models.},
  archive      = {J_KIS},
  author       = {Farhan, Ahnaf and Camacho Barranco, Roberto and Akbar, Monika and Hossain, M. Shahriar},
  doi          = {10.1007/s10115-023-01920-8},
  journal      = {Knowledge and Information Systems},
  month        = {12},
  number       = {12},
  pages        = {5159-5194},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Temporal word embedding with predictive capability},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comment on “new cosine similarity and distance measures for
fermatean fuzzy sets and TOPSIS approach.” <em>KIS</em>,
<em>65</em>(12), 5151–5157. (<a
href="https://doi.org/10.1007/s10115-023-01926-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the above paper, Kirisci (Knowl Inform Syst 65:855–868, 2023) proposed a new cosine similarity and distance measures for Fermatean fuzzy sets. In this comment, we point out some mistakes in the definitions. In parallel, in the light of the problem mentioned in the paper, we propose two improved cosine similarity measures that are superior and capable of solving the problem.},
  archive      = {J_KIS},
  author       = {Liu, Zhe and Huang, Haojian},
  doi          = {10.1007/s10115-023-01926-2},
  journal      = {Knowledge and Information Systems},
  month        = {12},
  number       = {12},
  pages        = {5151-5157},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Comment on “New cosine similarity and distance measures for fermatean fuzzy sets and TOPSIS approach”},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Eight years of AutoML: Categorisation, review and trends.
<em>KIS</em>, <em>65</em>(12), 5097–5149. (<a
href="https://doi.org/10.1007/s10115-023-01935-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge extraction through machine learning techniques has been successfully applied in a large number of application domains. However, apart from the required technical knowledge and background in the application domain, it usually involves a number of time-consuming and repetitive steps. Automated machine learning (AutoML) emerged in 2014 as an attempt to mitigate these issues, making machine learning methods more practicable to both data scientists and domain experts. AutoML is a broad area encompassing a wide range of approaches aimed at addressing a diversity of tasks over the different phases of the knowledge discovery process being automated with specific techniques. To provide a big picture of the whole area, we have conducted a systematic literature review based on a proposed taxonomy that permits categorising 447 primary studies selected from a search of 31,048 papers. This review performs an extensive and rigorous analysis of the AutoML field, scrutinising how the primary studies have addressed the dimensions of the taxonomy, and identifying any gaps that remain unexplored as well as potential future trends. The analysis of these studies has yielded some intriguing findings. For instance, we have observed a significant growth in the number of publications since 2018. Additionally, it is noteworthy that the algorithm selection problem has gradually been superseded by the challenge of workflow composition, which automates more than one phase of the knowledge discovery process simultaneously. Of all the tasks in AutoML, the growth of neural architecture search is particularly noticeable.},
  archive      = {J_KIS},
  author       = {Barbudo, Rafael and Ventura, Sebastián and Romero, José Raúl},
  doi          = {10.1007/s10115-023-01935-1},
  journal      = {Knowledge and Information Systems},
  month        = {12},
  number       = {12},
  pages        = {5097-5149},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Eight years of AutoML: Categorisation, review and trends},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Federated search techniques: An overview of the trends and
state of the art. <em>KIS</em>, <em>65</em>(12), 5065–5095. (<a
href="https://doi.org/10.1007/s10115-023-01922-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional search engines, such as Bing, Baidu, and Google, offer a convenient way for users to seek information on the web. However, with all the benefits they provide, one major limitation is that a sizable portion of the information sources on the web may not be available due to commercial or proprietary reasons. Federated search solves this problem by providing a single user interface through which multiple independent resources can be searched and their results are combined for end users. Up to now, federated search has become a well-established research area, with many systems developed and algorithms proposed to deal with three major issues: resource description, resource selection, and results merging. This paper reviews state-of-the-art federated search techniques developed over the past three decades, with more attention to recent achievement. Both resource selection and result merging methods are categorized into three types, heuristic, machine learning-based, and other methods. Apart from the three major issues above-mentioned, we also discuss systems and prototypes developed, and datasets used for federated search experiments. Some other related issues including retrieval evaluation, aggregated search, metasearch, supporting personalization in federated search, are also covered. Finally, we conclude by discussing some directions for future research.},
  archive      = {J_KIS},
  author       = {Garba, Adamu and Wu, Shengli and Khalid, Shah},
  doi          = {10.1007/s10115-023-01922-6},
  journal      = {Knowledge and Information Systems},
  month        = {12},
  number       = {12},
  pages        = {5065-5095},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Federated search techniques: An overview of the trends and state of the art},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient deep learning framework for occlusion face
prediction system. <em>KIS</em>, <em>65</em>(11), 5043–5063. (<a
href="https://doi.org/10.1007/s10115-023-01896-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generally, face detection or prediction and tracking technology is the most critical research direction for target tracking and identifying criminal activities. However, crime detection in a surveillance system is complex to use. Moreover, preprocessing layer takes more time and needs to get pure-quality data. This research designed a novel, Crow Search-based Recurrent Neural Scheme to enhance the prediction performance of occlusion faces and improve classification results. Thus, the developed model was implemented in the Python tool, and the online COFW dataset was collected and trained for the system. Furthermore, enhance the performance of prediction accuracy and classify the person accurately by using Crow search fitness. Thus, the designed optimization technique tracks and searches the person&#39;s location and predicts the occlusion faces using labels. Finally, developed model experimental outcomes show better performance in predicting the occlusion faces, and the attained results are validated with prevailing models. The designed model gained 98.75% accuracy, 99% recall, and 98.56% precision for predicting occlusion faces. It shows the efficiency of the developed model and attains better performance while comparing other models.},
  archive      = {J_KIS},
  author       = {Naveen Kumar Polisetty, S. and Sivaprakasam, T. and Sreeram, Indraneel},
  doi          = {10.1007/s10115-023-01896-5},
  journal      = {Knowledge and Information Systems},
  month        = {11},
  number       = {11},
  pages        = {5043-5063},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {An efficient deep learning framework for occlusion face prediction system},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing multiple-choice question answering through
sequential fine-tuning and curriculum learning strategies. <em>KIS</em>,
<em>65</em>(11), 5025–5042. (<a
href="https://doi.org/10.1007/s10115-023-01918-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the transformer-based pre-trained language models, multiple-choice question answering (MCQA) systems can reach a particular level of performance. This study focuses on inheriting the benefits of contextualized language representations acquired by language models and transferring and sharing information among MCQA datasets. In this work, a method called multi-stage-fine-tuning considering the Curriculum Learning strategy is presented, which proposes sequencing not training samples, but the source datasets in a meaningful order, not randomized. Consequently, an extensive series of experiments over various MCQA datasets shows that the proposed method reaches remarkable performance enhancements than classical fine-tuning over picked baselines T5 and RoBERTa. Moreover, the experiments are conducted on merged source datasets, and the proposed method achieves improved performance. This study shows that increasing the number of source datasets and even using some small-scale datasets helps build well-generalized models. Moreover, having a higher similarity between source datasets and target also plays a vital role in the performance.},
  archive      = {J_KIS},
  author       = {Yigit, Gulsum and Amasyali, Mehmet Fatih},
  doi          = {10.1007/s10115-023-01918-2},
  journal      = {Knowledge and Information Systems},
  month        = {11},
  number       = {11},
  pages        = {5025-5042},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Enhancing multiple-choice question answering through sequential fine-tuning and curriculum learning strategies},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GWNN-HF: Beyond assortativity in graph wavelet neural
network. <em>KIS</em>, <em>65</em>(11), 5005–5024. (<a
href="https://doi.org/10.1007/s10115-023-01900-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph wavelet neural network exerts a powerful learning ability in assortative networks where most of the adjacent nodes have the same label as the target node. However, it does not perform well in disassortative networks where most of the adjacent nodes have different label than the target node. So graph wavelet neural network cannot extract the most useful information based on different types of networks. On the one hand, graph wavelet neural network is not able to extract the similarity information of the same labeled neighbor nodes and the difference information of different labeled neighbor nodes in a flexible way. On the other hand, graph wavelet neural network only aggregates neighbor nodes so that it cannot obtain information of nodes which have similar feature with the target node and are far from the target node. To solve the above problems, we propose the GWNN-HF model, which can effectively adapt to different types of networks and get a better node representation. Specifically speaking, firstly, we design low-pass filter and high-pass filter convolution kernels to get low-pass and high-pass signals and then use the adaptive fusion method to fuse them, which effectively get commonality of same label nodes and difference of different label nodes. Secondly, we use the Relaxed Minimum Spanning Tree algorithm to construct a feature correlation graph and use an attention mechanism to fuse the original graph and feature correlation graph representation. Extensive experiments on benchmark datasets clearly indicate that GWNN-HF has a good performance in different types of network structures.},
  archive      = {J_KIS},
  author       = {Huang, Binfeng and Zheng, Wenjie and Qian, Fulan and Zhao, Shu and Chen, Jie and Zhang, Yanping},
  doi          = {10.1007/s10115-023-01900-y},
  journal      = {Knowledge and Information Systems},
  month        = {11},
  number       = {11},
  pages        = {5005-5024},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {GWNN-HF: Beyond assortativity in graph wavelet neural network},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimating time series averages from latent space of
multi-tasking neural networks. <em>KIS</em>, <em>65</em>(11), 4967–5004.
(<a href="https://doi.org/10.1007/s10115-023-01927-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series averages are one key input to temporal data mining techniques such as classification, clustering, forecasting, etc. In practice, the optimality of estimated averages often impacts the performance of such temporal data mining techniques. Practically, an estimated average is presumed to be optimal if it minimizes the discrepancy between itself and members of an averaged set while preserving descriptive shapes. However, estimating an average under such constraints is often not trivial due to temporal shifts. To this end, all pioneering averaging techniques propose to align averaged series before estimating an average. Practically, the alignment gets performed to transform the averaged series, such that, after the transformation, they get registered to their arithmetic mean. However, in practice, most proposed alignment techniques often introduce additional challenges. For instance, Dynamic Time Warping (DTW)-based alignment techniques make the average estimation process non-smooth, non-convex, and computationally demanding. With such observation in mind, we approach time series averaging as a generative problem. Thus, we propose to mimic the effects of temporal alignment in the latent space of multi-tasking neural networks. We also propose to estimate (augment) time domain averages from the latent space representations. With this approach, we provide state-of-the-art latent space registration. Moreover, we provide time domain estimations that are better than the estimates generated by some pioneering averaging techniques.},
  archive      = {J_KIS},
  author       = {Terefe, Tsegamlak and Devanne, Maxime and Weber, Jonathan and Hailemariam, Dereje and Forestier, Germain},
  doi          = {10.1007/s10115-023-01927-1},
  journal      = {Knowledge and Information Systems},
  month        = {11},
  number       = {11},
  pages        = {4967-5004},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Estimating time series averages from latent space of multi-tasking neural networks},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed probabilistic top-k dominating queries over
uncertain databases. <em>KIS</em>, <em>65</em>(11), 4939–4965. (<a
href="https://doi.org/10.1007/s10115-023-01917-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many real-world applications such as business planning and sensor data monitoring, one important, yet challenging, task is to rank objects (e.g., products, documents, or spatial objects) based on their ranking scores and efficiently return those objects with the highest scores. In practice, due to the unreliability of data sources, many real-world objects often contain noises and are thus imprecise and uncertain. In this paper, we study the problem of probabilistic top-k dominating (PTD) query on such large-scale uncertain data in a distributed environment, which retrieves k uncertain objects from distributed uncertain databases (on multiple distributed servers), having the largest ranking scores with high confidences. In order to efficiently tackle the distributed PTD problem, we propose a MapReduce framework for processing distributed PTD queries over distributed uncertain databases. In this MapReduce framework, we design effective pruning strategies to filter out false alarms in the distributed setting, propose cost-model-based index distribution mechanisms over servers, and develop efficient distributed PTD query processing algorithms. Extensive experiments have demonstrated the efficiency and effectiveness of our proposed distributed PTD approaches on both real and synthetic data sets through various experimental settings.},
  archive      = {J_KIS},
  author       = {Rai, Niranjan and Lian, Xiang},
  doi          = {10.1007/s10115-023-01917-3},
  journal      = {Knowledge and Information Systems},
  month        = {11},
  number       = {11},
  pages        = {4939-4965},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Distributed probabilistic top-k dominating queries over uncertain databases},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid clustering approach for link prediction in
heterogeneous information networks. <em>KIS</em>, <em>65</em>(11),
4905–4937. (<a
href="https://doi.org/10.1007/s10115-023-01914-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, researchers from academic and industrial fields have become increasingly interested in social network data to extract meaningful information. This information is used in applications such as link prediction between people groups, community detection, protein module identification, etc. Therefore, the clustering technique has emerged as a solution to finding similarities between social network members. Recently, in most graph clustering solutions, the structural similarity of nodes is combined with their attribute similarity. The results of these solutions indicate that the graph&#39;s topological structure is more important. Since most social networks are sparse, these solutions often suffer from insufficient use of node features. This paper proposes a hybrid clustering approach as an application for link prediction in heterogeneous information networks (HINs). In our approach, an adjacency vector is determined for each node until, in this vector, the weight of the direct edge or the weight of the shortest communication path among every pair of nodes is considered. A similarity metric is presented that calculates similarity using the direct edge weight between two nodes and the correlation between their adjacency vectors. Finally, we evaluated the effectiveness of our proposed method using DBLP, Political blogs, and Citeseer datasets under entropy, density, purity, and execution time metrics. The simulation results demonstrate that while maintaining the cluster density significantly reduces the entropy and the execution time compared with the other methods.},
  archive      = {J_KIS},
  author       = {Sajjadi, Zahra Sadat and Esmaeili, Mahdi and Ghobaei-Arani, Mostafa and Minaei-Bidgoli, Behrouz},
  doi          = {10.1007/s10115-023-01914-6},
  journal      = {Knowledge and Information Systems},
  month        = {11},
  number       = {11},
  pages        = {4905-4937},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A hybrid clustering approach for link prediction in heterogeneous information networks},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Leveraging BERT for extractive text summarization on federal
police documents. <em>KIS</em>, <em>65</em>(11), 4873–4903. (<a
href="https://doi.org/10.1007/s10115-023-01912-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A document known as notitia criminis (NC) is use in the Brazilian Federal Police as the starting point of the criminal investigation. An NC aims to report a summary of investigative activities. Thus, it contains all relevant information about a supposed crime that occurred. To manage an inquiry and correlate similar investigations, the Federal Police usually needs to extract essential information from an NC document. The manual extraction (reading and understanding the entire content) may be human mentally exhausting, due to the size and complexity of the documents. In this light, natural language processing (NLP) techniques are commonly used for automatic information extraction from textual documents. Deep neural networks are successfully apply to many different NLP tasks. A neural network model that leveraged the results in a wide range of NLP tasks was the BERT model—an acronym for Bidirectional Encoder Representations from Transformers. In this article, we propose approaches based on the BERT model to extract relevant information from textual documents using automatic text summarization techniques. In other words, we aim to analyze the feasibility of using the BERT model to extract and synthesize the most essential information of an NC document. We evaluate the performance of the proposed approaches using two real-world datasets: the Federal Police dataset (a private domain dataset) and the Brazilian WikiHow dataset (a public domain dataset). Experimental results using different variants of the ROUGE metric show that our approaches can significantly increase extractive text summarization effectiveness without sacrificing efficiency.},
  archive      = {J_KIS},
  author       = {Barros, Thierry S. and Pires, Carlos Eduardo S. and Nascimento, Dimas Cassimiro},
  doi          = {10.1007/s10115-023-01912-8},
  journal      = {Knowledge and Information Systems},
  month        = {11},
  number       = {11},
  pages        = {4873-4903},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Leveraging BERT for extractive text summarization on federal police documents},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A two-way dense feature pyramid networks for object
detection of remote sensing images. <em>KIS</em>, <em>65</em>(11),
4847–4871. (<a
href="https://doi.org/10.1007/s10115-023-01916-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bird’s eye view, multi-scale and dense classes in remote sensing images challenge the object detection of remote sensing images. It is not satisfactory to directly apply the object detection method designed for natural scene images to the object detection of remote sensing images. In this paper, we propose a detector with enhanced feature extraction ability to solve the above challenges, namely TWDFPN. TWDFPN has designed the structure of a two-way feature pyramid network (TWFPN) by combining feature maps with different generation directions and different spatial resolutions, which not only improves the utilization of the underlying feature information, but also strengthens the repeated utilization of the feature information of the backbone network, and ultimately improves the feature extraction ability of the network. Meanwhile, the dense-connected module is used in TWFPN to enhance the feature representation ability through limited additional computation cost, which extends the network and deepens the network. To evaluate the effectiveness of the proposed algorithm, this paper carried out experiments on NWPUVHR-10 and RSOD public remote sensing datasets, and the average accuracy (mAP) of 92.98% and 96.16%, respectively, which achieves advanced performance.},
  archive      = {J_KIS},
  author       = {Li, Haocong and Ma, Hui and Che, Yanbo and Yang, Zedong},
  doi          = {10.1007/s10115-023-01916-4},
  journal      = {Knowledge and Information Systems},
  month        = {11},
  number       = {11},
  pages        = {4847-4871},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A two-way dense feature pyramid networks for object detection of remote sensing images},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continuous prediction of a time intervals-related pattern’s
completion. <em>KIS</em>, <em>65</em>(11), 4797–4846. (<a
href="https://doi.org/10.1007/s10115-023-01910-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many daily applications, such as meteorology or patient data, the starting and ending times of the events are stored in a database, resulting in time interval data. Discovering patterns from time interval data can reveal informative patterns, in which the time intervals are related by temporal relations, such as before or overlaps. When multiple temporal variables are sampled in a variety of forms, and frequencies, as well as irregular events that may or may not have a duration, time intervals patterns can be a powerful way to discover temporal knowledge, since these temporal variables can be transformed into a uniform format of time intervals. Predicting the completion of such patterns can be used when the pattern ends with an event of interest, such as the recovery of a patient, or an undesirable event, such as a medical complication. In recent years, an increasing number of studies have been published on time intervals-related patterns (TIRPs), their discovery, and their use as features for classification. However, as far as we know, no study has investigated the prediction of the completion of a TIRP. The main challenge in performing such a completion prediction occurs when the time intervals are coinciding and not finished yet which introduces uncertainty in the evolving temporal relations, and thus on the TIRP’s evolution process. To overcome this challenge, we propose a new structure to represent the TIRP’s evolution process and calculate the TIRP’s completion probabilities over time. We introduce two continuous prediction models (CPMs), segmented continuous prediction model (SCPM), and fully continuous prediction model (FCPM) to estimate the TIRP’s completion probability. With the SCPM, the TIRP’s completion probability changes only at the TIRP’s time intervals’ starting or ending point. The FCPM incorporates, in addition, the duration between the TIRP’s time intervals’ starting and ending time points. A rigorous evaluation of four real-life medical and non-medical datasets was performed. The FCPM outperformed the SCPM and the baseline models (random forest, artificial neural network, and recurrent neural network) for all datasets. However, there is a trade-off between the prediction performance and their earliness since the new TIRP’s time intervals’ starting and ending time points are revealed over time, which increases the CPM’s prediction performance.},
  archive      = {J_KIS},
  author       = {Itzhak, Nevo and Jaroszewicz, Szymon and Moskovitch, Robert},
  doi          = {10.1007/s10115-023-01910-w},
  journal      = {Knowledge and Information Systems},
  month        = {11},
  number       = {11},
  pages        = {4797-4846},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Continuous prediction of a time intervals-related pattern’s completion},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). STORM-GAN+: Spatio-temporal meta-GAN for cross-city
estimation of heterogeneous human mobility responses to COVID-19.
<em>KIS</em>, <em>65</em>(11), 4759–4795. (<a
href="https://doi.org/10.1007/s10115-023-01921-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating human mobility is essential during the COVID-19 pandemic because it provides policymakers with important information for non-pharmaceutical actions. Deep learning methods perform better on tasks with enough training data than traditional estimating techniques. However, estimating human mobility during the rapidly developing pandemic is challenging because of data non-stationarity, a lack of observations, and complicated social situations. Prior studies on estimating mobility either concentrate on a single city or cannot represent the spatio-temporal relationships across cities and time periods. To address these issues, we solve the cross-city human mobility estimation problem using a deep meta-generative framework. Recently, we proposed the Spatio-Temporal Meta-Generative Adversarial Network (STORM-GAN) model, which estimates dynamic human mobility responses under social and policy conditions relevant to COVID-19 and is facilitated by a novel spatio-temporal task-based graph (STTG) embedding. Although STORM-GAN achieves a good average estimation accuracy, it creates higher errors and exhibits over-fitting in particular cities due to spatial heterogeneity. To address these issues, in this paper, we extend our prior work by introducing an improved spatio-temporal deep generative model, namely STORM-GAN+. STORM-GAN+ deals with the difficulties by including a distance-based weighted training technique into the STTG embedding component to better represent the variety of knowledge transfer across cities. Furthermore, to mitigate the issue of overfitting, we modify the meta-learning training objective to teach estimated mobility. Finally, we propose a conditional meta-learning algorithm that explicitly tailors transferable knowledge to various task clusters. We perform comprehensive evaluations, and STORM-GAN+ approximates real-world human mobility responses more accurately than previous methods, including STORM-GAN.},
  archive      = {J_KIS},
  author       = {Bao, Han and Zhou, Xun and Xie, Yiqun and Li, Yanhua and Jia, Xiaowei},
  doi          = {10.1007/s10115-023-01921-7},
  journal      = {Knowledge and Information Systems},
  month        = {11},
  number       = {11},
  pages        = {4759-4795},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {STORM-GAN+: Spatio-temporal meta-GAN for cross-city estimation of heterogeneous human mobility responses to COVID-19},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new type of cosine similarity measures based on
intuitionistic hesitant fuzzy rough sets for the evaluation of volatile
currency: Evidence from the pakistan economy. <em>KIS</em>,
<em>65</em>(11), 4741–4758. (<a
href="https://doi.org/10.1007/s10115-023-01909-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes novel cosine and weighted cosine similarity measures based on intuitionistic hesitant fuzzy rough sets and examines their fundamental characteristics. Similarity measures are crucial and advantageous tools that have a broad range of applications in decision making, data mining, medical diagnosis, and pattern recognition. To demonstrate the validity of the proposed similarity measures, an illustrative example in the evaluation of volatile currency in Pakistan is presented to verify the efficacy of our approach. Additionally, the rankings of suggested similarity measures are compared to those identified in the literature. The findings demonstrate that the innovative similarity measures lead in consistent patterns of ranking. The comparison confirms that the suggested similarity measures methodologies may achieve precise classification results and are applicable to real-world challenges involving hesitancy and uncertainty.},
  archive      = {J_KIS},
  author       = {Attaullah and Ullah, Sami and Drissi, Ramzi and Al-Duais, Fuad S.},
  doi          = {10.1007/s10115-023-01909-3},
  journal      = {Knowledge and Information Systems},
  month        = {11},
  number       = {11},
  pages        = {4741-4758},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A new type of cosine similarity measures based on intuitionistic hesitant fuzzy rough sets for the evaluation of volatile currency: Evidence from the pakistan economy},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic single table storage structure selection for
hybrid workload. <em>KIS</em>, <em>65</em>(11), 4713–4739. (<a
href="https://doi.org/10.1007/s10115-023-01913-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the use of database systems, the design of the storage engine and data model directly affects the performance of the database when performing queries. Therefore, the users of the database need to select the storage engine and design data model according to the workload encountered. However, in a hybrid workload, the query set of the database is dynamically changing, and the design of its optimised storage structure is also changing. Motivated by this, we propose an automatic storage structure selection system based on learning cost, which is used to dynamically select the optimised storage structure of the database under hybrid workloads. In the system, we introduce a machine learning method to build a cost model for the storage engine, and a column-oriented data layout generation algorithm. Experimental results show that the proposed system can choose the optimal combination of storage engine and data model according to the current workload, which greatly improves the performance of the default storage structure. And the system is designed to be compatible with different storage engines for easy use in practical applications.},
  archive      = {J_KIS},
  author       = {Wang, Hongzhi and Wei, Yan and Yan, Hao},
  doi          = {10.1007/s10115-023-01913-7},
  journal      = {Knowledge and Information Systems},
  month        = {11},
  number       = {11},
  pages        = {4713-4739},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Automatic single table storage structure selection for hybrid workload},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Temporal super-resolution traffic flow forecasting via
continuous-time network dynamics. <em>KIS</em>, <em>65</em>(11),
4687–4712. (<a
href="https://doi.org/10.1007/s10115-023-01887-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow forecasting is a critical task for intelligent transportation systems. However, the existed forecasting can only be conducted at certain time steps, because the data are discretely collected at these time steps. In contrast, traffic flow evolves in real time via a continuous manner in real world. Therefore, an ideal forecasting paradigm should be performed at arbitrary time steps instead of only at these certain time steps. Considering the forecasting time steps will no longer be restricted by these time steps, we call such paradigm as temporal super-resolution forecasting. In this paper, we incorporate the idea of neural ordinary differential equations (neural ODEs) to handle the problem, modeling the change rate of traffic flow on the urban road. Therefore, due to the continuous nature of ordinary differential equations, the traffic flow at arbitrary time steps can be forecasted by performing definite integral for the change rate. The urban road is usually regarded as a network, and the change rate of which can be described by continuous-time network dynamics, we parameterize the network dynamics of the traffic flow to quantify the change rate. On these foundations, we propose spatial-temporal continuous dynamics network to complete the temporal super-resolution forecasting task. Extensive experiments on public traffic flow datasets illustrate that our model can achieve high accuracy on temporal super-resolution forecasting, while ensuring its performance on conventional experimental settings at these certain time steps.},
  archive      = {J_KIS},
  author       = {Xie, Yi and Xiong, Yun and Zhang, Jiawei and Chen, Chao and Zhang, Yao and Zhao, Jie and Jiao, Yizhu and Zhao, Jinjing and Zhu, Yangyong},
  doi          = {10.1007/s10115-023-01887-6},
  journal      = {Knowledge and Information Systems},
  month        = {11},
  number       = {11},
  pages        = {4687-4712},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Temporal super-resolution traffic flow forecasting via continuous-time network dynamics},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Meta-heuristic endured deep learning model for big data
classification: Image analytics. <em>KIS</em>, <em>65</em>(11),
4655–4685. (<a
href="https://doi.org/10.1007/s10115-023-01888-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image processing is currently developing as a unique and the inventive field in computer research and applications in the modern area. Most image processing algorithms produce a large quantity of data as an outcome, which is termed as Big-data. These algorithms process and store bulky information either as structured or unstructured data. The use of big data analytics to mine the data produced by image processing technology has huge potential in areas like education, governments, medical establishments, production units, finance and banking, and retail business centers. This paper well defined the innovations made in Big Data analytics and image processing. In this study, a novel data classification approach especially for image analytics is proposed. To improve image quality, pre-processing is applied to huge data that has been gathered. Then, most relevant features like spatial information, texture GLCM, and color and shape features are extracted from the pre-processed image. Since the dimensions of the features are huge in size, an adaptive map-reduce framework with Improved Shannon Entropy has been introduced to lessen the dimensionality of the extracted features. Then, in the big data classification phase, an optimized deep learning classifier deep convolutional neural network (DCNN) is introduced to classify the images accurately. The weight function of the DCNN is fine-tuned using the newly proposed dragonfly updated mothsearch (DAUMS) Algorithm to enhance the classification accuracy and to solve the optimization problems of the research work. The moth search algorithm and dragonfly algorithm are both concepts in this hybrid algorithm DAUMS.},
  archive      = {J_KIS},
  author       = {Naveen, P. and Diwan, B.},
  doi          = {10.1007/s10115-023-01888-5},
  journal      = {Knowledge and Information Systems},
  month        = {11},
  number       = {11},
  pages        = {4655-4685},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Meta-heuristic endured deep learning model for big data classification: Image analytics},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A robust adaptive linear regression method for severe noise.
<em>KIS</em>, <em>65</em>(11), 4613–4653. (<a
href="https://doi.org/10.1007/s10115-023-01924-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Up to now, the inaccurate supervision problem caused by label noises poses a big challenge for regression modeling. Regularized noise-robust models provide a valid way for dealing with label noises in regression tasks. They generally use robust losses to cope with label noises and further enhance model robustness by feature selection. But most of them may not work well on data sets contaminated by severe noises (whose magnitudes are extreme), because severe noises do not coincide with their noise assumptions. To address this concern, this paper proposes a robust adaptive linear regression method named TC-ALASSO (Truncated Cauchy Adaptive LASSO), in which model learning and feature selection are finished simultaneously. The fat-tailed Cauchy distribution and truncation theory are adopted to deal with moderate noises and identified extreme noises, respectively, and construct the Truncated Cauchy loss for regression tasks. Moreover, TC-ALASSO applies the adaptive regularizer to finish feature selection well. Note that its adaptive regularizer weights are acquired according to regression coefficient estimations under the truncated Cauchy loss. We also theoretically analyze the robustness of proposed TC-ALASSO in this paper. The experimental results on artificial and benchmark data sets all confirm the robustness and effectiveness of TC-ALASSO. In addition, experimental results on face recognition databases validate the performance advantage of TC-ALASSO over state-of-the-art methods in dealing with extreme illumination variations.},
  archive      = {J_KIS},
  author       = {Guo, Yaqing and Wang, Wenjian},
  doi          = {10.1007/s10115-023-01924-4},
  journal      = {Knowledge and Information Systems},
  month        = {11},
  number       = {11},
  pages        = {4613-4653},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A robust adaptive linear regression method for severe noise},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human activity recognition using fuzzy proximal support
vector machine for multicategory classification. <em>KIS</em>,
<em>65</em>(11), 4585–4611. (<a
href="https://doi.org/10.1007/s10115-023-01911-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying machine learning tools to human activity analysis presents two major challenges: Firstly, the transformation of actions into multiple attributes increases training and testing time significantly. Secondly, the presence of noises and outliers in the dataset adds complexity and makes it difficult to implement the activity detection system efficiently. This paper addresses both of the challenges by proposing a kernel fuzzy proximal support vector machine as a robust classifier for multicategory classification problems. It transforms the input patterns into a higher-dimensional space and assigns each pattern an appropriate membership degree to reduce the effect of noises and outliers. The proposed method only requires the solution of a set of linear equations to obtain the classifiers; thus, it is computationally efficient. The computer simulation results on ten UCI benchmark problems show that the proposed method outperforms established methods in predictive accuracy. Finally, numerical results from three human activity recognition problems validate the applicability of the proposed method.},
  archive      = {J_KIS},
  author       = {Laxmi, Scindhiya and Kumar, Sumit and Gupta, S. K.},
  doi          = {10.1007/s10115-023-01911-9},
  journal      = {Knowledge and Information Systems},
  month        = {11},
  number       = {11},
  pages        = {4585-4611},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Human activity recognition using fuzzy proximal support vector machine for multicategory classification},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Near-optimal steiner tree computation powered by node
embeddings. <em>KIS</em>, <em>65</em>(11), 4563–4583. (<a
href="https://doi.org/10.1007/s10115-023-01893-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Steiner minimum tree problem on a graph, i.e., finding a tree with the minimum weight that covers the set of terminal nodes, is a classical NP-hard problem. Thus, we develop a method based on supervised learning to produce a near-optimal Steiner tree in this paper. It contains three main phases, namely node embedding, candidate set generation, and tree construction. Leveraged on compressed sensing, we devise a novel node embedding that exhibits a good nature of reversibility for sparse linear aggregations, which powers learning a mapping function from the terminal set to the optimal Steiner tree. Finally, we propose efficient pruning techniques to improve the solution quality. The experimental results show that our approach delivers high-quality solutions and runs faster than the competitors by one or two orders of magnitude on graphs with more than 200 nodes.},
  archive      = {J_KIS},
  author       = {Yang, Boyu and Zheng, Weiguo},
  doi          = {10.1007/s10115-023-01893-8},
  journal      = {Knowledge and Information Systems},
  month        = {11},
  number       = {11},
  pages        = {4563-4583},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Near-optimal steiner tree computation powered by node embeddings},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Read to grow: Exploring metadata of books to make intriguing
book recommendations for teenage readers. <em>KIS</em>, <em>65</em>(11),
4537–4562. (<a
href="https://doi.org/10.1007/s10115-023-01907-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is clearly established that spending time reading is beneficial for an individual’s development in terms of their social, emotional, and intellectual capabilities. This is especially true for teenagers who are in the growing process and reading can improve their memory, vocabulary, concentration and attention span, creativity and imagination, and writing skills. With the overwhelming volume of (online) books available these days, it becomes a huge challenge to find suitable and appealing books to read. Current book recommender systems, however, do not adequately capitalize teenagers’ specific needs such as readability levels, emotional capabilities, and subject’s comprehension, that are more at the forefront for teenage readers than adults and children. To make appropriate recommendations on books for teenagers, we propose a book recommender system, called TBRec. TBRec recommends books to teenagers based on their personal preferences and needs that are determined by using various book features. These features, which include book genres, topic relevance, emotion traits, readers’ advisory, predicted user rating, and readability level, have significant impact on the teenagers’ preference and satisfaction on a book. These distinguished parts of a book, which are premeditated and essential criteria for book selection, identify the type, subject area, state of consciousness, appeal factors, (un)likeness, and complexity of the book content, respectively. Experimental results reveal that TBRec outperforms Amazon, Barnes and Noble, and LibraryThing, three of the widely used book recommenders, in making book recommendations for teenagers, and the results are statistically significant.},
  archive      = {J_KIS},
  author       = {Ng, Yiu-Kai},
  doi          = {10.1007/s10115-023-01907-5},
  journal      = {Knowledge and Information Systems},
  month        = {11},
  number       = {11},
  pages        = {4537-4562},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Read to grow: Exploring metadata of books to make intriguing book recommendations for teenage readers},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Revisiting of peer-to-peer traffic: Taxonomy, applications,
identification techniques, new trends and challenges. <em>KIS</em>,
<em>65</em>(11), 4479–4536. (<a
href="https://doi.org/10.1007/s10115-023-01915-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The services provided through peer-to-peer (P2P) architecture involve the transmission of text, images, documents, and multimedia. Especially the distribution of multimedia content like video and audio is mainly demanded by clients and has become the major reason for generating traffic by consuming significant bandwidth. This traffic is mostly generated by P2P applications like Napster, Gnutella, BitTorrent, PPTV, YuppTV, and many more. To use the network bandwidth proficiently, thus classification and identification of this Internet traffic became necessary. Moreover, it is required to classify the specific P2P application traffic, so data distribution over the P2P network can be improved. This survey paper discusses the working of different P2P applications for which traffic is created and raises related issues. The paper deliberates the various techniques and overlays that are used to provide the services over the P2P network. This paper includes the various techniques of feature selection and the machine learning algorithm for the identification and classification of internet traffic. This paper also reviewed the recent developments and highlights the future direction of research work in P2P networks.},
  archive      = {J_KIS},
  author       = {Ansari, Md. Sarfaraj Alam and Pal, Kunwar and Govil, Mahesh Chandra},
  doi          = {10.1007/s10115-023-01915-5},
  journal      = {Knowledge and Information Systems},
  month        = {11},
  number       = {11},
  pages        = {4479-4536},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Revisiting of peer-to-peer traffic: Taxonomy, applications, identification techniques, new trends and challenges},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scholarly recommendation systems: A literature survey.
<em>KIS</em>, <em>65</em>(11), 4433–4478. (<a
href="https://doi.org/10.1007/s10115-023-01901-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A scholarly recommendation system is an important tool for identifying prior and related resources such as literature, datasets, grants, and collaborators. A well-designed scholarly recommender significantly saves the time of researchers and can provide information that would not otherwise be considered. The usefulness of scholarly recommendations, especially literature recommendations, has been established by the widespread acceptance of web search engines such as CiteSeerX, Google Scholar, and Semantic Scholar. This article discusses different aspects and developments of scholarly recommendation systems. We searched the ACM Digital Library, DBLP, IEEE Explorer, and Scopus for publications in the domain of scholarly recommendations for literature, collaborators, reviewers, conferences and journals, datasets, and grant funding. In total, 225 publications were identified in these areas. We discuss methodologies used to develop scholarly recommender systems. Content-based filtering is the most commonly applied technique, whereas collaborative filtering is more popular among conference recommenders. The implementation of deep learning algorithms in scholarly recommendation systems is rare among the screened publications. We found fewer publications in the areas of the dataset and grant funding recommenders than in other areas. Furthermore, studies analyzing users’ feedback to improve scholarly recommendation systems are rare for recommenders. This survey provides background knowledge regarding existing research on scholarly recommenders and aids in developing future recommendation systems in this domain.},
  archive      = {J_KIS},
  author       = {Zhang, Zitong and Patra, Braja Gopal and Yaseen, Ashraf and Zhu, Jie and Sabharwal, Rachit and Roberts, Kirk and Cao, Tru and Wu, Hulin},
  doi          = {10.1007/s10115-023-01901-x},
  journal      = {Knowledge and Information Systems},
  month        = {11},
  number       = {11},
  pages        = {4433-4478},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Scholarly recommendation systems: A literature survey},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Correction: Meta-heuristic endured deep learning model for
big data classification: Image analytics. <em>KIS</em>, <em>65</em>(10),
4431. (<a href="https://doi.org/10.1007/s10115-023-01944-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_KIS},
  author       = {Naveen, P. and Diwan, B.},
  doi          = {10.1007/s10115-023-01944-0},
  journal      = {Knowledge and Information Systems},
  month        = {10},
  number       = {10},
  pages        = {4431},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Correction: meta-heuristic endured deep learning model for big data classification: image analytics},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Owner name entity recognition in websites based on
heterogeneous and dynamic graph transformer. <em>KIS</em>,
<em>65</em>(10), 4411–4429. (<a
href="https://doi.org/10.1007/s10115-023-01908-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying owners of devices on the Internet can enable numerous network security applications. For example, accurate Owner Name Entity Recognition (ONER) of websites is critical to find influenced owners in light of new security threats. In this situation, as a specific task of Multimodal Named Entity Recognition (MNER), ONER is essential and helpful for network security. Currently, most existing MNER models only use texts and images, so they cannot effectively utilize the multimodal data of devices to achieve ONER accurately. Also, most of the existing MNER models separately use information in each modality and between modalities. Thus, the fusion is inconsistent, so the effect is not satisfied. Therefore, the paper proposes HDGT: A heterogeneous and Dynamic Graph Transformer, to improve the performance of ONER. The core components in HDGT to realize MNER are a dynamic graph and two-stream mechanism, which could learn the relationship between different modalities during training and the graph’s structure well. The paper manually labels a multimodal dataset containing texts, images, and domains to prove the performance of HDGT. Also, the paper conducts experiments on existing and public MNER datasets. The results show that HDGT achieves 84.88% F1 scores on the recognition of owner entities, 75.21% F1 on Twitter2015, and 87.03% F1 on Twitter2017, which outperforms other existing MNER models.},
  archive      = {J_KIS},
  author       = {Ren, Yimo and Li, Hong and Liu, Peipei and Liu, Jie and Li, Zhi and Zhu, Hongsong and Sun, Limin},
  doi          = {10.1007/s10115-023-01908-4},
  journal      = {Knowledge and Information Systems},
  month        = {10},
  number       = {10},
  pages        = {4411-4429},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Owner name entity recognition in websites based on heterogeneous and dynamic graph transformer},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A graph-based approach for minimising the knowledge
requirement of explainable recommender systems. <em>KIS</em>,
<em>65</em>(10), 4379–4409. (<a
href="https://doi.org/10.1007/s10115-023-01903-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditionally, recommender systems use collaborative filtering or content-based approaches based on ratings and item descriptions. However, this information is unavailable in many domains and applications, and recommender systems can only tackle the problem using information about interactions or implicit knowledge. Within this scenario, this work proposes a novel approach based on link prediction techniques over graph structures that exclusively considers interactions between users and items to provide recommendations. We present and evaluate two alternative recommendation methods: one item-based and one user-based that apply the edge weight, common neighbours, Jaccard neighbours, Adar/Adamic, and Preferential Attachment link prediction techniques. This approach has two significant advantages, which are the novelty of our proposal. First, it is suitable for minimal knowledge scenarios where explicit data such as ratings or preferences are not available. However, as our evaluation demonstrates, this approach outperforms state-of-the-art techniques using a similar level of interaction knowledge. Second, our approach has another relevant feature regarding one of the most significant concerns in current artificial intelligence research: the recommendation methods presented in this paper are easily interpretable for the users, improving their trust in the recommendations.},
  archive      = {J_KIS},
  author       = {Caro-Martínez, Marta and Jiménez-Díaz, Guillermo and Recio-Garcia, Juan A.},
  doi          = {10.1007/s10115-023-01903-9},
  journal      = {Knowledge and Information Systems},
  month        = {10},
  number       = {10},
  pages        = {4379-4409},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A graph-based approach for minimising the knowledge requirement of explainable recommender systems},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid CPU/GPU/APU accelerated query, insert, update and
erase operations in hash tables with string keys. <em>KIS</em>,
<em>65</em>(10), 4359–4377. (<a
href="https://doi.org/10.1007/s10115-023-01891-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern computer systems can use different types of hardware acceleration to achieve massive performance improvements. Some accelerators like FPGA and dedicated GPU (dGPU) need optimized data structures for the best performance and often use dedicated memory. In contrast, APUs, which are a combination of a CPU and an integrated GPU (iGPU), support shared memory and allow the iGPU to work together with the CPU on pointer-based data structures. First, we develop an approach for dGPU to accelerate queries in libcuckoo and robin-map and when looking at accelerating insert, updates and erase operations in the original libcuckoo using OneAPI on an APU. We evaluate the dGPU against the CPU variants and our dGPU approach adapted for the CPU and also in a hybrid context by using longer keys on the CPU and shorter keys on the dGPU. In comparison with the original libcuckoo algorithm, our dGPU approach achieves a speed-up of 2.1, and in comparison with the robin-map a speed-up of 1.5. For hybrid workloads, our approach is efficient if long keys are processed on the CPU and short keys are processed on the dGPU. By processing a mixture of 20% long keys on the CPU and 80% short keys on dGPU, our hybrid approach has a 40% higher throughput than the CPU only approach. In addition, we develop a hybrid APU approach for insert, update and erase operations in the original libcuckoo structure focusing on shared memory with iGPU accelerated look-ups of the positions for insert, update and erase operations.},
  archive      = {J_KIS},
  author       = {Groth, Tobias and Groppe, Sven and Pionteck, Thilo and Valdiek, Franz and Koppehel, Martin},
  doi          = {10.1007/s10115-023-01891-w},
  journal      = {Knowledge and Information Systems},
  month        = {10},
  number       = {10},
  pages        = {4359-4377},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Hybrid CPU/GPU/APU accelerated query, insert, update and erase operations in hash tables with string keys},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-task entity linking with supervision from a taxonomy.
<em>KIS</em>, <em>65</em>(10), 4335–4358. (<a
href="https://doi.org/10.1007/s10115-023-01905-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity linking is the task of resolving ambiguous mentions in documents to their referent entities in a knowledge graph (KG). Existing solutions mainly rely on three kinds of information: local contextual similarity, global coherence, and prior probability. But the information of the mentions’ types is rarely utilized, which is helpful for precise entity linking. That is to say, if the type information of a mention is obtained from a mention classifier, we can exclude candidate entities with different types. However, the key challenge of realizing it lies in obtaining the type labels with appropriate granularity and performing entity linking with the error propagated from the mention classifier. To solve the challenges, we propose a model named type-oriented multi-task entity linking (TMTEL). First, we select types with appropriate granularity from the taxonomy of a KG, which is modeled as a nonlinear integer programming problem. Second, we use a multi-task learning framework to incorporate the selected types into entity linking. The type information is used to enhance the representation of the mentions’ context, which is more robust to the errors of the mention classifier. Experimental results show that our model outperforms multiple existing solutions.},
  archive      = {J_KIS},
  author       = {Wang, Xuwu and Chen, Lihan and Zhu, Wei and Ni, Yuan and Xie, Guotong and Yang, Deqing and Xiao, Yanghua},
  doi          = {10.1007/s10115-023-01905-7},
  journal      = {Knowledge and Information Systems},
  month        = {10},
  number       = {10},
  pages        = {4335-4358},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Multi-task entity linking with supervision from a taxonomy},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GradeAid: A framework for automatic short answers grading in
educational contexts—design, implementation and evaluation.
<em>KIS</em>, <em>65</em>(10), 4295–4334. (<a
href="https://doi.org/10.1007/s10115-023-01892-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic short answer grading (ASAG), a hot field of natural language understanding, is a research area within learning analytics. ASAG solutions are conceived to offload teachers and instructors, especially those in higher education, where classes with hundreds of students are the norm and the task of grading (short)answers to open-ended questionnaires becomes tougher. Their outcomes are precious both for the very grading and for providing students with “ad hoc” feedback. ASAG proposals have also enabled different intelligent tutoring systems. Over the years, a variety of ASAG solutions have been proposed, still there are a series of gaps in the literature that we fill in this paper. The present work proposes GradeAid, a framework for ASAG. It is based on the joint analysis of lexical and semantic features of the students’ answers through state-of-the-art regressors; differently from any other previous work, (i) it copes with non-English datasets, (ii) it has undergone a robust validation and benchmarking phase, and (iii) it has been tested on every dataset publicly available and on a new dataset (now available for researchers). GradeAid obtains performance comparable to the systems presented in the literature (root-mean-squared errors down to 0.25 based on the specific tuple $$\langle $$ dataset-question $$\rangle $$ ). We argue it represents a strong baseline for further developments in the field.},
  archive      = {J_KIS},
  author       = {del Gobbo, Emiliano and Guarino, Alfonso and Cafarelli, Barbara and Grilli, Luca},
  doi          = {10.1007/s10115-023-01892-9},
  journal      = {Knowledge and Information Systems},
  month        = {10},
  number       = {10},
  pages        = {4295-4334},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {GradeAid: A framework for automatic short answers grading in educational contexts—design, implementation and evaluation},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Seq2EG: A novel and effective event graph parsing approach
for event extraction. <em>KIS</em>, <em>65</em>(10), 4273–4294. (<a
href="https://doi.org/10.1007/s10115-023-01898-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event extraction is a fundamental task in information extraction. Most previous approaches typically transform event extraction into two subtasks: trigger classification and argument classification, and solve them via classification-based methods, which suffer from some inherent drawbacks. To overcome these issues, in this paper, we propose a novel event extraction model Seq2EG by first formulating event extraction as an event graph parsing problem, and then exploiting a pre-trained sequence-to-sequence (seq2seq) model to transduce an input sentence into an accurate event graph without the need for trigger words. Based on the generative event graph parsing formulation, our model Seq2EG can explicitly model the multiple event correlations and argument sharing and can naturally incorporate some graph-structured features and the rich semantic information conveyed by the labels of event types and argument roles. Extensive experimental results on the public ACE2005 dataset show that our approach outperforms all previous state-of-the-art models for event extraction by a large margin, respectively, obtaining an improvement of 3.4% F1 score for event detection and an improvement of 4.7% F1 score for argument classification over the best baselines.},
  archive      = {J_KIS},
  author       = {Sun, Haotong and Zhou, Junsheng and Kong, Li and Gu, Yanhui and Qu, Weiguang},
  doi          = {10.1007/s10115-023-01898-3},
  journal      = {Knowledge and Information Systems},
  month        = {10},
  number       = {10},
  pages        = {4273-4294},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Seq2EG: A novel and effective event graph parsing approach for event extraction},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hash-based index for processing frequent updates and
continuous location-based range queries. <em>KIS</em>, <em>65</em>(10),
4233–4271. (<a
href="https://doi.org/10.1007/s10115-023-01884-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wide range of location-based services and sensors in GIS have to manage moving objects that change their position with respect to time. These applications generate voluminous amount of real-time data that demands an effective query processing mechanism to minimize the response time of a query. Spatial indexing emerged as an active area for research to accelerate the efficiency of a query processing engine by pruning the search space. Most of the existing indices in the literature for moving objects are based on tree structure and have poor update performance due to node splitting and other computationally expensive operations. Since the moving objects change their location continuously, the underlying index must be updated continuously to keep it up to date. An efficient index is needed that can perform well when there are excessive update operations. Recently, hash-based indices have been used to deal with the limitations of tree-based indices. However, most of them utilize excessive data structures in their operation and usually hold separate indices for queries and object updates. In this paper, we have designed a hash-based index that gives good performance for range search operation under high updates. Our proposed index relies only on one structure to serve both the updates and queries. We proposed a grid-based safe region method for processing continuous range queries under high updates. Experimental evaluation shows that the proposed index outperforms the hash-based indices present in the literature for continuous range search operations. For update operation, LHashMov performs 2.4 times better than u-Grid index and 43 times better than fixed grid index. For continuous-range search operation, LHashMov performs $$3.06 \times 10^{9}$$ times better than u-Grid index and $$8.58 \times 10^{9}$$ times better than fixed grid index.},
  archive      = {J_KIS},
  author       = {Chaudhry, Natalia and Yousaf, Muhammad Murtaza},
  doi          = {10.1007/s10115-023-01884-9},
  journal      = {Knowledge and Information Systems},
  month        = {10},
  number       = {10},
  pages        = {4233-4271},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A hash-based index for processing frequent updates and continuous location-based range queries},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Utilizing the influence of multiple potential factors for
social recommendation. <em>KIS</em>, <em>65</em>(10), 4213–4232. (<a
href="https://doi.org/10.1007/s10115-023-01883-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recommendation system helps users select satisfactory products and services to make reasonable decisions. In recent years, most methods have introduced social information into the recommendation system to improve recommendation accuracy. Most social recommendations only consider that users are affected by historical items and social information. But users are affected by multiple potential factors that cannot be explicitly distinguished when making decisions, such as consumption experience and life cycle related to users, social consumption culture, and social roles related to social friends, and they are mixed with each other. To describe the above scenario, we propose a model that Utilizes the influence of multiple potential factors for Social Recommendation (UimSRec). Specifically, we simulate the influence of different potential factors on users in the form of latent semantics, associate the potential influence with user representation, and use the user latent representation to model preferences. In addition, this paper uses the attention mechanism to adaptively assign weights to multiple influencing factors and common influencing factors. The experimental results on three real datasets show that modeling various potential impact information and their relationships can significantly improve the recommendation performance. The code is available at ( https://github.com/qinkaili/UimSRec ).},
  archive      = {J_KIS},
  author       = {Qian, Fulan and Qin, Kaili and Chen, Hai and Chen, Jie and Zhao, Shu and Zhou, Peng and Zhang, Yanping},
  doi          = {10.1007/s10115-023-01883-w},
  journal      = {Knowledge and Information Systems},
  month        = {10},
  number       = {10},
  pages        = {4213-4232},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Utilizing the influence of multiple potential factors for social recommendation},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accelerating massive queries of approximate nearest neighbor
search on high-dimensional data. <em>KIS</em>, <em>65</em>(10),
4185–4212. (<a
href="https://doi.org/10.1007/s10115-023-01899-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximate nearest neighbor (ANN) search on high-dimensional data is a fundamental operation in many applications. In this paper, we study massive queries of ANN (MQ-ANN) search, which deals with a large number of queries simultaneously. To improve the throughput, we combine the parallel capacity of multi-core CPUs and the filtering power of the state-of-the-art index methods, i.e., proximity graphs. However, there are no solutions that exploit proximity graphs to handle MQ-ANN in parallel, except the one called query view, which simply assigns each query to a hardware thread but suffers from numerous cache misses. As the first attempt, we design efficient methods for MQ-ANN with proximity graphs and propose a novel scheduling mechanism called bridge view, which shares the same data access across multiple queries in order to reduce cache misses. Moreover, we extend our method to deal with MQ-ANN on large-scale data sets (e.g. $$10^8$$ points). Finally, we conduct extensive experiments on real data sets to demonstrate the advantages of our method. According to our experimental results, bridge view significantly outperforms query view in various settings. In particular, bridge view with 8 hardware threads even outperforms query view with 24 hardware threads.},
  archive      = {J_KIS},
  author       = {Liu, Yingfan and Song, Chaowei and Cheng, Hong and Xia, Xiaofang and Cui, Jiangtao},
  doi          = {10.1007/s10115-023-01899-2},
  journal      = {Knowledge and Information Systems},
  month        = {10},
  number       = {10},
  pages        = {4185-4212},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Accelerating massive queries of approximate nearest neighbor search on high-dimensional data},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Imbalance factor: A simple new scale for measuring
inter-class imbalance extent in classification problems. <em>KIS</em>,
<em>65</em>(10), 4157–4183. (<a
href="https://doi.org/10.1007/s10115-023-01881-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from datasets that suffer from differences in absolute frequency of classes is one of the most challenging tasks in the machine learning field. Efforts have been made to tackle the problem of class imbalance by providing solutions at data and algorithmic levels. In these cases, in order to categorize the solutions according to problem class imbalance level and to obtain meaningful and consistent interpretations from the experiments, it is essential to be able to quantify the extent of dataset imbalance. A competent scale to summarize the severity of data inter-class imbalance, requires to meet at least the following three conditions: (1) the ability to calculate the imbalance extent for both binary and multi-class datasets, (2) output within a definite and fixed range of values, (3) being correlated with the performance of different classifiers. Nevertheless, none of the scales introduced so far satisfy all the enumerated requirements. In this study, we propose an informative scale called imbalance factor (IF) based on information theory, which, independent of the number of data classes, quantifies dataset imbalance extent in a single value in the range of [0, 1]. Besides, IF offers various limiting cases with different growth rates according to its α order. This property is critical as it can settle the possibility of having the same extent for distinct distributions. Eventually, empirical experiments indicate that with an average correlation of 0.766 with the classification accuracies over 15 real datasets, IF is remarkably more sensitive to class imbalance changes than other previous scales.},
  archive      = {J_KIS},
  author       = {Pirizadeh, Mohsen and Farahani, Hadi and Kheradpisheh, Saeed Reza},
  doi          = {10.1007/s10115-023-01881-y},
  journal      = {Knowledge and Information Systems},
  month        = {10},
  number       = {10},
  pages        = {4157-4183},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Imbalance factor: A simple new scale for measuring inter-class imbalance extent in classification problems},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhanced u-net segmentation with ensemble convolutional
neural network for automated skin disease classification. <em>KIS</em>,
<em>65</em>(10), 4111–4156. (<a
href="https://doi.org/10.1007/s10115-023-01865-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, skin-related problems induce psychological problems and also injure physical health, particularly if the patient’s face was disfigured or damaged. Smart devices are used for gathering medical images for knowing their skin condition. Skin disease diagnosis is a complex task, which can be solved by adopting different lesion detection and classification approaches. However, the existing challenges cannot be solved by mixing the disease samples from diverse data sources while using simple data fusion approaches. The traditional deep learning-based computer-aided diagnosis approaches suffer from poor extraction of skin lesions due to complex features like limited training datasets, low contrast with the background, presence of artifacts, and fuzzy boundaries. It also includes problems like complex computation, poor generalization, and over-fitting while using the appropriate tuning of large-scale parameters. This paper intends to propose a new framework by using skin lesions classification and segmentation procedures for the automated diagnosis of various skin diseases. The significant stages of the given offered method are pre-processing lesion segmentation and classification. In the beginning, grey-level conversion, hair removal, and contrast enhancement are performed to make the image fit for effective classification. Once image pre-processing is over, the segmentation of skin lesions is done by the enhanced U-Net segmentation, in which the improvement is attained by proposing a hybrid optimization algorithm. Moreover, the offered hybridized optimization algorithm solves the local optimum issues, and also it has the ability for resolving a finite set of problems. Merging the optimization algorithms can balance the exploration and exploitation capability owing to its ability of convergence speed, searching global optimum, and simplicity. The classification is further performed by the optimized ensemble-convolutional neural network (E-CNN). Instead of the fully connected layer in CNN, five different expert systems like random forest, artificial neural network, support vector machine, Adaboost, and Extreme Gradient Boosting (XGBoost) are used for classifying the skin disease by CNN. The system also employs optimization of different parameters in the classification stage to improve computing efficiency and reduce network complexity. The hybrid meta-heuristic termed whale-electric fish optimization (W-EFO) based on EFO and whale optimization algorithm is used for improvising the segmentation and classification task. The comparative analysis over conventional models proves that the developed model encourages effective performance when analyzing diverse measures.},
  archive      = {J_KIS},
  author       = {Reddy, Dasari Anantha and Roy, Swarup and Kumar, Sanjay and Tripathi, Rakesh},
  doi          = {10.1007/s10115-023-01865-y},
  journal      = {Knowledge and Information Systems},
  month        = {10},
  number       = {10},
  pages        = {4111-4156},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Enhanced U-net segmentation with ensemble convolutional neural network for automated skin disease classification},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Heterogeneous graph neural network with semantic-aware
differential privacy guarantees. <em>KIS</em>, <em>65</em>(10),
4085–4110. (<a
href="https://doi.org/10.1007/s10115-023-01895-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most social networks can be modeled as heterogeneous graphs. Recently, advanced graph learning methods exploit the rich node properties and topological relationships for downstream tasks. That means that more private information is embedded in the representation. However, the existing privacy-preserving methods only focus on protecting the single type of node attributes or relationships, which neglect the significance of high-order semantic information. To address this issue, we propose a novel Heterogeneous graph neural network with Semantic-aware Differential privacy Guarantees named HeteSDG, which provides a double privacy guarantee and performance trade-off in terms of both graph features and topology. In particular, we first reveal the privacy leakage in heterogeneous graphs and define a membership inference attack with a semantic enhancement (MIS) that will improve the means of member inference attacks by obtaining side background knowledge through semantics. Then we design a two-stage mechanism, which includes the feature attention personalized mechanism and the topology gradient perturbation mechanism, where the privacy-preserving technologies are based on differential privacy. These mechanisms will defend against MIS and provide stronger interpretation, but simultaneously bring in noise for representation learning. To better balance the noise perturbation and learning performance, we utilize a bi-level optimization pattern to allocate a suitable privacy budget for the above two modules. Our experiments on four public benchmarks conduct performance experiments, ablation studies, inference attack verification, etc. The results show the privacy protection capability and generalization of HeteSDG.},
  archive      = {J_KIS},
  author       = {Wei, Yuecen and Fu, Xingcheng and Yan, Dongqi and Sun, Qingyun and Peng, Hao and Wu, Jia and Wang, Jinyan and Li, Xianxian},
  doi          = {10.1007/s10115-023-01895-6},
  journal      = {Knowledge and Information Systems},
  month        = {10},
  number       = {10},
  pages        = {4085-4110},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Heterogeneous graph neural network with semantic-aware differential privacy guarantees},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analysis and price prediction of cryptocurrencies for
historical and live data using ensemble-based neural networks.
<em>KIS</em>, <em>65</em>(10), 4055–4084. (<a
href="https://doi.org/10.1007/s10115-023-01871-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The popularity of cryptocurrencies has been on the rise with the emergence of blockchain technologies. There have been enormous investments in the cryptocurrency market over the past few years. However, the volatile nature and significant price fluctuations in cryptocurrency have resulted in a high investment risk of these assets. In this paper, an improved neural network (NN) ensemble-based approach is proposed with the help of Convolutional Neural Network (CNN) and Bidirectional Long Short-Term Memory (LSTM), i.e., CNN-BiLSTM for long-term price prediction of cryptocurrencies using both live data API and historical data. The CNN learns internal representation of each cryptocurrency independently and extracts useful features. On the other hand, the LSTM layers are used to predict time-series data and recognize the long as well as short-term dependencies efficiently and accurately. The proposed ensemble of CNN-BiLSTM consists of three layers of CNN and two layers of Bi-LSTM to improve the accuracy of the predictions. Moreover, MLP, GRU, CNN and LSTM models are also implemented and compared with the proposed model on the test datasets followed by error evaluation. For evaluating the error of each model, Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) scores are analyzed for four cryptocurrencies Bitcoin, Ethereum, Dogecoin and Litecoin of historical and live data API. It is observed that the proposed CNN-BiLSTM ensemble model has the lowest RMSE score of 0.164 for live data API for Bitcoin and 0.166 for historical dataset for Dogecoin. The MSE score of 0.027 is observed for both Bitcoin and Dogecoin cryptocurrencies for live data API and 0.027 for Dogecoin for historical dataset. Thus, RMSE and MSE scores of the proposed approach are very less as compared to MLP, GRU, CNN and LSTM models for cryptocurrency price prediction for both the datasets.},
  archive      = {J_KIS},
  author       = {Rathee, Nisha and Ankita Singh and Sharda, Tanisha and Goel, Nimisha and Mansi Aggarwal and Dudeja, Sanya},
  doi          = {10.1007/s10115-023-01871-0},
  journal      = {Knowledge and Information Systems},
  month        = {10},
  number       = {10},
  pages        = {4055-4084},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Analysis and price prediction of cryptocurrencies for historical and live data using ensemble-based neural networks},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GM2NAS: Multitask multiview graph neural architecture
search. <em>KIS</em>, <em>65</em>(10), 4021–4054. (<a
href="https://doi.org/10.1007/s10115-023-01886-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural network-based multitask learning models on multiview graphs have achieved acceptable results in different real-world applications. However, constructing and fine-tuning artificially designed architectures for various multiview graphs are time-consuming and require expert knowledge. To address this challenge, we propose a multitask multiview graph neural architecture search framework called GM2NAS to automatically design multitask multiview model (M2 model) architectures. Specifically, the GM2NAS framework builds M2 model architectures for multiview graph learning and multitask learning. Unlike traditional graph neural architecture search (GNAS) approaches developed for single-task single-view problems, we design a multitask multiview (M2) search space and an unsupervised evaluation strategy to fit GNAS for multitask multiview graph learning. In terms of the search space, we design an effective multitask multiview (M2) search space that precisely allows identifying the optimal operations for multiview graph learning, multiview representation fusion, task-specific attention, and loss weighting to capture informative representation and implicitly transfer and share information among multiple tasks. In terms of the unsupervised evaluation strategy, we introduce an unsupervised evaluation strategy based on unsupervised learning to guide the search algorithm and enable GNAS to deal with multitask multiview graph learning effectively. Then, we explore different search algorithms to identify the optimal combinations of M2 models for multitask multiview graph learning. To validate the effectiveness of GM2NAS, we apply it to node classification and link prediction tasks. Based on the extensive experiments, the results reveal that GM2NAS outperforms the state-of-the-art models on actual multiview graph data.},
  archive      = {J_KIS},
  author       = {Gao, Jianliang and Al-Sabri, Raeed and Oloulade, Babatounde Moctard and Chen, Jiamin and Lyu, Tengfei and Wu, Zhenpeng},
  doi          = {10.1007/s10115-023-01886-7},
  journal      = {Knowledge and Information Systems},
  month        = {10},
  number       = {10},
  pages        = {4021-4054},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {GM2NAS: Multitask multiview graph neural architecture search},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploiting spatial relations for grammar-based specification
of multidimensional languages. <em>KIS</em>, <em>65</em>(10), 3995–4020.
(<a href="https://doi.org/10.1007/s10115-023-01879-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As opposed to textual programming languages, multidimensional languages compiler construction paradigms lack standardization. To this aim, in this paper we present the spatial grammar (SG) formalism, a grammar model for multidimensional languages which has string-like productions containing more general spatial relations other than string concatenation, and we provide mapping rules to translate an SG specification into a translation schema. In this way, the SG formalism inherits and extends to the multidimensional context concepts and techniques of standard compiler generation tools like YACC.},
  archive      = {J_KIS},
  author       = {Della Penna, Giuseppe and Orefice, Sergio and D’Angelo, Andrea},
  doi          = {10.1007/s10115-023-01879-6},
  journal      = {Knowledge and Information Systems},
  month        = {10},
  number       = {10},
  pages        = {3995-4020},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Exploiting spatial relations for grammar-based specification of multidimensional languages},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tracking social provenance in chains of retweets.
<em>KIS</em>, <em>65</em>(10), 3967–3994. (<a
href="https://doi.org/10.1007/s10115-023-01878-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of massive sharing of information, the term social provenance is used to denote the ownership, source or origin of a piece of information which has been propagated through social media. Tracking the provenance of information is becoming increasingly important as social platforms acquire more relevance as source of news. In this scenario, Twitter is considered one of the most important social networks for information sharing and dissemination which can be accelerated through the use of retweets and quotes. However, the Twitter API does not provide a complete tracking of the retweet chains, since only the connection between a retweet and the original post is stored, while all the intermediate connections are lost. This can limit the ability to track the diffusion of information as well as the estimation of the importance of specific users, who can rapidly become influencers, in the news dissemination. This paper proposes an innovative approach for rebuilding the possible chains of retweets and also providing an estimation of the contributions given by each user in the information spread. For this purpose, we define the concept of Provenance Constraint Network and a modified version of the Path Consistency Algorithm. An application of the proposed technique to a real-world dataset is presented at the end of the paper.},
  archive      = {J_KIS},
  author       = {Migliorini, Sara and Gambini, Mauro and Quintarelli, Elisa and Belussi, Alberto},
  doi          = {10.1007/s10115-023-01878-7},
  journal      = {Knowledge and Information Systems},
  month        = {10},
  number       = {10},
  pages        = {3967-3994},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Tracking social provenance in chains of retweets},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MIN: Multi-dimensional interest network for click-through
rate prediction. <em>KIS</em>, <em>65</em>(10), 3945–3965. (<a
href="https://doi.org/10.1007/s10115-023-01885-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Click-through rate (CTR) prediction is a critical task in recommender systems and online advertising systems. The extensive collection of behavior data has become popular for building prediction models by capturing user interests from behavior sequences. There are two types of entities involved in behavior sequences, users and items, which form three kinds of relationships: user-to-user, user-to-item, and item-to-item. Most related work focuses on only one or two of these relationships, often ignoring the association between users, which also helps discover potential user interests. In this paper, we consider all three relationships useful and propose a Multi-dimensional Interest Network (MIN) to focus on their impact on CTR prediction simultaneously. It consists of three sub-networks that capture users’ preferences regarding group interests and individual interests. Specifically, the u-u sub-network models the relationship between the target user and those who have clicked on the target item. It takes user representations learned from behavior sequences via transformer as input. Two other sub-networks capture the individual interest of the target user. The u-i sub-network models the relationship between the target user and the target item. The i-i sub-network models the relationship between the target item and the items the target user has interacted with in the past time. Extensive evaluations on the real datasets show that our MIN model outperforms the state-of-the-art solutions in prediction accuracy ( $$+$$ 5.0% in AUC and − 17.2% in Logloss, averagely). The ablation experiments also validate that each sub-network in MIN helps with improving the CTR prediction performance by using the u-u sub-network playing a more critical role. The source code is available at https://github.com/cocolixiao/MIN .},
  archive      = {J_KIS},
  author       = {Yan, Cairong and Li, Xiaoke and Zhang, Yanting and Wang, Zijian and Wan, Yongquan},
  doi          = {10.1007/s10115-023-01885-8},
  journal      = {Knowledge and Information Systems},
  month        = {10},
  number       = {10},
  pages        = {3945-3965},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {MIN: Multi-dimensional interest network for click-through rate prediction},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continual text classification based on knowledge
distillation and class-aware experience replay. <em>KIS</em>,
<em>65</em>(10), 3923–3944. (<a
href="https://doi.org/10.1007/s10115-023-01889-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual text classification aims at constantly classifying the texts from an infinite text stream while preserving stable classification performance on the seen texts. How to avoid catastrophic forgetting is a core issue in continual text classification. Most existing methods for handling catastrophic forgetting are based on regularization or replay. Usually, regularization-based strategies only consider one neural network layer and ignore the knowledge contained in other layers, and replay-based strategies neglect the class information. In the present paper, we introduce two strategies, knowledge distillation and class-aware experience replay, to consider two-level knowledge in a neural network and the class information to mitigate catastrophic forgetting. We use BERT as the encoder of our method. Extensive experimental results obtained on large-scale benchmarks show that our method is superior to the state-of-the-art methods under the continual learning setting.},
  archive      = {J_KIS},
  author       = {Yang, Fengqin and Che, Yinshu and Kang, Mei and Liu, Shuhua and Fu, Zhiguo},
  doi          = {10.1007/s10115-023-01889-4},
  journal      = {Knowledge and Information Systems},
  month        = {10},
  number       = {10},
  pages        = {3923-3944},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Continual text classification based on knowledge distillation and class-aware experience replay},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computer-aided diagnosis systems: A comparative study of
classical machine learning versus deep learning-based approaches.
<em>KIS</em>, <em>65</em>(10), 3881–3921. (<a
href="https://doi.org/10.1007/s10115-023-01894-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The diagnostic phase of the treatment process is essential for patient guidance and follow-up. The accuracy and effectiveness of this phase can determine the life or death of a patient. For the same symptoms, different doctors may come up with different diagnoses whose treatments may, instead of curing a patient, be fatal. Machine learning (ML) brings new solutions to healthcare professionals to save time and optimize the appropriate diagnosis. ML is a data analysis method that automates the creation of analytical models and promotes predictive data. There are several ML models and algorithms that rely on features extracted from, for example, a patient’s medical images to indicate whether a tumor is benign or malignant. The models differ in the way they operate and the method used to extract the discriminative features of the tumor. In this article, we review different ML models for tumor classification and COVID-19 infection to evaluate the different works. The computer-aided diagnosis (CAD) systems, which we referred to as classical, are based on accurate feature identification, usually performed manually or with other ML techniques that are not involved in classification. The deep learning-based CAD systems automatically perform the identification and extraction of discriminative features. The results show that the two types of DAC have quite close performances but the use of one or the other type depends on the datasets. Indeed, manual feature extraction is necessary when the size of the dataset is small; otherwise, deep learning is used.},
  archive      = {J_KIS},
  author       = {Guetari, Ramzi and Ayari, Helmi and Sakly, Houneida},
  doi          = {10.1007/s10115-023-01894-7},
  journal      = {Knowledge and Information Systems},
  month        = {10},
  number       = {10},
  pages        = {3881-3921},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Computer-aided diagnosis systems: A comparative study of classical machine learning versus deep learning-based approaches},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on rumor detection and prevention in social media
using deep learning. <em>KIS</em>, <em>65</em>(10), 3839–3880. (<a
href="https://doi.org/10.1007/s10115-023-01902-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current digital era, massive amounts of unreliable, purposefully misleading material, such as texts and images, are being shared widely on various web platforms to deceive the reader. Most of us use social media sites to exchange or obtain information. This opens a lot of space for false information, like fake news, rumors, etc., to spread that could harm a society’s social fabric, a person’s reputation, or the legitimacy of a whole country. Therefore, preventing the transmission of such dangerous material across platforms is a digital priority. However, the main goal of this survey paper is to thoroughly examine several current state-of-the-art research works on rumor control (detection and prevention) that use deep learning-based techniques and to identify major distinctions between these research efforts. The comparison results are intended to identify research gaps and challenges for rumor detection, tracking, and combating. This survey of the literature makes a significant contribution by highlighting several cutting-edge deep learning-based models for rumor detection in social media and critically evaluating their effectiveness on recently available standard datasets. Furthermore, to have a thorough grasp of rumor prevention to spread, we also looked into various pertinent approaches, including rumor veracity classification, stance classification, tracking, and combating. We also have created a summary of recent datasets with all the necessary information and analysis. Finally, as part of this survey, we have identified some of the potential research gaps and challenges that need to be addressed in order to develop early, effective methods of rumor control.},
  archive      = {J_KIS},
  author       = {Pattanaik, Barsha and Mandal, Sourav and Tripathy, Rudra M.},
  doi          = {10.1007/s10115-023-01902-w},
  journal      = {Knowledge and Information Systems},
  month        = {10},
  number       = {10},
  pages        = {3839-3880},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A survey on rumor detection and prevention in social media using deep learning},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge-based system for three-way decision-making under
uncertainty. <em>KIS</em>, <em>65</em>(9), 3807–3838. (<a
href="https://doi.org/10.1007/s10115-023-01882-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge-based systems developed based on Dempster–Shafer theory and prospect theory enhances decision-making under uncertainty. But at times, the traditional two-way decision approach may not be able to suggest a suitable decision confidently. This work proposes a three-way decision support system which divides the alternatives into three disjoint sets. Nonparametric Gaussian kernel and mid-range values are used to compute basic probabilities and reference points, respectively. The difference between basic probabilities and reference points is considered for assigning gain–loss values based on the value function from prospect theory. Ten publicly available benchmark data sets are considered, and the effectiveness of the proposed system is affirmed by comparing its performance with traditional machine learning models and other relevant decision-making systems in the literature. A case study related to evaluation of candidates is included, and it is also compared with other reference point estimation methods. From the results, it can be inferred that considering mid-range values as reference generates a preference order that is intuitive and compliable.},
  archive      = {J_KIS},
  author       = {Ramisetty, Kavya and Singh, Akshat and Christopher, Jabez and Panda, Subhrakanta},
  doi          = {10.1007/s10115-023-01882-x},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {3807-3838},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Knowledge-based system for three-way decision-making under uncertainty},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Garden: A real-time processing framework for continuous
top-k trajectory similarity search. <em>KIS</em>, <em>65</em>(9),
3777–3805. (<a
href="https://doi.org/10.1007/s10115-023-01880-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous top-k trajectory similarity Search (CkSearch) is now commonly required in real-time large-scale trajectory analysis, enabling the distributed stream processing engines to discover various dynamic patterns. As a fundamental operator, CkSearch empowers various applications, e.g., contact tracing during an outbreak and smart transportation. Although extensive efforts have been made to improve the efficiency of non-continuous top-k search, they do not consider dynamic capability of indexing (R1) and incremental capability of computing (R2). Therefore, in this paper, we propose a generic CkSearch-oriented framework for distributed real-time trajectory stream processing on Apache Flink, termed as Garden. To answer R1, we design a sophisticated distributed dynamic spatial index called Y-index, which consists of a real-time load scheduler and a two-layer indexing structure. To answer R2, we introduce a state reusing mechanism and index-based pruning methods that significantly reduce the computational cost. Empirical studies on real-world data validate the usefulness of our proposal and prove the huge advantage of our approach over state-of-the-art solutions in the literature.},
  archive      = {J_KIS},
  author       = {Pan, Zhicheng and Chao, Pingfu and Fang, Junhua and Chen, Wei and Xu, Jiajie and Zhao, Lei},
  doi          = {10.1007/s10115-023-01880-z},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {3777-3805},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Garden: A real-time processing framework for continuous top-k trajectory similarity search},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FoodRecNet: A comprehensively personalized food recommender
system using deep neural networks. <em>KIS</em>, <em>65</em>(9),
3753–3775. (<a
href="https://doi.org/10.1007/s10115-023-01897-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, the huge variety of foods and the existence of different food preferences among people have made it difficult to choose the right food according to people&#39;s food preferences for different meals. Also, achieving a pleasant balance between users’ food preferences and health requirements, considering the physical condition, diseases/allergies of users, and having a suitable dietary diversity, has become a requirement in the field of nutrition. Therefore, the need for an intelligent system to recommend and choose the proper food based on these criteria is felt more and more. In this paper, a deep learning-based food recommender system, termed “FoodRecNet”, is presented using a comprehensive set of characteristics and features of users and foods, including users’ long-term and short-term preferences, users’ health conditions, demographic information, culture, religion, food ingredients, type of cooking, food category, food tags, diet, allergies, text description, and even the images of the foods. The appropriate combination of features used in the proposed system has been identified based on detailed investigations conducted in this research. In order to achieve a desired architecture of the deep artificial neural network for our purpose, five different architectures are designed and evaluated, considering the specific characteristics of the intended application In addition, to evaluate the FoodRecNet, this work constructs a large-scale annotated dataset, consisting of 3,335,492 records of food information, users and their scores, and 54,554 food images. The experiments conducted on this dataset and the “FOOD.COM” benchmark dataset confirm the effectiveness of the combination of features used in FoodRecNet. The RMSE rates obtained by FoodRecNet on these two datasets are 0.7167 and 0.4930, respectively, which are much better than that of competitors. All the implementation source codes and datasets of this research are made publicly available at https://github.com/saeedhamdollahi/FoodRecNet .},
  archive      = {J_KIS},
  author       = {Hamdollahi Oskouei, Saeed and Hashemzadeh, Mahdi},
  doi          = {10.1007/s10115-023-01897-4},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {3753-3775},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {FoodRecNet: A comprehensively personalized food recommender system using deep neural networks},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Migrating federated learning to centralized learning with
the leverage of unlabeled data. <em>KIS</em>, <em>65</em>(9), 3725–3752.
(<a href="https://doi.org/10.1007/s10115-023-01869-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning carries out cooperative training without local data sharing; the obtained global model performs generally better than independent local models. Benefiting from the free data sharing, federated learning preserves the privacy of local users. However, the performance of the global model might be degraded if diverse clients hold non-IID training data. This is because the different distributions of local data lead to weight divergence of local models. In this paper, we introduce a novel teacher–student framework to alleviate the negative impact of non-IID data. On the one hand, we maintain the advantage of the federated learning on the privacy-preserving, and on the other hand, we take the advantage of the centralized learning on the accuracy. We use unlabeled data and global models as teachers to generate a pseudo-labeled dataset, which can significantly improve the performance of the global model. At the same time, the global model as a teacher provides more accurate pseudo-labels. In addition, we perform a model rollback to mitigate the impact of latent noise labels and data imbalance in the pseudo-labeled dataset. Extensive experiments have verified that our teacher ensemble performs a more robust training. The empirical study verifies that the reliance on the centralized pseudo-labeled data enables the global model almost immune to non-IID data.},
  archive      = {J_KIS},
  author       = {Wang, Xiaoya and Zhu, Tianqing and Ren, Wei and Zhang, Dongmei and Xiong, Ping},
  doi          = {10.1007/s10115-023-01869-8},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {3725-3752},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Migrating federated learning to centralized learning with the leverage of unlabeled data},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel scheme to detect the best cloud service provider
using logarithmic operational law in generalized spherical fuzzy
environment. <em>KIS</em>, <em>65</em>(9), 3695–3724. (<a
href="https://doi.org/10.1007/s10115-023-01873-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized spherical fuzzy number (GSFN) is an extension of spherical fuzzy number (SFN) which deals the uncertainties involved in the real-life problems in much better way than other fuzzy numbers. So far, some fundamental operational laws of GSFNs are characterized, yet excluding the logarithmic operation. In this manuscript, we have defined and discussed various algebraic properties of logarithmic operational law (LOL) for GSFN where the logarithmic base $$\delta $$ is a positive real number. Moreover, we have developed weighted averaging and weighted geometric aggregation operators and utilize these aggregation operators to initiate a multi-criteria group decision making (MCGDM) technique in the generalized spherical fuzzy (GSF) environment, which has been used to solve a problem of cloud service management. We have indicated the utility and reliability of the proposed MCGDM technique through sensitivity analysis. Finally, a comparative study has been presented with the help of a real data set to justify the rationality and efficiency of our proposed method with the existing methods.},
  archive      = {J_KIS},
  author       = {Haque, Tipu Sultan and Chakraborty, Avishek and Alam, Shariful},
  doi          = {10.1007/s10115-023-01873-y},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {3695-3724},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A novel scheme to detect the best cloud service provider using logarithmic operational law in generalized spherical fuzzy environment},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A consensus reaching process with hesitant fuzzy elements
considers the individuals best and worst consensus levels. <em>KIS</em>,
<em>65</em>(9), 3665–3693. (<a
href="https://doi.org/10.1007/s10115-023-01874-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purposes of the study: to address the situation where multi-criteria decision-making (MCDM) problems with hesitant fuzzy elements (HFEs), this study develops group decision-making method considering the individuals best and worst consensus levels simultaneously. Procedures: first, the concepts of individual best and worst consensus levels are proposed, and then, the concept of acceptable consensus level is developed. Second, several optimization models are constructed for improving the consensus levels. Third, the proposed consensus checking and improving processes are extended to incomplete evaluation information. Fourth, an algorithm is designed for deriving the priority weights of decision-makers. Finally, an illustrative example in conjunction with comparative analysis is provided. Findings: the concept of acceptable individual consensus level with HFEs not only overcomes the shortcoming of difficult to achieve owing to too restricted, but also the loss of information owing to too loose. The consensus improving process considers all the evaluation information and avoids the loss of information. Conclusions: Several programming models are constructed to improve the consensus level with HFEs. This provides the direction of the decision-makers to revise their evaluation values, and the consensus improving process is time-saving and easy to extend to incomplete evaluation information.},
  archive      = {J_KIS},
  author       = {Li, Jian and Niu, Li-li and Chen, Qiongxia and Li, Feilong and Wei, Limei and Wang, Zhong-xing},
  doi          = {10.1007/s10115-023-01874-x},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {3665-3693},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A consensus reaching process with hesitant fuzzy elements considers the individuals best and worst consensus levels},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic generation of incremental taxonomies for
supporting the users in the development of an RPA project. <em>KIS</em>,
<em>65</em>(9), 3633–3664. (<a
href="https://doi.org/10.1007/s10115-023-01876-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The robotic process automation (RPA) paradigm is a discipline that is becoming increasingly popular thanks to the great interest shown by the industry. In such context, RPA solutions based on artificial intelligence, i.e., cognitive solutions, are receiving increasing attention. In a cognitive RPA project, the RPA developer is in charge of selecting the most suitable components that solve specific tasks from the sets of components provided by different RPA platforms. This selection is very challenging, especially since there is no homogeneity in component names or component classifications. Such a situation turns an RPA project’s development into a time-consuming, error-prone, and very tedious process. Therefore, supporting the RPA developer in developing a cognitive RPA project is desired. The industry has also pointed out this need. This work presents a proposal for supporting the users in developing a cognitive RPA project. To be more precise, an incremental method to automatically generate taxonomies from cognitive RPA platforms is proposed. Such taxonomies can be dynamically adapted when necessary. In previous work, the initial aspects of this research were presented. However, the current work greatly enhances such previous work by: (1) extending the proposed method to improve the management of real-world use cases from industry, (2) developing a proof-of-concept tool that is based on the proposed approach, (3) validating the proposed method by applying it to real-world use cases from industry, and (4) performing a literature review on related topics. The results obtained are auspicious and demonstrate that the proposed approach substantially improves the support given to users during the development of a cognitive RPA project.},
  archive      = {J_KIS},
  author       = {Martínez-Rojas, Antonio and Barba, Irene and Del Valle, Carmelo and Jiménez-Ramírez, Andrés and González-Enríquez, José},
  doi          = {10.1007/s10115-023-01876-9},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {3633-3664},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Automatic generation of incremental taxonomies for supporting the users in the development of an RPA project},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge graph incremental embedding for unseen modalities.
<em>KIS</em>, <em>65</em>(9), 3611–3631. (<a
href="https://doi.org/10.1007/s10115-023-01868-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding (KGE) projects entities and relations into low-dimension continuous vector space, which promotes the widespread use of knowledge graphs in many downstream applications. Despite the fact that most of existing KGE models focus on static single-modal knowledge graphs, many knowledge graphs are incremental and multi-modal in the real world. Especially, the incremental entities are accompanied by new modalities, i.e., unseen modalities in background knowledge graphs. To well address the novel task, i.e., incrementally embed the new entities with unseen modal information effectively and efficiently, we propose a novel incremental multi-modal knowledge graph embedding model entitled Multi-Modal Rotating on Hyperplanes, which consists of the following two modules. (1) To gain a high-quality background KGE space, the module Background Knowledge Graph Embedding Module is developed to fuse seen modal information with a gated multi-modal encoder and decode the triples by a rotation-based KGE model. (2) The module Incremental Knowledge Graph Embedding Module is designed to fuse unseen modal information of incremental entities and incrementally embed the new entities into the trained embedding space. Extensive experiments are conducted on two real-world multi-modal datasets, and the results demonstrate the superiority of the proposed model in terms of both effectiveness and efficiency compared with the state-of-the-art approaches.},
  archive      = {J_KIS},
  author       = {Wei, Yuyang and Chen, Wei and Wen, Shiting and Liu, An and Zhao, Lei},
  doi          = {10.1007/s10115-023-01868-9},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {3611-3631},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Knowledge graph incremental embedding for unseen modalities},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Entity graphs for exploring online discourse. <em>KIS</em>,
<em>65</em>(9), 3591–3609. (<a
href="https://doi.org/10.1007/s10115-023-01877-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A vast amount of human communication occurs online. These digital traces of natural human communication along with recent advances in natural language processing technology provide for computational analysis of these discussions. In the study of social networks, the typical perspective is to view users as nodes and concepts as flowing through and among the user nodes within the social network. In the present work, we take the opposite perspective: we extract and organize massive amounts of group discussion into a concept space we call an entity graph where concepts and entities are static and human communicators move about the concept space via their conversations. Framed by this perspective, we performed several experiments and comparative analysis on large volumes of online discourse from Reddit. In quantitative experiments, we found that discourse was difficult to predict, especially as the conversation carried on. We also developed an interactive tool to visually inspect conversation trails over the entity graph; although they were difficult to predict, we found that conversations, in general, tended to diverge to a vast swath of topics initially, but then tended to converge to simple and popular concepts as the conversation progressed. An application of the spreading activation function from the field of cognitive psychology also provided compelling visual narratives from the data.},
  archive      = {J_KIS},
  author       = {Botzer, Nicholas and Weninger, Tim},
  doi          = {10.1007/s10115-023-01877-8},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {3591-3609},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Entity graphs for exploring online discourse},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CP-nets-based user preference learning in automated
negotiation through completion and correction. <em>KIS</em>,
<em>65</em>(9), 3567–3590. (<a
href="https://doi.org/10.1007/s10115-023-01872-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User preference learning is an important process in automated negotiation, because only when the negotiating agents are able to fully grasp the user preference information can the negotiation strategy play its due role. However, in most automated negotiation systems, user preference is assumed to be complete and correct, which is quite different from the reality. In real life, user preference is often complex and incomplete, which hinders the application of automated negotiation research in practice. To this end, this paper focuses on the learning method of user preference in negotiation. Since CP-nets can intuitively express the interdependence among negotiation issues, which have good interpretability and expansibility, they have become one of most important representations of user preference in automated negotiation. Therefore, we propose a CP-nets-based user preference learning module in negotiation framework, which consists of both passive learning and active learning methods. In passive learning, we propose an algorithm to construct complete CP-nets with incomplete user preference information. In active learning, we innovatively propose the structural query method, which improves the accuracy of preference learning represented by CP-nets with less query cost. The experimental results show that the module is effective for negotiation framework and can help users reach better agreements in negotiation.},
  archive      = {J_KIS},
  author       = {Cai, Jianlong and Zhan, Jieyu and Jiang, Yuncheng},
  doi          = {10.1007/s10115-023-01872-z},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {3567-3590},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {CP-nets-based user preference learning in automated negotiation through completion and correction},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cutting to the chase with warm-start contextual bandits.
<em>KIS</em>, <em>65</em>(9), 3533–3565. (<a
href="https://doi.org/10.1007/s10115-023-01861-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-armed bandits achieve excellent long-term performance in practice and sublinear cumulative regret in theory. However, a real-world limitation of bandit learning is poor performance in early rounds due to the need for exploration—a phenomenon known as the cold-start problem. While this limitation may be necessary in the general classical stochastic setting, in practice where “pre-training” data or knowledge is available, it is natural to attempt to “warm-start” bandit learners. This paper provides a theoretical treatment of warm-start contextual bandit learning, adopting Linear Thompson Sampling as a principled framework for flexibly transferring domain knowledge as might be captured by bandit learning in a prior related task, a supervised pre-trained Bayesian posterior, or domain expert knowledge. Under standard conditions, we prove a general regret bound. We then apply our warm-start algorithmic technique to other common bandit learners—the $$\epsilon $$ -greedy and upper-confidence bound contextual learners. An upper regret bound is then provided for LinUCB. Our suite of warm-start learners are evaluated in experiments with both artificial and real-world datasets, including a motivating task of tuning a commercial database. A comprehensive range of experimental results are presented, highlighting the effect of different hyperparameters and quantities of pre-training data.},
  archive      = {J_KIS},
  author       = {Oetomo, Bastian and Perera, R. Malinga and Borovica-Gajic, Renata and Rubinstein, Benjamin I. P.},
  doi          = {10.1007/s10115-023-01861-2},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {3533-3565},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Cutting to the chase with warm-start contextual bandits},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cybersecurity knowledge graphs. <em>KIS</em>,
<em>65</em>(9), 3511–3531. (<a
href="https://doi.org/10.1007/s10115-023-01860-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cybersecurity knowledge graphs, which represent cyber-knowledge with a graph-based data model, provide holistic approaches for processing massive volumes of complex cybersecurity data derived from diverse sources. They can assist security analysts to obtain cyberthreat intelligence, achieve a high level of cyber-situational awareness, discover new cyber-knowledge, visualize networks, data flow, and attack paths, and understand data correlations by aggregating and fusing data. This paper reviews the most prominent graph-based data models used in this domain, along with knowledge organization systems that define concepts and properties utilized in formal cyber-knowledge representation for both background knowledge and specific expert knowledge about an actual system or attack. It is also discussed how cybersecurity knowledge graphs enable machine learning and facilitate automated reasoning over cyber-knowledge.},
  archive      = {J_KIS},
  author       = {Sikos, Leslie F.},
  doi          = {10.1007/s10115-023-01860-3},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {3511-3531},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Cybersecurity knowledge graphs},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new fuzzy time series forecasting model based on
clustering technique and normal fuzzy function. <em>KIS</em>,
<em>65</em>(8), 3489–3509. (<a
href="https://doi.org/10.1007/s10115-023-01875-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting is of great interest to managers and scientists because of the numerous benefits it offers. This study proposes three main improvements for forecasting to time series. First, we establish the percentage variation series between two consecutive times and use an automatic algorithm to divide it into clusters with a suitable number. This algorithm also determines the specific elements in each cluster. Second, a new fuzzy function with a normal type is built for each cluster. Finally, we develop the forecasting rule based on the previous two improvements. By combining these enhancements, we obtain an effective model for forecasting. The proposed model is presented step-by-step and executed rapidly using the MATLAB procedure. Compared to many models tested on the M3-Competition set with 3003 series and the M4-Competition set with 100,000 series, the proposed model obtains outstanding results. It also achieves competitive results when compared to existing models across several benchmarks and real series.},
  archive      = {J_KIS},
  author       = {Nguyen-Huynh, Luan and Vo-Van, Tai},
  doi          = {10.1007/s10115-023-01875-w},
  journal      = {Knowledge and Information Systems},
  month        = {8},
  number       = {8},
  pages        = {3489-3509},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A new fuzzy time series forecasting model based on clustering technique and normal fuzzy function},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DisGeReExT: A knowledge discovery system for exploration of
disease–gene associations through large-scale literature-wide analysis
study. <em>KIS</em>, <em>65</em>(8), 3463–3487. (<a
href="https://doi.org/10.1007/s10115-023-01862-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective Advanced experimental methods such as next-generation sequencing (NGS) produced a large number of potential indicative genetic biomarkers and gene variants to diseases mentioned as research outputs in the scientific literature. To elucidate novel biomarkers and therapeutic candidates from this larger number of literature, highly sophisticated text mining-based knowledge-driven frameworks are a necessity. Materials and Methods This paper presents DisGeReExT Web server for performing a literature-wide analysis study (LWAS) to extract both direct and indirect gene–disease associations using joint ensemble learning (explicit) along with concept profiling using the ABC principle (implicit) for prioritizing and rationalizing potential informative discoveries of the genetic role on diseases. In addition, we ranked the informative sentences using a scoring model and calculated the disease–disease similarity using functional association among shared genes. Results From complete MEDLINE corpus dated September 2020 with 28 million records, DisGeReExT identified a total of 2,237,545 gene–disease associations and 2,851,662 disease–disease similarities. Discussion DisGeReExT was able to extract informative sentences related to both diseases and genes in large scale. It also explored the gene–disease association of two diseases, namely Alzheimer’s disease and liver carcinoma, and identified its top 10 associated genes and diseases of both diseases. Conclusion Overall, we strongly believe that our large-scale automated approach for knowledge discovery of gene-associated diseases from literature could provide new insights into the genetic mechanism and disease etiology and can play a pivotal role in translational research, drug discovery, and repurposing.},
  archive      = {J_KIS},
  author       = {Bhasuran, Balu and Natarajan, Jeyakumar},
  doi          = {10.1007/s10115-023-01862-1},
  journal      = {Knowledge and Information Systems},
  month        = {8},
  number       = {8},
  pages        = {3463-3487},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {DisGeReExT: A knowledge discovery system for exploration of disease–gene associations through large-scale literature-wide analysis study},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast data-free model compression via dictionary-pair
reconstruction. <em>KIS</em>, <em>65</em>(8), 3435–3461. (<a
href="https://doi.org/10.1007/s10115-023-01846-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural network (DNN) obtained satisfactory results on different vision tasks; however, they usually suffer from large models and massive parameters during model deployment. While DNN compression can reduce the memory footprint of deep model effectively, so that the deep model can be deployed on portable devices. However, most of the existing model compression methods cost lots of time, e.g., vector quantization or pruning, which makes them inept to the application that needs fast computation. In this paper, we therefore explore how to accelerate the model compression process by reducing the computation cost. Then, we propose a new model compression method, termed dictionary-pair-based fast data-free DNN compression, which aims at reducing the memory consumption of DNNs without extra training and can greatly improve the compression efficiency. Specifically, our method performs tensor decomposition of DNN model with a fast dictionary-pair learning-based reconstruction approach, which can be deployed on different weight layers (e.g., convolution and fully connected layers). Given a pre-trained DNN model, we first divide the parameters (i.e., weights) of each layer into a series of partitions for dictionary pair-driven fast reconstruction, which can potentially discover more fine-grained information and provide the possibility for parallel model compression. Then, dictionaries of less memory occupation are learned to reconstruct the weights. Moreover, automatic hyper-parameter tuning and shared-dictionary mechanism is proposed to improve the model performance and availability. Extensive experiments on popular DNN models (i.e., VGG-16, ResNet-18 and ResNet-50) showed that our proposed weight compression method can significantly reduce the memory footprint and speed up the compression process, with less performance loss.},
  archive      = {J_KIS},
  author       = {Gao, Yangcheng and Zhang, Zhao and Zhang, Haijun and Zhao, Mingbo and Yang, Yi and Wang, Meng},
  doi          = {10.1007/s10115-023-01846-1},
  journal      = {Knowledge and Information Systems},
  month        = {8},
  number       = {8},
  pages        = {3435-3461},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Fast data-free model compression via dictionary-pair reconstruction},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The impact of prior knowledge on causal structure learning.
<em>KIS</em>, <em>65</em>(8), 3385–3434. (<a
href="https://doi.org/10.1007/s10115-023-01858-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal Bayesian networks have become a powerful technology for reasoning under uncertainty in areas that require transparency and explainability, by relying on causal assumptions that enable us to simulate hypothetical interventions. The graphical structure of such models can be estimated by structure learning algorithms, domain knowledge, or a combination of both. Various knowledge approaches have been proposed in the literature that enables us to specify prior knowledge that constrains or guides these algorithms. This paper introduces some novel, and also describes some existing, knowledge-based approaches that enable us to combine structure learning with knowledge obtained from heterogeneous sources. We investigate the impact of these approaches on structure learning across different algorithms, case studies and settings that we might encounter in practice. Each approach is assessed in terms of effectiveness and efficiency, including graphical accuracy, model fitting, complexity, and runtime; making this the first paper that provides a comparative evaluation of a wide range of knowledge approaches for structure learning. Because the value of knowledge depends on what data are available, we illustrate the results both with limited and big data. While the overall results show that knowledge becomes less important with big data due to higher learning accuracy rendering knowledge less important, some of the knowledge approaches are found to be more important with big data. Amongst the main conclusions is the observation that reduced search space obtained from knowledge does not always imply reduced computational complexity, perhaps because the relationships implied by the data and knowledge are in tension.},
  archive      = {J_KIS},
  author       = {Constantinou, Anthony C. and Guo, Zhigao and Kitson, Neville K.},
  doi          = {10.1007/s10115-023-01858-x},
  journal      = {Knowledge and Information Systems},
  month        = {8},
  number       = {8},
  pages        = {3385-3434},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {The impact of prior knowledge on causal structure learning},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). COOT optimization algorithm on training artificial neural
networks. <em>KIS</em>, <em>65</em>(8), 3353–3383. (<a
href="https://doi.org/10.1007/s10115-023-01859-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, significant advancements have been made in artificial neural network models and they have been applied to a variety of real-world problems. However, one of the limitations of artificial neural networks is that they can getting stuck in local minima during the training phase, which is a consequence of their use of gradient descent-based techniques. This negatively impacts the generalization performance of the network. In this study, it is proposed a new hybrid artificial neural network model called COOT-ANN, which uses the coot optimization algorithm firstly for optimizing artificial neural networks parameters, a metaheuristic-based approach. The COOT-ANN model does not get stuck in local minima during the training phase due to the use of metaheuristic-based optimization algorithm. The results of the study demonstrate that the proposed method is quite successful in terms of accuracy, cross-entropy, F1-score, and Cohen’s Kappa metrics when compared to gradient descent, scaled conjugate gradient, and Levenberg–Marquardt optimization techniques.},
  archive      = {J_KIS},
  author       = {Özden, Ayşenur and İşeri, İsmail},
  doi          = {10.1007/s10115-023-01859-w},
  journal      = {Knowledge and Information Systems},
  month        = {8},
  number       = {8},
  pages        = {3353-3383},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {COOT optimization algorithm on training artificial neural networks},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new interest extraction method based on multi-head
attention mechanism for CTR prediction. <em>KIS</em>, <em>65</em>(8),
3337–3352. (<a
href="https://doi.org/10.1007/s10115-023-01867-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Click-through rate (CTR) prediction plays a vital role in recommendation systems. Most models pay little attention to the relationship between target items in the user behavior sequence. The attention units used in these models cannot fully capture the context information, which can be used to reflect the variations of user interests. To address these problems, we propose a new model named interest extraction method based on multi-head attention mechanism (IEN) for CTR prediction. Specifically, we design an interest extraction module, which consists of two sub-modules: the item representation module (IRM) and the context–item interaction module (CIM). In IRM, we learn the relationship between target items in the user behavior sequence by a multi-head attention mechanism. Then, the user representation is gained by integrating the refined item representation and position information. At last, the correlation between the user and the target item is used to reflect user interests. In CIM, the context information has valuable temporal features which can reflect the variations of user interests. Therefore, user interests can be further acquired through the feature interaction between the context and the target item. After that, the learned relevance and the feature interaction are fed to the multi-layer perceptron (MLP) for prediction. Besides, experiments on four Amazon datasets were conducted to evaluate the effectiveness of our method in capturing user interests. The experimental results show that our proposed method outperforms state-of-the-art methods in terms of AUC and RI in the CTR prediction task.},
  archive      = {J_KIS},
  author       = {Yang, Haifeng and Yao, Linjing and Cai, Jianghui and Wang, Yupeng and Zhao, Xujun},
  doi          = {10.1007/s10115-023-01867-w},
  journal      = {Knowledge and Information Systems},
  month        = {8},
  number       = {8},
  pages        = {3337-3352},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A new interest extraction method based on multi-head attention mechanism for CTR prediction},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mining frequent generators and closures in data streams with
FGC-stream. <em>KIS</em>, <em>65</em>(8), 3295–3335. (<a
href="https://doi.org/10.1007/s10115-023-01852-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mining frequent itemsets (FIs) from data streams is a challenging task due to the limited resources available w.r.t. the typically large size of the result and the need for frequent recalculations due to data evolution. Therefore, the mining of condensed representations, e.g. frequent closures (FCIs) or generators (FGIs), instead of plain FIs, has been explored. So far the tasks of mining FGIs and FCIs have only been addressed separately over data streams. Yet, both itemset families combine in the solutions of a range of practical problems while they also underlie the definition of handy association rule bases. To date, the joint mining task can only be approached by a combining two dedicated miners. As a remedy, we propose a holistic approach rooted in the support set-based equivalence classes underlying a transaction dataset: the ensuing $$\textit{FGC-Stream}$$ miner exploits some mathematical results about those classes’ evolution to efficiently update both FCIs and FGIs. Thus, targeting a sliding window mode—where the window over a stream expands and shrinks—we enhance results from formal concept analysis to design an efficient expansion procedure. On window shrinking, we exploit some thoroughly new results about class evolution. Overall, $$\textit{FGC-Stream}$$ achieves significant effort factoring through the collaborative maintenance of FCIs and FGIs. As a result, when confronted experimentally, it managed to largely outperform its unique FGI mining competitor while keeping up with two of the most efficient FCI miners. This outcome confirms that $$\textit{FGC-Stream}$$ will dominate any combination of miners for the joint task. This article is an extended version of our paper [27] presented at the 21st International Conference on Data Mining.},
  archive      = {J_KIS},
  author       = {Martin, Tomas and Valtchev, Petko and Roux, Louis-Romain},
  doi          = {10.1007/s10115-023-01852-3},
  journal      = {Knowledge and Information Systems},
  month        = {8},
  number       = {8},
  pages        = {3295-3335},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Mining frequent generators and closures in data streams with FGC-stream},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Grier: Graph repairing based on iterative embedding and
rules. <em>KIS</em>, <em>65</em>(8), 3273–3294. (<a
href="https://doi.org/10.1007/s10115-023-01866-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying and repairing the erroneous and missing information in the graphs is crucial. Rule-based studies rely on graph quality rules to detect the inconsistencies among different entities and make a one-time repair to resolve these inconsistencies. The missing data can be predicted and imputed by graph embedding methods by preserving the inherent structure of a reliable graph. However, both lines of way need more evidence to improve. In this paper, we propose Grier, a novel repairing method to enrich the evidence by taking advantage of rule-based repairing and graph embedding. Specifically, Grier iteratively learns the graph embeddings with guidance from logical rules, which has significant power in knowledge acquisition and inference. The erroneous triples are detected and repaired by evaluating the correctness of the triples in the embedding space. The newly repaired triples are used as training data to update the embedding module for better learning. Extensive experiments on three graphs demonstrate the effectiveness of Grier even with very few rules.},
  archive      = {J_KIS},
  author       = {Ye, Chen and Xu, Hong and Zhang, Hua and Wu, Yifan and Dai, Guojun},
  doi          = {10.1007/s10115-023-01866-x},
  journal      = {Knowledge and Information Systems},
  month        = {8},
  number       = {8},
  pages        = {3273-3294},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Grier: Graph repairing based on iterative embedding and rules},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stable and semi-stable sampling approaches for continuously
used samples. <em>KIS</em>, <em>65</em>(8), 3251–3271. (<a
href="https://doi.org/10.1007/s10115-022-01806-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge and information systems are usually measured by labeling the relevance of results corresponding to a sample of user queries. In practical systems like search engines, such measurement needs to be performed continuously, such as daily or weekly. This creates a trade-off between (a) representativeness of query sample to current query traffic of the product; (b) labeling cost—if we keep the same query sample, results would be similar allowing us to reuse their labels; and (c) overfitting caused by continuous usage of same query sample. In this paper, we explicitly formulate this tradeoff, propose two new variants—stable and semi-stable—to simple and weighted random sampling and show that they outperform existing approaches for the continuous usage settings, including monitoring/debugging search engine or comparing ranker candidates.},
  archive      = {J_KIS},
  author       = {Astrakhantsev, Nikita and Chittajallu, Deepak Roy and Kaushal, Nabeel and Mokeev, Vladislav},
  doi          = {10.1007/s10115-022-01806-1},
  journal      = {Knowledge and Information Systems},
  month        = {8},
  number       = {8},
  pages        = {3251-3271},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Stable and semi-stable sampling approaches for continuously used samples},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Physics-guided machine learning from simulated data with
different physical parameters. <em>KIS</em>, <em>65</em>(8), 3223–3250.
(<a href="https://doi.org/10.1007/s10115-023-01864-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-based models are widely used to study dynamical systems in a variety of scientific and engineering problems. However, these models are necessarily approximations of reality due to incomplete knowledge or excessive complexity in modeling underlying processes. As a result, they often produce biased simulations due to inaccurate parameterizations or approximations used to represent the true physics. In this paper, we aim to build a new physics-guided machine learning framework to monitor dynamical systems. The idea is to use advanced machine learning model to extract complex spatio-temporal data patterns while also incorporating general scientific knowledge embodied in simulated data generated by the physics-based model. To handle the bias in simulated data caused by imperfect parameterization, we propose to extract general physical relations jointly from multiple sets of simulations generated by a physics-based model under different physical parameters. In particular, we develop a spatio-temporal network architecture that uses its gating variables to capture the variation of physical parameters. We initialize this model using a pre-training strategy that helps discover common physical patterns shared by different sets of simulated data. Then, we fine-tune it combining limited observations and adequate simulations. By leveraging the complementary strength of machine learning and domain knowledge, our method has been shown to produce accurate predictions, use less training samples and generalize to out-of-sample scenarios. We further show that the method can provide insights about the variation of physical parameters over space and time in two domain applications: predicting temperature in streams and predicting temperature in lakes.},
  archive      = {J_KIS},
  author       = {Chen, Shengyu and Kalanat, Nasrin and Xie, Yiqun and Li, Sheng and Zwart, Jacob A. and Sadler, Jeffrey M. and Appling, Alison P. and Oliver, Samantha K. and Read, Jordan S. and Jia, Xiaowei},
  doi          = {10.1007/s10115-023-01864-z},
  journal      = {Knowledge and Information Systems},
  month        = {8},
  number       = {8},
  pages        = {3223-3250},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Physics-guided machine learning from simulated data with different physical parameters},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A combined approach for improving humanoid robots autonomous
cognitive capabilities. <em>KIS</em>, <em>65</em>(8), 3197–3221. (<a
href="https://doi.org/10.1007/s10115-023-01844-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent technologies advancements promise to change our lives dramatically in the near future. A new different living society is progressively emerging, witnessed from the conception of novel digital ecosystems, where humans are expected to share their own spaces and habits with machines. Humanoid robots are more and more being developed and provided with enriched functionalities; however, they are still lacking in many ways. One important goal in this sense is to enrich their cognitive capabilities, to make them more “intelligent” in order to better support humans in both daily and special activities. The goal of this research is to set a step in bridging the gap between symbolic AI and connectionist approaches in the context of knowledge acquisition and conceptualization. Hence, we present a combined approach based on semantics and machine learning techniques for improving robots cognitive capabilities. This is part of a wider framework that covers several aspects of knowledge management, from representation and conceptualization, to acquisition, sharing and interaction with humans. Our focus in this work is in particular on the development and implementation of techniques for knowledge acquisition. Such techniques are discussed and validated through experiments, carried out on a real robotic platform, showing the effectiveness of our approach. The results obtained confirmed that the combination of the approaches gives superior performance with respect to when they are considered individually.},
  archive      = {J_KIS},
  author       = {Madani, Kurosh and Rinaldi, Antonio M. and Russo, Cristiano and Tommasino, Cristian},
  doi          = {10.1007/s10115-023-01844-3},
  journal      = {Knowledge and Information Systems},
  month        = {8},
  number       = {8},
  pages        = {3197-3221},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A combined approach for improving humanoid robots autonomous cognitive capabilities},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data management in digital twins: A systematic literature
review. <em>KIS</em>, <em>65</em>(8), 3165–3196. (<a
href="https://doi.org/10.1007/s10115-023-01870-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) and continuous advances in data-gathering devices and techniques have significantly increased the amount of relevant data that can be leveraged for innovative real-time, data-driven applications. Digital Twins (DTs) are virtual representations of physical objects, which are fully integrated and in which the automatic data exchange occurs in a bidirectional way. Modern DTs follow a five-component architecture, which includes an explicit Data Management (DM) component that acts as a bridge between the other systems. However, there is no clarity on its role and functionalities. This article presents a Systematic Literature Review on DM solutions proposed in the DT context. We analyzed DM under the Big Data chain of activities to add value to data, highlighting key issues to be addressed: data heterogeneity, interoperability, integration, data search, and quality. In addition to surveying existing solutions for handling these issues, we contextualized them in the domain and function for which the DT was proposed, the type of data dealt with, and the technological infrastructure. Our main findings revealed that the maturity level assumed for the DM component is at an early stage. The most mature solutions were proposed for the industry domain, and many of them assume humans as the ultimate information consumers. Data integration is the prevalent DM issue addressed due to the bridging role of the DM component, and cloud computing is the key implementation technology. Among the research opportunities are reference data management architectures, adoption of industry standards and ontologies, interoperability among distinct DTs, the development of agnostic standard implementations, and data provenance mechanisms.},
  archive      = {J_KIS},
  author       = {Correia, Jaqueline B. and Abel, Mara and Becker, Karin},
  doi          = {10.1007/s10115-023-01870-1},
  journal      = {Knowledge and Information Systems},
  month        = {8},
  number       = {8},
  pages        = {3165-3196},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Data management in digital twins: A systematic literature review},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A domain adaptation method by incorporating belief function
in twin quarter-sphere SVM. <em>KIS</em>, <em>65</em>(7), 3125–3163. (<a
href="https://doi.org/10.1007/s10115-023-01857-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation is a representative problem in transfer learning, which aims to tackle the problem of insufficient labeled data in a target domain by exploiting discriminant information from a labeled source domain. Since the source and target domains follow different distributions, source domain data are uncertain with respect to the target domain. Ignoring the uncertainty may lead to unreliable label prediction for the target domain. Despite the many studies that have been done on domain adaptation, most have ignored the adverse impact of uncertain and noisy data on learning an adaptive classifier. Regarding these issues, the present paper introduces a robust to noise domain adaptation method by extending the quarter-sphere SVM classifier. Essentially, the proposed method builds an individual classifier for each available class per domain. Also, a belief theory-based weighting approach is designed to provide noise robustness. The strength of the proposed method is that after constructing and training the source domain classifiers, accessibility to the source domain data is not required, and the existence of only the source domain hyperspheres is sufficient. The effectiveness of the proposed method has been compared to the state-of-the-art methods on 15 tasks taken from two benchmark datasets. The experimental results demonstrate the superiority of the proposed method over state-of-the-art ones in terms of classification accuracy and computational time. Besides, the noise analysis proves the robustness of the proposed method. To prove a meaningful distinction between the evaluation metrics results of the proposed method and the competing ones, the Wilcoxon statistical test has been conducted.},
  archive      = {J_KIS},
  author       = {Moradi, Mona and Hamidzadeh, Javad},
  doi          = {10.1007/s10115-023-01857-y},
  journal      = {Knowledge and Information Systems},
  month        = {7},
  number       = {7},
  pages        = {3125-3163},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A domain adaptation method by incorporating belief function in twin quarter-sphere SVM},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Motif-guided heterogeneous graph deep generation.
<em>KIS</em>, <em>65</em>(7), 3099–3124. (<a
href="https://doi.org/10.1007/s10115-023-01863-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex systems in the real-world are commonly associated with multiple types of objects and relations, and heterogeneous graphs are ubiquitous data structures that can inherently represent multimodal interactions between objects. Generating high-quality heterogeneous graphs allows us to understand the implicit distribution of heterogeneous graphs and provides benchmarks for downstream heterogeneous representation learning tasks. Existing works are limited to either merely generating the graph topology with neglecting local semantic information or only generating the graph without preserving the higher-order structural information and the global heterogeneous distribution in generated graphs. To this end, we formulate a general, end-to-end framework— HGEN for generating novel heterogeneous graphs with a newly proposed heterogeneous walk generator. On top of HGEN, we further develop a network motif generator to better characterize the higher-order structural distribution. A novel heterogeneous graph assembler is further developed to adaptively assemble novel heterogeneous graphs from the generated heterogeneous walks and motifs in a stratified manner. The extended model is proven to preserve the local semantic and heterogeneous global distribution of observed graphs with the theoretical guarantee. Lastly, comprehensive experiments on both synthetic and real-world practical datasets demonstrate the power and efficiency of the proposed method.},
  archive      = {J_KIS},
  author       = {Ling, Chen and Yang, Carl and Zhao, Liang},
  doi          = {10.1007/s10115-023-01863-0},
  journal      = {Knowledge and Information Systems},
  month        = {7},
  number       = {7},
  pages        = {3099-3124},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Motif-guided heterogeneous graph deep generation},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sequence likelihood divergence for fast time series
comparison. <em>KIS</em>, <em>65</em>(7), 3079–3098. (<a
href="https://doi.org/10.1007/s10115-023-01855-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Comparing and contrasting subtle historical patterns is central to time series analysis. Here we introduce a new approach to quantify deviations in the underlying hidden stochastic generators of sequential discrete-valued data streams. The proposed measure is universal in the sense that we can compare data streams without any feature engineering step, and without the need of any hyper-parameters. Our core idea here is the generalization of the Kullback–Leibler divergence, often used to compare probability distributions, to a notion of divergence between finite-valued ergodic stationary stochastic processes. Using this notion of process divergence, we craft a measure of deviation on finite sample paths which we call the sequence likelihood divergence (SLD) which approximates a metric on the space of the underlying generators within a well-defined class of discrete-valued stochastic processes. We compare the performance of SLD against the state of the art approaches, e.g., dynamic time warping (Petitjean et al. in Pattern Recognit 44(3):678–693, 2011) with synthetic data, real-world applications with electroencephalogram data and in gait recognition, and on diverse time-series classification problems from the University of California, Riverside time series classification archive (Thanawin Rakthanmanon and Westover). We demonstrate that the new tool is at par or better in classification accuracy, while being significantly faster in comparable implementations. Released in the publicly domain, we are hopeful that SLD will enhance the standard toolbox used in classification, clustering and inference problems in time series analysis.},
  archive      = {J_KIS},
  author       = {Huang, Yi and Rotaru, Victor and Chattopadhyay, Ishanu},
  doi          = {10.1007/s10115-023-01855-0},
  journal      = {Knowledge and Information Systems},
  month        = {7},
  number       = {7},
  pages        = {3079-3098},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Sequence likelihood divergence for fast time series comparison},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated database design for document stores with
multicriteria optimization. <em>KIS</em>, <em>65</em>(7), 3045–3078. (<a
href="https://doi.org/10.1007/s10115-023-01828-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document stores have gained popularity among NoSQL systems mainly due to the semi-structured data storage structure and the enhanced query capabilities. The database design in document stores expands beyond the first normal form by encouraging de-normalization through nesting. This hinders the process, as the number of alternatives grows exponentially with multiple choices in nesting (including different levels) and referencing (including the direction of the reference). Due to this complexity, document store data design is mostly carried out in trial-and-error or ad-hoc rule-based approaches. However, the choices affect multiple, often conflicting, aspects such as query performance, storage space, and complexity of the documents. To overcome these issues, in this paper, we apply multicriteria optimization. Our approach is driven by a query workload and a set of optimization objectives. First, we formalize a canonical model to represent alternative designs and introduce an algebra of transformations that can systematically modify a design. Then, using these transformations, we implement a local search algorithm driven by a loss function that can propose near-optimal designs with high probability. Finally, we compare our prototype against an existing document store data design solution purely driven by query cost, where our proposed designs have better performance and are more compact with less redundancy.},
  archive      = {J_KIS},
  author       = {Hewasinghage, Moditha and Nadal, Sergi and Abelló, Alberto and Zimányi, Esteban},
  doi          = {10.1007/s10115-023-01828-3},
  journal      = {Knowledge and Information Systems},
  month        = {7},
  number       = {7},
  pages        = {3045-3078},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Automated database design for document stores with multicriteria optimization},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A decomposition hybrid structure learning algorithm for
bayesian network using expert knowledge. <em>KIS</em>, <em>65</em>(7),
3023–3044. (<a
href="https://doi.org/10.1007/s10115-023-01843-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decomposition hybrid structure learning algorithms (DHSLAs), which combine the idea of divide and conquer with hybrid algorithms to reduce the computational complexity, are used to learn Bayesian network (BN) structure. Nevertheless, it’s hard to learn highly accurate BN structures using DHSLAs based on data alone in some cases. First, accurate divisions for the whole domain are difficult to obtain because of the effect on network density and substructures tend to be poorly learned because of the large search space. In addition, using data alone, it is difficult to distinguish Markov equivalence classes. At this point, utilizing expert knowledge is an effective way. However, existing algorithms have not been studied to integrate expert knowledge into DHSLAs. Therefore, in this paper, we propose the first structure learning algorithm for using expert knowledge in DHSLAs called Decomposition Hybrid Structure Learning Algorithm with Expert Knowledge (DHSLA-EK). In the DHSLA-EK, we incorporate domain knowledge and structural knowledge with confidence into the DHSLA by constructing prior subdomains in the decomposition stage and by forming a novel scoring function in the subdomain structure learning stage. Extensive experiments on four benchmark networks indicate that the proposed algorithm can effectively improve the learning effect of the DHSLA.},
  archive      = {J_KIS},
  author       = {Guo, Huiping and Li, Hongru},
  doi          = {10.1007/s10115-023-01843-4},
  journal      = {Knowledge and Information Systems},
  month        = {7},
  number       = {7},
  pages        = {3023-3044},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A decomposition hybrid structure learning algorithm for bayesian network using expert knowledge},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BPF: A novel cluster boundary points detection method for
static and streaming data. <em>KIS</em>, <em>65</em>(7), 2991–3022. (<a
href="https://doi.org/10.1007/s10115-023-01854-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data points situated near a cluster boundary are called boundary points and they can represent useful information about the process generating this data. The existing methods of boundary points detection cannot differentiate boundary points from outliers as they are affected by the presence of outliers as well as by the size and density of clusters in the dataset. Also, they require tuning of one or more parameters and prior knowledge of the number of outliers in the dataset for tuning. In this research, a boundary points detection method called BPF is proposed which can effectively differentiate boundary points from outliers and core points. BPF combines the well-known outlier detection method Local Outlier Factor (LOF) with Gravity value to calculate the BPF score. Our proposed algorithm StaticBPF can detect the top-m boundary points in the given dataset. Importantly, StaticBPF requires tuning of only one parameter i.e. the number of nearest neighbors $$(k)$$ and can employ the same $$k$$ used by LOF for outlier detection. This paper also extends BPF for streaming data and proposes StreamBPF. StreamBPF employs a grid structure for improving k-nearest neighbor computation and an incremental method of calculating BPF scores of a subset of data points in a sliding window over data streams. In evaluation, the accuracy of StaticBPF and the runtime efficiency of StreamBPF are evaluated on synthetic and real data where they generally performed better than their competitors.},
  archive      = {J_KIS},
  author       = {Khalique, Vijdan and Kitagawa, Hiroyuki and Amagasa, Toshiyuki},
  doi          = {10.1007/s10115-023-01854-1},
  journal      = {Knowledge and Information Systems},
  month        = {7},
  number       = {7},
  pages        = {2991-3022},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {BPF: A novel cluster boundary points detection method for static and streaming data},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PPDU: Dynamic graph publication with local differential
privacy. <em>KIS</em>, <em>65</em>(7), 2965–2989. (<a
href="https://doi.org/10.1007/s10115-023-01838-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local differential privacy (LDP) is an emerging privacy-preserving data collection model that requires no trusted third party. Most privacy-preserving decentralized graph publishing studies adopt LDP technique to ensure individual privacy. However, existing LDP-based synthetic graph generation approaches focus on static graph publishing and can only republish synthetic graphs in a brute-force manner when dealing with dynamic graph problems, resulting in low synthetic graph accuracy. The main difficulties come from the two steps of dynamic graph publishing: excessive noise injection in initial graph generation and over-segmentation of the privacy budget in graph update. We address these two issues by presenting PPDU, the first dynamic graph publication approach under LDP. PPDU uses a privacy-preference-specifying mechanism to untie the noise injection and the graph size, significantly reducing noise injection. We then divide the privacy-preserving graph update problem into three subproblems: node insertion, edge insertion, and edge deletion, and propose update threshold-based dynamic graph releasing methods to avoid excessive segmentation of the privacy budget, thereby significantly improving the accuracy of synthetic graphs. Theoretical analysis and experimental results prove that our solution can continually yield high-quality dynamic graphs while satisfying edge LDP.},
  archive      = {J_KIS},
  author       = {Hou, Lihe and Ni, Weiwei and Zhang, Sen and Fu, Nan and Zhang, Dongyue},
  doi          = {10.1007/s10115-023-01838-1},
  journal      = {Knowledge and Information Systems},
  month        = {7},
  number       = {7},
  pages        = {2965-2989},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {PPDU: Dynamic graph publication with local differential privacy},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpretable tabular data generation. <em>KIS</em>,
<em>65</em>(7), 2935–2963. (<a
href="https://doi.org/10.1007/s10115-023-01834-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial network (GAN) models have been successfully utilized in a wide range of machine learning applications, and tabular data generation domain is not an exception. Notably, some state-of-the-art models of tabular data generation, such as CTGAN,  TableGan, MedGAN, etc. are based on GAN models. Even though these models have resulted in superior performance in generating artificial data when trained on a range of datasets, there is a lot of room (and desire) for improvement. Not to mention that existing methods do have some weaknesses other than performance. For example, the current methods focus only on the performance of the model, and limited emphasis is given on the interpretation of the model. Secondly, the current models operate on raw features only, and hence they fail to exploit any prior knowledge on explicit feature interactions that can be utilized during data generation process. To alleviate the two above-mentioned limitations, in this work, we propose a novel tabular data generation model—Generative Adversarial Network modelling inspired from Naive Bayes and Logistic Regression’s relationship ( $${ { \texttt {GANBLR} } }$$ ), which not only address the interpretation limitation of existing tabular GAN-based models but provides capability to handle explicit feature interactions as well. Through extensive evaluations on wide range of datasets, we demonstrate $${ { \texttt {GANBLR} } }$$ ’s superior performance as well as better interpretable capability (explanation of feature importance in the synthetic generation process) as compared to existing state-of-the-art tabular data generation models.},
  archive      = {J_KIS},
  author       = {Zhang, Yishuo and Zaidi, Nayyar and Zhou, Jiahui and Li, Gang},
  doi          = {10.1007/s10115-023-01834-5},
  journal      = {Knowledge and Information Systems},
  month        = {7},
  number       = {7},
  pages        = {2935-2963},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Interpretable tabular data generation},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Entity integrity management under data volume, variety and
veracity. <em>KIS</em>, <em>65</em>(7), 2895–2934. (<a
href="https://doi.org/10.1007/s10115-022-01814-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edgar Codd introduced the principle of entity integrity in the context of his relational model of data. The principle says that every targeted real-world entity should be uniquely represented in the database. In actual database systems, entity integrity is typically enforced by primary keys. We introduce a framework toward generalizing entity integrity to different dimensions of data, including volume, variety, and veracity. We establish axiomatic and algorithmic foundations for the implication problem of the combined class of uniqueness constraints, functional dependencies, and multivalued dependencies in all combinations of the dimensions we consider. These are based on specific approaches to the semantics of these integrity constraints and to the dimensions of data. We also highlight how our concepts lead to new opportunities for diverse and important areas of applications, such as query optimization, database design and security, and data quality. Overall, this sets out an agenda for future research that extends our approaches or applies different approaches in this area, as driven by application requirements.},
  archive      = {J_KIS},
  author       = {Link, Sebastian},
  doi          = {10.1007/s10115-022-01814-1},
  journal      = {Knowledge and Information Systems},
  month        = {7},
  number       = {7},
  pages        = {2895-2934},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Entity integrity management under data volume, variety and veracity},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards intelligent database systems using clusters of SQL
transactions. <em>KIS</em>, <em>65</em>(7), 2863–2894. (<a
href="https://doi.org/10.1007/s10115-023-01850-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transactions are the bread-and-butter of database management system (DBMS) industry. When you check your bank balance, pay bill, or move money from saving to chequing account, transactions are involved. That transactions are self-similar—whether you pay a utility company or credit card, it is still a ‘pay bill’ transaction—has been noted before. Somewhat surprisingly, that property remains largely unexploited, barring some notable exceptions. The research reported in this paper begins to build ‘intelligence’ into database systems by offering built-in transaction classification and clustering. The utility of such an approach is demonstrated by showing how it simplifies DBMS monitoring and troubleshooting. The well-known DBSCAN algorithm clusters online transaction processing (OLTP) transactions: this paper’s contribution is in demonstrating a robust server-side feature extraction approach, rather than the previously suggested and error-prone log-mining approach. It is shown how ‘DBSCAN + angular cosine distance function’ finds better clusters than the previously tried combinations, and simplifies DBSCAN parameter tuning—a known nontrivial task. DBMS troubleshooting efficacy is demonstrated by identifying the root causes of several real-life performance problems: problematic transaction rollbacks; performance drifts; system-wide issues; CPU and memory bottlenecks; and so on. It is also shown that the cluster count remains unchanged irrespective of system load—a desirable but often overlooked property. The transaction clustering solution has been implemented inside the popular MySQL DBMS, although most modern relational database systems can benefit from the ideas described herein.},
  archive      = {J_KIS},
  author       = {Marathe, Arunprasad P.},
  doi          = {10.1007/s10115-023-01850-5},
  journal      = {Knowledge and Information Systems},
  month        = {7},
  number       = {7},
  pages        = {2863-2894},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Towards intelligent database systems using clusters of SQL transactions},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of automated data augmentation algorithms for deep
learning-based image classification tasks. <em>KIS</em>, <em>65</em>(7),
2805–2861. (<a
href="https://doi.org/10.1007/s10115-023-01853-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, one of the most popular techniques in the computer vision community has been the deep learning technique. As a data-driven technique, deep model requires enormous amounts of accurately labelled training data, which is often inaccessible in many real-world applications. A data-space solution is Data Augmentation (DA), that can artificially generate new images out of original samples. Image augmentation strategies can vary by dataset, as different data types might require different augmentations to facilitate model training. However, the design of DA policies has been largely decided by the human experts with domain knowledge, which is considered to be highly subjective and error-prone. To mitigate such problem, a novel direction is to automatically learn the image augmentation policies from the given dataset using Automated Data Augmentation (AutoDA) techniques. The goal of AutoDA models is to find the optimal DA policies that can maximize the model performance gains. This survey discusses the underlying reasons of the emergence of AutoDA technology from the perspective of image classification. We identify three key components of a standard AutoDA model: a search space, a search algorithm and an evaluation function. Based on their architecture, we provide a systematic taxonomy of existing image AutoDA approaches. This paper presents the major works in AutoDA field, discussing their pros and cons, and proposing several potential directions for future improvements.},
  archive      = {J_KIS},
  author       = {Yang, Zihan and Sinnott, Richard O. and Bailey, James and Ke, Qiuhong},
  doi          = {10.1007/s10115-023-01853-2},
  journal      = {Knowledge and Information Systems},
  month        = {7},
  number       = {7},
  pages        = {2805-2861},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A survey of automated data augmentation algorithms for deep learning-based image classification tasks},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Text classification using embeddings: A survey.
<em>KIS</em>, <em>65</em>(7), 2761–2803. (<a
href="https://doi.org/10.1007/s10115-023-01856-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text classification results can be hindered when just the bag-of-words model is used for representing features, because it ignores word order and senses, which can vary with the context. Embeddings have recently emerged as a means to circumvent these limitations, allowing considerable performance gains. However, determining the best combinations of classification techniques and embeddings for classifying particular corpora can be challenging. This survey provides a comprehensive review of text classification approaches that employ embeddings. First, it analyzes past and recent advancements in feature representation for text classification. Then, it identifies the combinations of embedding-based feature representations and classification techniques that have provided the best performances for classifying text from distinct corpora, also providing links to the original articles, source code (when available) and data sets used in the performance evaluation. Finally, it discusses current challenges and promising directions for text classification research, such as cost-effectiveness, multi-label classification, and the potential of knowledge graphs and knowledge embeddings to enhance text classification.},
  archive      = {J_KIS},
  author       = {da Costa, Liliane Soares and Oliveira, Italo L. and Fileto, Renato},
  doi          = {10.1007/s10115-023-01856-z},
  journal      = {Knowledge and Information Systems},
  month        = {7},
  number       = {7},
  pages        = {2761-2803},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Text classification using embeddings: A survey},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Aspect and orientation-based sentiment analysis of customer
feedback using mathematical optimization models. <em>KIS</em>,
<em>65</em>(6), 2731–2760. (<a
href="https://doi.org/10.1007/s10115-023-01848-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is a natural language processing method used to assess data&#39;s positivity, negativity, and neutrality. Several techniques were suggested as ways to solve the sentiment analysis task. This study presents a novel multi-criteria decision-making (MCDM) and game theory-based mathematical framework for the sentiment orientation of reviews. We propose two frameworks: sentiment orientation tagger modal (SOTM) and aspect-based ranking modal (ABRM). The SOTM consists of the simple additive weighting (SAW) technique and the principle of Nash equilibrium from game theory to deduce the tag for the review dataset. We identify a review&#39;s sentiment as positive, negative, or neutral. In ABRM, we rank the aspects of the review using the preference selection index (PSI). We propose an unsupervised sentiment classification model that combines context, rating, and emotion scores with a mathematical optimization model. The effectiveness of our proposed model is comparable to the state-of-the-art models, as demonstrated by experimental results on three benchmark review datasets. We also establish the significance of the results through statistical analysis. The proposed model ensures rationality and consistency. The novel combination of the MCDM and game theory model with the reviews&#39; context, rating, and emotion scores creates a new paradigm in sentiment analysis. Also, the proposed model is generalizable and can analyze sentiment in many fields.},
  archive      = {J_KIS},
  author       = {Punetha, Neha and Jain, Goonjan},
  doi          = {10.1007/s10115-023-01848-z},
  journal      = {Knowledge and Information Systems},
  month        = {6},
  number       = {6},
  pages        = {2731-2760},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Aspect and orientation-based sentiment analysis of customer feedback using mathematical optimization models},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Harnessing heterogeneity in space with statistically guided
meta-learning. <em>KIS</em>, <em>65</em>(6), 2699–2729. (<a
href="https://doi.org/10.1007/s10115-023-01847-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial data are ubiquitous, massively collected, and widely used to support critical decision-making in many societal domains, including public health (e.g., COVID-19 pandemic control), agricultural crop monitoring, transportation, etc. While recent advances in machine learning and deep learning offer new promising ways to mine such rich datasets (e.g., satellite imagery, COVID statistics), spatial heterogeneity—an intrinsic characteristic embedded in spatial data—poses a major challenge as data distributions or generative processes often vary across space at different scales, with their spatial extents unknown. Recent studies (e.g., SVANN, spatial ensemble) targeting this difficult problem either require a known space-partitioning as the input, or can only support very limited number of partitions or classes (e.g., two) due to the decrease in training data size and the complexity of analysis. To address these limitations, we propose a model-agnostic framework to automatically transform a deep learning model into a spatial-heterogeneity-aware architecture, where the learning of arbitrary space partitionings is guided by a learning-engaged generalization of multivariate scan statistic and parameters are shared based on spatial relationships. Moreover, we propose a spatial moderator to generalize learned space partitionings to new test regions. Finally, we extend the framework by integrating meta-learning-based training strategies into both spatial transformation and moderation to enhance knowledge sharing and adaptation among different processes. Experiment results on real-world datasets show that the framework can effectively capture flexibly shaped heterogeneous footprints and substantially improve prediction performances.},
  archive      = {J_KIS},
  author       = {Xie, Yiqun and Chen, Weiye and He, Erhu and Jia, Xiaowei and Bao, Han and Zhou, Xun and Ghosh, Rahul and Ravirathinam, Praveen},
  doi          = {10.1007/s10115-023-01847-0},
  journal      = {Knowledge and Information Systems},
  month        = {6},
  number       = {6},
  pages        = {2699-2729},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Harnessing heterogeneity in space with statistically guided meta-learning},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Elastic similarity and distance measures for multivariate
time series. <em>KIS</em>, <em>65</em>(6), 2665–2698. (<a
href="https://doi.org/10.1007/s10115-023-01835-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper contributes multivariate versions of seven commonly used elastic similarity and distance measures for time series data analytics. Elastic similarity and distance measures can compensate for misalignments in the time axis of time series data. We adapt two existing strategies used in a multivariate version of the well-known Dynamic Time Warping (DTW), namely, Independent and Dependent DTW, to these seven measures. While these measures can be applied to various time series analysis tasks, we demonstrate their utility on multivariate time series classification using the nearest neighbor classifier. On 23 well-known datasets, we demonstrate that each of the measures but one achieves the highest accuracy relative to others on at least one dataset, supporting the value of developing a suite of multivariate similarity and distance measures. We also demonstrate that there are datasets for which either the dependent versions of all measures are more accurate than their independent counterparts or vice versa. In addition, we also construct a nearest neighbor-based ensemble of the measures and show that it is competitive to other state-of-the-art single-strategy multivariate time series classifiers.},
  archive      = {J_KIS},
  author       = {Shifaz, Ahmed and Pelletier, Charlotte and Petitjean, François and Webb, Geoffrey I.},
  doi          = {10.1007/s10115-023-01835-4},
  journal      = {Knowledge and Information Systems},
  month        = {6},
  number       = {6},
  pages        = {2665-2698},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Elastic similarity and distance measures for multivariate time series},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Disentangling interest and conformity for eliminating
popularity bias in session-based recommendation. <em>KIS</em>,
<em>65</em>(6), 2645–2664. (<a
href="https://doi.org/10.1007/s10115-023-01839-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation (SBR) is to predict the next item, given an anonymous interaction sequence. Recently, many advanced SBR models have shown great recommending performance, but few studies note that they suffer from popularity bias seriously: the model tends to recommend popular items and fails to recommend long-tail items. The only few debias works relieve popularity bias indeed. However, they ignore individual’s conformity toward popular items and thus decrease recommending performance on popular items. Besides, conformity is always entangled with individual’s real interest, which hinders extracting one’s comprehensive preference. To tackle the problem, we propose an SBR framework with Disentangling InteRest and Conformity for eliminating popularity bias in SBR. In this framework, two groups of item encoders and session modeling modules are devised to extract interest and conformity, respectively, and a fusion module is designed to combine these two types of preference. Also, a discrepancy loss is utilized to disentangle the representation of interest and conformity. Besides, our devised framework can integrate with several SBR models seamlessly. We conduct extensive experiments on three real-world datasets with four advanced SBR models. The results show that our framework outperforms other state-of-the-art debias methods consistently.},
  archive      = {J_KIS},
  author       = {Liu, Qidong and Tian, Feng and Zheng, Qinghua and Wang, Qianying},
  doi          = {10.1007/s10115-023-01839-0},
  journal      = {Knowledge and Information Systems},
  month        = {6},
  number       = {6},
  pages        = {2645-2664},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Disentangling interest and conformity for eliminating popularity bias in session-based recommendation},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Matching heterogeneous ontologies based on multi-strategy
adaptive co-firefly algorithm. <em>KIS</em>, <em>65</em>(6), 2619–2644.
(<a href="https://doi.org/10.1007/s10115-023-01845-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an effective method of addressing ontology heterogeneity problem, ontology matching becomes increasingly important for knowledge sharing and inter-system communication. Ontology meta-matching, which aims at finding optimal ways of integrating different similarity measures, is an effective method of determining high-quality ontology alignment. However, the existing ontology meta-matching techniques suffer from the following defects: first, most of them are depending on the reference alignment that ought to be given by experts in advance, which is not available in the practical scenarios; second, they tend to get stuck in the local optima, which makes the alignment unsatisfactory. In order to solve the above problems, in this work, an optimization model for ontology meta-matching problem is constructed on the basis of a new proposed evaluation metric on the alignment’s quality. After that, a multi-strategy adaptive co-firefly algorithm (MACFA), which is able to trade off the algorithm’s exploitation and exploration, is proposed to overcome the premature convergence. The testing cases in Ontology Alignment Evaluation Initiative (OAEI) is utilized to verify the effectiveness of our approach. Experimental results show that the optimization model as well as MACFA improves the ontology alignment’s quality, and compared with OAEI’s participants, the proposed matching system achieves competitive results.},
  archive      = {J_KIS},
  author       = {Zhou, Xin and Lv, Qing and Geng, Aifeng},
  doi          = {10.1007/s10115-023-01845-2},
  journal      = {Knowledge and Information Systems},
  month        = {6},
  number       = {6},
  pages        = {2619-2644},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Matching heterogeneous ontologies based on multi-strategy adaptive co-firefly algorithm},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hepatitis c virus prediction based on machine learning
framework: A real-world case study in egypt. <em>KIS</em>,
<em>65</em>(6), 2595–2617. (<a
href="https://doi.org/10.1007/s10115-023-01851-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction and classification of diseases are essential in medical science, as it attempts to immune the spread of the disease and discover the infected regions from the early stages. Machine learning (ML) approaches are commonly used for predicting and classifying diseases that are precisely utilized as an efficient tool for doctors and specialists. This paper proposes a prediction framework based on ML approaches to predict Hepatitis C Virus among healthcare workers in Egypt. We utilized real-world data from the National Liver Institute, founded at Menoufiya University (Menoufiya, Egypt). The collected dataset consists of 859 patients with 12 different features. To ensure the robustness and reliability of the proposed framework, we performed two scenarios: the first without feature selection and the second after the features are selected based on sequential forward selection (SFS). Furthermore, the feature subset selected based on the generated features from SFS is evaluated. Naïve Bayes, random forest (RF), K-nearest neighbor, and logistic regression are utilized as induction algorithms and classifiers for model evaluation. Then, the effect of parameter tuning on learning techniques is measured. The experimental results indicated that the proposed framework achieved higher accuracies after SFS selection than without feature selection. Moreover, the RF classifier achieved 94.06% accuracy with a minimum learning elapsed time of 0.54 s. Finally, after adjusting the hyperparameter values of the RF classifier, the classification accuracy is improved to 94.88% using only four features.},
  archive      = {J_KIS},
  author       = {Mamdouh Farghaly, Heba and Shams, Mahmoud Y. and Abd El-Hafeez, Tarek},
  doi          = {10.1007/s10115-023-01851-4},
  journal      = {Knowledge and Information Systems},
  month        = {6},
  number       = {6},
  pages        = {2595-2617},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Hepatitis c virus prediction based on machine learning framework: A real-world case study in egypt},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fairness with censorship and group constraints.
<em>KIS</em>, <em>65</em>(6), 2571–2594. (<a
href="https://doi.org/10.1007/s10115-023-01842-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fairness in machine learning (ML) has gained attention within the ML community and the broader society beyond with many fairness definitions and algorithms being proposed. Surprisingly, there is little work quantifying and guaranteeing fairness in the presence of uncertainty which is prevalent in many socially sensitive applications, ranging from marketing analytics to actuarial analysis and recidivism prediction instruments. To this end, we revisit fairness and reveal idiosyncrasies of existing fairness literature assuming certainty on the class label that limits their real-world utility. Our primary contributions are formulating fairness under uncertainty and group constraints along with a suite of corresponding new fairness definitions and algorithm. We argue that this formulation has a broader applicability to practical scenarios concerning fairness. We also show how the newly devised fairness notions involving censored information and the general framework for fair predictions in the presence of censorship allow us to measure and mitigate discrimination under uncertainty that bridges the gap with real-world applications. Empirical evaluations on real-world datasets with censorship and sensitive attributes demonstrate the practicality of our approach.},
  archive      = {J_KIS},
  author       = {Zhang, Wenbin and Weiss, Jeremy C.},
  doi          = {10.1007/s10115-023-01842-5},
  journal      = {Knowledge and Information Systems},
  month        = {6},
  number       = {6},
  pages        = {2571-2594},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Fairness with censorship and group constraints},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). User view dynamic graph-driven sequential recommendation.
<em>KIS</em>, <em>65</em>(6), 2541–2569. (<a
href="https://doi.org/10.1007/s10115-023-01840-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In most recommendation scenarios, user information is difficult to obtain due to user privacy and data protection issues. Some graph-based methods can learn the user’s feature information through the structural relationship in both user graphs and item graphs. However, a user’s latent associations with other users, especially those hidden in the user’s sequential behavior, are not well identified in the sequential recommendation. In this work, we propose a user view dynamic graph-driven sequential recommender to find out different user latent associations without additional user information. Our model can not only find out the global associations of users, but also discover the user dynamic associations through information dissemination during training. In particular, the dynamic associations are highlighted via contrastive learning to refine global associations from the user view to achieve more efficient sequential recommendations. Furthermore, our approach can serve as a container for commonly used sequential recommenders to achieve better performances. Experimental results show that the user view information has a positive guiding effect on sequential recommendation and our approach outperforms state-of-the-art models.},
  archive      = {J_KIS},
  author       = {Chen, Jianzhen and Zheng, Lin and Chen, Sentao},
  doi          = {10.1007/s10115-023-01840-7},
  journal      = {Knowledge and Information Systems},
  month        = {6},
  number       = {6},
  pages        = {2541-2569},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {User view dynamic graph-driven sequential recommendation},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FCHM-stream: Fast closed high utility itemsets mining over
data streams. <em>KIS</em>, <em>65</em>(6), 2509–2539. (<a
href="https://doi.org/10.1007/s10115-023-01831-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The high-speed, continuous and endless characteristics of data streams make it a challenging task to quickly mine high utility itemsets in limited memory space. The sliding window model, which focuses only on the most recent data, has received extensive research and attention as it can effectively adapt to the data stream environment. However, the presence of many communal batches in adjacent sliding windows causes the algorithm to repeatedly generate a large number of identical itemsets, which reduces the spatiotemporal performance of the algorithm. In order to solve these problems and provide users with a concise and lossless resultset, a new closed high utility pattern mining algorithm over data stream is proposed, named FCHM-Stream. A new utility list structure based on batch division and a resultset maintenance strategy based on skip-list structure are designed to effectively reduce identical itemsets repeatedly generated and thus reduce the running time of the algorithm. Extensive experimental results show that the proposed algorithm has a large improvement in runtime compared to the state-of-the-art algorithms.},
  archive      = {J_KIS},
  author       = {Li, Muhang and Han, Meng and Chen, Zhiqiang and Wu, Hongxin and Zhang, Xilong},
  doi          = {10.1007/s10115-023-01831-8},
  journal      = {Knowledge and Information Systems},
  month        = {6},
  number       = {6},
  pages        = {2509-2539},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {FCHM-stream: Fast closed high utility itemsets mining over data streams},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Early portfolio pruning: A scalable approach to hybrid
portfolio selection. <em>KIS</em>, <em>65</em>(6), 2485–2508. (<a
href="https://doi.org/10.1007/s10115-023-01832-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driving the decisions of stock market investors is among the most challenging financial research problems. Markowitz’s approach to portfolio selection models stock profitability and risk level through a mean–variance model, which involves estimating a very large number of parameters. In addition to requiring considerable computational effort, this raises serious concerns about the reliability of the model in real-world scenarios. This paper presents a hybrid approach that combines itemset extraction with portfolio selection. We propose to adapt Markowitz’s model logic to deal with sets of candidate portfolios rather than with single stocks. We overcome some of the known issues of the Markovitz model as follows: (i) Complexity: we reduce the model complexity, in terms of parameter estimation, by studying the interactions among stocks within a shortlist of candidate stock portfolios previously selected by an itemset mining algorithm. (ii) Portfolio-level constraints: we not only perform stock-level selection, but also support the enforcement of arbitrary constraints at the portfolio level, including the properties of diversification and the fundamental indicators. (iii) Usability: we simplify the decision-maker’s work by proposing a decision support system that enables flexible use of domain knowledge and human-in-the-loop feedback. The experimental results, achieved on the US stock market, confirm the proposed approach’s flexibility, effectiveness, and scalability.},
  archive      = {J_KIS},
  author       = {Gioia, Daniele G. and Fior, Jacopo and Cagliero, Luca},
  doi          = {10.1007/s10115-023-01832-7},
  journal      = {Knowledge and Information Systems},
  month        = {6},
  number       = {6},
  pages        = {2485-2508},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Early portfolio pruning: A scalable approach to hybrid portfolio selection},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Density of states for fast embedding node-attributed graphs.
<em>KIS</em>, <em>65</em>(6), 2455–2483. (<a
href="https://doi.org/10.1007/s10115-023-01836-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a node-attributed graph, how can we efficiently represent it with few numerical features that expressively reflect its topology and attribute information? We propose A-DOGE, for attributed DOS-based graph embedding, based on density of states (DOS, a.k.a. spectral density) to tackle this problem. A-DOGE is designed to fulfill a long desiderata of desirable characteristics. Most notably, it capitalizes on efficient approximation algorithms for DOS, that we extend to blend in node labels and attributes for the first time, making it fast and scalable for large attributed graphs and graph databases. Being based on the entire eigenspectrum of a graph, A-DOGE can capture structural and attribute properties at multiple (“glocal”) scales. Moreover, it is unsupervised (i.e., agnostic to any specific objective) and lends itself to various interpretations, which makes it suitable for exploratory graph mining tasks. Finally, it processes each graph independent of others, making it amenable for streaming settings as well as parallelization. Through extensive experiments, we show the efficacy and efficiency of A-DOGE on exploratory graph analysis and graph classification tasks, where it significantly outperforms unsupervised baselines and achieves competitive performance with modern supervised GNNs, while achieving the best trade-off between accuracy and runtime.},
  archive      = {J_KIS},
  author       = {Zhao, Lingxiao and Sawlani, Saurabh and Akoglu, Leman},
  doi          = {10.1007/s10115-023-01836-3},
  journal      = {Knowledge and Information Systems},
  month        = {6},
  number       = {6},
  pages        = {2455-2483},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Density of states for fast embedding node-attributed graphs},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast computation of distance-generalized cores using
sampling. <em>KIS</em>, <em>65</em>(6), 2429–2453. (<a
href="https://doi.org/10.1007/s10115-023-01830-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Core decomposition is a classic technique for discovering densely connected regions in a graph with large range of applications. Formally, a k-core is a maximal subgraph where each vertex has at least k neighbors. A natural extension of a k-core is a (k, h)-core, where each node must have at least k nodes that can be reached with a path of length h. The downside in using (k, h)-core decomposition is the significant increase in the computational complexity: whereas the standard core decomposition can be done in $${{\mathcal {O}}}{\left( m\right) }$$ time, the generalization can require $${{\mathcal {O}}}{\left( n^2m\right) }$$ time, where n and m are the number of nodes and edges in the given graph. In this paper, we propose a randomized algorithm that produces an $$\epsilon $$ -approximation of (k, h) core decomposition with a probability of $$1 - \delta $$ in $${{\mathcal {O}}}{\left( \epsilon ^{-2} hm (\log ^2 n - \log \delta )\right) }$$ time. The approximation is based on sampling the neighborhoods of nodes, and we use Chernoff bound to prove the approximation guarantee. We also study distance-generalized dense subgraphs, show that the problem is NP-hard, provide an algorithm for discovering such graphs with approximate core decompositions, and provide theoretical guarantees for the quality of the discovered subgraphs. We demonstrate empirically that approximating the decomposition complements the exact computation: computing the approximation is significantly faster than computing the exact solution for the networks where computing the exact solution is slow.},
  archive      = {J_KIS},
  author       = {Tatti, Nikolaj},
  doi          = {10.1007/s10115-023-01830-9},
  journal      = {Knowledge and Information Systems},
  month        = {6},
  number       = {6},
  pages        = {2429-2453},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Fast computation of distance-generalized cores using sampling},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Climate modeling with neural advection–diffusion equation.
<em>KIS</em>, <em>65</em>(6), 2403–2427. (<a
href="https://doi.org/10.1007/s10115-023-01829-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the remarkable development of deep learning technology, there have been a series of efforts to build deep learning-based climate models. Whereas most of them utilize recurrent neural networks and/or graph neural networks, we design a novel climate model based on two concepts, the neural ordinary differential equation (NODE) and the advection–diffusion equation. The advection–diffusion equation is widely used for climate modeling because it describes many physical processes involving Brownian and bulk motions in climate systems. On the other hand, NODEs are to learn a latent governing equation of ODE from data. In our presented method, we combine them into a single framework and propose a concept, called neural advection–diffusion equation (NADE). Our NADE, equipped with the advection–diffusion equation and one more additional neural network to model inherent uncertainty, can learn an appropriate latent governing equation that best describes a given climate dataset. In our experiments with three real-world and two synthetic datasets and fourteen baselines, our method consistently outperforms existing baselines by non-trivial margins.},
  archive      = {J_KIS},
  author       = {Choi, Hwangyong and Choi, Jeongwhan and Hwang, Jeehyun and Lee, Kookjin and Lee, Dongeun and Park, Noseong},
  doi          = {10.1007/s10115-023-01829-2},
  journal      = {Knowledge and Information Systems},
  month        = {6},
  number       = {6},
  pages        = {2403-2427},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Climate modeling with neural advection–diffusion equation},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Range-constrained probabilistic mutual furthest neighbor
queries in uncertain databases. <em>KIS</em>, <em>65</em>(6), 2375–2402.
(<a href="https://doi.org/10.1007/s10115-022-01807-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For decades, query processing over uncertain databases has received much attention from the database community due to the pervasive data uncertainty in many real-world applications such as location-based services (LBS), sensor networks, business planning, biological databases, and so on. In this paper, we will study a novel query type, namely range-constrained probabilistic mutual furthest neighbor query (PMFN), over uncertain databases. PMFN retrieves a set of object pairs, $$(o_i, o_j)$$ , within a given query range Q, such that uncertain objects $$o_i$$ and $$o_j$$ are furthest neighbors of each other with high probabilities. In order to efficiently tackle the PMFN problem, we propose effective pruning methods, range, convex hull, and hypersphere pruning, for filtering out uncertain objects that can never appear in the PMFN answer set. Then, we also design spatial and probabilistic pruning methods to rule out false alarms of PMFN candidate pairs. Finally, we utilize a variant of the R $$^*$$ -tree to integrate our proposed pruning methods and efficiently process ad hoc PMFN queries. Extensive experiments show the efficiency and effectiveness of our pruning techniques and PMFN query processing algorithms over real and synthetic data sets.},
  archive      = {J_KIS},
  author       = {Bavi, Kovan and Lian, Xiang},
  doi          = {10.1007/s10115-022-01807-0},
  journal      = {Knowledge and Information Systems},
  month        = {6},
  number       = {6},
  pages        = {2375-2402},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Range-constrained probabilistic mutual furthest neighbor queries in uncertain databases},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CaSPiTa: Mining statistically significant paths in time
series data from an unknown network. <em>KIS</em>, <em>65</em>(6),
2347–2374. (<a
href="https://doi.org/10.1007/s10115-022-01800-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mining of time series data has applications in several domains, and in many cases the data are generated by networks, with time series representing paths on such networks. In this work, we consider the scenario in which the dataset, i.e., a collection of time series, is generated by an unknown underlying network, and we study the problem of mining statistically significant paths, which are paths whose number of observed occurrences in the dataset is unexpected given the distribution defined by some features of the underlying network. A major challenge in such a problem is that the underlying network is unknown, and, thus, one cannot directly identify such paths. We then propose caSPiTa, an algorithm to mine statistically significant paths in time series data generated by an unknown and underlying network that considers a generative null model based on meaningful characteristics of the observed dataset, while providing guarantees in terms of false discoveries. Our extensive evaluation on pseudo-artificial and real data shows that caSPiTa is able to efficiently mine large sets of significant paths, while providing guarantees on the false positives.},
  archive      = {J_KIS},
  author       = {Tonon, Andrea and Vandin, Fabio},
  doi          = {10.1007/s10115-022-01800-7},
  journal      = {Knowledge and Information Systems},
  month        = {6},
  number       = {6},
  pages        = {2347-2374},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {CaSPiTa: Mining statistically significant paths in time series data from an unknown network},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Group decision-making with interval multiplicative
preference relations. <em>KIS</em>, <em>65</em>(5), 2305–2346. (<a
href="https://doi.org/10.1007/s10115-022-01816-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses group decision-making (GDM) with interval multiplicative preference relations (IMPRs) based on the geometric consistency. We propose a logarithmically geometric compatibility degree between two IMPRs and then define a geometrically logarithmic consistency index of IMPRs. The new consistency index of IMPRs is invariant under permutation of alternatives and transpose of IMPRs. By the statistics theory, the thresholds of the geometrically logarithmic consistency index are provided. For an unacceptably consistent IMPR, an interactive iterative algorithm is designed to improve its consistency level. Using the relationship between an interval weight vector (IWV) and an IMPR, a fuzzy programming model is established to derive an IWV. This model is converted into a linear programming model for resolution. Subsequently, a new individual decision-making (IDM) method with an IMPR is put forward. By minimizing the logarithmically geometric compatibility degree between each individual IMPR and the collective one, a convex programming model is built to determine experts’ weights. Consequently, a novel GDM method with IMPRs is presented. Numerical examples and simulation experiments are conducted to reveal the superiority of the proposed IDM method and GDM method.},
  archive      = {J_KIS},
  author       = {Wan, Shuping and Cheng, Xianjuan and Dong, Jiuying},
  doi          = {10.1007/s10115-022-01816-z},
  journal      = {Knowledge and Information Systems},
  month        = {5},
  number       = {5},
  pages        = {2305-2346},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Group decision-making with interval multiplicative preference relations},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive curvature exploration geometric graph neural
network. <em>KIS</em>, <em>65</em>(5), 2281–2304. (<a
href="https://doi.org/10.1007/s10115-022-01811-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural networks (GNNs) which are powerful and widely applied models are based on the assumption that graph topologies play key roles in the graph representation learning.However, the existing GNN methods are based on the Euclidean space embedding, which is difficult to represent a variety of graph geometric properties well. Recently, Riemannian geometries have been introduced into GNNs, such as Hyperbolic Graph Neural Networks proposed for the hierarchy-preserving graph representation learning. In Riemannian geometry, the different graph topological structures can be reflected by corresponding curved embedding spaces, such as a hyperbolic space can be understood as a continuous tree-like structure and a spherical space can be understood as a continuous clique. However, most existing non-Euclidean GNNs are based on heuristic, manual statistical, or estimation methods, which is difficult to automatically select the appropriate embedding space for graphs with different topological properties. To deal with this problem, we propose the Adaptive Curvature Exploration Geometric Graph Neural Network to automatically learn high-quality graph representations and explore the embedding space with optimal curvature at the same time. We optimize the multi-objective optimization problem of the graph representation learning and curvature exploration with the multi-agent reinforcement learning and using the Nash Q-learning algorithm to collaboratively train the two agents to reach Nash equilibrium. We construct extensive experiments including synthetic and real-world graph datasets, and the results demonstrate significant and consistent performance improvement and generalization of our method.},
  archive      = {J_KIS},
  author       = {Fu, Xingcheng and Li, Jianxin and Wu, Jia and Qin, Jiawen and Sun, Qingyun and Ji, Cheng and Wang, Senzhang and Peng, Hao and Yu, Philip S.},
  doi          = {10.1007/s10115-022-01811-4},
  journal      = {Knowledge and Information Systems},
  month        = {5},
  number       = {5},
  pages        = {2281-2304},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Adaptive curvature exploration geometric graph neural network},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An action–reaction influence model relying on OSN
user-generated content. <em>KIS</em>, <em>65</em>(5), 2251–2280. (<a
href="https://doi.org/10.1007/s10115-023-01833-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the sustained popularization of Online Social Networks (OSNs), it has become of interest for a variety of domains of applications to correctly characterize how the behavior of an individual user can be influenced by the actions of other users in a network. Additionally, the richness of available features in modern OSNs highlights the growing importance of user-generated data in establishing user relations. In this paper, we follow a data-driven methodology and propose a diffusion algorithm designed around user-to-content relationships and an action–reaction paradigm. Crucially, we design our approach by integrating different cross-disciplinary theories of how users influence each other. Thus, we enrich the influence maximization task with a psychological dimension and define a model that ties influence diffusion to recurrent users’ behavior from OSN logs, considering relationships between users mediated by user-generated content. We evaluate our approach over the Yahoo Flickr Creative Commons 100 Million real-world dataset. We measure efficiency and effectiveness by analyzing scalability and spread efficacy and show how our model outperforms existing state-of-the-art methods.},
  archive      = {J_KIS},
  author       = {De Santo, Aniello and Ferraro, Antonino and Moscato, Vincenzo and Sperlí, Giancarlo},
  doi          = {10.1007/s10115-023-01833-6},
  journal      = {Knowledge and Information Systems},
  month        = {5},
  number       = {5},
  pages        = {2251-2280},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {An action–reaction influence model relying on OSN user-generated content},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Falcon: Lightweight and accurate convolution based on
depthwise separable convolution. <em>KIS</em>, <em>65</em>(5),
2225–2249. (<a
href="https://doi.org/10.1007/s10115-022-01818-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How can we efficiently compress convolutional neural network (CNN) using depthwise separable convolution, while retaining their accuracy on classification tasks? Depthwise separable convolution, which replaces a standard convolution with a depthwise convolution and a pointwise convolution, has been used for building lightweight architectures. However, previous works based on depthwise separable convolution are limited when compressing a trained CNN model since (1) they are mostly heuristic approaches without a precise understanding of their relations to standard convolution, and (2) their accuracies do not match that of the standard convolution. In this paper, we propose Falcon, an accurate and lightweight method to compress CNN based on depthwise separable convolution.Falcon uses generalized elementwise product (GEP), our proposed mathematical formulation to approximate the standard convolution kernel, to interpret existing convolution methods based on depthwise separable convolution. By exploiting the knowledge of a trained standard model and carefully determining the order of depthwise separable convolution via GEP, Falcon achieves sufficient accuracy close to that of the trained standard model. Furthermore, this interpretation leads to developing a generalized version rank-k Falcon which performs k independent Falcon operations and sums up the result. Experiments show that Falcon (1) provides higher accuracy than existing methods based on depthwise separable convolution and tensor decomposition and (2) reduces the number of parameters and FLOPs of standard convolution by up to a factor of 8 while ensuring similar accuracy. We also demonstrate that rank-k Falcon further improves the accuracy while sacrificing a bit of compression and computation reduction rates.},
  archive      = {J_KIS},
  author       = {Jang, Jun-Gi and Quan, Chun and Lee, Hyun Dong and Kang, U.},
  doi          = {10.1007/s10115-022-01818-x},
  journal      = {Knowledge and Information Systems},
  month        = {5},
  number       = {5},
  pages        = {2225-2249},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Falcon: Lightweight and accurate convolution based on depthwise separable convolution},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A jointly non-cooperative game-based offloading and dynamic
service migration approach in mobile edge computing. <em>KIS</em>,
<em>65</em>(5), 2187–2223. (<a
href="https://doi.org/10.1007/s10115-022-01822-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increase in the use of compute-intensive applications, the demand to continuously boost the efficiency of data processing increases. Offloading the compute-intensive application tasks to the edge servers can effectively solve problems for resource-constrained mobile devices. However, the computation offloading may increase network load and transmission delay, which will influence the user experience. On the other hand, the unceasing distance change between the local device and edge server could also affect the service quality due to user mobility. This paper proposes the offloading and service migration methods for compute-intensive applications to deal with these issues. First, the fine-grained computation offloading algorithm based on a non-cooperative game is proposed. The overhead on both the local side and edge side is analyzed. Moreover, the service migration path selection based on the Markov decision process is proposed by considering user mobility, energy cost, migration cost, available storage, and bandwidth. The optimal service migration path is selected according to the Markov decision process, which can improve service quality. Experiment results show that our proposed offloading strategy performs better in reducing energy consumption by more than 10% and latency by more than 6.2%, compared with other baseline algorithms, and saving mobile device energy and reducing task response time, saving over 10% of time and energy consumption compared to similar algorithms. The proposed service migration scheme can reduce migration times and maintain a success rate of more than 90% while guaranteeing service continuity in a multi-user scenario.},
  archive      = {J_KIS},
  author       = {Li, Chunlin and Zhang, Qingzhe and Luo, Youlong},
  doi          = {10.1007/s10115-022-01822-1},
  journal      = {Knowledge and Information Systems},
  month        = {5},
  number       = {5},
  pages        = {2187-2223},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A jointly non-cooperative game-based offloading and dynamic service migration approach in mobile edge computing},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using topic-noise models to generate domain-specific topics
across data sources. <em>KIS</em>, <em>65</em>(5), 2159–2186. (<a
href="https://doi.org/10.1007/s10115-022-01805-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain-specific document collections, such as data sets about the COVID-19 pandemic, politics, and sports, have become more common as platforms grow and develop better ways to connect people whose interests align. These data sets come from many different sources, ranging from traditional sources like open-ended surveys and newspaper articles to one of the dozens of online social media platforms. Most topic models are equipped to generate topics from one or more of these data sources, but models rarely work well across all types of documents. The main problem that many models face is the varying noise levels inherent in different types of documents. We propose topic-noise models, a new type of topic model that jointly models topic and noise distributions to produce a more accurate, flexible representation of documents regardless of their origin and varying qualities. Our topic-noise model, Topic Noise Discriminator (TND) approximates topic and noise distributions side-by-side with the help of word embedding spaces. While topic-noise models are important for the types of short, noisy documents that often originate on social media platforms, TND can also be used with more traditional data sources like newspapers. TND itself generates a noise distribution that when ensembled with other generative topic models can produce more coherent and diverse topic sets. We show the effectiveness of this approach using Latent Dirichlet Allocation (LDA), and demonstrate the ability of TND to improve the quality of LDA topics in noisy document collections. Finally, researchers are beginning to generate topics using multiple sources and finding that they need a way to identify a core set based on text from different sources. We propose using cross-source topic blending (CSTB), an approach that maps topics sets to an s-partite graph and identifies core topics that blend topics from across s sources by identifying subgraphs with certain linkage properties. We demonstrate the effectiveness of topic-noise models and CSTB empirically on large real-world data sets from multiple domains and data sources.},
  archive      = {J_KIS},
  author       = {Churchill, Rob and Singh, Lisa},
  doi          = {10.1007/s10115-022-01805-2},
  journal      = {Knowledge and Information Systems},
  month        = {5},
  number       = {5},
  pages        = {2159-2186},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Using topic-noise models to generate domain-specific topics across data sources},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ultra-fast meta-parameter optimization for time series
similarity measures with application to nearest neighbour
classification. <em>KIS</em>, <em>65</em>(5), 2123–2157. (<a
href="https://doi.org/10.1007/s10115-022-01827-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nearest neighbour similarity measures are widely used in many time series data analysis applications. They compute a measure of similarity between two time series. Most applications require tuning of these measures’ meta-parameters in order to achieve good performance. However, most measures have at least $$O(L^2)$$ complexity, making them computationally expensive and the process of learning their meta-parameters burdensome, requiring days even for datasets containing only a few thousand series. In this paper, we propose UltraFastMPSearch, a family of algorithms to learn the meta-parameters for different types of time series distance measures. These algorithms are significantly faster than the prior state of the art. Our algorithms build upon the state of the art, exploiting the properties of a new efficient exact algorithm which supports early abandoning and pruning for most time series distance measures. We show on 128 datasets from the UCR archive that our new family of algorithms are up to an order of magnitude faster than the previous state of the art.},
  archive      = {J_KIS},
  author       = {Tan, Chang Wei and Herrmann, Matthieu and Webb, Geoffrey I.},
  doi          = {10.1007/s10115-022-01827-w},
  journal      = {Knowledge and Information Systems},
  month        = {5},
  number       = {5},
  pages        = {2123-2157},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Ultra-fast meta-parameter optimization for time series similarity measures with application to nearest neighbour classification},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An integer linear programming model to improve the
dependency graph discovery step of heuristics miner methods.
<em>KIS</em>, <em>65</em>(5), 2087–2121. (<a
href="https://doi.org/10.1007/s10115-022-01821-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heuristic mining techniques are among the most popular methods in the process discovery area. This category of methods is composed of two main steps: (1) discovering a dependency graph and (2) determining the split/join patterns of the dependency graph. The current dependency graph discovery techniques of heuristic-based methods select the initial set of graph arcs according to dependency measures and then modify the set regarding some criteria. This can lead to selecting the non-optimal set of arcs. Also, the modifications can result in modeling rare behaviors and, consequently, low precision and non-simple process models. The motivation of this paper is to improve the heuristic mining methods by addressing the mentioned issues. The contribution of this paper is to propose a new integer linear programming model that determines the optimal set of graph arcs regarding dependency measures. Simultaneously, the proposed method can eliminate some other issues that the existing methods cannot handle completely; i.e., even in the presence of loops, it guarantees that all tasks are on a path from the initial to the final tasks. This approach also allows utilizing domain knowledge by introducing appropriate constraints, which can be a practical advantage in real-world problems. To assess the results, we modified two existing methods of evaluating process models to make them capable of measuring the quality of dependency graphs. According to assessments, the proposed method’s outputs are superior to those of the most prominent dependency graph discovery methods in terms of fitness, precision, and especially simplicity.},
  archive      = {J_KIS},
  author       = {Tavakoli-Zaniani, Maryam and Gholamian, Mohammad Reza and Golpayegani, S. Alireza Hashemi and Ghazanfari, Mehdi},
  doi          = {10.1007/s10115-022-01821-2},
  journal      = {Knowledge and Information Systems},
  month        = {5},
  number       = {5},
  pages        = {2087-2121},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {An integer linear programming model to improve the dependency graph discovery step of heuristics miner methods},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DAuCNet: Deep autoregressive framework for temporal link
prediction combining copy mechanism network. <em>KIS</em>,
<em>65</em>(5), 2061–2085. (<a
href="https://doi.org/10.1007/s10115-022-01823-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The research on temporal knowledge graphs (TKGs) has received increasing attention. Since knowledge graphs are always incomplete, knowledge reasoning problems are crucial. However, knowledge reasoning is challenging due to the temporal evolution of TKGs. Yet, most existing approaches focus on knowledge graph inference within past timestamps and cannot predict upcoming facts. There is evidence that when temporal facts in TKGs are evolving and interacting, most of them exhibit repeating patterns along the historical timeline. This observation indicates that forecasting models may predict upcoming facts based on history. To this end, this paper proposes a novel temporal representation learning model for predicting future facts named DAuCNet, which applies a Deep Autoregressive structure as the main framework and combines it with a time-aware Copy-based mechanism Network. Specifically, our model proposes a Temporal Fact Encoder to encode historical facts and a Duplicate Fact Collector to collect historically relevant events and identify repetitive events. It employs a multi-relation Neighborhood Aggregator based on graph-attention networks to model the connection of facts at the concurrent window. Finally, DAuCNet integrates these three modules to forecast future facts. Experimental results show that DAuCNet performs significantly better at temporal link prediction and inference for future timestamps than other baselines using five public knowledge graph datasets.},
  archive      = {J_KIS},
  author       = {Hou, Xiangning and Ma, Ruizhe and Yan, Li and Ma, Zongmin},
  doi          = {10.1007/s10115-022-01823-0},
  journal      = {Knowledge and Information Systems},
  month        = {5},
  number       = {5},
  pages        = {2061-2085},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {DAuCNet: Deep autoregressive framework for temporal link prediction combining copy mechanism network},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new approach to neutrosophic soft rough sets.
<em>KIS</em>, <em>65</em>(5), 2043–2060. (<a
href="https://doi.org/10.1007/s10115-022-01824-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rough set is a world-renowned innovation for dealing with ambiguous, incomplete, and imprecise situations. Soft set theory and neutrosophic set theory are other advanced mathematical techniques for dealing with ambiguous, partial, and inconsistent data. The aim of this paper is to broaden the scope of rough set theory, soft set theory, and neutrosophic set theory. The notion of neutrosophic soft rough sets have been re-introduced. On neutrosophic soft rough set, several definitions, properties, and examples have been established. We also develop the concept of neutrosophic soft rough topology, which is based on a novel neutrosophic soft rough set approach. We have defined open sets, closed sets, interior, and closure as characteristics of neutrosophic soft rough topology.},
  archive      = {J_KIS},
  author       = {Yolcu, Adem and Benek, Aysun and Öztürk, Taha Yasin},
  doi          = {10.1007/s10115-022-01824-z},
  journal      = {Knowledge and Information Systems},
  month        = {5},
  number       = {5},
  pages        = {2043-2060},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A new approach to neutrosophic soft rough sets},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel correlation gaussian process regression-based
extreme learning machine. <em>KIS</em>, <em>65</em>(5), 2017–2042. (<a
href="https://doi.org/10.1007/s10115-022-01803-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An obvious defect of extreme learning machine (ELM) is that its prediction performance is sensitive to the random initialization of input-layer weights and hidden-layer biases. To make ELM insensitive to random initialization, GPRELM adopts the simple an effective strategy of integrating Gaussian process regression into ELM. However, there is a serious overfitting problem in kernel-based GPRELM (kGPRELM). In this paper, we investigate the theoretical reasons for the overfitting of kGPRELM and further propose a correlation-based GPRELM (cGPRELM), which uses a correlation coefficient to measure the similarity between two different hidden-layer output vectors. cGPRELM reduces the likelihood that the covariance matrix becomes an identity matrix when the number of hidden-layer nodes is increased, effectively controlling overfitting. Furthermore, cGPRELM works well for improper initialization intervals where ELM and kGPRELM fail to provide good predictions. The experimental results on real classification and regression data sets demonstrate the feasibility and superiority of cGPRELM, as it not only achieves better generalization performance but also has a lower computational complexity.},
  archive      = {J_KIS},
  author       = {Ye, Xuan and He, Yulin and Zhang, Manjing and Fournier-Viger, Philippe and Huang, Joshua Zhexue},
  doi          = {10.1007/s10115-022-01803-4},
  journal      = {Knowledge and Information Systems},
  month        = {5},
  number       = {5},
  pages        = {2017-2042},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A novel correlation gaussian process regression-based extreme learning machine},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Information extraction pipelines for knowledge graphs.
<em>KIS</em>, <em>65</em>(5), 1989–2016. (<a
href="https://doi.org/10.1007/s10115-022-01826-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decade, a large number of knowledge graph (KG) completion approaches were proposed. Albeit effective, these efforts are disjoint, and their collective strengths and weaknesses in effective KG completion have not been studied in the literature. We extend Plumber, a framework that brings together the research community’s disjoint efforts on KG completion. We include more components into the architecture of Plumber  to comprise 40 reusable components for various KG completion subtasks, such as coreference resolution, entity linking, and relation extraction. Using these components, Plumber dynamically generates suitable knowledge extraction pipelines and offers overall 432 distinct pipelines. We study the optimization problem of choosing optimal pipelines based on input sentences. To do so, we train a transformer-based classification model that extracts contextual embeddings from the input and finds an appropriate pipeline. We study the efficacy of Plumber for extracting the KG triples using standard datasets over three KGs: DBpedia, Wikidata, and Open Research Knowledge Graph. Our results demonstrate the effectiveness of Plumber in dynamically generating KG completion pipelines, outperforming all baselines agnostic of the underlying KG. Furthermore, we provide an analysis of collective failure cases, study the similarities and synergies among integrated components and discuss their limitations.},
  archive      = {J_KIS},
  author       = {Jaradeh, Mohamad Yaser and Singh, Kuldeep and Stocker, Markus and Both, Andreas and Auer, Sören},
  doi          = {10.1007/s10115-022-01826-x},
  journal      = {Knowledge and Information Systems},
  month        = {5},
  number       = {5},
  pages        = {1989-2016},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Information extraction pipelines for knowledge graphs},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Selection of browsers for smartphones: A fuzzy hybrid
approach and machine learning technique. <em>KIS</em>, <em>65</em>(5),
1963–1988. (<a
href="https://doi.org/10.1007/s10115-022-01778-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The telecommunication segment has grown tremendously over the past few decades. Particularly smartphones have now turned out to be essential and have outperformed many gadgets like computers, cameras, etc. In this current scenario, smartphones become an essential product for all kinds of consumers such as students, teachers, businessmen, etc. And the consumers also like an extensive number of enhanced and better-quality features being embedded into them. Along with this growth, there is a fast growth of mobile application software providers also. Apart from calling, many consumers use smartphones for browsing the internet. Many android developers provide browser application software with several advancements. This puts the consumers into confusion to select a better browser for their smartphone to accomplish their requirements. Hence the consumers need a proven methodology to select a better browser for their smartphones. To select a better browser, in this paper a hybrid multi-criteria decision making model is proposed by integrating grey relational analysis (GRA) and fuzzy analytical hierarchy process (FAHP). The findings are compared and validated through a machine learning approach also.},
  archive      = {J_KIS},
  author       = {Arunagiri, Ramathilagam and Pandian, Pitchipoo and Krishnasamy, Valarmathi and Ramasamy, Ramani and Sivaprakasam, Rajakarunakaran},
  doi          = {10.1007/s10115-022-01778-2},
  journal      = {Knowledge and Information Systems},
  month        = {5},
  number       = {5},
  pages        = {1963-1988},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Selection of browsers for smartphones: A fuzzy hybrid approach and machine learning technique},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interactive reinforced feature selection with traverse
strategy. <em>KIS</em>, <em>65</em>(5), 1935–1962. (<a
href="https://doi.org/10.1007/s10115-022-01812-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a single-agent Monte Carlo-based reinforced feature selection method, as well as two efficiency improvement strategies, i.e., early stopping strategy and reward-level interactive strategy. Feature selection is one of the most important technologies in data prepossessing, aiming to find the optimal feature subset for a given downstream machine learning task. Enormous research has been done to improve its effectiveness and efficiency. Recently, the multi-agent reinforced feature selection (MARFS) has achieved great success in improving the performance of feature selection. However, MARFS suffers from the heavy burden of computational cost, which greatly limits its application in real-world scenarios. In this paper, we propose an efficient reinforcement feature selection method, which uses one agent to traverse the whole feature set and decides to select or not select each feature one by one. Specifically, we first develop one behavior policy and use it to traverse the feature set and generate training data. And then, we evaluate the target policy based on the training data and improve the target policy by Bellman equation. Besides, we conduct the importance sampling in an incremental way and propose an early stopping strategy to improve the training efficiency by the removal of skew data. In the early stopping strategy, the behavior policy stops traversing with a probability inversely proportional to the importance sampling weight. In addition, we propose a reward-level and training-level interactive strategy to improve the training efficiency via external advice. What’s more, we propose an incremental descriptive statistics method to represent the state with low computational cost. Finally, we design extensive experiments on real-world data to demonstrate the superiority of the proposed method.},
  archive      = {J_KIS},
  author       = {Liu, Kunpeng and Wang, Dongjie and Du, Wan and Wu, Dapeng Oliver and Fu, Yanjie},
  doi          = {10.1007/s10115-022-01812-3},
  journal      = {Knowledge and Information Systems},
  month        = {5},
  number       = {5},
  pages        = {1935-1962},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Interactive reinforced feature selection with traverse strategy},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An in-depth and contrasting survey of meta-heuristic
approaches with classical feature selection techniques specific to
cervical cancer. <em>KIS</em>, <em>65</em>(5), 1881–1934. (<a
href="https://doi.org/10.1007/s10115-022-01825-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data mining and machine learning algorithms’ performance is degraded by data of high-dimensional nature due to an issue called “curse of dimensionality”. Feature selection is a hot research topic where a subset of features are selected to reduce the dimensionality and thereby increasing the accuracy of learning algorithms. Redundant and irrelevant features are eliminated. Cervical cancer is most commonly occurring disease and driving reasons for untimely mortality among ladies worldwide especially in emerging low income nations like India. However, literature shows that the early identification and exact conclusion of cervical malignant growth can increase the survival chances. The disease does not show signs of its presence in the early stages of its growth. Automated classification and diagnosis of cervical cancer using machine learning and deep learning techniques is in high demand as it allows timely, accurate and regular study of the patient’s health progress. Meta-heuristics algorithms provide a global problem independent optimal solution and applied on feature selection problem since decades. In spite of having a good number of literature, there is no survey on feature selection techniques applied to cervical cancer dataset. This paper presents a brief survey on meta-heuristic, its variants, hybrid meta-heuristic and hyper-heuristic techniques. This survey summarizes the feature selection techniques applied to the cervical cancer data to identify the research gap thereby guiding the researchers in the future research direction. The summary of categorization of the techniques such as nature-inspired or non-nature inspired and trajectory or population based is also highlighted. The survey provides a comparative literature review involving classical feature selection techniques and feature selection using metaheuristic algorithms for cervical cancer classification application.},
  archive      = {J_KIS},
  author       = {Kurman, Sangeeta and Kisan, Sumitra},
  doi          = {10.1007/s10115-022-01825-y},
  journal      = {Knowledge and Information Systems},
  month        = {5},
  number       = {5},
  pages        = {1881-1934},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {An in-depth and contrasting survey of meta-heuristic approaches with classical feature selection techniques specific to cervical cancer},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Few-shot partial multi-label learning via prototype
rectification. <em>KIS</em>, <em>65</em>(4), 1851–1880. (<a
href="https://doi.org/10.1007/s10115-022-01819-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial multi-label learning (PML) models the scenario where each training sample is annotated with a candidate label set, among which only a subset corresponds to the ground-truth labels. Existing PML approaches generally promise that there are sufficient partial multi-label samples for training the predictor. Nevertheless, when dealing with new tasks, it is more common that we only have a few PML samples associated with those tasks at hand. Furthermore, existing few-shot learning solutions typically assume the labels of support (training) samples are noise-free; as a result, noisy labels concealed within the candidate labels may seriously misinform the meta-learner and thus lead to a compromised performance. We formalize this problem as new learning paradigm called few-shot partial multi-label learning (FsPML), which aims to induce a noise-robust multi-label classifier with limited PML samples related to the target task. To address this problem, we propose a method named FsPML via prototype rectification (FsPML-PR). Specifically, FsPML-PR first conducts adaptive distance metric learning with an embedding network on the tasks previously encountered. Next, it performs positive/negative prototype rectification and disambiguating labels using samples features and label correlations in the embedding space. A new sample can then be classified based on its distances to the positive and to the negative prototypes. Extensive experimental studies on benchmark datasets certificate that our proposed FsPML achieves superior performance across various settings.},
  archive      = {J_KIS},
  author       = {Zhao, Yunfeng and Yu, Guoxian and Liu, Lei and Yan, Zhongmin and Domeniconi, Carlotta and Zhang, Xiayan and Cui, Lizhen},
  doi          = {10.1007/s10115-022-01819-w},
  journal      = {Knowledge and Information Systems},
  month        = {4},
  number       = {4},
  pages        = {1851-1880},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Few-shot partial multi-label learning via prototype rectification},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Provably accurate and scalable linear classifiers in
hyperbolic spaces. <em>KIS</em>, <em>65</em>(4), 1817–1850. (<a
href="https://doi.org/10.1007/s10115-022-01820-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many high-dimensional practical data sets have hierarchical structures induced by graphs or time series. Such data sets are hard to process in Euclidean spaces, and one often seeks low-dimensional embeddings in other space forms to perform the required learning tasks. For hierarchical data, the space of choice is a hyperbolic space because it guarantees low-distortion embeddings for tree-like structures. The geometry of hyperbolic spaces has properties not encountered in Euclidean spaces that pose challenges when trying to rigorously analyze algorithmic solutions. We propose a unified framework for learning scalable and simple hyperbolic linear classifiers with provable performance guarantees. The gist of our approach is to focus on Poincaré ball models and formulate the classification problems using tangent space formalisms. Our results include a new hyperbolic perceptron algorithm as well as an efficient and highly accurate convex optimization setup for hyperbolic support vector machine classifiers. Furthermore, we adapt our approach to accommodate second-order perceptrons, where data are preprocessed based on second-order information (correlation) to accelerate convergence, and strategic perceptrons, where potentially manipulated data arrive in an online manner and decisions are made sequentially. The excellent performance of the Poincaré second-order and strategic perceptrons shows that the proposed framework can be extended to general machine learning problems in hyperbolic spaces. Our experimental results, pertaining to synthetic, single-cell RNA-seq expression measurements, CIFAR10, Fashion-MNIST and mini-ImageNet, establish that all algorithms provably converge and have complexity comparable to those of their Euclidean counterparts.},
  archive      = {J_KIS},
  author       = {Pan, Chao and Chien, Eli and Tabaghi, Puoya and Peng, Jianhao and Milenkovic, Olgica},
  doi          = {10.1007/s10115-022-01820-3},
  journal      = {Knowledge and Information Systems},
  month        = {4},
  number       = {4},
  pages        = {1817-1850},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Provably accurate and scalable linear classifiers in hyperbolic spaces},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Paired k-NN learners with dynamically adjusted number of
neighbors for classification of drifting data streams. <em>KIS</em>,
<em>65</em>(4), 1787–1816. (<a
href="https://doi.org/10.1007/s10115-022-01817-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the years, several classification algorithms have been proposed in the machine learning area to address challenges related to the continuous arrival of data over time, formally known as data stream. The implementations of these approaches are of vital importance for the different applications where they are used, and they have also received modifications, specifically to address the problem of concept drift, a phenomenon present in classification problems with data streams. The K-nearest neighbors (k-NN) classification algorithm is one of the methods of the family of lazy approaches used to address this problem in online learning, but it still presents some challenges that can be improved, such as the efficient choice of the number of neighbors k used in the learning process. This article proposes paired k-NN learners with dynamically adjusted number of neighbors (PL-kNN), an innovative method which adjusts dynamically and incrementally the number of neighbors used by its pair of k-NN learners in the process of online learning regarding data streams with concept drifts. To validate it, experiments were carried out with both artificial and real-world datasets and the results were evaluated using the accuracy metric, run-time, memory usage, and the Friedman statistical test with the Nemenyi post hoc test. The experimental results show that PL-kNN improves and optimizes the accuracy performances of k-NN with fixed neighboring k values in most tested scenarios.},
  archive      = {J_KIS},
  author       = {Hidalgo, Juan Isidro González and Santos, Silas Garrido T. C. and de Barros, Roberto Souto Maior},
  doi          = {10.1007/s10115-022-01817-y},
  journal      = {Knowledge and Information Systems},
  month        = {4},
  number       = {4},
  pages        = {1787-1816},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Paired k-NN learners with dynamically adjusted number of neighbors for classification of drifting data streams},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Structure-aware attributed heterogeneous network embedding.
<em>KIS</em>, <em>65</em>(4), 1769–1785. (<a
href="https://doi.org/10.1007/s10115-022-01810-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network embedding in heterogeneous network has recently attracted much attention due to its effectiveness in capturing the structure and inherent properties of networks. Most existing models focus on node proximity of networks. Nevertheless, in heterogeneous network, it contains different types (domains) of nodes and edges. The same types of nodes exhibit global patterns widely known as communities, and a community is intuitively identified as a group of nodes with more connections between its internal nodes compared with the external ones. Similarly, we assume that there is also an intermediate structure in the different types of nodes, which we call it as organization, and nodes in an organization interact more frequently than external ones. Thus, nodes within the same community and organization should have similar node embeddings. Inspired by this, we take the structural characteristics in heterogeneous network into consideration and propose a novel structure-aware Attributed Heterogeneous Network Embedding model (SAHNE). Specifically, we first introduce a random walk strategy based upon node degree to sample node sequences, which can better explore the community and organization information in heterogeneous network. Next, we design a structure-aware attributed heterogeneous network embedding model to simultaneously detect community and organization distribution of each node and learn embeddings of nodes, communities and organizations. Extensive experiments on three real-world heterogeneous networks demonstrate that SAHNE outperforms the state-of-the-art methods in terms of various datamining tasks.},
  archive      = {J_KIS},
  author       = {Wei, Hao and Xiong, Gang and Wei, Qiang and Cao, Weiquan and Li, Xin},
  doi          = {10.1007/s10115-022-01810-5},
  journal      = {Knowledge and Information Systems},
  month        = {4},
  number       = {4},
  pages        = {1769-1785},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Structure-aware attributed heterogeneous network embedding},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A three-stage holistic risk assessment approach proposal
based on KEMIRA-m and DEMATEL integration. <em>KIS</em>, <em>65</em>(4),
1735–1768. (<a
href="https://doi.org/10.1007/s10115-022-01809-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a three-stage Modified Kemeny Median Indicator Rank Accordance (KEMIRA-M) and Decision-Making Trial and Evaluation Laboratory (DEMATEL) integration for RA. At the first stage, risk criteria rankings are obtained for each expert separately by implementing DEMATEL. At the second stage, criteria weights obtained from DEMATEL are used to determine Median Priority Components which is an aggregated criterion ranking for all experts as in traditional KEMIRA-M. In this stage, initial decision matrix including danger sources’ performance values for risk criteria is formed and rankings of danger sources are obtained via KEMIRA-M selection procedure considering criteria weights obtained from DEMATEL. At the third stage, direct relationship matrix of DEMATEL is used again to determine affect level of measures on danger sources. Then, by using the danger sources’ weights obtained from the second stage, the measures were prioritized according to the weighted means. This study is the first one that advance KEMIRA-M’s weighting procedure by implementing DEMATEL. In this way, a systematic weighting procedure has been gained for KEMIRA-M and a rule-based weight assignment can be performed for risk criteria in KEMIRA-M. Additionally, a three-step KEMIRA-M and DEMATEL is first proposed in this study as a holistic RA to prioritize measures. There is no study that considers risk criteria, danger sources and measures at the same time to prioritize measures. This study provides a new comprehensive approach for experts and executives to make a work plan for measure applications considering risk criteria and danger sources.},
  archive      = {J_KIS},
  author       = {Toktaş, Pelin and Can, Gülin Feryal},
  doi          = {10.1007/s10115-022-01809-y},
  journal      = {Knowledge and Information Systems},
  month        = {4},
  number       = {4},
  pages        = {1735-1768},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A three-stage holistic risk assessment approach proposal based on KEMIRA-M and DEMATEL integration},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Matching news articles and wikipedia tables for news
augmentation. <em>KIS</em>, <em>65</em>(4), 1713–1734. (<a
href="https://doi.org/10.1007/s10115-022-01815-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, digital-news understanding is often overwhelmed by the deluge of online information. One approach to cover this gap is to outline the news story by highlighting the most relevant facts. For example, recent studies summarize news articles by generating representative headlines. In this paper, we go beyond and argue news understanding can also be enhanced by surfacing contextual data relevant to the article, such as structured web tables. Specifically, our goal is to match news articles and web tables for news augmentation. For that, we introduce a novel BERT-based attention model to compute this matching degree. Through an extensive experimental evaluation over Wikipedia tables, we compare the performance of our model with standard IR techniques, document/sentence encoders and neural IR models for this task. The overall results point out our model outperforms all baselines at different levels of accuracy and in the mean reciprocal ranking measure.},
  archive      = {J_KIS},
  author       = {Silva, Levy and Barbosa, Luciano},
  doi          = {10.1007/s10115-022-01815-0},
  journal      = {Knowledge and Information Systems},
  month        = {4},
  number       = {4},
  pages        = {1713-1734},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Matching news articles and wikipedia tables for news augmentation},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient joint framework for interacting knowledge graph
and item recommendation. <em>KIS</em>, <em>65</em>(4), 1685–1712. (<a
href="https://doi.org/10.1007/s10115-022-01808-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incorporating knowledge graphs in recommendation systems is promising as knowledge graphs can be a side information for recommendation systems to alleviate the sparsity and the cold start problems. However, existing works essentially assume that side information (i.e.,  knowledge graphs) is completed, which may lead to sub-optimal performance. Meanwhile, semantic hierarchies implied in applications are prevalent, and many existing approaches fail to model this semantic characteristic. Modeling the semantic structure between items in recommendation systems is a crucial challenge. Therefore, it is crucial to solve the incompleteness of knowledge graphs when integrating it into recommendation system as well as to represent the hierarchical structure contained in items. In this paper, we propose Paguridae, a framework that utilizes the item recommendation task to assist link prediction task. A core idea of the Paguridae is that two tasks automatically share the potential features between items and entities. We adopt two main structures to model the hierarchy between items and entities. In order to model the hierarchy in items, we adopt graph convolutional networks as a representation learning method. In order to model the hierarchy in entities, we use Hirec model, which maps entities into the polar coordinate system. Under the framework, users can get better recommendations and knowledge graphs can be completed as these two tasks have a mutual effect. Experiments on two real-world datasets show that the Paguridae can be trained substantially, improving F1-score by 62.51% and precision by 49.31% compared to the state-of-the-art methods.},
  archive      = {J_KIS},
  author       = {Du, Haizhou and Tang, Yue and Cheng, Zebang},
  doi          = {10.1007/s10115-022-01808-z},
  journal      = {Knowledge and Information Systems},
  month        = {4},
  number       = {4},
  pages        = {1685-1712},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {An efficient joint framework for interacting knowledge graph and item recommendation},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hypergraph-based importance assessment for binary
classification data. <em>KIS</em>, <em>65</em>(4), 1657–1683. (<a
href="https://doi.org/10.1007/s10115-022-01786-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel hypergraph-based framework enabling an assessment of the importance of binary classification data elements. Specifically, we apply the hypergraph model to rate data samples’ and categorical feature values’ relevance to classification labels. The proposed Hypergraph-based Importance ratings are theoretically grounded on the hypergraph cut conductance minimization concept. As a result of using hypergraph representation, which is a lossless representation from the perspective of higher-order relationships in data, our approach allows for more precise exploitation of the information on feature and sample coincidences. The solution was tested using two scenarios: undersampling for imbalanced classification data and feature selection. The experimentation results have proven the good quality of the new approach when compared with other state-of-the-art and baseline methods for both scenarios measured using the average precision evaluation metric.},
  archive      = {J_KIS},
  author       = {Misiorek, Pawel and Janowski, Szymon},
  doi          = {10.1007/s10115-022-01786-2},
  journal      = {Knowledge and Information Systems},
  month        = {4},
  number       = {4},
  pages        = {1657-1683},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Hypergraph-based importance assessment for binary classification data},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph transfer learning. <em>KIS</em>, <em>65</em>(4),
1627–1656. (<a
href="https://doi.org/10.1007/s10115-022-01782-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph embeddings have been tremendously successful at producing node representations that are discriminative for downstream tasks. In this paper, we study the problem of graph transfer learning: given two graphs and labels in the nodes of the first graph, we wish to predict the labels on the second graph. We propose a tractable, non-combinatorial method for solving the graph transfer learning problem by combining classification and embedding losses with a continuous, convex penalty motivated by tractable graph distances. We demonstrate that our method successfully predicts labels across graphs with almost perfect accuracy; in the same scenarios, training embeddings through standard methods leads to predictions that are no better than random.},
  archive      = {J_KIS},
  author       = {Gritsenko, Andrey and Shayestehfard, Kimia and Guo, Yuan and Moharrer, Armin and Dy, Jennifer and Ioannidis, Stratis},
  doi          = {10.1007/s10115-022-01782-6},
  journal      = {Knowledge and Information Systems},
  month        = {4},
  number       = {4},
  pages        = {1627-1656},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Graph transfer learning},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep reinforcement learning agent for geometry online
tutoring. <em>KIS</em>, <em>65</em>(4), 1611–1625. (<a
href="https://doi.org/10.1007/s10115-022-01804-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we apply deep reinforcement learning (DRL) for geometry reasoning and develop Dragon to facilitate online tutoring. Its success is contingent on a flexible data model to capture diverse concepts and heterogeneous relations, as well as an effective DRL agent to generate near-optimal and human-readable solutions. We use proximal policy optimization (PPO) as the backbone DRL architecture, customized with effective state representation and integrated with a bunch of optimization tricks including attention mechanism, action mask, data augmentation and curriculum learning. In our experimental study, we craft so far the largest scale dataset with geometry problems and a knowledge base with 46 theorems. We implement various heuristic algorithms and DRL models as baselines for performance comparison. The results show that our agent achieves near-optimal solution and is superior over multiple competitive baselines. To benefit the community, we opensource the dataset and implementation at https://github.com/AIEdu-xzy/geometry-solver .},
  archive      = {J_KIS},
  author       = {Xiao, Ziyang and Zhang, Dongxiang},
  doi          = {10.1007/s10115-022-01804-3},
  journal      = {Knowledge and Information Systems},
  month        = {4},
  number       = {4},
  pages        = {1611-1625},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A deep reinforcement learning agent for geometry online tutoring},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An experimental study on classifying spatial trajectories.
<em>KIS</em>, <em>65</em>(4), 1587–1609. (<a
href="https://doi.org/10.1007/s10115-022-01802-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide the first comprehensive study on how to classify trajectories using only their spatial representations, measured on 5 real-world datasets. Our comparison considers 20 distinct classifiers arising either as a KNN classifier of a popular distance, or as a more general type of classifier using a vectorized representation of each trajectory. We additionally develop new methods for how to vectorize trajectories via a data-driven method to select the associated landmarks, and these methods prove among the most effective in our study. These vectorized approaches are simple and efficient to use, and also provide state-of-the-art accuracy on an established transportation mode classification task. In all, this study sets the standard for how to classify trajectories, including introducing new simple techniques to achieve these results, and sets a rigorous standard for the inevitable future study on this topic.},
  archive      = {J_KIS},
  author       = {Pourmahmood-Aghababa, Hasan and Phillips, Jeff M.},
  doi          = {10.1007/s10115-022-01802-5},
  journal      = {Knowledge and Information Systems},
  month        = {4},
  number       = {4},
  pages        = {1587-1609},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {An experimental study on classifying spatial trajectories},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Temporal hypergraph motifs. <em>KIS</em>, <em>65</em>(4),
1549–1586. (<a
href="https://doi.org/10.1007/s10115-023-01837-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group interactions arise in our daily lives (email communications, on-demand ride sharing, and comment interactions on online communities, to name a few), and they together form hypergraphs that evolve over time. Given such temporal hypergraphs, how can we describe their underlying design principles? If their sizes and time spans are considerably different, how can we compare their structural and temporal characteristics? In this work, we define 96 temporal hypergraph motifs (TH-motifs) and propose the relative occurrences of their instances as an answer to the above questions. TH-motifs categorize the relational and temporal dynamics among three connected hyperedges that appear within a short time. For scalable analysis, we develop THyMe $$^{+}$$ , a fast and exact algorithm for counting the instances of TH-motifs in massive hypergraphs, and we show that THyMe $$^{+}$$ is up to 2,163 $$\times $$ faster while requiring less space than baseline approaches. In addition to exact counting algorithms, we design three versions of sampling algorithms for approximate counting. We theoretically analyze the accuracy of the proposed methods, and we empirically show that the most advanced algorithm, is up to $$11.1\times $$ more accurate than baseline approaches. Using the algorithms, we investigate 11 real-world temporal hypergraphs from various domains. We demonstrate that TH-motifs provide important information useful for downstream tasks and reveal interesting patterns, including the striking similarity between temporal hypergraphs from the same domain.},
  archive      = {J_KIS},
  author       = {Lee, Geon and Shin, Kijung},
  doi          = {10.1007/s10115-023-01837-2},
  journal      = {Knowledge and Information Systems},
  month        = {4},
  number       = {4},
  pages        = {1549-1586},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Temporal hypergraph motifs},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph theory-based mathematical modeling and analysis to
predict a football dream team. <em>KIS</em>, <em>65</em>(4), 1523–1547.
(<a href="https://doi.org/10.1007/s10115-023-01849-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The popularity of football among fans to analyze the game has been immense with the advent of internet. The concept of making a dream team in football has become a new fashion for the football lovers. The paper focuses in helping achieving this prediction of a football dream team. The aim of this research is to assess the dynamics of a complex topological structure when prompted with random entities whose attributes are known to us. Using graph theory and vectorial distances, the dream team is evaluated on the basis of individual abilities and interplayer synergy. Instead of focusing on discrete events in a match, this framework proposes an idea in which a dream team is quantified on the basis of their positional attributes. Each player is rated in accordance to the position he is playing, which eventually helps in finding the overall team rating. The second part of this research uses graph theory to evaluate structural and topological properties of interpersonal interactions of teammates. Teammates are treated as nodes of a graph, where each edge exemplifies the strength of their interpersonal interaction. The strength of the bond depends on on-field interactions via ball passing, ball receiving and communication which depend on experience of playing together, Nationality and Club. The methodology adopted in this paper can be a formidable basis for similarly situated larger setups involving much larger intricacies. Using this framework, we can see the behavior of a hypothetical topological structure whose node attributes are known to us, thus projecting its performance as a team and individual entities.},
  archive      = {J_KIS},
  author       = {Vyas, Anamaya and Parnami, Arsh and Prusty, Manas Ranjan},
  doi          = {10.1007/s10115-023-01849-y},
  journal      = {Knowledge and Information Systems},
  month        = {4},
  number       = {4},
  pages        = {1523-1547},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Graph theory-based mathematical modeling and analysis to predict a football dream team},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fair and interpretable network for clinical risk
prediction: A regularized multi-view multi-task learning approach.
<em>KIS</em>, <em>65</em>(4), 1487–1521. (<a
href="https://doi.org/10.1007/s10115-022-01813-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In healthcare domain, complication risk profiling which can be seen as multiple clinical risk prediction tasks is challenging due to the complex interaction between heterogeneous clinical entities. With the availability of real-world data, many deep learning methods are proposed for complication risk profiling. However, the existing methods face three open challenges. First, they leverage clinical data from a single view and then lead to suboptimal models. Second, most existing methods lack an effective mechanism to interpret predictions. Third, models learned from clinical data may have inherent pre-existing biases and exhibit discrimination against certain social groups. We then propose a multi-view multi-task network (MuViTaNet) to tackle these issues. MuViTaNet complements patient representation by using a multi-view encoder to exploit more information. Moreover, it uses a multi-task learning to generate more generalized representations using both labeled and unlabeled datasets. Last, a fairness variant (F-MuViTaNet) is proposed to mitigate the unfairness issues and promote healthcare equity. The experiments show that MuViTaNet outperforms existing methods for cardiac complication profiling. Its architecture also provides an effective mechanism for interpreting the predictions, which helps clinicians discover the underlying mechanism triggering the complication onsets. F-MuViTaNet can also effectively mitigate the unfairness with only negligible impact on accuracy.},
  archive      = {J_KIS},
  author       = {Pham, Thai-Hoang and Yin, Changchang and Mehta, Laxmi and Zhang, Xueru and Zhang, Ping},
  doi          = {10.1007/s10115-022-01813-2},
  journal      = {Knowledge and Information Systems},
  month        = {4},
  number       = {4},
  pages        = {1487-1521},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A fair and interpretable network for clinical risk prediction: A regularized multi-view multi-task learning approach},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning-based question answering: A survey.
<em>KIS</em>, <em>65</em>(4), 1399–1485. (<a
href="https://doi.org/10.1007/s10115-022-01783-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Question Answering is a crucial natural language processing task. This field of research has attracted a sudden amount of interest lately due mainly to the integration of the deep learning models in the Question Answering Systems which consequently power up many advancements and improvements. This survey aims to explore and shed light upon the recent and most powerful deep learning-based Question Answering Systems and classify them based on the deep learning model used, stating the details of the used word representation, datasets, and evaluation metrics. It aims to highlight and discuss the currently used models and give insights that direct future research to enhance this increasingly growing field.},
  archive      = {J_KIS},
  author       = {Abdel-Nabi, Heba and Awajan, Arafat and Ali, Mostafa Z.},
  doi          = {10.1007/s10115-022-01783-5},
  journal      = {Knowledge and Information Systems},
  month        = {4},
  number       = {4},
  pages        = {1399-1485},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Deep learning-based question answering: A survey},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tailoring and evaluating the wikipedia for in-domain
comparable corpora extraction. <em>KIS</em>, <em>65</em>(3), 1365–1397.
(<a href="https://doi.org/10.1007/s10115-022-01767-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a language-independent graph-based method to build à-la-carte article collections on user-defined domains from the Wikipedia. The core model is based on the exploration of the encyclopedia’s category graph and can produce both mono- and multilingual comparable collections. We run thorough experiments to assess the quality of the obtained corpora in 10 languages and 743 domains. According to an extensive manual evaluation, our graph model reaches an average precision of $$84\%$$ on in-domain articles, outperforming an alternative model based on information retrieval techniques. As manual evaluations are costly, we introduce the concept of domainness and design several automatic metrics to account for the quality of the collections. Our best metric for domainness shows a strong correlation with human judgments, representing a reasonable automatic alternative to assess the quality of domain-specific corpora. We release the WikiTailor toolkit with the implementation of the extraction methods, the evaluation measures and several utilities.},
  archive      = {J_KIS},
  author       = {España-Bonet, Cristina and Barrón-Cedeño, Alberto and Màrquez, Lluís},
  doi          = {10.1007/s10115-022-01767-5},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {1365-1397},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Tailoring and evaluating the wikipedia for in-domain comparable corpora extraction},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated urban planning aware spatial hierarchies and human
instructions. <em>KIS</em>, <em>65</em>(3), 1337–1364. (<a
href="https://doi.org/10.1007/s10115-022-01801-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional urban planning demands urban experts to spend much time producing an optimal urban plan under many architectural constraints. The remarkable imaginative ability of deep generative learning provides hope for renovating this domain. Existing works are constrained by: (1) neglecting human requirements; (2) omitting spatial hierarchies, and (3) lacking urban plan samples. We propose a novel, deep human-instructed urban planner to fill these gaps and implement two practical frameworks. In the preliminary version, we formulate the task into an encoder–decoder paradigm. The encoder is to learn the information distribution of surrounding contexts, human instructions, and land-use configuration. The decoder is to reconstruct the land-use configuration and the associated urban functional zones. Although it has achieved good results, the generation performance is still unstable due to the complex optimization directions of the decoder. Thus, we propose a cascading deep generative adversarial network (GAN) in this paper, inspired by the workflow of urban experts. The first GAN is to build urban functional zones based on human instructions and surrounding contexts. The second GAN will produce the land-use configuration by considering the built urban functional zones. Finally, we conducted extensive experiments and case studies to validate the effectiveness and superiority of our work.},
  archive      = {J_KIS},
  author       = {Wang, Dongjie and Liu, Kunpeng and Huang, Yanyong and Sun, Leilei and Du, Bowen and Fu, Yanjie},
  doi          = {10.1007/s10115-022-01801-6},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {1337-1364},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Automated urban planning aware spatial hierarchies and human instructions},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved score aggregation for authorship verification.
<em>KIS</em>, <em>65</em>(3), 1317–1336. (<a
href="https://doi.org/10.1007/s10115-022-01798-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Impostors method is one of the most successful solvers of author verification problems. Given a pair of texts, it aims to find whether the same author wrote them or not. This paper describes a proposed approach with the primary objective of achieving a higher classification accuracy. This higher accuracy is achieved by modifying the vector representations of input texts, such that the effect of them possibly being in different domains is reduced. Such vector modification factors are obtained by the addition of a computational step that empirically estimates the expected difference, or ratio, between the questioned texts’ similarity scores against their in-domain samples. Our evaluation confirms that our proposed approach is capable of achieving higher classification accuracy than the original method. Despite the size of the evaluation dataset, some of the increases in the classification accuracy are large enough to allow for observing statistically significant, very significant, and highly significant gains.},
  archive      = {J_KIS},
  author       = {Khonji, Mahmoud and Iraqi, Youssef and Mekouar, Loubna},
  doi          = {10.1007/s10115-022-01798-y},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {1317-1336},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Improved score aggregation for authorship verification},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust and fast low-rank deep convolutional feature
recovery: Toward information retention and accelerated convergence.
<em>KIS</em>, <em>65</em>(3), 1287–1315. (<a
href="https://doi.org/10.1007/s10115-022-01795-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Notwithstanding the great progress on deep convolutional neural networks (CNNs) has been made during last decade, the representation ability may still be restricted and it usually needs more epochs to converge in training, due to the information loss caused by the up-/down-sampling operations. In this paper, we propose a general deep feature recovery layer, termed Low-rank Deep Feature Recovery (LDFR), to enhance the representation of convolutional features by seamlessly integrating the low-rank recovery into CNNs, which can be easily extended to all CNNs-based models. To be specific, to recover the lost useful information, LDFR learns the low-rank projections to embed feature maps onto a low-rank subspace based on the selected informative convolutional feature maps. Such operation can ensure all the convolutional feature maps to be reconstructed easily to recover the underlying subspace, with more useful detailed information discovered, e.g., the strokes of characters or the texture information of clothes. To make the learnt low-rank subspaces more powerful for feature recovery, we design a fusion strategy to obtain a generalized subspace, which averages over all learnt subspaces in each LDFR layer, so that the convolutional features in test phase can be recovered effectively via low-rank embedding. We also present a fast version of LDFR, called FLDFR, to speedup the optimization of LDFR by flattening all feature maps of batch images to recover the lost information. Extensive simulations on several image datasets show that the existing CNN models equipped with our LDFR layers can obtain better performance.},
  archive      = {J_KIS},
  author       = {Ren, Jiahuan and Zhang, Zhao and Fan, Jicong and Zhang, Haijun and Xu, Mingliang and Wang, Meng},
  doi          = {10.1007/s10115-022-01795-1},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {1287-1315},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Robust and fast low-rank deep convolutional feature recovery: Toward information retention and accelerated convergence},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Advanced agronomics model with species classification,
minimum support price prediction, and profit suggestion using enhanced
deep learning strategy. <em>KIS</em>, <em>65</em>(3), 1243–1285. (<a
href="https://doi.org/10.1007/s10115-022-01787-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimum support price (MSP) is an advisory price signal, which is a component of a huge collection of agricultural policies in parts of India. The agricultural commodities evaluate the derivatives by noticing the climate changes regarding external factors like economic and weather conditions. The severe changes in these factors result in significant price changes. Here, it may experience more cost-efficiency in analyzing the agricultural species. The problem arises because the mixed species in the single pixel increases the pixel size. The high-dimensional problem of input and outputs occurs in the hyper-spectral data. Hence, this research implements a new MSP method in Agronomics or Agriculture through deep learning algorithms. In the species prediction phase, the input remote sensing images are gathered and processed in pre-processing phase using median filtering and contrast limited adaptive histogram equalization. Here, the pre-processed images are fed to feature extraction using the gray-level co-occurrence matrix (GLCM) and spatial feature extraction techniques. Further, the deep feature extraction is analyzed using convolutional neural network (CNN) by considering the input as the pre-processed images and extracting GLCM and spatial features. These deep features are forwarded to the enhanced recurrent neural-long short-term memory (ERN-LSTM), where the parameters of RNN and LSTM are tuned by self-adaptive dingo optimizer (SA-DOX). Finally, the species prediction outcomes are attained by enhanced RNN + LSTM. Secondly, in the MSP prediction phase, the major aim is to predict the MSP based on the species detected. Here, the gathered price data, along with the extracted CNN-based deep features, are processed to select the significant optimal features and are carried out by the same improved DOX. The selected features are given to enhanced RNN + LSTM for predicting the MSP price related to the crop type. Thirdly, the predicted prices are split into four shares. Fourthly, profit suggestion is carried out by training the location and regional crop data, and thus, the enhanced RNN + LSTM model gives the best profitable harvests. Through the experimental results, the accuracy of species classification using SA-DOX-based ERN-LSTM was 10.9, 8.3, 6.85, and 4.7%, accordingly advanced than SVM, LSTM, RNN, and RNN-LSTM. From the given findings, the better accuracy rate of the given designed method is 96.75%. Accordingly, the better sensitivity and precision rates are 95.9 and 95.5%. Finally, this study explores competitive performance through the experimental results relative to the traditional approaches.},
  archive      = {J_KIS},
  author       = {Visnu Dharsini, S. and Babu, S.},
  doi          = {10.1007/s10115-022-01787-1},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {1243-1285},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Advanced agronomics model with species classification, minimum support price prediction, and profit suggestion using enhanced deep learning strategy},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploiting anonymous entity mentions for named entity
linking. <em>KIS</em>, <em>65</em>(3), 1221–1242. (<a
href="https://doi.org/10.1007/s10115-022-01793-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named entity linking or named entity disambiguation is to link entity mentions to corresponding entities in a knowledge base for resolving the ambiguity of entity mentions. Recently, collective linking methods exploit document-level coherence of the referenced entities by computing a pairwise score between candidates of a pair of named entity mentions (e.g., Raytheon and Boeing) in a document. However, in a document, named entity mentions are significantly less frequent than anonymous entity mentions (e.g., defense contractor and the company). In this paper, we propose a method, DOCument-level Anonymous Entity Type words relatedness (DOC-AET), to exploit the document-level coherence between candidate entities and anonymous entity mentions. We use the anonymous entity type (AET) words to extract anonymous entity mentions. We learn embeddings of AET words from their inter-paragraph co-occurrence matrix; thus, the document-level entity-type relatedness is encoded in the AET word embeddings. Then, we compute the coherence scores between candidate entities and anonymous entity mentions using the AET entity embeddings and document context embeddings. By incorporating such coherence scores for candidates ranking, DOC-AET has achieved new state-of-the-art results on two of the five out-domain test sets for named entity linking.},
  archive      = {J_KIS},
  author       = {Hou, Feng and Wang, Ruili and Ng, See-Kiong and Witbrock, Michael and Zhu, Fangyi and Jia, Xiaoyun},
  doi          = {10.1007/s10115-022-01793-3},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {1221-1242},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Exploiting anonymous entity mentions for named entity linking},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluation of information diffusion path based on a
multi-topic relationship strength network. <em>KIS</em>, <em>65</em>(3),
1199–1220. (<a
href="https://doi.org/10.1007/s10115-022-01794-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Paths in online social networks play different roles in information dissemination. Ranking edges and identifying the influential edges in OSNs are imperative for intervening in or guiding information diffusion. The existing studies are limited to measuring the weight of paths in networks or the impact of paths on network connectivity while ignoring measuring the role of paths in information diffusion. In this study, we solve the problem by constructing an interactive network and calculating the information diffusion capacity (IDC) of paths. First, a multi-topic relationship strength network is constructed to describe users’ interactive preferences. Second, we propose the IDC method to measure the IDC of paths considering users’ interactive activity, relationship strength, users’ influence and users’ topic preferences. Users’ multi-topic relationship strength makes it possible to distinguish the importance of edges under different topics. Finally, we compare the IDC method with the baseline methods including the connectivity-based method and the method of edge betweenness centrality from the perspectives of ranking granularity and spreading ability in two subnets from Sina Weibo and Twitter. The results show that the IDC method ranks edges in finer grain than the connectivity-based method. Based on the SIR model, we compare the spreading ability of the three methods and find that the important edges evaluated by the IDC method behave better in topic spreading. Application exploration shows that the backbone network and the weak ties in information diffusion can be discovered through evaluating the paths in the relationship strength network.},
  archive      = {J_KIS},
  author       = {Zhu, Hengmin and Yang, Xinyi and Wei, Jing and Shen, Chao},
  doi          = {10.1007/s10115-022-01794-2},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {1199-1220},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Evaluation of information diffusion path based on a multi-topic relationship strength network},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new method of ensemble learning: Case of cryptocurrency
price prediction. <em>KIS</em>, <em>65</em>(3), 1179–1197. (<a
href="https://doi.org/10.1007/s10115-022-01796-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a novel method of ensemble learning for time series prediction. Different machine learning-based models have been integrated, and a combined prediction model has been created. The objective of the ensemble model is that it must outperform all other individual models that are used to construct the ensemble model in terms of producing excellent predictions. The field of cryptocurrencies has been selected as the domain of this work where the focus is to predict the cryptocurrency prices using the proposed model. A new regression model is proposed and implemented in this work. Different machine learning techniques have been adopted and integrated to form a combined prediction model. The machine learning models include deep neural networks, support vector regression, and decision trees. The regression scheme has to be implemented on each machine learning model separately as well as their performance is also to be improved. The combined prediction model requires optimal weights generation for integration, and therefore, time complexity is a concern. A large set of experiments have been carried out on various cryptocurrencies and the results are displayed. Real-world data has been used here and a comparison is also performed. It is observed that the combined prediction model outperforms other models resulting in excellent predictions capturing most of the nonstationary movements in the data.},
  archive      = {J_KIS},
  author       = {Rather, Akhter Mohiuddin},
  doi          = {10.1007/s10115-022-01796-0},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {1179-1197},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A new method of ensemble learning: Case of cryptocurrency price prediction},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identifying significant textual features in titles of google
play store applications and their influence on user review rating.
<em>KIS</em>, <em>65</em>(3), 1159–1178. (<a
href="https://doi.org/10.1007/s10115-022-01799-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User review rating of mobile applications is a crucial factor related to downloads and it greatly impacts the customer’s decisions to prefer the applications with the highest (most positive) ratings. Whereas, titles are among the first information displayed to users when they search for any particular application and a compelling title can be a leading cause for an application’s success. Hence, developer companies fashion (optimize) their application titles strategically, in such a way, that they are highly eye-catching and descriptive about application functionalities in an attempt to lure users to download and positively rate their applications. However, traditional literature may lack the scientific approaches which investigate what (specific) kind of textual features in application titles actually have a positive (or negative) effect on the review rating. Therefore, aim of this research work is to perform two separate kinds of scientific analyses to determine the impacts of unconscious (aspects usually not observed by users) and conscious (keyterms which are observed by users) features of Google-play store application titles on the user review rating. At first, for the investigation of unconscious aspects various machine learning algorithms are employed and secondly, for the conscious features another keyterms analysis is carried out. Overall, according to the results, certain unconscious aspects can lead towards the elevated review ratings in both cases of Applications and Games. Albeit, conscious aspects tend to have a positive impact only on the review ratings of Games.},
  archive      = {J_KIS},
  author       = {Bilal, Ahmad and Mirza, Hamid Turab and Hussain, Ibrar},
  doi          = {10.1007/s10115-022-01799-x},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {1159-1178},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Identifying significant textual features in titles of google play store applications and their influence on user review rating},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DNETC: Dynamic network embedding preserving both triadic
closure evolution and community structures. <em>KIS</em>,
<em>65</em>(3), 1129–1157. (<a
href="https://doi.org/10.1007/s10115-022-01792-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network embedding, a central issue of deep learning preprocessing on social networks, aims to transform network elements (vertices) into low-dimensional latent vector space while preserving the topology and properties of the network. However, most of the existing methods mainly focus on static networks, neglecting the dynamic characteristics of real social networks. The explanation for the fundamental dynamic mechanism of social network evolution is still lacking. We design a novel dynamic network embedding approach preserving both triadic closure evolution and community structures (DNETC). First, three factors, the popularity of vertices, the proximity of vertices, and the community structures, are incorporated relying on the triadic closure principle in social networks. Second, the triadic closure loss function, the community loss function, and the temporal smoothness loss function are constructed and incorporated to optimize DNETC. Finally, the low-dimensional cognition presentation of a dynamic social network can be achieved, which can save both the evolution patterns of microscopic vertices and the structure information of macroscopic communities. Experiments on the classical tasks of link prediction, link reconstruction, and changed link reconstruction and prediction demonstrate the superiority of DNETC over state-of-the-art methods. The first experimental results validate the effectiveness of adopting triadic closure progress and community structures to improve the quality of the learned low-dimensional vectors. The last experimental results further verify the parameter sensitivity of DNETC to the analysis task. It provides a new idea for dynamic network embedding to reflect the real evolution characteristics of networks and enhance the effect of network analysis tasks. The code is available at https://github.com/YangMin-10/DNETC .},
  archive      = {J_KIS},
  author       = {Yang, Min and Chen, Xiaoliang and Chen, Baiyang and Lu, Peng and Du, Yajun},
  doi          = {10.1007/s10115-022-01792-4},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {1129-1157},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {DNETC: Dynamic network embedding preserving both triadic closure evolution and community structures},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic ensemble selection classification algorithm based on
window over imbalanced drift data stream. <em>KIS</em>, <em>65</em>(3),
1105–1128. (<a
href="https://doi.org/10.1007/s10115-022-01791-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data stream classification is an important research direction in the field of data mining, but in many practical applications, it is impossible to collect the complete training set at one time, and the data may be in an imbalanced state and interspersed with concept drift, which will greatly affect the classification performance. To this end, an online dynamic ensemble selection classification algorithm based on window over imbalanced drift data stream (DESW-ID) is proposed. The algorithm employs various balancing measures, first resampling the data stream using Poisson distribution, and if it is in a highly imbalanced state then secondary sampling is performed using a window storing a minority class instances to achieve the current balanced state of the data. To improve the processing efficiency of the algorithm, a classifier selection ensemble is proposed to dynamically adjust the number of classifiers, and the algorithm runs with an ADWIN detector to detect the presence of concept drift. The experimental results show that the proposed algorithm ranks first on average in all five classification performance metrics compared to the state-of-the-art methods. Therefore, the proposed algorithm has better classification performance for imbalanced data streams with concept drift and also improves the operation efficiency of the algorithm.},
  archive      = {J_KIS},
  author       = {Han, Meng and Zhang, Xilong and Chen, Zhiqiang and Wu, Hongxin and Li, Muhang},
  doi          = {10.1007/s10115-022-01791-5},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {1105-1128},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Dynamic ensemble selection classification algorithm based on window over imbalanced drift data stream},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Logical design of multi-model data warehouses. <em>KIS</em>,
<em>65</em>(3), 1067–1103. (<a
href="https://doi.org/10.1007/s10115-022-01788-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-model DBMSs, which support different data models with a fully integrated backend, have been shown to be beneficial to data warehouses and OLAP systems. Indeed, they can store data according to the multidimensional model and, at the same time, let each of its elements be represented through the most appropriate model. An open challenge in this context is the lack of methods for logical design. Indeed, in a multi-model context, several alternatives emerge for the logical representation of dimensions and facts. The goal of this paper is to devise a set of guidelines for the logical design of multi-model data warehouses so that the designer can achieve the best trade-off between features such as querying, storage, and ETL. To this end, for each model considered (relational, document-based, and graph-based) and for each type of multidimensional element (e.g., non-strict hierarchy) we propose some solutions and carry out a set of intra-model and inter-model comparisons. The resulting guidelines are then tested on a case study that shows all types of multidimensional elements.},
  archive      = {J_KIS},
  author       = {Bimonte, Sandro and Gallinucci, Enrico and Marcel, Patrick and Rizzi, Stefano},
  doi          = {10.1007/s10115-022-01788-0},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {1067-1103},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Logical design of multi-model data warehouses},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). KLECA: Knowledge-level-evolution and category-aware
personalized knowledge recommendation. <em>KIS</em>, <em>65</em>(3),
1045–1065. (<a
href="https://doi.org/10.1007/s10115-022-01789-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge recommendation plays a crucial role in online learning platforms. It aims to optimize the service quality so as to improve users’ learning efficiency and outcomes. Existing approaches generally leverage RNN-based methods in combination with attention mechanisms to learn user preference. There is a lack of in-depth understanding of users’ knowledge-level changes over time and the impact of knowledge item categories on recommendation performance. To this end, we propose the knowledge-level-evolution and category-aware personalized knowledge recommendation (KLECA) model. The model firstly leverages bidirectional GRU and the time adjustment function to understand users’ learning evolution by analyzing their learning trajectory data. Secondly, it considers the effect of item categories and descriptive information and enhances the accuracy of knowledge recommendation by introducing a cross-head decorrelation module to capture the information of knowledge items based on a multi-head attention mechanism. In addition, a personalized attention mechanism and gated function are introduced to grab the relationship between items, item categories and user learning trajectory to strengthen the representation of information. Through extensive experiments on real-world data collected from an online learning platform, the proposed approach has been shown to significantly outperform other approaches.},
  archive      = {J_KIS},
  author       = {Cheng, Lin and Shi, Yuliang and Li, Lin and Yu, Han and Wang, Xinjun and Yan, Zhongmin},
  doi          = {10.1007/s10115-022-01789-z},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {1045-1065},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {KLECA: Knowledge-level-evolution and category-aware personalized knowledge recommendation},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Concept drift detection and accelerated convergence of
online learning. <em>KIS</em>, <em>65</em>(3), 1005–1043. (<a
href="https://doi.org/10.1007/s10115-022-01790-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Streaming data has become an important form in the era of big data, and the concept drift, as one of the most important problem of it, is often studied deeply. However, similar to true concept drift, noise and too small training samples will also lead to the classification performance fluctuation, which is easy to confuse with true concept drift. To solve this problem, an improved concept drift detection method is proposed, and the accelerated convergence of the model after concept drift is also studied. Firstly, the effective fluctuation sites can be obtained by group detection method. Secondly, the authenticity of concept drift can be determined by tracking the testing accuracy of reference sites near the effective fluctuation site. Lastly, in the convergence acceleration stage, the time sequential distance is designed to measure the similarity of these sequential data blocks during different time periods, and the noncritical disturbance data with the largest time sequential distance are removed sequentially to improve the convergence speed of the model after concept drift occurs. The experimental results demonstrate that the proposed method not only produces better identification results in distinguishing true and false concept drift but also improves the convergence speed of the model.},
  archive      = {J_KIS},
  author       = {Guo, Husheng and Li, Hai and Sun, Ni and Ren, Qiaoyan and Zhang, Aijuan and Wang, Wenjian},
  doi          = {10.1007/s10115-022-01790-6},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {1005-1043},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Concept drift detection and accelerated convergence of online learning},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic construction of non-i.i.d. Data sets from a
single data set: Non-identically distributed data. <em>KIS</em>,
<em>65</em>(3), 991–1003. (<a
href="https://doi.org/10.1007/s10115-022-01785-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven models strongly depend on data. Nevertheless, for research and academic purposes, public data sets are usually considered and analyzed. For example, most machine learning algorithms are applied and tested using the UCI Machine Learning repository. There is a current need for not i.i.d. data sets for distributed machine learning. Recall that i.i.d. random variables stand for independent and identically distributed (i.i.d.) random variables. An example of this need is federated learning. In federated learning, the typical scenario is to consider a set of agents each one with its own data set. Agents are typically heterogeneous and because of that, it is not appropriate to consider that the data of these agents follow the same distributions. In this paper we propose an approach to build non-identically distributed data sets from a single data set for machine learning classification, where we may suppose or not that all instances follow the same distribution. Each device will have only instances of a subset of the classes. The approach uses optimization to distribute the data set into a set of subsets, each one following a different distribution. Our goal is to define an approach for building subsets for training that is as systematic as the approaches used for cross-validation/k-fold validation.},
  archive      = {J_KIS},
  author       = {Torra, Vicenç},
  doi          = {10.1007/s10115-022-01785-3},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {991-1003},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A systematic construction of non-i.i.d. data sets from a single data set: Non-identically distributed data},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of continuous subgraph matching for dynamic graphs.
<em>KIS</em>, <em>65</em>(3), 945–989. (<a
href="https://doi.org/10.1007/s10115-022-01753-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of information technologies, multi-source heterogeneous data has become an open problem, and the data is usually modeled as graphs since the graph structure is able to encode complex relationships among entities. However, in practical applications, such as network security analysis and public opinion analysis over social networks, the structure and the content of graph data are constantly evolving. Therefore, the ability to continuously monitor and detect interesting patterns on massive and dynamic graphs in real-time is crucial for many applications. Recently, a large group of excellent research works has also emerged. Nevertheless, these studies focus on different updates of graphs and apply different subgraph matching algorithms; thus, it is desirable to review these works comprehensively and give a thorough overview. In this paper, we systematically investigate the existing continuous subgraph matching techniques from the aspects of key techniques, representative algorithms, and performance evaluation. Furthermore, the typical applications and challenges of continuous subgraph matching over dynamic graphs, as well as the future development trends, are summarized and prospected.},
  archive      = {J_KIS},
  author       = {Wang, Xi and Zhang, Qianzhen and Guo, Deke and Zhao, Xiang},
  doi          = {10.1007/s10115-022-01753-x},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {945-989},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A survey of continuous subgraph matching for dynamic graphs},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bold driver and static restart fused adaptive momentum for
visual question answering. <em>KIS</em>, <em>65</em>(2), 921–943. (<a
href="https://doi.org/10.1007/s10115-022-01775-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stacked attention networks (SANs) are one of the most classic models for visual question answering (VQA) and have effectively promoted the research progress of VQA. Existing literature utilized momentum to optimize SANs and obtained impressive results. However, error analysis shows that the fixed global learning rate in momentum makes it easy to fall into local optimal solution. Many Learning Rate Adaptation algorithms (LRA) (e.g., static restart, bold driver) are proposed to solve the issue by adjusting global learning rate. However, these algorithms still have many defects. For example, static restart has too high restart learning rate and the blindness of adaptive global learning rate; although bold driver can solve the blindness, it has the improper setting of adaptive parameters. To solve these issues, we fuse bold driver and static restart (BDSR) into momentum to devise our method called bold driver and static restart fused adaptive momentum (BDSRM). Then, we analyze its optimization process and time complexity and conduct quantitative experiments on VQAv1, Cifar-10 and similar models to verify that our BDSRM outperforms the state-of-the-art optimization algorithms on SANs. Afterward, we perform ablation experiments and visualization experiments to verify that our BDSR has preferable effectiveness.},
  archive      = {J_KIS},
  author       = {Li, Shengdong and Luo, Chuanwen and Zhu, Yuqing and Wu, Weili},
  doi          = {10.1007/s10115-022-01775-5},
  journal      = {Knowledge and Information Systems},
  month        = {2},
  number       = {2},
  pages        = {921-943},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Bold driver and static restart fused adaptive momentum for visual question answering},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Discovering disjoint object property pairs in knowledge
graphs using probabilistic soft logic. <em>KIS</em>, <em>65</em>(2),
899–919. (<a href="https://doi.org/10.1007/s10115-022-01773-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although Knowledge Graphs (KGs) have turned out to become a popular and powerful tool in the industry world, the major focus of most researchers has been only on adding more and more triples to the A-Boxes of the KGs. An often overlooked but important part of a KG is its T-Box. If the T-Box contains incorrect statements or if certain correct statements are absent in it, it can lead to inconsistent knowledge in the KG or to information loss respectively. In this paper, we propose a novel system, DOPLEX, based on Probabilistic Soft Logic (PSL) to detect disjointness between pairs of object properties present in the KG. Current approaches mainly rely on checking the absence of common triples and miss out on exploiting the semantics of property names. In the proposed system, in addition to checking common triples, PSL is used to determine if property names imply disjointness. We particularly focus on knowledge graphs that are auto-extracted from large text corpora. Our evaluation demonstrates that the proposed approach discovers disjoint property pairs with better precision when compared to the state-of-the-art system without compromising much on the number of disjoint pairs discovered. Towards the end of the paper, we discuss the disjointness of properties in the context of time and propose a new notion called temporal-non-disjointness and discuss its importance and characteristics. We also present an approach for the discovery of property pairs that are potentially temporally non-disjoint.},
  archive      = {J_KIS},
  author       = {Subhashree, S. and Kumar, P. Sreenivasa},
  doi          = {10.1007/s10115-022-01773-7},
  journal      = {Knowledge and Information Systems},
  month        = {2},
  number       = {2},
  pages        = {899-919},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Discovering disjoint object property pairs in knowledge graphs using probabilistic soft logic},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SVM-based subspace optimization domain transfer method for
unsupervised cross-domain time series classification. <em>KIS</em>,
<em>65</em>(2), 869–897. (<a
href="https://doi.org/10.1007/s10115-022-01784-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series classification on edge devices has received considerable attention in recent years, and it is often conducted on the assumption that the training and testing data are drawn from the same distribution. However, in practical IoT applications, this assumption does not hold due to variations in installation positions, precision error, and sampling frequency of edge devices. To tackle this problem, in this paper, we propose a new SVM-based domain transfer method called subspace optimization transfer support vector machine (SOTSVM) for cross-domain time series classification. SOTSVM aims to learn a domain-invariant SVM classifier by which (1) global projected distribution alignment jointly exploits the marginal distribution discrepancy, geometric structure, and distribution scatter to reduce the global distribution discrepancy between the source and target domains; (2) feature grouping is used to divide the features into highly transferable features (HTF) and lowly transferable features (LTF), where the importance of HTF is preserved and importance of LTF is suppressed in the domain-invariant classifier training; and (3) empirical risk minimization is constructed for improving the discrimination of the SOTSVM. In this paper, we formulate a minimization problem that integrates global projected distribution alignment, feature grouping and empirical risk minimization into the joint SVM framework, giving an effective optimization algorithm. Furthermore, we present the extension of multiple kernel SOTSVM. Experimental results on three sets of cross-domain time series datasets show that our method outperforms some state-of-the-art conventional transfer learning methods and no transfer learning methods.},
  archive      = {J_KIS},
  author       = {Ma, Fei and Wang, Chengliang and Zeng, Zhuo},
  doi          = {10.1007/s10115-022-01784-4},
  journal      = {Knowledge and Information Systems},
  month        = {2},
  number       = {2},
  pages        = {869-897},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {SVM-based subspace optimization domain transfer method for unsupervised cross-domain time series classification},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). New cosine similarity and distance measures for fermatean
fuzzy sets and TOPSIS approach. <em>KIS</em>, <em>65</em>(2), 855–868.
(<a href="https://doi.org/10.1007/s10115-022-01776-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The most straightforward approaches to checking the degrees of similarity and differentiation between two sets are to use distance and cosine similarity metrics. The cosine of the angle between two n-dimensional vectors in n-dimensional space is called cosine similarity. Even though the two sides are dissimilar in size, cosine similarity may readily find commonalities since it deals with the angle in between. Cosine similarity is widely used because it is simple, ideal for usage with sparse data, and deals with the angle between two vectors rather than their magnitude. The distance function is an elegant and canonical quantitative tool to measure the similarity or difference between two sets. This work presents new metrics of distance and cosine similarity amongst Fermatean fuzzy sets. Initially, the definitions of the new measures based on Fermatean fuzzy sets were presented, and their properties were explored. Considering that the cosine measure does not satisfy the axiom of similarity measure, then we propose a method to construct other similarity measures between Fermatean fuzzy sets based on the proposed cosine similarity and Euclidean distance measures and it satisfies the axiom of the similarity measure. Furthermore, we obtain a cosine distance measure between Fermatean fuzzy sets by using the relationship between the similarity and distance measures, then we extend the technique for order of preference by similarity to the ideal solution method to the proposed cosine distance measure, which can deal with the related decision-making problems not only from the point of view of geometry but also from the point of view of algebra. Finally, we give a practical example to illustrate the reasonableness and effectiveness of the proposed method, which is also compared with other existing methods.},
  archive      = {J_KIS},
  author       = {Kirişci, Murat},
  doi          = {10.1007/s10115-022-01776-4},
  journal      = {Knowledge and Information Systems},
  month        = {2},
  number       = {2},
  pages        = {855-868},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {New cosine similarity and distance measures for fermatean fuzzy sets and TOPSIS approach},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A storytree-based model for inter-document causal relation
extraction from news articles. <em>KIS</em>, <em>65</em>(2), 827–853.
(<a href="https://doi.org/10.1007/s10115-022-01781-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With more and more news articles appearing on the Internet, discovering causal relations between news articles is very important for people to understand the development of news. Extracting the causal relations between news articles is an inter-document relation extraction task. Existing works on relation extraction cannot solve it well because of the following two reasons: (1) most relation extraction models are intra-document models, which focus on relation extraction between entities. However, news articles are many times longer and more complex than entities, which makes the inter-document relation extraction task harder than intra-document. (2) Existing inter-document relation extraction models rely on similarity information between news articles, which could limit the performance of extraction methods. In this paper, we propose an inter-document model based on storytree information to extract causal relations between news articles. We adopt storytree information to integer linear programming (ILP) and design the storytree constraints for the ILP objective function. Experimental results show that all the constraints are effective and the proposed method outperforms widely used machine learning models and a state-of-the-art deep learning model, with F1 improved by more than 5% on three different datasets. Further analysis shows that five constraints in our model improve the results to varying degrees and the effects on the three datasets are different. The experiment about link features also suggests the positive influence of link information.},
  archive      = {J_KIS},
  author       = {Zhang, Chong and Lyu, Jiagao and Xu, Ke},
  doi          = {10.1007/s10115-022-01781-7},
  journal      = {Knowledge and Information Systems},
  month        = {2},
  number       = {2},
  pages        = {827-853},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A storytree-based model for inter-document causal relation extraction from news articles},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AdaCC: Cumulative cost-sensitive boosting for imbalanced
classification. <em>KIS</em>, <em>65</em>(2), 789–826. (<a
href="https://doi.org/10.1007/s10115-022-01780-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance poses a major challenge for machine learning as most supervised learning models might exhibit bias towards the majority class and under-perform in the minority class. Cost-sensitive learning tackles this problem by treating the classes differently, formulated typically via a user-defined fixed misclassification cost matrix provided as input to the learner. Such parameter tuning is a challenging task that requires domain knowledge and moreover, wrong adjustments might lead to overall predictive performance deterioration. In this work, we propose a novel cost-sensitive boosting approach for imbalanced data that dynamically adjusts the misclassification costs over the boosting rounds in response to model’s performance instead of using a fixed misclassification cost matrix. Our method, called AdaCC, is parameter-free as it relies on the cumulative behavior of the boosting model in order to adjust the misclassification costs for the next boosting round and comes with theoretical guarantees regarding the training error. Experiments on 27 real-world datasets from different domains with high class imbalance demonstrate the superiority of our method over 12 state-of-the-art cost-sensitive boosting approaches exhibiting consistent improvements in different measures, for instance, in the range of [0.3–28.56%] for AUC, [3.4–21.4%] for balanced accuracy, [4.8–45%] for gmean and [7.4–85.5%] for recall.},
  archive      = {J_KIS},
  author       = {Iosifidis, Vasileios and Papadopoulos, Symeon and Rosenhahn, Bodo and Ntoutsi, Eirini},
  doi          = {10.1007/s10115-022-01780-8},
  journal      = {Knowledge and Information Systems},
  month        = {2},
  number       = {2},
  pages        = {789-826},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {AdaCC: Cumulative cost-sensitive boosting for imbalanced classification},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Isolation kernel estimators. <em>KIS</em>, <em>65</em>(2),
759–787. (<a href="https://doi.org/10.1007/s10115-022-01765-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing adaptive kernel density estimators (KDEs) and kernel regressions (KRs) often employ a data-independent kernel, such as Gaussian kernel. They require an additional means to adapt the kernel bandwidth locally in a given dataset in order to produce better estimations. But this comes with high computational cost. In this paper, we show that adaptive KDEs and KRs can be directly derived from Isolation Kernel with constant-time complexity for each estimation. The resultant estimators called IKDE and IKR are the first KDE and KR that are fast and adaptive. We demonstrate both the superior efficiency and efficacy of IKDE and IKR in anomaly detection and regression tasks, respectively.},
  archive      = {J_KIS},
  author       = {Ting, Kai Ming and Washio, Takashi and Wells, Jonathan and Zhang, Hang and Zhu, Ye},
  doi          = {10.1007/s10115-022-01765-7},
  journal      = {Knowledge and Information Systems},
  month        = {2},
  number       = {2},
  pages        = {759-787},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Isolation kernel estimators},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A prediction model of student performance based on
self-attention mechanism. <em>KIS</em>, <em>65</em>(2), 733–758. (<a
href="https://doi.org/10.1007/s10115-022-01774-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Performance prediction is an important research facet of educational data mining. Most models extract student behavior features from campus card data for prediction. However, most of these methods have coarse time granularity, difficulty in extracting useful high-order behavior combination features, dependence on 6 historical achievements, etc. To solve these problems, this paper utilizes prediction of grade point average (GPA prediction) and whether a specific student has failing subjects (failing prediction) in a term as the goal of performance prediction and proposes a comprehensive performance prediction model of college students based on behavior features. First, a method for representing campus card data based on behavior flow is introduced to retain higher time accuracy. Second, a method for extracting student behavior features based on multi-head self-attention mechanism is proposed to automatically select more important high-order behavior combination features. Finally, a performance prediction model based on student behavior feature mode difference is proposed to improve the model’s prediction accuracy and increases the model’s robustness for students with significant changes in performance. The performance of the model is verified on actual data collected by the teaching monitoring big data platform of Xi’an Jiaotong University. The results show that the model’s prediction performance is better than the comparison algorithms on both the failing prediction and GPA prediction.},
  archive      = {J_KIS},
  author       = {Chen, Yan and Wei, Ganglin and Liu, Jiaxin and Chen, Yunwei and Zheng, Qinghua and Tian, Feng and Zhu, Haiping and Wang, Qianying and Wu, Yaqiang},
  doi          = {10.1007/s10115-022-01774-6},
  journal      = {Knowledge and Information Systems},
  month        = {2},
  number       = {2},
  pages        = {733-758},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A prediction model of student performance based on self-attention mechanism},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Query-adaptive training data recommendation for
cross-building predictive modeling. <em>KIS</em>, <em>65</em>(2),
707–732. (<a href="https://doi.org/10.1007/s10115-022-01771-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive modeling in buildings is a key task for the optimal management of building energy. Relevant building operational data are a prerequisite for such task, notably when deep learning is used. However, building operational data are not always available, such is the case in newly built, newly renovated, or even not yet built buildings. To address this problem, we propose a deep similarity learning approach to recommend relevant training data to a target building solely by using a minimal contextual description on it. Contextual descriptions are modeled as user queries. We further propose to ensemble most used machine learning algorithms in the context of predictive modeling. This contributes to the genericity of the proposed methodology. Experimental evaluations show that our methodology offers a generic methodology for cross-building predictive modeling and achieves good generalization performance.},
  archive      = {J_KIS},
  author       = {Labiadh, Mouna and Obrecht, Christian and Ferreira da Silva, Catarina and Ghodous, Parisa and Benabdeslem, Khalid},
  doi          = {10.1007/s10115-022-01771-9},
  journal      = {Knowledge and Information Systems},
  month        = {2},
  number       = {2},
  pages        = {707-732},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Query-adaptive training data recommendation for cross-building predictive modeling},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gated information bottleneck for generalization in
sequential environments. <em>KIS</em>, <em>65</em>(2), 683–705. (<a
href="https://doi.org/10.1007/s10115-022-01770-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks suffer from poor generalization to unseen environments when the underlying data distribution is different from that in the training set. By learning minimum sufficient representations from training data, the information bottleneck (IB) approach has demonstrated its effectiveness to improve generalization in different AI applications. In this work, we propose a new neural network-based IB approach, termed gated information bottleneck (GIB), that dynamically drops spurious correlations and progressively selects the most task-relevant features across different environments by a trainable soft mask (on raw features). Using the recently proposed matrix-based Rényi’s $$\alpha $$ -order mutual information estimator, GIB enjoys a simple and tractable objective, without any variational approximation or distributional assumption. We empirically demonstrate the superiority of GIB over other popular neural network-based IB approaches in adversarial robustness and out-of-distribution detection. Meanwhile, we also establish the connection between IB theory and invariant causal representation learning and observed that GIB demonstrates appealing performance when different environments arrive sequentially, a more practical scenario where invariant risk minimization fails.},
  archive      = {J_KIS},
  author       = {Alesiani, Francesco and Yu, Shujian and Yu, Xi},
  doi          = {10.1007/s10115-022-01770-w},
  journal      = {Knowledge and Information Systems},
  month        = {2},
  number       = {2},
  pages        = {683-705},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Gated information bottleneck for generalization in sequential environments},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). KRL_match: Knowledge graph objects matching for knowledge
representation learning. <em>KIS</em>, <em>65</em>(2), 641–681. (<a
href="https://doi.org/10.1007/s10115-022-01764-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The way of obtaining the embeddings of the knowledge graph objects through modeling with binary classification method from the level of triple structure is coarser in granularity for the existing knowledge representation learning models based on the probability, and the space-time efficiency of negative sampling is lower for the most of the knowledge representation learning models at present. To solve these problems, this paper proposes a knowledge representation learning model KRL_Match, which carries out the knowledge graph objects matching centered on a certain kind of knowledge graph objects (head entity, tail entity, relation), and executes multi-classification learning to determine the true matching and dynamic implicit negative sampling. Specifically, first, we make two classes of the knowledge graph objects of target and source in the same kind of knowledge graph objects matched mutually by their matrix multiplication operation in a knowledge graph batch sample space, which is constructed by random sampling from the universe set of the knowledge graph instance, and the knowledge graph objects matching sample spaces will be implicitly generated meanwhile; then, we measure the matching degree of each matching of the knowledge graph objects by softmax regression multi-classification method in each implicit sample space; finally, we fit the real probability with the matching degree by optimizing the cross-entropy loss based on the local closed world assumption. We conduct the knowledge graph objects matching for the knowledge representation learning inspired by the attention mechanism and firstly create the dynamic implicit negative sampling method in the knowledge representation learning. Experiments show that the KRL_Match model has achieved better performances compared with the baselines: Hits@10 (filter) has increased by 12.2% and 6.1% on benchmarks FB15K and FB15K237 respectively for the entity prediction task, and accuracy has increased by 12.6% on benchmark FB13 for the triple classification task. In addition, space-time efficiency test indicates that the negative sampling of KRL_Match is less 7395.59s and half in time and the storage space separately than TransE’s on benchmark FB15K (BS = 12000).},
  archive      = {J_KIS},
  author       = {Suo, Xinhua and Guo, Bing and Shen, Yan and Dai, Shengxin and Wang, Wei and Chen, Yaosen and Zhang, Zhen},
  doi          = {10.1007/s10115-022-01764-8},
  journal      = {Knowledge and Information Systems},
  month        = {2},
  number       = {2},
  pages        = {641-681},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {KRL_Match: Knowledge graph objects matching for knowledge representation learning},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Embedding text-rich graph neural networks with sequence and
topical semantic structures. <em>KIS</em>, <em>65</em>(2), 613–640. (<a
href="https://doi.org/10.1007/s10115-022-01768-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have demonstrated great power in tackling various analytical tasks on graph (i.e. network) data. However, graphs in the real world are usually text-rich, implying that valuable semantic structures need to be considered carefully. Existing GNNs for text-rich networks typically treat the text as attribute words alone, which inevitably leads to the loss of important semantic structures, limiting the representation capability of GNNs. To solve this limitation, we propose AS-GNN, an end-to-end adaptive GNN architecture via unified modelling of semantic structure and network propagation on text-rich networks. Specifically, we utilize semantic structure modelling part to capture both the local word-sequence and the global topic semantic structures from text. We then augment the original text-rich network into a tri-typed heterogeneous network (including document nodes, word nodes, and topic nodes) and accordingly design a semantic-aware propagation of information by introducing a discriminative convolutional mechanism. We further train these two parts together by leveraging distribution sharing and joint training strategies, so as to adaptively generate an appropriate network structure aiming at the learning objectives. In addition, we present a simplified semantic architecture S-GNN, which adopts the cascaded “Structure-GNN” pattern, to promote the efficiency of the model and be easily combined with existing GNNs. Extensive experiments on text-rich networks demonstrate the superiority of our new architectures over state of the arts. Meanwhile, such architectures can also be applied to e-commerce search scenes, and experiments on a real e-commerce problem from JD further illustrate the effectiveness of AS-GNN over the baselines.},
  archive      = {J_KIS},
  author       = {Yu, Zhizhi and Jin, Di and Liu, Ziyang and He, Dongxiao and Wang, Xiao and Tong, Hanghang and Han, Jiawei},
  doi          = {10.1007/s10115-022-01768-4},
  journal      = {Knowledge and Information Systems},
  month        = {2},
  number       = {2},
  pages        = {613-640},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Embedding text-rich graph neural networks with sequence and topical semantic structures},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploiting bilingual lexicons to improve multilingual
embedding-based document and sentence alignment for low-resource
languages. <em>KIS</em>, <em>65</em>(2), 571–612. (<a
href="https://doi.org/10.1007/s10115-022-01761-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural machine translation systems trained on low-resource languages produce sub-optimal results due to the scarcity of large parallel datasets. To alleviate this problem, parallel corpora can be mined from the web. Two key tasks in a parallel corpus mining pipeline are web document alignment and sentence alignment. Effective approaches for these tasks obtained vector representations of the documents (or sentences) belonging to the two languages and determine the alignment between the documents (or sentences) based on a semantic similarity scoring mechanism. Recently, document or sentence representations obtained from pre-trained multilingual language models (PMLMs) such as LASER, XLM-R and LaBSE have significantly improved the benchmark scores in diverse natural language processing tasks. In this study, we carry out an empirical analysis of the effectiveness of these PMLMs of the document and sentence alignment tasks in the context of the low-resource language pairs Sinhala–English, Tamil–English and Sinhala–Tamil. Further, we introduce a weighting mechanism based on small-scale bilingual lexicons to improve the semantic similarity measurement between sentences and documents. Our results show that both document and sentence alignment can be further improved using our weighting mechanism. We have also compiled a gold-standard evaluation benchmark dataset for document alignment and sentence alignment tasks for the considered language pairs. This dataset ( https://github.com/kdissa/comparable-corpus ) and the source code ( https://github.com/nlpcuom/parallel_corpus_mining ) are publicly released.},
  archive      = {J_KIS},
  author       = {Fernando, Aloka and Ranathunga, Surangika and Sachintha, Dilan and Piyarathna, Lakmali and Rajitha, Charith},
  doi          = {10.1007/s10115-022-01761-x},
  journal      = {Knowledge and Information Systems},
  month        = {2},
  number       = {2},
  pages        = {571-612},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Exploiting bilingual lexicons to improve multilingual embedding-based document and sentence alignment for low-resource languages},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fairness in graph-based semi-supervised learning.
<em>KIS</em>, <em>65</em>(2), 543–570. (<a
href="https://doi.org/10.1007/s10115-022-01738-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning is widely deployed in society, unleashing its power in a wide range of applications owing to the advent of big data. One emerging problem faced by machine learning is the discrimination from data, and such discrimination is reflected in the eventual decisions made by the algorithms. Recent study has proved that increasing the size of training (labeled) data will promote the fairness criteria with model performance being maintained. In this work, we aim to explore a more general case where quantities of unlabeled data are provided, indeed leading to a new form of learning paradigm, namely fair semi-supervised learning. Taking the popularity of graph-based approaches in semi-supervised learning, we study this problem both on conventional label propagation method and graph neural networks, where various fairness criteria can be flexibly integrated. Our developed algorithms are proved to be non-trivial extensions to the existing supervised models with fairness constraints. Extensive experiments on real-world datasets exhibit that our methods achieve a better trade-off between classification accuracy and fairness than the compared baselines.},
  archive      = {J_KIS},
  author       = {Zhang, Tao and Zhu, Tianqing and Han, Mengde and Chen, Fengwen and Li, Jing and Zhou, Wanlei and Yu, Philip S},
  doi          = {10.1007/s10115-022-01738-w},
  journal      = {Knowledge and Information Systems},
  month        = {2},
  number       = {2},
  pages        = {543-570},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Fairness in graph-based semi-supervised learning},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EDU-capsule: Aspect-based sentiment analysis at clause
level. <em>KIS</em>, <em>65</em>(2), 517–541. (<a
href="https://doi.org/10.1007/s10115-022-01797-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many studies on aspect-based sentiment analysis (ABSA) aim to directly predict aspects and polarities at sentence level. However, it is not rare that a long sentence expresses multiple aspects. In this paper, we propose to study ABSA at EDU-level. Elementary discourse unit (EDU) in rhetorical structure theory is an atomic semantic unit, similar to a clause in a sentence. Through manual annotation of 8,823 EDUs, obtained from the SemEval-2014 Task 4 Restaurant Review dataset, we show that more than 97% of EDUs express at most one aspect. Based on this observation, we propose an EDU-level Capsule network for ABSA. EDU-Capsule learns EDU representations within its sentential context for aspect detection and sentiment prediction. EDU-Capsule outperforms strong baselines in our experiments on two benchmark datasets. Both the EDU-level annotations and EDU-Capsule source code are released to support further studies in this area.},
  archive      = {J_KIS},
  author       = {Lin, Ting and Sun, Aixin and Wang, Yequan},
  doi          = {10.1007/s10115-022-01797-z},
  journal      = {Knowledge and Information Systems},
  month        = {2},
  number       = {2},
  pages        = {517-541},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {EDU-capsule: Aspect-based sentiment analysis at clause level},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Information extraction from electronic medical documents:
State of the art and future research directions. <em>KIS</em>,
<em>65</em>(2), 463–516. (<a
href="https://doi.org/10.1007/s10115-022-01779-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the medical field, a doctor must have a comprehensive knowledge by reading and writing narrative documents, and he is responsible for every decision he takes for patients. Unfortunately, it is very tiring to read all necessary information about drugs, diseases and patients due to the large amount of documents that are increasing every day. Consequently, so many medical errors can happen and even kill people. Likewise, there is such an important field that can handle this problem, which is the information extraction. There are several important tasks in this field to extract the important and desired information from unstructured text written in natural language. The main principal tasks are named entity recognition and relation extraction since they can structure the text by extracting the relevant information. However, in order to treat the narrative text we should use natural language processing techniques to extract useful information and features. In our paper, we introduce and discuss the several techniques and solutions used in these tasks. Furthermore, we outline the challenges in information extraction from medical documents. In our knowledge, this is the most comprehensive survey in the literature with an experimental analysis and a suggestion for some uncovered directions.},
  archive      = {J_KIS},
  author       = {Landolsi, Mohamed Yassine and Hlaoua, Lobna and Ben Romdhane, Lotfi},
  doi          = {10.1007/s10115-022-01779-1},
  journal      = {Knowledge and Information Systems},
  month        = {2},
  number       = {2},
  pages        = {463-516},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Information extraction from electronic medical documents: State of the art and future research directions},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual neighborhood thresholding patterns based on directional
sampling. <em>KIS</em>, <em>65</em>(1), 435–462. (<a
href="https://doi.org/10.1007/s10115-022-01720-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evaluation of face recognition algorithms relies on the diversity of the challenges simulated on the adopted benchmarks. The main face recognition challenges cover the illumination changes, inhomogeneous background, different facial expressions, pose variations, occlusion, aging and resolution. Many 2D databases that include one challenge or more have been proposed in the state of the art. These databases represent different amount of individuals and samples, and generally the number of persons does not exceed 100 classes. The reason behind this limitation relies on the resources and materials required to construct a database composed of thousands of images and hundreds of persons along with the mentioned face recognition basic challenges. As a solution, researchers proposed to build benchmarks based on collecting the web images of celebrities from search engines such as Google Images and Flicker. The well-known database of this kind is Labeled Faces in the Wild (LFW) as a public benchmark for face verification. This solution managed to constitute a dependent way to construct benchmarks, but it could not be applicable for face recognition since the collected images have a low resolution and the majority of the persons are represented over few samples (one or two in most cases), which made these databases extremely hard for handcrafted-based face recognition systems. In this paper, we propose to construct a challenging database referred to as mixed face recognition database (MFRD) based on gathering the images of eight well-known benchmarks of the literature (FERET, Extended Yale B, ORL, AR, FEI, KDEF, IMM and JAFFE). The constructed database is expected to be more complex in terms of the amount of classes/images and the diversity of challenges. We expect then that the recognition performance on this database will drop compared to the one recorded on each considered benchmark individually. This paper presents also a new LBP variant, namely dual neighborhood thresholding patterns based on directional sampling (DNTPDS) as a robust and computationally efficient handcrafted descriptor for face recognition. The concept behind this new descriptor is based on defining a $$5\times 5$$ neighborhood topology, that relies on a directional sampling to select the only 16 prominent neighbors instead of 25. The proposed DNTPDS operator demonstrates a superior performance and outperforms 18 state-of-the-art LBP variants that is proved through a set of comprehensive experiments.},
  archive      = {J_KIS},
  author       = {Kas, M. and El-merabet, Y. and Ruichek, Y. and Messoussi, R.},
  doi          = {10.1007/s10115-022-01720-6},
  journal      = {Knowledge and Information Systems},
  month        = {1},
  number       = {1},
  pages        = {435-462},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Dual neighborhood thresholding patterns based on directional sampling},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient computational offloading framework using HAA
optimization-based deep reinforcement learning in edge-based cloud
computing architecture. <em>KIS</em>, <em>65</em>(1), 409–433. (<a
href="https://doi.org/10.1007/s10115-022-01746-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Cloud Computing (MCC) has emerged as a popular model for bringing the benefits of cloud computing to the proximity of mobile devices. MCC&#39;s preliminary goal is to improve service availability as well as performance and mobility features. Edge computing, a novel paradigm, provides rich computing capabilities at the edge of pervasive radio access networks close to users. Designing an efficient offloading technique for edge computing is a major research challenge given the constrained resources. Offloading speeds up processing, which has an impact on service quality in heterogeneous devices. Due to the difficulties of the network states&#39; distribution environment, allocating computing resources is a difficult process. In this study, inputs from various sorts of devices such as cars, mobile phones, and heterogeneous building sources are considered. When an accurate energy estimation model is established to compute the energy consumption of the tasks during offloading, an effective task offloading technique can be derived. The model should select whether or not to conduct offloading based on the computed energy cost. This study proposed a Hybrid Arithmetic Archimedes Optimization algorithm-based Deep Reinforcement Learning model for computation offloading in heterogeneous devices. The effectiveness of the proposed method is evaluated using different state-of-art methods such as First Upload Round and Second Upload Round (FUR-SUR), Efficient Dynamic-Decision Based Task Scheduler, Context‐aware computation offloading and Price-based distributed offloading. The proposed method offers superior results to other existing methods. The user’s average utility of the proposed method increases by 410% contrasted to FUR-SUR.},
  archive      = {J_KIS},
  author       = {Saranya, G. and Sasikala, E.},
  doi          = {10.1007/s10115-022-01746-w},
  journal      = {Knowledge and Information Systems},
  month        = {1},
  number       = {1},
  pages        = {409-433},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {An efficient computational offloading framework using HAA optimization-based deep reinforcement learning in edge-based cloud computing architecture},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Manifold clustering optimized by adaptive aggregation
strategy. <em>KIS</em>, <em>65</em>(1), 379–408. (<a
href="https://doi.org/10.1007/s10115-022-01769-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different from general spherical datasets, manifold datasets have a more complex spatial manifold structure, which makes it difficult to distinguish sample points on different manifold structures by Euclidean distance. Although the density peak clustering (DPC, two parameters: the cut-off ratio $$\mathrm{dc}$$ and the number of class centers $$C$$ ) algorithm can search for density peaks quickly and assign sample points, it cannot identify clusters effectively with complex manifold structures due to the sample similarity measurement only based on Euclidean distance. To solve these problems, this paper proposes a Manifold Clustering optimized by Adaptive Aggregation Strategy (MC-AAS, two parameters: the number of nearest neighbors $$k$$ and the threshold ratio of core points $$p$$ ). Firstly, it introduces a novel manifold similarity measurement based on the shared nearest neighbors and redefines the local density of sample points by summing the manifold similarity. Secondly, the core points are determined by the statistical characteristics of local density, and the local sub-clusters of manifold structural datasets are obtained by means of the nearest neighbor connection of the core points. And then, the initial clusters are merged on the basis of the statistical test of boundary density and the silhouette coefficient of adjacent subclass to realize the identification of manifold structural datasets. Finally, based on three evaluation metrics: Adjusted Mutual Information, Adjusted Rand Index and Fowlkes-Mallows Index, we conduct extensive experiments on synthetic datasets and real-world datasets. The experimental results indicate that, compared with current methods, the MC-AAS algorithm achieves a better clustering effect in identifying complex manifold datasets and has better robustness.},
  archive      = {J_KIS},
  author       = {Zhang, Yunong and Wei, Xiao and Li, Chunzhong},
  doi          = {10.1007/s10115-022-01769-3},
  journal      = {Knowledge and Information Systems},
  month        = {1},
  number       = {1},
  pages        = {379-408},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Manifold clustering optimized by adaptive aggregation strategy},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An EEG-based subject-independent emotion recognition model
using a differential-evolution-based feature selection algorithm.
<em>KIS</em>, <em>65</em>(1), 341–377. (<a
href="https://doi.org/10.1007/s10115-022-01762-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalogram (EEG)-based emotion recognition models are gaining interest as they show the intrinsic state of human. A wide range of features are extracted from the scalp EEG recorded using a different set of electrodes across the brain regions. However, there are no standard set of features accepted amongst researchers for emotion recognition. As a result, new researchers in the field use all features reported in the literature which leads to the curse of dimensionality problem and performance degradation due to high correlation within the feature set. Thus, the primary objective of this work is to improve the performance of the emotion recognition model by using an optimal feature set. This research article proposes differential-evolution-based feature selection (DEFS) algorithm to obtain an optimal feature set for effective subject-independent emotion recognition. The optimal feature set obtained from the DEFS algorithm is used to train the SVM classifier. A wide range of experiments are conducted to analyze the performance of our proposed model using a publicly available EEG-based emotion recognition dataset. The proposed model has been compared with several state-of-the-art feature selection and optimization algorithms. The results are analyzed in the aspects of classification performance, fitness value optimization and computational time. In addition, to assure the subject-independent behavior of the proposed model, subject-wise performance has been analyzed. The proposed DEFS-SVM emotion recognition model has got the classification accuracies of 73.60, 74.23, 71.88 and 71.80% to detect valence arousal, valence, dominance, and liking emotional states, respectively. The experimental results assured that our proposed model outperforms all other algorithms in all aspects. Also, the proposed feature selection algorithm is suitable for any EEG-based emotion recognition model to optimize the feature set.},
  archive      = {J_KIS},
  author       = {Kannadasan, K. and Veerasingam, Sridevi and Shameedha Begum, B. and Ramasubramanian, N.},
  doi          = {10.1007/s10115-022-01762-w},
  journal      = {Knowledge and Information Systems},
  month        = {1},
  number       = {1},
  pages        = {341-377},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {An EEG-based subject-independent emotion recognition model using a differential-evolution-based feature selection algorithm},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-objective covering salesman problem: A decomposition
approach using grey wolf optimization. <em>KIS</em>, <em>65</em>(1),
281–339. (<a href="https://doi.org/10.1007/s10115-022-01752-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, the basic grey wolf optimization (GWO) algorithm is modified along with K-bit exchange, K-opt operation, and integrated with the structure of multi-objective evolutionary algorithm with decomposition approach (MOEA/D) to solve multi-objective covering salesman problem(MOCSP). The algorithm is named a “multi-objective evolutionary algorithm with decomposition using Grey Wolf optimization (MOEA/D-GWO).” The K-opt operation with $$K=3$$ and $$K=4$$ is used to generate the initial solution set. The GWO algorithm is modified with a set of newly introduced perturbation rules. A two-stage updating mechanism has been introduced to improve the quality of a potential solution. The first sage of the process is done by the modified GWO algorithm, and in the second stage, a perturbation technique using K-bits exchange operation is applied. The MOEA/D-GWO algorithm is a two-phase algorithm where in the first phase, the clustering/grouping of cities is done, and in the next phase one city from each cluster/group is selected to search pareto-optimal Hamiltonian cycles in such a way that each cycle maintains the pre-define covering distance. Here, for the first time a heuristic approach is proposed for MOCSP. Different sizes of standard benchmark MOCSP test instances are used to test the performance of the MOEA/D-GWO algorithm. The instances are generated from TSPLIB. Different traditional multi-objective optimization algorithms, like NSGA-II, SPEA2, MOEA/D, MR-ABCWCD, SMPSO, SR4-MOEA/D for MOOP, have been modified according to MOCSP and implemented to compare the efficiency of the proposed approach. Nine standard well-known performance metrics/indicators have been used to analyse the performance of the MOEA/D-GWO algorithm for MOCSP. Different sizes bi-objective instances are generated from TSPLIB, for the illustration and testing the performance of the algorithm. Detailed problem generation approach is also discussed. From all the numerical studies, it is concluded that the proposed algorithm is efficient enough to deal with the MOCSPs.},
  archive      = {J_KIS},
  author       = {Khan, Indadul and Basuli, Krishnendu and Maiti, Manas Kumar},
  doi          = {10.1007/s10115-022-01752-y},
  journal      = {Knowledge and Information Systems},
  month        = {1},
  number       = {1},
  pages        = {281-339},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Multi-objective covering salesman problem: A decomposition approach using grey wolf optimization},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Conversation and recommendation: Knowledge-enhanced
personalized dialog system. <em>KIS</em>, <em>65</em>(1), 261–279. (<a
href="https://doi.org/10.1007/s10115-022-01766-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional recommender systems are usually single-shot systems, lacking real-time dialog with customers. Using dialog as an interactive method can help capture user preferences more accurately and enhance system transparency. However, developing such a goal-oriented dialog system has suffered many challenges as the system must collaborate with other subtasks, such as collecting user demands through interaction and recommending appropriate products to users. Additionally, most previous studies on dialog systems do not consider this situation and its challenges. This paper proposes a novel memory network framework for conversational recommendation, which harnesses dialog historical information to endow our model with adaptability in various dialog scenarios. Additionally, it leverages the knowledge base and user profiles to reweight candidates, reducing the ambiguity during interactions and improving the quality of conversational recommender systems. We demonstrate that the proposed method can achieve state-of-the-art performance in a few traditional tasks, such as options display and information provision, through experiments on the personalized bAbI dialog dataset and restaurant recommendation application.},
  archive      = {J_KIS},
  author       = {He, Ming and Wang, Jiwen and Ding, Tianyu and Shen, Tong},
  doi          = {10.1007/s10115-022-01766-6},
  journal      = {Knowledge and Information Systems},
  month        = {1},
  number       = {1},
  pages        = {261-279},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Conversation and recommendation: Knowledge-enhanced personalized dialog system},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the use of the descriptive variable for enhancing the
aggregation of crowdsourced labels. <em>KIS</em>, <em>65</em>(1),
241–260. (<a href="https://doi.org/10.1007/s10115-022-01743-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of crowdsourcing for annotating data has become a popular and cheap alternative to expert labelling. As a consequence, an aggregation task is required to combine the different labels provided and agree on a single one per example. Most aggregation techniques, including the simple and robust majority voting—to select the label with the largest number of votes—disregard the descriptive information provided by the explanatory variable. In this paper, we propose domain-aware voting, an extension of majority voting which incorporates the descriptive variable and the rest of the instances of the dataset for aggregating the label of every instance. The experimental results with simulated and real-world crowdsourced data suggest that domain-aware voting is a competitive alternative to majority voting, especially when a part of the dataset is unlabelled. We elaborate on practical criteria for the use of domain-aware voting.},
  archive      = {J_KIS},
  author       = {Beñaran-Muñoz, Iker and Hernández-González, Jerónimo and Pérez, Aritz},
  doi          = {10.1007/s10115-022-01743-z},
  journal      = {Knowledge and Information Systems},
  month        = {1},
  number       = {1},
  pages        = {241-260},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {On the use of the descriptive variable for enhancing the aggregation of crowdsourced labels},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient algorithm for mining closed high utility
itemsets over data streams with one dataset scan. <em>KIS</em>,
<em>65</em>(1), 207–240. (<a
href="https://doi.org/10.1007/s10115-022-01763-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The high utility itemsets mining over data streams will produce many redundant itemsets. To remove redundant itemsets, the researchers proposed to mine the closed high utility itemsets, the number of which is much smaller than that of the complete high utility itemsets and the result is lossless. However, the existing closed high utility itemsets mining algorithm over data streams needs to scan the dataset twice, and this algorithm that requires multiple scans cannot meet the real-time processing requirements of the streaming environment. To solve the above problem, this paper proposed a new algorithm CHUIDS_OSc that only needs to scan the original dataset once to achieve mining closed high utility itemsets over data streams. A new utility-list structure is designed in CHUIDS_OSc, and this structure can quickly complete the construction and update of batch information without rescanning the original dataset. In addition, effective pruning strategies are applied to improve the closed itemsets mining process and eliminate potential low utility candidates. Experimental evaluations show the efficiency and feasibility of the algorithm for scanning and processing datasets. As far as the running time is concerned, it is better than the previously proposed closed high utility itemsets mining algorithms that require multiple scans over data streams.},
  archive      = {J_KIS},
  author       = {Han, Meng and Cheng, Haodong and Zhang, Ni and Li, Xiaojuan and Wang, Le},
  doi          = {10.1007/s10115-022-01763-9},
  journal      = {Knowledge and Information Systems},
  month        = {1},
  number       = {1},
  pages        = {207-240},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {An efficient algorithm for mining closed high utility itemsets over data streams with one dataset scan},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mining dynamic preferences from geographical and interactive
correlations for next POI recommendation. <em>KIS</em>, <em>65</em>(1),
183–206. (<a href="https://doi.org/10.1007/s10115-022-01749-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next point-of-interest recommendation has become an increasingly significant requirement in location-based social networks. Recently, RNN-based methods have shown promising advantages in next POI recommendation due to their superior abilities in modeling sequential transitions of user behaviors. Despite their success, however, exploring complex correlations between POIs and capturing user dynamic preferences are still challenging issues. To overcome the limitations, we propose a novel framework named MPGI (Mining Preferences from Geographical and Interactive Correlations) for next POI recommendation. Specifically, we first design a POI correlation modeling layer to capture geographical distances and interactive correlations between all of POI pairs. Then, we fuse relevant signals from highly correlated POIs into target POI for high-quality POI representations. Furthermore, for user long- and short-term preferences modeling, we propose position-aware attention unites and attention network to dynamically select the most valuable information in check-in trajectories. Experimental results on two real-world datasets demonstrate that MPGI consistently outperforms the state-of-the-art methods.},
  archive      = {J_KIS},
  author       = {Ren, Jieyu and Gan, Mingxin},
  doi          = {10.1007/s10115-022-01749-7},
  journal      = {Knowledge and Information Systems},
  month        = {1},
  number       = {1},
  pages        = {183-206},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Mining dynamic preferences from geographical and interactive correlations for next POI recommendation},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AKUPP: Attention-enhanced joint propagation of knowledge and
user preference for recommendation systems. <em>KIS</em>,
<em>65</em>(1), 163–182. (<a
href="https://doi.org/10.1007/s10115-022-01693-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As knowledge graphs have attracted enormous attention from researchers, much effort has been invested in recommendation systems to mine user preferences effectively. In particular, knowledge graphs, which convey useful side information about users and items, can provide more accurate and explainable recommendations. When it comes to interactions between entities, however, the majority of existing work fails to incorporate high-order relations that ensure recommendation accuracy. This paper proposes attention-enhanced joint knowledge and user preference propagation (AKUPP), which integrates two types of knowledge propagation. The first is propagating user preferences based on the users&#39; history of interacting items through ripple sets. The second propagation employs an attention mechanism to emphasize the important semantics of relations, and with multiple layers, high-order relations are explored. Therefore, we successfully incorporate both side information and high-order relations in the knowledge graph. We show, via extensive experimentation on real-world datasets, that our approach outperforms numerous state-of-the-art baselines in terms of performance and accuracy.},
  archive      = {J_KIS},
  author       = {Ma, Xintao and Dong, Liyan and Wang, Yuequn and Li, Yongli and Zhang, Hao},
  doi          = {10.1007/s10115-022-01693-6},
  journal      = {Knowledge and Information Systems},
  month        = {1},
  number       = {1},
  pages        = {163-182},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {AKUPP: Attention-enhanced joint propagation of knowledge and user preference for recommendation systems},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Isomorphic encryption and coupled ANN with mealy machine: A
cutting edge data security model for cloud computing environment.
<em>KIS</em>, <em>65</em>(1), 133–162. (<a
href="https://doi.org/10.1007/s10115-022-01760-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing is defined as the distribution of computing including hardware and software to the consumer through the Internet. In the era of ICT, cloud computing has been influenced by many industries including technology, business, management, logistics and numerous other industry. But some new kinds of risks and vulnerabilities exist in cloud environment. Users of cloud services are under constant threat. Hence, security-related risks are the main disadvantage of cloud computing. The aim of this paper is to enhance the cloud security by designing a secure cryptosystem based on AI. We have emphasized on secure key generation algorithm based on coupled artificial neural network with Mealy machine, genetic algorithm and weight vector-based authentication mechanism. We have used coupled multilayer feedforward neural network, Mealy machine and genetic algorithm for key generation. Machine learning is done ‘n’ times between two ANNs, and after several steps, we have generated a secret key for encryption. A novel key wrapping protocol has also been introduced using one-way function. For encryption and decryption, we have used the concept of isomorphism in vector space and XOR operation with double encryption key. Thus, our paper is equipped with different types of new concepts. Varieties of experimental results and analysis prove the efficiency and robustness of our technique in the field of cryptography.},
  archive      = {J_KIS},
  author       = {Bhowmik, Anirban and Karforma, Sunil},
  doi          = {10.1007/s10115-022-01760-y},
  journal      = {Knowledge and Information Systems},
  month        = {1},
  number       = {1},
  pages        = {133-162},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Isomorphic encryption and coupled ANN with mealy machine: A cutting edge data security model for cloud computing environment},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MG2Vec+: A multi-headed graph attention network for
multigraph embedding. <em>KIS</em>, <em>65</em>(1), 111–132. (<a
href="https://doi.org/10.1007/s10115-022-01706-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation learning of graphs in the form of graph embeddings is an extensively studies area, especially for simple networks, to help with different downstream applications such as node clustering, link prediction, and node classification. In this paper, we propose MG2Vec+, a method that generates node embeddings for a multigraph, a network structure comprising multiple types of edges between pairs of nodes. MG2Vec+ uses multi-headed attention layers to aggregate multiple types of edge-relations that can exist among nodes. The parameters are learned using a graph likelihood loss function which ensures that the sum of attention scores for high-priority nodes is larger as compared to low-priority nodes. We compare MG2Vec+ with nine existing baseline methods after modifying them to our setting on four real-world datasets. MG2Vec+ outperforms the competing methods when evaluated on two downstream tasks: (1) link prediction, and (2) multi-class node classification. It is able to achieve a 5.88% higher AUC-ROC score than the best baseline for link prediction and 9.52% higher classification accuracy than the best baseline for the multi-class node classification task. The superiority of MG2Vec+ can be explained by its principled way of capturing multi-relational contexts and learning them in an unsupervised manner with the same set of parameters using graph likelihood loss.},
  archive      = {J_KIS},
  author       = {Roy, Aman and Mittal, Shravika and Chakraborty, Tanmoy},
  doi          = {10.1007/s10115-022-01706-4},
  journal      = {Knowledge and Information Systems},
  month        = {1},
  number       = {1},
  pages        = {111-132},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {MG2Vec+: A multi-headed graph attention network for multigraph embedding},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Asymmetric kernel-based robust classification by ADMM.
<em>KIS</em>, <em>65</em>(1), 89–110. (<a
href="https://doi.org/10.1007/s10115-022-01758-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Correntropy is a locally second-order statistical measure in kernel space. The different kernel functions induce different correntropy with different properties. In this work, we propose an asymmetric mixture kernel and the corresponding correntropy. Then, we propose a new loss function (called RCH-loss) that is induced by the correntropy with the reproducing asymmetric kernel. Some important properties of the proposed kernel and RCH-loss are demonstrated such as non-convexity, boundedness, asymmetry and asymptotic approximation. Moreover, the proposed RCH-loss satisfies Bayes optimal decision rule. With the RCH-loss function, a new robust classification framework is built to handle robust classification. Theoretically, we prove the generalization bound of the proposed model based on the Rademacher complexity. Following that, DC (difference of convex functions) programming algorithm (DCA) is developed to solve the problem iteratively, where ADMM (alternating direction method of multipliers) is used to solve the subproblem at each iteration. Moreover, we analyze the computation complexity of the algorithm and the sensitivity of parameters. Numerical experimentations are carried out on various datasets including benchmark data sets and artificial data sets with different noise levels. The experimental results display the feasibility and effectiveness of the proposed methods.},
  archive      = {J_KIS},
  author       = {Ding, Guangsheng and Yang, Liming},
  doi          = {10.1007/s10115-022-01758-6},
  journal      = {Knowledge and Information Systems},
  month        = {1},
  number       = {1},
  pages        = {89-110},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Asymmetric kernel-based robust classification by ADMM},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An effective cost-sensitive sparse online learning framework
for imbalanced streaming data classification and its application to
online anomaly detection. <em>KIS</em>, <em>65</em>(1), 59–87. (<a
href="https://doi.org/10.1007/s10115-022-01745-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance is one of the most challenging problems in streaming data mining due to its adverse impact on predictive capability of online models. Most of the existing approaches for online learning lack an effective mechanism to handle high-dimensional streaming data with skewed class distributions, resulting in deteriorated model performance and limited interpretability. In this paper, we develop a cost-sensitive regularized dual averaging (CSRDA) method to tackle this problem. Our proposed method substantially extends the influential regularized dual averaging method by formulating a new convex optimization function, in which four $$\ell _1$$ -norm regularized cost-sensitive objective functions are directly optimized, respectively. We then theoretically analyze CSRDA’s regret bounds and the bounds of primal variables, demonstrating that CSRDA and its variants can achieve a theoretical convergence in terms of the balanced cost and sparsity when handling severe imbalanced and high-dimensional streaming data. To validate the proposed methods, we conduct extensive experiments on six benchmark streaming datasets with varied imbalance ratios and three online anomaly detection tasks. The experimental results demonstrate that, compared to other baseline methods, CSRDA and its variants not only improve classification performance, but also successfully capture sparse features more effectively and hence potentially have a better model interpretability.},
  archive      = {J_KIS},
  author       = {Chen, Zhong and Sheng, Victor and Edwards, Andrea and Zhang, Kun},
  doi          = {10.1007/s10115-022-01745-x},
  journal      = {Knowledge and Information Systems},
  month        = {1},
  number       = {1},
  pages        = {59-87},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {An effective cost-sensitive sparse online learning framework for imbalanced streaming data classification and its application to online anomaly detection},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Imbalanced data preprocessing techniques for machine
learning: A systematic mapping study. <em>KIS</em>, <em>65</em>(1),
31–57. (<a href="https://doi.org/10.1007/s10115-022-01772-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Learning (ML) algorithms have been increasingly replacing people in several application domains—in which the majority suffer from data imbalance. In order to solve this problem, published studies implement data preprocessing techniques, cost-sensitive and ensemble learning. These solutions reduce the naturally occurring bias towards the majority sample through ML. This study uses a systematic mapping methodology to assess 9927 papers related to sampling techniques for ML in imbalanced data applications from 7 digital libraries. A filtering process selected 35 representative papers from various domains, such as health, finance, and engineering. As a result of a thorough quantitative analysis of these papers, this study proposes two taxonomies—illustrating sampling techniques and ML models. The results indicate that oversampling and classical ML are the most common preprocessing techniques and models, respectively. However, solutions with neural networks and ensemble ML models have the best performance—with potentially better results through hybrid sampling techniques. Finally, none of the 35 works apply simulation-based synthetic oversampling, indicating a path for future preprocessing solutions.},
  archive      = {J_KIS},
  author       = {Werner de Vargas, Vitor and Schneider Aranda, Jorge Arthur and dos Santos Costa, Ricardo and da Silva Pereira, Paulo Ricardo and Victória Barbosa, Jorge Luis},
  doi          = {10.1007/s10115-022-01772-8},
  journal      = {Knowledge and Information Systems},
  month        = {1},
  number       = {1},
  pages        = {31-57},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Imbalanced data preprocessing techniques for machine learning: A systematic mapping study},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Partial-order-based process mining: A survey and outlook.
<em>KIS</em>, <em>65</em>(1), 1–29. (<a
href="https://doi.org/10.1007/s10115-022-01777-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of process mining focuses on distilling knowledge of the (historical) execution of a process based on the operational event data generated and stored during its execution. Most existing process mining techniques assume that the event data describe activity executions as degenerate time intervals, i.e., intervals of the form [t, t], yielding a strict total order on the observed activity instances. However, for various practical use cases, e.g., the logging of activity executions with a nonzero duration and uncertainty on the correctness of the recorded timestamps of the activity executions, assuming a partial order on the observed activity instances is more appropriate. Using partial orders to represent process executions, i.e., based on recorded event data, allows for new classes of process mining algorithms, i.e., aware of parallelism and robust to uncertainty. Yet, interestingly, only a limited number of studies consider using intermediate data abstractions that explicitly assume a partial order over a collection of observed activity instances. Considering recent developments in process mining, e.g., the prevalence of high-quality event data and techniques for event data abstraction, the need for algorithms designed to handle partially ordered event data is expected to grow in the upcoming years. Therefore, this paper presents a survey of process mining techniques that explicitly use partial orders to represent recorded process behavior. We performed a keyword search, followed by a snowball sampling strategy, yielding 68 relevant articles in the field. We observe a recent uptake in works covering partial-order-based process mining, e.g., due to the current trend of process mining based on uncertain event data. Furthermore, we outline promising novel research directions for the use of partial orders in the context of process mining algorithms.},
  archive      = {J_KIS},
  author       = {Leemans, Sander J. J. and van Zelst, Sebastiaan J. and Lu, Xixi},
  doi          = {10.1007/s10115-022-01777-3},
  journal      = {Knowledge and Information Systems},
  month        = {1},
  number       = {1},
  pages        = {1-29},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Partial-order-based process mining: A survey and outlook},
  volume       = {65},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
