<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JGO_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jgo---121">JGO - 121</h2>
<ul>
<li><details>
<summary>
(2023). IPRQP: A primal-dual interior-point relaxation algorithm for
convex quadratic programming. <em>JGO</em>, <em>87</em>(2), 1027–1053.
(<a href="https://doi.org/10.1007/s10898-023-01314-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose IPRQP, an enhanced primal-dual interior-point relaxation method (IPRM), for solving convex quadratic programming. This method is based on a smoothing barrier augmented Lagrangian function for convex quadratic programming. IPRQP inherits the advantages of IPRM, including not requiring iterative points to be interior points, which makes IPRQP suitable for the warm-starting of combinatorial optimization problems. Compared to IPRM, the customized starting points allow the line search of IPRQP to contain only vector operations. In addition, IPRQP improves the updating scheme of the barrier parameter and provides a certificate of infeasibility. Some results on global convergence are presented. We implement the algorithm on convex quadratic programming problems from Maros-Mészaros and the benchmark problem sets NETLIB and Kennington, which contain feasible and infeasible linear programming problems. The numerical results show that our algorithm is reliable for feasible problems and efficient for detecting the infeasibility of infeasible problems.},
  archive      = {J_JGO},
  author       = {Zhang, Rui-Jin and Liu, Xin-Wei and Dai, Yu-Hong},
  doi          = {10.1007/s10898-023-01314-8},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {1027-1053},
  shortjournal = {J. Glob. Optim.},
  title        = {IPRQP: A primal-dual interior-point relaxation algorithm for convex quadratic programming},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A mini-batch stochastic conjugate gradient algorithm with
variance reduction. <em>JGO</em>, <em>87</em>(2), 1009–1025. (<a
href="https://doi.org/10.1007/s10898-022-01205-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic gradient descent method is popular for large scale optimization but has slow convergence asymptotically due to the inherent variance. To remedy this problem, there have been many explicit variance reduction methods for stochastic descent, such as SVRG Johnson and Zhang [Advances in neural information processing systems, (2013), pp. 315–323], SAG Roux et al. [Advances in neural information processing systems, (2012), pp. 2663–2671], SAGA Defazio et al. [Advances in neural information processing systems, (2014), pp. 1646–1654] and so on. Conjugate gradient method, which has the same computation cost with gradient descent method, is considered. In this paper, in the spirit of SAGA, we propose a stochastic conjugate gradient algorithm which we call SCGA. With the Fletcher and Reeves type choices, we prove a linear convergence rate for smooth and strongly convex functions. We experimentally demonstrate that SCGA converges faster than the popular SGD type algorithms for four machine learning models, which may be convex, nonconvex or nonsmooth. Solving regression problems, SCGA is competitive with CGVR, which is the only one stochastic conjugate gradient algorithm with variance reduction so far, as we know.},
  archive      = {J_JGO},
  author       = {Kou, Caixia and Yang, Han},
  doi          = {10.1007/s10898-022-01205-4},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {1009-1025},
  shortjournal = {J. Glob. Optim.},
  title        = {A mini-batch stochastic conjugate gradient algorithm with variance reduction},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning-augmented algorithms for online subset sum.
<em>JGO</em>, <em>87</em>(2), 989–1008. (<a
href="https://doi.org/10.1007/s10898-022-01156-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of Karp’s 21 NP-complete problems, the subset sum problem, as well as its generalization, has been well studied. Among the rich literature, there is little work on the online version, where items arrive over list and irrevocable decisions on packing them or not must be made immediately. Under the online setting, no deterministic algorithms are competitive, while for randomized algorithms the best competitive ratio is 1/2. It is thus of great interest to improve the performance bounds for both deterministic and randomized algorithms, assuming predicted information is available in the learning-augmented model. Along this line, we revisit online subset sum by showing that, with learnable predictions, there exist learning-augmented algorithms to break through the worst-case bounds on competitive ratio. The theoretical results are also experimentally verified, where we come up with a new idea in designing experiments. Namely, we design neural networks to serve as adversaries, verifying the robustness of online algorithms. Under this framework, several networks are trained to select adversarial instances and the results show that our algorithms are competitive and robust.},
  archive      = {J_JGO},
  author       = {Xu, Chenyang and Zhang, Guochuan},
  doi          = {10.1007/s10898-022-01156-w},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {989-1008},
  shortjournal = {J. Glob. Optim.},
  title        = {Learning-augmented algorithms for online subset sum},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An inexact primal–dual method with correction step for a
saddle point problem in image debluring. <em>JGO</em>, <em>87</em>(2),
965–988. (<a href="https://doi.org/10.1007/s10898-022-01211-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an inexact primal–dual method with correction step for a saddle point problem by introducing the notations of inexact extended proximal operators with symmetric positive definite matrix D. Relaxing requirement on primal–dual step sizes, we prove the convergence of the proposed method. We also establish the O(1/N) convergence rate of our method in the ergodic sense. Moreover, we apply our method to solve TV- $$\hbox {L}_1$$ image deblurring problems. Numerical simulation results illustrate the efficiency of our method.},
  archive      = {J_JGO},
  author       = {Fang, Changjie and Hu, Liliang and Chen, Shenglan},
  doi          = {10.1007/s10898-022-01211-6},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {965-988},
  shortjournal = {J. Glob. Optim.},
  title        = {An inexact primal–dual method with correction step for a saddle point problem in image debluring},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Some accelerated alternating proximal gradient algorithms
for a class of nonconvex nonsmooth problems. <em>JGO</em>,
<em>87</em>(2), 939–964. (<a
href="https://doi.org/10.1007/s10898-022-01214-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study a class of nonconvex and nonsmooth optimization problems, whose objective function can be split into two separable terms and one coupling term. Alternating proximal gradient methods combining with extrapolation are proposed to solve such problems. Under some assumptions, we prove that every cluster point of the sequence generated by our algorithms is a critical point. Furthermore, if the objective function satisfies Kurdyka–Łojasiewicz property, the generated sequence is globally convergent to a critical point. In order to make the algorithm more effective and flexible, we also use some strategies to update the extrapolation parameter and solve the problems with unknown Lipschitz constant. Numerical experiments demonstrate the effectiveness of our algorithms.},
  archive      = {J_JGO},
  author       = {Yang, Xin and Xu, Lingling},
  doi          = {10.1007/s10898-022-01214-3},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {939-964},
  shortjournal = {J. Glob. Optim.},
  title        = {Some accelerated alternating proximal gradient algorithms for a class of nonconvex nonsmooth problems},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A maximum hypergraph 3-cut problem with limited unbalance:
Approximation and analysis. <em>JGO</em>, <em>87</em>(2), 917–937. (<a
href="https://doi.org/10.1007/s10898-022-01183-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the max hypergraph 3-cut problem with limited unbalance (MH3C-LU). The objective is to divide the vertex set of an edge-weighted hypergraph $$H=(V,E,w)$$ into three disjoint subsets $$V_{1}$$ , $$V_{2}$$ , and $$V_{3}$$ such that the sum of edge weights cross different parts is maximized subject to $$||V_{i}|-|V_{l}||\le B$$ ( $$\forall i\ne l\in {1,2,3}$$ ) for a given parameter B. This problem is NP-hard because it includes some well-known problems like the max 3-section problem and the max 3-cut problem as special cases. We formulate the MH3C-LU as a ternary quadratic program and present a randomized approximation algorithm based on the complex semidefinite programming relaxation technique.},
  archive      = {J_JGO},
  author       = {Sun, Jian and Zhang, Zan-Bo and Chen, Yannan and Han, Deren and Du, Donglei and Zhang, Xiaoyan},
  doi          = {10.1007/s10898-022-01183-7},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {917-937},
  shortjournal = {J. Glob. Optim.},
  title        = {A maximum hypergraph 3-cut problem with limited unbalance: Approximation and analysis},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-trading coordination with government subsidy.
<em>JGO</em>, <em>87</em>(2), 877–915. (<a
href="https://doi.org/10.1007/s10898-022-01259-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data trading has become increasingly attractive and crucial in the era of the digital economy. Previous studies present insightful but only partial analysis on data-trading coordination which is of great societal value. One particular case in point is government subsidy that has been a common practice in real-life data trading markets among different countries. We propose a differential game with government subsidies that consists of three agents, a data-providing enterprise, a data trading platform, and the government. We analyze and compare the social welfares for both the centralized and decentralized systems, and present a cost-sharing contract and a revenue sharing contract to maximize the system social welfare, in which the quality and the advertising effort are important factors on data products goodwill. Our results reveal that centralization enhances the efficiency of the data trading system, and the government achieves a higher social welfare level with a lower cost subsidy coefficient. Numerical analyses are also carried to provide further managerial insights by comparative statics analysis on system parameters.},
  archive      = {J_JGO},
  author       = {Jing, Kui and Liu, Xin and Xu, Fengmin and Du, Donglei},
  doi          = {10.1007/s10898-022-01259-4},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {877-915},
  shortjournal = {J. Glob. Optim.},
  title        = {Data-trading coordination with government subsidy},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A note on the SDP relaxation of the minimum cut problem.
<em>JGO</em>, <em>87</em>(2), 857–876. (<a
href="https://doi.org/10.1007/s10898-022-01235-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a recent paper by Li et al. (Comput Optim Appl 78(3):853–891, 2021), the authors propose an SDP relaxation for solving the minimum cut problem. In this note, we derive this SDP relaxation by Li et al. in a different way which provides a new perspective. Moreover, we give a rigorous proof that this relaxation by Li et al. is a stronger relaxation than the SDP relaxation presented in Pong et al. (Comput Optim Appl 63(2):333–364, 2016). The technique that we use to compare these two relaxations is through establishing a containment relationship between the feasible sets of these two relaxations. This technique is then studied and analyzed in a more general setting. We present some interesting observations about the differences in the optimal sets and values under this technique. Finally, we verify the strength of the SDP relaxation by Li et al. on some random graphs and also on some classical graphs for solving the vertex separator problems in the numerical experiments.},
  archive      = {J_JGO},
  author       = {Hu, Hao and Li, Xinxin and Wu, Jiageng},
  doi          = {10.1007/s10898-022-01235-y},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {857-876},
  shortjournal = {J. Glob. Optim.},
  title        = {A note on the SDP relaxation of the minimum cut problem},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A facial reduction approach for the single source
localization problem. <em>JGO</em>, <em>87</em>(2), 831–855. (<a
href="https://doi.org/10.1007/s10898-022-01188-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The single source localization problem (SSLP) appears in several fields such as signal processing and global positioning systems. The optimization problem of SSLP is nonconvex and difficult to find its globally optimal solution. It can be reformulated as a rank constrained Euclidean distance matrix (EDM) completion problem with a number of equality constraints. In this paper, we propose a facial reduction approach to solve such an EDM completion problem. For the constraints of fixed distances between sensors, we reduce them to a face of the EDM cone and derive the closed formulation of the face. We prove constraint nondegeneracy for each feasible point of the resulting EDM optimization problem without a rank constraint, which guarantees the quadratic convergence of semismooth Newton’s method. To tackle the nonconvex rank constraint, we apply the majorized penalty approach developed by Zhou et al. (IEEE Trans Signal Process 66(3):4331-4346, 2018). Numerical results verify the fast speed of the proposed approach while giving comparable quality of solutions as other methods.},
  archive      = {J_JGO},
  author       = {Shi, He and Li, Qingna},
  doi          = {10.1007/s10898-022-01188-2},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {831-855},
  shortjournal = {J. Glob. Optim.},
  title        = {A facial reduction approach for the single source localization problem},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiobjective optimization with least constraint violation:
Optimality conditions and exact penalization. <em>JGO</em>,
<em>87</em>(2), 807–830. (<a
href="https://doi.org/10.1007/s10898-022-01158-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although multiobjective optimization problem (MOP) is useful for solving many practical optimization problems, it is possible that the constraints are inconsistent. In this paper, we reformulate MOP with possible inconsistent constraints into MOP with least constraint violation and provide necessary optimality conditions from the perspective of M-stationary point, Fritz-John stationary point and L-stationary point. A power penalty problem is proposed by using infeasibility measure of constraints. The calmness conditions of order $$\ell $$ of the MOP with least constraint violation and the local exact penalization of order $$\ell $$ of the power penalty problem are respectively introduced, which do not require the feasibility of the original MOP. We obtain the equivalence between the calmness of order $$\ell $$ of the MOP with least constraint violation and the local exact penalization of order $$\ell $$ of the power penalty problem. Necessary and sufficient conditions for calmness of order $$\ell $$ are also established under suitable conditions.},
  archive      = {J_JGO},
  author       = {Chen, Jiawei and Dai, Yu-Hong},
  doi          = {10.1007/s10898-022-01158-8},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {807-830},
  shortjournal = {J. Glob. Optim.},
  title        = {Multiobjective optimization with least constraint violation: Optimality conditions and exact penalization},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributionally robust mean-absolute deviation portfolio
optimization using wasserstein metric. <em>JGO</em>, <em>87</em>(2),
783–805. (<a href="https://doi.org/10.1007/s10898-022-01171-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data uncertainty has a great impact on portfolio selection. Based on the popular mean-absolute deviation (MAD) model, we investigate how to make robust portfolio decisions. In this paper, a novel Wasserstein metric-based data-driven distributionally robust mean-absolute deviation (DR-MAD) model is proposed. However, the proposed model is non-convex with an infinite-dimensional inner problem. To solve this model, we prove that it can be transformed into two simple finite-dimensional linear programs. Consequently, the problem can be solved as easily as solving the classic MAD model. Furthermore, the proposed DR-MAD model is compared with the 1/N, classic MAD and mean-variance model on S &amp;P 500 constituent stocks in six different settings. The experimental results show that the portfolios constructed by DR-MAD model are superior to the benchmarks in terms of profitability and stability in most fluctuating markets. This result suggests that Wasserstein distributionally robust optimization framework is an effective approach to address data uncertainty in portfolio optimization.},
  archive      = {J_JGO},
  author       = {Chen, Dali and Wu, Yuwei and Li, Jingquan and Ding, Xiaohui and Chen, Caihua},
  doi          = {10.1007/s10898-022-01171-x},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {783-805},
  shortjournal = {J. Glob. Optim.},
  title        = {Distributionally robust mean-absolute deviation portfolio optimization using wasserstein metric},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Painlevé-kuratowski convergence of minimal solutions for
set-valued optimization problems via improvement sets. <em>JGO</em>,
<em>87</em>(2), 759–781. (<a
href="https://doi.org/10.1007/s10898-022-01166-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to explore the stability of (weak)-minimal solutions for set-valued optimization problems via improvement sets. Firstly, the optimality and closedness of solution sets for the set-valued optimization problem under the upper order relation are discussed. Then, a new convergence concept for set-valued mapping sequences is introduced, and some properties of the set-valued mapping sequences are shown under the new convergence assumption. Moreover, by means of upper level sets, Painlevé-Kuratowski convergences of (weak) E-u-solutions to set-valued optimization problems with respect to the perturbations of feasible sets and objective mappings are established under mild conditions. The order that we use to establish the result depends on the improvement set, which is not necessarily a cone order. Our results can be seen as the extension of the related work established recently in this field.},
  archive      = {J_JGO},
  author       = {Peng, Zai-Yun and Chen, Xue-Jing and Zhao, Yun-Bin and Li, Xiao-Bing},
  doi          = {10.1007/s10898-022-01166-8},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {759-781},
  shortjournal = {J. Glob. Optim.},
  title        = {Painlevé-kuratowski convergence of minimal solutions for set-valued optimization problems via improvement sets},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quaternion matrix decomposition and its theoretical
implications. <em>JGO</em>, <em>87</em>(2), 741–758. (<a
href="https://doi.org/10.1007/s10898-022-01210-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel matrix rank-one decomposition for quaternion Hermitian matrices, which admits a stronger property than the previous results in Ai W et al (Math Progr 128(1):253–283, 2011), Huang Y, Zhang S (Math Oper Res 32(3):758–768, 2007), Sturm JF, Zhang S (Math Oper Res 28(2):246–267 2003). The enhanced property can be used to drive some improved results in joint numerical range, $${\mathcal {S}}$$ -Procedure and quadratically constrained quadratic programming (QCQP) in the quaternion domain, demonstrating the capability of our new decomposition technique.},
  archive      = {J_JGO},
  author       = {He, Chang and Jiang, Bo and Zhu, Xihua},
  doi          = {10.1007/s10898-022-01210-7},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {741-758},
  shortjournal = {J. Glob. Optim.},
  title        = {Quaternion matrix decomposition and its theoretical implications},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Zeroth-order algorithms for nonconvex–strongly-concave
minimax problems with improved complexities. <em>JGO</em>,
<em>87</em>(2), 709–740. (<a
href="https://doi.org/10.1007/s10898-022-01160-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study zeroth-order algorithms for minimax optimization problems that are nonconvex in one variable and strongly-concave in the other variable. Such minimax optimization problems have attracted significant attention lately due to their applications in modern machine learning tasks. We first consider a deterministic version of the problem. We design and analyze the Zeroth-Order Gradient Descent Ascent (ZO-GDA) algorithm, and provide improved results compared to existing works, in terms of oracle complexity. We also propose the Zeroth-Order Gradient Descent Multi-Step Ascent (ZO-GDMSA) algorithm that significantly improves the oracle complexity of ZO-GDA. We then consider stochastic versions of ZO-GDA and ZO-GDMSA, to handle stochastic nonconvex minimax problems. For this case, we provide oracle complexity results under two assumptions on the stochastic gradient: (i) the uniformly bounded variance assumption, which is common in traditional stochastic optimization, and (ii) the Strong Growth Condition (SGC), which has been known to be satisfied by modern over-parameterized machine learning models. We establish that under the SGC assumption, the complexities of the stochastic algorithms match that of deterministic algorithms. Numerical experiments are presented to support our theoretical results.},
  archive      = {J_JGO},
  author       = {Wang, Zhongruo and Balasubramanian, Krishnakumar and Ma, Shiqian and Razaviyayn, Meisam},
  doi          = {10.1007/s10898-022-01160-0},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {709-740},
  shortjournal = {J. Glob. Optim.},
  title        = {Zeroth-order algorithms for nonconvex–strongly-concave minimax problems with improved complexities},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Decision bounding problems for two-stage distributionally
robust stochastic bilevel optimization. <em>JGO</em>, <em>87</em>(2),
679–707. (<a href="https://doi.org/10.1007/s10898-022-01227-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributionally robust optimization (DRO) becomes a hot research topic in stochastic programming (SP) due to its characteristic for solving SP problems with incomplete distribution information. In this paper, we study a two-stage distributionally robust stochastic bilevel optimization problem (TDRBO) under the moment uncertainty. The TDRBO problem has a complicated optimization structure and is intractable. To this end, we first present the corresponding robust optimistic and pessimistic models as the bounds of the TDRBO problem. Then we use the decision rule approach to handle the bounded optimization problems under two situations of fixed recourse and random recourse. Finally, we obtain the tractable bounded optimization problems of the TDRBO problem. Some theoretical results are established and the numerical results are presented, showing that the approaches proposed in this paper are reasonable and effective.},
  archive      = {J_JGO},
  author       = {Tong, Xiaojiao and Li, Manlan and Sun, Hailin},
  doi          = {10.1007/s10898-022-01227-y},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {679-707},
  shortjournal = {J. Glob. Optim.},
  title        = {Decision bounding problems for two-stage distributionally robust stochastic bilevel optimization},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A derivative-free scaling memoryless DFP method for solving
large scale nonlinear monotone equations. <em>JGO</em>, <em>87</em>(2),
641–677. (<a href="https://doi.org/10.1007/s10898-022-01215-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quasi-Newton methods for solving nonlinear system of equations provide an attractive alternative to the Newton method in which they do not require computation of the Jacobian matrix and still possess superlinear convergence. In this paper, we develop a new sufficient descent direction based on a scaling memoryless DFP updating formula. By combining this descent direction with a projection approach, we propose a derivative-free scaling memoryless DFP method for solving nonlinear monotone equations and establish its global convergence under reasonable conditions. In sharp contrast with the original DFP method, our new method does not involve computing matrices. This makes it particularly suitable for solving large scale problems. The presented results of numerical experiments demonstrate the robustness and efficiency of our new method.},
  archive      = {J_JGO},
  author       = {Rao, Jiayun and Huang, Na},
  doi          = {10.1007/s10898-022-01215-2},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {641-677},
  shortjournal = {J. Glob. Optim.},
  title        = {A derivative-free scaling memoryless DFP method for solving large scale nonlinear monotone equations},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A relaxed inertial and viscosity method for split
feasibility problem and applications to image recovery. <em>JGO</em>,
<em>87</em>(2), 619–639. (<a
href="https://doi.org/10.1007/s10898-022-01246-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, by combining Polyak’s inertial extrapolation technique for minimization problem with the viscosity approximation for fixed point problem, we develop a new type of numerical solution method for split feasibility problem. Under suitable assumptions, we establish the global convergence of the designed method. The given experimental results applied on the sparse reconstruction problem show that the proposed algorithm is not only robust to different levels of sparsity and amplitude of signals and the noise pixels but also insensitive to the diverse values of scalar weight. Further, the proposed algorithm achieves better restoration performance compared with some other algorithms for image recovery.},
  archive      = {J_JGO},
  author       = {Che, Haitao and Zhuang, Yaru and Wang, Yiju and Chen, Haibin},
  doi          = {10.1007/s10898-022-01246-9},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {619-639},
  shortjournal = {J. Glob. Optim.},
  title        = {A relaxed inertial and viscosity method for split feasibility problem and applications to image recovery},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Approximation algorithms for the individually fair k-center
with outliers. <em>JGO</em>, <em>87</em>(2), 603–618. (<a
href="https://doi.org/10.1007/s10898-022-01195-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose and investigate the individually fair k-center with outliers (IFkCO). In the IFkCO, we are given an n-sized vertex set in a metric space, as well as integers k and q. At most k vertices can be selected as the centers and at most q vertices can be selected as the outliers. The centers are selected to serve all the not-an-outlier (i.e., served) vertices. The so-called individual fairness constraint restricts that every served vertex must have a selected center not too far way. More precisely, it is supposed that there exists at least one center among its $$\lceil (n-q) / k \rceil $$ closest neighbors for every served vertex. Because every center serves $$(n -q) / k$$ vertices on the average. The objective is to select centers and outliers, assign every served vertex to some center, such that the maximum fairness ratio over all served vertices is minimized, where the fairness ratio of a vertex is defined as the ratio between its distance with the assigned center and its distance with a $$\lceil (n - q )/k \rceil _\mathrm{th}$$ closest neighbor. As our main contribution, a 4-approximation algorithm is presented, based on which we develop an improved algorithm from a practical perspective. Extensive experiment results on both synthetic datasets and real-world datasets are presented to illustrate the effectiveness of the proposed algorithms.},
  archive      = {J_JGO},
  author       = {Han, Lu and Xu, Dachuan and Xu, Yicheng and Yang, Ping},
  doi          = {10.1007/s10898-022-01195-3},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {603-618},
  shortjournal = {J. Glob. Optim.},
  title        = {Approximation algorithms for the individually fair k-center with outliers},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A golden ratio proximal alternating direction method of
multipliers for separable convex optimization. <em>JGO</em>,
<em>87</em>(2), 581–602. (<a
href="https://doi.org/10.1007/s10898-022-01154-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Separable convex optimization problems often arise from large scale applications, and alternating direction method of multipliers (ADMM), due to its ability to utilize the separable structure of the objective function, has become an extremely popular approach for solving this class of problems. However, the convergence of the primal iterates generated by ADMM is not guaranteed and the ADMM subproblems can be computationally demanding. Proximal ADMM (PADMM), which introduces proximal terms to the ADMM subproblems, not only guarantees convergence of both the primal and the dual iterates but also is able to take advantage of the problem structures. In this paper, by adopting a convex combination technique we propose a new variant of the classical ADMM, which we call golden ratio proximal ADMM (GrpADMM) as the golden ratio appears to be a key parameter. GrpADMM preserves all the favorable features of PADMM, such as the ability to take full use of problem structures and global convergence under relaxed parameter condition. We show that GrpADMM shares the $${\mathcal {O}}({1}/{N})$$ ergodic sublinear convergence rate, where N denotes the iteration counter. Furthermore, as long as one of the functions in the objective is strongly convex, the algorithm can be modified to achieve faster $${\mathcal {O}}(1/N^2)$$ ergodic convergence. Finally, we demonstrate the performance of the proposed algorithms via preliminary numerical experiments.},
  archive      = {J_JGO},
  author       = {Chen, Hongmei and Gu, Guoyong and Yang, Junfeng},
  doi          = {10.1007/s10898-022-01154-y},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {581-602},
  shortjournal = {J. Glob. Optim.},
  title        = {A golden ratio proximal alternating direction method of multipliers for separable convex optimization},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Zeroth-order single-loop algorithms for nonconvex-linear
minimax problems. <em>JGO</em>, <em>87</em>(2), 551–580. (<a
href="https://doi.org/10.1007/s10898-022-01169-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonconvex minimax problems have attracted significant interest in machine learning and many other fields in recent years. In this paper, we propose a new zeroth-order alternating randomized gradient projection algorithm to solve smooth nonconvex-linear problems and its iteration complexity to find an $$\varepsilon $$ -first-order Nash equilibrium is $${\mathcal {O}}\left( \varepsilon ^{-3} \right) $$ and the number of function value estimation per iteration is bounded by $${\mathcal {O}}\left( d_{x}\varepsilon ^{-2} \right) $$ . Furthermore, we propose a zeroth-order alternating randomized proximal gradient algorithm for block-wise nonsmooth nonconvex-linear minimax problems and its corresponding iteration complexity is $${\mathcal {O}}\left( K^{\frac{3}{2}} \varepsilon ^{-3} \right) $$ and the number of function value estimation is bounded by $${\mathcal {O}}\left( d_{x}\varepsilon ^{-2} \right) $$ per iteration. The numerical results indicate the efficiency of the proposed algorithms.},
  archive      = {J_JGO},
  author       = {Shen, Jingjing and Wang, Ziqi and Xu, Zi},
  doi          = {10.1007/s10898-022-01169-5},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {551-580},
  shortjournal = {J. Glob. Optim.},
  title        = {Zeroth-order single-loop algorithms for nonconvex-linear minimax problems},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An indefinite proximal subgradient-based algorithm for
nonsmooth composite optimization. <em>JGO</em>, <em>87</em>(2), 533–550.
(<a href="https://doi.org/10.1007/s10898-022-01173-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an indefinite proximal subgradient-based algorithm (IPSB) for solving nonsmooth composite optimization problems. IPSB is a generalization of the Nesterov’s dual algorithm, where an indefinite proximal term is added to the subproblems, which can make the subproblem easier and the algorithm efficient when an appropriate proximal operator is judiciously setting down. Under mild assumptions, we establish sublinear convergence of IPSB to a region of the optimal value. We also report some numerical results, demonstrating the efficiency of IPSB in comparing with the classical dual averaging-type algorithms.},
  archive      = {J_JGO},
  author       = {Liu, Rui and Han, Deren and Xia, Yong},
  doi          = {10.1007/s10898-022-01173-9},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {533-550},
  shortjournal = {J. Glob. Optim.},
  title        = {An indefinite proximal subgradient-based algorithm for nonsmooth composite optimization},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new global algorithm for factor-risk-constrained
mean-variance portfolio selection. <em>JGO</em>, <em>87</em>(2),
503–532. (<a href="https://doi.org/10.1007/s10898-022-01218-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the factor-risk-constrained mean-variance portfolio-selection (MVPS) problem that allows managers to construct portfolios with desired factor-risk characteristics. Its optimization model is a non-convex quadratically constrained quadratic program that is known to be NP-hard. In this paper, we investigate the new global algorithm for factor-risk-constrained MVPS problem based on the successive convex optimization (SCO) method and the semi-definite relaxation (SDR) with a second-order cone (SOC) constraint. We first develop an SCO algorithm and show that it converges to a KKT point of the problem. We then develop a new global algorithm for factor-risk-constrained MVPS, which integrates the SCO method, the SDR with an SOC constraint, the branch-and-bound framework and the adaptive branch-and-cut rule for factor-related variables, to find a globally optimal solution to the underlying problem within a pre-specified $$\epsilon $$ -tolerance. We establish the global convergence of the proposed algorithm and its complexity. Preliminary numerical results demonstrate the effectiveness of the proposed algorithm in finding a globally optimal solution to medium- and large-scale instances of factor-risk-constrained MVPS.},
  archive      = {J_JGO},
  author       = {Wu, Huixian and Luo, Hezhi and Zhang, Xianye and Liu, Jianzhen},
  doi          = {10.1007/s10898-022-01218-z},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {503-532},
  shortjournal = {J. Glob. Optim.},
  title        = {A new global algorithm for factor-risk-constrained mean-variance portfolio selection},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Characterizing robust optimal solution sets for nonconvex
uncertain semi-infinite programming problems involving tangential
subdifferentials. <em>JGO</em>, <em>87</em>(2), 481–501. (<a
href="https://doi.org/10.1007/s10898-022-01134-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we give some characterizations of the robust optimal solution set for nonconvex uncertain semi-infinite programming problems in terms of tangential subdifferentials. By using a new robust-type constraint qualification, we first obtain some necessary and sufficient optimality conditions of the robust optimal solution for the nonconvex uncertain semi-infinite programming problem via the robust optimization approach. Then, by using the Dini pseudoconvexity, we obtain some characterizations of the robust optimal solution set for the nonconvex uncertain semi-infinite programming problem. Finally, as applications of our results, we derive some optimality conditions of the robust optimal solution and characterizations of the robust optimal solution set for the cone-constrained nonconvex uncertain optimization problem. Some examples are given to illustrate the advantage of the results.},
  archive      = {J_JGO},
  author       = {Liu, Juan and Long, Xian-Jun and Sun, Xiang-Kai},
  doi          = {10.1007/s10898-022-01134-2},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {481-501},
  shortjournal = {J. Glob. Optim.},
  title        = {Characterizing robust optimal solution sets for nonconvex uncertain semi-infinite programming problems involving tangential subdifferentials},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An entropy-regularized ADMM for binary quadratic
programming. <em>JGO</em>, <em>87</em>(2), 447–479. (<a
href="https://doi.org/10.1007/s10898-022-01144-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an entropy regularized splitting model using low-rank factorization for solving binary quadratic programming with linear inequality constraints. Different from the semidefinite programming relaxation model, our model preserves the rank-one constraint and aims to find high quality rank-one solutions directly. The factorization transforms the variables into low-rank matrices, while the entropy term enforces the low-rank property of the splitting variable . A customized alternating direction method of multipliers is utilized to solve the proposed model. Specifically, our method uses the augmented Lagrangian function to deal with inequality constraints, and solves one subproblem on the oblique manifold by a regularized Newton method. Numerical results on the multiple-input multiple-output detection problem, the maxcut problem and the quadratic $$0-1$$ problem indicate that our proposed algorithm has advantage over the SDP methods.},
  archive      = {J_JGO},
  author       = {Liu, Haoming and Deng, Kangkang and Liu, Haoyang and Wen, Zaiwen},
  doi          = {10.1007/s10898-022-01144-0},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {447-479},
  shortjournal = {J. Glob. Optim.},
  title        = {An entropy-regularized ADMM for binary quadratic programming},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved variance reduction extragradient method with line
search for stochastic variational inequalities. <em>JGO</em>,
<em>87</em>(2), 423–446. (<a
href="https://doi.org/10.1007/s10898-022-01135-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the numerical methods for solving stochastic variational inequalities. Using line search scheme, we propose an improved variance based stochastic extragradient method with different step sizes in the prediction and correction steps. The range of correction step size which can guarantee the convergence is also given. For the initial line search step size of each iteration, an adaptive method is adopted. Rather than the same scale for each reduction, a proportional reduction related to the problem is used to meet the line search criteria. Under the assumptions of Lipschitz continuous, pseudo-monotone operator and independent identically distributed sampling, the iterative complexity and the oracle complexity are obtained. When estimating the upper bound of the second order moment of the martingale difference sequence, we give a more convenient and comprehensible proof instead of using the Burkholder-Davis-Gundy inequality. The proposed algorithm is applied to fractional programming problems and the $$l_2$$ regularized logistic regression problem. The numerical results demonstrate its superiority.},
  archive      = {J_JGO},
  author       = {Li, Ting and Cai, Xingju and Song, Yongzhong and Ma, Yumin},
  doi          = {10.1007/s10898-022-01135-1},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {423-446},
  shortjournal = {J. Glob. Optim.},
  title        = {Improved variance reduction extragradient method with line search for stochastic variational inequalities},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A proximal alternating minimization algorithm for the
largest c-eigenvalue of piezoelectric-type tensors. <em>JGO</em>,
<em>87</em>(2), 405–422. (<a
href="https://doi.org/10.1007/s10898-022-01180-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {C-eigenvalues of piezoelectric-type tensors play an important role in piezoelectric effect and converse piezoelectric effect. While the largest C-eigenvalue of a given piezoelectric-type tensor has concrete physical meaning which determines the highest piezoelectric coupling constant. In this paper, we focus on computing the maximum C-eigenvalue of piezoelectric-type tensors which is a third degree polynomial problem. To do that, we first establish the equivalence between the proposed polynomial optimization problem (POP) and a multi-linear optimization problem (MOP) under conditions that the original objective function is concave. Then, an augmented POP (which can also be regarded as a regularized POP) is introduced for the purpose to guarantee the concavity of the underlying objective function. Theoretically, both the augmented POP and the original problem share the same optimal solutions when the compact sets are specified as unit spheres. By exploiting the multi-block structure of the resulting MOP, we accordingly propose a proximal alternating minimization algorithm to get an approximate optimal value of the maximum C-eigenvalue. Furthermore, convergence of the proposed algorithm is established under mild conditions. Finally, some preliminary computational results on synthetic data sets are reported to show the efficiency of the proposed algorithm.},
  archive      = {J_JGO},
  author       = {Wang, Wenjie and Chen, Haibin and Wang, Yiju and Zhou, Guanglu},
  doi          = {10.1007/s10898-022-01180-w},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {405-422},
  shortjournal = {J. Glob. Optim.},
  title        = {A proximal alternating minimization algorithm for the largest C-eigenvalue of piezoelectric-type tensors},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Randomized algorithms for the computation of multilinear
rank- <span
class="math display">(<em>μ</em><sub>1</sub>, <em>μ</em><sub>2</sub>, <em>μ</em><sub>3</sub>)</span>
approximations. <em>JGO</em>, <em>87</em>(2), 373–403. (<a
href="https://doi.org/10.1007/s10898-022-01182-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present some randomized algorithms for computing multilinear rank- $$(\mu _1,\mu _2,\mu _3)$$ approximations of tensors by combining the sparse subspace embedding and the singular value decomposition. The error bound for this algorithm with the high probability is obtained by the properties of sparse subspace embedding. Furthermore, combining the power scheme and the proposed randomized algorithm, we derive a three-stage randomized algorithm and make a probabilistic analysis for its error bound. The efficiency of the proposed algorithms is illustrated via numerical examples.},
  archive      = {J_JGO},
  author       = {Che, Maolin and Wei, Yimin and Xu, Yanwei},
  doi          = {10.1007/s10898-022-01182-8},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {373-403},
  shortjournal = {J. Glob. Optim.},
  title        = {Randomized algorithms for the computation of multilinear rank- $$(\mu _1,\mu _2,\mu _3)$$ approximations},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solution sets of three sparse optimization problems for
multivariate regression. <em>JGO</em>, <em>87</em>(2), 347–371. (<a
href="https://doi.org/10.1007/s10898-021-01124-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multivariate regression analysis, a coefficient matrix is used to relate multiple response variables to regressor variables in a noisy linear system from given data. Optimization is a natural approach to find such coefficient matrix with few nonzero rows. However, the relationship of most group sparse optimization models with cardinality penalty or cardinality constraints is not clear. In this paper, we give a comprehensive description of the relationship between three widely used group sparse optimization problems with cardinality terms: (i) the number of nonzero rows is minimized subject to an error tolerance for regression; (ii) the error for regression is minimized subject to a row cardinality constraint; (iii) the sum of the number of nonzero rows and error for regression is minimized. The first two problems have convex constraints and cardinality constraints respectively, while the third one is an unconstrained optimization problem with a cardinality penalty. We provide sufficient conditions under which the three optimization problems have the same global minimizers. Moreover, we analyze the relationship of stationary points and local minimizers of the three problems. Finally, we use two examples to illustrate our theoretical results for finding solutions of constrained optimization problems involving cardinality terms by unconstrained optimization problems with penalty functions.},
  archive      = {J_JGO},
  author       = {Chen, Xiaojun and Pan, Lili and Xiu, Naihua},
  doi          = {10.1007/s10898-021-01124-w},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {347-371},
  shortjournal = {J. Glob. Optim.},
  title        = {Solution sets of three sparse optimization problems for multivariate regression},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fitting feature-dependent markov chains. <em>JGO</em>,
<em>87</em>(2), 329–346. (<a
href="https://doi.org/10.1007/s10898-022-01198-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe a method for fitting a Markov chain, with a state transition matrix that depends on a feature vector, to data that can include missing values. Our model consists of separate logistic regressions for each row of the transition matrix. We fit the parameters in the model by maximizing the log-likelihood of the data minus a regularizer. When there are missing values, the log-likelihood becomes intractable, and we resort to the expectation-maximization (EM) heuristic. We illustrate the method on several examples, and describe our efficient Python open-source implementation.},
  archive      = {J_JGO},
  author       = {Barratt, Shane and Boyd, Stephen},
  doi          = {10.1007/s10898-022-01198-0},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {329-346},
  shortjournal = {J. Glob. Optim.},
  title        = {Fitting feature-dependent markov chains},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Preface: Special issue of MOA 2020. <em>JGO</em>,
<em>87</em>(2), 325–327. (<a
href="https://doi.org/10.1007/s10898-023-01323-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JGO},
  author       = {Liu, Ya-Feng and Xu, Zi and Krokhmal, Pavlo A. and Peng, Jiming},
  doi          = {10.1007/s10898-023-01323-7},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {325-327},
  shortjournal = {J. Glob. Optim.},
  title        = {Preface: Special issue of MOA 2020},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On solving bi-objective constrained minimum spanning tree
problems. <em>JGO</em>, <em>87</em>(1), 301–323. (<a
href="https://doi.org/10.1007/s10898-023-01295-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates two approaches for solving bi-objective constrained minimum spanning tree problems. The first seeks to minimize the tree weight, keeping the problem’s additional objective as a constraint, and the second aims at minimizing the other objective while constraining the tree weight. As case studies, we propose and solve bi-objective generalizations of the Hop-Constrained Minimum Spanning Tree Problem (HCMST) and the Delay-Constrained Minimum Spanning Tree Problem (DCMST). First, we present an Integer Linear Programming (ILP) formulation for the HCMST. Then, we propose a new compact mathematical model for the DCMST based on the well-known Miller–Tucker–Zemlin subtour elimination constraints. Next, we extend these formulations as bi-objective models and solve them using an Augmented $$\epsilon $$ -constraints method. Computational experiments performed on classical instances from the literature evaluated two different implementations of the Augmented $$\epsilon $$ -constraints method for each problem. Results indicate that the algorithm performs better when minimizing the tree weight while constraining the other objective since this implementation finds shorter running times than the one that minimizes the additional objective and constrains the tree weight.},
  archive      = {J_JGO},
  author       = {Carvalho, Iago A. and Coco, Amadeu A.},
  doi          = {10.1007/s10898-023-01295-8},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {301-323},
  shortjournal = {J. Glob. Optim.},
  title        = {On solving bi-objective constrained minimum spanning tree problems},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An alternating structure-adapted bregman proximal gradient
descent algorithm for constrained nonconvex nonsmooth optimization
problems and its inertial variant. <em>JGO</em>, <em>87</em>(1),
277–300. (<a href="https://doi.org/10.1007/s10898-023-01300-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the nonconvex nonsmooth minimization problem over abstract sets, whose objective function is the sum of a proper lower semicontinuous biconvex function of the entire variables and two smooth nonconvex functions of their private variables. Fully exploiting the problem structure, we propose an alternating structure-adapted Bregman proximal (ASABP for short) gradient descent algorithm, where the geometry of the abstract set and the function is captured by employing generalized Bregman function. Under the assumption that the underlying function satisfies the Kurdyka–Łojasiewicz property, we prove that each bounded sequence generated by ASABP globally converges to a critical point. We then adopt an inertial strategy to accelerate the ASABP algorithm (IASABP), and utilize a backtracking line search scheme to find “suitable” step sizes, making the algorithm efficient and robust. The global O(1/K) sublinear convergence rate measured by Bregman distance is also established. Furthermore, to illustrate the potential of ASABP and its inertial version (IASABP), we apply them to solving the Poisson linear inverse problem, and the results are promising.},
  archive      = {J_JGO},
  author       = {Gao, Xue and Cai, Xingju and Wang, Xiangfeng and Han, Deren},
  doi          = {10.1007/s10898-023-01300-0},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {277-300},
  shortjournal = {J. Glob. Optim.},
  title        = {An alternating structure-adapted bregman proximal gradient descent algorithm for constrained nonconvex nonsmooth optimization problems and its inertial variant},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). New semidefinite relaxations for a class of complex
quadratic programming problems. <em>JGO</em>, <em>87</em>(1), 255–275.
(<a href="https://doi.org/10.1007/s10898-023-01290-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose some new semidefinite relaxations for a class of nonconvex complex quadratic programming problems, which widely appear in the areas of signal processing and power system. By deriving new valid constraints to the matrix variables in the lifted space, we derive some enhanced semidefinite relaxations of the complex quadratic programming problems. Then, we compare the proposed semidefinite relaxations with existing ones, and show that the newly proposed semidefinite relaxations could be strictly tighter than the previous ones. Moreover, the proposed semidefinite relaxations can be applied to more general cases of complex quadratic programming problems, whereas the previous ones are only designed for special cases. Numerical results indicate that the proposed semidefinite relaxations not only provide tighter relaxation bounds, but also improve some existing approximation algorithms by finding better sub-optimal solutions.},
  archive      = {J_JGO},
  author       = {Xu, Yingzhe and Lu, Cheng and Deng, Zhibin and Liu, Ya-Feng},
  doi          = {10.1007/s10898-023-01290-z},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {255-275},
  shortjournal = {J. Glob. Optim.},
  title        = {New semidefinite relaxations for a class of complex quadratic programming problems},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sparse conic reformulation of structured QCQPs based on
copositive optimization with applications in stochastic optimization.
<em>JGO</em>, <em>87</em>(1), 221–254. (<a
href="https://doi.org/10.1007/s10898-023-01283-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Bomze et al. introduced a sparse conic relaxation of the scenario problem of a two stage stochastic version of the standard quadratic optimization problem. When compared numerically to Burer’s classical reformulation, the authors showed that there seems to be almost no difference in terms of solution quality, whereas the solution time can differ by orders of magnitudes. While the authors did find a very limited special case, for which Burer’s reformulation and their relaxation are equivalent, no satisfying explanation for the high quality of their bound was given. This article aims at shedding more light on this phenomenon and give a more thorough theoretical account of its inner workings. We argue that the quality of the outer approximation cannot be explained by traditional results on sparse conic relaxations based on positive semidenifnite or completely positive matrix completion, which require certain sparsity patterns characterized by chordal and block clique graphs respectively, and put certain restrictions on the type of conic constraint they seek to sparsify. In an effort to develop an alternative approach, we will provide a new type of convex reformulation of a large class of stochastic quadratically constrained quadratic optimization problems that is similar to Burer’s reformulation, but lifts the variables into a comparatively lower dimensional space. The reformulation rests on a generalization of the set-completely positive matrix cone. This cone can then be approximated via inner and outer approximations in order to obtain upper and lower bounds, which potentially close the optimality gap, and hence can give a certificate of exactness for these sparse reformulations outside of traditional, known sufficient conditions. Finally, we provide some numerical experiments, where we asses the quality of the inner and outer approximations, thereby showing that the approximations may indeed close the optimality gap in interesting cases.},
  archive      = {J_JGO},
  author       = {Gabl, Markus},
  doi          = {10.1007/s10898-023-01283-y},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {221-254},
  shortjournal = {J. Glob. Optim.},
  title        = {Sparse conic reformulation of structured QCQPs based on copositive optimization with applications in stochastic optimization},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An effective global algorithm for worst-case linear
optimization under polyhedral uncertainty. <em>JGO</em>, <em>87</em>(1),
191–219. (<a href="https://doi.org/10.1007/s10898-023-01286-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate effective algorithms for the worst-case linear optimization (WCLO) under polyhedral uncertainty on the right-hand-side of the constraints that arises from a broad range of applications and is known to be strongly NP-hard. We first develop a successive convex optimization (SCO) algorithm for WCLO and show that it converges to a local solution of the transformed problem of WCLO. Second, we develop a global algorithm (called SCOBB) for WCLO that finds a globally optimal solution to the underlying WCLO within a pre-specified $$\epsilon $$ -tolerance by integrating the SCO method, LO relaxation, branch-and-bound framework and initialization. We establish the global convergence of the SCOBB algorithm and estimate its complexity. Finally, we integrate the SCOBB algorithm for WCLO to develop a global algorithm for the two-stage adaptive robust optimization with a polyhedral uncertainty set. Preliminary numerical results illustrate that the SCOBB algorithm can effectively find a global optimal solution to medium and large-scale WCLO instances.},
  archive      = {J_JGO},
  author       = {Wu, Huixian and Luo, Hezhi and Zhang, Xianye and Qi, Haiqiang},
  doi          = {10.1007/s10898-023-01286-9},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {191-219},
  shortjournal = {J. Glob. Optim.},
  title        = {An effective global algorithm for worst-case linear optimization under polyhedral uncertainty},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mixed-integer programming techniques for the minimum
sum-of-squares clustering problem. <em>JGO</em>, <em>87</em>(1),
133–189. (<a href="https://doi.org/10.1007/s10898-022-01267-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimum sum-of-squares clustering problem is a very important problem in data mining and machine learning with very many applications in, e.g., medicine or social sciences. However, it is known to be NP-hard in all relevant cases and to be notoriously hard to be solved to global optimality in practice. In this paper, we develop and test different tailored mixed-integer programming techniques to improve the performance of state-of-the-art MINLP solvers when applied to the problem—among them are cutting planes, propagation techniques, branching rules, or primal heuristics. Our extensive numerical study shows that our techniques significantly improve the performance of the open-source MINLP solver SCIP. Consequently, using our novel techniques, we can solve many instances that are not solvable with SCIP without our techniques and we obtain much smaller gaps for those instances that can still not be solved to global optimality.},
  archive      = {J_JGO},
  author       = {Burgard, Jan Pablo and Moreira Costa, Carina and Hojny, Christopher and Kleinert, Thomas and Schmidt, Martin},
  doi          = {10.1007/s10898-022-01267-4},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {133-189},
  shortjournal = {J. Glob. Optim.},
  title        = {Mixed-integer programming techniques for the minimum sum-of-squares clustering problem},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive piecewise linear relaxations for enclosure
computations for nonconvex multiobjective mixed-integer quadratically
constrained programs. <em>JGO</em>, <em>87</em>(1), 97–132. (<a
href="https://doi.org/10.1007/s10898-023-01309-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new method for computing an enclosure of the nondominated set of multiobjective mixed-integer quadratically constrained programs without any convexity requirements is presented. In fact, our criterion space method makes use of piecewise linear relaxations in order to bypass the nonconvexity of the original problem. The method chooses adaptively which level of relaxation is needed in which parts of the image space. Furthermore, it is guaranteed that after finitely many iterations, an enclosure of the nondominated set of prescribed quality is returned. We demonstrate the advantages of this approach by applying it to multiobjective energy supply network problems.},
  archive      = {J_JGO},
  author       = {Link, Moritz and Volkwein, Stefan},
  doi          = {10.1007/s10898-023-01309-5},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {97-132},
  shortjournal = {J. Glob. Optim.},
  title        = {Adaptive piecewise linear relaxations for enclosure computations for nonconvex multiobjective mixed-integer quadratically constrained programs},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Extended McCormick relaxation rules for handling empty
arguments representing infeasibility. <em>JGO</em>, <em>87</em>(1),
57–95. (<a href="https://doi.org/10.1007/s10898-023-01315-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {McCormick’s relaxation technique is one of the most versatile and commonly used methods for computing the convex relaxations necessary for deterministic global optimization. The core of the method is a set of rules for propagating relaxations through basic arithmetic operations. Computationally, each rule operates on four-tuples describing each input argument in terms of a lower bound value, an upper bound value, a convex relaxation value, and a concave relaxation value. We call such tuples McCormick objects. This paper extends McCormick’s rules to accommodate input objects that are empty (i.e., the convex relaxation value lies above the concave, or both relaxation values lie outside the bounds). Empty McCormick objects provide a natural way to represent infeasibility and are readily generated by McCormick-based domain reduction techniques. The standard McCormick rules are strictly undefined for empty inputs and applying them anyway can yield relaxations that are non-convex/concave on infeasible parts of their domains. In contrast, our extended rules always produce relaxations that are well-defined and convex/concave on their entire domain. This capability has important applications in reduced-space global optimization, global dynamic optimization, and domain reduction.},
  archive      = {J_JGO},
  author       = {Ye, Jason and Scott, Joseph K.},
  doi          = {10.1007/s10898-023-01315-7},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {57-95},
  shortjournal = {J. Glob. Optim.},
  title        = {Extended McCormick relaxation rules for handling empty arguments representing infeasibility},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hesitant adaptive search with estimation and quantile
adaptive search for global optimization with noise. <em>JGO</em>,
<em>87</em>(1), 31–55. (<a
href="https://doi.org/10.1007/s10898-023-01307-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive random search approaches have been shown to be effective for global optimization problems, where under certain conditions, the expected performance time increases only linearly with dimension. However, previous analyses assume that the objective function can be observed directly. We consider the case where the objective function must be estimated, often using a noisy function, as in simulation. We present a finite-time analysis of algorithm performance that combines estimation with a sampling distribution. We present a framework called Hesitant Adaptive Search with Estimation, and derive an upper bound on function evaluations that is cubic in dimension, under certain conditions. We extend the framework to Quantile Adaptive Search with Estimation, which focuses sampling points from a series of nested quantile level sets. The analyses suggest that computational effort is better expended on sampling improving points than refining estimates of objective function values during the progress of an adaptive search algorithm.},
  archive      = {J_JGO},
  author       = {Zabinsky, Zelda B. and Linz, David D.},
  doi          = {10.1007/s10898-023-01307-7},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {31-55},
  shortjournal = {J. Glob. Optim.},
  title        = {Hesitant adaptive search with estimation and quantile adaptive search for global optimization with noise},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exchange rates and multicommodity international trade:
Insights from spatial price equilibrium modeling with policy instruments
via variational inequalities. <em>JGO</em>, <em>87</em>(1), 1–30. (<a
href="https://doi.org/10.1007/s10898-023-01292-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we construct a multicommodity international trade spatial price equilibrium model of special relevance to agriculture in which exchange rates are included along with policy instruments in the form of tariffs, subsidies as well as quotas. The model allows for multiple trade routes between country origin nodes and country destination nodes and these trade routes can include different modes of transportation and transport through distinct countries. We capture the impacts of exchange rates through the definition of effective path costs and identify the governing multicommodity international trade spatial price equilibrium conditions, which are then formulated as a variational inequality problem in product path flows. Existence results are established and a computational procedure presented. The illustrative numerical examples and a case study are inspired by the impacts of the war against Ukraine on agricultural trade flows and product prices. The modeling and algorithmic framework allows for the quantification of the impacts of exchange rates and various trade policies, as well as the addition or deletion of supply markets, demand markets and/or routes, on supply and demand market prices in local currencies, and on the volume of product trade flows with implications for food security.},
  archive      = {J_JGO},
  author       = {Nagurney, Anna and Hassani, Dana and Nivievskyi, Oleg and Martyshev, Pavlo},
  doi          = {10.1007/s10898-023-01292-x},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {1-30},
  shortjournal = {J. Glob. Optim.},
  title        = {Exchange rates and multicommodity international trade: Insights from spatial price equilibrium modeling with policy instruments via variational inequalities},
  volume       = {87},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finding global solutions of some inverse optimal control
problems using penalization and semismooth newton methods. <em>JGO</em>,
<em>86</em>(4), 1025–1061. (<a
href="https://doi.org/10.1007/s10898-023-01288-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a method to solve a special class of parameter identification problems for an elliptic optimal control problem to global optimality. The bilevel problem is reformulated via the optimal-value function of the lower-level problem. The reformulated problem is nonconvex and standard regularity conditions like Robinson’s CQ are violated. Via a relaxation of the constraints, the problem can be decomposed into a family of convex problems and this is the basis for a solution algorithm. The convergence properties are analyzed. It is shown that a penalty method can be employed to solve this family of problems while maintaining convergence speed. For an example problem, the use of the identity as penalty function allows for the solution by a semismooth Newton method. Numerical results are presented. Difficulties and limitations of our approach to solve a nonconvex problem to global optimality are discussed.},
  archive      = {J_JGO},
  author       = {Friedemann, Markus and Harder, Felix and Wachsmuth, Gerd},
  doi          = {10.1007/s10898-023-01288-7},
  journal      = {Journal of Global Optimization},
  number       = {4},
  pages        = {1025-1061},
  shortjournal = {J. Glob. Optim.},
  title        = {Finding global solutions of some inverse optimal control problems using penalization and semismooth newton methods},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Second-order characterization of convex mappings in banach
spaces and its applications. <em>JGO</em>, <em>86</em>(4), 1005–1023.
(<a href="https://doi.org/10.1007/s10898-023-01301-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that the positive semi-definiteness of the regular or limiting (Mordukhovich) second-order subdifferential of an approximately convex function is a sufficient condition for its convexity. As a consequence of our result, we obtain a second-order characterization for the class of lower- $$C^1$$ functions. Furthermore, we show by an example that positive semi-definiteness of the second-order subdifferential of convex functions is not a necessary condition for some cases. Also, a second-order characterization for C-convex mappings is obtained, and derive some applications in optimization.},
  archive      = {J_JGO},
  author       = {Nadi, Mohammad Taghi and Zafarani, Jafar},
  doi          = {10.1007/s10898-023-01301-z},
  journal      = {Journal of Global Optimization},
  number       = {4},
  pages        = {1005-1023},
  shortjournal = {J. Glob. Optim.},
  title        = {Second-order characterization of convex mappings in banach spaces and its applications},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Noncoercive and noncontinuous equilibrium problems:
Existence theorem in infinite-dimensional spaces. <em>JGO</em>,
<em>86</em>(4), 989–1003. (<a
href="https://doi.org/10.1007/s10898-023-01289-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we extend the definition of the qx-asymptotic functions, for an extended real-valued function defined on the infinite-dimensional topological normed spaces without lower semicontinuity or quasi-convexity condition. As the main result, by using some asymptotic conditions, we obtain sufficient optimality conditions for the existence of solutions to equilibrium problems, under weaker assumptions of continuity and convexity, when the feasible set is an unbounded subset of infinite-dimensional space. Also, as a corollary, we obtain necessary and sufficient optimality conditions for the existence of solutions to equilibrium problems with an unbounded feasible set. Finally, as an application, we establish a result for the existence of solutions to minimization problems.},
  archive      = {J_JGO},
  author       = {Fakhar, F. and Hajisharifi, H. R. and Soltani, Z.},
  doi          = {10.1007/s10898-023-01289-6},
  journal      = {Journal of Global Optimization},
  number       = {4},
  pages        = {989-1003},
  shortjournal = {J. Glob. Optim.},
  title        = {Noncoercive and noncontinuous equilibrium problems: Existence theorem in infinite-dimensional spaces},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Mixed polynomial variational inequalities. <em>JGO</em>,
<em>86</em>(4), 953–988. (<a
href="https://doi.org/10.1007/s10898-023-01298-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of this paper is to introduce a class of mixed polynomial variational inequalities, which is a natural generalization of the affine variational inequality and the tensor variational inequality, and a special case of the mixed variational inequality. It is shown that a class of polynomial optimization problem and a class of m-person noncooperative game can be reformulated as a mixed polynomial variational inequality. Firstly, some classes of structured tensor tuples are introduced and the relationship between them is discussed. Then, a new asymptotic function (denoted by m-asymptotic function) is introduced and some basic properties are investigated. An equivalent characterization for the nonexistence of solutions is given by using the exceptional family of elements. Finally, the nonemptiness and compactness of the solution sets of the mixed polynomial variational inequalities with some special structured tensors and m-asymptotic function are proved and then the uniqueness of the solution is further investigated.},
  archive      = {J_JGO},
  author       = {Shang, Tong-tong and Tang, Guo-ji},
  doi          = {10.1007/s10898-023-01298-5},
  journal      = {Journal of Global Optimization},
  number       = {4},
  pages        = {953-988},
  shortjournal = {J. Glob. Optim.},
  title        = {Mixed polynomial variational inequalities},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the study of multistage stochastic vector
quasi-variational problems. <em>JGO</em>, <em>86</em>(4), 931–952. (<a
href="https://doi.org/10.1007/s10898-023-01282-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the study of multistage stochastic vector generalized quasi-variational inequalities with a variable ordering structure. The proposed multistage stochastic vector quasi-variational problems are defined in a suitable functional setting relative to a finite set of final possible states and certain information fields; these formulations are a multicriteria extension of the multistage stochastic variational inequalities. A relevant aspect of these problems is the presence of the nonanticipativity constraints on the variables of the problem; stage by stage, these constraints impose the measurability with respect to the information field at that stage. Without requiring any assumption of monotonicity, we prove some existence results by using a nonlinear scalarization technique. On this basis, we analyze multistage stochastic vector Nash equilibrium problems: as an example, we focus on a suitable multistage stochastic bicriteria Cournot oligopolistic model.},
  archive      = {J_JGO},
  author       = {Molho, Elena and Scopelliti, Domenico},
  doi          = {10.1007/s10898-023-01282-z},
  journal      = {Journal of Global Optimization},
  number       = {4},
  pages        = {931-952},
  shortjournal = {J. Glob. Optim.},
  title        = {On the study of multistage stochastic vector quasi-variational problems},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new scheme for approximating the weakly efficient solution
set of vector rational optimization problems. <em>JGO</em>,
<em>86</em>(4), 905–930. (<a
href="https://doi.org/10.1007/s10898-023-01287-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we provide a new scheme for approximating the weakly efficient solution set for a class of vector optimization problems with rational objectives over a feasible set defined by finitely many polynomial inequalities. More precisely, we present a procedure to obtain a sequence of explicit approximations of the weakly efficient solution set of the problem in question. Each approximation is the intersection of the sublevel set of a single polynomial and the feasible set. To this end, we make use of the achievement function associated with the considered problem and construct polynomial approximations of it over the feasible set from above. Remarkably, the construction can be converted to semidefinite programming problems. Several nontrivial examples are designed to illustrate the proposed new scheme.},
  archive      = {J_JGO},
  author       = {Guo, Feng and Jiao, Liguo},
  doi          = {10.1007/s10898-023-01287-8},
  journal      = {Journal of Global Optimization},
  number       = {4},
  pages        = {905-930},
  shortjournal = {J. Glob. Optim.},
  title        = {A new scheme for approximating the weakly efficient solution set of vector rational optimization problems},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An average-compress algorithm for the sample mean problem
under dynamic time warping. <em>JGO</em>, <em>86</em>(4), 885–903. (<a
href="https://doi.org/10.1007/s10898-023-01294-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computing a sample mean of time series under dynamic time warping is NP-hard. Consequently, there is an ongoing research effort to devise efficient heuristics. The majority of heuristics have been developed for the constrained sample mean problem that assumes a solution of predefined length. In contrast, research on the unconstrained sample mean problem is underdeveloped. In this article, we propose a generic average-compress (AC) algorithm to address the unconstrained problem. The algorithm alternates between averaging (A-step) and compression (C-step). The A-step takes an initial guess as input and returns an approximation of a sample mean. Then the C-step reduces the length of the approximate solution. The compressed approximation serves as initial guess of the A-step in the next iteration. The purpose of the C-step is to direct the algorithm to more promising solutions of shorter length. The proposed algorithm is generic in the sense that any averaging and any compression method can be used. Experimental results show that the AC algorithm substantially outperforms current state-of-the-art algorithms for time series averaging.},
  archive      = {J_JGO},
  author       = {Jain, Brijnesh and Froese, Vincent and Schultz, David},
  doi          = {10.1007/s10898-023-01294-9},
  journal      = {Journal of Global Optimization},
  number       = {4},
  pages        = {885-903},
  shortjournal = {J. Glob. Optim.},
  title        = {An average-compress algorithm for the sample mean problem under dynamic time warping},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Structured tensor tuples to polynomial complementarity
problems. <em>JGO</em>, <em>86</em>(4), 867–883. (<a
href="https://doi.org/10.1007/s10898-023-01302-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well known that structured tensors play an important role in the investigation of tensor complementarity problems. The polynomial complementarity problem is a natural generalization of the tensor complementarity problem. Similar to the investigation of tensor complementarity problems, it is believed that structured tensor tuples will play an important role in the investigation of polynomial complementarity problems. In the present paper, several classes of structured tensor tuples are introduced and the relationships between them are discussed. By using the structured tensor(s) (tuples), the uniqueness of the solution and the global upper bound of the solution set of the polynomial complementarity problem are investigated. The results presented in the present paper generalize the corresponding those in the recent literature.},
  archive      = {J_JGO},
  author       = {Shang, Tong-tong and Tang, Guo-ji},
  doi          = {10.1007/s10898-023-01302-y},
  journal      = {Journal of Global Optimization},
  number       = {4},
  pages        = {867-883},
  shortjournal = {J. Glob. Optim.},
  title        = {Structured tensor tuples to polynomial complementarity problems},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semistrictly and neatly quasiconvex programming using lower
global subdifferentials. <em>JGO</em>, <em>86</em>(4), 845–865. (<a
href="https://doi.org/10.1007/s10898-023-01278-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main goal of this paper is to investigate the properties and connections of neatly and semistrictly quasiconvex functions, especially when they appear in constrained and unconstrained optimization problems. The lower global subdifferential, recently introduced in the literature, plays an essential role in this study. We present several optimality conditions for constrained and unconstrained nonsmooth neatly/semistrictly quasiconvex optimization problems in terms of lower global subdifferentials. To this end, for a constrained optimization problem, we present some characterizations for the normal and tangent cones and the cone of feasible directions of the feasible set. Some relationships between the Greenberg–Pierskalla, tangentially and lower global subdifferentials of neatly and semistrictly quasiconvex functions are also given. The mentioned relationships show that the outcomes of this paper generalize some results existing in the literature.},
  archive      = {J_JGO},
  author       = {Kabgani, A. and Lara, F.},
  doi          = {10.1007/s10898-023-01278-9},
  journal      = {Journal of Global Optimization},
  number       = {4},
  pages        = {845-865},
  shortjournal = {J. Glob. Optim.},
  title        = {Semistrictly and neatly quasiconvex programming using lower global subdifferentials},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An extrapolated proximal iteratively reweighted method for
nonconvex composite optimization problems. <em>JGO</em>, <em>86</em>(4),
821–844. (<a href="https://doi.org/10.1007/s10898-023-01299-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a class of problems where the objective function is the sum of a smooth function and a composition of nonconvex and nonsmooth functions. Such optimization problems arise frequently in machine learning and data processing. The proximal iteratively reweighted method has been widely used and popularized in solving these problems. In this paper, we develop an extrapolated proximal iteratively reweighted method that incorporates two different flexible inertial steps at each iteration. We first prove the subsequential convergence of the proposed method under parameter constraints. Moreover, if the objective function satisfies the Kurdyka-Łojasiewicz property, the global convergence of the new method is established. In addition, we analyze the local convergence rate by making assumptions on the Kurdyka-Łojasiewicz exponent of the objective function. Finally, numerical results on $$l_p$$ minimization and feature selection problems are reported to show the effectiveness and superiority of the proposed algorithm.},
  archive      = {J_JGO},
  author       = {Ge, Zhili and Wu, Zhongming and Zhang, Xin and Ni, Qin},
  doi          = {10.1007/s10898-023-01299-4},
  journal      = {Journal of Global Optimization},
  number       = {4},
  pages        = {821-844},
  shortjournal = {J. Glob. Optim.},
  title        = {An extrapolated proximal iteratively reweighted method for nonconvex composite optimization problems},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The interpolating element-free galerkin method for the
p-laplace double obstacle mixed complementarity problem. <em>JGO</em>,
<em>86</em>(3), 781–820. (<a
href="https://doi.org/10.1007/s10898-022-01260-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the interpolating element-free Galerkin method is presented for the p-Laplace double obstacle mixed complementarity problem when $$12$$ . First, a nonlinear power penalty equation is obtained by a power penalty approximation method and the existence and uniqueness of the solution to the power penalty equation are proved when $$12$$ . The convergence of the power penalty solution to the original problem and the penalty estimates are analyzed. Second, the interpolating element-free Galerkin method is constructed for the nonlinear power penalty equation. The numerical implementation is introduced in detail and the convergence of the interpolating element-free Galerkin method is also given. Error estimates indicate that the convergence order depends on not only the spatial step h and the number of bases functions m in the interpolating element-free Galerkin method, but also the index k in the penalty term, the penalty factor $$\lambda $$ and p. For different p, the method that how to choose the optimal k and $$\lambda $$ is also given. Numerical examples verify error estimates and illustrate the influence of each parameter on the solution.},
  archive      = {J_JGO},
  author       = {Ding, Rui and Ding, Chaoren and Shen, Quan},
  doi          = {10.1007/s10898-022-01260-x},
  journal      = {Journal of Global Optimization},
  number       = {3},
  pages        = {781-820},
  shortjournal = {J. Glob. Optim.},
  title        = {The interpolating element-free galerkin method for the p-laplace double obstacle mixed complementarity problem},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A three-stage stochastic optimization model integrating 5G
technology and UAVs for disaster management. <em>JGO</em>,
<em>86</em>(3), 741–780. (<a
href="https://doi.org/10.1007/s10898-023-01274-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop a three-stage stochastic network-based optimization model for the provision of 5G services with Unmanned Aerial Vehicles (UAVs) in the disaster management phases of: preparedness, response and recover/reconstruction. Users or devices on the ground request services of a fleet of controller UAVs in flight and the requested services are executed by a fleet of UAVs organized as a Flying Ad-Hoc Network and interconnected via 5G technology. A disaster scenario can create difficulties for the provision of services by service providers. For this reason, in the first stage, service providers make predictions about possible scenarios in the second stage. Therefore, the first stage represents the preparedness phase, the second stage represents the response phase, followed by the recovery/reconstruction phase, represented by the third stage. In each of the three stages, service providers seek to maximize the amount of services to be performed, assigning each service a priority. They also aim to, simultaneously, minimize the total management costs of requests, the transmission and execution costs of services, the costs to increase the resources of the pre-existing network and, if need be, to reduce them in the recovery/reconstruction phase. For the proposed multi-stage stochastic optimization model, we provide variational formulations for which we investigate the existence and uniqueness of the solution. Finally, a detailed numerical example is solved in order underline some of the key aspects of the model. This paper adds to the literature on the rigorous mathematical modeling of advanced technologies for disaster management.},
  archive      = {J_JGO},
  author       = {Colajanni, Gabriella and Daniele, Patrizia and Nagurney, Anna and Nagurney, Ladimer S. and Sciacca, Daniele},
  doi          = {10.1007/s10898-023-01274-z},
  journal      = {Journal of Global Optimization},
  number       = {3},
  pages        = {741-780},
  shortjournal = {J. Glob. Optim.},
  title        = {A three-stage stochastic optimization model integrating 5G technology and UAVs for disaster management},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A robust investment-consumption optimization problem in a
switching regime interest rate setting. <em>JGO</em>, <em>86</em>(3),
713–739. (<a href="https://doi.org/10.1007/s10898-023-01273-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we are dealing with a robust investment-consumption optimization problem in an incomplete market with a switching regime stochastic interest rate. Our methodology combines duality approach with stochastic control techniques (applied to the dual problem) specific to a non-Markovian setting, such as dynamic programming principle (initiated in Karoui and Quenez (SIAM J Control Optim 33(1):29–66, 1995)) and Backward Stochastic Differential Equations (BSDEs) theory. An auxiliary dual problem is established by means of infinite-dimensional convex duality. We derive explicit formulas for the optimal trading strategy and consumption rate in terms of the solution of some nonstandard BSDE with jumps. Links to other significant results in the domain are also provided.},
  archive      = {J_JGO},
  author       = {Iftimie, Bogdan},
  doi          = {10.1007/s10898-023-01273-0},
  journal      = {Journal of Global Optimization},
  number       = {3},
  pages        = {713-739},
  shortjournal = {J. Glob. Optim.},
  title        = {A robust investment-consumption optimization problem in a switching regime interest rate setting},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A robust multi-objective bayesian optimization framework
considering input uncertainty. <em>JGO</em>, <em>86</em>(3), 693–711.
(<a href="https://doi.org/10.1007/s10898-022-01262-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian optimization is a popular tool for optimizing time-consuming objective functions with a limited number of function evaluations. In real-life applications like engineering design, the designer often wants to take multiple objectives as well as input uncertainty into account to find a set of robust solutions. While this is an active topic in single-objective Bayesian optimization, it is less investigated in the multi-objective case. We introduce a novel Bayesian optimization framework to perform multi-objective optimization considering input uncertainty. We propose a robust Gaussian Process model to infer the Bayes risk criterion to quantify robustness, and we develop a two-stage Bayesian optimization process to search for a robust Pareto frontier, i.e., solutions that have good average performance under input uncertainty. The complete framework supports various distributions of the input uncertainty and takes full advantage of parallel computing. We demonstrate the effectiveness of the framework through numerical benchmarks.},
  archive      = {J_JGO},
  author       = {Qing, Jixiang and Couckuyt, Ivo and Dhaene, Tom},
  doi          = {10.1007/s10898-022-01262-9},
  journal      = {Journal of Global Optimization},
  number       = {3},
  pages        = {693-711},
  shortjournal = {J. Glob. Optim.},
  title        = {A robust multi-objective bayesian optimization framework considering input uncertainty},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exact SDP relaxations for quadratic programs with bipartite
graph structures. <em>JGO</em>, <em>86</em>(3), 671–691. (<a
href="https://doi.org/10.1007/s10898-022-01268-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For nonconvex quadratically constrained quadratic programs (QCQPs), we first show that, under certain feasibility conditions, the standard semidefinite programming (SDP) relaxation is exact for QCQPs with bipartite graph structures. The exact optimal solutions are obtained by examining the dual SDP relaxation and the rank of the optimal solution of this dual SDP relaxation under strong duality. Our results generalize the previous results on QCQPs with sign-definite bipartite graph structures, QCQPs with forest structures, and QCQPs with nonpositive off-diagonal data elements. Second, we propose a conversion method from QCQPs with no particular structure to the ones with bipartite graph structures. As a result, we demonstrate that a wider class of QCQPs can be exactly solved by the SDP relaxation. Numerical instances are presented for illustration.},
  archive      = {J_JGO},
  author       = {Azuma, Godai and Fukuda, Mituhiro and Kim, Sunyoung and Yamashita, Makoto},
  doi          = {10.1007/s10898-022-01268-3},
  journal      = {Journal of Global Optimization},
  number       = {3},
  pages        = {671-691},
  shortjournal = {J. Glob. Optim.},
  title        = {Exact SDP relaxations for quadratic programs with bipartite graph structures},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed primal outer approximation algorithm for sparse
convex programming with separable structures. <em>JGO</em>,
<em>86</em>(3), 637–670. (<a
href="https://doi.org/10.1007/s10898-022-01266-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the distributed primal outer approximation (DiPOA) algorithm for solving sparse convex programming (SCP) problems with separable structures, efficiently, and in a decentralized manner. The DiPOA algorithm development consists of embedding the recently proposed relaxed hybrid alternating direction method of multipliers (RH-ADMM) algorithm into the outer approximation (OA) algorithm. We also propose two main improvements to control the quality and the number of cutting planes that approximate nonlinear functions. In particular, the RH-ADMM algorithm acts as a distributed numerical engine inside the DiPOA algorithm. DiPOA takes advantage of the multi-core architecture of modern processors to speed up optimization algorithms. The proposed distributed algorithm makes practical the solution of SCP in learning and control problems from the application side. This paper concludes with a performance analysis of DiPOA for the distributed sparse logistic regression and quadratically constrained optimization problems. Finally, the paper concludes with a numerical comparison with state-of-the-art optimization solvers.},
  archive      = {J_JGO},
  author       = {Olama, Alireza and Camponogara, Eduardo and Mendes, Paulo R. C.},
  doi          = {10.1007/s10898-022-01266-5},
  journal      = {Journal of Global Optimization},
  number       = {3},
  pages        = {637-670},
  shortjournal = {J. Glob. Optim.},
  title        = {Distributed primal outer approximation algorithm for sparse convex programming with separable structures},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Approximate douglas–rachford algorithm for two-sets convex
feasibility problems. <em>JGO</em>, <em>86</em>(3), 621–636. (<a
href="https://doi.org/10.1007/s10898-022-01264-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new algorithm combining the Douglas–Rachford (DR) algorithm and the Frank–Wolfe algorithm, also known as the conditional gradient (CondG) method, for solving the classic convex feasibility problem. Within the algorithm, which will be named Approximate Douglas–Rachford (ApDR) algorithm, the CondG method is used as a subroutine to compute feasible inexact projections on the sets under consideration, and the ApDR iteration is defined based on the DR iteration. The ApDR algorithm generates two sequences, the main sequence, based on the DR iteration, and its corresponding shadow sequence. When the intersection of the feasible sets is nonempty, the main sequence converges to a fixed point of the usual DR operator, and the shadow sequence converges to the solution set. We provide some numerical experiments to illustrate the behaviour of the sequences produced by the proposed algorithm.},
  archive      = {J_JGO},
  author       = {Díaz Millán, R. and Ferreira, O. P. and Ugon, J.},
  doi          = {10.1007/s10898-022-01264-7},
  journal      = {Journal of Global Optimization},
  number       = {3},
  pages        = {621-636},
  shortjournal = {J. Glob. Optim.},
  title        = {Approximate Douglas–Rachford algorithm for two-sets convex feasibility problems},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A proximal bundle method for a class of nonconvex nonsmooth
composite optimization problems. <em>JGO</em>, <em>86</em>(3), 589–620.
(<a href="https://doi.org/10.1007/s10898-023-01279-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a proximal bundle method is proposed for a class of nonconvex nonsmooth composite optimization problems. The composite problem considered here is the sum of two functions: one is convex and the other is nonconvex. Local convexification strategy is adopted for the nonconvex function and the corresponding convexification parameter varies along iterations. Then the sum of the convex function and the extended function is dynamically constructed to approximate the primal problem. To choose a suitable cutting plane model for the approximation function, here we consider the sum of two cutting planes, which are designed respectively for the convex function and the extended function. By choosing appropriate descent condition, our method can keep track of the relationship between primal problem and approximate models. Under mild conditions, the convergence is proved and the accumulation point of iterations is a stationary point of the primal problem. Two polynomial problems and twelve DC (difference of convex) problems are referred in numerical experiments. The preliminary numerical results show that the proposed method is effective for solving these testing problems.},
  archive      = {J_JGO},
  author       = {Pang, Liping and Wang, Xiaoliang and Meng, Fanyun},
  doi          = {10.1007/s10898-023-01279-8},
  journal      = {Journal of Global Optimization},
  number       = {3},
  pages        = {589-620},
  shortjournal = {J. Glob. Optim.},
  title        = {A proximal bundle method for a class of nonconvex nonsmooth composite optimization problems},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Subdomain separability in global optimization. <em>JGO</em>,
<em>86</em>(3), 573–588. (<a
href="https://doi.org/10.1007/s10898-022-01265-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a generalization of separability for global optimization, presented in the context of a simple branch and bound method. Our results apply to continuously differentiable objective functions implemented as computer programs. A significant search space reduction can be expected to yield an acceleration of any global optimization method. We show how to utilize interval derivatives calculated by adjoint algorithmic differentiation to examine the monotonicity of the objective with respect to so called structural separators and how to verify the latter automatically.},
  archive      = {J_JGO},
  author       = {Deussen, Jens and Naumann, Uwe},
  doi          = {10.1007/s10898-022-01265-6},
  journal      = {Journal of Global Optimization},
  number       = {3},
  pages        = {573-588},
  shortjournal = {J. Glob. Optim.},
  title        = {Subdomain separability in global optimization},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). General convex relaxations of implicit functions and inverse
functions. <em>JGO</em>, <em>86</em>(3), 545–572. (<a
href="https://doi.org/10.1007/s10898-023-01281-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convex relaxations of nonconvex functions provide useful bounding information in applications such as deterministic global optimization and reachability analysis. In some situations, the original nonconvex functions may not be known explicitly, but are instead described implicitly by nonlinear equation systems. In these cases, established convex relaxation methods for closed-form functions are not directly applicable. This article presents a new general strategy to construct convex relaxations for such implicit functions. These relaxations are described as convex parametric programs whose constraints are convex relaxations of the original residual function. This relaxation strategy is straightforward to implement, produces tight relaxations in practice, is particularly efficient to carry out when monotonicity properties can be exploited, and does not assume the existence or uniqueness of an implicit function on the entire intended domain. Unlike all previous approaches to the authors’ knowledge, this new approach permits any relaxations of the residual function; it does not require the residual relaxations to be factorable or to be obtained from a McCormick-like traversal of a computational graph. This new convex relaxation strategy is extended to inverse functions, compositions involving implicit functions, feasible-set mappings in constraint satisfaction problems, and solutions of parametric ODEs. Based on a proof-of-concept implementation in Julia, numerical examples are presented to illustrate the convex relaxations produced for various implicit functions and optimal-value functions.},
  archive      = {J_JGO},
  author       = {Cao, Huiyi and Khan, Kamil A.},
  doi          = {10.1007/s10898-023-01281-0},
  journal      = {Journal of Global Optimization},
  number       = {3},
  pages        = {545-572},
  shortjournal = {J. Glob. Optim.},
  title        = {General convex relaxations of implicit functions and inverse functions},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A linear programming approach to approximating the infinite
time reachable set of strictly stable linear control systems.
<em>JGO</em>, <em>86</em>(2), 521–543. (<a
href="https://doi.org/10.1007/s10898-022-01261-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The infinite time reachable set of a strictly stable linear control system is the Hausdorff limit of the finite time reachable set of the origin as time tends to infinity. By definition, it encodes useful information on the long-term behavior of the control system. Its characterization as a limit set gives rise to numerical methods for its computation that are based on forward iteration of approximate finite time reachable sets. These methods tend to be computationally expensive, because they essentially perform a Minkowski sum in every single forward step. We develop a new approach to computing the infinite time reachable set that is based on the invariance properties of the control system and the desired set. These allow us to characterize a polyhedral outer approximation as the unique solution to a linear program with constraints that incorporate the system dynamics. In particular, this approach does not rely on forward iteration of finite time reachable sets.},
  archive      = {J_JGO},
  author       = {Ernst, Andreas and Grüne, Lars and Rieger, Janosch},
  doi          = {10.1007/s10898-022-01261-w},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {521-543},
  shortjournal = {J. Glob. Optim.},
  title        = {A linear programming approach to approximating the infinite time reachable set of strictly stable linear control systems},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fixed point iterative method for tensor complementarity
problems with the implicit z-tensors. <em>JGO</em>, <em>86</em>(2),
495–520. (<a href="https://doi.org/10.1007/s10898-022-01263-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider solving the tensor complementarity problem (TCP). We first introduce the concept of the implicit Z-tensor, which is a generalization of Z-tensor. Then, based on a new fixed point reformulation of the TCP, we design an iterative algorithm for solving the TCP with an implicit Z-tensor under the assumption that the feasible set of the problem involved is nonempty. We prove that the proposed fixed point iterative method converges monotonically downward to a solution of the TCP. Furthermore, we establish the global linear rate of convergence of the proposed method under some reasonable assumptions. Compared with the existing related studies, the proposed method not only solves a wider range of TCPs, but also has a lower computational cost. The numerical results verify our theoretical findings.},
  archive      = {J_JGO},
  author       = {Huang, Zheng-Hai and Li, Yu-Fan and Wang, Yong},
  doi          = {10.1007/s10898-022-01263-8},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {495-520},
  shortjournal = {J. Glob. Optim.},
  title        = {A fixed point iterative method for tensor complementarity problems with the implicit Z-tensors},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel graph-theoretical clustering approach to find a
reduced set with extreme solutions of pareto optimal solutions for
multi-objective optimization problems. <em>JGO</em>, <em>86</em>(2),
467–494. (<a href="https://doi.org/10.1007/s10898-023-01275-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective optimization problems and their solution algorithms are of great importance as single-objective optimization problems are not usually a true representation of many real-world problems. In general, multi-objective optimization problems result in a large set of Pareto optimal solutions. Each solution in this set is optimal with some trade-offs. Therefore, it is difficult for the decision-maker to select a solution, especially in the absence of subjective or judgmental information. Moreover, an analysis of all the solutions is computationally expensive and, hence, not practical. Thus, researchers have proposed several techniques such as clustering and ranking of Pareto optimal solutions to reduce the number of solutions. The ranking methods are often used to obtain a single solution, which is not a good representation of the entire Pareto set. This paper deviates from the common approach and proposes a novel graph-theoretical clustering method. The quality of the clustering based on the Silhouette score is used to determine the number of clusters. The connectivity in the objective space is used to find representative solutions for clusters. One step forward, we identify ‘extreme solutions’. Hence, the reduced set contains both extreme solutions and representative solutions. We demonstrate the performance of the proposed method by using different 3D and 8D benchmark Pareto fronts as well as Pareto fronts from a case study in Royal Australian Navy. Results revealed that the reduced set obtained from the proposed method outperforms that from the K-means clustering, which is the most popular traditional clustering approach in Pareto pruning.},
  archive      = {J_JGO},
  author       = {Kahagalage, Sanath and Turan, Hasan Hüseyin and Jalalvand, Fatemeh and El Sawah, Sondoss},
  doi          = {10.1007/s10898-023-01275-y},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {467-494},
  shortjournal = {J. Glob. Optim.},
  title        = {A novel graph-theoretical clustering approach to find a reduced set with extreme solutions of pareto optimal solutions for multi-objective optimization problems},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Faster distance-based representative skyline and k-center
along pareto front in the plane. <em>JGO</em>, <em>86</em>(2), 441–466.
(<a href="https://doi.org/10.1007/s10898-023-01280-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of computing the distance-based representative skyline in the plane, a problem introduced by Tao, Ding, Lin and Pei [Proc. 25th IEEE International Conference on Data Engineering (ICDE), 2009] and independently considered by Dupin, Nielsen and Talbi [Mathematics; Optimization and Learning - Third International Conference, OLA 2020] in the context of multi-objective optimization. Given a set P of n points in the plane and a parameter k, the task is to select k points of the skyline defined by P (also known as Pareto front for P) to minimize the maximum distance from the points of the skyline to the selected points. We show that the problem can be solved in $$O(n\log h)$$ time, where h is the number of points in the skyline of P. We also show that the decision problem can be solved in $$O(n\log k)$$ time and the optimization problem can be solved in $$O(n \log k + n {{\,\textrm{loglog}\,}}n)$$ time. This improves previous algorithms and is optimal for a large range of values of k.},
  archive      = {J_JGO},
  author       = {Cabello, Sergio},
  doi          = {10.1007/s10898-023-01280-1},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {441-466},
  shortjournal = {J. Glob. Optim.},
  title        = {Faster distance-based representative skyline and k-center along pareto front in the plane},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analysis of the weighted tchebycheff weight set
decomposition for multiobjective discrete optimization problems.
<em>JGO</em>, <em>86</em>(2), 417–440. (<a
href="https://doi.org/10.1007/s10898-023-01284-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scalarization is a common technique to transform a multiobjective optimization problem into a scalar-valued optimization problem. This article deals with the weighted Tchebycheff scalarization applied to multiobjective discrete optimization problems. This scalarization consists of minimizing the weighted maximum distance of the image of a feasible solution to some desirable reference point. By choosing a suitable weight, any Pareto optimal image can be obtained. In this article, we provide a comprehensive theory of this set of eligible weights. In particular, we analyze the polyhedral and combinatorial structure of the set of all weights yielding the same Pareto optimal solution as well as the decomposition of the weight set as a whole. The structural insights are linked to properties of the set of Pareto optimal solutions, thus providing a profound understanding of the weighted Tchebycheff scalarization method and, as a consequence, also of all methods for multiobjective optimization problems using this scalarization as a building block.},
  archive      = {J_JGO},
  author       = {Helfrich, Stephan and Perini, Tyler and Halffmann, Pascal and Boland, Natashia and Ruzika, Stefan},
  doi          = {10.1007/s10898-023-01284-x},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {417-440},
  shortjournal = {J. Glob. Optim.},
  title        = {Analysis of the weighted tchebycheff weight set decomposition for multiobjective discrete optimization problems},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Approximating biobjective minimization problems using
general ordering cones. <em>JGO</em>, <em>86</em>(2), 393–415. (<a
href="https://doi.org/10.1007/s10898-023-01276-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the approximation quality achievable for biobjective minimization problems with respect to the Pareto cone by solutions that are (approximately) optimal with respect to larger ordering cones. When simultaneously considering $$\alpha $$ -approximations for all closed convex ordering cones of a fixed inner angle $$\gamma \in \left[ \frac{\pi }{2}, \pi \right] $$ , an approximation guarantee between $$\alpha $$ and $$2 \alpha $$ is achieved, which depends continuously on $$\gamma $$ . The analysis is best-possible for any inner angle and it generalizes and unifies the known results that the set of supported solutions is a 2-approximation and that the efficient set itself is a 1-approximation. Moreover, it is shown that, for maximization problems, no approximation guarantee is achievable in general by considering larger ordering cones in the described fashion, which again generalizes a known result about the set of supported solutions.},
  archive      = {J_JGO},
  author       = {Herzel, Arne and Helfrich, Stephan and Ruzika, Stefan and Thielen, Clemens},
  doi          = {10.1007/s10898-023-01276-x},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {393-415},
  shortjournal = {J. Glob. Optim.},
  title        = {Approximating biobjective minimization problems using general ordering cones},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient enumeration of the optimal solutions to the
correlation clustering problem. <em>JGO</em>, <em>86</em>(2), 355–391.
(<a href="https://doi.org/10.1007/s10898-023-01270-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to the structural balance theory, a signed graph is considered structurally balanced when it can be partitioned into a number of modules such that positive and negative edges are respectively located inside and between the modules. In practice, real-world networks are rarely structurally balanced, though. In this case, one may want to measure the magnitude of their imbalance, and to identify the set of edges causing this imbalance. The correlation clustering (CC) problem precisely consists in looking for the signed graph partition having the least imbalance. Recently, it has been shown that the space of the optimal solutions of the CC problem can be constituted of numerous and diverse optimal solutions. Yet, this space is difficult to explore, as the CC problem is NP-hard, and exact approaches do not scale well even when looking for a single optimal solution. To alleviate this issue, in this work we propose an efficient enumeration method allowing to retrieve the complete space of optimal solutions of the CC problem. It combines an exhaustive enumeration strategy with neighborhoods of varying sizes, to achieve computational effectiveness. Results obtained for middle-sized networks confirm the usefulness of our method.},
  archive      = {J_JGO},
  author       = {Arınık, Nejat and Figueiredo, Rosa and Labatut, Vincent},
  doi          = {10.1007/s10898-023-01270-3},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {355-391},
  shortjournal = {J. Glob. Optim.},
  title        = {Efficient enumeration of the optimal solutions to the correlation clustering problem},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A non-convex piecewise quadratic approximation of <span
class="math display"><em>ℓ</em><sub>0</sub></span> regularization:
Theory and accelerated algorithm. <em>JGO</em>, <em>86</em>(2), 323–353.
(<a href="https://doi.org/10.1007/s10898-022-01257-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-convex regularization has been recognized as an especially important approach in recent studies to promote sparsity. In this paper, we study the non-convex piecewise quadratic approximation (PQA) regularization for sparse solutions of the linear inverse problem. It is shown that exact recovery of sparse signals and stable recovery of compressible signals are possible through local optimum of this regularization. After developing a thresholding representation theory for PQA regularization, we propose an iterative PQA thresholding algorithm (PQA algorithm) to solve this problem. The PQA algorithm converges to a local minimizer of the regularization, with an eventually linear convergence rate. Furthermore, we adopt the idea of accelerated gradient method to design the accelerated iterative PQA thresholding algorithm (APQA algorithm), which is also linearly convergent, but with a faster convergence rate. Finally, we carry out a series of numerical experiments to assess the performance of both algorithms for PQA regularization. The results show that PQA regularization outperforms $$\ell _1$$ and $$\ell _{1/2}$$ regularizations in terms of accuracy and sparsity, while the APQA algorithm is demonstrated to be significantly better than the PQA algorithm.},
  archive      = {J_JGO},
  author       = {Li, Qian and Zhang, Wei and Bai, Yanqin and Wang, Guoqiang},
  doi          = {10.1007/s10898-022-01257-6},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {323-353},
  shortjournal = {J. Glob. Optim.},
  title        = {A non-convex piecewise quadratic approximation of $$\ell _{0}$$ regularization: Theory and accelerated algorithm},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Globally minimizing a class of linear multiplicative forms
via simplicial branch-and-bound. <em>JGO</em>, <em>86</em>(2), 303–321.
(<a href="https://doi.org/10.1007/s10898-023-01277-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider in this paper a class of linear multiplicative programming problems that arise from numerous applications such as network flows and financial optimization. The problem is first transformed into an equivalent nonlinear optimization problem to provide a novel convex quadratic relaxation. A simplicial branch-and-bound algorithm is then designed to globally solve the problem, based on the proposed relaxation and simplicial branching process. The convergence and computational complexity of the algorithm are also analyzed. The results of numerical experiments confirm the efficiency of the proposed algorithm for tested instances.},
  archive      = {J_JGO},
  author       = {Shen, Peiping and Wu, Dianxiao and Wang, Kaimin},
  doi          = {10.1007/s10898-023-01277-w},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {303-321},
  shortjournal = {J. Glob. Optim.},
  title        = {Globally minimizing a class of linear multiplicative forms via simplicial branch-and-bound},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). KKT-based primal-dual exactness conditions for the shor
relaxation. <em>JGO</em>, <em>86</em>(2), 285–301. (<a
href="https://doi.org/10.1007/s10898-022-01258-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we present some exactness conditions for the Shor relaxation of diagonal (or, more generally, diagonalizable) QCQPs, which extend the conditions introduced in different recent papers about the same topic. It is shown that the Shor relaxation is equivalent to two convex quadratic relaxations. Then, sufficient conditions for the exactness of the relaxations are derived from their KKT systems. It will be shown that, in some cases, by this derivation previous conditions in the literature, which can be viewed as dual conditions, since they only involve the Lagrange multipliers appearing in the KKT systems, can be extended to primal-dual conditions, which also involve the primal variables appearing in the KKT systems.},
  archive      = {J_JGO},
  author       = {Locatelli, M.},
  doi          = {10.1007/s10898-022-01258-5},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {285-301},
  shortjournal = {J. Glob. Optim.},
  title        = {KKT-based primal-dual exactness conditions for the shor relaxation},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The restricted inverse optimal value problem on shortest
path under <span class="math display"><em>l</em><sub>1</sub></span> norm
on trees. <em>JGO</em>, <em>86</em>(1), 251–284. (<a
href="https://doi.org/10.1007/s10898-022-01256-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the restricted inverse optimal value problem on shortest path under weighted $$l_1$$ norm on trees (RIOVSPT $$\varvec{_1}$$ ). It aims at adjusting some edge weights to minimize the total cost under weighted $$l_1$$ norm on the premise that the length of the shortest root-leaf path of the tree is lower-bounded by a given value D, which is just the restriction on the length of a given root-leaf path $$P_0$$ . If we ignore the restriction on the path $$P_0$$ , then we obtain the minimum cost shortest path interdiction problem on trees (MCSPIT $$\varvec{_1}$$ ). We analyze some properties of the problem (RIOVSPT $$\varvec{_1}$$ ) and explore the relationship of the optimal solutions between (MCSPIT $$\varvec{_1}$$ ) and (RIOVSPT $$\varvec{_1}$$ ). We first take the optimal solution of the problem (MCSPIT $$\varvec{_1}$$ ) as an initial infeasible solution of problem (RIOVSPT $$\varvec{_1}$$ ). Then we consider a slack problem $${\textbf {(}} {{\textbf {RIOVSPT}}}\varvec{_1^s)}$$ , where the length of the path $$P_0$$ is greater than D. We obtain its feasible solutions gradually approaching to an optimal solution of the problem (RIOVSPT $$\varvec{_1}$$ ) by solving a series of subproblems $${{\textbf {(RIOVSPT}}}\varvec{_1^i)}$$ . It aims at determining the only weight-decreasing edge on the path $$P_0$$ with the minimum cost so that the length of the shortest root-leaf path is no less than D. The subproblem can be solved by searching for a minimum cost cut in O(n) time. The iterations continue until the length of the path $$P_0$$ equals D. Consequently, the time complexity of the algorithm is $$O(n^2)$$ and we present some numerical experiments to show the efficiency of the algorithm. Additionally, we devise a linear time algorithm for the problem (RIOVSPT $$\varvec{_{u1}}$$ ) under unit $$l_1$$ norm.},
  archive      = {J_JGO},
  author       = {Zhang, Qiao and Guan, Xiucui and Jia, Junhua and Qian, Xinqiang and Pardalos, Panos M.},
  doi          = {10.1007/s10898-022-01256-7},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {251-284},
  shortjournal = {J. Glob. Optim.},
  title        = {The restricted inverse optimal value problem on shortest path under $$l_1$$ norm on trees},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lifting for the integer knapsack cover polyhedron.
<em>JGO</em>, <em>86</em>(1), 205–249. (<a
href="https://doi.org/10.1007/s10898-022-01252-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the integer knapsack cover polyhedron which is the convex hull of the set consisting of n-dimensional nonnegative integer vectors that satisfy one linear constraint. We study the sequentially lifted (SL) inequality, derived by the sequential lifting from a seed inequality containing a single variable, and provide bounds on the lifting coefficients, which is useful in solving the separation problem of the SL inequalities. The proposed SL inequality is shown to dominate the well-known mixed integer rounding (MIR) inequality under certain conditions. We show that the problem of computing the coefficients for an SL inequality is $$\mathcal{N}\mathcal{P}$$ -hard but can be solved by a pseudo-polynomial time algorithm. As a by-product of analysis, we provide new conditions to guarantee the MIR inequality to be facet-defining for the considered polyhedron and prove that in general, the problem of deciding whether an MIR inequality defines a facet is $$\mathcal{N}\mathcal{P}$$ -complete. Finally, we perform numerical experiments to evaluate the performance and impact of using the proposed SL inequalities as cutting planes in solving mixed integer linear programming problems. Numerical results demonstrate that the proposed SL cuts are much more effective than the MIR cuts in terms of strengthening the problem formulation and improving the solution efficiency. Moreover, when applied to solve random and real application problems, the proposed SL cuts demonstrate the benefit in reducing the solution time.},
  archive      = {J_JGO},
  author       = {Chen, Wei-Kun and Chen, Liang and Dai, Yu-Hong},
  doi          = {10.1007/s10898-022-01252-x},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {205-249},
  shortjournal = {J. Glob. Optim.},
  title        = {Lifting for the integer knapsack cover polyhedron},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global linear convergence of evolution strategies with
recombination on scaling-invariant functions. <em>JGO</em>,
<em>86</em>(1), 163–203. (<a
href="https://doi.org/10.1007/s10898-022-01249-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolution Strategies (ESs) are stochastic derivative-free optimization algorithms whose most prominent representative, the CMA-ES algorithm, is widely used to solve difficult numerical optimization problems. We provide the first rigorous investigation of the linear convergence of step-size adaptive ESs involving a population and recombination, two ingredients crucially important in practice to be robust to local irregularities or multimodality. We investigate the convergence of step-size adaptive ESs with weighted recombination on composites of strictly increasing functions with continuously differentiable scaling-invariant functions with a global optimum. This function class includes functions with non-convex sublevel sets and discontinuous functions. We prove the existence of a constant r such that the logarithm of the distance to the optimum divided by the number of iterations converges to r. The constant is given as an expectation with respect to the stationary distribution of a Markov chain—its sign allows to infer linear convergence or divergence of the ES and is found numerically. Our main condition for convergence is the increase of the expected log step-size on linear functions. In contrast to previous results, our condition is equivalent to the almost sure geometric divergence of the step-size on linear functions.},
  archive      = {J_JGO},
  author       = {Toure, Cheikh and Auger, Anne and Hansen, Nikolaus},
  doi          = {10.1007/s10898-022-01249-6},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {163-203},
  shortjournal = {J. Glob. Optim.},
  title        = {Global linear convergence of evolution strategies with recombination on scaling-invariant functions},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Some saddle-point theorems for vector-valued functions.
<em>JGO</em>, <em>86</em>(1), 141–161. (<a
href="https://doi.org/10.1007/s10898-022-01250-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns with vector saddle point problems where the image space of the objective bifunction is not endowed with any topology and the orders in the image space are defined from general sets. Some new existence results of vector saddle points are established based on using notions of vector-cyclic quasimonotonicity together with notions of “algebraic” semicontinuity, without assuming convexity assumptions.},
  archive      = {J_JGO},
  author       = {Hai, Nguyen Xuan and Quan, Nguyen Hong and Tri, Vo Viet},
  doi          = {10.1007/s10898-022-01250-z},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {141-161},
  shortjournal = {J. Glob. Optim.},
  title        = {Some saddle-point theorems for vector-valued functions},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Extension of forward-reflected-backward method to non-convex
mixed variational inequalities. <em>JGO</em>, <em>86</em>(1), 123–140.
(<a href="https://doi.org/10.1007/s10898-022-01253-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a modification of a recently studied forward-reflected-backward splitting method to solve non-convex mixed variational inequalities. We give global convergence results and nonasymptotic O(1/k) rate of convergence of the proposed method under some appropriate conditions and present some numerical illustrations, one of which is derived from oligopolistic equilibrium problems, to show the efficiency of our proposed method.},
  archive      = {J_JGO},
  author       = {Izuchukwu, Chinedu and Shehu, Yekini and Okeke, Chibueze C.},
  doi          = {10.1007/s10898-022-01253-w},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {123-140},
  shortjournal = {J. Glob. Optim.},
  title        = {Extension of forward-reflected-backward method to non-convex mixed variational inequalities},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalized damped newton algorithms in nonsmooth
optimization via second-order subdifferentials. <em>JGO</em>,
<em>86</em>(1), 93–122. (<a
href="https://doi.org/10.1007/s10898-022-01248-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper proposes and develops new globally convergent algorithms of the generalized damped Newton type for solving important classes of nonsmooth optimization problems. These algorithms are based on the theory and calculations of second-order subdifferentials of nonsmooth functions with employing the machinery of second-order variational analysis and generalized differentiation. First we develop a globally superlinearly convergent damped Newton-type algorithm for the class of continuously differentiable functions with Lipschitzian gradients, which are nonsmooth of second order. Then we design such a globally convergent algorithm to solve a structured class of nonsmooth quadratic composite problems with extended-real-valued cost functions, which typically arise in machine learning and statistics. Finally, we present the results of numerical experiments and compare the performance of our main algorithm applied to an important class of Lasso problems with those achieved by other first-order and second-order optimization algorithms.},
  archive      = {J_JGO},
  author       = {Khanh, Pham Duy and Mordukhovich, Boris S. and Phat, Vo Thanh and Tran, Dat Ba},
  doi          = {10.1007/s10898-022-01248-7},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {93-122},
  shortjournal = {J. Glob. Optim.},
  title        = {Generalized damped newton algorithms in nonsmooth optimization via second-order subdifferentials},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Outcome-space branch-and-bound outer approximation algorithm
for a class of non-convex quadratic programming problems. <em>JGO</em>,
<em>86</em>(1), 61–92. (<a
href="https://doi.org/10.1007/s10898-022-01255-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quadratically constrained quadratic programming problem often appears in various fields such as engineering practice, management science and network communication. This paper mainly considers a non-convex quadratic programming problem with convex quadratic constraints. Firstly, the objective function of the problem is reconstructed into a form composed of only one convex function and several linear functions by using the eigenvalue decomposition technique of matrix. Then the reconstructed problem is converted to the equivalent problem with simple concave quadratic objective function in the outcome space by introducing appropriate auxiliary variables, and its feasible domain is convex. Based on the branch-and-bound framework which can guarantee the global optimality of the solution, a global optimization algorithm for solving the equivalent problem is proposed, which integrates the effective relaxation process and the branching process related to the outer approximation technique. Finally, the effectiveness and feasibility of the algorithm are illustrated by numerical experiments.},
  archive      = {J_JGO},
  author       = {Zhang, Bo and Gao, YueLin and Liu, Xia and Huang, XiaoLi},
  doi          = {10.1007/s10898-022-01255-8},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {61-92},
  shortjournal = {J. Glob. Optim.},
  title        = {Outcome-space branch-and-bound outer approximation algorithm for a class of non-convex quadratic programming problems},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nonconvex sensitivity-based generalized benders
decomposition. <em>JGO</em>, <em>86</em>(1), 37–60. (<a
href="https://doi.org/10.1007/s10898-022-01254-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers general separable pseudoconvex optimization problems with continuous complicating variables in which primal and projected problems are both pseudoconvex problems. A novel decomposition method based on generalized Benders decomposition, named nonconvex sensitivity-based generalized Benders decomposition, is developed and proved strictly to obtain optimal solutions of general separable pseudoconvex optimization problems of interest without constructing surrogate models. By the use of a reformulation strategy (introducing an extra equality constraint and constructing several subproblems), the algorithm handles the nonconvexity by direct manipulations of consistent linear Benders cuts and the check of optimality conditions and approximating the feasible region of complicating variables by supporting hyperplanes. The master problems of the new algorithm are always linear programming problems and the solution of the algorithm contains sensitivity information about complicating variables. Moreover, the new algorithm could also be used as a tool to check the nonconvexity of an optimization problem. Two cases are given to confirm the validity and applicability of the proposed algorithm.},
  archive      = {J_JGO},
  author       = {Lin, Jia-Jiang and Xu, Feng and Luo, Xiong-Lin},
  doi          = {10.1007/s10898-022-01254-9},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {37-60},
  shortjournal = {J. Glob. Optim.},
  title        = {Nonconvex sensitivity-based generalized benders decomposition},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Projections onto hyperbolas or bilinear constraint sets in
hilbert spaces. <em>JGO</em>, <em>86</em>(1), 25–36. (<a
href="https://doi.org/10.1007/s10898-022-01247-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sets of bilinear constraints are important in various machine learning models. Mathematically, they are hyperbolas in a product space. In this paper, we give a complete formula for projections onto sets of bilinear constraints or hyperbolas in a general Hilbert space.},
  archive      = {J_JGO},
  author       = {Bauschke, Heinz H. and Lal, Manish Krishan and Wang, Xianfu},
  doi          = {10.1007/s10898-022-01247-8},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {25-36},
  shortjournal = {J. Glob. Optim.},
  title        = {Projections onto hyperbolas or bilinear constraint sets in hilbert spaces},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TREGO: A trust-region framework for efficient global
optimization. <em>JGO</em>, <em>86</em>(1), 1–23. (<a
href="https://doi.org/10.1007/s10898-022-01245-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient global optimization (EGO) is the canonical form of Bayesian optimization that has been successfully applied to solve global optimization of expensive-to-evaluate black-box problems. However, EGO struggles to scale with dimension, and offers limited theoretical guarantees. In this work, a trust-region framework for EGO (TREGO) is proposed and analyzed. TREGO alternates between regular EGO steps and local steps within a trust region. By following a classical scheme for the trust region (based on a sufficient decrease condition), the proposed algorithm enjoys global convergence properties, while departing from EGO only for a subset of optimization steps. Using extensive numerical experiments based on the well-known COCO bound constrained problems, we first analyze the sensitivity of TREGO to its own parameters, then show that the resulting algorithm is consistently outperforming EGO and getting competitive with other state-of-the-art black-box optimization methods.},
  archive      = {J_JGO},
  author       = {Diouane, Youssef and Picheny, Victor and Riche, Rodolophe Le and Perrotolo, Alexandre Scotto Di},
  doi          = {10.1007/s10898-022-01245-w},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {1-23},
  shortjournal = {J. Glob. Optim.},
  title        = {TREGO: A trust-region framework for efficient global optimization},
  volume       = {86},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finding globally shortest paths through a sequence of
adjacent triangles by the method of orienting curves. <em>JGO</em>,
<em>85</em>(4), 1037–1063. (<a
href="https://doi.org/10.1007/s10898-022-01244-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an exact algorithm based on the method of orienting curves is developed for solving the convex non-differentiable optimization problem on the closed unit cube in a finite dimensional space: finding the shortest path joining two points going through a sequence of adjacent triangles in 3D. As a result, the global solution of the problem is determined successively by some orienting curves and final curve, which can be exactly constructed with ruler and compass. A detailed numerical example is presented.},
  archive      = {J_JGO},
  author       = {An, Phan Thanh and Phu, Hoang Xuan},
  doi          = {10.1007/s10898-022-01244-x},
  journal      = {Journal of Global Optimization},
  number       = {4},
  pages        = {1037-1063},
  shortjournal = {J. Glob. Optim.},
  title        = {Finding globally shortest paths through a sequence of adjacent triangles by the method of orienting curves},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Separating bichromatic point sets in the plane by restricted
orientation convex hulls. <em>JGO</em>, <em>85</em>(4), 1003–1036. (<a
href="https://doi.org/10.1007/s10898-022-01238-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore the separability of point sets in the plane by a restricted-orientation convex hull, which is an orientation-dependent, possibly disconnected, and non-convex enclosing shape that generalizes the convex hull. Let R and B be two disjoint sets of red and blue points in the plane, and $$\mathcal {O}$$ be a set of $$k\ge 2$$ lines passing through the origin. We study the problem of computing the set of orientations of the lines of $$\mathcal {O}$$ for which the $$\mathcal {O}$$ -convex hull of R contains no points of B. For $$k=2$$ orthogonal lines we have the rectilinear convex hull. In optimal $$O(n\log n)$$ time and O(n) space, $$n = \vert R \vert + \vert B \vert $$ , we compute the set of rotation angles such that, after simultaneously rotating the lines of $$\mathcal {O}$$ around the origin in the same direction, the rectilinear convex hull of R contains no points of B. We generalize this result to the case where $$\mathcal {O}$$ is formed by $$k \ge 2$$ lines with arbitrary orientations. In the counter-clockwise circular order of the lines of $$\mathcal {O}$$ , let $$\alpha _i$$ be the angle required to clockwise rotate the ith line so it coincides with its successor. We solve the problem in this case in $$O({1}/{\Theta }\cdot N \log N)$$ time and $$O({1}/{\Theta }\cdot N)$$ space, where $$\Theta = \min { \alpha _1,\ldots ,\alpha _k }$$ and $$N=\max {k,\vert R \vert + \vert B \vert }$$ . We finally consider the case in which $$\mathcal {O}$$ is formed by $$k=2$$ lines, one of the lines is fixed, and the second line rotates by an angle that goes from 0 to $$\pi $$ . We show that this last case can also be solved in optimal $$O(n\log n)$$ time and O(n) space, where $$n = \vert R \vert + \vert B \vert $$ .},
  archive      = {J_JGO},
  author       = {Alegría, Carlos and Orden, David and Seara, Carlos and Urrutia, Jorge},
  doi          = {10.1007/s10898-022-01238-9},
  journal      = {Journal of Global Optimization},
  number       = {4},
  pages        = {1003-1036},
  shortjournal = {J. Glob. Optim.},
  title        = {Separating bichromatic point sets in the plane by restricted orientation convex hulls},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weak and strong convergence of generalized proximal point
algorithms with relaxed parameters. <em>JGO</em>, <em>85</em>(4),
969–1002. (<a href="https://doi.org/10.1007/s10898-022-01241-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose and study a framework of generalized proximal point algorithms associated with a maximally monotone operator. We indicate sufficient conditions on the regularization and relaxation parameters of generalized proximal point algorithms for the equivalence of the boundedness of the sequence of iterations generated by this algorithm and the non-emptiness of the zero set of the maximally monotone operator, and for the weak and strong convergence of the algorithm. Our results cover or improve many results on generalized proximal point algorithms in our references. Improvements of our results are illustrated by comparing our results with related known ones.},
  archive      = {J_JGO},
  author       = {Ouyang, Hui},
  doi          = {10.1007/s10898-022-01241-0},
  journal      = {Journal of Global Optimization},
  number       = {4},
  pages        = {969-1002},
  shortjournal = {J. Glob. Optim.},
  title        = {Weak and strong convergence of generalized proximal point algorithms with relaxed parameters},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An inertial proximal point method for difference of maximal
monotone vector fields in hadamard manifolds. <em>JGO</em>,
<em>85</em>(4), 941–968. (<a
href="https://doi.org/10.1007/s10898-022-01240-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an inertial proximal point method for variational inclusion involving difference of two maximal monotone vector fields in Hadamard manifolds. We prove that if the sequence generated by the method is bounded, then every cluster point is a solution of the non-monotone variational inclusion. Some sufficient conditions for boundedness and full convergence of the sequence are presented. The efficiency of the method is verified by numerical experiments comparing its performance with classical versions of the method for monotone and non-monotone problems.},
  archive      = {J_JGO},
  author       = {Andrade, João S. and Lopes, Jurandir de O. and Souza, João Carlos de O.},
  doi          = {10.1007/s10898-022-01240-1},
  journal      = {Journal of Global Optimization},
  number       = {4},
  pages        = {941-968},
  shortjournal = {J. Glob. Optim.},
  title        = {An inertial proximal point method for difference of maximal monotone vector fields in hadamard manifolds},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Conditions for the stability of ideal efficient solutions in
parametric vector optimization via set-valued inclusions. <em>JGO</em>,
<em>85</em>(4), 917–940. (<a
href="https://doi.org/10.1007/s10898-022-01232-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In present paper, an analysis of the stability behaviour of ideal efficient solutions to parametric vector optimization problems is conducted. A sufficient condition for the existence of ideal efficient solutions to locally perturbed problems and their nearness to a given reference value is provided by refining recent results on the stability theory of parameterized set-valued inclusions. More precisely, the Lipschitz lower semicontinuity property of the solution mapping is established, with an estimate of the related modulus. A notable consequence of this fact is the calmness behaviour of the ideal value mapping associated to the parametric class of vector optimization problems. Within such an analysis, a refinement of a recent existence result, specific for ideal efficient solutions to unperturbed problem and enhanced by related error bounds, is discussed. Some connections with the concept of robustness in multi-objective optimization are also sketched.},
  archive      = {J_JGO},
  author       = {Uderzo, Amos},
  doi          = {10.1007/s10898-022-01232-1},
  journal      = {Journal of Global Optimization},
  number       = {4},
  pages        = {917-940},
  shortjournal = {J. Glob. Optim.},
  title        = {Conditions for the stability of ideal efficient solutions in parametric vector optimization via set-valued inclusions},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A class of infeasible proximal bundle methods for nonsmooth
nonconvex multi-objective optimization problems. <em>JGO</em>,
<em>85</em>(4), 891–915. (<a
href="https://doi.org/10.1007/s10898-022-01242-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a class of infeasible proximal bundle methods for solving nonsmooth nonconvex multi-objective optimization problems. The proposed algorithms have no requirements on the feasibility of the initial points. In the algorithms, the multi-objective functions are handled directly without any scalarization procedure. To speed up the convergence of the infeasible algorithm, an acceleration technique, i.e., the penalty skill, is applied into the algorithm. The strategies are introduced to adjust the proximal parameters and penalty parameters. Under some wild assumptions, the sequence generated by infeasible proximal bundle methods converges to the globally Pareto solution of multi-objective optimization problems. Numerical results shows the good performance of the proposed algorithms.},
  archive      = {J_JGO},
  author       = {Pang, Li-Ping and Meng, Fan-Yun and Yang, Jian-Song},
  doi          = {10.1007/s10898-022-01242-z},
  journal      = {Journal of Global Optimization},
  number       = {4},
  pages        = {891-915},
  shortjournal = {J. Glob. Optim.},
  title        = {A class of infeasible proximal bundle methods for nonsmooth nonconvex multi-objective optimization problems},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Calmness of partial perturbation to composite rank
constraint systems and its applications. <em>JGO</em>, <em>85</em>(4),
867–889. (<a href="https://doi.org/10.1007/s10898-022-01239-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the calmness of a partial perturbation to the composite rank constraint system, an intersection of the rank constraint set and a general closed set, which is shown to be equivalent to a local Lipschitz-type error bound and also a global Lipschitz-type error bound under a certain compactness. Based on its lifted formulation, we derive two criteria for identifying those closed sets such that the associated partial perturbation possesses the calmness, and provide a collection of examples to demonstrate that the criteria are satisfied by common nonnegative and positive semidefinite rank constraint sets. Then, we use the calmness of this perturbation to obtain several global exact penalties for rank constrained optimization problems, and a family of equivalent DC surrogates for rank regularized problems.},
  archive      = {J_JGO},
  author       = {Qian, Yitian and Pan, Shaohua and Liu, Yulan},
  doi          = {10.1007/s10898-022-01239-8},
  journal      = {Journal of Global Optimization},
  number       = {4},
  pages        = {867-889},
  shortjournal = {J. Glob. Optim.},
  title        = {Calmness of partial perturbation to composite rank constraint systems and its applications},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Primal-dual splittings as fixed point iterations in the
range of linear operators. <em>JGO</em>, <em>85</em>(4), 847–866. (<a
href="https://doi.org/10.1007/s10898-022-01237-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study the convergence of the relaxed primal-dual algorithm with critical preconditioners for solving composite monotone inclusions in real Hilbert spaces. We prove that this algorithm define Krasnosel’skiĭ-Mann (KM) iterations in the range of a particular monotone self-adjoint linear operator with non-trivial kernel. Our convergence result generalizes (Condat in J Optim Theory Appl 158: 460–479, 2013, Theorem 3.3) and follows from that of KM iterations defined in the range of linear operators, which is a real Hilbert subspace under suitable conditions. The Douglas–Rachford splitting (DRS) with a non-standard metric is written as a particular instance of the primal-dual algorithm with critical preconditioners and we recover classical results from this new perspective. We implement the algorithm in total variation reconstruction, verifying the advantages of using critical preconditioners and relaxation steps.},
  archive      = {J_JGO},
  author       = {Briceño-Arias, Luis and Roldán, Fernando},
  doi          = {10.1007/s10898-022-01237-w},
  journal      = {Journal of Global Optimization},
  number       = {4},
  pages        = {847-866},
  shortjournal = {J. Glob. Optim.},
  title        = {Primal-dual splittings as fixed point iterations in the range of linear operators},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving saddle point problems: A landscape of primal-dual
algorithm with larger stepsizes. <em>JGO</em>, <em>85</em>(4), 821–846.
(<a href="https://doi.org/10.1007/s10898-022-01233-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a class of saddle point problems frequently arising in the areas of image processing and machine learning. In this paper, we propose a simple primal-dual algorithm, which embeds a general proximal term induced with a positive definite matrix into one subproblem. It is remarkable that our algorithm enjoys larger stepsizes than many existing state-of-the-art primal-dual-like algorithms due to our relaxed convergence-guaranteeing condition. Moreover, our algorithm includes the well-known primal-dual hybrid gradient method as its special case, while it is also of possible benefit to deriving partially linearized primal-dual algorithms. Finally, we show that our algorithm is able to deal with multi-block separable saddle point problems. In particular, an application to a multi-block separable minimization problem with linear constraints yields a parallel algorithm. Some computational results sufficiently support the promising improvement brought by our relaxed requirement.},
  archive      = {J_JGO},
  author       = {Jiang, Fan and Zhang, Zhiyuan and He, Hongjin},
  doi          = {10.1007/s10898-022-01233-0},
  journal      = {Journal of Global Optimization},
  number       = {4},
  pages        = {821-846},
  shortjournal = {J. Glob. Optim.},
  title        = {Solving saddle point problems: A landscape of primal-dual algorithm with larger stepsizes},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On piecewise linear approximations of bilinear terms:
Structural comparison of univariate and bivariate mixed-integer
programming formulations. <em>JGO</em>, <em>85</em>(4), 789–819. (<a
href="https://doi.org/10.1007/s10898-022-01243-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bilinear terms naturally appear in many optimization problems. Their inherent non-convexity typically makes them challenging to solve. One approach to tackle this difficulty is to use bivariate piecewise linear approximations for each variable product, which can be represented via mixed-integer linear programming (MIP) formulations. Alternatively, one can reformulate the variable products as a sum of univariate functions. Each univariate function can again be approximated by a piecewise linear function and modelled via an MIP formulation. In the literature, heterogeneous results are reported concerning which approach works better in practice, but little theoretical analysis is provided. We fill this gap by structurally comparing bivariate and univariate approximations with respect to two criteria. First, we compare the number of simplices sufficient for an $$ \varepsilon $$ -approximation. We derive upper bounds for univariate approximations and compare them to a lower bound for bivariate approximations. We prove that for a small prescribed approximation error $$ \varepsilon $$ , univariate $$ \varepsilon $$ -approximations require fewer simplices than bivariate $$ \varepsilon $$ -approximations. The second criterion is the tightness of the continuous relaxations (CR) of corresponding sharp MIP formulations. Here, we prove that the CR of a bivariate MIP formulation describes the convex hull of a variable product, the so-called McCormick relaxation. In contrast, we show by a volume argument that the CRs corresponding to univariate approximations are strictly looser. This allows us to explain many of the computational effects observed in the literature and to give theoretical evidence on when to use which kind of approximation.},
  archive      = {J_JGO},
  author       = {Bärmann, Andreas and Burlacu, Robert and Hager, Lukas and Kleinert, Thomas},
  doi          = {10.1007/s10898-022-01243-y},
  journal      = {Journal of Global Optimization},
  number       = {4},
  pages        = {789-819},
  shortjournal = {J. Glob. Optim.},
  title        = {On piecewise linear approximations of bilinear terms: Structural comparison of univariate and bivariate mixed-integer programming formulations},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comparing reference point based interactive multiobjective
optimization methods without a human decision maker. <em>JGO</em>,
<em>85</em>(3), 757–788. (<a
href="https://doi.org/10.1007/s10898-022-01230-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactive multiobjective optimization methods have proven promising in solving optimization problems with conflicting objectives since they iteratively incorporate preference information of a decision maker in the search for the most preferred solution. To find the appropriate interactive method for various needs involves analysis of the strengths and weaknesses. However, extensive analysis with human decision makers may be too costly and for that reason, we propose an artificial decision maker to compare a class of popular interactive multiobjective optimization methods, i.e., reference point based methods. Without involving any human decision makers, the artificial decision maker works automatically to interact with different methods to be compared and evaluate the final results. It makes a difference between a learning phase and a decision phase, that is, learns about the problem based on information acquired to identify a region of interest and refines solutions in that region to find a final solution, respectively. We adopt different types of utility functions to evaluation solutions, present corresponding performance indicators and propose two examples of artificial decision makers. A series of experiments on benchmark test problems and a water resources planning problem is conducted to demonstrate how the proposed artificial decision makers can be used to compare reference point based methods.},
  archive      = {J_JGO},
  author       = {Chen, Lu and Miettinen, Kaisa and Xin, Bin and Ojalehto, Vesa},
  doi          = {10.1007/s10898-022-01230-3},
  journal      = {Journal of Global Optimization},
  number       = {3},
  pages        = {757-788},
  shortjournal = {J. Glob. Optim.},
  title        = {Comparing reference point based interactive multiobjective optimization methods without a human decision maker},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Calabi-polyak convexity theorem, yuan’s lemma and s-lemma:
Extensions and applications. <em>JGO</em>, <em>85</em>(3), 743–756. (<a
href="https://doi.org/10.1007/s10898-022-01225-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We extend the Calabi-Polyak theorem on the convexity of joint numerical range from three to any number of matrices on condition that each of them is a linear combination of three matrices having a positive definite linear combination. Our new result covers the fundamental Dines’s theorem. As applications, the further extended Yuan’s lemma and S-lemma are presented. The former is used to establish a more generalized assumption under which the standard second-order necessary optimality condition holds at the local minimizer in nonlinear programming, and the latter reveals hidden convexity of the homogeneous quadratic optimization problem with two bilateral quadratic constraints and its fractional extension.},
  archive      = {J_JGO},
  author       = {Song, Mengmeng and Xia, Yong},
  doi          = {10.1007/s10898-022-01225-0},
  journal      = {Journal of Global Optimization},
  number       = {3},
  pages        = {743-756},
  shortjournal = {J. Glob. Optim.},
  title        = {Calabi-polyak convexity theorem, yuan’s lemma and S-lemma: Extensions and applications},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the structure of regularization paths for piecewise
differentiable regularization terms. <em>JGO</em>, <em>85</em>(3),
709–741. (<a href="https://doi.org/10.1007/s10898-022-01223-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regularization is used in many different areas of optimization when solutions are sought which not only minimize a given function, but also possess a certain degree of regularity. Popular applications are image denoising, sparse regression and machine learning. Since the choice of the regularization parameter is crucial but often difficult, path-following methods are used to approximate the entire regularization path, i.e., the set of all possible solutions for all regularization parameters. Due to their nature, the development of these methods requires structural results about the regularization path. The goal of this article is to derive these results for the case of a smooth objective function which is penalized by a piecewise differentiable regularization term. We do this by treating regularization as a multiobjective optimization problem. Our results suggest that even in this general case, the regularization path is piecewise smooth. Moreover, our theory allows for a classification of the nonsmooth features that occur in between smooth parts. This is demonstrated in two applications, namely support-vector machines and exact penalty methods.},
  archive      = {J_JGO},
  author       = {Gebken, Bennet and Bieker, Katharina and Peitz, Sebastian},
  doi          = {10.1007/s10898-022-01223-2},
  journal      = {Journal of Global Optimization},
  number       = {3},
  pages        = {709-741},
  shortjournal = {J. Glob. Optim.},
  title        = {On the structure of regularization paths for piecewise differentiable regularization terms},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Directional derivatives and subdifferentials for set-valued
maps applied to set optimization. <em>JGO</em>, <em>85</em>(3), 687–707.
(<a href="https://doi.org/10.1007/s10898-022-01222-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a general method to devise directional derivatives and subdifferentials for set-valued maps that generalize the corresponding constructions from the classical situation of real-valued functions. We show that these generalized differentiation objects enjoy some properties that, on the one hand, meaningfully extend the aforementioned case and, on the another hand, are useful to deal with the so-called $$\ell $$ -minimality in set optimization problems.},
  archive      = {J_JGO},
  author       = {Durea, Marius and Strugariu, Radu},
  doi          = {10.1007/s10898-022-01222-3},
  journal      = {Journal of Global Optimization},
  number       = {3},
  pages        = {687-707},
  shortjournal = {J. Glob. Optim.},
  title        = {Directional derivatives and subdifferentials for set-valued maps applied to set optimization},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimality and duality for nonsmooth mathematical
programming problems with equilibrium constraints. <em>JGO</em>,
<em>85</em>(3), 663–685. (<a
href="https://doi.org/10.1007/s10898-022-01231-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we construct a Wolfe and Mond-Weir types dual problem in terms of contingent epiderivatives for nonsmooth mathematical programming problems with equilibrium constraints (NMPEC) in real Banach spaces. First, we establish some strong and weak duality theorems for the original problem and its dual problem under suitable assumptions on the pseudo-convexity of objective and constraint functions at the point under consideration. We also impose a regularity condition of the (RC) type to have strong duality theorems using both the contingent epiderivative and the contingent hypoderivative. Second, we provide various types of sufficient optimality conditions for the (NMPEC) problem, where either the objective and constraint functions are pseudo-convex at the point under consideration, or the objective function is strict quasi-convex and the constraint functions are quasi-convex at the point under consideration. Some illustrative examples also provided for our findings.},
  archive      = {J_JGO},
  author       = {Su, Tran Van},
  doi          = {10.1007/s10898-022-01231-2},
  journal      = {Journal of Global Optimization},
  number       = {3},
  pages        = {663-685},
  shortjournal = {J. Glob. Optim.},
  title        = {Optimality and duality for nonsmooth mathematical programming problems with equilibrium constraints},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EFIX: Exact fixed point methods for distributed
optimization. <em>JGO</em>, <em>85</em>(3), 637–661. (<a
href="https://doi.org/10.1007/s10898-022-01221-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider strongly convex distributed consensus optimization over connected networks. EFIX, the proposed method, is derived using quadratic penalty approach. In more detail, we use the standard reformulation—transforming the original problem into a constrained problem in a higher dimensional space—to define a sequence of suitable quadratic penalty subproblems with increasing penalty parameters. For quadratic objectives, the corresponding sequence consists of quadratic penalty subproblems. For generic strongly convex case, the objective function is approximated with a quadratic model and hence the sequence of the resulting penalty subproblems is again quadratic. EFIX is then derived by solving each of the quadratic penalty subproblems via a fixed point (R)-linear solver, e.g., Jacobi Over-Relaxation method. The exact convergence is proved as well as the worst case complexity of order $${{\mathcal {O}}}(\epsilon ^{-1})$$ for the quadratic case. In the case of strongly convex generic functions, the standard result for penalty methods is obtained. Numerical results indicate that the method is highly competitive with state-of-the-art exact first order methods, requires smaller computational and communication effort, and is robust to the choice of algorithm parameters.},
  archive      = {J_JGO},
  author       = {Jakovetić, Dušan and Krejić, Nataša and Krklec Jerinkić, Nataša},
  doi          = {10.1007/s10898-022-01221-4},
  journal      = {Journal of Global Optimization},
  number       = {3},
  pages        = {637-661},
  shortjournal = {J. Glob. Optim.},
  title        = {EFIX: Exact fixed point methods for distributed optimization},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Relaxed-inertial proximal point type algorithms for
quasiconvex minimization. <em>JGO</em>, <em>85</em>(3), 615–635. (<a
href="https://doi.org/10.1007/s10898-022-01226-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a relaxed-inertial proximal point type algorithm for solving optimization problems consisting in minimizing strongly quasiconvex functions whose variables lie in finitely dimensional linear subspaces. A relaxed version of the method where the constraint set is only closed and convex is also discussed, and so is the case of a quasiconvex objective function. Numerical experiments illustrate the theoretical results.},
  archive      = {J_JGO},
  author       = {Grad, S.-M. and Lara, F. and Marcavillaca, R. T.},
  doi          = {10.1007/s10898-022-01226-z},
  journal      = {Journal of Global Optimization},
  number       = {3},
  pages        = {615-635},
  shortjournal = {J. Glob. Optim.},
  title        = {Relaxed-inertial proximal point type algorithms for quasiconvex minimization},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). New bounds for nonconvex quadratically constrained quadratic
programming. <em>JGO</em>, <em>85</em>(3), 595–613. (<a
href="https://doi.org/10.1007/s10898-022-01224-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study some bounds for nonconvex quadratically constrained quadratic programs (QCQPs). We propose two types of bounds for QCQPs, quadratic and cubic bounds. We use affine functions as Lagrange multipliers for quadratic bounds. We demonstrate that most semidefinite relaxations can be obtained as the dual of a quadratic bound. In addition, we study bounds obtained by changing the ground set. For cubic bounds, in addition to affine multipliers we employ quadratic functions. We provide a comparison between the proposed cubic bound and typical bounds for standard quadratic programs. Moreover, we report comparison results of some quadratic and cubic bounds.},
  archive      = {J_JGO},
  author       = {Zamani, Moslem},
  doi          = {10.1007/s10898-022-01224-1},
  journal      = {Journal of Global Optimization},
  number       = {3},
  pages        = {595-613},
  shortjournal = {J. Glob. Optim.},
  title        = {New bounds for nonconvex quadratically constrained quadratic programming},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Convex and concave envelopes of artificial neural network
activation functions for deterministic global optimization.
<em>JGO</em>, <em>85</em>(3), 569–594. (<a
href="https://doi.org/10.1007/s10898-022-01228-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present general methods to construct convex/concave relaxations of the activation functions that are commonly chosen for artificial neural networks (ANNs). The choice of these functions is often informed by both broader modeling considerations balanced with a need for high computational performance. The direct application of factorable programming techniques to compute bounds and convex/concave relaxations of such functions often lead to weak enclosures due to the dependency problem. Moreover, the piecewise formulation that defines several popular activation functions, prevents the computation of convex/concave relaxations as they violate the factorable function requirement. To improve the performance of relaxations of ANNs for deterministic global optimization applications, this study presents the development of a library of envelopes of the thoroughly studied rectifier-type and sigmoid activation functions, in addition to the novel self-gated sigmoid-weighted linear unit (SiLU) and Gaussian error linear unit activation functions. We demonstrate that the envelopes of activation functions directly lead to tighter relaxations of ANNs on their input domain. In turn, these improvements translate to a dramatic reduction in CPU runtime required for solving optimization problems involving ANN models to epsilon-global optimality. We further demonstrate that the factorable programming approach leads to superior computational performance over alternative state-of-the-art approaches.},
  archive      = {J_JGO},
  author       = {Wilhelm, Matthew E. and Wang, Chenyu and Stuber, Matthew D.},
  doi          = {10.1007/s10898-022-01228-x},
  journal      = {Journal of Global Optimization},
  number       = {3},
  pages        = {569-594},
  shortjournal = {J. Glob. Optim.},
  title        = {Convex and concave envelopes of artificial neural network activation functions for deterministic global optimization},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computational advances in polynomial optimization: RAPOSa, a
freely available global solver. <em>JGO</em>, <em>85</em>(3), 541–568.
(<a href="https://doi.org/10.1007/s10898-022-01229-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we introduce RAPOSa, a global optimization solver specifically designed for (continuous) polynomial programming problems with box-constrained variables. Written entirely in C++, RAPOSa is based on the Reformulation-Linearization (Sherali and Tuncbilek in J Glob Optim 103:225–249, 1992). We present a description of the main characteristics of RAPOSa along with a thorough analysis of the impact on its performance of various enhancements discussed in the literature, such as bound tightening and SDP cuts. We also present a comparative study with three of the main state-of-the-art global optimization solvers: BARON, Couenne and SCIP.},
  archive      = {J_JGO},
  author       = {González-Rodríguez, Brais and Ossorio-Castillo, Joaquín and González-Díaz, Julio and González-Rueda, Ángel M. and Penas, David R. and Rodríguez-Martínez, Diego},
  doi          = {10.1007/s10898-022-01229-w},
  journal      = {Journal of Global Optimization},
  number       = {3},
  pages        = {541-568},
  shortjournal = {J. Glob. Optim.},
  title        = {Computational advances in polynomial optimization: RAPOSa, a freely available global solver},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global well-posedness of set-valued optimization with
application to uncertain problems. <em>JGO</em>, <em>85</em>(2),
511–539. (<a href="https://doi.org/10.1007/s10898-022-01208-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Well-posedness for optimization problems is a well-known notion and has been studied extensively for scalar, vector and set-valued optimization problems. There is a broad classification in terms of pointwise and global well-posedness notions in vector and set-valued optimization problems. We have focused on global well-posedness for set-valued optimization problems in this paper. A number of notions of global well-posedness for set-valued optimization problems already exist in the literature. However, we found equivalence between some existing notions of global well-posedness for set-valued optimization problems and also found scope of improving and extending the research in that field. That has been the first aim of this paper. On the other hand, robust approach towards uncertain optimization problems is another growing area of research. The well-posedness for the robust counterparts have been explored in very few papers, and that too only in the scalar and vector cases (see (Anh et al. in Ann Oper Res 295(2):517–533, 2020), (Crespi et al. in Ann Oper Res 251(1–2):89–104, 2017)). Therefore, the second aim of this paper is to study some global well-posedness properties of the robust formulation of uncertain set-valued optimization problems that generalize the concept of the well-posedness of robust formulation of uncertain vector optimization problems as discussed in Anh et al. (Ann Oper Res 295(2):517–533, 2020), Crespi et al. (Ann Oper Res 251(1–2):89–104, 2017).},
  archive      = {J_JGO},
  author       = {Som, Kuntal and Vetrivel, V.},
  doi          = {10.1007/s10898-022-01208-1},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {511-539},
  shortjournal = {J. Glob. Optim.},
  title        = {Global well-posedness of set-valued optimization with application to uncertain problems},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). One-step iterative method for bilevel equilibrium problem in
hilbert space. <em>JGO</em>, <em>85</em>(2), 487–510. (<a
href="https://doi.org/10.1007/s10898-022-01207-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this paper is to introduce a simple iterative method for finding a solution of an equilibrium problem whose constraint is the solution set of another monotone equilibrium problem in a Hilbert space. Unlike the multi-step methods, the new method only requires to find one value of the proximal mapping associated with cost bifunctions at the current approximation over each iterative step. The strong convergence of the iterative sequence generated by the method is established by incorporating with a regularization technique. The numerical behavior of our method is also illustrated in comparison with several other methods.},
  archive      = {J_JGO},
  author       = {Van Hieu, Dang and Quy, Pham Kim},
  doi          = {10.1007/s10898-022-01207-2},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {487-510},
  shortjournal = {J. Glob. Optim.},
  title        = {One-step iterative method for bilevel equilibrium problem in hilbert space},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vertex quickest 1-center location problem on trees and its
inverse problem under weighted <span
class="math display"><em>l</em><sub>∞</sub></span> norm. <em>JGO</em>,
<em>85</em>(2), 461–485. (<a
href="https://doi.org/10.1007/s10898-022-01212-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In view of some shortcomings of traditional vertex 1-center (V1C), we introduce a vertex quickest 1-center (VQ1C) problem on a tree, which aims to find a vertex such that the maximum transmission time to transmit $$\sigma $$ units data is minimum. We first characterize some intrinsic properties of VQ1C and design a binary search algorithm in $$O(n \log n)$$ time based on the relationship between V1C and VQ1C, where n is the number of vertices. Furthermore, we investigate the inverse VQ1C problem under weighted $$l_\infty $$ norm, in which we modify a given capacity vector in an optimal way such that a prespecified vertex becomes the vertex quickest 1-center. We introduce a concept of an effective modification and provide some optimality conditions for the problem. Then we propose an $$O(n^2 \log n)$$ time algorithm. Finally, we show some numerical experiments to verify the efficiency of the algorithms.},
  archive      = {J_JGO},
  author       = {Qian, Xinqiang and Guan, Xiucui and Jia, Junhua and Zhang, Qiao and Pardalos, Panos M.},
  doi          = {10.1007/s10898-022-01212-5},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {461-485},
  shortjournal = {J. Glob. Optim.},
  title        = {Vertex quickest 1-center location problem on trees and its inverse problem under weighted $$l_\infty $$ norm},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Aubin property for solution set in multi-objective
programming. <em>JGO</em>, <em>85</em>(2), 441–460. (<a
href="https://doi.org/10.1007/s10898-022-01209-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the behavior of the solutions of a multi-objective optimization problem, whose the objective functions are perturbed by adding a small linear term, is analyzed. In this regard, a new notion of Lipschitzian stability, by means of the Aubin property of the solution set, is defined. Lipschitz stable locally efficient solutions, as generalization of tilt/full stable solutions, are introduced and characterized by modern variational analysis tools. Applying the weighted sum method, the relationships between these solutions and full-stable local optimal solutions of the scalarized problem are investigated. The key tools in deriving our results come from the first- and second-order variational analysis.},
  archive      = {J_JGO},
  author       = {Rahimi, Morteza and Soleimani-damaneh, Majid},
  doi          = {10.1007/s10898-022-01209-0},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {441-460},
  shortjournal = {J. Glob. Optim.},
  title        = {Aubin property for solution set in multi-objective programming},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An active set strategy to address the ill-conditioning of
smoothing methods for solving finite linear minimax problems.
<em>JGO</em>, <em>85</em>(2), 421–439. (<a
href="https://doi.org/10.1007/s10898-022-01217-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an active set strategy is presented to address the ill-conditioning of smoothing methods for solving finite linear minimax problems. Based on the first order optimality conditions, a concept of the strongly active set composed of a part of active indexes is introduced. In the active set strategy, a strongly active set is obtained by solving a linear system or a linear programming problem, then an optimal solution with its active set and Lagrange multipliers is computed by an iterative process. A hybrid algorithm combining a smoothing algorithm and the active set strategy is proposed for solving finite linear minimax problems, in which an approximate solution is obtained by the smoothing algorithm, then an optimal solution is computed by the active set strategy. The convergences of the active set strategy and the hybrid algorithm are established for general finite linear minimax problems. Preliminary numerical experiments show that the active set strategy and the hybrid algorithm are effective and robust, and the active set strategy can effectively address the ill-conditioning of smoothing methods for solving general finite linear minimax problems.},
  archive      = {J_JGO},
  author       = {Zhou, Zhengyong and Dai, Xiaoyang},
  doi          = {10.1007/s10898-022-01217-0},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {421-439},
  shortjournal = {J. Glob. Optim.},
  title        = {An active set strategy to address the ill-conditioning of smoothing methods for solving finite linear minimax problems},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accelerated dai-liao projection method for solving systems
of monotone nonlinear equations with application to image deblurring.
<em>JGO</em>, <em>85</em>(2), 377–420. (<a
href="https://doi.org/10.1007/s10898-022-01213-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A modified Dai-Liao type conjugate gradient method for solving large-scale nonlinear systems of monotone equations is introduced and investigated in actual research. The starting point is the Dai-Liao type conjugate gradient method which is based on the descent Dai-Liao method and the hyperplane projection technique, known as the Dai-Liao projection method (DLPM). Our algorithm, termed MSMDLPM, proposes a novel search direction for the DLPM, which arises from appropriate acceleration parameters obtained after hybridizing the accelerated gradient-descent method MSM with the DLPM method. The main goal of the proposed MSMDLPM method is to correlate the MSM and the DLPM. The global convergence and the convergence rate of the MSMDLPM method are investigated theoretically. Numerical results show the efficiency of the proposed method in solving large-scale nonlinear systems of monotone equations. The effectiveness of the method in image restoration is verified based on performed numerical experiments.},
  archive      = {J_JGO},
  author       = {Ivanov, Branislav and Milovanović, Gradimir V. and Stanimirović, Predrag S.},
  doi          = {10.1007/s10898-022-01213-4},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {377-420},
  shortjournal = {J. Glob. Optim.},
  title        = {Accelerated dai-liao projection method for solving systems of monotone nonlinear equations with application to image deblurring},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-instance learning by maximizing the area under
receiver operating characteristic curve. <em>JGO</em>, <em>85</em>(2),
351–375. (<a href="https://doi.org/10.1007/s10898-022-01219-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this study is to solve the multi-instance classification problem by maximizing the area under the Receiver Operating Characteristic (ROC) curve obtained for witness instances. We derive a mixed integer linear programming model that chooses witnesses and produces the best possible ROC curve using a linear ranking function for multi-instance classification. The formulation is solved using a commercial mathematical optimization solver as well as a fast metaheuristic approach. When the data is not linearly separable, we illustrate how new features can be generated to tackle the problem. We present a comprehensive computational study to compare our methods against the state-of-the-art approaches in the literature. Our study reveals the success of an optimal linear ranking function through cross validation for several benchmark instances.},
  archive      = {J_JGO},
  author       = {Sakarya, I. Edhem and Kundakcioglu, O. Erhun},
  doi          = {10.1007/s10898-022-01219-y},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {351-375},
  shortjournal = {J. Glob. Optim.},
  title        = {Multi-instance learning by maximizing the area under receiver operating characteristic curve},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sparse estimation via lower-order penalty optimization
methods in high-dimensional linear regression. <em>JGO</em>,
<em>85</em>(2), 315–349. (<a
href="https://doi.org/10.1007/s10898-022-01220-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The lower-order penalty optimization methods, including the $$\ell _q$$ minimization method and the $$\ell _q$$ regularization method $$(0&lt;q\le 1)$$ , have been widely applied to find sparse solutions of linear regression problems and gained successful applications in various mathematics and applied science fields. In this paper, we aim to investigate statistical properties of the $$\ell _q$$ penalty optimization methods with randomly noisy observations and a deterministic/random design. For this purpose, we introduce a general q-Restricted Eigenvalue Condition (REC) and provide its sufficient conditions in terms of several widely-used regularity conditions such as sparse eigenvalue condition, restricted isometry property, and mutual incoherence property. By virtue of the q-REC, we exhibit the $$\ell _2$$ recovery bounds of order $$O(\epsilon ^2)$$ and $$O(\lambda ^{\frac{2}{2-q}}s)$$ for the $$\ell _q$$ minimization method and the $$\ell _q$$ regularization method, respectively, with high probability for either deterministic or random designs. The results in this paper are nonasymptotic and only assume the weak q-REC. The preliminary numerical results verify the established statistical properties and demonstrate the advantages of the $$\ell _q$$ penalty optimization methods over existing sparse optimization methods.},
  archive      = {J_JGO},
  author       = {Li, Xin and Hu, Yaohua and Li, Chong and Yang, Xiaoqi and Jiang, Tianzi},
  doi          = {10.1007/s10898-022-01220-5},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {315-349},
  shortjournal = {J. Glob. Optim.},
  title        = {Sparse estimation via lower-order penalty optimization methods in high-dimensional linear regression},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel approach for solving multi-parametric problems with
nonlinear constraints. <em>JGO</em>, <em>85</em>(2), 283–313. (<a
href="https://doi.org/10.1007/s10898-022-01204-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parametric optimization problems appear in many areas of applications even though most of the existing solution methods for such problems are limited to problems with polyhedral constraints. In this article, a global solution strategy is proposed for a general convex multi-parametric problems with nonlinear constraints and bounded regions. The basic idea of the proposed approach is to obtain an approximate parametric solution based on the sensitivity analysis theory in the interior of the nonlinear feasible region, and on finding analytic parametric solutions on the boundaries of the nonlinear constraints. The method employs a barrier function reformulation technique to construct a barrier multi-parametric problem with polyhedral constraints. The proposed method also provides exact solutions to convex multi-parametric problems whose objective function and constraints are polynomials of up to third-degree in the optimization variables and quadratic in the parameters vector.},
  archive      = {J_JGO},
  author       = {Zewde, Addis Belete and Kassa, Semu Mitiku},
  doi          = {10.1007/s10898-022-01204-5},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {283-313},
  shortjournal = {J. Glob. Optim.},
  title        = {A novel approach for solving multi-parametric problems with nonlinear constraints},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Regularized sample average approximation for
high-dimensional stochastic optimization under low-rankness.
<em>JGO</em>, <em>85</em>(2), 257–282. (<a
href="https://doi.org/10.1007/s10898-022-01206-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns a high-dimensional stochastic programming (SP) problem of minimizing a function of expected cost with a matrix argument. To this problem, one of the most widely applied solution paradigms is the sample average approximation (SAA), which uses the average cost over sampled scenarios as a surrogate to approximate the expected cost. Traditional SAA theories require the sample size to grow rapidly when the problem dimensionality increases. Indeed, for a problem of optimizing over a p-by-p matrix, the sample complexity of the SAA is given by $${\widetilde{O}}(1)\cdot \frac{p^2}{\epsilon ^2}\cdot {polylog}(\frac{1}{\epsilon })$$ to achieve an $$\epsilon $$ -suboptimality gap, for some poly-logarithmic function $${polylog}(\,\cdot \,)$$ and some quantity $${\widetilde{O}}(1)$$ independent of dimensionality p and sample size n. In contrast, this paper considers a regularized SAA (RSAA) with a low-rankness-inducing penalty. We demonstrate that, when the optimal solution to the SP is of low rank, the sample complexity of RSAA is $${\widetilde{O}}(1)\cdot \frac{p}{\epsilon ^3}\cdot {polylog}(p,\,\frac{1}{\epsilon })$$ , which is almost linear in p and thus indicates a substantially lower dependence on dimensionality. Therefore, RSAA can be more advantageous than SAA especially for larger scale and higher dimensional problems. Due to the close correspondence between stochastic programming and statistical learning, our results also indicate that high-dimensional low-rank matrix recovery is possible generally beyond a linear model, even if the common assumption of restricted strong convexity is completely absent.},
  archive      = {J_JGO},
  author       = {Lee, Hung Yi and Hernandez, Charles and Liu, Hongcheng},
  doi          = {10.1007/s10898-022-01206-3},
  journal      = {Journal of Global Optimization},
  number       = {2},
  pages        = {257-282},
  shortjournal = {J. Glob. Optim.},
  title        = {Regularized sample average approximation for high-dimensional stochastic optimization under low-rankness},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Book review on “convex analysis and beyond. Volume i: Basic
theory,” a monograph by boris s. Mordukhovich and nguyen mau nam.
<em>JGO</em>, <em>85</em>(1), 251–255. (<a
href="https://doi.org/10.1007/s10898-022-01234-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JGO},
  author       = {Yen, Nguyen Dong},
  doi          = {10.1007/s10898-022-01234-z},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {251-255},
  shortjournal = {J. Glob. Optim.},
  title        = {Book review on “Convex analysis and beyond. volume i: Basic theory”, a monograph by boris s. mordukhovich and nguyen mau nam},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Characterizations of set order relations and nonlinear
scalarizations via generalized oriented distance function in set
optimization. <em>JGO</em>, <em>85</em>(1), 235–249. (<a
href="https://doi.org/10.1007/s10898-022-01203-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to establish scalar characterizations of minimal, weak minimal and strict minimal solutions in terms of a generalized oriented distance function defined on sets in real normed linear space with respect to a point in the space. Further, we study the lower and upper semicontinuity of the generalized oriented distance function.},
  archive      = {J_JGO},
  author       = {Khushboo and Lalitha, C. S.},
  doi          = {10.1007/s10898-022-01203-6},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {235-249},
  shortjournal = {J. Glob. Optim.},
  title        = {Characterizations of set order relations and nonlinear scalarizations via generalized oriented distance function in set optimization},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimising portfolio diversification and dimensionality.
<em>JGO</em>, <em>85</em>(1), 185–234. (<a
href="https://doi.org/10.1007/s10898-022-01202-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new framework for portfolio diversification is introduced which goes beyond the classical mean-variance approach and portfolio allocation strategies such as risk parity. It is based on a novel concept called portfolio dimensionality that connects diversification to the non-Gaussianity of portfolio returns and can typically be defined in terms of the ratio of risk measures which are homogenous functions of equal degree. The latter arises naturally due to our requirement that diversification measures should be leverage invariant. We introduce this new framework and argue the benefits relative to existing measures of diversification in the literature, before addressing the question of optimizing diversification or, equivalently, dimensionality. Maximising portfolio dimensionality leads to highly non-trivial optimization problems with objective functions which are typically non-convex and potentially have multiple local optima. Two complementary global optimization algorithms are thus presented. For problems of moderate size and more akin to asset allocation problems, a deterministic Branch and Bound algorithm is developed, whereas for problems of larger size a stochastic global optimization algorithm based on Gradient Langevin Dynamics is given. We demonstrate analytically and through numerical experiments that the framework reflects the desired properties often discussed in the literature.},
  archive      = {J_JGO},
  author       = {Barkhagen, M. and García, S. and Gondzio, J. and Kalcsics, J. and Kroeske, J. and Sabanis, S. and Staal, A.},
  doi          = {10.1007/s10898-022-01202-7},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {185-234},
  shortjournal = {J. Glob. Optim.},
  title        = {Optimising portfolio diversification and dimensionality},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the second-order optimality conditions for
multi-objective optimal control problems with mixed pointwise
constraints. <em>JGO</em>, <em>85</em>(1), 155–183. (<a
href="https://doi.org/10.1007/s10898-022-01201-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we derive second-order necessary optimality conditions and second-order sufficient optimality condition for locally Pareto solutions to a class of multi-objective optimal control problems with mixed pointwise constraints. The necessary optimality conditions for the multi-objective optimal control problem are established via optimality conditions of a specific vector optimization problem in Banach spaces, which is proved directly without using the scalarization method.},
  archive      = {J_JGO},
  author       = {Kien, Bui Trong and Binh, Trinh Duy},
  doi          = {10.1007/s10898-022-01201-8},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {155-183},
  shortjournal = {J. Glob. Optim.},
  title        = {On the second-order optimality conditions for multi-objective optimal control problems with mixed pointwise constraints},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DC auxiliary principle methods for solving lexicographic
equilibrium problems. <em>JGO</em>, <em>85</em>(1), 129–153. (<a
href="https://doi.org/10.1007/s10898-022-01200-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present DC (difference of convex functions) auxiliary principle methods for solving lexicographic equilibrium problems. Under the strongly monotone and Lipchitz-type assumptions of the cost bifunction, we study the convergence of the sequence generated by the proposed algorithms to a unique solution of the considered lexicographic equilibrium problem. Moreover, we also study the asymptotic behavior of the algorithm for solving the considered problem under the presence of computational errors. Finally, we give some numerical experiments to illustrate the behaviour of the proposed algorithms and provide their comparison with some known algorithms.},
  archive      = {J_JGO},
  author       = {Anh, Pham Ngoc and Ansari, Qamrul Hasan and Tu, Ho Phi},
  doi          = {10.1007/s10898-022-01200-9},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {129-153},
  shortjournal = {J. Glob. Optim.},
  title        = {DC auxiliary principle methods for solving lexicographic equilibrium problems},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On maximum-sum matchings of points. <em>JGO</em>,
<em>85</em>(1), 111–128. (<a
href="https://doi.org/10.1007/s10898-022-01199-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Huemer et al. (Discrete Mathematics, 2019) proved that for any two point sets R and B with $$|R|=|B|$$ , the perfect matching that matches points of R with points of B, and maximizes the total squared Euclidean distance of the matched pairs, has the property that all the disks induced by the matching have a common point. Each pair of matched points $$p\in R$$ and $$q\in B$$ induces the disk of smallest diameter that covers p and q. Following this research line, in this paper we consider the perfect matching that maximizes the total Euclidean distance. First, we prove that this new matching for R and B does not always ensure the common intersection property of the disks. Second, we extend the study of this new matching for sets of 2n uncolored points in the plane, where a matching is just a partition of the points into n pairs. As the main result, we prove that in this case all disks of the matching do have a common point.},
  archive      = {J_JGO},
  author       = {Bereg, Sergey and Chacón-Rivera, Oscar P. and Flores-Peñaloza, David and Huemer, Clemens and Pérez-Lantero, Pablo and Seara, Carlos},
  doi          = {10.1007/s10898-022-01199-z},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {111-128},
  shortjournal = {J. Glob. Optim.},
  title        = {On maximum-sum matchings of points},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Second order analysis for robust inclusion systems and
applications. <em>JGO</em>, <em>85</em>(1), 81–110. (<a
href="https://doi.org/10.1007/s10898-022-01197-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study an uncertain inequality system, where the input data are uncertain and belong to prescribed uncertainty sets. Using the deterministic approach in robust optimization, we treat this uncertain system by examining the so-called robust system. This approach enables us to compute the second order tangent sets for the solution set of the robust system and then obtain the second order epi-subderivative for the indicator function of its solution set. In this way, we are able to calculate the graphical derivative for the normal cone mapping of solution set of the robust system under certain qualification conditions. As applications, we establish second order necessary and sufficient optimality conditions, and derive necessary and sufficient conditions for stability properties such as the isolated calmness of optimization problems involving uncertain constraints under weak qualification conditions.},
  archive      = {J_JGO},
  author       = {Thinh, V. D. and Chuong, T. D. and Anh, N. L. H.},
  doi          = {10.1007/s10898-022-01197-1},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {81-110},
  shortjournal = {J. Glob. Optim.},
  title        = {Second order analysis for robust inclusion systems and applications},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Regrets of proximal method of multipliers for online
non-convex optimization with long term constraints. <em>JGO</em>,
<em>85</em>(1), 61–80. (<a
href="https://doi.org/10.1007/s10898-022-01196-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The online optimization problem with non-convex loss functions over a closed convex set, coupled with a set of inequality (possibly non-convex) constraints is a challenging online learning problem. A proximal method of multipliers with quadratic approximations (named as OPMM) is presented to solve this online non-convex optimization with long term constraints. Regrets of the violation of Karush-Kuhn-Tucker conditions of OPMM for solving online non-convex optimization problems are analyzed. Under mild conditions, it is shown that this algorithm exhibits $${{\mathcal {O}}}(T^{-1/8})$$ Lagrangian gradient violation regret, $${{\mathcal {O}}}(T^{-1/8})$$ constraint violation regret and $${{\mathcal {O}}}(T^{-1/4})$$ complementarity residual regret if parameters in the algorithm are properly chosen, where T denotes the number of time periods. For the case that the objective is a convex quadratic function, we demonstrate that the regret of the objective reduction can be established even the feasible set is non-convex. For the case when the constraint functions are convex, if the solution of the subproblem in OPMM is obtained by solving its dual, OPMM is proved to be an implementable projection method for solving the online non-convex optimization problem.},
  archive      = {J_JGO},
  author       = {Zhang, Liwei and Liu, Haoyang and Xiao, Xiantao},
  doi          = {10.1007/s10898-022-01196-2},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {61-80},
  shortjournal = {J. Glob. Optim.},
  title        = {Regrets of proximal method of multipliers for online non-convex optimization with long term constraints},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Packing convex polygons in minimum-perimeter convex hulls.
<em>JGO</em>, <em>85</em>(1), 39–59. (<a
href="https://doi.org/10.1007/s10898-022-01194-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of packing a given set of freely translated and rotated convex polygons in a minimum-perimeter convex polygon (in particular the minimum-perimeter convex hull) is introduced. A mathematical model of the problem using the phi-function technique is provided. Problem instances with up to 6 convex polygons are solved by the global NLP solver BARON to get a minimum-perimeter convex hull. Numerical experiments for larger instances are reported using the local NLP solver IPOPT.},
  archive      = {J_JGO},
  author       = {Kallrath, Josef and Romanova, Tatiana and Pankratov, Alexander and Litvinchev, Igor and Infante, Luis},
  doi          = {10.1007/s10898-022-01194-4},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {39-59},
  shortjournal = {J. Glob. Optim.},
  title        = {Packing convex polygons in minimum-perimeter convex hulls},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fast and deterministic algorithm for knapsack-constrained
monotone DR-submodular maximization over an integer lattice.
<em>JGO</em>, <em>85</em>(1), 15–38. (<a
href="https://doi.org/10.1007/s10898-022-01193-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a knapsack-constrained maximization problem of a nonnegative monotone DR-submodular function f over a bounded integer lattice $$[\varvec{B}]$$ in $${\mathbb {R}}_+^n$$ , $$\max {f({\varvec{x}}): {\varvec{x}}\in [\varvec{B}] \text {~and~} \sum _{i=1}^n {\varvec{x}}(i)c(i)\le 1}$$ , where n is the cardinality of a ground set N and $$c(\cdot )$$ is a cost function defined on N. Soma and Yoshida [Math. Program., 172 (2018), pp. 539-563] present a $$(1-e^{-1}-O(\epsilon ))$$ -approximation algorithm for this problem by combining threshold greedy algorithm with partial element enumeration technique. Although the approximation ratio is almost tight, their algorithm runs in $$O(\frac{n^3}{\epsilon ^3}\log ^3 \tau [\log ^3 \left\| \varvec{B}\right\| _\infty + \frac{n}{\epsilon }\log \left\| \varvec{B}\right\| _\infty \log \frac{1}{\epsilon c_{\min }}])$$ time, where $$c_{\min }=\min _i c(i)$$ and $$\tau $$ is the ratio of the maximum value of f to the minimum nonzero increase in the value of f. Besides, Ene and Nguy $$\tilde{\check{\text {e}}}$$ n [ arXiv:1606.08362 , 2016] indirectly give a $$(1-e^{-1}-O(\epsilon ))$$ -approximation algorithm with $$O({(\frac{1}{\epsilon })}^{ O(1/\epsilon ^4)}n \log {\Vert \varvec{B}\Vert }_\infty \log ^2{(n \log {\Vert \varvec{B}\Vert }_\infty )})$$ time. But their algorithm is random. In this paper, we make full use of the DR-submodularity over a bounded integer lattice, carry forward the greedy idea in the continuous process and provide a simple deterministic rounding method so as to obtain a feasible solution of the original problem without loss of objective value. We present a deterministic algorithm and theoretically reduce its running time to a new record, $$O\big ((\frac{1}{\epsilon })^{O({1}/{\epsilon ^5})} \cdot n \log \frac{1}{c_{\min }} \log {\Vert \varvec{B}\Vert _\infty }\big )$$ , with the same approximate ratio.},
  archive      = {J_JGO},
  author       = {Gong, Suning and Nong, Qingqin and Bao, Shuyu and Fang, Qizhi and Du, Ding-Zhu},
  doi          = {10.1007/s10898-022-01193-5},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {15-38},
  shortjournal = {J. Glob. Optim.},
  title        = {A fast and deterministic algorithm for knapsack-constrained monotone DR-submodular maximization over an integer lattice},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finding the set of global minimizers of a piecewise affine
function. <em>JGO</em>, <em>85</em>(1), 1–13. (<a
href="https://doi.org/10.1007/s10898-022-01191-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coexhausters are families of convex compact sets that allow one to represent the approximation of the increment of a function at a given point in the form of minmax or maxmin of affine functions. We demonstrate that this representation can be used to define a piecewise affine function and therefore coexhausters are a natural technique for studying the problem of finding a global minimum of piecewise affine functions. All the conditions and methods in the current study were obtained by means of coexhausters theory. Firstly, we apply coexhauster based conditions to state and prove necessary and sufficient conditions for a piecewise affine function to be bounded from below. Secondly, we use coexhausters to construct a simple method which allows one to get the minimum value of the studied function and the corresponding set of all its global minimizers. Illustrative numerical examples are provided throughout the paper.},
  archive      = {J_JGO},
  author       = {Abbasov, Majid E.},
  doi          = {10.1007/s10898-022-01191-7},
  journal      = {Journal of Global Optimization},
  number       = {1},
  pages        = {1-13},
  shortjournal = {J. Glob. Optim.},
  title        = {Finding the set of global minimizers of a piecewise affine function},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
