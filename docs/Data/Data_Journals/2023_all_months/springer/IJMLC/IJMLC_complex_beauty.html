<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJMLC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijmlc---273">IJMLC - 273</h2>
<ul>
<li><details>
<summary>
(2023). Multi-scale fusion transformer based weakly supervised
hashing learning for instance retrieval. <em>IJMLC</em>,
<em>14</em>(12), 4431–4442. (<a
href="https://doi.org/10.1007/s13042-023-01907-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instance retrieval is concerned with obtaining representations of instances (objects) in images and using them for similarity comparisons between instances. However, most methods require instance-level categories to train the model, which increases the burden of annotation. Along with the advancement of convolutional neural networks and transformers in computer vision, in this work, we propose a hierarchical with a spatial pyramidal structure for weakly supervised multi-instance hash learning. It merges the advantages of local and multi-scale perception on CNN with the global field of view on Transformer. Further, it leverages the principle of multi-instance learning, allowing the proposed model to implement an instance-level hash mapping capability in a weakly supervised learning manner. The experimental results on three public datasets achieved more improved results compared to the typical methods, validating the effectiveness of the proposed method.},
  archive      = {J_IJMLC},
  author       = {Lv, Yuanhai and Jiao, Chen and Zhao, Wanqing and Zhao, Wei and Guan, Ziyu and He, Xiaofei},
  doi          = {10.1007/s13042-023-01907-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4431-4442},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-scale fusion transformer based weakly supervised hashing learning for instance retrieval},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient dual domain image denoising via SURE-based
optimization. <em>IJMLC</em>, <em>14</em>(12), 4417–4430. (<a
href="https://doi.org/10.1007/s13042-023-01902-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dual domain image denoising (DDID) is an effective denoising method by utilizing bilateral filter (BF) and frequency-based filtering method. DDID-based methods have achieved competitive results compared with state-of-the-art denoising methods due to its simplicity and effectiveness. However, the optimal parameter selection of DDID-based methods has less been explored, thus resulting in its sensitiveness to noise level and image content. To address this issue, we study the parameter analysis for DDID, and propose an adaptive DDID via Stein’s unbiased risk estimate principle. Specifically, we here drive Stein’s unbiased risk estimate (SURE) for DDID to tune the parameters adaptively. The SURE can be used to optimize the parameters by monitoring the mean square error (MSE) of images with additive white Gaussian noise. Due to the SURE principle, we can measure the MSE without access to the noise-free signal (ground truth), thus leading to the optimal parameters in the minimum MSE sense. Experimental results demonstrate the accuracy of the SURE and effectiveness of our SURE-based DDID.},
  archive      = {J_IJMLC},
  author       = {Dai, Tao and Li, Yanjie},
  doi          = {10.1007/s13042-023-01902-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4417-4430},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Efficient dual domain image denoising via SURE-based optimization},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Convergence analysis for sparse pi-sigma neural network
model with entropy error function. <em>IJMLC</em>, <em>14</em>(12),
4405–4416. (<a
href="https://doi.org/10.1007/s13042-023-01901-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a high-order neural network, the Pi-sigma neural network has demonstrated its capacities for fast learning and strong nonlinear processing. In this paper, a new algorithm is proposed for Pi-sigma neural networks with entropy error functions based on $$L_{0}$$ regularization. One of the key features of the proposed algorithm is the use of an entropy error function instead of the more common square error function, which is different from those in most existing literature. At the same time, the proposed algorithm also employs $$L_{0}$$ regularization as a means of ensuring the efficiency of the network. Based on the gradient method, the monotonicity, and strong and weak convergence of the network are strictly proved by theoretical analysis and experimental verification. Experiments on applying the proposed algorithm to both classification and regression problems have demonstrated the improved performance of the algorithm.},
  archive      = {J_IJMLC},
  author       = {Fan, Qinwei and Zheng, Fengjiao and Huang, Xiaodi and Xu, Dongpo},
  doi          = {10.1007/s13042-023-01901-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4405-4416},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Convergence analysis for sparse pi-sigma neural network model with entropy error function},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). General fine-grained event detection based on fusion of
multi-information representation and attention mechanism.
<em>IJMLC</em>, <em>14</em>(12), 4393–4403. (<a
href="https://doi.org/10.1007/s13042-023-01900-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event extraction is an important field in information extraction, which aims to extract key information from unstructured text automatically. Event extraction is mainly divided into trigger identification and classification. The existing models are deficient in sentence representation in the initial word embeddings training process, which makes it difficult to capture the deep bidirectional representation and can’t handle the semantic information of the context well, thus affecting the performance of event detection. In this paper, a model BMRMC (BERT + Mean pooling layer + Relative position in multi-head attention + CRF) based on multi-information representation and attention mechanism is proposed. Firstly, the BERT pre-training model based on a bidirectional training transformer is used to embed words and extract word-level features. Then the sentence-level semantic representation is fused by mean pooling layer. In addition, relative position is combined with multi-head attention, which can strengthen the connection of contents. Finally, the sequences are labeled by CRF based on the BIO-labeling mechanism. The experimental results show that the proposed model BMRMC improves the performance of event detection, and the F value on the MAVEN dataset is 67.74\%, which achieves state-of-the-art performance in the general fine-grained event detection task.},
  archive      = {J_IJMLC},
  author       = {He, Xinyu and Yan, Ge and Si, Changfu and Ren, Yonggong},
  doi          = {10.1007/s13042-023-01900-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4393-4403},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {General fine-grained event detection based on fusion of multi-information representation and attention mechanism},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust stability of complex-valued fractional-order neural
networks with uncertain parameters based on new integral inequalities.
<em>IJMLC</em>, <em>14</em>(12), 4377–4391. (<a
href="https://doi.org/10.1007/s13042-023-01899-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the stability of complex-valued (CV) fractional-order neural networks with uncertain parameters and neutral-type delay. Firstly, two improved reciprocally convex inequalities (RCIs) and three less-conservative integral inequalities are generalized to the complex-valued domain. Secondly, the existence, uniqueness and delay-independent robust stability conditions of the addressed networks are proposed based on the CV homeomorphism theorem. Thirdly, by constructing a Lyapunov–Krasovskii functional, delay-dependent robust stability conditions of the considered networks are derived by utilizing the improved complex-valued RCIs and integral inequalities. Finally, two simulation examples are given to show the effectiveness and practicality of the presented method.},
  archive      = {J_IJMLC},
  author       = {Wang, Yushan and Zheng, Cheng-De and Lin, Meiyan},
  doi          = {10.1007/s13042-023-01899-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4377-4391},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Robust stability of complex-valued fractional-order neural networks with uncertain parameters based on new integral inequalities},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). UniSAr: A unified structure-aware autoregressive language
model for text-to-SQL semantic parsing. <em>IJMLC</em>, <em>14</em>(12),
4361–4376. (<a
href="https://doi.org/10.1007/s13042-023-01898-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing text-to-SQL semantic parsers are typically designed for particular settings such as handling queries that span multiple tables, domains, or turns which makes them ineffective when applied to different settings. We present UniSAr (Unified Structure-Aware Autoregressive Language Model), which benefits from directly using an off-the-shelf language model architecture and demonstrates consistently high performance under different settings. Specifically, UniSAr extends existing autoregressive language models to incorporate two non-invasive extensions to make them structure-aware: (1) adding structure mark to encode database schema, conversation context, and their relationships; (2) constrained decoding to decode well-structured SQL for a given database schema. On seven well-known text-to-SQL datasets covering multi-domain, multi-table, and multi-turn, UniSAr demonstrates highly comparable or better performance to the most advanced specifically-designed text-to-SQL models.},
  archive      = {J_IJMLC},
  author       = {Dou, Longxu and Gao, Yan and Pan, Mingyang and Wang, Dingzirui and Che, Wanxiang and Lou, Jian-Guang and Zhan, Dechen},
  doi          = {10.1007/s13042-023-01898-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4361-4376},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {UniSAr: A unified structure-aware autoregressive language model for text-to-SQL semantic parsing},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature selection using symmetric uncertainty and hybrid
optimization for high-dimensional data. <em>IJMLC</em>, <em>14</em>(12),
4339–4360. (<a
href="https://doi.org/10.1007/s13042-023-01897-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, when handling high-dimensional data, it has become extremely difficult to search this optimal subset of selected features due to the restriction of reducing the exponential increase of the search procedure, and most of those feature selection models neglect the interactions of features or feature and decision class. This paper develops a novel feature selection approach using symmetric uncertainty and hybrid optimization for high-dimensional data (FSUHO) for high-dimensional data. First, to fully reflect the interaction relationship of features or feature and decision class, the F-relevance between features and the C-correlation between feature and decision class based on the symmetric uncertainty are constructed to remove those redundant features. Then, a strong correlation threshold is improved based on the C-correlation and random coefficient to prevent the removal of the effective features in this first stage. Second, to decrease this expensive computational consumption, one criterion for judging a weakly correlated feature is designed to sort all features, and another criterion is developed to select the class center. The similarity between features and class centers is calculated, and similar features are clustered into one class. Then, the symmetric uncertainty correlation-based feature clustering model can be constructed in this second stage. In the third stage, a hybrid optimization approach of particle swarm optimizer (PSO) and wild horse optimizer (WHO) for feature selection is proposed, where the association-guided group initialization probability with a multiobjective optimized particle selection scheme is defined as a criterion for the PSO in selecting stallion particles for the WHO, and the improved WHO is developed by integrating the nonlinear inertial weight factor and the Brownian motion operator to obtain the optimal subset of selected features. Finally, a novel three-stage feature selection algorithm is developed. Experimental results apply to 16 datasets prove the efficiency of FSUHO in tackling high-dimensional feature selection problems in metrics of classification accuracy and running time.},
  archive      = {J_IJMLC},
  author       = {Sun, Lin and Sun, Shujing and Ding, Weiping and Huang, Xinyue and Fan, Peiyi and Li, Kunyu and Chen, Leqi},
  doi          = {10.1007/s13042-023-01897-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4339-4360},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Feature selection using symmetric uncertainty and hybrid optimization for high-dimensional data},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fuzzy clustering ensemble selection based on active
full-link similarity. <em>IJMLC</em>, <em>14</em>(12), 4325–4337. (<a
href="https://doi.org/10.1007/s13042-023-01896-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In fuzzy clustering ensemble, the quality of fuzzy base clustering has an important influence on the performance of the final clustering result. Due to the performance of fuzzy clustering is affected by the initial parameters and fuzzy factors, it may cause unstable clustering results such as unsatisfactory data affiliation, and large differences with the distribution of the real data set. In addition, how to use fuzzy ensemble information to determine the similarity among samples effectively plays a crucial role in the generation of co-association matrix elements. In view of the above problems, combined with the compactness, separation and overlap in the evaluation index of fuzzy clustering, an optimized fuzzy clustering evaluation index is designed to select high quality fuzzy base clustering members to participate the final fusion. Then, the concept of sample attribution clarity is proposed, and the attribution clarity of each sample in the fuzzy base clustering set is learned actively. For samples with different attribution clarity, different full-link similarity measurement methods between samples are designed to further reduce the uncertainty of samples. Finally, the clustering results are obtained by the agglomerative hierarchical clustering. In order to verify the effectiveness of the proposed method, ten data sets are used to conduct experiments. Experiments show that the results obtained by the proposed method are closer to the real distribution structure of the data set in most experimental dataset, and are not sensitive to the diversity of base clustering members, and have good robustness.},
  archive      = {J_IJMLC},
  author       = {Xu, Li and Yan, XiaoFei and Huang, Jie and Wang, Yanqiu and Li, Zeng},
  doi          = {10.1007/s13042-023-01896-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4325-4337},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A fuzzy clustering ensemble selection based on active full-link similarity},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Face alignment combined with shape constraints and gaussian
heatmap. <em>IJMLC</em>, <em>14</em>(12), 4311–4324. (<a
href="https://doi.org/10.1007/s13042-023-01895-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face alignment is a hot topic in the field of computer vision because it is an important intermediate step in face recognition, 3D face reconstruction, etc. Its task is to locate the key parts of the human face with landmarks. For the lack of shape constraints and weak correlation between landmarks in face alignment based on Gaussian heatmap regression, this paper presents a novel method combining shape constraints with Gaussian heatmap regression network. Our method consists of a 3D model parameter prediction network, an attention map generator, and a Gaussian heatmap regression network. The 3D model parameter prediction network fits the 3D face model and sample face. The attention map generator can generate an attention map containing shape constraint information based on the fitting results. The attention map and the original image will be used together as the input of the Gaussian heatmap regression network to achieve coarse to fine face alignment. The experimental results demonstrate that our method has a lower error on multiple mainstream datasets and is robust for some complex samples compared with the Gaussian heatmap regression method without shape constraints.},
  archive      = {J_IJMLC},
  author       = {Di, Lan and Zhang, Jiahui and Liang, Jiuzhen},
  doi          = {10.1007/s13042-023-01895-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4311-4324},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Face alignment combined with shape constraints and gaussian heatmap},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Similarity graph-based max-flow and duality approaches for
semi-supervised data classification and image segmentation.
<em>IJMLC</em>, <em>14</em>(12), 4285–4310. (<a
href="https://doi.org/10.1007/s13042-023-01894-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The max-flow problem entails the computation of a maximum feasible flow from a source to a sink through a network under constraints. Its connection to total variation presents an opportunity to apply the problem to machine learning tasks by incorporating a similarity graph-based setting. In this paper, we integrate max-flow and duality techniques, similarity graph-based frameworks, semi-supervised procedures, class size information and class homogeneity terms to derive three algorithms for machine learning tasks, such as classification, and image segmentation. The first algorithm involves similarity graph-based max-flow incorporating supervised constraints and class size information. The second method involves a duality approach and global minimization of similarity graph-based total variation problems incorporating class size information. The third algorithm involves graph-based convex optimization via max-flow techniques for image segmentation problems involving region parameters, in the case the latter is unknown. An important advantage of the methods is that they require only a small set of labeled samples for good accuracy, in part due to the integration of graph-based and semi-supervised techniques; this is an important advantage due to the scarcity of labeled data. Moreover, some of the proposed algorithms are based on global minimization, and are also able to incorporate class size information, which often improves performance. In addition, the methods perform well on both large and small data sets, the latter of which can result in poor performances for learning methods due to a decreased ability to learn from observed data. The proposed methods are validated using benchmark data sets and are compared favorably to recent methods.},
  archive      = {J_IJMLC},
  author       = {Merkurjev, Ekaterina},
  doi          = {10.1007/s13042-023-01894-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4285-4310},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Similarity graph-based max-flow and duality approaches for semi-supervised data classification and image segmentation},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel stratification clustering algorithm based on a new
local density estimation method and an improved local inter-cluster
distance measure. <em>IJMLC</em>, <em>14</em>(12), 4251–4283. (<a
href="https://doi.org/10.1007/s13042-023-01893-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently clustering for datasets with different shapes, densities and noises has attracted more and more attention from scholars. However, most current clustering algorithms improve the clustering performance at the expense of the simplicity, and cannot balance well between the clustering quality and the operability for the users. To solve this problem, we propose a new algorithm called stratification clustering based on density, hierarchy and partition (SDHP) by effectively integrating the advantages of the density-based, hierarchical-based and partition-based clustering. First, a new parameter-free local density estimation strategy based on the bidirectional natural neighbor relationship named local density based on natural neighbor (NN-LD) is proposed to identify the core part of each sub-cluster. Then, a new stratification strategy based on the NN-LD Stratification-NN-LD (S-NN-LD) is proposed to divide the entire dataset into two layers, the core layer and the edge layer, to simplify the dataset structure and make the algorithm robust to noises. Next, the hierarchical-based single-linkage algorithm is adopted in the core layer to obtain the initial clustering result since it has advantages on clustering the datasets with various shapes and densities. Finally, to improve the clustering accuracy of samples in the edge layer, a combination of a new local inter-cluster distance measure based on the average of neighbor distances and the partitioning clustering is adopted to match these samples to the sub-clusters in the initial clustering result. The experiments on twenty datasets show that the SDHP has better clustering accuracy, and can be applied in practice well compared with four popular hierarchical clustering algorithms, four recent density-based clustering algorithms, and a state-of-the-art partitioning clustering algorithm. The source code can be downloaded from https://github.com/qi111678/SDHP .},
  archive      = {J_IJMLC},
  author       = {Qi, Jianfang and Li, Yue and Jin, Haibin and Feng, Jianying and Tian, Dong and Mu, Weisong},
  doi          = {10.1007/s13042-023-01893-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4251-4283},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel stratification clustering algorithm based on a new local density estimation method and an improved local inter-cluster distance measure},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-similarity feature based few-shot learning via
hierarchical relation network. <em>IJMLC</em>, <em>14</em>(12),
4237–4249. (<a
href="https://doi.org/10.1007/s13042-023-01892-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning aims to recognize new visual concepts with a small number of labeled samples. The hierarchical structure based on inter-class labels performs well in many few-shot learning models. However, intra-class features are similar and difficult to distinguish, which is important for mining the correlation and independence between intra-class features in the scene of sparse data. In this paper, we propose a few-shot learning model with a self-similarity feature representation by a hierarchical relation network, which considers inter-class labels and intra-class features to guide few-shot learning. First, we introduce a self-similarity feature representation module as the intermediate feature transform in the neural network. Unlike the traditional model, it extracts specific feature information from intra-class features. Second, we leverage the inter-class label hierarchical structure as important auxiliary information to establish a hierarchical relation network metric module. The module uses coarse-grained information to guide fine-grained classification, which effectively alleviates the problem of insufficient data. Experimental results show that our model improves the classification accuracy, reaching 58.68\% on the tieredImageNet dataset.},
  archive      = {J_IJMLC},
  author       = {Zhong, Yangqing and Su, Yuling and Zhao, Hong},
  doi          = {10.1007/s13042-023-01892-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4237-4249},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Self-similarity feature based few-shot learning via hierarchical relation network},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A causality-inspired data augmentation approach to
cross-domain burr detection using randomly weighted shallow networks.
<em>IJMLC</em>, <em>14</em>(12), 4223–4236. (<a
href="https://doi.org/10.1007/s13042-023-01891-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The challenge of generalizing deep learning models to new, unseen areas or domains is common in material removal applications. This paper focuses on the specific problem of detecting burrs after material removal operations when training data is only available from a single operation. To address this issue, we propose a causality-based data augmentation approach for cross-domain burr image detection. The process involves using a combination of shallow networks to create a deep neural network resilient to differences in image intensity and texture. Additionally, we use various appearance transformations to enhance the training images further. However, we also demonstrate how incorrect correlations between objects in an image can negatively impact the model&#39;s robustness. To address this, we intervene in the causal chain of events by resampling the images of potentially linked objects. Hence it eliminates any erroneous correlations and helps the model to make more accurate predictions. To validate our approach, we perform experiments on three cross-domain burr detection tasks: milling, press punching, and casting. The results show that our approach consistently outperforms other methods when tested on unknown domains.},
  archive      = {J_IJMLC},
  author       = {Rahul, M. R. and Chiddarwar, Shital S.},
  doi          = {10.1007/s13042-023-01891-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4223-4236},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A causality-inspired data augmentation approach to cross-domain burr detection using randomly weighted shallow networks},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised concept drift detection method based on robust
random cut forest. <em>IJMLC</em>, <em>14</em>(12), 4207–4222. (<a
href="https://doi.org/10.1007/s13042-023-01890-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevalence of streams in practical applications is rapidly increasing, making stream data mining increasingly important. However, unlike the static datasets used in machine learning, streams are dynamic and tend to exhibit non-stationarity, with their underlying distributions changing over time over time. As a result, the previous models are not suitable anymore and the prediction performance decreases sharply. This phenomenon is referred to as concept drift, which poses a crucial challenge for stream mining. Hence, taking some measures to deal with concept drift is urgent and essential. Most approaches are dedicated to handling concept drift with true labeled data. However, the unavailability or latency of labels and the costly labeling expense in the real world remain a challenge. In this paper, we propose an unsupervised drift detection approach: concept drift detection method based on robust random cut forest and t-test (RFTT). It uses a sliding window and Robust Random Cut Forest (RRCF) to compute anomaly ratio and anomaly score to detect drift. Fourteen popular algorithms have been used for comprehensive experiments on 11 classic datasets, effectively validating our proposed method. The results show that RFTT performs well on most datasets and has the highest average ranking.},
  archive      = {J_IJMLC},
  author       = {Pang, Zijuan and Cen, Jianming and Yi, Ming},
  doi          = {10.1007/s13042-023-01890-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4207-4222},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Unsupervised concept drift detection method based on robust random cut forest},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IST-PTEPN: An improved pedestrian trajectory and endpoint
prediction network based on spatio-temporal information. <em>IJMLC</em>,
<em>14</em>(12), 4193–4206. (<a
href="https://doi.org/10.1007/s13042-023-01889-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of pedestrian trajectories in complicated dynamic situations has garnered a great deal of interest among researchers and academics, and it plays a crucial role in numerous domains, including autonomous vehicles, intelligent robotics, and video surveillance. In this study, we offer the IST-PTEPN, a trainable and interpretable end-to-end model for predicting pedestrian trajectory. IST-PTEPN encodes the spatial and temporal characteristics of pedestrian trajectories and surrounding scenes with CNN and Transformer, then feeds the encoded vectors into Endpoint Classify CNN to generate predicted endpoints of the trajectories, and finally combines TCN and GAN to generate high-quality pedestrian trajectories. Experiments on two public datasets, ETH and UCY, demonstrate that our IST-PTEPN pedestrian trajectory prediction and endpoint prediction method outperforms the mainstream state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Yang, Xin and Fan, Jiangfeng and Xing, Siyuan},
  doi          = {10.1007/s13042-023-01889-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4193-4206},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {IST-PTEPN: An improved pedestrian trajectory and endpoint prediction network based on spatio-temporal information},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vulnerable point detection and repair against adversarial
attacks for convolutional neural networks. <em>IJMLC</em>,
<em>14</em>(12), 4163–4192. (<a
href="https://doi.org/10.1007/s13042-023-01888-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, convolutional neural networks have been shown to be sensitive to artificially designed perturbations that are imperceptible to the naked eye. Whether it is image classification, semantic segmentation, or object detection, all of them will face such problem. The existence of adversarial examples raises questions about the security of smart applications. Some works have paid attention to this problem and proposed several defensive strategies to resist adversarial attacks. However, no one explored the vulnerable area of the model under multiple attacks. In this work, we fill this gap by exploring the vulnerable areas of the model, which is vulnerable to adversarial attacks. Specifically, under various attack methods with different strengths, we conduct extensive experiments on two datasets based on three different networks and illustrate some phenomena. Besides, by exploiting the Siamese Network, we propose a novel approach to more intuitively discover the deficiencies of the model. Moreover, we further provide a novel adaptive vulnerable point repair method to improve the adversarial robustness of the model. Extensive experimental results show that our proposed method can effectively improve the adversarial robustness of the model.},
  archive      = {J_IJMLC},
  author       = {Gao, Jie and Xia, Zhaoqiang and Dai, Jing and Dang, Chen and Jiang, Xiaoyue and Feng, Xiaoyi},
  doi          = {10.1007/s13042-023-01888-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4163-4192},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Vulnerable point detection and repair against adversarial attacks for convolutional neural networks},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Structured deep learning based object-specific distance
estimation from a monocular image. <em>IJMLC</em>, <em>14</em>(12),
4151–4161. (<a
href="https://doi.org/10.1007/s13042-023-01887-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distance calculation is a critical link in the research fields of object trajectory prediction, automatic driving obstacle avoidance, and so on. However, the research on distance using deep learning methods has yet to attract wide attention. The accuracy of traditional distance estimation algorithms based on the optical principle and mathematical modeling is low in practical applications, mainly the curve or slope of the road surface. This paper addresses the challenging distance estimation problem by developing an end-to-end structured model to directly predict the distance for objects in a given image. Besides, the traditional mathematical modeling process is replaced by this learning-based method. To facilitate the research on this task, we construct the extended distance datasets by KITTI (Karlsruhe Institute of Technology and Toyota Technological Institute) and NYU(Nathan Silberman, Pushmeet Kohli, Derek Hoiem, Rob Fergus) Depth V2 distance datasets. Experimental results demonstrate that the structured learning model has higher accuracy than the traditional algorithm in different distance ranges and better performance for curves and ramps. Moreover, improving neural network performance will be the direction of improving the model in the future.},
  archive      = {J_IJMLC},
  author       = {Shi, Yu and Lin, Tao and Chen, Biao and Wang, Ruixia and Zhang, Yabo},
  doi          = {10.1007/s13042-023-01887-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4151-4161},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Structured deep learning based object-specific distance estimation from a monocular image},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PDR-SMOTE: An imbalanced data processing method based on
data region partition and k nearest neighbors. <em>IJMLC</em>,
<em>14</em>(12), 4135–4150. (<a
href="https://doi.org/10.1007/s13042-023-01886-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development and progress of machine learning, classification algorithms are commonly used. One of the main factors that affect classification algorithms is imbalanced data. The Synthetic Minority Oversampling Technique (SMOTE) is considered to be a benchmark in resolving the problem of imbalanced data. Although the SMOTE algorithm performs well on most classification tasks, it also has the disadvantage of introducing new noisy instances and blurring the boundary between the majority class and the minority class. To solve such problems, in this paper, the PDR-SMOTE algorithm is proposed based on SMOTE algorithm which divides the sample space into safety region, boundary region and noisy region by K nearest neighbors algorithm (KNN). Delete the instances in the noisy region, use the SMOTE algorithm for the data synthesis of minority class instances in the safety region, and when the boundary region instances are used to synthesize the minority class instances, the PDR-SMOTE algorithm is used to make the newly synthesized instances related to the safety region instances. Data region partition and different processing in different regions can effectively avoid generating noisy instances and avoid blurring the boundary between the minority class and the majority class. In experiments on 24 imbalanced data sets, the PDR-SMOTE algorithm shows promising results in Recall, F-measure, G-mean and AUC in comparison with several common imbalanced data processing algorithms when using Support Vector Machine (SVM) and Random Forest (RF) as classifiers. Meanwhile, the results of the significant analysis show that the proposed PDR-SMOTE algorithm is better than other SMOTE variant algorithms.},
  archive      = {J_IJMLC},
  author       = {Zhou, Hongfang and Wu, Zongling and Xu, Ningning and Xiao, Hao},
  doi          = {10.1007/s13042-023-01886-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4135-4150},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {PDR-SMOTE: An imbalanced data processing method based on data region partition and k nearest neighbors},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-perspective contrastive learning framework guided by
sememe knowledge and label information for sarcasm detection.
<em>IJMLC</em>, <em>14</em>(12), 4119–4134. (<a
href="https://doi.org/10.1007/s13042-023-01884-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sarcasm is a prevailing rhetorical device that intentionally uses words that literally meaning opposite the real meaning. Due to this deliberate ambiguity, accurately detecting sarcasm can encourage the comprehension of users’ real intentions. Therefore, sarcasm detection is a critical and challenging task for sentiment analysis. In previous research, neural network-based models are generally unsatisfactory when dealing with complex sarcastic expressions. To ameliorate this situation, we propose a multi-perspective contrastive learning framework for sarcasm detection, called SLGC, which is guided by sememe knowledge and label information based on the pre-trained neural model. For the in-instance perspective, we leverage the sememe, the minimum meaning unit, to guide the contrastive learning to produce high-quality sentence representations. For the between-instance perspective, we utilize label information to guide contrastive learning to mine potential interaction relationships between sarcastic expressions. Experiments on two public benchmark sarcasm detection dataset demonstrate that our approach significantly outperforms the current state-of-the-art model.},
  archive      = {J_IJMLC},
  author       = {Wen, Zhiyuan and Wang, Rui and Luo, Xuan and Wang, Qianlong and Liang, Bin and Du, Jiachen and Yu, Xiaoqi and Gui, Lin and Xu, Ruifeng},
  doi          = {10.1007/s13042-023-01884-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4119-4134},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-perspective contrastive learning framework guided by sememe knowledge and label information for sarcasm detection},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Incomplete multi-view clustering via attention-based
contrast learning. <em>IJMLC</em>, <em>14</em>(12), 4101–4117. (<a
href="https://doi.org/10.1007/s13042-023-01883-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering (MVC) is an essential and challenging task in machine learning and data mining. In recent years, this field has attracted a lot of attention and achieved remarkable results. The success of multi-view clustering relies heavily on the consistency and integrity of data views to ensure complete data information. In the process of data collection and transmission, data inevitably be lost, which leads to the occurrence of partial view unalignment (VN) and partial view missing (VM). This situation reduces the available information and increases the difficulty of joint learning of multi-view data. To address the incomplete information problem, in this article, we present a novel incomplete multi-view clustering via attention-based contrast learning framework (MCAC) to address the VN and VM puzzles. Due to the diversity of different views, negative samples are formed by randomly selecting some cross-view samples from positive samples, then computing the correlation between local features and latent features for each view by maximizing mutual information and, fusing each specific low-dimensional representation into a joint representation through an attention fusion layer, in addition, adding noise contrast loss reduces or even eliminates the effect of negative samples. MCAC conducts experiments on seven multi-view datasets and demonstrates the effectiveness compared to eleven state-of-the-art methods on the multi-view clustering task.},
  archive      = {J_IJMLC},
  author       = {Zhang, Yanhao and Zhu, Changming},
  doi          = {10.1007/s13042-023-01883-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4101-4117},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Incomplete multi-view clustering via attention-based contrast learning},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Multiple sparse spaces network pruning via a joint
similarity criterion. <em>IJMLC</em>, <em>14</em>(12), 4079–4099. (<a
href="https://doi.org/10.1007/s13042-023-01882-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a simple and effective neural network pruning framework is proposed to solve the problems of low model acceleration efficiency and inaccurate identification of pruning channels in conventional methods. Therefore, this paper first proposes a multi-sparse space network pruning scheme, which reduces the impact of pruning on network performance by defining the pruning task as an optimisation task in two different sparse spaces to gradually remove redundant parameters from the network. In this paper, we focus on the distribution characteristics of network weights in different sparse spaces, and we show that a decision method combining distance and direction information between weights can better locate the redundant information in the network. Experimental results and analysis have shown that the method can effectively prune neural networks, obtaining better results at higher compression and acceleration rates compared to other state-of-the-art methods. For example, on CIFAR-10, it reduces FLOPs by 67.5\% and 64.2\% for ResNet56 and ResNet110, respectively, while improving accuracy by 0.10\% and 0.55\%, respectively. On the CIFAR-100 dataset, the FLOPs for ResNet32 were reduced by 40.3\%, while the accuracy was improved by 0.06\%. On the STL-10 dataset, it was able to reduce the FLOPs of the ResNet18 model by 71.5\% and gain an accuracy improvement of 0.59\%.},
  archive      = {J_IJMLC},
  author       = {Li, Guoqiang and Chen, Anbang and Liu, Bowen},
  doi          = {10.1007/s13042-023-01882-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4079-4099},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multiple sparse spaces network pruning via a joint similarity criterion},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive affinity matrix learning for dimensionality
reduction. <em>IJMLC</em>, <em>14</em>(12), 4063–4077. (<a
href="https://doi.org/10.1007/s13042-023-01881-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional graph-based dimensionality reduction methods treat graph leaning and subspace learning as two separate steps, and fix the graph during subspace learning. However, the graph obtained from the original data may be not optimal, because the original high-dimensional data contains redundant information and noise, thus the subsequent subspace learning based on the graph may be affected. In this paper, we propose a model called adaptive affinity matrix learning (AAML) for unsupervised dimensionality reduction. Different from traditional graph-based methods, we integrate two steps into a unified framework and adaptively adjust the learned graph. To obtain an ideal neighbor assignment, we introduce a rank constraint to the Laplacian matrix of the affinity matrix. In this way, the number of connected components of the graph is exactly equal to the number of class numbers. By approximating two low-dimensional subspaces, the affinity matrix can obtain the original neighbor structure from the similarity matrix, and the projection matrix can get low-rank information from the affinity matrix, then a distinctive subspace can be learned. Moreover, we propose an efficient algorithm to solve the optimization problem of AAML. Experimental results on four data sets show the effectiveness of the proposed model.},
  archive      = {J_IJMLC},
  author       = {He, Junran and Fang, Xiaozhao and Kang, Peipei and Jiang, Lin and Fei, Lunke and Han, Na and Sun, Weijun},
  doi          = {10.1007/s13042-023-01881-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4063-4077},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Adaptive affinity matrix learning for dimensionality reduction},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BCDetNet: A deep learning architecture for building change
detection from bi-temporal high resolution satellite images.
<em>IJMLC</em>, <em>14</em>(12), 4047–4062. (<a
href="https://doi.org/10.1007/s13042-023-01880-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Change detection is becoming more and more popular technology for the analysis of remote sensing data and is very important for an accurate understanding of changes that are happening in the Earth’s surface. Different Deep Learning methods proposed till now are mainly focused on simple networks which results in poor detection for small changed areas because they can not differentiate between the bi-temporal image’s characteristics. To solve this problem, this article proposes a novel Building Change Detection Network (BCDetNet) for building object change detection and its analysis from bi-temporal high resolution satellite image. The proposed BCDetNet model can detect small change areas with the help of multiple feature extraction block. The proposed BCDetNet model executes building change detection using bi-temporal high resolution satellite images. The proposed BCDetNet model is trained on two publicly available datasets namely LEVIR and WHU change detection(CD) datasets. These datasets contain RGB images with dimensions of (1024 $$\times$$ 1024) and (512 $$\times$$ 512), respectively. The BCDetNet model can learn from scratch during training and performs better than the benchmark change detection models with fewer trainable parameters. The BCDetNet model gives Recall—94.06\%, Precision—93.00\%, Jaccard score—88.40\%, Accuracy—98.73\%, F1 score—93.52\% and Kappa coefficient—87.05\% on LEVIR CD dataset and Recall—89.51\%, Precision —92.78\%, Jaccard score - 84.38\%, Accuracy—96.78\%, F1 score—91.06\% and Kappa coefficient - 82.12\% on WHU CD dataset. This work is a step in the direction of achieving best results in building change detection from high resolution satellite images.},
  archive      = {J_IJMLC},
  author       = {Basavaraju, K. S. and Hiren, N. Solanki and Sravya, N. and Lal, Shyam and Nalini, J. and Reddy, Chintala Sudhakar},
  doi          = {10.1007/s13042-023-01880-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4047-4062},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {BCDetNet: A deep learning architecture for building change detection from bi-temporal high resolution satellite images},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). QMGR-net: Quaternion multi-graph reasoning network for 3D
hand pose estimation. <em>IJMLC</em>, <em>14</em>(12), 4029–4045. (<a
href="https://doi.org/10.1007/s13042-023-01879-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D Hand Pose Estimation (HPE) is a task of recognizing the 3D joints of the hand from static images or dynamic video frames, which is an important topic in human-computer interaction and computer vision. Even though the rise of deep learning promotes the accuracy quite a lot, previous CNN-based methods still suffer from two drawbacks in nature. On one hand, real-valued CNNs break the original structure of the RGB images, and learn color features dependencies and hidden relations mixedly resulting in prediction difficulty when skin is similar. On the other hand, the feature representation for each pixel is only learned by local convolution while the global context information is ignored. To alleviate these problems, we propose a deep learning architecture, named Quaternion Multi-Graph Reasoning Network (QMGR-Net), which contains two novel modules: Quaternion Separation Learning Module (RSLM) and Global Quaternion Reasoning Module (GQRM). The RSLM is proposed to learn color feature dependencies and hidden relations such as edges or shapes at the different level where features can be learned in the quaternion space. Besides, the GQRM is proposed to explicitly capture the interactions among hand joints and model the relationship of non-adjacent nodes. Compared with other state-of-the-art (SOTA) methods on the STB dataset and the RHD dataset, we achieve the best results with 7.27 EPE and 18.59 EPE, respectively, which exhibit the effectiveness of our method.},
  archive      = {J_IJMLC},
  author       = {Ni, Haomin and Xie, Shengli and Xu, Pingping and Fang, Xiaozhao and Sun, Weijun and Fang, Ribo},
  doi          = {10.1007/s13042-023-01879-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4029-4045},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {QMGR-net: Quaternion multi-graph reasoning network for 3D hand pose estimation},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature selection using neighborhood uncertainty measures
and fisher score for gene expression data classification.
<em>IJMLC</em>, <em>14</em>(12), 4011–4028. (<a
href="https://doi.org/10.1007/s13042-023-01878-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification of gene expression data provides a basis for the study of pathogenesis and treatment. However, this type of data is characterized by high dimensionality and small samples, which seriously affect the classification results. Consequently, it is necessary to use a gene selection algorithm to select key genes from gene expression data to improve the classification results, but the existing gene selection algorithm has the problems of low classification precision and high time complexity. Therefore, this paper proposes a gene selection algorithm using neighborhood uncertainty measures and Fisher score. First, to make full use of the information provided by the neighborhood decision system, the neighborhood fusion coverage and neighborhood fusion credibility are defined based on the neighborhood coverage and neighborhood credibility, and they are used to characterize neighborhood uncertainty measures. Second, the neighborhood uncertainty measures are extended by combining the algebraic and information theory views, and a heuristic nonmonotonic gene selection algorithm is designed based on the neighborhood uncertainty measures. The algorithm makes full use of the information in the neighborhood decision system to evaluate the importance of genes from the algebraic and information theory views, thereby selecting an optimal gene subset and improving classification precision. Third, Fisher score method is introduced into the proposed algorithm to preliminarily eliminate redundant genes to reduce the time cost of calculation and improve the performance of the algorithm. Finally, by comparing the experimental results of our algorithm with those of existing gene selection algorithms on ten gene datasets, it is proved that our algorithm can effectively improve the classification results for gene data.},
  archive      = {J_IJMLC},
  author       = {Xu, Jiucheng and Qu, Kanglin and Qu, Kangjian and Hou, Qincheng and Meng, Xiangru},
  doi          = {10.1007/s13042-023-01878-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {4011-4028},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Feature selection using neighborhood uncertainty measures and fisher score for gene expression data classification},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Correction: A writing style-based multi-task model with the
hierarchical attention for rumor detection. <em>IJMLC</em>,
<em>14</em>(11), 4009–4010. (<a
href="https://doi.org/10.1007/s13042-023-01915-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJMLC},
  author       = {Wan, Shuzhen and Tang, Bin and Dong, Fangmin and Wang, Mengyuan and Yang, Guanghao},
  doi          = {10.1007/s13042-023-01915-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {4009-4010},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Correction: A writing style-based multi-task model with the hierarchical attention for rumor detection},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). A writing style-based multi-task model with the
hierarchical attention for rumor detection. <em>IJMLC</em>,
<em>14</em>(11), 3993–4008. (<a
href="https://doi.org/10.1007/s13042-023-01877-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of the Internet and social media, the harm caused by rumors has become more and more serious. Existing rumor detection methods focus on determining rumors by capturing their unusual textual content or communication structure, but fewer methods focus on the writing style of rumors. In order to identify rumors more effectively, we design and implement a multi-task rumor detection model with the hierarchical attention mechanism based on writing styles inspired by multi-task learning in this paper. The model combines a content-based rumor detection task and a writing style-based rumor detection task in a multi-task format, so that the two tasks can enhance their respective detection effects by interacting with each other during the model training process. In addition, we also use the hierarchical attention mechanism consisting of a word attention mechanism and a sentence attention mechanism to focus on words and posts that are more useful for rumor detection, which can reduce the interference of noise and further improve the detection accuracy. The experimental results of our model on the publicly available English Pheme dataset and Chinese Weibo dataset show that our model outperforms most of the existing better rumor detection methods.},
  archive      = {J_IJMLC},
  author       = {Wan, Shuzhen and Tang, Bin and Dong, Fangmin and Wang, Mengyuan and Yang, Guanghao},
  doi          = {10.1007/s13042-023-01877-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3993-4008},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A writing style-based multi-task model with the hierarchical attention for rumor detection},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Brain-inspired learning to deeper inductive reasoning for
video captioning. <em>IJMLC</em>, <em>14</em>(11), 3979–3991. (<a
href="https://doi.org/10.1007/s13042-023-01876-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video captioning requires deeply understanding video content, describing the video concisely and accurately in one sentence. Since the video usually contains multiple atomic events, conventional methods using the attention mechanism or alignment between frame and word, lack deep inductive reasoning for multiple motions and appearances. Considering the inductive reasoning mechanism of the human brain, a brain-inspired deeper inductive reasoning model(DIR) is proposed in this paper. The DIR model discusses the inductive reasoning to presents the semantic similarity and dissimilarity of multiple atomic events, describing the video concisely and accurately. We evaluate the effectiveness of our method on public benchmarks (MSVD and MSR-VTT). Extensive experiments demonstrate that DIR outperforms general state-of-the-art methods, and show the advantages in deep reasoning compared with traditional captioning models.},
  archive      = {J_IJMLC},
  author       = {Yao, Xiao and Xu, Feiyang and Gu, Min and Wang, Peipei},
  doi          = {10.1007/s13042-023-01876-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3979-3991},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Brain-inspired learning to deeper inductive reasoning for video captioning},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-stages de-smoking model based on CycleGAN for surgical
de-smoking. <em>IJMLC</em>, <em>14</em>(11), 3965–3978. (<a
href="https://doi.org/10.1007/s13042-023-01875-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smoke generated during laparoscopic surgery blocks the doctor’s sight and degrades the quality of the images severely; thus, surgical de-smoking is a crucial task during laparoscopic surgery. Previous deep learning methods extract the features of smoke images to restore clear images using convolutional neural networks. However, these methods training on simulated images result in performance degradation when generalized to real smoke images. In this paper, we introduce cycle generative adversarial networks to bridge the gap between simulated and real surgical images. Therefore, we propose a multi-stages surgical de-smoking model based on cycle generative adversarial networks(MS-CycleGAN). By leveraging the convolutional neural networks-based de-smoking module in the first stage, we additionally utilize the simulated-to-real module in the second stage to pull simulated smoke-free images to the real surgical domain, generating real-like smoke-free images that even the discriminator cannot distinguish from real smoke-free images. Furthermore, to make real images and de-smoking images more consistent in image feature space instead of pixel space, the perceptual loss function is employed to calculate the loss in feature space. MS-CycleGAN outperforms state-of-the-art de-smoking methods on the evaluation metrics of both Peak Signal to Noise Ratio and Structural Similarity Index Measure. Most importantly, our MS-CycleGAN achieves qualitatively superior results on de-smoking for real surgical smoke images.},
  archive      = {J_IJMLC},
  author       = {Su, Xinpei and Wu, Qiuxia},
  doi          = {10.1007/s13042-023-01875-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3965-3978},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-stages de-smoking model based on CycleGAN for surgical de-smoking},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-label feature selection via joint label enhancement
and pairwise label correlations. <em>IJMLC</em>, <em>14</em>(11),
3943–3964. (<a
href="https://doi.org/10.1007/s13042-023-01874-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label feature selection(MFS) has gained in importance, and it is today confronted with the current need to process multi-semantic high-dimensional data. Recent studies usually figure out the MFS problems either simply assume that all associated labels are equally important for each instance; or that the labels are independent of each other. In many real-world applications, however, both cases may occur that the significance of each relevant label is generally different and label correlations are ubiquitous. Based on this observation, we propose a new algorithm, called FSEP, to perform MFS by considering label significance and pairwise label correlations. In FSEP, we first construct a label enhancement method that is able to obtain label distribution and further earn the information of label significance. Then, FSEP explores the influence mechanism of label correlations to features by using neighborhood mutual information and incorporates this influence into the process of feature evaluation. After that, a novel multi-label feature selection strategy, namely, Max-Relevance, Max-Contribution, and Min-Redundancy, is proposed, which achieves a favorable trade-off among feature relevance, the contribution of label correlations to features, and feature redundancy, simultaneously. Extensive experiments on both public and real-world datasets show that the proposed method achieves encouraging results compared with state-of-the-art MFS algorithms.},
  archive      = {J_IJMLC},
  author       = {Liu, Jinghua and Yang, Songwei and Lin, Yaojin and Wang, Chenxi and Wang, Cheng and Du, Jixiang},
  doi          = {10.1007/s13042-023-01874-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3943-3964},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-label feature selection via joint label enhancement and pairwise label correlations},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Manifold-based denoising, outlier detection, and dimension
reduction algorithm for high-dimensional data. <em>IJMLC</em>,
<em>14</em>(11), 3923–3942. (<a
href="https://doi.org/10.1007/s13042-023-01873-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manifold learning, which has emerged in recent years, plays an increasingly important role in machine learning. However, because inevitable noises and outliers destroy the manifold structure of data, the dimensionality reduction effect of manifold learning will be reduced. Therefore, this paper proposes a denoising algorithm for high-dimensional data based on manifold learning. The algorithm first projects noisy sample vectors onto the local manifold, thereby achieving noise reduction. Then, a statistical analysis of noises is performed to obtain a data boundary. Because all the data come from the same background and obey the same distribution, the sample vectors that are not within the data boundary are marked as outliers, and these outliers are eliminated. Finally, the dimension reduction of the data after noise reduction and outlier detection is performed. Experimental results show that the algorithm can effectively eliminate the interference of noises and outliers in high-dimensional datasets to some extent for manifold learning.},
  archive      = {J_IJMLC},
  author       = {Zhao, Guanghua and Yang, Tao and Fu, Dongmei},
  doi          = {10.1007/s13042-023-01873-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3923-3942},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Manifold-based denoising, outlier detection, and dimension reduction algorithm for high-dimensional data},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cervical cancerous cell classification: Opposition-based
harmony search for deep feature selection. <em>IJMLC</em>,
<em>14</em>(11), 3911–3922. (<a
href="https://doi.org/10.1007/s13042-023-01872-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over 500 K (per year) cervical cancer cases are reported with a high mortality rate (6–9\%). Automatically detecting cervical cancer using the Computer-Aided Diagnosis (CAD) tool at an early stage is important since it leads to successful treatment as pathologists. In this paper, we propose a tool that classifies cervical cancer cases from Pap smear cytology images using deep features. The proposed tool constitutes a Convolutional Neural Network (CNN) and a metaheuristic evolutionary algorithm called Opposition-based Harmony Search Algorithm (O-bHSA) for deep feature section. These features are classified using standard classifiers: SVM, MLP, and KNN. On two different publicly available datasets: Pap smear and liquid-based cytology, the proposed tool outperforms not only seven well-known optimization algorithms but also state-of-the-art methods. Codes are publicly available on GitHub .},
  archive      = {J_IJMLC},
  author       = {Das, Nibaran and Mandal, Bodhisatwa and Santosh, KC and Shen, Linlin and Chakraborty, Sukanta},
  doi          = {10.1007/s13042-023-01872-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3911-3922},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Cervical cancerous cell classification: Opposition-based harmony search for deep feature selection},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An attentive-based generative model for medical image
synthesis. <em>IJMLC</em>, <em>14</em>(11), 3897–3910. (<a
href="https://doi.org/10.1007/s13042-023-01871-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic resonance (MR) and computer tomography (CT) imaging are valuable tools for diagnosing diseases and planning treatment. However, limitations such as radiation exposure and cost can restrict access to certain imaging modalities. To address this issue, medical image synthesis can generate one modality from another, but many existing models struggle with high-quality image synthesis when multiple slices are present in the dataset. This study proposes an attention-based dual contrast generative model, called ADC-cycleGAN, which can synthesize medical images from unpaired data with multiple slices. The model integrates a dual contrast loss term with the CycleGAN loss to ensure that the synthesized images are distinguishable from the source domain. Additionally, an attention mechanism is incorporated into the generators to extract informative features from both channel and spatial domains. To improve performance when dealing with multiple slices, the K-means algorithm is used to cluster the dataset into K groups, and each group is used to train a separate ADC-cycleGAN. Experimental results demonstrate that the proposed ADC-cycleGAN model produces comparable samples to other state-of-the-art generative models, achieving the highest PSNR and SSIM values of 19.04385 and 0.68551, respectively. We publish the code at https://github.com/JiayuanWang-JW/ADC-cycleGAN .},
  archive      = {J_IJMLC},
  author       = {Wang, Jiayuan and Wu, Q. M. Jonathan and Pourpanah, Farhad},
  doi          = {10.1007/s13042-023-01871-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3897-3910},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An attentive-based generative model for medical image synthesis},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel fairness-aware ensemble model based on hybrid
sampling and modified two-layer stacking for fair classification.
<em>IJMLC</em>, <em>14</em>(11), 3883–3896. (<a
href="https://doi.org/10.1007/s13042-023-01870-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fair classification is an important field in machine learning, especially in ensemble learning research. However, traditional machine learning methods neither consider the bias in datasets nor the unfairness while training the ensemble model. Therefore, in this paper, a novel fairness-aware ensemble model (FAEM) based on hybrid sampling and modified two-layer stacking is proposed to achieve more equitable predictive performance. To reduce the bias caused by the imbalanced dataset, a new hybrid sampling-based bias-alleviation method is proposed, which removes majority samples through cross-validation-based under-sampling and adds generated minority samples through sensitive attribute-based over-sampling. The fairness of the proposed FAEM is further improved by the proposed new two-layer stacking-based fairness-aware ensemble learning method, which modifies the individual prediction results of the base classifiers in the first layer of stacking to alleviate the bias. Four datasets and five evaluation metrics were used to evaluate the classification performance and fairness of the model. The experiment results show that the proposed FAEM can effectively trade off accuracy for fairness and is 54.8\% better than benchmark models in fairness metrics in average.},
  archive      = {J_IJMLC},
  author       = {Zhang, Wenyu and He, Fang and Zhang, Shuai},
  doi          = {10.1007/s13042-023-01870-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3883-3896},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel fairness-aware ensemble model based on hybrid sampling and modified two-layer stacking for fair classification},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reinforced feature selection using q-learning based on
collaborative agents. <em>IJMLC</em>, <em>14</em>(11), 3867–3882. (<a
href="https://doi.org/10.1007/s13042-023-01869-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforced feature selection (RFS) applies reinforcement learning to feature selection, which can continue to learn the procedure of feature selection and then effectively find the optimal feature subset from original features. Q-learning with Fisher score (QLFS), a kind of filtering RFS algorithm, adopts the Fisher score to construct the internal reward and then achieves good performance on large-scale data sets. However, it is hard for QLFS to automatically determine how many features should be selected. To remedy it, this paper proposes a novel RFS method, called Q-learning based on collaborative agents (QLCA). To implement automatic feature selection, QLCA adopts two agents to collaboratively learn the optimal strategies. One agent, called selection agent, is used to select features, where the Fisher scores of feature subsets are taken as the reward; while the other agent, called classification agent, is to determine how many features should be chosen, where the classification performance of a classifier on selected features is regarded as the reward. The selection agent provides feature subsets for the classification agent, while the classification agent gives the classification performance to the selection agent. In doing so, these two agents work well together in QLCA. Extensive experiments were conducted on several small and large real-world data sets. According to statistical analysis on experimental results, QLCA is significantly better than QLFS. Findings indicate that QLCA can effectively and automatically perform feature selection.},
  archive      = {J_IJMLC},
  author       = {Zhang, Li and Jin, Lingbin and Gan, Min and Zhao, Lei and Yin, Hongwei},
  doi          = {10.1007/s13042-023-01869-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3867-3882},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Reinforced feature selection using Q-learning based on collaborative agents},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust multimedia recommender system based on dynamic
collaborative filtering and directed adversarial learning.
<em>IJMLC</em>, <em>14</em>(11), 3851–3865. (<a
href="https://doi.org/10.1007/s13042-023-01868-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimedia Recommendation Systems (MRSs) have shown to be quite effective in learning consumer preferences and recommending the best multimedia products. Recent breakthroughs in adversarial machine learning have piqued the interest of researchers in the security of MRSs. It has been established that widely deployed MRSs are not resilient to detrimental perturbations applied to the learnt parameters, which can result in a significant loss in recommendation accuracy. Adversarial Multimedia Ranking (AMR) mitigates this problem by boosting Visual Bayesian Pairwise Ranking (VBPR) through adversarial learning. The quantitative gains in AMR’s performance on VBPR have led to its widespread implementation in numerous MRS models. However, in MRSs, this strategy overlooks the collaborative feature and is unable to effectively capture the smoothness of data distribution. We contend that modeling MRSs requires the collaborative feature, which displays the behavioral similarity between consumers and products. In this paper, we implement directed adversarial learning with the explicit introduction of the collaborative feature into the perturbation process. Technically, we propose the Adversarial Dynamic Collaborative Filtering (ADCF) for recommendation, which models visual characteristics and captures visual time dynamics. To reduce the influence of perturbation, we train the ADCF objective through minimax adversarial learning. Furthermore, we enhance the ADCF by directed adversarial learning. The objective is to restrict the direction of perturbation in the embedding space to other examples in the present embedding space. This enables us to integrate the collaborative feature into the learning process. Comprehensive evaluations using three Amazon datasets revealed that our technique outperformed baselines.},
  archive      = {J_IJMLC},
  author       = {Paul, Agyemang and Wu, Zhefu and Luo, Kai and Ma, Yuhang and Fang, Luping},
  doi          = {10.1007/s13042-023-01868-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3851-3865},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Robust multimedia recommender system based on dynamic collaborative filtering and directed adversarial learning},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Linear-combined rough vague sets and their three-way
decision modeling and uncertainty measurement optimization.
<em>IJMLC</em>, <em>14</em>(11), 3827–3850. (<a
href="https://doi.org/10.1007/s13042-023-01867-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rough sets (RSs) and vague sets (VSs) are fundamental uncertainty methodologies, and their integrated rough vague sets (RVSs) establish a robust platform for data analysis. For RVSs, double-approximate VSs exhibit the singleness and extreme, so improved models are worth constructing. Thus, linear-combined rough vague sets (LcRVSs) are proposed to perfect RVSs, and subsequent probabilistic-RSs (called LcRVSs-PRSs) are modeled by three-way decision (3WD); furthermore, relevant uncertainty measurement optimization is investigated. At first, LcRVSs are parametrically constructed by fusing and extending RVSs, and their integration algorithms and operation properties are discussed; the granulation-cognitive approximation from LcRVSs to VSs is optimally considered by three-way similarity measures, and thus the optimal parameter value is approximately solved by a discrete search algorithm. Furthermore, LcRVSs motivate the LcRVSs-PRSs model via 3WD, and related construction algorithms and operation properties are offered; for uncertainty measurement, the accuracy, roughness, and dependency are discussed, and their cognitive approximation and parametric optimization are revealed. Finally, the obtained results of models, properties, measures, and algorithms are thoroughly demonstrated by data examples and numerical experiments. By this study, LcRVSs systematically extend, balance, improve RVSs, and their 3WD model (i.e., LcRVSs-PRSs) facilitates roughness decision, so relevant uncertainty measurement and parameter optimization benefit cognitive learning.},
  archive      = {J_IJMLC},
  author       = {Wang, Xiaoxue and Zhang, Xianyong},
  doi          = {10.1007/s13042-023-01867-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3827-3850},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Linear-combined rough vague sets and their three-way decision modeling and uncertainty measurement optimization},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Consensus latent incomplete multi-view clustering with
low-rank tensor constraint. <em>IJMLC</em>, <em>14</em>(11), 3813–3825.
(<a href="https://doi.org/10.1007/s13042-023-01866-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional multi-view clustering (MVC) assumes that all views are complete and it cannot address a lack of views. In real life, a lack of views often occurs, thus leading to the problem of incomplete MVC (IMVC). Although the existing IMVC methods have achieved good performance, they have the following weaknesses. (1) The completion method is not flexible enough for the case where view information is arbitrarily missing. (2) They fail to adequately explore the higher-order correlations among views. (3) The cluster structure of the input data is not considered. Thus, to solve these problems, in this paper, we propose a novel method, i.e., consensus latent incomplete multi-view clustering with low-rank tensor constraint (CLIMVC/LTC). Specifically, we first use a latent model to generate the missing views to make the completion process more flexible. Then, we utilize the low-rank tensor constraint and consensus representation term to jointly explore the higher-order correlations, the cluster structure of the data and the consistency between different views. That is, CLIMVC/LTC combines missing view completion, which is implemented by a latent model, low-rank tensor constraint and consensus representation learning into a unified framework, and their interaction yields improved clustering performance. An optimization procedure based on the augmented Lagrange multiplier (ALM) method is also designed to solve CLIMVC/LTC. The effectiveness of CLIMVC/LTC is verified on several well-known datasets, and it has good clustering performance.},
  archive      = {J_IJMLC},
  author       = {Ji, Guangyan and Lu, Gui-Fu},
  doi          = {10.1007/s13042-023-01866-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3813-3825},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Consensus latent incomplete multi-view clustering with low-rank tensor constraint},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Relation-attention semantic-correlative knowledge graph
embedding for inductive link prediction. <em>IJMLC</em>,
<em>14</em>(11), 3799–3811. (<a
href="https://doi.org/10.1007/s13042-023-01865-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction has increasingly been the focus of significant research interest, benefited from the explosion of machine learning and deep learning techniques. Graph embedding has been proven to be an effective method for predicting missing links in graph-based structure. In this work, we propose a novel relation-attention semantic-correlative graph embedding for inductive link prediction. Unlike existing embedding-based methods, we shift the node representation learning from a node’s perspective to a relational subgraph perspective. Our model has a better inductive bias to learn entity-independent relational semantics. We consider two kinds of relational subgraph topology for a given entity pair: relational correlation subgraph and relational path subgraph. Firstly, we capture the structure of neighboring relation-properties of semantic-missing entity by relational correlation subgraph. Secondly, we capture the set of relational paths between given entity pair by relational path subgraph. Finally, we organize the above two modules in a unified framework for relation prediction. Our ablation experiments show that two kinds of relational subgraph topology are important for relation prediction. Experimental results on six benchmark datasets demonstrate that our proposed graph embedding outperforms existing state-of-the-art models for link prediction tasks.},
  archive      = {J_IJMLC},
  author       = {Xiaonan, Li and Bo, Ning and Guanyu, Li and Jie, Wang},
  doi          = {10.1007/s13042-023-01865-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3799-3811},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Relation-attention semantic-correlative knowledge graph embedding for inductive link prediction},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Personalized federated learning based on multi-head
attention algorithm. <em>IJMLC</em>, <em>14</em>(11), 3783–3798. (<a
href="https://doi.org/10.1007/s13042-023-01864-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is an algorithm for the encrypted exchange of model parameters while ensuring the independence of participants. Classic federated learning does not take into account the correlation between features, nor does it take into account the data differences caused by the reasonable personalization of each client. Therefore, this paper proposes a personalized federated learning algorithm based on a multi-head attention mechanism. First, in order to improve the personalization of local models, attention mechanism is used to capture the relevance of local features. Then, when aggregating local models, the weight $$\lambda$$ is generated for local models based on the differences between models, and finally aggregate them into a new global model. Finally, the multi-head attention is proposed to calculate the importance score of the global model parameters on the current local model, and assign it to the local model as the attention coefficient, so as to realize personalized federated learning. Through experiments on MNIST, SVHN and STL10 datasets, the validity of Personalized Federated Learning is verified, and the rationality of hyperparameter setting is discussed through visualizing results.},
  archive      = {J_IJMLC},
  author       = {Jiang, Shanshan and Lu, Meixia and Hu, Kai and Wu, Jiasheng and Li, Yaogen and Weng, Liguo and Xia, Min and Lin, Haifeng},
  doi          = {10.1007/s13042-023-01864-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3783-3798},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Personalized federated learning based on multi-head attention algorithm},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new method for two-stage partial-to-partial 3D point cloud
registration: Multi-level interaction perception. <em>IJMLC</em>,
<em>14</em>(11), 3765–3781. (<a
href="https://doi.org/10.1007/s13042-023-01863-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D point cloud registration related to rigid transformation is a fundamental yet crucial task in computer vision and graphics. For rigid registration, the local alignment of two-point clouds is equivalent to a global alignment. Since sufficient information exchange is an effective way to enhance mutual understanding, it is necessary to design a reasonable and sufficient feature interaction across two-point clouds to to obtain discriminative features and explore overlapping points. Recently, although a series of learning-based registration methods have been explored, most of the existing methods lack attention to multi-level feature interactions. In addition, there seems to be no paper that explicitly proposes a method for two-stage registration. However, intermediate constraints can be set in the two-stage registration to supervise the coarse registration and better refine the fine registration. To this end, this paper proposes a multi-level interaction perception method for two-stage partial-to-partial point cloud registration that can hierarchically capture discriminative structural features by the interaction of local details and global features from different dimensions, as well as improve the perception of locality in the early information exchange. Also, a spatial overlap-aware transformer is constructed to highlight the common regions while perceiving the global information of the point cloud. Thus, overlap constraints with high confidence between source and target point clouds can be obtained. The registration evaluation is performed on numerous partial 3D point clouds with Gaussian noise, and the results reveal that our method can achieve superior performance.},
  archive      = {J_IJMLC},
  author       = {Meng, Xinhong and Zhu, Lei and Ye, Hailiang and Cao, Feilong},
  doi          = {10.1007/s13042-023-01863-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3765-3781},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A new method for two-stage partial-to-partial 3D point cloud registration: Multi-level interaction perception},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identifying implicit emotions via hierarchical structure and
rhetorical correlation. <em>IJMLC</em>, <em>14</em>(11), 3753–3764. (<a
href="https://doi.org/10.1007/s13042-023-01862-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implicit emotional expressions, without using explicit emotion words, usually depend on rhetorics to vividly show the user’s emotions. Sentences carved with specific rhetorics tend to express certain types of emotions. Moreover, a hierarchical structure between emotional pleasure valences and categories exists in psychological sciences from coarse to fine, which helps human understand textual emotions. However, existing implicit emotion identification models ignore the hierarchy structure and the correlations between emotions and rhetorics. In this paper, we propose an implicit emotion identification model via hierarchical structure and rhetorical correlation, which consists of two major layers. Specifically, a hierarchical layer is designed to leverage hierarchical structure and provide coarse-grained emotional valences for identifying emotions, and a correlation layer to learn the latent correlation between emotions and rhetorics. Finally, supported by two layers, a novel multi-task learning model is proposed to train three related identification tasks of pleasure valences, emotions and rhetorics simultaneously, thus improving the overall performance of the emotion identification problem. Experimental results on the implicit emotion dataset demonstrate that the proposed model achieves 89.78\% and 88.74\% in terms of micro-F1 and weight-F1 metric respectively, outperforming the state-of-the-art methods consistently.},
  archive      = {J_IJMLC},
  author       = {Chen, Xin and Wang, Suge and Li, Xiaoli and Hai, Zhen and Li, Yang and Li, Deyu and Cai, Jianghui},
  doi          = {10.1007/s13042-023-01862-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3753-3764},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Identifying implicit emotions via hierarchical structure and rhetorical correlation},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-granular labels with three-way decisions for
multi-label classification. <em>IJMLC</em>, <em>14</em>(11), 3737–3752.
(<a href="https://doi.org/10.1007/s13042-023-01861-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label classification is a challenging issue because it simultaneously embraces the characteristics of the imbalanced class distribution for each label and the uncertain label correlation among the whole label space. The decision-theoretic rough set can describe the roughness of concepts in the sense of minimizing decision risk but fails to consider the case where concepts are compatible. We argue that it is feasible to analyze the uncertainty of coarse-grained logical labels with limited label correlation assumptions and reduce the classification error for those uncertain instances by learning fine-grained numerical labels. Consequently, we develop a multi-granular label information system by introducing a multi-granular threshold with a three-way-based label enhancement (MGT-LEML) model. With the second-order label correlation assumption, we deduce the pseudo-positive and pseudo-negative classes for each label. The decision-theoretic rough set evaluates the possibility of misclassification independently, and a novel uncertain measure called instance uncertainty degree determines whether it is necessary to conduct label enhancement afterward. In this way, instances with the most uncertain classifications across label space compute fine-granule numerical labels by label enhancement, whereas remaining unchanged otherwise. We analyze the comparison results among nine algorithms on eight benchmarks with six metrics to demonstrate the superiority of the proposed MGT-LEML algorithm over state-of-the-art multi-label classification algorithms. Compared with the HNOML algorithm, our algorithm achieves significant improvement. Concretely, the performance is reduced by 2.9\% in Hamming Loss, 12.4\% in Ranking Loss, 14.3\% in One Error, 465.5\% in Coverage, and is increased by 14.2\% in Average Precision.},
  archive      = {J_IJMLC},
  author       = {Zhao, Tianna and Zhang, Yuanjian and Miao, Duoqian and Zhang, Hongyun},
  doi          = {10.1007/s13042-023-01861-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3737-3752},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-granular labels with three-way decisions for multi-label classification},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal scale selection based on three-way decisions with
decision-theoretic rough sets in multi-scale set-valued decision tables.
<em>IJMLC</em>, <em>14</em>(11), 3719–3736. (<a
href="https://doi.org/10.1007/s13042-023-01860-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal scale selection (OSS) is a fundamental topic in the studies of multi-scale decision tables (MSDTs). Multi-scale set-valued decision tables (MSSVDTs) widely exist in practical applications, and the attribute value is a linguistic set-value. Existing studies of OSS in the MSDT with cost-sensitive learning have constructed total cost mainly from two aspects: test cost and delay cost. Moreover, they are given subjectively, resulting in a lack of objectivity in the construction of total cost. Therefore, constructing a relatively objective and comprehensive total cost for OSS based on cost-sensitive learning is worthwhile in MSSVDTs. In this paper, we firstly propose a quantization method to reasonably transform the linguistic set-value into a numerical value according to the granular structures. Then, based on three-way decisions with decision-theoretic rough sets, loss functions of every object on different scales are constructed, and uncertainty is quantified. Afterwards, loss functions are introduced into the construction of total cost with regard to OSS. This helps us obtain relatively objective total cost, including test cost, delay cost, and misclassification cost. Furthermore, in light of the idea of Technique for Order Preferences by Similarity to an Ideal Solution, we design an OSS algorithm to select the optimal scale according to the ordered change of uncertainty and total cost. Finally, the feasibility and effectiveness of the proposed algorithm are verified through experiments on UCI data sets.},
  archive      = {J_IJMLC},
  author       = {Li, Runkang and Yang, Jilin and Zhang, Xianyong},
  doi          = {10.1007/s13042-023-01860-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3719-3736},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Optimal scale selection based on three-way decisions with decision-theoretic rough sets in multi-scale set-valued decision tables},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid dimensionality reduction method for outlier
detection in high-dimensional data. <em>IJMLC</em>, <em>14</em>(11),
3705–3718. (<a
href="https://doi.org/10.1007/s13042-023-01859-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection becomes challenging when data are featured by high-dimension. Using dimensionality reduction (DR) techniques to discard the irrelevant attributes is a straightforward solution. However, it appears to be rather difficult for single DR algorithm to discover all outliers, owing to the rarity, heterogeneity, and boundless nature of outliers. In this paper, we propose a hybrid DR method dedicated to outlier detection base on ensemble learning. Multiple algorithms with different specifications of parameters are used to generate accurate and diverse base detectors at the phase of ensemble generation. A two-stage combination function is used at the phase of ensemble combination. Both variance reduction and bias reduction are taken into account in our framework. More importantly, the high flexibility of the proposed detection framework implies that any outlier detection algorithm can be applicable. 15 high-dimensional data sets from KEEL repository and one image data set are used to validate the performance of our method. One semi-supervised and one unsupervised outlier detection algorithms are used in separate experiments. In spite of subtle differences, the advantage of our method has been approved by both experiments. Moreover, contributions of two ingredients of our method are also verified via two pairs of experimental comparisons.},
  archive      = {J_IJMLC},
  author       = {Meng, Guanglei and Wang, Biao and Wu, Yanming and Zhou, Mingzhe and Meng, Tiankuo},
  doi          = {10.1007/s13042-023-01859-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3705-3718},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A hybrid dimensionality reduction method for outlier detection in high-dimensional data},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Label-dependent feature exploration for label distribution
learning. <em>IJMLC</em>, <em>14</em>(11), 3685–3704. (<a
href="https://doi.org/10.1007/s13042-023-01858-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label distribution learning (LDL) explicitly models label ambiguity by assigning a real-valued vector with label description degrees to each sample. Most LDL methods only build models on the same feature (sub)space shared by all labels. However, they ignore that each label has its own specific features, and there are some common features among labels. In this paper, we propose a novel LDL (LDL-LDF) algorithm that aims to exploit both label-dependent and common features. First, label-dependent feature reconstruction utilizes thresholding for relevant sample subset identification, density peaks clustering for representative sample selection, and Euclidean distance for feature value calculation. Second, common feature reconstruction follows a similar approach, however, on the whole dataset. Finally, the prediction neural network is composed of several components that serve each label with label-dependent features, one component that serves all labels with common features, and the fusion component. The effectiveness and competitiveness of our algorithm are verified through various experiments comparing seven algorithms on fourteen real-world datasets.},
  archive      = {J_IJMLC},
  author       = {Bai, Run-Ting and Zhang, Heng-Ru and Min, Fan},
  doi          = {10.1007/s13042-023-01858-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3685-3704},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Label-dependent feature exploration for label distribution learning},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ICUnet++: An inception-CBAM network based on unet++ for MR
spine image segmentation. <em>IJMLC</em>, <em>14</em>(10), 3671–3683.
(<a href="https://doi.org/10.1007/s13042-023-01857-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, more attention paid to the spine caused by related diseases, spinal parsing (the multi-class segmentation of vertebrae and intervertebral disc) is an important part of the diagnosis and treatment of various spinal diseases. The more accurate the segmentation of medical images, the more convenient and quick the clinicians can evaluate and diagnose spinal diseases. Traditional medical image segmentation is often time consuming and energy consuming. In this paper, an efficient and novel automatic segmentation network model for MR spine images is designed. The proposed Inception-CBAM Unet++ (ICUnet++) model replaces the initial module with the Inception structure in the encoder-decoder stage base on Unet++ , which uses the parallel connection of multiple convolution kernels to obtain the features of different receptive fields during in the feature extraction. According to the characteristics of the attention mechanism, Attention Gate module and CBAM module are used in the network to make the attention coefficient highlight the characteristics of the local area. To evaluate the segmentation performance of network model, four evaluation metrics, namely intersection over union (IoU), dice similarity coefficient(DSC), true positive rate(TPR), positive predictive value(PPV) are used in the study. The published SpineSagT2Wdataset3 spinal MRI dataset is used during the experiments. In the experiment results, IoU reaches 83.16\%, DSC is 90.32\%, TPR is 90.40\%, and PPV is 90.52\%. It can be seen that the segmentation indicators have been significantly improved, which reflects the effectiveness of the model.},
  archive      = {J_IJMLC},
  author       = {Li, Lei and Qin, Juan and Lv, Lianrong and Cheng, Mengdan and Wang, Biao and Xia, Dan and Wang, Shike},
  doi          = {10.1007/s13042-023-01857-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3671-3683},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {ICUnet++: An inception-CBAM network based on unet++ for MR spine image segmentation},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transferring variational autoencoders with coarse-and-fine
alignment for open set broad classification. <em>IJMLC</em>,
<em>14</em>(10), 3655–3669. (<a
href="https://doi.org/10.1007/s13042-023-01856-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning aims to help target learners with a different but related source domain. Open set recognition extends the settings of transfer learning for identifying whether an instance belongs to an unseen category. However, it is often pragmatic and valuable to further classify the unseen categories in target domain. We present a new setting called open set broad classification (OSBC) to classify unseen target categories which are open within the broad classes of source domain. Aiming at adapting to the challenging domain shift between unseen categories and seen categories, we propose a variational autoencoders model with coarse-and-fine alignment (CFVA) to leverage the structural information in the OSBC setting. First, two-stream decoders are employed and coarsely aligned by a relaxed parameters regularizer, which can absorb domain shift on features to facilitate fine alignment. Then fine alignment at encoding level enhances discriminative power of the latent representation by mixing the distributional structure hinted by source domain. Experimental results demonstrate the effectiveness of our CFVA approach in improving the accuracies in both unsupervised and semi-supervised cases.},
  archive      = {J_IJMLC},
  author       = {Sun, Shichang and Huang, Yongdong and Zhao, Di and Yu, Yuhai and Meng, Jiana},
  doi          = {10.1007/s13042-023-01856-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3655-3669},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Transferring variational autoencoders with coarse-and-fine alignment for open set broad classification},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving label quality in crowdsourcing using deep
co-teaching-based noise correction. <em>IJMLC</em>, <em>14</em>(10),
3641–3654. (<a
href="https://doi.org/10.1007/s13042-023-01855-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the crowdsourcing scenario, repeated labeling is employed to obtain each instance’s multiple noisy label set from different crowd workers on the Internet, and then a ground truth inference method is used to obtain its integrated label. However, no matter which ground truth inference method is used, a certain level of noise remains in the integrated labels. To improve the quality of the integrated labels, a number of noise correction methods have been proposed in recent years. However, to the best of our knowledge, almost all these methods filter out too many instances that are regarded as noise instances and thus can only use a few clean instances to learn classifiers for noise correction. In this paper, we propose a two-stage noise correction method called deep co-teaching-based noise correction (DCTNC), which can learn not only from clean instances but also from noise instances adaptively. In the first stage, original instances are split into a clean set and a noise set according to the confusion level of their multiple noisy label sets. In the second stage, we at first train a deep network on the clean set and then use it to guide the training of another two deep networks on the noise set through an improved co-teaching algorithm. Finally, we use the trained three deep networks to correct the instances in the noise set. The experimental results on eleven simulated datasets and one real-world dataset show that the proposed DCTNC achieves new state-of-the-art results.},
  archive      = {J_IJMLC},
  author       = {Zhu, Kang and Xue, Siqing and Jiang, Liangxiao},
  doi          = {10.1007/s13042-023-01855-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3641-3654},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Improving label quality in crowdsourcing using deep co-teaching-based noise correction},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving cross-lingual language understanding with
consistency regularization-based fine-tuning. <em>IJMLC</em>,
<em>14</em>(10), 3621–3639. (<a
href="https://doi.org/10.1007/s13042-023-01854-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-tuning pre-trained cross-lingual language models alleviates the need for annotated data in different languages, as it allows the models to transfer task-specific supervision between languages, especially from high- to low-resource languages. In this work, we propose to improve cross-lingual language understanding with consistency regularization-based fine-tuning. Specifically, we use example consistency regularization to penalize the prediction sensitivity to four types of data augmentations, i.e., subword sampling, Gaussian noise, code-switch substitution, and machine translation. In addition, we employ model consistency to regularize the models trained with two augmented versions of the same training set. Experimental results on the XTREME benchmark show that our method (the code is available at https://github.com/bozheng-hit/xTune )  achieves significant improvements across various cross-lingual language understanding tasks, including text classification, question answering, and sequence labeling. Furthermore, we extend our method to the few-shot cross-lingual transfer setting, particularly considering a more realistic setting where machine translation systems are available. Meanwhile, machine translation as data augmentation can be well combined with our consistency regularization method. Experimental results demonstrate that our method also benefits the few-shot scenario.},
  archive      = {J_IJMLC},
  author       = {Zheng, Bo and Che, Wanxiang},
  doi          = {10.1007/s13042-023-01854-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3621-3639},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Improving cross-lingual language understanding with consistency regularization-based fine-tuning},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Siamese global location-aware network for visual object
tracking. <em>IJMLC</em>, <em>14</em>(10), 3607–3620. (<a
href="https://doi.org/10.1007/s13042-023-01853-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual tracking is widely used in industrial systems such as vision servo systems and in intelligent robots. However, most tracking algorithms are designed without considering the balance of algorithmic efficiency and accuracy in system applications, making them less preferable for applications. This paper proposes a siamese global location-aware object tracking algorithm (SiamGLA) to address this issue. First, due to the limited performance of efficient lightweight backbone networks, this study designs an internal feature combination (IFC) module that improves feature representation with almost no additional parameters. Second, a global-aware (GA) attention module is proposed to improve the classification ability of foreground and background, which is especially important for trackers. Finally, a location-aware (LA) attention module is designed to improve the regression performance of the tracking framework. Comprehensive experiments show that SiamGLA is effective, and overcomes the drawbacks of poor robustness and weak generalization ability. When the performance reaches state-of-the-art, SiamGLA requires fewer calculations and parameters, making it more likely to be applied in practice.},
  archive      = {J_IJMLC},
  author       = {Li, Jiafeng and Li, Bin and Ding, Guodong and Zhuo, Li},
  doi          = {10.1007/s13042-023-01853-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3607-3620},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Siamese global location-aware network for visual object tracking},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi video summarization using query based deep
optimization algorithm. <em>IJMLC</em>, <em>14</em>(10), 3591–3606. (<a
href="https://doi.org/10.1007/s13042-023-01852-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The popularity of online video-sharing platforms has fuelled demand for systems that can quickly browse, extract, and summarise video information. Nowadays, numerous automatic multi-video summarization (MVS) techniques have come into existence. The existing MVS approach, on the other hand, produces summarised video with a lot of unimportant and duplicate frames. It also arranges frames in a meaningless manner. To solve these problems in MVS, Query-based Deep African Vulture Learning (QDAVOL) is proposed in this paper. It uses tag information and web images searched by the query as important information to identify the query intent. An event-based object detection and grouping (EODG) technique is used to assign keyframes to groups of specific events relevant with the query. In addition, we introduce the African vulture optimization algorithm (AVOA) for the efficient key frame selection. Moreover, we have also developed a similarity-based frame closeness (SFC) technique to provide more comprehensible summary. Experimental results demonstrate that the proposed framework outperforms existing approaches in terms of precision (0.765), recall (0.845), and average F-score (0.774) on MVS1K dataset.},
  archive      = {J_IJMLC},
  author       = {Ansari, Shaharyar Alam and Zafar, Aasim},
  doi          = {10.1007/s13042-023-01852-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3591-3606},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi video summarization using query based deep optimization algorithm},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning anomalous human actions using frames of interest
and decoderless deep embedded clustering. <em>IJMLC</em>,
<em>14</em>(10), 3575–3589. (<a
href="https://doi.org/10.1007/s13042-023-01851-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inconsistent data and unclear labels make it difficult to learn anomalous behavior from video. Therefore, methods based on deep clustering are now trending in this area. A deep clustering strategy usually relies on encoding and reconstruction to facilitate information discovery. However, it seems pointless to reconstruct the input after the model’s learning process is already concluded. On the other hand, multiple input types carry various features which may help identify the problem more accurately. Hence to mitigate the requirement of utilizing assorted features with clustering, we propose Skeletal Based Autoencoder (SKELBA), which allows us to process the different types of inputs parallelly. The model consists of a spatial graph convolution operator, which helps us convolve the skeletal data more precisely. A decoder-less deep clustering architecture is introduced to enhance the stability of clustering. The relation between reconstruction error and minimizing the lower bound of mutual information (MI) helps us look into decoder-free systems. The joint venture of local–global feature collection and decoder-free encoders techniques shows improved results. Extensive experiments performed on the various benchmark datasets highlight the proposed model’s superiority among recently proposed approaches in the same field.},
  archive      = {J_IJMLC},
  author       = {Javed, Muhammad Hafeez and Yu, Zeng and Li, Tianrui and Anwar, Noreen and Rajeh, Taha M.},
  doi          = {10.1007/s13042-023-01851-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3575-3589},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Learning anomalous human actions using frames of interest and decoderless deep embedded clustering},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An interpretable neural network TV program recommendation
based on SHAP. <em>IJMLC</em>, <em>14</em>(10), 3561–3574. (<a
href="https://doi.org/10.1007/s13042-023-01850-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of artificial intelligence, many fields are trying to solve problems with the powerful representation ability of neural networks. Recently, recommendation systems based on neural networks have become increasingly popular and the applications are expanding, especially in TV program recommendations. However, the opacity of the neural networks has resulted in users being unable to fully trust the predicted recommendations, which increases the need for interpretable recommendation systems. This paper analyzes the interpretability of a recommendation model based on neural networks. We propose a convolutional neural TV program recommendation based on auxiliary information (CNPR-AI) to learn the program features effectively. First, we construct program dictionaries and leverage word embeddings to learn textual auxiliary information to generate program representations. We further learn program representations to generate user representations with convolutional neural networks. Then we input the program representation and user representation into the prediction module to obtain the recommendation results. As SHapley Additive exPlanations (SHAP) can provide interpretation solutions for deep learning, we utilize it to generate visual interpretations for our model to show the role played by each TV program feature in predicting user interests. We believe that the interpretations developed can help users better understand the learning mechanisms of the neural network and reflect different users’ preferences.},
  archive      = {J_IJMLC},
  author       = {Yin, Fulian and Fu, Ruiling and Feng, Xiaoli and Xing, Tongtong and Ji, Meiqi},
  doi          = {10.1007/s13042-023-01850-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3561-3574},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An interpretable neural network TV program recommendation based on SHAP},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved collaborative filtering model based on time
weighted correlation coefficient and inter-cluster separation.
<em>IJMLC</em>, <em>14</em>(10), 3543–3560. (<a
href="https://doi.org/10.1007/s13042-023-01849-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recommendation system is a good choice to provide users with personalized services. Facing with a large amount of data, clustering technology can group similar users into one category, which can make more rapid and accurate recommendations for target users. Due to user’s interests changing over time, how to make reasonable recommendations is an important issue. In this article, an improved k-means clustering algorithm based on cuckoo search is proposed and an improved time correlation coefficient is added to the algorithm to improve the accuracy of recommendation system. The proposed clustering algorithm integrates intra-cluster compactness and inter-cluster separation, which can improve the similarity of users in the same cluster. The proposed time correlation coefficient creatively considers both the inherent connection between user’s preference and time, and the impact of the periodicity and continuity of time on user rating patterns.},
  archive      = {J_IJMLC},
  author       = {Lan, Ruike and Tian, Donghong and Wu, Qianqian and Li, Min},
  doi          = {10.1007/s13042-023-01849-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3543-3560},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An improved collaborative filtering model based on time weighted correlation coefficient and inter-cluster separation},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stochastic configuration networks for adaptive inverse
dynamics modeling. <em>IJMLC</em>, <em>14</em>(10), 3529–3541. (<a
href="https://doi.org/10.1007/s13042-023-01848-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our previous works have shown that an enhanced plant Jacobian is helpful to improve the control performance of the inverse dynamic neural controller. This paper further studies this control scheme by using stochastic configuration networks (SCNs) and Savitzky–Golay (SG) filter, which can be used to produce higher quality of Jacobian teaching signals. It is observed SCN-based modeling techniques with reduced noise of estimated Jacobian can make the tracking performance favorably. Convergence and stability analysis of the closed-loop system are given. Comprehensive simulations are carried out, and results clearly demonstrate the effectiveness of our proposed method.},
  archive      = {J_IJMLC},
  author       = {Dang, Gang and Wang, Dianhui},
  doi          = {10.1007/s13042-023-01848-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3529-3541},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Stochastic configuration networks for adaptive inverse dynamics modeling},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lightweight single image super-resolution based on
multi-path progressive feature fusion and attention mechanism.
<em>IJMLC</em>, <em>14</em>(10), 3517–3528. (<a
href="https://doi.org/10.1007/s13042-023-01847-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single image super-resolution (SISR) is a fundamental image processing task, which aims to generate a high-resolution (HR) image from its low-resolution (LR) counterpart. Deep convolution neural networks (CNNs) have significantly improved the performance of SISR, and dominated the current research on SISR techniques. However, the performance improvement depends heavily on the size of the networks. In general, the deeper the networks, the better the performance, which limits their use to devices with limited computing and memory resources. The challenge is to find the optimal balance between network model complexity and SISR performance. In this paper, we propose a new lightweight SISR algorithm based on CNNs, which uses multi-path progressive feature fusion and attention mechanism. Our main contributions are as follows: (1) We propose a multi-path progressive feature fusion block (PFF), which can use the feature from the previous path to gradually guide the feature learning of the next path step by step in multiple paths. (2) We propose a multi-path feature attention mechanism (FAM), which can adaptively weigh the multi-path feature channels to be concatenated, improve the utilization of feature information and feature representation capability. The experimental results show that whether it is an objective measurement or a subjective measurement, our method is better than other similar state of the art methods, and has a better model complexity and performance balance.},
  archive      = {J_IJMLC},
  author       = {Li, Shanshan and Zhou, Dengwen and Liu, Yukai and Gao, Dandan and Wang, Wanjun},
  doi          = {10.1007/s13042-023-01847-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3517-3528},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Lightweight single image super-resolution based on multi-path progressive feature fusion and attention mechanism},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic graph-based attribute reduction approach with fuzzy
rough sets. <em>IJMLC</em>, <em>14</em>(10), 3501–3516. (<a
href="https://doi.org/10.1007/s13042-023-01846-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incremental datasets are becoming increasingly common as interesting data are continually accumulated across various application fields. Selecting informative attributes from dynamically changing datasets poses numerous challenges. Completely reapplying the attribute reduction algorithm to detect the changes in the data and learn the selected attributes following frequently changing data is prohibitively expensive. In this regard, an incremental processing mechanism is desired to facilitate progressively updating the attribute reducts when the data is updated. In this paper, we consider the maintenance of the fuzzy rough attribute reduction in dynamic data that is changing through the arrival of samples. Based on the transformation of attribute reduction in a fuzzy decision system into the minimal transversal of a derivative hypergraph, a novel dynamic fuzzy rough attribute reduction approach is presented from a graph-theoretic perspective, so as to facilitate efficient computation of reduct in incremental datasets. Extensive experimental evaluation shows that the proposed dynamic graph-based fuzzy rough approach provides significantly faster attribute reduction than completely re-reduction by its original static counterpart as well as the existing dynamic attribute reduction approach based on fuzzy discernibility matrix, and is also effective in preserving the quality of the selected reduct.},
  archive      = {J_IJMLC},
  author       = {Ma, Lei and Luo, Chuan and Li, Tianrui and Chen, Hongmei and Liu, Dun},
  doi          = {10.1007/s13042-023-01846-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3501-3516},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dynamic graph-based attribute reduction approach with fuzzy rough sets},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). An efficient planning method based on deep reinforcement
learning with hybrid actions for autonomous driving on highway.
<em>IJMLC</em>, <em>14</em>(10), 3483–3499. (<a
href="https://doi.org/10.1007/s13042-023-01845-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the complexity and uncertainty of the traffic, planning for autonomous driving (AD) on highway is challenging. Traditional planning algorithms have the problems of low and unstable efficiency, which reduces the real-time performance of the autonomous vehicle (AV). Deep reinforcement learning (DRL) is an emerging and promising method that has achieved amazing performance in many fields. In this paper, we propose a novel planning approach based on soft actor critic (SAC) with hybrid actions. The algorithm takes the structured information of the ego vehicle and the surroundings as input, and generates a termination state on the Frenet space for ego vehicle, then a feasible and continuous spatiotemporal trajectory will be output by a polynomial planner based on the intermediate state. Different from other sampling-based planning methods, only single polynomial planning is required, which improves planning efficiency significantly. Experiments show that DRL agent with hybrid actions is more secure than the agents with only continuous or discrete actions. Compared with other planning methods, the proposed algorithm has the least and most robust time for planning in different scenarios.},
  archive      = {J_IJMLC},
  author       = {Zhang, Mei and Chen, Kai and Zhu, Jinhui},
  doi          = {10.1007/s13042-023-01845-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3483-3499},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An efficient planning method based on deep reinforcement learning with hybrid actions for autonomous driving on highway},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). OSAGGAN: One-shot unsupervised image-to-image translation
using attention-guided generative adversarial networks. <em>IJMLC</em>,
<em>14</em>(10), 3471–3482. (<a
href="https://doi.org/10.1007/s13042-023-01844-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a single-image translation method based on attention guidance to solve the problem of poor image quality in current single-image translation. The model uses a multi-scale pyramid architecture. First, the input image is downsampled, and then the downsampled image is input into the attention-guided generator to complete the translation of an image from the source domain X to the target domain Y. We introduce an attention module and a Scale-Add (SA) module, which can stabilize the training process of GAN and effectively improve the image quality. The attention module can retain the contour and detail of the object. In addition, the Scale-Add (SA) module can adjust the style of the image and add some low-scale detail information. Through extensive experimental verification and comparison with several baseline methods on benchmark datasets, we verify the effectiveness of the proposed framework.},
  archive      = {J_IJMLC},
  author       = {Huo, Xiaofei and Jiang, Bin and Hu, Haotian and Zhou, Xinjiao and Zhang, Bolin},
  doi          = {10.1007/s13042-023-01844-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3471-3482},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {OSAGGAN: One-shot unsupervised image-to-image translation using attention-guided generative adversarial networks},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Domain generalization by distribution estimation.
<em>IJMLC</em>, <em>14</em>(10), 3457–3470. (<a
href="https://doi.org/10.1007/s13042-023-01843-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain generalization generalizes a prediction model trained on multiple source domains to an unseen target domain. The source and target domains are different but related, making cross domain model generalization challenging but possible. Existing works assume that the domains are related by a feature transformation that makes the marginal distributions, the class-conditional distributions, or the posterior distributions similar among the domains, and learn this transformation via kernel mean matching or adversarial training. Here, in a neural network context we relate the source and target domains via the network mapping, innovatively learn this mapping by matching multiple source joint distributions to their mixture distribution, and simultaneously learn a subsequent probabilistic classifier for target domain classification. To quantify the discrepancy among the source joint distributions, we exploit the Kullback–Leibler (KL) divergence, and show that in our case the KL divergence can be approximated via estimating a domain label posterior distribution. We model this discrete posterior distribution as multiple linear functions, and obtain their optimal parameters in an analytic manner. The resulting cost function is a combination of the cross-entropy loss and the estimated KL divergence, which is directly minimized via optimizing the network parameters. The experiments on several publicly available datasets demonstrate the effectiveness of our proposal. We release the source code at https://github.com/sentaochen/Domain-Generalization-by-Distribution-Estimation .},
  archive      = {J_IJMLC},
  author       = {Chen, Sentao and Hong, Zijie},
  doi          = {10.1007/s13042-023-01843-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3457-3470},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Domain generalization by distribution estimation},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pseudo-label driven deep hashing for unsupervised
cross-modal retrieval. <em>IJMLC</em>, <em>14</em>(10), 3437–3456. (<a
href="https://doi.org/10.1007/s13042-023-01842-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of big data and the Internet, cross-modal retrieval has become a popular research topic. Cross-modal hashing is an important research direction in cross-modal retrieval, due to its highly efficiency and small memory consumption. Recently, many unsupervised cross-modal hashing methods achieved great results on cross-modal retrieval tasks. However, how to narrow the heterogeneous gap between different modalities and generate more discriminative hash codes are still the main problems of unsupervised hashing. In this paper, we propose a novel unsupervised cross-modal hashing method Pseudo-label Driven Deep Hashing to solve aforementioned problems. We introduce clustering into our modal to obtain initialized semantical information called pseudo-label, and we propose a novel adjusting method that uses pseudo-labels to adjust joint-semantic similarity matrix. We construct a similarity consistency loss function that focuses on the heterogeneity gap between different modalities, and a real values and binary codes fine-tuning strategy for closing the gap between real value space and Hamming space. We conduct experiments on five datasets including three natural datasets which have larger inter-class distances and two medical datasets which have smaller inter-class distances, the results demonstrate the superiority of our method compared with several unsupervised cross-modal hashing methods.},
  archive      = {J_IJMLC},
  author       = {Zeng, XianHua and Xu, Ke and Xie, YiCai},
  doi          = {10.1007/s13042-023-01842-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3437-3456},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Pseudo-label driven deep hashing for unsupervised cross-modal retrieval},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-layered semantic representation network for
multi-label image classification. <em>IJMLC</em>, <em>14</em>(10),
3427–3435. (<a
href="https://doi.org/10.1007/s13042-023-01841-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label image classification is a fundamental and practical task, which aims to assign multiple possible labels to an image. In recent years, many deep convolutional neural network (CNN) based approaches have been proposed which model label correlations to discover semantics of labels and learn semantic representations of images. This paper advances this research direction by improving both the modeling of label correlations and the learning of semantic representations. On the one hand, besides the local semantics of each label, we propose to further explore global semantics shared by multiple labels. On the other hand, existing approaches mainly learn the semantic representations at the last convolutional layer of a CNN. But it has been noted that the image representations of different layers of CNN capture different levels or scales of features and have different discriminative abilities. We thus propose to learn semantic representations at multiple convolutional layers. To this end, this paper designs a Multi-layered Semantic Representation Network (MSRN) which discovers both local and global semantics of labels through modeling label correlations and utilizes the label semantics to guide the semantic representations learning at multiple layers through an attention mechanism. Extensive experiments on five benchmark datasets including VOC2007, VOC2012, MS-COCO, NUS-WIDE, and Apparel show a competitive performance of the proposed MSRN against state-of-the-art models.},
  archive      = {J_IJMLC},
  author       = {Qu, Xiwen and Che, Hao and Huang, Jun and Xu, Linchuan and Zheng, Xiao},
  doi          = {10.1007/s13042-023-01841-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3427-3435},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-layered semantic representation network for multi-label image classification},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transformer-based contrastive learning framework for image
anomaly detection. <em>IJMLC</em>, <em>14</em>(10), 3413–3426. (<a
href="https://doi.org/10.1007/s13042-023-01840-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection refers to the problem of uncovering patterns in a given data set that do not conform to the expected behavior. Recently, owing to the continuous development of deep representation learning, a large number of anomaly detection approaches based on deep learning models have been developed and achieved promising performance. In this work, an image anomaly detection approach based on contrastive learning framework is proposed. Rather than adopting ResNet or other CNN-based deep neural networks as in most of the previous deep learning-based image anomaly detection approaches to learn representations from training samples, a contrastive learning framework is developed for anomaly detection in which Transformer is adopted for extracting better representations. Then, we develop a triple contrastive loss function and embed it into the proposed contrastive learning framework to alleviate the problem of catastrophic collapse that is often encountered in many anomaly detection approaches. Furthermore, a nonlinear Projector is integrated with our model to improve the performance of anomaly detection. The effectiveness of our image anomaly detection approach is validated through experiments on multiple benchmark data sets. According to the experimental results, our approach can obtain better or comparative performance in comparison with state-of-the-art anomaly detection approaches.},
  archive      = {J_IJMLC},
  author       = {Fan, Wentao and Shangguan, Weimin and Chen, Yewang},
  doi          = {10.1007/s13042-023-01840-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3413-3426},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Transformer-based contrastive learning framework for image anomaly detection},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). OUBoost: Boosting based over and under sampling technique
for handling imbalanced data. <em>IJMLC</em>, <em>14</em>(10),
3393–3411. (<a
href="https://doi.org/10.1007/s13042-023-01839-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most real-world datasets usually contain imbalanced data. Learning from datasets where the number of samples in one class (minority) is much smaller than in another class (majority) creates biased classifiers to the majority class. The overall prediction accuracy in imbalanced datasets is higher than 90\%, while this accuracy is relatively lower for minority classes. In this paper, we first propose a new technique for under-sampling based on the Peak clustering method from the majority class on imbalanced datasets. We then propose a novel boosting-based algorithm for learning from imbalanced datasets, based on a combination of the proposed Peak under-sampling algorithm and over-sampling technique (SMOTE) in the boosting procedure, named OUBoost. In the proposed OUBoost algorithm, misclassified examples are not given equal weights. OUBoost selects useful examples from the majority class and creates synthetic examples for the minority class. In fact, it indirectly updates the weights of samples. We designed experiments using several evaluation metrics, such as Recall, MCC, Gmean, and F-score on 30 real-world imbalanced datasets. The results show improved prediction performance in the minority class in most used datasets using OUBoost. We further report time comparisons and statistical tests to analyze our proposed algorithm in more details.},
  archive      = {J_IJMLC},
  author       = {Mostafaei, Sahar Hassanzadeh and Tanha, Jafar},
  doi          = {10.1007/s13042-023-01839-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3393-3411},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {OUBoost: Boosting based over and under sampling technique for handling imbalanced data},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimizing traffic efficiency via a reinforcement learning
approach based on time allocation. <em>IJMLC</em>, <em>14</em>(10),
3381–3391. (<a
href="https://doi.org/10.1007/s13042-023-01838-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing scale of urbanization, traffic congestion has caused a severe negative impact on the efficiency of social development. To this end, a series of intelligent traffic light control methods based on reinforcement learning are proposed. They get superior performance compared with conventional control methods under certain conditions. However, because of the usage of actions based on switching phase, almost all of these methods cannot provide a countdown function, for the switching phase actions need to be executed immediately. So they are difficult to be applied in most real-world scenarios from the practical consideration of traffic safety and efficiency. For example, without the countdown function, it cannot inform pedestrians how many seconds the green light remains to cross the road. This paper proposes a novel method that can naturally provide a countdown function by adopting a new action design. Specifically, this action design achieves control in the manner of time allocation, and the model figures out the duration of each phase at the beginning of every signal cycle. In this way, our method is more practical for real-world traffic applications. Plenty of simulation experiments show that our method eases congestion substantially in single intersection environments with the countdown requirement, e.g., our model cuts down 74\% waiting time compared with a competitive baseline in the experiment with 2 phases and mix flow.},
  archive      = {J_IJMLC},
  author       = {Xiang, Chao and Jin, Zhongming and Yu, Zhengxu and Hua, Xian-Sheng and Hu, Yao and Qian, Wei and Zhu, Kaili and Cai, Deng and He, Xiaofei},
  doi          = {10.1007/s13042-023-01838-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3381-3391},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Optimizing traffic efficiency via a reinforcement learning approach based on time allocation},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Asymmetric models of intuitionistic fuzzy rough sets and
their applications in decision-making. <em>IJMLC</em>, <em>14</em>(10),
3353–3380. (<a
href="https://doi.org/10.1007/s13042-023-01837-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The variable precision rough set is one of the well-liked extensions of rough sets for misclassification and perturbations. The classical variable precision rough set and some of its extensions are based on equivalence relations. The applicability of those models are constrained by the too-strict equivalence relations. In this paper, we extend equivalence relations in an intuitionistic fuzzy environment and put forward some intuitionistic fuzzy neighborhoods. The classical variable precision rough set is based on two thresholds $$\beta$$ and $$1-\beta$$ to construct the $$\beta$$ -lower and $$\beta$$ -upper approximations. The sum of two thresholds is 1. They are called the symmetrical thresholds. If the sum of two thresholds is not always 1, we call them asymmetrical thresholds. The model with symmetrical thresholds is called a symmetric model while the model with asymmetrical thresholds is called an asymmetric model. The thresholds play a key role in the classical variable precision rough set. However, the condition that the sum of two thresholds is 1, is too harsh to limit the applications of the classical variable precision rough set. Following the probabilistic rough sets, we weaken the conditions and propose three types of asymmetric models of intuitionistic fuzzy rough set models. These proposed models, which are the generalizations of the classical variable precision rough sets, are capable of successfully resolving uncertain problems with hesitant degrees, misclassifications, and perturbations in the intuitionistic fuzzy covering approximate space. The first type of our proposed model has greater accuracy than other two types of models. A new multi-attribute decision-making approach is proposed in order to effectively use our proposed models, combining the benefits of the traditional PROMETHEE and TOPSIS procedures. Two illustrated instances are also presented to test the decision-making process. The proposed method’s viability and efficacy are shown by comparison analysis, sensitivity analysis, and validity analysis.},
  archive      = {J_IJMLC},
  author       = {Zhang, Li and Zhu, Ping},
  doi          = {10.1007/s13042-023-01837-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3353-3380},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Asymmetric models of intuitionistic fuzzy rough sets and their applications in decision-making},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LSTM with spatiotemporal attention for IoT-based wireless
sensor collected hydrological time-series forecasting. <em>IJMLC</em>,
<em>14</em>(10), 3337–3352. (<a
href="https://doi.org/10.1007/s13042-023-01836-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is necessary to accurately assess the inflow and infiltration conditions in sewer systems if sewer overflows are to be avoided. In this regard, Long Short-Term Memory (LSTM) is widely utilized for hydrological time-series forecasting. However, hydrological time-series have been found to be highly nonlinear and dynamic, such that the original LSTM model cannot simultaneously consider the spatiotemporal correlations of the input sequences for water flow rate forecasting. To address this problem, we propose using an LSTM with spatiotemporal attention (LSTM-STA) model, one based on encoder-decoder architecture, as this will allow accurate forecasting of the water flow rate. The encoder incorporates a spatial attention mechanism module allowing it to adaptively capture the key spatial attributes from all related spatial attributes at each time step. The decoder also incorporates a temporal attention mechanism module for dynamically discovering the key encoder hidden states from all time steps in the window. Using the spatiotemporal attention mechanism, the LSTM-STA model comprehensively considers all the important factors influencing the water flow rate forecasting, in both temporal and spatial dimensions. We performed extensive experiments; applying the LSTM-STA model to real-world hydrological time-series datasets, each one containing 52,704 sampled data points while leveraging state-of-the-art SVR-rbf, MLP, CNN1D, GRU, LSTM, Encoder-Decoder, LSTM-SA, and LSTM-TA as baselines. The experimental results demonstrated that the LSTM-STA model outperforms the state-of-the-art baseline models. Specifically, the LSTM-STA model yields the lowest RMSE, MAE, MAPE, and the highest R2 in the test process, said values being 73.19, 33.37, 1.09, and 0.99858, respectively. We also verified the stability and hyperparameter sensitivity of the LSTM-STA model. Furthermore, we visualized the spatial attention weights and benefitted from spatial interpretability.},
  archive      = {J_IJMLC},
  author       = {Huang, Jianying and Li, Jinhui and Oh, Jeill and Kang, Hoon},
  doi          = {10.1007/s13042-023-01836-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3337-3352},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {LSTM with spatiotemporal attention for IoT-based wireless sensor collected hydrological time-series forecasting},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Coarse-to-fine knowledge transfer based long-tailed
classification via bilateral-sampling network. <em>IJMLC</em>,
<em>14</em>(10), 3323–3336. (<a
href="https://doi.org/10.1007/s13042-023-01835-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-tailed classification faces a considerable challenge from the imbalanced distribution of head and tail data. Re-sampling is a traditional Single Branch Sampling (SBS) method used to adjust data imbalances that effectively improves the performance of long-tailed classification models. Most existing SBS models assume that the classes are independent of each other and ignore the hierarchical relations among the classes. However, the hierarchical structure is exhibited as coarse- and fine-grained semantic relations, a significant knowledge to guide long-tailed classification. In this paper, we propose a Coarse-to-Fine knowledge transfer based Bilateral-Sampling Network (CFBSNet) for long-tailed classification that alleviates the effects of imbalances in long-tailed data and considers coarse- and fine-grained semantic relationships. First, we present a Bilateral-Branch Sampling Network consisting of two sampling branches. The two sampling branches perform reverse sampling and uniform sampling, respectively. Second, we design a Coarse-to-Fine Knowledge Transfer strategy that regulates different learning stages by adjusting loss weight in each task progressively. CFBSNet pays attention to the semantic relationship between tail data and granularity. The experimental results demonstrated the effectiveness of CFBSNet for long-tailed classification tasks. For instance, the classification accuracy of CFBSNet is 3.16 $$\%$$ and 2.62 $$\%$$ better than that of baseline models on the CIFAR-100-LT and the SUN datasets, respectively.},
  archive      = {J_IJMLC},
  author       = {Xu, Junyan and Zhao, Wei and Zhao, Hong},
  doi          = {10.1007/s13042-023-01835-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3323-3336},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Coarse-to-fine knowledge transfer based long-tailed classification via bilateral-sampling network},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning-based robust model predictive control with
data-driven koopman operators. <em>IJMLC</em>, <em>14</em>(9),
3295–3321. (<a
href="https://doi.org/10.1007/s13042-023-01834-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a data-driven control strategy for nonlinear dynamical systems, which fully exploits the advantages of the Koopman operator in globally linearizing nonlinear dynamical systems. We first generalize the Koopman operator framework to the controlled nonlinear systems, enabling comprehensive linear analysis and control methods to be valid for nonlinear systems. When extracting the Koopman operator approximation from data, model uncertainty always arises due to the variation of the data-driven setting. We next present a hierarchical neural network (HNN) approach to approximate the finite-dimensional Koopman operator representations and construct multiple Koopman-based lifted models for original controlled nonlinear systems in a polytope set construction. Based on that, a robust Koopman-based model predictive control (rKMPC) approach considering state and input constraints is constructed to realize the control of the original nonlinear systems. In particular, we extend the proposed rKMPC framework to a Koopman operator-based reduced-order model, thereby achieving the nonlinear control using only a few given inputs. Finally, several numerical examples and a physical experiment are provided to demonstrate the effectiveness of the proposed data-driven control approach, and numerical comparisons are carried out with existing Koopman-based control methods.},
  archive      = {J_IJMLC},
  author       = {Wang, Meixi and Lou, Xuyang and Cui, Baotong},
  doi          = {10.1007/s13042-023-01834-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {3295-3321},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Learning-based robust model predictive control with data-driven koopman operators},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Siamese infrared and visible light fusion network for RGB-t
tracking. <em>IJMLC</em>, <em>14</em>(9), 3281–3293. (<a
href="https://doi.org/10.1007/s13042-023-01833-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the different photosensitive properties of infrared and visible light, infrared and visible light images have individual features. However, since the registered RGB-T image pairs shot in the same scene, they also contain common features. This paper proposes a Siamese infrared and visible light fusion Network (SiamIVFN) for RBG-T image-based tracking. SiamIVFN contains two main subnetworks: a complementary-feature-fusion network (CFFN) and a contribution-aggregation network (CAN). CFFN utilizes a two-stream multilayer convolutional structure that separately extracts individual features, and filters in each layer are partially coupled to extract common features. CFFN is a feature-level fusion network, which can cope with the misalignment of the RGB-T image pairs. Through adaptively calculating the contributions of infrared and visible light features obtained from CFFN, CAN makes the tracker robust under various light conditions. Experiments show that compared to state-of-the-art techniques, SiamIVFN improves the PR/SR score with 1.5\%/8.8\% on RGBT234 and 2.1\%/6.9\% on GTOT. The tracking speed of SiamIVFN is 147.6FPS, the current fastest RGB-T fusion tracker. The source codes are available at https://github.com/PengJingchao/SiamIVFN .},
  archive      = {J_IJMLC},
  author       = {Peng, Jingchao and Zhao, Haitao and Hu, Zhengwei and Zhuang, Yi and Wang, Bofan},
  doi          = {10.1007/s13042-023-01833-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {3281-3293},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Siamese infrared and visible light fusion network for RGB-T tracking},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A three-way decisions approach based on double hierarchy
linguistic aggregation operators of strict t-norms and t-conorms.
<em>IJMLC</em>, <em>14</em>(9), 3257–3280. (<a
href="https://doi.org/10.1007/s13042-023-01832-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the massive increase in uncertainty of linguistic information in realistic decision making, there is a great challenge for people to make decisions in the complex linguistic environment. To overcome this challenge, this paper proposes a three-way decisions method based on aggregation operators of strict t-norms and t-conorms under double hierarchy linguistic environment. By mining the double hierarchy linguistic information, strict t-norms and t-conorms are introduced to define the operation rules and their operation examples are also given. Then, the double hierarchy linguistic weighted average (DHLWA) operator and weighted geometric (DHLWG) operator are proposed based on strict t-norms and t-conorms. Besides, some of their important properties are also proved and derived, such as idempotency, boundedness and monotonicity. Next, DHLWA and DHLWG are integrated with three-way decisions to construct our three-way decisions model. Specifically, the double hierarchy linguistic decision theoretic rough set (DHLDTRS) model is constructed by incorporating the computational model of expected loss with DHLWA and DHLWG, which can consider the various decision attitudes from decision makers more adequately. Furthermore, we also propose a novel entropy weight calculation formula to improve the entropy weight method for obtaining the weights more objectively, and integrate grey relational analysis (GRA) method to calculate the conditional probability. Based on the Bayesian minimum-loss decision rules, the solving method of our model is also propounded and the corresponding algorithm is designed. Finally, an illustrative example and experimental analysis are presented, which can validate the rationality, robustness as well as superiority of our method.},
  archive      = {J_IJMLC},
  author       = {Zhong, Yihua and Wu, Ping and Chen, Chuan and Min, Chao and Yong, Xue},
  doi          = {10.1007/s13042-023-01832-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {3257-3280},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A three-way decisions approach based on double hierarchy linguistic aggregation operators of strict t-norms and t-conorms},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BART-based contrastive and retrospective network for
aspect-category-opinion-sentiment quadruple extraction. <em>IJMLC</em>,
<em>14</em>(9), 3243–3255. (<a
href="https://doi.org/10.1007/s13042-023-01831-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-category-opinion-sentiment (ACOS) quadruple extraction is a fine-grained sentiment analysis task to extract full sentiment information, which aims to extract all the ACOS quads in a given sentence. ACOS contains four types of quads: explicit aspect and explicit opinion, implicit aspect and explicit opinion, explicit aspect and implicit opinion, and implicit aspect and implicit opinion. Current studies generally apply the two-stage methods to ACOS studies. However, there are two main limitations. One is the error propagation while the other is the ignorance of diversity among different types of quads. In this work, we propose a BART-based Contrastive and Retrospective Network (BART-CRN), which tackles ACOS extraction as a sequence generation task. Specifically, a machine reading comprehension based (MRC-based) supervised contrastive and retrospective learning module is developed, which aims to learn the associations among all types of quads and determines the context-related generative quads through an end-to-end way. Experimental results on two ACOS datasets reveal that our model outperforms the baseline methods and achieves advanced performances.},
  archive      = {J_IJMLC},
  author       = {Xiong, Haoliang and Yan, Zehao and Wu, Chuhan and Lu, Guojun and Pang, Shiguan and Xue, Yun and Cai, Qianhua},
  doi          = {10.1007/s13042-023-01831-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {3243-3255},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {BART-based contrastive and retrospective network for aspect-category-opinion-sentiment quadruple extraction},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AANet: Adaptive attention network for rolling bearing fault
diagnosis under varying loads. <em>IJMLC</em>, <em>14</em>(9),
3227–3241. (<a
href="https://doi.org/10.1007/s13042-023-01830-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, modern intelligent fault diagnosis algorithms based on deep learning have been widely used to recognize the health state of rolling bearings. However, the constantly varying load in real industry leads to unsatisfactory diagnosis results. How to make the models effectively diagnose the health state of rolling bearings under varying loads is a key issue. In this paper, an Adaptive Attention Network (AANet) is proposed to resolve the issue. That the interference is introduced by the Multi-scale Convolution Module with wide kernels (MCM) at the head of the AANet is the premise for extending the model to other loads. And the Adaptive Attention Modules (AAMs) embedded in the AANet distinguishe state-related features and unrelated features, which enhances the diagnostic ability of the model across loads. In order to verify the effectiveness of the algorithm, experiments have been performed on a public data set. Experimental results show that the average accuracy of this algorithm achieves 0.976, which can effectively recognize the health state of rolling bearings under varying loads, compared to other algorithms.},
  archive      = {J_IJMLC},
  author       = {Sun, Shixin and Gao, Jie and Wang, Wei and Du, Jinsong and Yang, Xu},
  doi          = {10.1007/s13042-023-01830-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {3227-3241},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {AANet: Adaptive attention network for rolling bearing fault diagnosis under varying loads},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal interventional policy based on discrete-time fuzzy
rules equivalent model utilizing with COVID-19 pandemic data.
<em>IJMLC</em>, <em>14</em>(9), 3217–3226. (<a
href="https://doi.org/10.1007/s13042-023-01829-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a mathematical model of the COVID-19 pandemic is formulated by fitting it to actual data collected during the fifth wave of the COVID-19 pandemic in Coahuila, Mexico, from June 2022 to October 2022. The data sets used are recorded on a daily basis and presented in a discrete-time sequence. To obtain the equivalent data model, fuzzy rules emulated networks are utilized to derive a class of discrete-time systems based on the daily hospitalized individuals’ data. The aim of this study is to investigate the optimal control problem to determine the most effective interventional policy including precautionary and awareness measures, the detection of asymptomatic and symptomatic individuals, and vaccination. A main theorem is developed to guarantee the closed-loop system performance by utilizing approximate functions of the equivalent model. The numerical results indicate that the proposed interventional policy can eradicate the pandemic within 1–8 weeks. Additionally, the results show that if the policy is implemented within the first 3 weeks, the number of hospitalized individuals remains below the hospital’s capacity.},
  archive      = {J_IJMLC},
  author       = {Treesatayapun, C.},
  doi          = {10.1007/s13042-023-01829-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {3217-3226},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Optimal interventional policy based on discrete-time fuzzy rules equivalent model utilizing with COVID-19 pandemic data},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IMovieRec: A hybrid movie recommendation method based on a
user-image-item model. <em>IJMLC</em>, <em>14</em>(9), 3205–3216. (<a
href="https://doi.org/10.1007/s13042-023-01828-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose iMovieRec, a hybrid movie recommendation method that employs an image-user-item model, which utilizes both CF models and graph features. The purpose of this model is to efficiently learn the interactions between users and items and the key features of the poster images using single layer neural networks and matrix factorization. In particular, we consider various types of graph architectures to determine the graph structure that would express the relationship between users and items. The experimental results obtained using two benchmarking datasets indicate that iMovieRec is more efficient than the other recommendation models, which exhibit limited and varied image feature effects. In addition, we make both our datasets and the iMovieRec model publicly available.},
  archive      = {J_IJMLC},
  author       = {Hwang, Syjung and Ahn, Hyeongjin and Park, Eunil},
  doi          = {10.1007/s13042-023-01828-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {3205-3216},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {IMovieRec: A hybrid movie recommendation method based on a user-image-item model},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RePGAN: Image inpainting via residual partial connection and
mask discriminator. <em>IJMLC</em>, <em>14</em>(9), 3193–3203. (<a
href="https://doi.org/10.1007/s13042-023-01827-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, image inpainting approaches have shown remarkable improvements by employing encoder-decoder-based convolutional neural networks (CNNs). An important issue is that texture information is lost during the convolution procedure. Previous works addressed this problem by employing skip connection strategies, which deliver encoder features to a symmetrical decoder, neglecting the fact that the shallow encoder layers contain both zeros and noise. In this paper, we propose a novel strategy that applies a residual partial module (RePM) to divide the feature maps into two branches (i.e., identity and residual branches) to replace skip connections. The identity branch retains the texture information, and the residual branch eliminates noise. Moreover, we propose a mask discriminator that judges the ground truth of the missing area. Experiments on benchmark datasets show the effectiveness of our method in producing coherent images, with our approach performing favourably against existing approaches.},
  archive      = {J_IJMLC},
  author       = {Sun, Lin and Jiang, Bin and Yang, Chao and Dai, Jiawu and Zeng, Weiyuan},
  doi          = {10.1007/s13042-023-01827-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {3193-3203},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {RePGAN: Image inpainting via residual partial connection and mask discriminator},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BenchMetrics prob: Benchmarking of probabilistic error/loss
performance evaluation instruments for binary classification problems.
<em>IJMLC</em>, <em>14</em>(9), 3161–3191. (<a
href="https://doi.org/10.1007/s13042-023-01826-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic error/loss performance evaluation instruments that are originally used for regression and time series forecasting are also applied in some binary-class or multi-class classifiers, such as artificial neural networks. This study aims to systematically assess probabilistic instruments for binary classification performance evaluation using a proposed two-stage benchmarking method called BenchMetrics Prob. The method employs five criteria and fourteen simulation cases based on hypothetical classifiers on synthetic datasets. The goal is to reveal specific weaknesses of performance instruments and to identify the most robust instrument in binary classification problems. The BenchMetrics Prob method was tested on 31 instrument/instrument variants, and the results have identified four instruments as the most robust in a binary classification context: Sum Squared Error (SSE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE, as the variant of MSE), and Mean Absolute Error (MAE). As SSE has lower interpretability due to its [0, ∞) range, MAE in [0, 1] is the most convenient and robust probabilistic metric for generic purposes. In classification problems where large errors are more important than small errors, RMSE may be a better choice. Additionally, the results showed that instrument variants with summarization functions other than mean (e.g., median and geometric mean), LogLoss, and the error instruments with relative/percentage/symmetric-percentage subtypes for regression, such as Mean Absolute Percentage Error (MAPE), Symmetric MAPE (sMAPE), and Mean Relative Absolute Error (MRAE), were less robust and should be avoided. These findings suggest that researchers should employ robust probabilistic metrics when measuring and reporting performance in binary classification problems.},
  archive      = {J_IJMLC},
  author       = {Canbek, Gürol},
  doi          = {10.1007/s13042-023-01826-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {3161-3191},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {BenchMetrics prob: Benchmarking of probabilistic error/loss performance evaluation instruments for binary classification problems},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Irregular convolution strategy based tensorized type-2
single layer feedforward network. <em>IJMLC</em>, <em>14</em>(9),
3129–3159. (<a
href="https://doi.org/10.1007/s13042-023-01825-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensorized type-2 single layer feedforward network extends the single layer feedforward network with tensorized type-2 fuzzy structure. In the tensorized type-2 single layer feedforward network, type-2 fuzzy sets are used to generate tensor with lower membership function, principal membership function and upper membership function. Other compositions of the single layer feedforward network, such as defuzzification results, weighted averaged results and different type reduction results could also be formed by the tensorized fuzzy construction method. In thus doing, the type-reduction or defuzzification approach is the unimportance procedure in the fuzzy network operation and construction. To deeply unveil the implicit information hidden in the type-2 fuzzy sets, cross-shaped convolution with irregular convolution kernel is used to form the tensor. The named irregular convolution kernel based tensorized type-2 single layer feedforward network adopts an iterative tensor equation solving algorithm with tensor inequality constraint (Huang and Ma in Linear Multilinear Algebra, 1–24, 2021, https://doi.org/10.1080/03081087.2021.1954140 ). Finally, the effectiveness of different convolution kernels for irregular convolution strategy based tensorized type-2 single layer feedforward network are tested. Comparisons are carried out on several benchmark datasets, and five different type-reduction methods for the irregular convolution strategy based tensorized type-2 single layer feedforward network are compared. Results show that the proposed learning method could be improved with this new information extraction strategy.},
  archive      = {J_IJMLC},
  author       = {Li, Jie and Zhao, Guoliang and Huang, Sharina and Weng, Zhi},
  doi          = {10.1007/s13042-023-01825-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {3129-3159},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Irregular convolution strategy based tensorized type-2 single layer feedforward network},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An attention-based automatic vulnerability detection
approach with GGNN. <em>IJMLC</em>, <em>14</em>(9), 3113–3127. (<a
href="https://doi.org/10.1007/s13042-023-01824-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vulnerability detection has long been an important issue in software security. The existing methods mainly define the rules and features of vulnerabilities through experts, which are time-consuming and laborious, and usually with poor accuracy. Thus automatic vulnerability detection methods based on code representation graph and Graph Neural Network (GNN) have been proposed with the advantage of effectively capture both the semantics and structure information of the source code, showing a better performance. However, these methods ignore the redundant information in the graph and the GNN model, leading to a still unsatisfactory performance. To alleviate this problem, we propose a attention-based automatic vulnerability detection approach with Gated Graph Sequence Neural Network (GGNN). Firstly, we introduce two preprocessing methods namely pruning and symbolization representation to reduce the redundant information of the input code representation graph, and then put the graph into the GGNN layer to update the node features. Next, the key subgraph extraction and global feature aggregation are realized through the attention-based Pooling layers. Finally, the classification result is obtained through a linear classifier. The experimental results show the effectiveness of our proposed preprocessing methods and attention-based Pooling layers, especially the higher Accuracy and F1-score gains compared with the state-of-the-art automatic vulnerability detection approaches.},
  archive      = {J_IJMLC},
  author       = {Tang, Gaigai and Yang, Lin and Zhang, Long and Cao, Weipeng and Meng, Lianxiao and He, Hongbin and Kuang, Hongyu and Yang, Feng and Wang, Huiqiang},
  doi          = {10.1007/s13042-023-01824-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {3113-3127},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An attention-based automatic vulnerability detection approach with GGNN},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Text semantic matching with an enhanced sample building
method based on contrastive learning. <em>IJMLC</em>, <em>14</em>(9),
3105–3112. (<a
href="https://doi.org/10.1007/s13042-023-01823-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text semantic matching aims to determine whether two pieces of text point to the same semantic, which has been widely applied in clinical terminology standardization, recommendation systems, and other scenarios. Recently, many existing methods introduce the idea of contrast learning, to construct positive sample pairs and negative sample pairs for text semantic matching tasks. These methods first construct positive samples by using data augmentation and then use other samples within the same group as negative samples. However, the existing mainstream data enhancement methods like dropout ignore the impact of sentence length structure, and the implementation of the word repetition method is relatively complex. On the other hand, a sufficient number of negative samples is also crucial to the quality of model training. In this paper, we propose an enhanced sample building method (ESNCSE) to construct positive samples and negative samples for text semantic matching tasks. To generate positive sample pairs, we randomly insert some punctuation marks into the original text, which aims to add noise simply and efficiently. For the expansion of the number of negative samples without increasing calculation cost, we utilize the momentum contrast based on the sentence embedding method with soft negative sample (SNCSE). The experiment results on text semantic similarity task show that the average Spearman correlation coefficient is 79.74\% for BERT-base and 80.64\% for BERT-large.},
  archive      = {J_IJMLC},
  author       = {Wu, Lishan and Hu, Jie and Teng, Fei and Li, Tianrui and Du, Shengdong},
  doi          = {10.1007/s13042-023-01823-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {3105-3112},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Text semantic matching with an enhanced sample building method based on contrastive learning},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Link prediction for heterogeneous information networks based
on enhanced meta-path aggregation and attention mechanism.
<em>IJMLC</em>, <em>14</em>(9), 3087–3103. (<a
href="https://doi.org/10.1007/s13042-023-01822-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous link prediction aims to reveal potential connections between two nodes in heterogeneous information networks. Most existing studies are based on meta-paths, but ignore the information contained in incomplete meta-paths. They simply aggregate meta-paths, leading to mining semantic information insufficiently. To solve this problem, we propose a link prediction model based on enhanced meta-path aggregation and attention mechanism. In this model, the deficiency of missing topological information from incomplete meta-paths is compensated by aggregating structural features and semantics. Different from existing meta-path encoders, we use recurrent neural networks and the attention mechanism to learn explicit and implicit semantic knowledge from meta-paths, which can capture more complex semantic associations between nodes. In addition, to avoid duplicate feature acquisition by random walking, we design a novel bidirectional biased random walking algorithm. It is applied to guide the generation of heterogeneous neighbors of each node that contain features ignored by the meta-path-wise model, which can mine complete topological information and get more accurate link prediction results. The extensive experiments on several datasets demonstrate that the proposed model outperforms baselines.},
  archive      = {J_IJMLC},
  author       = {Shao, Hao and Wang, Lunwen and Zhu, Rangang},
  doi          = {10.1007/s13042-023-01822-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {3087-3103},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Link prediction for heterogeneous information networks based on enhanced meta-path aggregation and attention mechanism},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recommendation model based on multi-grained interaction that
fuses users’ dynamic interests. <em>IJMLC</em>, <em>14</em>(9),
3071–3085. (<a
href="https://doi.org/10.1007/s13042-023-01821-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Users leave many reviews while participating in network activities, and these have been proven to improve the performance of recommendation systems. However, most current works in the field of rating prediction only capture preference information from the single granularity of each review. This inevitably incurs the loss of fine-grained information in reviews. In addition, people do not realize that the usefulness of reviews is also affected by the dynamics of time. User interests continuously change over time, and reviews at different stages have different meanings for user interest modeling. Therefore, we propose a new dynamic multi-granular interaction recommendation (DMIR) model. First, the model does not aggregate reviews into a single vector but rather extracts the feature information from the multi-granular fragments of each review by dilated convolution. Second, the model uses multi-granular feature information to construct the personalized fine-grained interactions between users and items. At the same time, the model assigns each user’s dynamic interest representation according to the user’s interaction with the item at different stages and obtains the corresponding user-item interactions based on the dynamic interest. Finally, we design a gating mechanism to fuse the ratings obtained by two interactions for the final rating prediction. After extensive experiments conducted on five standard datasets based on Amazon, the results show that DMIR achieves a substantial improvement over the existing state-of-the-art models in terms of rating prediction. Additionally, fusing the user’s dynamic interest and multi-granular text interactions not only improves the performance of the model but also enhances the robustness of rating prediction.},
  archive      = {J_IJMLC},
  author       = {Yang, Zhenyu and Wang, Yu and Liu, Guojing and Li, Zhe and Wang, Xingang},
  doi          = {10.1007/s13042-023-01821-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {3071-3085},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Recommendation model based on multi-grained interaction that fuses users’ dynamic interests},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ESTI: An action recognition network with enhanced
spatio-temporal information. <em>IJMLC</em>, <em>14</em>(9), 3059–3070.
(<a href="https://doi.org/10.1007/s13042-023-01820-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action recognition is an active topic in video understanding, which aims to recognize human actions in videos. The critical step is to model the spatio-temporal information and extract key action clues. To this end, we propose a simple and efficient network (dubbed ESTI) which consists of two core modules. The Local Motion Extraction module highlights the short-term temporal context. While the Global Multi-scale Feature Enhancement module strengthens the spatio-temporal and channel features to model long-term information. By appending ESTI to a 2D ResNet backbone, our network is capable of reasoning different kinds of actions with various amplitudes in videos. Our network is developed under two Geforce RTX 3090 using Python3.7/Pytorch1.8. Extensive experiments have been conducted on 5 mainstream datasets to verify the effectiveness of our network, in which ESTI outperforms most of the state-of-the-arts methods in terms of accuracy, computational cost and network scale. Besides, we also visualize the feature representation of our model by using Grad-Cam to validate its accuracy.},
  archive      = {J_IJMLC},
  author       = {Jiang, ZhiYu and Zhang, Yi and Hu, Shu},
  doi          = {10.1007/s13042-023-01820-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {3059-3070},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {ESTI: An action recognition network with enhanced spatio-temporal information},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep hashing via multi-scale and multi-directional pooling
for image retrieval. <em>IJMLC</em>, <em>14</em>(9), 3047–3057. (<a
href="https://doi.org/10.1007/s13042-023-01819-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Hashing methods have been widely used for large-scale image retrieval due to its advantages in retrieval efficiency and accuracy. Recent methods cannot effectively capture the scale variation and complex distribution of image features in the feature extraction process. As a result, these methods were easily affected by the environment and the retrieval accuracy is not high. In this regard, we propose multi-scale and multi-direction pooling for deep hashing (MMDH). Specifically, the proposed method uses a multi-direction strip pooling module (MSPM) so that it can also fuse the features in the diagonal direction. Also, we combine MSPM with pyramid pooling which capture multi-scale features to build a hybrid pooling module. The input image is subjected to the hybrid pooling operation to extract multi-scale and multi-direction image features which can help the network improve its feature extraction ability. The atrous spatial pyramid pooling operation is used to retain the multi-scale features further to help the model analyze the image structure flexibly and effectively. The experimental results show that the proposed method can perform well on two public datasets. In addition, to verify the generality of the results, we also conducted experiments on the cloth dataset Fabric. The results prove that the proposed method can better extract multi-scale and multi-direction image feature information in various situations.},
  archive      = {J_IJMLC},
  author       = {Rao, Yunbo and Zhou, Wang and Zeng, Shaoning and Xue, Junmin},
  doi          = {10.1007/s13042-023-01819-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {3047-3057},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Deep hashing via multi-scale and multi-directional pooling for image retrieval},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Robust unsupervised feature selection via dual space latent
representation learning and adaptive structure learning. <em>IJMLC</em>,
<em>14</em>(9), 3025–3045. (<a
href="https://doi.org/10.1007/s13042-023-01818-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Great significance has been attached to unsupervised feature selection in consideration of the difficulty in obtaining labels. Existent unsupervised feature selection methods have the following three main shortcomings: (1) The link information between features and that between samples are not taken into account simultaneously. (2) A fixed graph is constructed to preserve the local manifold structure. (3) The impact of the different sparsification terms is ignored. To tackle these problems, robust unsupervised feature selection via dual space latent representation learning and adaptive structure learning, DSLRAS in short, is proposed. The algorithm captures the correlation between features and the correlation between samples on the basis of latent representation learning in both feature space and data space. Adaptive graph learning is utilized to maintain the local geometric structure of data more accurately. The $${l_{2,p}}$$ -norm regularization term is added so as to guarantee the row-sparsity and achieve better results. An efficient algorithm is designed to optimize the minimization problem iteratively. The convergence is proved in theory and in experiments. Extensive experiments on nine benchmark datasets are conducted which verify the effectiveness of DSLRAS in comparison with seven state-of-the-art algorithms.},
  archive      = {J_IJMLC},
  author       = {Li, Weiyi and Chen, Hongmei and Li, Tianrui and Yin, Tengyu and Luo, Chuan},
  doi          = {10.1007/s13042-023-01818-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {3025-3045},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Robust unsupervised feature selection via dual space latent representation learning and adaptive structure learning},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning positioning policies for mobile manipulation
operations with deep reinforcement learning. <em>IJMLC</em>,
<em>14</em>(9), 3003–3023. (<a
href="https://doi.org/10.1007/s13042-023-01815-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work focuses on the operation of picking an object on a table with a mobile manipulator. We use deep reinforcement learning (DRL) to learn a positioning policy for the robot’s base by considering the reachability constraints of the arm. This work extends our first proof-of-concept with the ultimate goal of validating the method on a real robot. Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm is used to model the base controller, and is optimised using the feedback from the MoveIt! based arm planner. The idea is to encourage the base controller to position itself in areas where the arm reaches the object. Following a simulation-to-reality approach, first we create a realistic simulation of the robotic environment in Unity, and integrate it in Robot Operating System (ROS). The drivers for both the base and the arm are also implemented. The DRL-based agent is trained in simulation and, both the robot and target poses are randomised to make the learnt base controller robust to uncertainties. We propose a task-specific setup for TD3, which includes state/action spaces, reward function and neural architectures. We compare the proposed method with the baseline work and show that the combination of TD3 and the proposed setup leads to a $$11\%$$ higher success rate than with the baseline, with an overall success rate of $$97\%$$ . Finally, the learnt agent is deployed and validated in the real robotic system where we obtain a promising success rate of $$75\%$$ .},
  archive      = {J_IJMLC},
  author       = {Iriondo, Ander and Lazkano, Elena and Ansuategi, Ander and Rivera, Andoni and Lluvia, Iker and Tubío, Carlos},
  doi          = {10.1007/s13042-023-01815-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {3003-3023},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Learning positioning policies for mobile manipulation operations with deep reinforcement learning},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A static video summarization approach via block-based
self-motivated visual attention scoring mechanism. <em>IJMLC</em>,
<em>14</em>(9), 2991–3002. (<a
href="https://doi.org/10.1007/s13042-023-01814-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since automatic visual semantic comprehension of video content is currently infeasible and unintelligent, key frames extracted from videos are inconsistent with human visual understanding. In this paper, a block-based self-motivated visual attention scoring mechanism named the BSVAS mechanism is proposed for extracting key frames. The approach described in this paper first reduces the dimensionality of the video by exploiting entropy as a static global characteristic measurement. Next, two block-based motion metrics are employed to express features from a spatiotemporal perspective, and a novel self-motivated strategy is applied to conduct feature fusion. Finally, a self-motivated scoring algorithm is performed to evaluate content attractiveness and frame importance to generate key frames. Experiments on gesture videos with various postures demonstrate that key frames extracted using the proposed method provide high-quality video summaries and cover the main content of the gesture videos as compared to several other excellent mechanisms in the literature.},
  archive      = {J_IJMLC},
  author       = {Li, Wen-lin and Zhang, Tong and Liu, Xiao},
  doi          = {10.1007/s13042-023-01814-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2991-3002},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A static video summarization approach via block-based self-motivated visual attention scoring mechanism},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Importance-aware contrastive learning via semantically
augmented instances for unsupervised sentence embeddings.
<em>IJMLC</em>, <em>14</em>(9), 2979–2990. (<a
href="https://doi.org/10.1007/s13042-023-01813-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attaining better sentence embeddings benefits a wide range of natural language processing tasks. SimCSE applied a simple contrastive learning framework to train BERT models and achieved excellent sentence embeddings. Based on SimCSE, this paper proposes Importance-aware contrastive learning via semantically augmented instances for Unsupervised Sentence Embeddings (IconUSE), further improving the performance of sentence embeddings. IconUSE includes three optimizations. Firstly IconUSE applies a snippet affixation operation to modify the original sentence as its augmented version and then passes them into the pre-trained model respectively to get the positive pair. Then since hard negative instances that are similar to the anchor instance are more helpful for contrastive learning, IconUSE mixes the embeddings of the anchor instance and its negative instances to generate its virtual hard negative instances. In addition, classic contrastive learning treats all anchor instances with the same importance though some are already well represented, then IconUSE uses a modulating factor to apply different weights to different anchor instances. Experimental results suggest that our proposed IconUSE outperforms unsupervised SimCSE by + 1.35\% Spearman’s correlation scores on semantic textual similarity tasks.},
  archive      = {J_IJMLC},
  author       = {Ma, Xin and Li, Hong and Shi, Jiawen and Zhang, Yi and Long, Zhigao},
  doi          = {10.1007/s13042-023-01813-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2979-2990},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Importance-aware contrastive learning via semantically augmented instances for unsupervised sentence embeddings},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NMEAS: Neuro-MaxEnt architecture search. <em>IJMLC</em>,
<em>14</em>(9), 2963–2977. (<a
href="https://doi.org/10.1007/s13042-023-01812-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fusion operations are widely used in many hand-crafted convolutional neural network model to reduce parameter number and improve feature learning, however, most neural architecture search methods suffered from large search cost, usually used simple fusion operations of add or concatenation while ignoring others to limit the search space. This could speed up the search stage but limit the performance of the final architecture at evaluation stage. In this paper, based on differentiable architecture search, we expand the search space by introducing more fusion operations into search space, including max, convolution, multiplication, 3D-pooling and 3D-convolution+pooling. In particular, we generalized all fusion operations to more general forms to receive multi-stream inputs. Besides, in order to overcome the complexity of search space expansion, we also regularize both outer and inner variables of the bi-level optimization problem in architecture search to avoid overfitting of architecture parameters. Finally, we propose a new way of Neuro-MaxEnt approach with maximum entropy (MaxEnt) principle, namely, Neuro-MaxEnt Architecture Search, to reduce the search cost and improve the model performance. The experimental results based on image classification benchmarks and scene dataset suggest that the proposed method can speed up the search phase, and find a better architecture with appropriate fusion operations. Our method discovers top performing architectures with much less search cost than previous state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Zou, Zhiyuan and Liu, Weibin and Xing, Weiwei and Zhang, Shunli},
  doi          = {10.1007/s13042-023-01812-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2963-2977},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {NMEAS: Neuro-MaxEnt architecture search},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RNON: Image inpainting via repair network and optimization
network. <em>IJMLC</em>, <em>14</em>(9), 2945–2961. (<a
href="https://doi.org/10.1007/s13042-023-01811-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last few years, image inpainting methods based on deep learning models had shown obvious advantages compared with existing traditional methods. The former can better generate visually reasonable image structure and texture information. However, the existing premier convolutional neural networks methods usually causes the problems of excessive color difference and image texture loss and distortion phenomenon. The paper has proposed an effective image inpainting method using generative adversarial networks, which is composed of two mutually independent generative confrontation networks. Among them, the image repair network module aims to solve the problem of repairing the irregular missing areas of the image, and its generator is based on a partial convolutional network. The image optimization network module aims to solve the problem of local chromatic aberration in the repaired images, and its generator has based on deep residual networks. Through the synergy of the two network modules, the visual effect and image quality of the images has improved. The experimental results can show that the proposed method (RNON) performs better from comparisons of qualitative and quantitative evaluations with state-of-the-arts in image inpainting quality field.},
  archive      = {J_IJMLC},
  author       = {Chen, Yuantao and Xia, Runlong and Zou, Ke and Yang, Kai},
  doi          = {10.1007/s13042-023-01811-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2945-2961},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {RNON: Image inpainting via repair network and optimization network},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CatSight, a direct path to proper multi-variate time series
change detection: Perceiving a concept drift through common spatial
pattern. <em>IJMLC</em>, <em>14</em>(9), 2925–2944. (<a
href="https://doi.org/10.1007/s13042-023-01810-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting changes in data streams, with the data flowing continuously, is an important problem which Industry 4.0 has to deal with. In industrial monitoring, the data distribution may vary after a change in the machine’s operating point; this situation is known as concept drift, and it is key to detecting this change. One drawback of conventional machine learning algorithms is that they are usually static, trained offline, and require monitoring at the input level. A change in the distribution of data, in the relationship between the input and the output data, would result in the deterioration of the predictive performance of the models due to the lack of an ability to generalize the model to new concepts. Drift detecting methods emerge as a solution to identify the concept drift in the data. This paper proposes a new approach for concept drift detection—a novel approach to deal with sudden or abrupt drift, the most common drift found in industrial processes-, called CatSight. Briefly, this method is composed of two steps: (i) Use of Common Spatial Patterns (a statistical approach to deal with data streaming, closely related to Principal Component Analysis) to maximize the difference between two different distributions of a multivariate temporal data, and (ii) Machine Learning conventional algorithms to detect whether a change in the data flow has been occurred or not. The performance of the CatSight method, has been evaluated on a real use case, training six state of the art Machine Learning (ML) classifiers; obtained results indicate how adequate the new approach is.},
  archive      = {J_IJMLC},
  author       = {Flórez, Arantzazu and Rodríguez-Moreno, Itsaso and Artetxe, Arkaitz and Olaizola, Igor García and Sierra, Basilio},
  doi          = {10.1007/s13042-023-01810-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2925-2944},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {CatSight, a direct path to proper multi-variate time series change detection: Perceiving a concept drift through common spatial pattern},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HMNet: A hierarchical multi-modal network for educational
video concept prediction. <em>IJMLC</em>, <em>14</em>(9), 2913–2924. (<a
href="https://doi.org/10.1007/s13042-023-01809-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Educational video concept prediction is a challenging task in the online education system that aims to assign appropriate hierarchical concepts to the video. The key to this problem is to model and fuse the multimodal information of the video. However, most prior studies tend to ignore the incremental characteristics of the educational video, and most of the video segmentation strategies do not apply well to the educational video. Moreover, most existing methods overlook the class hierarchy and do not consider the class dependencies when predicting the hierarchical concepts of a video. To that end, in this paper, we propose a Hierarchical Multi-modal Network (HMNet) framework for predicting the hierarchical concepts of educational videos via fusing the multimodal information and modeling the class dependencies. Specifically, we first apply a video divider for extracting keyframes from the video, which considers the incremental characteristics of the educational video. The video is divided into a series of video sections with subtitles. Then, we utilize a multi-modal encoder to obtain the unified representation for multi-modality. Finally, we design a hierarchical predictor capable of fusing the multi-modality representation, modeling the class dependencies and predicting the hierarchical concepts of video in a top-down manner. Extensive experimental results on two real-world datasets demonstrate the effectiveness and explanatory power of HMNet.},
  archive      = {J_IJMLC},
  author       = {Huang, Wei and Xiao, Tong and Liu, Qi and Huang, Zhenya and Ma, Jianhui and Chen, Enhong},
  doi          = {10.1007/s13042-023-01809-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2913-2924},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {HMNet: A hierarchical multi-modal network for educational video concept prediction},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A unified approach to designing sequence-based personalized
food recommendation systems: Tackling dynamic user behaviors.
<em>IJMLC</em>, <em>14</em>(9), 2903–2912. (<a
href="https://doi.org/10.1007/s13042-023-01808-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recommender system (RS) is a well-known practical application of the state-of-the-art information filtering and machine learning technologies. Traditional recommendation approaches, including collaborative and content-based filtering techniques, have been widely employed to provide suggestions in RSs, where the user-item interaction matrix is the primary data source. In many application domains, interactions between users and items are more likely to be dynamic rather than static, and thus dynamic user behaviors should be taken into account when solving recommendation tasks in order to provide more accurate suggestions. In this work, we consider the sequentially ordered information from user-item interactions in the RSs where a sequence-based recommendation model is put forward with applications to the food recommendation scenario. Furthermore, the long short-term memory (LSTM) network is employed as the building block to establish such a recommendation model, and a collaborative filtering unit is adopted to make personalized food recommendation. The proposed LSTM-based RS is successfully applied to a real-world food recommendation data set. Experimental results demonstrate that the developed method outperforms some currently popular RSs in terms of precision, recall, mean average precision and mean reciprocal rank in food recommendation.},
  archive      = {J_IJMLC},
  author       = {Zhang, Jieyu and Wang, Zidong and Liu, Weibo and Liu, Xiaohui and Zheng, Qiusheng},
  doi          = {10.1007/s13042-023-01808-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2903-2912},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A unified approach to designing sequence-based personalized food recommendation systems: Tackling dynamic user behaviors},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A co-training method based on parameter-free and single-step
unlabeled data selection strategy with natural neighbors.
<em>IJMLC</em>, <em>14</em>(8), 2887–2902. (<a
href="https://doi.org/10.1007/s13042-023-01805-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an effective semi-supervised learning algorithm, the co-training method trains two classifiers on two views independently. The unlabeled sample selection strategy in the self-labeled process is crucial for co-training. However, most of the existing strategies strongly depend on parameter settings and require re-calculating the confidence of unlabeled samples in each iteration. Inspired by the concept of natural neighbors introduced recently, a co-training method based on parameter-free and single-step unlabeled data selection strategy with natural neighbors (CT-NaN) is proposed in this paper. In CT-NaN, the confidence value of unlabeled samples is calculated in a parameter-free manner by analyzing the training data based on natural neighbors before the iteration of co-training, and it requires to be calculated only once in the whole process of co-training. Besides, CT-NaN is able to mitigate the negative effect of outliers because the training stops automatically when only outliers remain. Four groups of experiments with 22 data sets are conducted, and the results verify the effectiveness of CT-NaN when compared with 8 state-of-the-art co-training methods.},
  archive      = {J_IJMLC},
  author       = {Gong, Yanlu and Wu, Quanwang and Cheng, Dongdong},
  doi          = {10.1007/s13042-023-01805-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2887-2902},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A co-training method based on parameter-free and single-step unlabeled data selection strategy with natural neighbors},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A cross-validation framework to find a better state than the
balanced one for oversampling in imbalanced classification.
<em>IJMLC</em>, <em>14</em>(8), 2877–2886. (<a
href="https://doi.org/10.1007/s13042-023-01804-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalance classification has always been a popular research point in the application of machine learning, data mining and pattern recognition. At present, there are also many techniques to reduce the negative impact of imbalance on classification performance, and oversampling is the most commonly used one. In this paper, we illustrate the relationship between imbalance rate and classification performance in the oversampling process from a novel perspective that oversampling may cause the loss of the distribution while minority class is enhanced. In addition, this paper proposes a novel cross-validation framework called “icross-validation” that can be used in sampling to find a better state than the balanced state. This framework is general and can be applied into various oversampling methods. In comparison with some state-of-the-art and widely used oversampling methods, the experimental results on some real data sets demonstrate the effectiveness of the icross-validation. All code has been released in the open source icross-validation library at https://github.com/syxiaa/icross-valiation .},
  archive      = {J_IJMLC},
  author       = {Dai, Qizhu and Li, Donggen and Xia, Shuyin},
  doi          = {10.1007/s13042-023-01804-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2877-2886},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A cross-validation framework to find a better state than the balanced one for oversampling in imbalanced classification},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic network link prediction based on random walking and
time aggregation. <em>IJMLC</em>, <em>14</em>(8), 2867–2875. (<a
href="https://doi.org/10.1007/s13042-023-01803-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic network link prediction has practical applications in many areas, such as social networks, traffic networks, biological networks, and citation networks. Because of its essential practical significance, it has attracted the attention of many researchers. The key to dynamic network link prediction is to model the network topology evolution and capture time information. Currently, most studies divide dynamic networks into a series of static time snapshots, which can be considered a rough compressed of continuous-time dynamic networks. Such compression will lead to the loss of time evolution information in the window and how to choose the appropriate partition granularity is a considerable challenge. In this paper, we propose a link prediction method for continuous-time networks based on Random Walk and Time Aggregation(RWTA). In the method, we perform random walk with time-constrained directly on a continuous-time network to get node sequence without slicing into time snapshots. Then, based on skip-gram, the initial node representation is gotten, and the dynamic graph with node representation is created. A temporal proximity neighborhood aggregation process is designed to enhance node representation, and the binary operator is done to obtain edge representation. Finally, A classifier is utilized to predict links. Extensive experiments on real-world datasets show that our model outperforms other state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Zhang, Mingliang and Xu, Baining and Wang, Li},
  doi          = {10.1007/s13042-023-01803-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2867-2875},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dynamic network link prediction based on random walking and time aggregation},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DBCGN: Dual branch cascade graph network for skin lesion
segmentation. <em>IJMLC</em>, <em>14</em>(8), 2847–2865. (<a
href="https://doi.org/10.1007/s13042-023-01802-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of skin lesions in dermoscopic images is essential for early diagnosis and prevention of skin cancer. However, it is still a challenging task due to the large number of artifacts (hairs, bubbles, ink stains, etc.) in dermoscopic images and irregular shapes and blurred borders. In this paper, we propose a novel skin lesion segmentation network-DBCGN. In the feature extraction stage, We use the Transformer branch to build global contextual dependencies across scales against semantic features using three layers of high-level semantic features from the CNN branch. To more effectively couple local–global features, we design the Dual-branch Cascade-feature Fusion Module (DCFM) to implement multi-scale feature fusion of CNN and Transformer. In addition, to outline the boundaries of the target region more accurately, we design the Reverse Graph Reasoning Module (RGRM) which can refine the boundaries of the target region using low-level features. Extensive experiments have shown that our method outperforms the currently popular methods and provides more accurate segmentation of the target region. Furthermore, our method is computationally less complex and more efficient, which is more in line with the practical requirements of actual clinical segmentation.},
  archive      = {J_IJMLC},
  author       = {Song, Pengfei and Li, Jinjiang and Fan, Hui and Fan, Linwei},
  doi          = {10.1007/s13042-023-01802-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2847-2865},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {DBCGN: Dual branch cascade graph network for skin lesion segmentation},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual graph attention networks for multi-behavior
recommendation. <em>IJMLC</em>, <em>14</em>(8), 2831–2846. (<a
href="https://doi.org/10.1007/s13042-023-01801-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Behavior Recommendation (MBR) attracts much attention in recent years, whose goal is to improve the prediction of the target behavior (i.e., purchase) by exploiting multi-typed auxiliary behaviors (e.g., view, favorite and add-to-cart). Recently, leveraging Graph Convolutional Networks (GCNs) to capture collaborative signals has been the mainstream paradigm for MBR. However, the existing multi-behavior recommendation methods have suffered from two limitations. On the one hand, personalized user preferences hidden in multi-behavior data are not fully exploited. Users’ multiple types of interactions, such as views, clicks, and so on, offer fine-grained and a deep understanding of the preferences. The importance of different types of behaviors should be carefully distinguished. On the other hand, these methods aggregate the original neighbors of target user and item independently. Users’ preferences may change dynamically with a specific target item. Therefore, users’ dynamic preferences based on specific items should be sufficiently considered. These limitations motivate us to propose a novel recommendation model DGAMR (Dual Graph Attention Networks for Multi-behavior Recommendation), which accurately learns user and item representation by multiple types of behaviors. First, we utilize node-level attention to learn the representation of users and items under specific behavior. Second, behavioral-level attention is used to aggregate different behaviors to generate the final representation of users and items. In addition, we learn the dynamic characteristics of target user and target item by modeling the dependency relation between them. Finally, we utilize the static and dynamic embedding of users/items to predict users’ preferences for items. Extensive experimental results on two real-world datasets clearly show the effectiveness of our proposed model.},
  archive      = {J_IJMLC},
  author       = {Wei, Yunhe and Ma, Huifang and Wang, Yike and Li, Zhixin and Chang, Liang},
  doi          = {10.1007/s13042-023-01801-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2831-2846},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dual graph attention networks for multi-behavior recommendation},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). L-fuzzy covering rough sets based on complete co-residuated
lattice. <em>IJMLC</em>, <em>14</em>(8), 2815–2829. (<a
href="https://doi.org/10.1007/s13042-023-01800-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For $$L=(L,\odot ,\rightsquigarrow )$$ a complete co-residuated lattice, the notions of $$\odot$$ -subsethood degree and $$\rightsquigarrow$$ -intersection degree between L-fuzzy sets are defined. It is shown that these notions reasonably extend the notions of subset and intersection between crisp sets. Then by using $$\odot$$ -subsethood degree and $$\rightsquigarrow$$ -intersection degree, a new model of L-fuzzy covering based L-fuzzy rough sets is investigated and studied. Firstly, a pair of L-fuzzy lower and upper approximation operators are constructed and their fundamental properties are discussed. Secondly, an axiom set or even a single axiom is presented to characterize the proposed approximate operators. Thirdly, the L-fuzzy topology and L-fuzzy co-topology induced by the L-fuzzy lower and upper approximation operators are researched, respectively. At last, the relationships between the new model and Qiao’s L-fuzzy relation based rough sets are established.},
  archive      = {J_IJMLC},
  author       = {Xu, Yao-Liang and Zou, Dan-Dan and Li, Ling-Qiang and Yao, Bing-Xue},
  doi          = {10.1007/s13042-023-01800-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2815-2829},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {L-fuzzy covering rough sets based on complete co-residuated lattice},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Widely-activated network merging perceptual loss via
discrete wavelet transform for image super-resolution. <em>IJMLC</em>,
<em>14</em>(8), 2793–2813. (<a
href="https://doi.org/10.1007/s13042-023-01799-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are some problems with image super-resolution techniques, such as insufficient utilization of image features in different layers and lack high frequency information resulting in blurred texture edges in reconstructed images. A new method for the image super-resolution reconstruction of Widely Activated Network Fused Perceptual Loss (P-WAN) is proposed, which can improve the usage of image features from different layers. The method uses a pre-training model to extract features before activation to obtain the perceptual loss, meanwhile, draws on the adversarial loss in the adversarial generation network, and combines the pixel loss of the image to form a new loss function. Finally, we optimize the loss function by adjusting the weights of the three loss terms. Based on this research, a Widely Activated Network Based on Discrete Wavelet Transform and Fused Perceptual Loss (DP-WAN) is further proposed, which can reconstruct better high frequency information and higher quality texture edges. The method mainly adds the discrete wavelet transform on the basis of P-WAN, trains the different components obtained by the transform separately, and finally reconstructs the super-resolution image through the inverse discrete wavelet transform. To validate the feasibility and effectiveness, 4 representative methods are selected to test on 5 datasets. Experimental results have shown that the proposed method achieves the best performance in objective evaluation, and can obtain a good visual experience in subjective visual evaluation.},
  archive      = {J_IJMLC},
  author       = {Guo, Lili and Wang, Yanru and Wang, Fanchao and Ding, Ling and Ding, Shifei},
  doi          = {10.1007/s13042-023-01799-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2793-2813},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Widely-activated network merging perceptual loss via discrete wavelet transform for image super-resolution},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive focused target feature fusion network for
detection of foreign bodies in coal flow. <em>IJMLC</em>,
<em>14</em>(8), 2777–2791. (<a
href="https://doi.org/10.1007/s13042-023-01798-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the process of conveying raw coal to the surface on conveyor belts, the raw coal is generally blended with foreign bodies, such as large pieces of gangue and damaged bolts, which can affect the quality of mined coal, damage the transportation equipment and even jam the coal conduit, seriously reducing the coal conveying efficiency. To handle to the existing problems of underground complex environment, low detection accuracy and poor real-time performance in coal flow foreign bodies detection, we propose an adaptive focused target feature fusion network (AFFNet) based on YOLOX. The multi-transformer parallel (MTRP) module is used to expand the receptive field and fuse the features under different receptive fields with the transformer encoder to enhance the feature extraction ability. The cross stage partial transformer (CSPTR) with transformer encoder module is designed to capture the global context information of the feature maps in the network, and improve the location prediction in the detection. In the feature fusion channel of different scales, the learnable weight parameters are added to learn the spatial weight of feature map fusion adaptively, and the feature expression ability of different scales is optimized. SCYLLA-IoU (SIoU) loss and varifocal loss are used to obtain more accurate bounding boxes and deal with the sample category imbalance problem, respectively. The experimental results show that AFFNet can achieve a detection speed of 48 frame per second (FPS) and a mean average precision (mAP50) of 95.6\%, 6.7\% higher than YOLOX-s on the dataset of foreign body in coal flow. It can balance both the detection speed and detection accuracy, and can be used to improve the efficiency of detecting foreign bodies in the coal flow.},
  archive      = {J_IJMLC},
  author       = {Ye, Tao and Zheng, Zhikang and Li, Yunwang and Zhang, Xi and Deng, Xiangpeng and Ouyang, Yu and Zhao, Zongyang and Gao, Xiaozhi},
  doi          = {10.1007/s13042-023-01798-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2777-2791},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An adaptive focused target feature fusion network for detection of foreign bodies in coal flow},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recognition of odor and pleasantness based on olfactory EEG
combined with functional brain network model. <em>IJMLC</em>,
<em>14</em>(8), 2761–2776. (<a
href="https://doi.org/10.1007/s13042-023-01797-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the food field, the sensory evaluation of food texture, aroma, and flavor still relies on artificial sensory evaluation and machine perception, but the results of artificial sensory evaluation by professionals are not universal, and machines cannot obtain psychological information. In this work, an electroencephalogram (EEG) analysis method based on the functional brain network was proposed, which effectively realized odor recognition and pleasantness recognition. Firstly, a self-developed odor generator was used to induce olfactory EEG, and the signals were collected and preprocessed. Secondly, the functional brain networks were constructed by mutual information (MI). Finally, the network properties were extracted and input to the support vector machine (SVM) classifier. Compared with the traditional EEG feature extraction methods, the degree of the functional brain network can effectively extract EEG features, the average accuracy and F1 score of odor recognition were 95.78\% and 95.24\%, respectively, and in the pleasantness recognition were 98.21\% and 98.21\%, respectively. In conclusion, a method for odor and pleasantness recognition was proposed, which provided a new idea for food sensory evaluation.},
  archive      = {J_IJMLC},
  author       = {Xia, Xiuxin and Liu, Xiaotong and Zheng, Wenbo and Jia, Xiaofei and Wang, Bo and Shi, Yan and Men, Hong},
  doi          = {10.1007/s13042-023-01797-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2761-2776},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Recognition of odor and pleasantness based on olfactory EEG combined with functional brain network model},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TTL: Transformer-based two-phase transfer learning for
cross-lingual news event detection. <em>IJMLC</em>, <em>14</em>(8),
2739–2760. (<a
href="https://doi.org/10.1007/s13042-023-01795-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, we have access to a vast data amount, especially on the internet. Online news agencies play a vital role in this data generation, but most of their data is unstructured, requiring an enormous effort to extract important information. Thus, automated intelligent event detection mechanisms are invaluable to the community. In this research, we focus on identifying event details at the sentence and token levels from news articles, considering their fine granularity. Previous research has proposed various approaches ranging from traditional machine learning to deep learning, targeting event detection at these levels. Among these approaches, transformer-based approaches performed best, utilising transformers’ transferability and context awareness, and achieved state-of-the-art results. However, they considered sentence and token level tasks as separate tasks even though their interconnections can be utilised for mutual task improvements. To fill this gap, we propose a novel learning strategy named Two-phase Transfer Learning (TTL) based on transformers, which allows the model to utilise the knowledge from a task at a particular data granularity for another task at different data granularity, and evaluate its performance in sentence and token level event detection. Also, we empirically evaluate how the event detection performance can be improved for different languages (high- and low-resource), involving monolingual and multilingual pre-trained transformers and language-based learning strategies along with the proposed learning strategy. Our findings mainly indicate the effectiveness of multilingual models in low-resource language event detection. Also, TTL can further improve model performance, depending on the involved tasks’ learning order and their relatedness concerning final predictions.},
  archive      = {J_IJMLC},
  author       = {Hettiarachchi, Hansi and Adedoyin-Olowe, Mariam and Bhogal, Jagdev and Gaber, Mohamed Medhat},
  doi          = {10.1007/s13042-023-01795-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2739-2760},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {TTL: Transformer-based two-phase transfer learning for cross-lingual news event detection},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hierarchical evolution of neural architecture search
method based on state transition algorithm. <em>IJMLC</em>,
<em>14</em>(8), 2723–2738. (<a
href="https://doi.org/10.1007/s13042-023-01794-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among different search strategies to realize neural architecture search (NAS), evolutionary algorithms (EAs) have gained much attention due to their global optimization capability. However, the large number of performance evaluation procedure makes the EA-based methods extremely time-consuming. To address this issue, an efficient framework called HENA (Hierarchical Evolution of Neural Architecture) is proposed in this paper. In HENA, NAS is hierarchically divided into two continuous phases, candidate operation search and connection relationship search. For this purpose, a supernet is defined to subsume the whole search space, where all weights can be inherited by all architectures. A novel evolutionary algorithm called state transition algorithm (STA) is used to traverse the search space continuously. In the first phase, several sampled architectures are trained on mini-group data to search better operation for different positions within the network. In the second phase, better connection relationship among operations can be directly determined without training via inheriting trained weights. Finally, the proposed method is evaluated on the widely used datasets, and the experimental results show that (1) the architecture learned by HENA obtains state-of-the-art performance (2.93\% and 20.44\% error rate on CIFAR-10 and CIFAR-100 respectively). (2) the learned architecture achieves 24.8\% top-1 error on ImageNet dataset.},
  archive      = {J_IJMLC},
  author       = {Du, Yangyi and Zhou, Xiaojun and Huang, Tingwen and Yang, Chunhua},
  doi          = {10.1007/s13042-023-01794-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2723-2738},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A hierarchical evolution of neural architecture search method based on state transition algorithm},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vision mechanism model using brain–computer interface for
light sensing. <em>IJMLC</em>, <em>14</em>(8), 2709–2722. (<a
href="https://doi.org/10.1007/s13042-023-01793-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The electroencephalograph (EEG) learning network model (EEGNet) is developed according to the convolutional neural network model architecture. It can be applied in the area of the EEG recognition because the EEGNet has the advantage of adapting to the EEG processing. However, the application has a bottleneck problem that the EEG selection of the specific brain–computer interface (BCI) affects the EEGNet recognition accuracy. In this paper, we developed an integrated EEGNet model of the human vision mechanism for light intensity perception. First, the special BCI is constructed by using a designed multiplexer, the EEG acquisition circuit, the magnifier and the filter. Second, the effect of the underground environment illumination on EEG is explored by using the constructed BCI. Third, the model of the vision mechanism is established by using the integrated EEGNet. Finally, experiments show that the integrated EEGNet increases the light intensity recognition accuracy respectively by 8.4\% and 3.9\%, compared with the multi-channel EEGNet and the single channel EEGNet. The integrated EEGNet effectively perceives and recognizes the underground illumination intensities, dim intensity of 0–60 Lx, mild intensity of 61–120 Lx, and bright intensity of 121–350 Lx. The proposed model can provide useful references for miner helmet or other special environment light-related devices.},
  archive      = {J_IJMLC},
  author       = {Wang, Mei and Cheng, Hao and Li, Yuancheng and Pan, Hongguang and Wang, Gang and Guo, Yuan},
  doi          = {10.1007/s13042-023-01793-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2709-2722},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Vision mechanism model using brain–computer interface for light sensing},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Window transformer for dialogue document: A joint framework
for causal emotion entailment. <em>IJMLC</em>, <em>14</em>(8),
2697–2707. (<a
href="https://doi.org/10.1007/s13042-023-01792-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Causal Emotion Entailment (CEE) task aims to extract all potential pairs of emotions and corresponding causes from the unannotated emotion document in the conversational context. Most existing methods to solve CEE task follow a two-stage pipeline framework, in which the first stage is to identify emotional clauses and cause clauses and extract clause representation,separately. And in the second stage is to construct the final emotion and cause pairs. However, they ignore the effect of the distance between clauses on emotion-cause pair matching. Here, we construct a joint framework with Window Transformer to handle this problem. The pre-trained BERT and RoBERTa are used as the text encoder to generate a local representation of clauses in a given document. Meanwhile, we feed it into 2D Window Transformer to make the clause representation sensitive to the context within the Window and to obtain the dependencies between clauses. At the same time, the document ranks the candidate clauses to extract causal emotion entailments, which enhances the representation of clause pairs (emotion pairs and cause pairs) by kernel-based relative position embedding. Experimental results indicate that the framework acquires state-of-the-art results on the benchmark dataset.},
  archive      = {J_IJMLC},
  author       = {Jiang, Dazhi and Liu, Hao and Tu, Geng and Wei, Runguo},
  doi          = {10.1007/s13042-023-01792-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2697-2707},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Window transformer for dialogue document: A joint framework for causal emotion entailment},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Target detection algorithm based on multilayer attention
mechanism-adaptive feature fusion network. <em>IJMLC</em>,
<em>14</em>(8), 2685–2695. (<a
href="https://doi.org/10.1007/s13042-023-01791-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Target images are complex and diverse under the influence of scale, occlusion and appearance factors in real scenes, and they affect the performance of target detection algorithms. They also make the existing target detection algorithms suffer from the following problems. On the one hand, the neurons in the target detection algorithm architecture cannot learn the complex interaction and semantic features inside the target image. On the other hand, the feature expression of different target images is insufficient and the channel reduction leads to the loss of position information and other problems. herefore, a multi-layer attention mechanism of considering both node and semantic level attention in the model architecture is proposed. In this method, the fusion of neighbors and semantic information is weighted, and node representations is learned under a hierarchical aggregation manner.Just because of this, it can improve the effectiveness and interpretability of the model, and solve the problem of complex interaction and rich semantic feature acquisition within images. Furthermore, we propose an adaptive feature fusion network which can adaptively filter the useless information of other layers and retain the feature information that is beneficial to target recognition. A feature enhancement module, is introduced to enhance the identifiability of the top-level target features of the feature network, and which can alleviate the problem of loss of target position. Finally, the extensive tests using PASCAL VOC and MSCOCO datasets, the experimental result shows that our method not only has the best recognition performance, but also has better stability and robustness.},
  archive      = {J_IJMLC},
  author       = {An, Fengping and Wang, Jianrong},
  doi          = {10.1007/s13042-023-01791-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2685-2695},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Target detection algorithm based on multilayer attention mechanism-adaptive feature fusion network},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Two-dimensional k-subspace clustering and its applications
on image recognition. <em>IJMLC</em>, <em>14</em>(8), 2671–2683. (<a
href="https://doi.org/10.1007/s13042-023-01790-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image clustering plays an important role in computer vision and machine learning. However, most of the existing clustering algorithms flatten the image into one-dimensional vector as an image representation for subsequent learning without fully considering the spatial relationship between pixels, which may lose some useful intrinsic structural information of the matrix data samples and result in high computational complexity. In this paper, we propose a novel two-dimensional k-subspace clustering (2DkSC). By projecting data samples into a discriminant low-dimensional space, 2DkSC maximizes the between-cluster difference and meanwhile minimizes within-cluster distance of matrix data samples in the projected space, thus dimensionality reduction and clustering can be realized simultaneously. The weight between the between-cluster and within-cluster terms is derived from a Bhattacharyya upper bound, which is determined by the involved input data samples. This weighting constant makes the proposed 2DkSC adaptive without setting any parameters, which improves the computational efficiency. Moreover, 2DkSC can be effectively solved by a standard eigenvalue decomposition problem. Experimental results on three different types of image datasets show that 2DkSC achieves the best clustering results in terms of average clustering accuracy and average normalized mutual information, which demonstrates the superiority of the proposed method.},
  archive      = {J_IJMLC},
  author       = {Guo, Yan Ru and Bai, Yan Qin},
  doi          = {10.1007/s13042-023-01790-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2671-2683},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Two-dimensional k-subspace clustering and its applications on image recognition},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SecureFed: Federated learning empowered medical imaging
technique to analyze lung abnormalities in chest x-rays. <em>IJMLC</em>,
<em>14</em>(8), 2659–2670. (<a
href="https://doi.org/10.1007/s13042-023-01789-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning is an effective and accurate technique to diagnose COVID-19 infections using image data, and chest X-Ray (CXR) is no exception. Considering privacy issues, machine learning scientists end up receiving less medical imaging data. Federated Learning (FL) is a privacy-preserving distributed machine learning paradigm that generates an unbiased global model that follows local model (from clients) without exposing their personal data. In the case of heterogeneous data among clients, vanilla or default FL mechanism still introduces an insecure method for updating models. Therefore, we proposed SecureFed—a secure aggregation method—which ensures fairness and robustness. In our experiments, we employed COVID-19 CXR dataset (of size 2100 positive cases) and compared it with the existing FL frameworks such as FedAvg, FedMGDA+, and FedRAD. In our comparison, we primarily considered robustness (accuracy) and fairness (consistency). As the SecureFed produced consistently better results, it is generic enough to be considered for multimodal data.},
  archive      = {J_IJMLC},
  author       = {Makkar, Aaisha and Santosh, KC},
  doi          = {10.1007/s13042-023-01789-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2659-2670},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {SecureFed: Federated learning empowered medical imaging technique to analyze lung abnormalities in chest X-rays},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BSSFS: Binary sparrow search algorithm for feature
selection. <em>IJMLC</em>, <em>14</em>(8), 2633–2657. (<a
href="https://doi.org/10.1007/s13042-023-01788-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Swarm intelligence algorithms can efficiently solve feature selection optimization problems for classification, and their classification performance is also excellent. The Sparrow Search Algorithm (SSA) has recently become a novel optimization method, which has the advantages of fewer parameters, a simple structure, and ease of implementation. Unfortunately, the traditional SSA has certain difficulties, trapping into a local optimum easily, and has a weakness in convergence. In this work, a novel SSA is studied to further develop two types of binary SSA for feature selection (BSSFS) to address optimization problems. First, to make the initial population of sparrows distributed as evenly as possible in the search space and augment the diversity of sparrows, a cubic chaotic mapping scheme needs to be introduced to initialize the sparrow population, and a reverse learning scheme is employed to enhance the global search ability of SSA. Second, the nonlinear adaptive inertia weight and the improved control parameters of step size are used to modify the position update formula of the sparrows and avert trapping into a local optimum. By integrating these strategies, a novel SSA (NSSA in short) is designed in this work. Third, NSSA is combined with the S- and V-shaped transfer functions, and the fitness function, which is raised on account of the set size of selected features and the classification error rate, are employed to design two types of BSSFS with the S- and V-shaped transfer functions, shortened as FSBSS and FSBSV, respectively. Finally, the optimization results for 18 classical benchmark functions illustrate that the optimization effectiveness of the NSSA is superior to that of other methods, and the experimental results on 10 low-dimensional and 10 high-dimensional datasets demonstrate that the FSBSV can outdo other comparative algorithms in terms of the classification effectiveness and robustness.},
  archive      = {J_IJMLC},
  author       = {Sun, Lin and Si, Shanshan and Ding, Weiping and Xu, Jiucheng and Zhang, Yan},
  doi          = {10.1007/s13042-023-01788-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2633-2657},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {BSSFS: Binary sparrow search algorithm for feature selection},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-view clustering based on view-attention driven.
<em>IJMLC</em>, <em>14</em>(8), 2621–2631. (<a
href="https://doi.org/10.1007/s13042-023-01787-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view Clustering focuses on discovering coherence information and complementary information about the data among the different views, but often the views are accompanied by related information that is unrelated to the clustering goal. To address this problem, this paper proposes a clustering method named Multi-view Clustering Based on View-Attention Driven. Based on Autoencoder, the method learns feature representations from different views data using contrast learning and attention mechanisms. During the process of learning feature representations of different views, consider information of interest to other views. Guiding information is provided in an attention-driven manner to guide feature learning. On the one hand, it strengthens the focus on information in all views. On the other hand, it reduces the impact on information contained only in a subset of views that isn’t relevant to clustering. In addition, random initialization is used to train the autoencoder, minimizing the network structure’s influence on initialization parameters. Four challenging datasets were used to test the method and it was shown to outperform other competitive multi-view clustering methods. The codes will be available at https://github.com/mzf1998/Multi-view-Clustering-Based-on-View-Attention-Driven .},
  archive      = {J_IJMLC},
  author       = {Ma, Zhifeng and Yu, Junyang and Wang, Longge and Chen, Huazhu and Zhao, Yuxi and He, Xin and Wang, Yingqi and Song, Yalin},
  doi          = {10.1007/s13042-023-01787-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2621-2631},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-view clustering based on view-attention driven},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global-chronological graph interactive networks for
multi-domain dialogue state tracking. <em>IJMLC</em>, <em>14</em>(8),
2607–2620. (<a
href="https://doi.org/10.1007/s13042-023-01785-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dialogue state tracking (DST) provides necessary information for the policy learning module to decide the next action according to the historical state and the utterance related details of the dialogue, so robust dialogue state tracking is a core part of high-quality task-oriented dialogue systems. The tasks addressed by dialogue state tracking are becoming increasingly complex, and due to the multi-domain switching in the dialogue relevant contexts, the model needs to have the ability to generate appropriate responses to accurately fit the domains, slots and slot values. However, efficient encoding of state information and fundamentally simulating the logical relationship between domains and slots to dynamically extract variation features of the multiple domains are still challenges for DST. In this paper, we propose a novel framework global-chronological graph interactive networks (GCGIN), which encodes both global and chronological information of the dialogue from dual perspectives, and leverages coupling and co-affine modules to interact with the above two different granularities information. Our model adopts the mask mechanism to improve anti-noise ability, and constructs the dynamic schema graph structure to dynamically model domain-slot and domain-value relations via dialogue chronological order to achieve cross-domain features learning and improve model scalability. Extensive experimental results on three benchmark datasets demonstrate that our proposed model outperforms existing mainstream methods, and comprehensive analysis validates the effectiveness of each component.},
  archive      = {J_IJMLC},
  author       = {Zhang, Qichen and Wang, Shuai and Li, Jingmei},
  doi          = {10.1007/s13042-023-01785-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2607-2620},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Global-chronological graph interactive networks for multi-domain dialogue state tracking},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data augmentation using heuristic masked language modeling.
<em>IJMLC</em>, <em>14</em>(8), 2591–2605. (<a
href="https://doi.org/10.1007/s13042-023-01784-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation has played an important role in generalization capability and performance improvement for data-driven deep learning models in recent years. However, most of the existing data augmentation methods in NLP suffer from high manpower consumption or low promotion, which limits the practical applications. To this end, we propose a simple yet effective approach named Heuristic Masked Language Modeling(HMLM) to obtain high-quality data by introducing mask language modeling embedded in pre-trained models. More specifically, the HMLM method first identifies the core words of the sentence and masks some non-core fragments in the sentence. Then, these masked fragments will be filled with words created by the pre-trained model to match the contextual semantics. Compared with the previous data augmentation approaches, the proposed method can create more grammatical and contextual augmented data without a heavy cost. We conducted experiments on typical text classification tasks e.g., intent recognition, news classification and sentiment analysis separately. Experimental results demonstrate that our proposed method is comparable to state-of-the-art data augmentation approaches.},
  archive      = {J_IJMLC},
  author       = {Liu, Xiaorong and Zhong, Yuan and Wang, Jie and Li, Ping},
  doi          = {10.1007/s13042-023-01784-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2591-2605},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Data augmentation using heuristic masked language modeling},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Building hierarchical class structures for extreme
multi-class learning. <em>IJMLC</em>, <em>14</em>(7), 2575–2590. (<a
href="https://doi.org/10.1007/s13042-023-01783-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class hierarchical structures play a significant role in large and complex tasks of machine learning. Existing studies on the construction of such structures follow a two-stage strategy. The category similarities are first computed with a certain assumption, and the group partition algorithm is then performed with some hyper-parameters to control the shape of class hierarchy. Despite their effectiveness in many cases, these methods suffer from two problems: (1) optimizing the two-stage objective to obtain the structure is sub-optimal; (2) hyper-parameters make the search space too large to find the optimal structure efficiently. In this paper, we propose a unified and dynamic framework to address these problems, which can: (1) jointly optimize the category similarity and group partition; (2) obtain the class hierarchical structure dynamically without any hyper-parameters. The framework replaces the traditional category similarity with the sample similarity, and constrains samples from the same atomic category partitioned to the same super-category. We theoretically prove that, within our framework, the sample similarity is equivalent to the category similarity and can balance the partitions in terms of the number of samples. Further, we design a modularity-based partition optimization algorithm that can automatically determine the number of partitions on each level. Extensive experimental results on multiple image classification datasets show that the hierarchical structure constructed by the proposed method achieves better accuracy and efficiency compared to existing methods. Additionally, the hierarchy obtained by the proposed method can benefit long-tail learning scenarios due to the balanced partition on samples.},
  archive      = {J_IJMLC},
  author       = {Huang, Hongzhi and Wang, Yu and Hu, Qinghua},
  doi          = {10.1007/s13042-023-01783-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2575-2590},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Building hierarchical class structures for extreme multi-class learning},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Image dehazing using multi-scale recursive networks.
<em>IJMLC</em>, <em>14</em>(7), 2563–2574. (<a
href="https://doi.org/10.1007/s13042-023-01782-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Haze severely degrades the definition of images captured in outdoor scenes. The goal of image dehazing is to restore clear images from hazy ones. This problem has been significantly advanced by using deep neural networks. The performance gains mainly depend on large capacity models, which inevitably increases memory consumption and is not benefit to deployment on mobile devices. In contrast, we propose an effective image dehazing method based on a multi-scale recursive network which does not simply stack deep neural networks to improve dehazing performance. The proposed network consists of both internal and external recursions and some residual blocks. In addition, an auxiliary network is developed to collaboratively train with the primary network and guide the training process of the primary network, which is termed as the auxiliary loss. To better train the proposed network, we develop the smooth $$L_{1}$$ -norm-based content loss, perceptual loss, and auxiliary loss to regularize the proposed network. Extensive experiments demonstrate that the multi-scale recursive network achieves favorable performances against state-of-the-art image dehazing methods.},
  archive      = {J_IJMLC},
  author       = {Li, Runde and Huang, Yuwen and Huang, Fuxian and Yang, Gongping},
  doi          = {10.1007/s13042-023-01782-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2563-2574},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Image dehazing using multi-scale recursive networks},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bi-STAN: Bilinear spatial-temporal attention network for
wearable human activity recognition. <em>IJMLC</em>, <em>14</em>(7),
2545–2561. (<a
href="https://doi.org/10.1007/s13042-023-01781-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the progressive development of ubiquitous computing, wearable human activity recognition is playing an increasingly important role in many fields, such as health monitoring, disease-assisted diagnostic rehabilitation, and exercise assessment. Internal measurement unit in wearable devices provides a rich representation of motion. Human activity recognition based on sensor sequence has proven to be crucial in machine learning research. The key challenge is to extract powerful representational features from multi-sensor data to capture subtle differences in human activities. Beyond this challenge, due to the lack of attention to the temporal and spatial dependence of the data, critical information is often lost in the feature extraction process. Few previous papers can jointly address these two challenges. In this paper, we propose an efficient Bilinear Spatial-Temporal Attention Network (Bi-STAN). Firstly, a multi-scale ResNet backbone network is used to extract multimodal signal features and jointly optimize the feature extraction process. Then, to adaptively focus on what and where is important in the original data and to mine the discriminative part of the features, we design a spatial-temporal attention network. Finally, a bilinear pooling with low redundancy is introduced to efficiently obtain second-order information. Experiments on three public datasets and our real-world dataset demonstrate that the proposed Bi-STAN is superior to existing methods in terms of both accuracy and efficiency. The code and models are publicly available at https://github.com/ilovesea/Bi-STAN.},
  archive      = {J_IJMLC},
  author       = {Gao, Chenlong and Chen, Yiqiang and Jiang, Xinlong and Hu, Lisha and Zhao, Zhicheng and Zhang, Yuxin},
  doi          = {10.1007/s13042-023-01781-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2545-2561},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Bi-STAN: Bilinear spatial-temporal attention network for wearable human activity recognition},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Iterative convolutional enhancing self-attention hawkes
process with time relative position encoding. <em>IJMLC</em>,
<em>14</em>(7), 2529–2544. (<a
href="https://doi.org/10.1007/s13042-023-01780-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling Hawkes process using deep learning is superior to traditional statistical methods in the goodness of fit. However, methods based on RNN or self-attention are deficient in long-time dependence and recursive induction, respectively. Universal Transformer (UT) is an advanced framework to integrate these two requirements simultaneously due to its continuous transformation of self-attention in the depth of the position. In addition, migration of the UT framework involves the problem of effectively matching Hawkes process modeling. Thus, in this paper, an iterative convolutional enhancing self-attention Hawkes process with time relative position encoding (ICAHP-TR) is proposed, which is based on improved UT. First, the embedding maps from dense layers are carried out on sequences of arrival time points and markers to enrich event representation. Second, the deep network composed of UT extracts hidden historical information from event expression with the characteristics of recursion and the global receptive field. Third, two designed mechanics, including the relative positional encoding on the time step and the convolution enhancing perceptual attention are adopted to avoid losing dependencies between relative and adjacent positions in the Hawkes process. Finally, the hidden historical information is mapped by Dense layers as parameters in Hawkes process intensity function, thereby obtaining the likelihood function as the network loss. The experimental results show that the proposed methods demonstrate the effectiveness of synthetic datasets and real-world datasets from the perspective of both the goodness of fit and predictive ability compared with other baseline methods.},
  archive      = {J_IJMLC},
  author       = {Bian, Wei and Li, Chenlong and Hou, Hongwei and Liu, Xiufang},
  doi          = {10.1007/s13042-023-01780-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2529-2544},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Iterative convolutional enhancing self-attention hawkes process with time relative position encoding},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Node embedding with capsule generation-embedding network.
<em>IJMLC</em>, <em>14</em>(7), 2511–2528. (<a
href="https://doi.org/10.1007/s13042-023-01779-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving interpretable embedding of real network has a significant impact on network analysis tasks. However, majority of node embedding-based methods seldom consider the rationality and interpretability of node embedding. Although graph attention networks-based approaches have been employed to improve the interpretability of node embedding, they are implicitly specifying different weights to different nodes in a neighborhood. In this study, we present node embedding with capsule generation-embedding network(CapsGE), which is a novel capsule network-based network architecture, and uses node density based on the definition of uncertainty of node community belongings to explicitly assign different weights to different nodes in a neighborhood. In addition, this model uses the proposed cognitive reasoning mechanism for the weighted features to achieve rational and interpretable embedding of nodes. The performance of the method is assessed on node classification task. The experimental results demonstrate its advantages over other methods.},
  archive      = {J_IJMLC},
  author       = {Wang, Jinghong and Zhang, Daipeng and Wei, Jianguo and Zhang, Shanshan and Wang, Wei},
  doi          = {10.1007/s13042-023-01779-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2511-2528},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Node embedding with capsule generation-embedding network},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generating adversarial samples by manipulating image
features with auto-encoder. <em>IJMLC</em>, <em>14</em>(7), 2499–2509.
(<a href="https://doi.org/10.1007/s13042-023-01778-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing adversarial attack methods usually add perturbations directly to the pixel space of an image, resulting in significant local noise in the image. Besides, the performance of existing attack methods is affected by various pixel-space based defense strategies. In this paper, we propose a novel method to generate adversarial examples by adding perturbations to the feature space. Specifically, the perturbation of the feature space is induced by a style-shifting-based network architecture called AdvAdaIN. Furthermore, we expose the feature space to the attacker via an encoder, and then the perturbation is injected into the feature space by AdvAdaIN. Simultaneously, due to the specificity of feature space perturbations, we trained a decoder to reflect the changes in feature space to pixel space and ensure that the perturbations are not easily detected. Meanwhile, we align the original image with another image in the feature space, adding additional adversarial information to the model. In addition, we can generate diverse adversarial samples by varying the perturbation parameters, which mainly change the overall color and brightness of the image. Experiments demonstrate that the proposed method outperforms existing methods and produces more natural adversarial samples when facing defensive strategies.},
  archive      = {J_IJMLC},
  author       = {Yang, Jianxin and Shao, Mingwen and Liu, Huan and Zhuang, Xinkai},
  doi          = {10.1007/s13042-023-01778-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2499-2509},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Generating adversarial samples by manipulating image features with auto-encoder},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Online rule fusion model based on formal concept analysis.
<em>IJMLC</em>, <em>14</em>(7), 2483–2497. (<a
href="https://doi.org/10.1007/s13042-023-01777-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A rule is an effective representation of knowledge in formal concept analysis (FCA), which can express the relations between concepts. One of the main research directions of FCA is to develop rule-based classification algorithms. Rule-based algorithms in FCA lack effective methods for analyze their generalization capability, which can provide an effective learning guarantee for the algorithm. To solve this problem and effectively improve the classification performance of rule-based algorithms in terms of speed and accuracy, this paper combines formal concept analysis with online learning theory to design an online rule fusion model based on FCA, named ORFM. First, the weak granular decision rule is proposed based on rule confidence. Second, the purpose of each iteration is to reduce the difference between the prediction rules extracted from the ORFM and the weak granular decision rules as much as possible so that the classifier model can be adjusted to the direction of the minimum regret growth rate, and the regret growth rate is 0 under the ideal state at the end of iteration. Third, it is proven that the regret of ORFM has an upper bound; that is, in an ideal state, the regret growth rate decreases rapidly with the increase in the number of iterations, eventually making the regret of the model no longer grow. This provides an effective learning guarantee for ORFM. Finally, experimental results on 16 datasets show that ORFM has better classification performance than other classifier models.},
  archive      = {J_IJMLC},
  author       = {Zhang, Xiaohe and Chen, Degang and Mi, Jusheng},
  doi          = {10.1007/s13042-023-01777-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2483-2497},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Online rule fusion model based on formal concept analysis},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lightweight image super-resolution with group-convolutional
feature enhanced distillation network. <em>IJMLC</em>, <em>14</em>(7),
2467–2482. (<a
href="https://doi.org/10.1007/s13042-023-01776-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the application of convolution neural network (CNN) in single image super-resolution (SISR) is gradually developing. Although many CNN-based methods have acquired splendid performance, oversized model complexity hinders their application in real life. In response to this problem, lightweight and efficient are becoming development tendency of SR models. The residual feature distillation network (RFDN) is one of the state-of-the-art lightweight SR networks. However, the shallow residual block (SRB) in RFDN still uses ordinary convolution to extract feature, where still has great improvement room for the reduction of network parameters. In this paper, we propose the Group-convolutional Feature Enhanced Distillation Network (GFEDNet), which is constructed by the stacking of feature distillation and aggregation block (FDAB). Benefitting from residual learning of residual feature aggregation (RFA) framework and feature distillation strategy of RFDN, the FDAB can obtain more diverse and detailed feature representations, thereby improves the SR capability. Furthermore, we propose the multi-scale group convolution block (MGCB) to replace the SRB. Thanks to group convolution and multi-branch parallel structure, the MGCB reduces the parameters substantially while maintaining SR performance. Extensive experiments show the powerful function of our proposed GFEDNet against other state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Zhang, Wei and Fan, Zhongqiang and Song, Yan and Wang, Yagang},
  doi          = {10.1007/s13042-023-01776-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2467-2482},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Lightweight image super-resolution with group-convolutional feature enhanced distillation network},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Coupling learning for feature selection in categorical data.
<em>IJMLC</em>, <em>14</em>(7), 2455–2465. (<a
href="https://doi.org/10.1007/s13042-023-01775-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection, which is a commonly used data prepossessing technique, focuses on improving model performance and efficiency by removing redundant or irrelevant features. However, an implicit assumption made by traditional feature selection approaches is that data are independent and identically distributed (IID). To further obtain more complex and significant information, an effective feature selection construction should consider the couplings (non-IIDness) contained within feature values and relevance between features. Hence, referring to rough set theory, this paper first introduces a new coupled similarity measure to discover the value-to-feature-to-class coupling information, which can be used to calculate object neighbor and update feature weights. Second, using mutual information, a new coupled relevance measure is defined to capture the feature-to-feature coupling relationships. On this basis, an effective feature-selection algorithm based on coupling learning is developed for categorical data. To demonstrate the proposed algorithm, four common classifiers and 12 UCI data sets are employed in the experiments. The experimental results confirm the feasibility of the new algorithm and its effectiveness.},
  archive      = {J_IJMLC},
  author       = {Wang, Feng and Liang, Jiye and Song, Peng},
  doi          = {10.1007/s13042-023-01775-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2455-2465},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Coupling learning for feature selection in categorical data},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-receptive field spatiotemporal network for action
recognition. <em>IJMLC</em>, <em>14</em>(7), 2439–2453. (<a
href="https://doi.org/10.1007/s13042-023-01774-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the great progress in action recognition made by deep neural networks, visual tempo may be overlooked in the feature learning process of existing methods. The visual tempo is the dynamic and temporal scale variation of actions. Existing models usually understand spatiotemporal scenes using temporal and spatial convolutions, which are limited in both temporal and spatial dimensions, and they cannot cope with differences in visual tempo changes. To address these issues, we propose a multi-receptive field spatiotemporal (MRF-ST) network to effectively model the spatial and temporal information of different receptive fields. In the proposed network, dilated convolution is utilized to obtain different receptive fields. Meanwhile, dynamic weighting for different dilation rates is designed based on the attention mechanism. Thus, the proposed MRF-ST network can directly caption various tempos in the same network layer without any additional cost. Moreover, the network can improve the accuracy of action recognition by learning more visual tempos of different actions. Extensive evaluations show that MRF-ST reaches the state-of-the-art on three popular benchmarks for action recognition: UCF-101, HMDB-51, and Diving-48. Further analysis also indicates that MRF-ST can significantly improve the performance at the scenes with large variances in visual tempo.},
  archive      = {J_IJMLC},
  author       = {Nie, Mu and Yang, Sen and Wang, Zhenhua and Zhang, Baochang and Lu, Huimin and Yang, Wankou},
  doi          = {10.1007/s13042-023-01774-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2439-2453},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-receptive field spatiotemporal network for action recognition},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Two-channel deep recursive multi-scale network based on
multi-attention for no-reference image quality assessment.
<em>IJMLC</em>, <em>14</em>(7), 2421–2437. (<a
href="https://doi.org/10.1007/s13042-023-01773-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of convolutional neural network (CNN) technology, No-reference Image Quality Assessment (NR-IQA) based on CNN has attracted the attention of many scholars. However, most of the previous methods improved the evaluation performance by increasing the network depth and various feature extraction mechanisms. This maybe causes some problems such as insufficient feature extraction, detail loss and gradient disappearance due to the limited samples with labels in the existing database. To learn feature representation more effectively, this paper proposes a Two-channel Deep Recursive Multi-Scale Network Based on Multi-Attention (ATDRMN), which can accurately evaluate image quality without relying on reference images. The network is a two-channel convolution networks with original image and gradient image as inputs. In two sub-branch networks, the Multi-scale Feature Extraction Block based on Attention (AMFEB) and the Improved Atrous Space Pyramid Pooling Network (IASPP-Net) are proposed to extend the attention-required feature information and obtain different levels of hierarchical feature information. Specifically, each AMFEB makes full use of image features in convolution kernels of different sizes to expand feature information, and further inputs these features into the attention mechanism to learn their corresponding weights. The output of each AMFEB is extended by the cavity convolution algorithm in IASPP-Net to obtain more context information and learn its hierarchical features. Finally, multiple AMFEBs and IASPP-Nets are respectively deeply and recursively fused to further obtain the most effective feature information, and then the output features are inputted to the regression network for final quality evaluation. The experimental results on seven databases showed that the proposed method has good robustness and is superior to the most advanced NR-IQA methods.},
  archive      = {J_IJMLC},
  author       = {Wang, Changzhong and Lv, Xiang and Fan, Xiaodong and Ding, Weiping and Jiang, Xiaoli},
  doi          = {10.1007/s13042-023-01773-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2421-2437},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Two-channel deep recursive multi-scale network based on multi-attention for no-reference image quality assessment},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DaCFN: Divide-and-conquer fusion network for RGB-t object
detection. <em>IJMLC</em>, <em>14</em>(7), 2407–2420. (<a
href="https://doi.org/10.1007/s13042-022-01771-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thermal images could help visual images to improve object detection performance under low illumination. On the other hand, the complementary fusion of visual and thermal features can be challenging. In RGB-T object detection, the two-stream network structure has been widely used, in which addition operation and concatenation operation are utilized to merge feature maps. However, the addition compacts two-stream feature with inevitable distortion, while direct concatenation may bring redundancy to features. In this paper, we show that the addition operation is more suitable for common features from RGB and thermal, while the concatenation operation is more suitable for specific features unique to RGB or thermal. Then we take the divide-and-conquer strategy to propose an RGB-T detector named Divide-and-Conquer Fusion Network (DaCFN), which divides RGB and thermal features into common and specific ones and applies category-customized operations to them. Specifically, we design the Partial Coupling Net Block (PCNB), in which common features are extracted by coupled parameters and specific features by independent ones. Then the Selective Common Addition (SCA) and the Independent Specific Concatenation (ISC) are designed to fuse common and specific features, respectively. Experiments on FLIR and KAIST datasets demonstrate that our approach achieves high accuracy with high speed against other state-of-the-art RGB-T detectors.},
  archive      = {J_IJMLC},
  author       = {Wang, Bofan and Zhao, Haitao and Zhuang, Yi},
  doi          = {10.1007/s13042-022-01771-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2407-2420},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {DaCFN: Divide-and-conquer fusion network for RGB-T object detection},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving text classification via a soft dynamical label
strategy. <em>IJMLC</em>, <em>14</em>(7), 2395–2405. (<a
href="https://doi.org/10.1007/s13042-022-01770-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Labels play a central role in the text classification tasks. However, most studies has a lossy label encoding problem, in which the label will be represented by a meaningless and independent one-hot vector. This paper proposes a novel strategy to dynamically generate a soft pseudo label based on the prediction for each training. This history-based soft pseudo label will be taken as the target to optimize parameters by minimizing the distance between the target and the prediction. In addition, we augment the training data with Mix-up, a widely used method, to prevent overfitting on the small dataset. Extensive experimental results demonstrate that the proposed dynamical soft label strategy significantly improves the performance of several widely used deep learning classification models on binary and multi-class text classification tasks. Not only is our simple and efficient strategy much easier to implement and train, it is also exhibits substantial improvements (up to 2.54\% relative improvement on FDCNews datasets with an LSTM encoder) over Label Confusion Learning (LCM)—a state-of-the-art label smoothing model—under the same experimental setting. The experimental result also demonstrate that Mix-up improves our method&#39;s performance on smaller datasets, but introduce excess noise in larger datasets, which diminishes the model’s performance.},
  archive      = {J_IJMLC},
  author       = {Wang, Jingjing and Xie, Haoran and Wang, Fu Lee and Lee, Lap-Kei},
  doi          = {10.1007/s13042-022-01770-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2395-2405},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Improving text classification via a soft dynamical label strategy},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weighted cluster-level social emotion classification across
domains. <em>IJMLC</em>, <em>14</em>(7), 2385–2394. (<a
href="https://doi.org/10.1007/s13042-022-01769-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social emotion classification is important for better capturing the preferences and perspectives of individual users to monitor public opinion and edit news. However, news reports have a strong domain dependence. Moreover, training data in the target domain are usually insufficient and only a small amount of training data may be labeled. To address these problems, we develop a cluster-level method for social emotion classification across domains. By discovering both source and target clusters and weighting the cluster in the source domain according to the similarity between its distribution and that of the target cluster, we can discover common patterns between the source and target domains, thus using both source and target data more effectively. Extensive experiments involving 12 cross-domain tasks conducted by using the ChinaNews dataset show that our model outperforms existing methods.},
  archive      = {J_IJMLC},
  author       = {Wang, Fu Lee and Zhao, Zhengwei and Cheng, Gary and Rao, Yanghui and Xie, Haoran},
  doi          = {10.1007/s13042-022-01769-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2385-2394},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Weighted cluster-level social emotion classification across domains},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Genetic algorithm based approach to compress and accelerate
the trained convolution neural network model. <em>IJMLC</em>,
<em>14</em>(7), 2367–2383. (<a
href="https://doi.org/10.1007/s13042-022-01768-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although transfer learning has been employed successfully with pre-trained models based on large convolutional neural networks, the demand for huge storage space makes it unattractive to deploy these solutions on edge devices having limited storage and computational power. A number of researchers have proposed Convolution Neural Network Compression models to take care of such issues. In this paper, a genetic algorithm-based approach has been employed to reduce the size of the Convolution Neural Network model, by selecting a subset of convolutional filters and nodes in the dense layers, while maintaining accuracy levels of original models. Specifically, AlexNet, VGG16, ResNet50 architectures have been taken up for model reduction and it has been shown that without compromising on the accuracy, huge gains can be made in terms of reduced storage space. The paper also shows that using this approach additional reduction in storage space of around 38\% could be achieved even for SqueezeNet, which is an already compressed model. The paper also reports a substantial reduction in inference time for standard datasets such as MNIST, CIFAR-10 and CIFAR-100 applied on all the compressed models mentioned above. For CIFAR-100, the reduction in time is almost double that of other results reported in the literature.},
  archive      = {J_IJMLC},
  author       = {Agarwal, Mohit and Gupta, Suneet Kr. and Biswas, K. K.},
  doi          = {10.1007/s13042-022-01768-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2367-2383},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Genetic algorithm based approach to compress and accelerate the trained convolution neural network model},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Collaborative optimization of spatial-spectrum parallel
convolutional network (CO-PCN) for hyperspectral image classification.
<em>IJMLC</em>, <em>14</em>(7), 2353–2366. (<a
href="https://doi.org/10.1007/s13042-022-01767-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deep learning model has demonstrated excellent performance in the fitting of data and knowledge. For hyperspectral images, accurate classification is still difficult in the case of limited samples and high-dimensional relevance. In this paper, we propose a collaborative optimization parallel convolution network consisting of 3D-2D CNN for hyperspectral image classification. One branch of the parallel network is a 3D-CNN consisting of three blocks for extracting spectrum features and spectrum correlation. The three blocks include a 3D bottleneck block (convolution), SEblock (attention), and a spatial-spectrum convolution module. Secondly, the diverse Region feature extraction network is employed as a spatial-spectrum feature computing module. Finally, the classification predictions from the two branches are fused to obtain the classification results. By comparing the experimental results conducted on three datasets, the proposed method performs significantly better than the SOTA methods in comparison and has better generalization capability.},
  archive      = {J_IJMLC},
  author       = {Sima, Haifeng and Gao, Feng and Zhang, Yudong and Sun, Junding and Guo, Ping},
  doi          = {10.1007/s13042-022-01767-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2353-2366},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Collaborative optimization of spatial-spectrum parallel convolutional network (CO-PCN) for hyperspectral image classification},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving boosting methods with a stable loss function
handling outliers. <em>IJMLC</em>, <em>14</em>(7), 2333–2352. (<a
href="https://doi.org/10.1007/s13042-022-01766-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In classification problems, the occurrence of abnormal observations is often encountered. How to obtain a stable model to deal with outliers has always been a subject of widespread concern. In this article, we draw on the ideas of the AdaBoosting algorithm and propose a asymptotically linear loss function, which makes the output function more stable for contaminated samples, and two boosting algorithms were designed based on two different way of updating, to handle outliers. In addition, a skill for overcoming the instability of Newton’s method when dealing with weak convexity is introduced. Several samples, where outliers were artificially added, show that the Discrete L-AdaBoost and Real L-AdaBoost Algorithms find the boundary of each category consistently under the condition where data is contaminated. Extensive real-world dataset experiments are used to test the robustness of the proposed algorithm to noise.},
  archive      = {J_IJMLC},
  author       = {Chao, Wang and Bo, Li and Lei, Wang and Pai, Peng},
  doi          = {10.1007/s13042-022-01766-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2333-2352},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Improving boosting methods with a stable loss function handling outliers},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Traffic data extraction and labeling for machine learning
based attack detection in IoT networks. <em>IJMLC</em>, <em>14</em>(7),
2317–2332. (<a
href="https://doi.org/10.1007/s13042-022-01765-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fast expansion of the Internet of Things (IoT) networks raises the possibility of further network threats. In today’s world, network traffic analysis has become an increasingly critical and useful tool for monitoring network traffic in general and analyzing attack patterns in particular. A few years ago, distributed denial-of-service attacks on IoT networks were considered the most pressing problem that needed to be addressed. The absence of high-quality datasets is one of the main obstacles to applying DDOS detection systems based on machine learning. Researchers have developed numerous methods to extract and analyze information from recorded files. From a literature review, it is clear that most of these tools share similar drawbacks. In this study, we proposed an intelligent raw network data extractor and labeler tool by incorporating the limitations of the tools that are available to transform PCAP to CSV. To generate and process a high-quality DDOS attack dataset suitable for machine learning models, we employed several data preprocessing operations on the selected network intrusion dataset. To confirm the validity and acceptability of the dataset, we tested different models. Among the models tested, the random forest was the most accurate in detecting the DDOS attack.},
  archive      = {J_IJMLC},
  author       = {Gebrye, Hayelom and Wang, Yong and Li, Fagen},
  doi          = {10.1007/s13042-022-01765-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2317-2332},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Traffic data extraction and labeling for machine learning based attack detection in IoT networks},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ConvHiA: Convolutional network with hierarchical attention
for knowledge graph multi-hop reasoning. <em>IJMLC</em>, <em>14</em>(7),
2301–2315. (<a
href="https://doi.org/10.1007/s13042-022-01764-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs can provide a rich resource for constructing question answering systems and recommendation systems. However, most knowledge graphs still encounter knowledge incompleteness. The path-based approach predicts the unknown relation between pairwise entities based on existing path facts. This approach is one of the most promising approaches for knowledge graph completion. A critical challenge of such approaches is integrating path sequence information to achieve the goal of better reasoning. Existing researches focus more on the features between neighboring entities and relations in a path, ignoring the semantic relations of the whole triple. A single path consists of entities and relations, but triples contain valuable semantic information. Moreover, the importance of different triples on each path is disparate. To address these problems, we propose a method convolutional network with hierarchical attention to complete the knowledge graph. Firstly, we use a convolutional network and bidirectional long short-term memory to extract the features of each triple in the path. Then, we employ a novel hierarchical attention network, including triple-level attention and path-level attention, picking up path features at multiple granularities. In addition, we elaborate a multistep reasoning component that repeats multiple interactions with the hierarchical attention module to obtain more plausible inference evidence. Finally, we predict the relation between query entities and provide the most dominant path to explain our answer. The experimental results show that our method outperforms existing approaches by 1–3 $$\%$$ on four datasets.},
  archive      = {J_IJMLC},
  author       = {Li, Dengao and Miao, Shuyi and Zhao, Baofeng and Zhou, Yu and Feng, Ding and Zhao, Jumin and Niu, Xupeng},
  doi          = {10.1007/s13042-022-01764-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2301-2315},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {ConvHiA: Convolutional network with hierarchical attention for knowledge graph multi-hop reasoning},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Target-oriented multimodal sentiment classification by using
topic model and gating mechanism. <em>IJMLC</em>, <em>14</em>(7),
2289–2299. (<a
href="https://doi.org/10.1007/s13042-022-01757-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodality sentiment classification of social media attracts increasing attention, whose main purpose is to predict the sentiment of the target mentioned in the posts. Current research mainly focuses on integrating the multimodal data, but fails to consider the impacts on the target. In this work, we tend to propose a target-oriented multimodal sentiment classification model. Specifically, our model starts with exploiting the target-oriented topic within the text. Then, a multi-head attention network is established to learn the multimodal interaction among textual, visual and topic information, based on which the target-oriented representations of the topic, the text and the image are obtained. Moreover, a gating unit to fuse the multimodal information is also built up. On the task of target-oriented multimodal sentiment classification, experiments on multimodal samples are carried out on manually annotated the dataset. Experimental results reveal that our method significantly reduces the gap over each given target, which sets a foundation to achieve the state-of-arts sentiment classification results.},
  archive      = {J_IJMLC},
  author       = {Song, Zhengxin and Xue, Yun and Gu, Donghong and Zhang, Haolan and Ding, Weiping},
  doi          = {10.1007/s13042-022-01757-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2289-2299},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Target-oriented multimodal sentiment classification by using topic model and gating mechanism},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Correction to: Robust two-phase registration method for
three-dimensional point set under the bayesian mixture framework.
<em>IJMLC</em>, <em>14</em>(6), 2287–2288. (<a
href="https://doi.org/10.1007/s13042-023-01816-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJMLC},
  author       = {Yang, Lijuan and Ji, Nannan and Wang, Changpeng and Wu, Tianjun and Li, Fuxiao},
  doi          = {10.1007/s13042-023-01816-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {2287-2288},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Correction to: Robust two-phase registration method for three-dimensional point set under the bayesian mixture framework},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Robust two-phase registration method for three-dimensional
point set under the bayesian mixture framework. <em>IJMLC</em>,
<em>14</em>(6), 2271–2285. (<a
href="https://doi.org/10.1007/s13042-022-01673-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to establish effective correspondences, a two-phase registration method for three-dimensional point set is proposed under the Bayesian mixture framework. In the first phase, the mixture model consisted of student’s t distribution and von Mises-Fisher (vMF) distribution is designed to perform similarity point set registration for recovering rotation transformation, where both distributions are used to measure positional and directional errors, respectively. The second phase implements nonrigid (affine as a particular case) registration between data point set and transformed model point set obtained in the first phase, which is based on student’s t mixture model (SMM) using positional information only. In each phase, variational inference is used to obtain approximate posteriors of model parameters. The experimental results on various datasets demonstrate that our proposed method can achieve better registration performance in terms of robustness to rotation and outliers.},
  archive      = {J_IJMLC},
  author       = {Yang, Lijuan and Ji, Nannan and Wang, Changpeng and Wu, Tianjun and Li, Fuxiao},
  doi          = {10.1007/s13042-022-01673-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {2271-2285},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Robust two-phase registration method for three-dimensional point set under the bayesian mixture framework},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Incremental approaches for optimal scale selection in
dynamic multi-scale set-valued decision tables. <em>IJMLC</em>,
<em>14</em>(6), 2251–2270. (<a
href="https://doi.org/10.1007/s13042-022-01761-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal scale selection is crucial for knowledge discovery in multi-scale decision tables (MDTs). Set-valued decision tables are the generalized versions of single-valued decision information systems and can also be the multi-scale property. Existing researches do not consider the optimal scale selection in a multi-scale set-valued decision table. To address this issue, we introduce the concept of multi-scale set-valued decision tables and study the optimal scale selection problem of multi-scale set-valued decision tables (MSDTs) when the objects are dynamically increased. Firstly, we propose an MSDT model under dominance relations and investigate its characteristics. Secondly, a sequential three-way decision model is established in MSDT. Through reasoning and analyzing the changing trends of the three-way decision at different scales, the optimal scale selection method based on the undetermined degree is proposed. Thirdly, with the increments of the objects in MSDT, we develop incremental algorithms to accelerate optimal scale selection. Finally, a series of comparative experiments on UCI datasets show that our incremental algorithms outperform the non-incremental algorithms in terms of computational complexity.},
  archive      = {J_IJMLC},
  author       = {Huang, Yuandong and Zhang, Yuanjian and Xu, Jianfeng},
  doi          = {10.1007/s13042-022-01761-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {2251-2270},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Incremental approaches for optimal scale selection in dynamic multi-scale set-valued decision tables},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Twin attentive deep reinforcement learning for multi-agent
defensive convoy. <em>IJMLC</em>, <em>14</em>(6), 2239–2250. (<a
href="https://doi.org/10.1007/s13042-022-01759-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent defensive convoy helps provide critical safety for a leader agent. Escort agents work by coordinating their actions to protect the leader agent in the convoy. This paper investigates the multi-agent defensive convoy problem based on deep reinforcement learning and attention mechanism. To address the joint overestimation and suboptimal policy in multi-agent environments, a novel multi-agent twin attentive reinforcement learning method is proposed with a twin attentive critic and a delay attenuation policy. In addition, a variable temperature coefficient for maximum entropy is added to the learning process. The proposed method is evaluated on the designed defensive convoy environment and two public experimental environments, where our proposed method produces competitive performance compared to prior works. The contribution of each novel component is also extensively studied and analyzed. Further evaluations show that our method is robust to several adaptations in the defensive convoy environments including a changing number of escort agents and a changing number of dangers.},
  archive      = {J_IJMLC},
  author       = {Fan, Dongyu and Shen, Haikuo and Dong, Lijing},
  doi          = {10.1007/s13042-022-01759-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {2239-2250},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Twin attentive deep reinforcement learning for multi-agent defensive convoy},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Training fuzzy deep neural network with honey badger
algorithm for intrusion detection in cloud environment. <em>IJMLC</em>,
<em>14</em>(6), 2221–2237. (<a
href="https://doi.org/10.1007/s13042-022-01758-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing (CC) has become one of the prominent technologies because of the significant utility services, which focus on outsourcing data to companies and individual clients. Intrusion Detection Systems (IDS) can be considered an effective solution to achieve security in the cloud computing environment. Blockchain and intrusion detection can be integrated to accomplish security and privacy in the cloud infrastructure. This research develops a new fuzzy deep neural network (FDNN) with Honey Bader Algorithm (HBA) for privacy-preserving intrusion detection technique, named FDNN-HBAID for cloud environment. The presented FDNN-HBAID system is based on the design of an intrusion detection approach with a blockchain-enabled privacy-preserving scheme. An effective training strategy with the FDNN model is applied for intrusion detection and classification. Moreover, FDNN-HBAID provides maximal-security resistance to alleviate zero-day vulnerability and guarantees integrity throughout the nodes and data confidentiality and authentication. In addition, the training process of the FDNN model is carried out using the HBA for optimal adjustment of the hyperparameters. Besides, the privacy-preserving blockchain and intelligent contract model is designed using the Ethereum library to offer privacy to the distributed IDS engine. The experimental validation on benchmark datasets revealed that the FDNN-HBAID approach had shown the potential to achieve security and privacy in the cloud infrastructure.},
  archive      = {J_IJMLC},
  author       = {Jain, Deepak Kumar and Ding, Weiping and Kotecha, Ketan},
  doi          = {10.1007/s13042-022-01758-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {2221-2237},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Training fuzzy deep neural network with honey badger algorithm for intrusion detection in cloud environment},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Image blending-based noise synthesis and attention-guided
network for single image marine snow denoising. <em>IJMLC</em>,
<em>14</em>(6), 2205–2219. (<a
href="https://doi.org/10.1007/s13042-022-01756-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the problem of single image marine snow denoising. Due to the complex underwater environment, the structure and statistical properties of marine snow noise are substantially different from those of the noises encountered in the atmosphere. To synthesize realistic noisy-clean image pairs for training, we propose an image blending-based noise synthesis method that can better simulate the marine snow without training deep networks. Specifically, the noise is first cropped from a real noisy image and pasted into a clean image to produce a composite image. Then, the Gaussian–Poisson Equation is employed to generate a well-blended image (synthetic noisy image). Furthermore, we introduce an attention-guided denoising network that leverages the location information of noise. The proposed network can detect the marine snow noise and then remove it guided by the estimated attention map. Extensive experiments on synthetic and real-world datasets demonstrate that our denoising network can effectively remove the marine snow noise, while preserving rich details of backgrounds. Other alternative marine snow synthesis approaches are also compared to show the superiority of our noise synthesis method in terms of visual quality and running time.},
  archive      = {J_IJMLC},
  author       = {Zhao, Zeyu and Li, Xiu},
  doi          = {10.1007/s13042-022-01756-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {2205-2219},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Image blending-based noise synthesis and attention-guided network for single image marine snow denoising},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Context-sensitive graph representation learning.
<em>IJMLC</em>, <em>14</em>(6), 2193–2203. (<a
href="https://doi.org/10.1007/s13042-022-01755-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph representation learning, which maps high-dimensional graphs or sparse graphs into a low-dimensional vector space, has shown its superiority in numerous learning tasks. Recently, researchers have identified some advantages of context-sensitive graph representation learning methods in functions such as link predictions and ranking recommendations. However, most existing methods depend on convolutional neural networks or recursive neural networks to obtain additional information outside a node, or require community algorithms to extract multiple contexts of a node, or focus only on the local neighboring nodes without their structural information. In this paper, we propose a novel context-sensitive representation method, Context-Sensitive Graph Representation Learning (CSGRL), which simultaneously combines attention networks and a variant of graph auto-encoder to learn weighty information about various aspects of participating neighboring nodes. The core of CSGRL is to utilize an asymmetric graph encoder to aggregate information about neighboring nodes and local structures to optimize the learning goal. The main benefit of CSGRL is that it does not need additional features and multiple contexts for the node. The message of neighboring nodes and their structures spread through the encoder. Experiments are conducted on three real datasets for both tasks of link prediction and node clustering, and the results demonstrate that CSGRL can significantly improve the effectiveness of all challenging learning tasks compared with 14 state-of-the-art baselines.},
  archive      = {J_IJMLC},
  author       = {Qin, Jisheng and Zeng, Xiaoqin and Wu, Shengli and Zou, Yang},
  doi          = {10.1007/s13042-022-01755-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {2193-2203},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Context-sensitive graph representation learning},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On development of multimodal named entity recognition using
part-of-speech and mixture of experts. <em>IJMLC</em>, <em>14</em>(6),
2181–2192. (<a
href="https://doi.org/10.1007/s13042-022-01754-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Named Entity Recognition (MNER) is a fundamental task in the field of natural language processing for social media posts. Current MNER models fail to deal with the relation between text and image entities, which results in the textual noise, image noise and even multimodal noise during processing. In this paper, we first introduce the Part-of-speech (POS) information, which is used for non-entity words eliminating and textual noise filtering. A POS-base gated cross-modal attention network is established to precisely learn the textual and visual representations to remove the image noise. Then, a Mixture-of-Experts (MOE) is proposed for multimodality integration, which optimize the effectiveness of named entity identification and filter the multimodal noise. We evaluate the proposed model on the Twitter dataset and the experimental results establish a strong evidence of the state-of-the-art performance.},
  archive      = {J_IJMLC},
  author       = {Chen, Jianying and Xue, Yun and Zhang, Haolan and Ding, Weiping and Zhang, Zhengxuan and Chen, Jiehai},
  doi          = {10.1007/s13042-022-01754-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {2181-2192},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {On development of multimodal named entity recognition using part-of-speech and mixture of experts},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Progressive image dehazing network based on dual feature
extraction modules. <em>IJMLC</em>, <em>14</em>(6), 2169–2180. (<a
href="https://doi.org/10.1007/s13042-022-01753-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image dehazing is of great importance and has been widely studied, as haze severely affects many high-level computer vision tasks. In this paper, by considering the gradual dissipation process of haze, a progressive dehazing network (PDN) is proposed. The proposed approach realizes haze removal step by step by constructing two main modules: the preliminary and fine dehazing modules. In the preliminary dehazing module, a combined residual block is first constructed to extract and enhance features of different levels. Then, an adaptive feature fusion strategy is designed to integrate these features and output the initial dehazing result. Aiming at the residual haze in the initial results, a fine dehazing module is constructed by simulating the last period of the haze dissipation process to further extract a fine haze layer. The final dehazing result is obtained by removing the fine haze layer from the initial dehazing result. Experimental results indicate that the proposed method is superior to some state-of-the-art dehazing methods in terms of visual comparison and objective evaluation.},
  archive      = {J_IJMLC},
  author       = {Yang, Yong and Hu, Wei and Huang, Shuying and Wan, Weiguo and Guan, Juwei},
  doi          = {10.1007/s13042-022-01753-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {2169-2180},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Progressive image dehazing network based on dual feature extraction modules},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust non-negative supervised low-rank discriminant
embedding (NSLRDE) for feature extraction. <em>IJMLC</em>,
<em>14</em>(6), 2155–2168. (<a
href="https://doi.org/10.1007/s13042-022-01752-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among many feature extraction technologies, non-negative matrix factorization (NMF) technology ignores the global representation of data and focuses on the local structure information of data. However, the global representation is often more robust than data noise. Therefore, aiming at solving the above problems, combined with the characteristics of local information data, global representation and low-rank representation, a non-negative supervised low-rank discriminant embedding model (NSLRDE) is proposed to improve the robustness of the algorithm. The algorithm decomposes the data $$X$$ into clean data $$A$$ and noise data $$E$$ , and sparsely constrains $$E$$ through $$L_{1}$$ -norm to enhance the robustness to noise. In addition, the algorithm uses low-rank representation learning and non-negative decomposition to further enhance the robustness of the algorithm. Finally, combined with graph embedding algorithm, local and global data are retained. We also apply the method to various noise databases to test the effectiveness.},
  archive      = {J_IJMLC},
  author       = {Wan, Minghua and Yan, Chengxu and Zhan, Tianming and Tan, Hai and Yang, Guowei},
  doi          = {10.1007/s13042-022-01752-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {2155-2168},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Robust non-negative supervised low-rank discriminant embedding (NSLRDE) for feature extraction},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel framework based on the multi-label classification
for dynamic selection of classifiers. <em>IJMLC</em>, <em>14</em>(6),
2137–2154. (<a
href="https://doi.org/10.1007/s13042-022-01751-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-classifier systems (MCSs) are some kind of predictive models that classify instances by combining the output of an ensemble of classifiers given in a pool. With the aim of enhancing the performance of MCSs, dynamic selection (DS) techniques have been introduced and applied to MCSs. Dealing with each test sample classification, DS methods seek to perform the task of classifier selection so that only the most competent classifiers are selected. The principal subject regarding DS techniques is how the competence of classifiers corresponding to every new test sample classification task can be estimated. In traditional dynamic selection methods, for classifying an unknown test sample x, first, a local region of data that is similar to x is detected. Then, those classifiers that efficiently classify the data in the local region are also selected so as to perform the classification task for x. Therefore, the main effort of these methods is focused on one of the two following tasks: (i) to provide a measure for identifying a local region, or (ii) to provide a criterion for measuring the efficiency of classifiers in the local region (competence measure). This paper proposes a new version of dynamic selection techniques that does not follow the aforementioned approach. Our proposed method uses a multi-label classifier in the training phase to determine the appropriate set of classifiers directly (without applying any criterion such as a competence measure). In the generalization phase, the suggested method is employed efficiently so as to predict the appropriate set of classifiers for classifying the test sample x. It is remarkable that the suggested multi-label-based framework is the first method that uses multi-label classification concepts for dynamic classifier selection. Unlike the existing meta-learning methods for dynamic ensemble selection in the literature, our proposed method is very simple to implement and does not need meta-features. As the experimental results indicate, the suggested technique produces a good performance in terms of both classification accuracy and simplicity which is fairly comparable with that of the benchmark DS techniques. The results of conducting the Quade non-parametric statistical test corroborate the clear dominance of the proposed method over the other benchmark methods.},
  archive      = {J_IJMLC},
  author       = {Elmi, Javad and Eftekhari, Mahdi and Mehrpooya, Adel and Ravari, Mohammad Rezaei},
  doi          = {10.1007/s13042-022-01751-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {2137-2154},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel framework based on the multi-label classification for dynamic selection of classifiers},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Conv-PVT: A fusion architecture of convolution and pyramid
vision transformer. <em>IJMLC</em>, <em>14</em>(6), 2127–2136. (<a
href="https://doi.org/10.1007/s13042-022-01750-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision Transformer (ViT) has fully exhibited the potential of Transformer in computer vision domain. However, the computational complexity is proportional to the input dimension which is a constant value for Transformer. Therefore, training a vision transformer network is extremely memory expensive, where a large number of intermediate activation functions and parameters are involved to compute the gradients during back-propagation. In this paper, we propose Conv-PVT (Convolution blocks + Pyramid Vision Transformer) to improve the overall performance of vision transformer. Especially, we deploy simple convolution blocks in the first layer to reduce the memory footprint by down-sampling the input. Extensive experiments (including image classification, object detection and segmentation) have been carried out on ImageNet-1k, COCO and ADE20k datasets to test the accuracy, training time, memory occupation and robustness of our model. The results demonstrate that Conv-PVT achieves comparable performances with the original PVT and outperforms ResNet and ResNetXt for some downstream vision tasks. But it shortens 60\% of the training time and reduces 42\% GPU (Graphics Processing Unit) memory occupation, realizing twice the inference speed of PVT.},
  archive      = {J_IJMLC},
  author       = {Zhang, Xin and Zhang, Yi},
  doi          = {10.1007/s13042-022-01750-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {2127-2136},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Conv-PVT: A fusion architecture of convolution and pyramid vision transformer},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multilayer discriminative extreme learning machine for
classification. <em>IJMLC</em>, <em>14</em>(6), 2111–2125. (<a
href="https://doi.org/10.1007/s13042-022-01749-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The representation learning is the key to deep learning. As a special deep learning algorithm, the generalization performance of the multilayer extreme learning machine (ML-ELM) is influenced by the feature extraction capability of the extreme learning machine autoencoder (ELM-AE). But the ELM-AE does not consider class labels, and it is difficult for the ELM-AE to build the discriminative feature space in the classification tasks. Thus, to improve the class separability of abstract feature, the discriminant regularization is introduced into the ELM-AE and a new regularized ELM-AE called discriminative extreme learning machine autoencoder (DELM-AE) is proposed. And by stacking the ELM-AE for feature extraction and adopting the ELM for classifying, the multilayer discriminative extreme learning machine (ML-DELM) is proposed for classification tasks. The DELM-AE adds the discriminant regularization term to the loss function to reduce the distance between samples and their class centers in feature space. Compared with the ELM-AE and ML-ELM, the DELM-AE and ML-DELM indirectly utilizes the category information contained in the discriminant regularization term to guide the feature extraction. Empirical evaluations and experiments on various benchmark datasets show that feature representation learned by the DELM-AE is discriminative and sparse, and the generalization performance and structural sparsity of ML-DELM are comparable with the other state-of-the-art ML-ELM algorithms.},
  archive      = {J_IJMLC},
  author       = {Lai, Jie and Wang, Xiaodan and Xiang, Qian and Song, Yafei and Quan, Wen},
  doi          = {10.1007/s13042-022-01749-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {2111-2125},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multilayer discriminative extreme learning machine for classification},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pyramid feature boosted network for single image dehazing.
<em>IJMLC</em>, <em>14</em>(6), 2099–2110. (<a
href="https://doi.org/10.1007/s13042-022-01748-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a Pyramid Feature Boosted Network is proposed for single image dehazing, which leverages the encoder-decoder structure and benefits from two core modules to achieve high-quality image recovery. Since image detail loss is a common problem in image restoration, we design a Feature Boosted module based on the Strengthen-Operate-Subtract boosting strategy to increase the quality of the image. This module innovatively incorporates multi-scale latent features to replenish the lost signals. In addition, to release the heterogeneous haze, a novel Mixture Attention unit is proposed to reinforce the important information in multiple dimensions and highlight the main object in the image from background. Extensive evaluations and simulation results show the proposed methods outperform the State-Of-The-Art (SOTA) methods on both synthetic datasets and real-world images.},
  archive      = {J_IJMLC},
  author       = {Hu, Guangrui and Tan, Anhui and He, Liangtian and Shen, Haozhen and Chen, Hongming and Wang, Chao and Du, Huandi},
  doi          = {10.1007/s13042-022-01748-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {2099-2110},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Pyramid feature boosted network for single image dehazing},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Android malware adversarial attacks based on feature
importance prediction. <em>IJMLC</em>, <em>14</em>(6), 2087–2097. (<a
href="https://doi.org/10.1007/s13042-022-01747-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decade, malicious Android applications have increased rapidly because of the popularity of Android mobile devices. In particular, some Android malware starts to use the adversarial examples generation technology to escape from the detection system. To defend against the adversarial examples of Android malware, researchers need to research the generation of adversarial examples. Meanwhile, substitute models are one of the research topics in machine learning interpretability. In the paper, we propose a new model called p-MalGAN with a Feature Importance Prediction (FIP) module based on MalGAN, a Generative Adversarial Network (GAN) for generating malware adversarial examples. FIP module uses random forest as an substitute model to calculates the importance of features by measuring the correlation between the features and the labels of the detector to predict the features used by the detector, then uses the high-confidence features to generate adversarial examples. Compared with MalGAN, our model overcomes the difficulty of not knowing detector features in realistic scenes. Experimental results show that our method can effectively predict the features of the detector and reduces the difference between the adversarial examples and the original malware with slightly affecting the attack performance.},
  archive      = {J_IJMLC},
  author       = {Guo, Yanping and Yan, Qiao},
  doi          = {10.1007/s13042-022-01747-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {2087-2097},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Android malware adversarial attacks based on feature importance prediction},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global-local information based oversampling for multi-class
imbalanced data. <em>IJMLC</em>, <em>14</em>(6), 2071–2086. (<a
href="https://doi.org/10.1007/s13042-022-01746-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-class imbalanced classification is a challenging problem in the field of machine learning. Many methods have been proposed to deal with it, and oversampling is one of the most popular techniques which alleviates class imbalance by generating instances for the minority classes. However, each oversampling utilizes a single way to generate instances for all candidate minority ones, which neglects the intrinsic characteristics among different minority class instances, and makes the synthetic instances redundant or ineffective. In this work, we propose a global-local-based oversampling method, termed GLOS. We introduce a new discreteness-based metric (DID) and distinguish the minority class from the majority class by comparing it with each class-level discreteness value. Then, for each minority class, some difficult-to-learn instances are selected, which have smaller instance-level dispersion than the corresponding class-level one, to generate synthetic instances. And the number of synthetic instances equals the difference between two types of dispersion values. These selected instances are assigned into different groups according to their local distribution. Furthermore, GLOS adopts a specific synthetic strategy to each group instance purposefully. Finally, all minority classes, part of the majority classes instances, and synthetic data will be used as training data. In this way, the quantity and quality of synthetic instances are guaranteed. Experimental results on KEEL and UCI data sets demonstrate the effectiveness of our proposal.},
  archive      = {J_IJMLC},
  author       = {Han, Mingming and Guo, Husheng and Li, Jinyan and Wang, Wenjian},
  doi          = {10.1007/s13042-022-01746-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {2071-2086},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Global-local information based oversampling for multi-class imbalanced data},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Method for three-way decisions using similarity in
incomplete information systems. <em>IJMLC</em>, <em>14</em>(6),
2053–2070. (<a
href="https://doi.org/10.1007/s13042-022-01745-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problems of filling missing information and calculating conditional probability and loss function in incomplete information systems, this paper provides a novel three-way decision model based on incomplete information systems. Firstly, a new information table is obtained by filling in the missing information based on similarity, and the conditional probability calculation method is established by the idea of a TOPSIS combination with the information table. The relative loss function is calculated based on the risk avoidance coefficient under different attributes. Then, we propose the notion of interval relative loss function and give formulae to calculate the interval relative loss function values. In particular, the key steps of constructing the three-way decision model are summarized. Finally, a case study of medical diagnosis is provided to verify the validity of the proposed method. Moreover, the rationality and superiority of the presented method are verified by sensitivity analysis and comparative analysis.},
  archive      = {J_IJMLC},
  author       = {Tu, Jing and Su, Shuhua},
  doi          = {10.1007/s13042-022-01745-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {2053-2070},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Method for three-way decisions using similarity in incomplete information systems},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhanced feature fusion structure of YOLO v5 for detecting
small defects on metal surfaces. <em>IJMLC</em>, <em>14</em>(6),
2041–2051. (<a
href="https://doi.org/10.1007/s13042-022-01744-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the detection ability for small defects on the surface of the metal base of an infrared laser sensor, master the fluctuation and distribution of product quality, and form closed-loop control of production and quality improvement, the advanced You Only Look Once (YOLO) v5s (an improved YOLO model) object detection algorithm was further improved in this study. Specifically, the same-scale feature fusion part that is easily ignored in the structure was strengthened to enhance the network detection performance. In deep learning object detection, the propagation of information between features in the neural network is important. It was often represented by the pyramid features in the neck part of the model to enhance feature fusion. First, this study proposed a cross-convolution feature strengthening connection method combining the backbone and neck, which shortened the path of information propagation and improved the semantic information between feature pyramids. Then, the concat module of the original network was improved, and a new enhanced feature concat module was proposed to enhance the fusion of features at the same scale. The attention modules implemented by combining the convolutional block attention module were integrated into the concat module to enable the network to learn the weights of each channel independently, enhance the information transmission between features, and improve the detection performance of deep learning small objects. Lastly, the K-means + + algorithm was used to optimize the self-made Metal Base dataset of Infrared Laser Sensor (ILS-MB) and generate a new anchor box suitable for small objects in this dataset to improve the matching degree of target objects. With a small increase in computational cost, the improved YOLO v5s algorithm enhanced the accuracy by 3.8\% on the ILS-MB dataset and achieved a very significant effect compared with other state-of-the-art detection methods.},
  archive      = {J_IJMLC},
  author       = {Zhu, Xingfei and Liu, Jiayi and Zhou, Xingyu and Qian, Shanhua and Yu, Jinghu},
  doi          = {10.1007/s13042-022-01744-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {2041-2051},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Enhanced feature fusion structure of YOLO v5 for detecting small defects on metal surfaces},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GCN recommendation model based on the fusion of dynamic
multiple-view latent interest topics. <em>IJMLC</em>, <em>14</em>(6),
2023–2039. (<a
href="https://doi.org/10.1007/s13042-022-01743-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural network-based representation models have shown extraordinary potential in numerous recommender system applications. Previous studies mainly considered high-order connectivity information in a single view from an interaction graph but ignored the individualized information of the users or items, making them vulnerable to over-smoothing problems. In this study, we proposed a dynamic multi-view fusion-based graph convolution network model for recommendation systems. Multiple views were generated for learning on the basis of latent user interest topics from the decomposed matrix, and a continuous awareness mechanism was proposed to maintain the model’s focus on the individualized features of the nodes. During the graph learning process, a dynamic aggregation mechanism was designed to adjust the fusion weight of different propagation layers. Lastly, the different features from multiple views were dynamically fused through an attention mechanism and a principal component control mechanism to predict the similarities between users and items. Experimental results of three popular datasets of recommendation systems demonstrated that our method could effectively alleviate the over-smoothing problem and achieved better performance than four state-of-the-art baselines.},
  archive      = {J_IJMLC},
  author       = {Liu, Feng and Liao, Jian and Zheng, Jianxing and Wang, Suge and Li, Deyu and Wang, Xin},
  doi          = {10.1007/s13042-022-01743-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {2023-2039},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {GCN recommendation model based on the fusion of dynamic multiple-view latent interest topics},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiview nonnegative matrix factorization with dual HSIC
constraints for clustering. <em>IJMLC</em>, <em>14</em>(6), 2007–2022.
(<a href="https://doi.org/10.1007/s13042-022-01742-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To utilize multiple features for clustering, this paper proposes a novel method named as multiview nonnegative matrix factorization with dual HSIC constraints for clustering. The Hilbert-Schmidt independence criterion (HSIC) is employed to measure the correlation(including linear and nonlinear correlation) between the latent representation of each view and the common ones (representation constraint). The independence among the vectors of the basis matrix for each view (basis constraint) is maximized to pursue the discriminant and informative basis. To maintain the nonlinear structure of multiview data, we directly optimize the kernel of the common representation and make its values of the same neighborhood are larger than the others. We adopt partition entropy to constrain the uniformity level of the its values. A novel iterative update algorithm is designed to seek the optimal solutions. We extensively test the proposed algorithm and several state-of-the-art NMF-based multiview methods on four datasets. The clustering results validate the effectiveness of our method.},
  archive      = {J_IJMLC},
  author       = {Wang, Sheng and Chen, Liyong and Sun, Yaowei and Peng, Furong and Lu, Jianfeng},
  doi          = {10.1007/s13042-022-01742-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {2007-2022},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multiview nonnegative matrix factorization with dual HSIC constraints for clustering},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Social activity matching with graph neural network in
event-based social networks. <em>IJMLC</em>, <em>14</em>(6), 1989–2005.
(<a href="https://doi.org/10.1007/s13042-022-01741-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, event-based social networks (EBSNs) have become increasingly popular. Different from traditional online social networks, EBSNs consist of valuable online and offline social interactions, which can bring users more experience and entertainment. One of the crucial tasks for the EBSN platforms is to match users and social activities to help users participate in suitable activities. However, the existing matching methods either do not consider the influence of adjacent activities and users and the processing of newly added activities, or ignore the actual attribute constraints, e.g., budget and capacity. To address the limitations, we propose a novel graph neural network-based social activity matching method. Specifically, we model the historical records with a heterogeneous graph, and connect any new activity node to the user node who is the organizer. We then design a neural network-based affinity calculation model to predict the affinities between users and new activities. Moreover, we use a greedy-based heuristic method for social activity matching, considering the bilateral constraints extracted from the user and the activity attributes. Extensive experiments on three real event-based social service datasets show the effectiveness of the proposed method, which outperforms the state-of-the-art baselines in terms of affinity prediction and social activity matching.},
  archive      = {J_IJMLC},
  author       = {Sun, Bingyi and Wei, Xiaohui and Cui, Jiaxu and Wu, Yan},
  doi          = {10.1007/s13042-022-01741-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1989-2005},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Social activity matching with graph neural network in event-based social networks},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Software defect prediction ensemble learning algorithm based
on adaptive variable sparrow search algorithm. <em>IJMLC</em>,
<em>14</em>(6), 1967–1987. (<a
href="https://doi.org/10.1007/s13042-022-01740-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software defect prediction has caused widespread concern among software engineering researchers, which aims to erect a software defect prediction model according to historical data. Among all the techniques used in this field, extreme learning machine is widely used by researchers because of its simple structure and excellent learning speed. At the same time, the prediction performance of extreme learning machine is greatly affected by the random selection of parameters and the weak generalization ability. In this sense, in order to improve the prediction performance of the model, researchers uses swarm intelligence optimization algorithm to provide the optimal parameters for the model. Sparrow search algorithm is a new meta-heuristic algorithm that simulates the foraging and anti-predation behavior of the sparrow group. However, the original sparrow search algorithm is easily trapped to local optimal solutions in the later stage of the iterations. To improve the global optimization ability of the original sparrow search algorithm, this paper proposed an adaptive variable sparrow search algorithm (AVSSA) based on adaptive hyper-parameters and variable logarithmic spiral. This work run experiments of AVSSA in eight benchmark functions, and obtained the satisfactory results. In the traditional software defect prediction algorithm, the imbalance of data distribution is also one of the main reasons that affect the performance of the model. Therefore, this paper uses the adaptive variable sparrow search algorithm to optimize the extreme learning machine as the base predictor for Bagging ensemble learning (AVSEB). A new software defect prediction ensemble learning model is proposed in this paper. Firstly, the model used the unstable cut-points algorithm to preprocess Bagging sample set in this model. Then, the adaptive variable sparrow search algorithm is used to optimize the extreme learning machine as the base predictor of ensemble learning. Finally, the voting method is used to output the prediction results of software defects. Based on the experimental results, the evaluation index of our proposed algorithm is significantly superior to the other four advanced comparison algorithms in 15 open software defect datasets. According to the test results of Friedman ranking and Holm’s post hoc test, this paper proposed algorithm has obvious statistical significance compared with other advanced prediction algorithms.},
  archive      = {J_IJMLC},
  author       = {Tang, Yu and Dai, Qi and Yang, Mengyuan and Du, Tony and Chen, Lifang},
  doi          = {10.1007/s13042-022-01740-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1967-1987},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Software defect prediction ensemble learning algorithm based on adaptive variable sparrow search algorithm},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Heterogeneous dual network with feature consistency for
domain adaptation person re-identification. <em>IJMLC</em>,
<em>14</em>(5), 1951–1965. (<a
href="https://doi.org/10.1007/s13042-022-01739-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To reduce the noisy pseudo-labels generated by clustering for unsupervised domain adaptation (UDA) person re-identification (re-ID), the method of collaborative training between dual networks has been proposed and proved to be effective. However, most of these methods ignore the coupling problem between dual networks with the same architecture, which makes them inevitably share a high similarity and lack heterogeneity and complementarity. In this paper, we propose a heterogeneous dual network (HDNet) framework with two asymmetric networks, one of which applies convolution with limited receptive fields to obtain local information and the other uses Transformer to capture long-range dependency. Additionally, we propose feature consistency loss (FCL) that does not rely on pseudo-labels. FCL focuses more on the consistency of the sample in the feature space rather than the class prediction space, driving the feature learning of UDA re-ID from the task level to the feature level. Furthermore, we propose an adaptive channel mutual-aware (ACMA) module which contains two branches to focus on the global and local information between channels. We evaluate our proposed method on three popular datasets: DukeMTMC-reID, Market-1501 and MSMT17. Extensive experimental results demonstrate that our method achieves a competitive performance.},
  archive      = {J_IJMLC},
  author       = {Zhou, Hua and Kong, Jun and Jiang, Min and Liu, Tianshan},
  doi          = {10.1007/s13042-022-01739-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1951-1965},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Heterogeneous dual network with feature consistency for domain adaptation person re-identification},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Maximum density minimum redundancy based hypergraph
regularized support vector regression. <em>IJMLC</em>, <em>14</em>(5),
1933–1950. (<a
href="https://doi.org/10.1007/s13042-022-01738-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning has attracted great attention in machine learning for it makes full use of labeled and unlabeled data for training. Most semi-supervised learning methods are not suitable for regression due to the data labels in regression are real-valued and smooth. In this paper, hypergraph instead of graph is utilized to represent the geometric structure of data. The manifold regularization term is constructed by calculating the hypergraph Laplacian and introduced into the regularization framework of kernel learning, a hypergraph regularized support vector regression (HGSVR) is proposed. Moreover, we propose a two-layer maximum density minimum redundancy method (MDMR) to pre-select initial labeled data, which fully considers the density and redundancy of data. The pre-select method is introduced into HGSVR and a second semi-supervised regression called MDMR-HGSVR is proposed. Experimental results on 9 UCI datasets show that HGSVR and MDMR-HGSVR outperform the other compared semi-supervised regression methods.},
  archive      = {J_IJMLC},
  author       = {Ding, Shifei and Sun, Yuting and Zhang, Jian and Guo, Lili and Xu, Xiao and Zhang, Zichen},
  doi          = {10.1007/s13042-022-01738-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1933-1950},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Maximum density minimum redundancy based hypergraph regularized support vector regression},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TAGNet: A tiny answer-guided network for conversational
question generation. <em>IJMLC</em>, <em>14</em>(5), 1921–1932. (<a
href="https://doi.org/10.1007/s13042-022-01737-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conversational Question Generation (CQG) aims to generate conversational questions with the given passage and conversation history. Previous work of CQG presumes a contiguous span as the answer and generates a question targeting it. However, this limits the application scenarios because answers in practical conversations are usually abstractive free-form text instead of extractive spans. In addition, most state-of-the-art CQG systems are based on pretrained language models consisting of hundreds of millions of parameters, bringing challenges to real-life applications due to latency and capacity constraints. To elegantly address these problems, in this work, we introduce the Tiny Answer-Guided Network (TAGNet) based on the lightweight module (Bi-LSTM) for CQG. We explicitly take the target answers as input, which interacts with the passages and conversation history in the encoder and guides the question generation through the gated attention mechanism in the decoder. Besides, we distill the knowledge from larger pretrained language models into our smaller network to make the trade-off between performance and efficiency. Experimental results show that our TAGNet achieves a comparable performance with large pretrained language models (retaining $$95.9\%$$ of teacher performance) while using $$5.7\times$$ fewer parameters and $$10.4\times$$ faster inference latency. TAGNet outperforms the previous best-performing model with similar parameter size by a large margin, and further analysis shows that TAGNet generates more answer-specific conversational questions.},
  archive      = {J_IJMLC},
  author       = {Wang, Zekun and Zhu, Haichao and Liu, Ming and Qin, Bing},
  doi          = {10.1007/s13042-022-01737-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1921-1932},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {TAGNet: A tiny answer-guided network for conversational question generation},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An inspection method of rail head surface defect via bimodal
structured light sensors. <em>IJMLC</em>, <em>14</em>(5), 1903–1920. (<a
href="https://doi.org/10.1007/s13042-022-01736-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rail defects have long threatened the safety of railway vehicles. Existing inspection methods still have some problems and flaws that can not meet practical application. In this paper, we propose a rail surface defect inspection method based on bimodal structured light sensors, termed Rail Surface Defect Inspection Network (RSDINet), which can detect and measure defect in bimodal rail images. To verify effect of the method, we establish a bimodal image dataset of intensity and depth images collected by the constructed bimodal structured light sensors data acquisition system. To solve the irregularity of rail surface defect shape, we propose a feature extraction backbone network by introducing deformable convolution. Moreover, RSDINet adopts a parallel feature extraction strategy to process bimodal images respectively. Specifically, we apply different backbone networks to bimodal images respectively for different image characteristics to enhance the feature representation ability of network. Then, our RSDINet fuses multi-scale feature of bimodal images respectively and carries out multi-scale rail surface defect detection and measurement. It is worth noting that the proposed RSDINet can accomplish these two tasks end-to-end simultaneously. Experiments demonstrate that based on the established dataset, the method achieves 87.17 mAP and 39.07 mSAP for detection and measurement respectively at 6.2 FPS on a single GPU, which has a better performance than previous SOTA methods and shows a promising potential for application in high-speed railway.},
  archive      = {J_IJMLC},
  author       = {Zheng, Jiajun and Wang, Le and Liu, Junbo and Wang, Hao and Wang, Shengchun and Wang, Liang and Zhang, Jiaxu},
  doi          = {10.1007/s13042-022-01736-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1903-1920},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An inspection method of rail head surface defect via bimodal structured light sensors},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-stage transfer learning with BERTology-based language
models for question answering system in vietnamese. <em>IJMLC</em>,
<em>14</em>(5), 1877–1902. (<a
href="https://doi.org/10.1007/s13042-022-01735-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the fast growth of information science and engineering, a large number of textual data generated are valuable for natural language processing and its applications. Particularly, finding correct answers to natural language questions or queries requires spending tremendous time and effort in human life. While using search engines to discover information, users manually determine the answer to a given question on a range of retrieved texts or documents. Question answering relies heavily on the capability to automatically comprehend questions in human language and extract meaningful answers from a single text. In recent years, such question–answering systems have become increasingly popular using machine reading comprehension techniques. On the other hand, high-resource languages (e.g., English and Chinese) have witnessed tremendous growth in question-answering methodologies based on various knowledge sources. Besides, powerful BERTology-based language models only encode texts with a limited length. The longer texts contain more distractor sentences that affect the QA system performance. Vietnamese has a variety of question words in the same question type. To address these challenges, we propose ViQAS, a new question–answering system with multi-stage transfer learning using language models based on BERTology for a low-resource language such as Vietnamese. Last but not least, our QA system is integrated with Vietnamese characteristics and transformer-based evidence extraction techniques into an effective contextualized language model-based QA system. As a result, our proposed system outperforms our forty retriever-reader QA configurations and seven state-of-the-art QA systems such as DrQA, BERTserini, BERTBM25, XLMRQA, ORQA, COBERT, and NeuralQA on three Vietnamese benchmark question answering datasets.},
  archive      = {J_IJMLC},
  author       = {Van Nguyen, Kiet and Do, Phong Nguyen-Thuan and Nguyen, Nhat Duy and Nguyen, Anh Gia-Tuan and Nguyen, Ngan Luu-Thuy},
  doi          = {10.1007/s13042-022-01735-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1877-1902},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-stage transfer learning with BERTology-based language models for question answering system in vietnamese},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Topic-aware hierarchical multi-attention network for text
classification. <em>IJMLC</em>, <em>14</em>(5), 1863–1875. (<a
href="https://doi.org/10.1007/s13042-022-01734-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks, primarily recurrent and convolutional Neural networks, have been proven successful in text classification. However, convolutional models could be limited when classification tasks are determined by long-range semantic dependency. While the recurrent ones can capture long-range dependency, the sequential architecture of which could constrain the training speed. Meanwhile, traditional networks encode the entire document in a single pass, which omits the hierarchical structure of the document. To address the above issues, this study presents T-HMAN, a Topic-aware Hierarchical Multiple Attention Network for text classification. A multi-head self-attention coupled with convolutional filters is developed to capture long-range dependency via integrating the convolution features from each attention head. Meanwhile, T-HMAN combines topic distributions generated by Latent Dirichlet Allocation (LDA) with sentence-level and document-level inputs respectively in a hierarchical architecture. The proposed model surpasses the accuracies of the current state-of-the-art hierarchical models on five publicly accessible datasets. The ablation study demonstrates that the involvement of multiple attention mechanisms brings significant improvement. The current topic distributions are fixed vectors generated by LDA, the topic distributions will be parameterized and updated simultaneously with the model weights in future work.},
  archive      = {J_IJMLC},
  author       = {Jiang, Ye and Wang, Yimin},
  doi          = {10.1007/s13042-022-01734-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1863-1875},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Topic-aware hierarchical multi-attention network for text classification},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel consensus model with probabilistic linguistic
preference relation for the utilization mode selection of renewable
energy sources. <em>IJMLC</em>, <em>14</em>(5), 1845–1861. (<a
href="https://doi.org/10.1007/s13042-022-01733-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exploitation and utilization of renewable energy is an important issue that contributes to the sustainable development of the national economy. This paper deals with the utilization mode selection of renewable energy in a group decision making (GDM) problem with multiple stakeholders whose assessments are represented as the probabilistic linguistic preference relations (PLPRs). For GDM problems with PLPRs, two requirements should be satisfied before selection process: individual consistency and group consensus. In this regard, a premetric-based consensus measure of PLPRs is defined to describe the consensus level among stakeholders and a consensus improvement model is developed to modify the identified PLPRs while guaranteeing the consistency of the adjusted PLPRs. Then, the proposed method is applied to solve the utilization modes selection of multiple renewable energy in the Jinsha River upper reaches. Finally, the robustness and comparative analysis validate the good adaptability, high efficiency and better practical use values of this method.},
  archive      = {J_IJMLC},
  author       = {You, Xinli and Hou, Fujun},
  doi          = {10.1007/s13042-022-01733-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1845-1861},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel consensus model with probabilistic linguistic preference relation for the utilization mode selection of renewable energy sources},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). KAMTFENet: A fall detection algorithm based on keypoint
attention module and temporal feature extraction. <em>IJMLC</em>,
<em>14</em>(5), 1831–1844. (<a
href="https://doi.org/10.1007/s13042-022-01730-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Falls have become the second leading cause of accidental death of the elderly. The serious consequences of falls in the elders can be reduced effectively if they can be detected early. This paper proposes a fall detection method based on keypoint attention module and temporal feature extraction. Firstly, the object detection model (YOLOv3) and the pose estimation model (Multi-stage Pose Estimation Network) are used to obtain the body keypoints. Then, we design a sliding window to preprocess the keypoints. The sliding window divides the keypoints in 30 consecutive frames into a group so that the subsequent network can extract the dynamic features from the keypoints. After that, an adaptive keypoint attention module is designed to strengthen the fall-related keypoints. We improve the long-short-term memory network, and utilize it on the strengthened features to extract the dynamic temporal features. Finally, the fully connected layers are used to recognize falls and normal poses. Experimental results show that the proposed approach achieves an accuracy of 99.73\% and 99.62\% when tested with UR Fall Detection Dataset and Le2i Fall Detection Dataset.},
  archive      = {J_IJMLC},
  author       = {Li, Jiangjiao and Gao, Mengqi and Li, Bin and Zhou, Dazheng and Zhi, Yumin and Zhang, Youmei},
  doi          = {10.1007/s13042-022-01730-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1831-1844},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {KAMTFENet: A fall detection algorithm based on keypoint attention module and temporal feature extraction},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-view subspace enhanced representation of manifold
regularization and low-rank tensor constraint. <em>IJMLC</em>,
<em>14</em>(5), 1811–1830. (<a
href="https://doi.org/10.1007/s13042-022-01729-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, to extract the manifold information from multi-view data and enhance the clustering performance of a multi-view learning method, the multi-view subspace enhanced representation of manifold regularization and low-rank tensor constraint (MSERMLRT) method is introduced. Our model uses a tensor to explore the correlation between views. The tensor is constrained with a low-rank, and the purpose of such processing is to reduce the redundant information of the learned subspace representation. This model also uses the manifold information from multi-view data and imposes a sparse constraint on the product of itself and the transpose of the subspace representation matrix to enhance the diagonal block structure of the subspace representation, thereby improving its clustering effect to a certain extent. We also designed a helpful method for solving the MSERMLRT model and analyzed the convergence of our approach both theoretically and experimentally. The clustering performance on certain challenging datasets indicate that the MSERMLRT model is superior to many other advanced multi-view clustering methods.},
  archive      = {J_IJMLC},
  author       = {Liu, Guoqing and Ge, Hongwei and Li, Ting and Su, Shuzhi and Wang, Shuangxi},
  doi          = {10.1007/s13042-022-01729-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1811-1830},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-view subspace enhanced representation of manifold regularization and low-rank tensor constraint},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Maximal consistent block based optimal scale selection for
incomplete multi-scale information systems. <em>IJMLC</em>,
<em>14</em>(5), 1797–1809. (<a
href="https://doi.org/10.1007/s13042-022-01728-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerical incomplete data are common in many real-life applications, and they are often hierarchically structured at different levels of granularity. A numerical incomplete multi-scale information system (NIMIS) is a special hierarchical data set in which each object can take on different values at different scales. In such a data set, an important issue is to choose the optimal scale in order to maintain certain conditions for final decision. In this paper, by employing maximal consistent block technique, we study the optimal scale selection with various requirements in NIMISs and numerical incomplete multi-scale decision systems (NIMDSs). We first introduce the concept of scale in NIMISs and NIMDSs. We then define the optimal scale and the maximal consistent block based optimal scale. Finally, we examine the relationship between the maximal consistent block based optimal scale and the optimal scale. We show that the maximal consistent block based optimal scale and the optimal scale are equivalent for both NIMISs and consistent NIMDSs. And in inconsistent NIMDSs, there is no static relationship between notions of the maximal consistent block based lower-approximation optimal scale and the upper-approximation optimal scale.},
  archive      = {J_IJMLC},
  author       = {Sun, Yu and Wu, Wei-Zhi and Wang, Xia},
  doi          = {10.1007/s13042-022-01728-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1797-1809},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Maximal consistent block based optimal scale selection for incomplete multi-scale information systems},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Few-shot learning based on enhanced pseudo-labels and graded
pseudo-labeled data selection. <em>IJMLC</em>, <em>14</em>(5),
1783–1795. (<a
href="https://doi.org/10.1007/s13042-022-01727-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pseudo-labeled data is used to solve the data shortage in few-shot learning, in which the quality of pseudo-labels and pseudo-labeled data selection determine the classification performance. In order to obtain the enhanced pseudo-labels, we used diverse inputs to encourage the label network to learn invariant and robust representations, improving the generalization ability. Simultaneously, the depthwise over-parameterized convolutional layer and group residual connection with shared parameters accelerate the network training and overcome the time-consuming caused by diverse inputs. Then, the graded pseudo-labeled data selection is proposed to determine various quantities of pseudo-labeled data based on the label network’s performance level, which improves the classification accuracy and avoids the high consumption caused by using all the pseudo-labeled data. Finally, we solved the data shortage in food recognition with the proposed method. The experiments show that our method has better classification accuracy and generalization ability in few-shot benchmark datasets and food recognition with few samples.},
  archive      = {J_IJMLC},
  author       = {Wang, Kang and Wang, Xuesong and Cheng, Yuhu},
  doi          = {10.1007/s13042-022-01727-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1783-1795},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Few-shot learning based on enhanced pseudo-labels and graded pseudo-labeled data selection},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interaction-based clustering algorithm for feature
selection: A multivariate filter approach. <em>IJMLC</em>,
<em>14</em>(5), 1769–1782. (<a
href="https://doi.org/10.1007/s13042-022-01726-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In pattern recognition and data mining, feature selection is a preprocessing step during which the dimensions of data are reduced by removing redundant, irrelevant, and noisy features for a machine learning task. Identifying the most informative features in a suitable computational time is one of the most important challenges in the existing feature selection methods. This paper introduces a multivariate filter feature selection method based on feature clustering technique called interaction-based feature clustering (IFC), which is very cost-effective in terms of computational cost while achieving high classification accuracy. In the proposed method, first, the features are ranked based on the symmetric uncertainty criterion, and then, the clustering of the features is performed by calculating their interactive weight as a similarity measure. To evaluate the performance, the results of the IFC algorithm are compared with six well-known multivariate filter methods on sixteen benchmark datasets using three classifiers of SVM, NB and kNN. In addition, for further evaluation, a comparison is made using the Akaike Information Criterion (AIC) and Pareto front curves. Experimental results prove that the IFC algorithm is often more efficient than the comparable methods in terms of classification accuracy and computational time and can be considered as a suitable method in the preprocessing step.},
  archive      = {J_IJMLC},
  author       = {Esfandiari, Ahmad and Khaloozadeh, Hamid and Farivar, Faezeh},
  doi          = {10.1007/s13042-022-01726-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1769-1782},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Interaction-based clustering algorithm for feature selection: A multivariate filter approach},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SCMP-IL: An incremental learning method with super
constraints on model parameters. <em>IJMLC</em>, <em>14</em>(5),
1751–1767. (<a
href="https://doi.org/10.1007/s13042-022-01725-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning technology has played an important role in our life. Since deep learning technology relies on the neural network model, it is still plagued by the catastrophic forgetting problem, which refers to the neural network model will forget what it has learned after learning new knowledge. The neural network model learns knowledge through labeled samples, and its knowledge is stored in its parameters. Therefore, many methods try to solve this problem from the perspective of constraint parameters and stored samples. There are few ways to solve this problem from the perspective of constraining features output of neural network models. This paper proposes an incremental learning method with super constraints on model parameters. This method not only calculates the parameter similarity loss of the old and new models, but also calculates the layer output feature similarity loss of the old and new models, and finally suppresses the change of model parameters from two directions. In addition, we also propose a new strategy for selecting representative samples from dataset and tackling the imbalance between stored samples and new task samples. Finally, we utilize the neural kernel mapping support vector machine theory to increase the interpretability of the model. In order to better meet the actual situation, five sample sets with different categories and amounts were employed in experiments. Experiments show the effectiveness of our method. For example, after learning the last task, our method is at least 1.930\% and 0.562\% higher than other methods on the training set and test set, respectively.},
  archive      = {J_IJMLC},
  author       = {Han, Jidong and Liu, Zhaoying and Li, Yujian and Zhang, Ting},
  doi          = {10.1007/s13042-022-01725-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1751-1767},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {SCMP-IL: An incremental learning method with super constraints on model parameters},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Complete solution for vehicle re-ID in surround-view camera
system. <em>IJMLC</em>, <em>14</em>(5), 1739–1749. (<a
href="https://doi.org/10.1007/s13042-022-01724-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle re-identification (Re-ID) is a critical component of the autonomous driving perception system, and research in this area has accelerated in recent years. However, there is yet no perfect solution to the vehicle re-identification issue associated with the car’s surround-view camera system. Our analysis identifies two significant issues in the aforementioned scenario: (1) It is difficult to identify the same vehicle in many picture frames due to the unique construction of the fisheye camera. (2) The appearance of the same vehicle when seen via the surround vision system’s several cameras is rather different. To overcome these issues, we suggest an integrative vehicle Re-ID solution method. On the one hand, we provide a technique for determining the consistency of the tracking box drift with respect to the target. On the other hand, we combine a Re-ID network based on the attention mechanism with spatial limitations to increase performance in situations involving multiple cameras. Finally, our approach combines state-of-the-art accuracy with real-time performance. We will soon make the source code and annotated fisheye dataset available.},
  archive      = {J_IJMLC},
  author       = {Wu, Zizhang and Xu, Tianhao and Wang, Fan and Wang, Xiaoquan and Song, Jing},
  doi          = {10.1007/s13042-022-01724-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1739-1749},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Complete solution for vehicle re-ID in surround-view camera system},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generative face inpainting hashing for occluded face
retrieval. <em>IJMLC</em>, <em>14</em>(5), 1725–1738. (<a
href="https://doi.org/10.1007/s13042-022-01723-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 has resulted in a significant impact on individual lives, bringing a unique challenge for face retrieval under occlusion. In this paper, an occluded face retrieval method which consists of generator, discriminator, and deep hashing retrieval network is proposed for face retrieval in a large-scale face image dataset under variety of occlusion situations. In the proposed method, occluded face images are firstly reconstructed using a face inpainting model, in which the adversarial loss, reconstruction loss and hash bits loss are combined for training. With the trained model, hash codes of real face images and corresponding reconstructed face images are aimed to be as similar as possible. Then, a deep hashing retrieval network is used to generate compact similarity-preserving hashing codes using reconstructed face images for a better retrieval performance. Experimental results show that the proposed method can successfully generate the reconstructed face images under occlusion. Meanwhile, the proposed deep hashing retrieval network achieves better retrieval performance for occluded face retrieval than existing state-of-the-art deep hashing retrieval methods.},
  archive      = {J_IJMLC},
  author       = {Yang, Yuxiang and Tian, Xing and Ng, Wing W. Y. and Wang, Ran and Gao, Ying and Kwong, Sam},
  doi          = {10.1007/s13042-022-01723-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1725-1738},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Generative face inpainting hashing for occluded face retrieval},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-label sequence generating model via label semantic
attention mechanism. <em>IJMLC</em>, <em>14</em>(5), 1711–1723. (<a
href="https://doi.org/10.1007/s13042-022-01722-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, a new attempt has been made to capture label co-occurrence by applying the sequence-to-sequence (Seq2Seq) model to multi-label text classification (MLTC). However, existing approaches frequently ignore the semantic information contained in the labels themselves. Besides, the Seq2Seq model is susceptible to the negative impact of label sequence order. Furthermore, it has been demonstrated that the traditional attention mechanism underperforms in MLTC. Therefore, we propose a novel Seq2Seq model with a different label semantic attention mechanism (S2S-LSAM), which generates fused information containing label and text information through the interaction of label semantics and text features in the label semantic attention mechanism. With the fused information, our model can select the text features that are most relevant to the labels more effectively. A combination of the cross-entropy loss function and the policy gradient-based loss function is employed to reduce the label sequence order effect. The experiments show that our model outperforms the baseline models.},
  archive      = {J_IJMLC},
  author       = {Zhang, Xiuling and Tan, Xiaofei and Luo, Zhaoci and Zhao, Jun},
  doi          = {10.1007/s13042-022-01722-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1711-1723},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-label sequence generating model via label semantic attention mechanism},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-level regularization-based unsupervised multi-view
feature selection with adaptive graph learning. <em>IJMLC</em>,
<em>14</em>(5), 1695–1709. (<a
href="https://doi.org/10.1007/s13042-022-01721-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised multi-view feature selection has become an important research direction in the field of pattern recognition and machine learning. However, most of existing methods fail to consider the redundancy information within and between views or the noise information in each view. In this paper, we propose a multi-level regularization-based unsupervised multi-view feature selection with adaptive graph learning. Our method adaptively learns a proper similarity matrix in the reduced feature space based on a learned projection matrix. To reduce the redundancy and noise information in the multi-view data, we adopt a multi-level regularization, which explores the structural sparsity, dependency, diversity information of the multi-view data, to constrain the learned projection matrix. Based on the obtained projection matrix, we rank the features and perform multi-view feature selection. We develop an effective iteration optimization algorithm to solve our method. A large number of experiments conducted on six popular multi-view datasets show that our method obtains excellent clustering performance and has superiority in comparison with mainstream methods.},
  archive      = {J_IJMLC},
  author       = {Chen, Tingjian and Zeng, Ying and Yuan, Haoliang and Zhong, Guo and Lai, Loi Lei and Tang, Yuan Yan},
  doi          = {10.1007/s13042-022-01721-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1695-1709},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-level regularization-based unsupervised multi-view feature selection with adaptive graph learning},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GMNet: An action recognition network with global motion
representation. <em>IJMLC</em>, <em>14</em>(5), 1683–1693. (<a
href="https://doi.org/10.1007/s13042-022-01720-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, an astonishing progress has been made in action recognition. However, the traditional spatio-temporal convolution kernels cannot learn sufficient motion information, which is the key step in action recognition. Therefore, a more effective motion representation approach is required to reason the motion cues in videos. In this light, we propose GMNet, an action recognition network with global motion representation to fulfill such task. It includes a short-term motion feature extraction module and a motion feature aggregation module. The former one is capable of capturing local motion features from adjacent frames, while the latter one excels at aggregating the above features to yield global motion representations. GMNet is easily compatible to any mainstream backbones to realize end-to-end training without additional supervision. Extensive experiments have been carried out on popular benchmarks (Something-Something V1 &amp; V2, Diving-48, Jester and Kinetics 400) to testify its effectiveness. It turns out that GMNet surpasses most of the state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Liu, Mingwei and Zhang, Yi},
  doi          = {10.1007/s13042-022-01720-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1683-1693},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {GMNet: An action recognition network with global motion representation},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Contrastive embedding-based feature generation for
generalized zero-shot learning. <em>IJMLC</em>, <em>14</em>(5),
1669–1681. (<a
href="https://doi.org/10.1007/s13042-022-01719-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a novel feature generation framework for zero-shot learning (ZSL) to recognize both fine-grained seen and unseen classes by constructing embedding from synthesized features. The observation is that the original feature space fails to capture the discriminative information for unseen classes. We first introduce a contrastive visual-semantic embedding (CVSE) approach, which integrates contrastive learning with semantic embedding to obtain both visual and semantic discriminative information for feature generation. In case, we propose to enforce contrastive learning on both real seen class samples and synthetic unseen class samples under a contrastive semantic embedding-based feature generation framework. The synthesized unseen class features together with synthesized seen class features are transformed into embedding features and utilized during classification to reduce ambiguities among semantics. We conduct experiments on four publicly available datasets of AWA1, AWA2, CUB, aPaY, showing that our method can outperform the state-of-the-art by a large margin on most of the datasets.},
  archive      = {J_IJMLC},
  author       = {Wang, Han and Zhang, Tingting and Zhang, Xiaoxuan},
  doi          = {10.1007/s13042-022-01719-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1669-1681},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Contrastive embedding-based feature generation for generalized zero-shot learning},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multilevel hybrid accurate handcrafted model for myocardial
infarction classification using ECG signals. <em>IJMLC</em>,
<em>14</em>(5), 1651–1668. (<a
href="https://doi.org/10.1007/s13042-022-01718-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Myocardial infarction (MI) is detected using electrocardiography (ECG) signals. Machine learning (ML) models have been used for automated MI detection on ECG signals. Deep learning models generally yield high classification performance but are computationally intensive. We have developed a novel multilevel hybrid feature extraction-based classification model with low time complexity for MI classification. The study dataset comprising 12-lead ECGs belonging to one healthy and 10 MI classes were downloaded from a public ECG signal databank. The model architecture comprised multilevel hybrid feature extraction, iterative feature selection, classification, and iterative majority voting (IMV). In the hybrid handcrafted feature (HHF) generation phase, both textural and statistical feature extraction functions were used to extract features from ECG beats but only at a low level. A new pooling-based multilevel decomposition model was presented to enable them to create features at a high level. This model used average and maximum pooling to create decomposed signals. Using these pooling functions, an unbalanced tree was obtained. Therefore, this model was named multilevel unbalanced pooling tree transformation (MUPTT). On the feature extraction side, two extractors (functions) were used to generate both statistical and textural features. To generate statistical features, 20 commonly used moments were used. A new, improved symmetric binary pattern function was proposed to generate textural features. Both feature extractors were applied to the original MI signal and the decomposed signals generated by the MUPTT. The most valuable features from among the extracted feature vectors were selected using iterative neighborhood component analysis (INCA). In the classification phase, a one-dimensional nearest neighbor classifier with ten-fold cross-validation was used to obtain lead-wise results. The computed lead-wise results derived from all 12 leads of the same beat were input to the IMV algorithm to generate ten voted results. The most representative was chosen using a greedy technique to calculate the overall classification performance of the model. The HHF-MUPTT-based ECG beat classification model attained excellent performance, with the best lead-wise accuracy of 99.85\% observed in Lead III and 99.94\% classification accuracy using the IMV algorithm. The results confirmed the high MI classification ability of the presented computationally lightweight HHF-MUPTT-based model.},
  archive      = {J_IJMLC},
  author       = {Barua, Prabal Datta and Aydemir, Emrah and Dogan, Sengul and Kobat, Mehmet Ali and Demir, Fahrettin Burak and Baygin, Mehmet and Tuncer, Turker and Oh, Shu Lih and Tan, Ru-San and Acharya, U. Rajendra},
  doi          = {10.1007/s13042-022-01718-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1651-1668},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multilevel hybrid accurate handcrafted model for myocardial infarction classification using ECG signals},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fusing collaborative transformation with temporally aware
target interaction networks for sequential recommendation.
<em>IJMLC</em>, <em>14</em>(5), 1635–1649. (<a
href="https://doi.org/10.1007/s13042-022-01717-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommendation aims to simulate the changes in users’ interests according to their historical behavior data to predict which items they may interact with next. However, most existing sequential recommendation methods (such as attention and recurrent network-based models) utilize only the user’s own behavior sequence for user modeling, ignoring the dynamic transitions between items in the temporal pattern and between users’ complex transition structures arising from multilevel interdependencies. Additionally, traditional methods fuse a sequence representation into a fixed vector, but user interests are diverse, and a single vector does not reflect the diversity of user interests, and a fixed vector representation will limit the representation capability of the model.To address the above problems, this paper proposes a novel sequential recommendation method that fuses collaborative transformations and temporally aware target interaction networks. It can automatically learn the item transformation relationships within and between sequences. We first design a global feature extraction layer. This layer explicitly captures item transitions in different sequences in the form of higher-order connectivity by performing embedding propagation using global graph contexts. The global static representation extracted after collaborative transformation is used as the initial embedding of the sequential pattern, and the user-item interaction information is integrated into the embedded representation to enhance the sequential pattern. Then, different forms of temporal embeddings are fused to capture the dynamic interest changes of users over time. Finally, the candidate target items are used to activate users’ specific interests, and some items in the interaction sequence are enhanced by measuring the correlation between historical items and candidate items, so as to realize diverse user interest modeling and greatly improve the expression ability of the model. Extensive experiments on three real datasets show that our model can effectively improve the recommendation performance compared with existing methods. Code and data are open-sourced at https://github.com/carolmky/FCTT4Rec .},
  archive      = {J_IJMLC},
  author       = {Ma, Kaiyang and Yang, Zhenyu and Wang, Yu and Cui, Laiping and Jiang, Wenfeng},
  doi          = {10.1007/s13042-022-01717-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1635-1649},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fusing collaborative transformation with temporally aware target interaction networks for sequential recommendation},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Near-infrared fusion for deep lightness enhancement.
<em>IJMLC</em>, <em>14</em>(5), 1621–1633. (<a
href="https://doi.org/10.1007/s13042-022-01716-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lightness enhancement is a long-standing research topic in computer vision. Existing deep learning-based approaches usually extract features from the low-light image to model the enlightening process, which may fall short of robustness since low-light features can be unreliable in heavily dark regions. Inspired by the fact that infrared imaging is immune to illumination variation, we propose to exploit an extra infrared image to help brighten the low-light one. Specifically, we design a deep convolutional neural network to jointly extract the infrared and low-light features and produce a normal-light image under the supervision of multi-scale loss functions, including a discriminator loss that enforces the network output image to mimic a real one. Moreover, a contextual attention module is proposed to reconstruct reliable low-light features in heavily dark regions by exploring feature correlation consistency among low-light and infrared features. Extensive experiments on two composited and one real-world datasets demonstrate the superiority of the proposed approach over existing methods qualitatively and quantitatively.},
  archive      = {J_IJMLC},
  author       = {Wang, Linbo and Wang, Tao and Yang, Deyun and Fang, Xianyong and Wan, Shaohua},
  doi          = {10.1007/s13042-022-01716-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1621-1633},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Near-infrared fusion for deep lightness enhancement},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RADCU-net: Residual attention and dual-supervision cascaded
u-net for retinal blood vessel segmentation. <em>IJMLC</em>,
<em>14</em>(5), 1605–1620. (<a
href="https://doi.org/10.1007/s13042-022-01715-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automated segmentation of retinal blood vessels plays an important role in the computer aided diagnosis of retinal diseases. In this study, we propose a novel retinal vessel segmentation method based on residual attention and dual-supervision cascaded U-Net (RADCU-Net). Specifically, a residual attention U-Net (RAU-Net), including a residual unit and an attention mechanism, is constructed to improve the feature representation ability by explicitly modelling the interdependency among the channels of the convolutional features. To boost the accuracy of retinal blood vessel segmentation, a cascaded RAU-Net framework is constructed by concatenating two RAU-Nets with the proposed residual attention modules. Moreover, a dual-supervision training strategy is designed to improve the supervision of the cascaded RAU-Net parameter learning by adding an additional balanced cross-entropy loss function in the middle of the cascaded RAU-Net. The results of extensive experiments on the DRIVE and STARE datasets demonstrate that the proposed method achieves better performance compared to state-of-the-art methods. Our method provides a meaningful attempt to improve blood vessel segmentation and can further facilitate the diagnosis of ophthalmological diseases.},
  archive      = {J_IJMLC},
  author       = {Yang, Yong and Wan, Weiguo and Huang, Shuying and Zhong, Xin and Kong, Xiangkai},
  doi          = {10.1007/s13042-022-01715-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1605-1620},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {RADCU-net: Residual attention and dual-supervision cascaded U-net for retinal blood vessel segmentation},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A local region proposals approach to instance segmentation
for intestinal polyp detection. <em>IJMLC</em>, <em>14</em>(5),
1591–1603. (<a
href="https://doi.org/10.1007/s13042-022-01714-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article designs a cascaded neural network to diagnose colonoscopic images automatically. With the limited number of labeled polyps masked in binary, the proposed detection network uses a hetero-encoder to map a colonoscopic image to an aggregated set of exemplified images as data argumentation to force the successive autoencoder to learn important features acting as a denoising autoencoder. In other words, the autoencoder denoises the transient images generated in the precedent hetero-encoder training process by auto-associating the ground truth and its variants. A hard attention model classifies the segmented image and applies a local region proposal network (RPN) to the generation and aggression of bounding boxes only on the segmented images to allow a more precise detection such that computations on bounding boxes with less information are avoided. The proposed system can outperform current complex state-of-art methods like faster-R-CNN from the experiments on endoscopic images.},
  archive      = {J_IJMLC},
  author       = {Hwang, Maxwell and Qian, Yucheng and Wu, Cai and Jiang, Wei-Cheng and Wang, Da and Wei, Jingsun and Ding, Kefeng and Hwang, Kao-Shing},
  doi          = {10.1007/s13042-022-01714-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1591-1603},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A local region proposals approach to instance segmentation for intestinal polyp detection},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel conformal deformation based sparse subspace
clustering. <em>IJMLC</em>, <em>14</em>(5), 1579–1590. (<a
href="https://doi.org/10.1007/s13042-022-01712-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse Subspace Clustering (SSC) methods based on variant norms have attracted significant attention due to their empirical success. However, SSC methods presume that data points are embedded in a linear space and use the linear structure to find the sparse representation of data. Unfortunately, real-world datasets usually reside on a special manifold where linear geometry reduces the efficiency of clustering methods. This paper extends Sparse Subspace Clustering with $$l_1$$ -norm and Entropy norm to cluster data points that lie in submanifolds of an unknown manifold. The key idea is to provide a novel feature space by conformal mapping the original intrinsic manifolds with unknown structures to n-spheres such that angles and sparse similarities of the original manifold data are preserved. The proposed method finds an appropriate distance instead of the Euclidean distance for the Kernel SSC algorithm and the SSC algorithm with Entropy norm. Finally, we provide the experimental analysis to compare the efficiency of stereographic sparse subspace clustering with $$l_1$$ -norm, Entropy norm, and kernel on several data sets.},
  archive      = {J_IJMLC},
  author       = {Eybpoosh, Kajal and Rezghi, Mansoor and Heydari, Abbas},
  doi          = {10.1007/s13042-022-01712-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1579-1590},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel conformal deformation based sparse subspace clustering},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of remaining useful life of rolling element
bearings based on LSTM and exponential model. <em>IJMLC</em>,
<em>14</em>(4), 1567–1578. (<a
href="https://doi.org/10.1007/s13042-023-01807-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault in rolling element bearings is a very common fault in mechanical systems. It may lead to abnormal operation of equipment, even to serious accidents or significant losses. Periodical monitoring of bearings plays a vital role in reducing unplanned maintenance and improving the reliability of machines. However, the existing methods for determining faults in rolling element bearings introduce too many artificial factors, and the results are often subjective. In order to solve this problem, the present paper proposes a hybrid real-time method for determining the starting time of a fault in a rolling element bearing. Based on the dynamic 3σ interval and voting mechanism, our method can adaptively predict the starting time. Firstly, the long short-term memory (LSTM) neural network is used to predict the trend of the future operation of the bearing. Then, an exponential model is used to estimate its remaining useful life (RUL). The obtained experimental results show that the proposed approach can significantly reduce artificial interference, adaptively divide the state of rolling element bearings, and accurately predict RUL.},
  archive      = {J_IJMLC},
  author       = {Liu, Jingna and Hao, Rujiang and Liu, Qiang and Guo, Wenwu},
  doi          = {10.1007/s13042-023-01807-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1567-1578},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Prediction of remaining useful life of rolling element bearings based on LSTM and exponential model},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Correction: Landmark based guidance for reinforcement
learning agents under partial observability. <em>IJMLC</em>,
<em>14</em>(4), 1565. (<a
href="https://doi.org/10.1007/s13042-022-01763-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJMLC},
  author       = {Demir, Alper and Çilden, Erkin and Polat, Faruk},
  doi          = {10.1007/s13042-022-01763-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1565},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Correction: Landmark based guidance for reinforcement learning agents under partial observability},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Landmark based guidance for reinforcement learning agents
under partial observability. <em>IJMLC</em>, <em>14</em>(4), 1543–1563.
(<a href="https://doi.org/10.1007/s13042-022-01713-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under partial observability, a reinforcement learning agent needs to estimate its true state by solely using its observation semantics. However, this interpretation has a drawback, which is called perceptual aliasing, avoiding the convergence guarantee of the learning algorithm. To overcome this issue, the state estimates are formed by the recent experiences of the agent, which can be formulated as a form of memory. Although the state estimates may still yield ambiguous action mappings due to aliasing, some estimates exist that naturally disambiguate the present situation of the agent in the domain. This paper introduces an algorithm that incorporates a guidance mechanism to accelerate reinforcement learning for partially observable problems with hidden states. The algorithm makes use of the landmarks of the problem, namely the distinctive and reliable experiences in the state estimates context within an ambiguous environment. The proposed algorithm constructs an abstract transition model by utilizing the landmarks observed, calculates their potentials throughout learning -as a mechanism borrowed from reward shaping-, and concurrently applies the potentials to provide guiding rewards for the agent. Additionally, we employ a known multiple instance learning method, diverse density, for automatically discovering landmarks before learning, and combine both algorithms to form a unified framework. The effectiveness of the algorithms is empirically shown via extensive experimentation. The results show that the proposed framework not only accelerates the underlying reinforcement learning methods, but also finds better policies for representative benchmark problems.},
  archive      = {J_IJMLC},
  author       = {Demir, Alper and Çilden, Erkin and Polat, Faruk},
  doi          = {10.1007/s13042-022-01713-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1543-1563},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Landmark based guidance for reinforcement learning agents under partial observability},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Density peaks clustering algorithm based on improved
similarity and allocation strategy. <em>IJMLC</em>, <em>14</em>(4),
1527–1542. (<a
href="https://doi.org/10.1007/s13042-022-01711-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density peaks clustering (DPC) algorithm provides an efficient method to quickly find cluster centers with decision graph. In recent years, due to its unique parameter, no iteration, and good robustness, DPC has been widely studied and applied. However, it also has some shortcomings, such as unable to effectively identify cluster centers and the chain reaction caused by non-central points error allocation. Aiming at these two shortcomings of DPC, an improved density peaks clustering based on variance (DPCV) is proposed. First, the algorithm uses the variance between points to improve similarity and reduce the density difference of unevenly distributed data sets. Then, according to the similar density relationship between a cluster center and surrounding points, the low-density points are used as the dividing boundary of the initial allocation process. In order to optimize the time consumption of calculating the variance, this paper replaces the variance with the Manhattan distance between points and proposes density peaks clustering based on Manhattan distance (MDDPC). Theoretical analysis and experiments on artificial data and UCI data sets show that, compared with DPC and its improved algorithms, DPCV and MDDPC further improve the clustering accuracy of the DPC algorithm while controlling the running time.},
  archive      = {J_IJMLC},
  author       = {Ding, Shifei and Du, Wei and Li, Chao and Xu, Xiao and Wang, Lijuan and Ding, Ling},
  doi          = {10.1007/s13042-022-01711-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1527-1542},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Density peaks clustering algorithm based on improved similarity and allocation strategy},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Leveraging deep learning for automatic literature screening
in intelligent bibliometrics. <em>IJMLC</em>, <em>14</em>(4), 1483–1525.
(<a href="https://doi.org/10.1007/s13042-022-01710-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent bibliometrics, by providing sufficient statistical information based on large-scale literature data analytics, is promising for understanding innovative pathways, addressing meaningful insights with the assistance of expert knowledge, and indicating key areas of scientific inquiry. However, the exponential growth of global scientific publication output in most areas of modern science makes it extremely difficult and labor-intensive to analyze literature in large volumes. This study aims to accelerate intelligent bibliometrics-driven literature analysis by leveraging deep learning for automatic literature screening. The comparison of different machine learning algorithms for the automatic classification of literature regarding relevance to a given research topic reveals the outstanding performance of deep learning. This study also compares different features as model input and provides suggestions about training dataset size. By leveraging deep learning’s abilities in predictive and big data analytics, this study makes contributions to intelligent bibliometrics by promoting literature screening and is promising to track technological changes and scientific evolutionary pathways.},
  archive      = {J_IJMLC},
  author       = {Chen, Xieling and Xie, Haoran and Li, Zongxi and Zhang, Dian and Cheng, Gary and Wang, Fu Lee and Dai, Hong-Ning and Li, Qing},
  doi          = {10.1007/s13042-022-01710-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1483-1525},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Leveraging deep learning for automatic literature screening in intelligent bibliometrics},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust nonparallel support vector machine with privileged
information for pattern recognition. <em>IJMLC</em>, <em>14</em>(4),
1465–1482. (<a
href="https://doi.org/10.1007/s13042-022-01709-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of pattern recognition, collected data always include some additional information which are usually termed as privileged information. The privileged information is latent information belonging to the training samples, which can be easily ignored. The privileged information can help to build a better classifier for classification. In this paper, we try to construct a robust nonparallel support vector machine (NPSVM) model under the privileged information learning (LUPI) setting, termed as R-NPSVM+. On the one hand, we introduce the privileged information into NPSVM so as to build a model for classification. In the training process, both the privileged information and “usual” samples are used to train the model, which can enhance the accuracy. On the other hand, due to the ε-insensitive loss and hinge loss, NPSVM is sensitive to noise or outliers. Hence, we use two robust loss functions in R-NPSVM+ model, which can further ensure the robustness of the model. In addition, we use the Lagrange multiplier method and the dual coordinate descent (DCD) algorithm to optimize the proposed objective function, respectively. Lastly, to evaluate the performance of R-NPSVM+, we conduct a series of experiments. Experimental results confirm that compared with other classical SVM-type algorithms, our R-NPSVM+ can produce a better performance, especially when the samples are corrupted by noise and outliers.},
  archive      = {J_IJMLC},
  author       = {Liu, Liming and Li, Ping and Chu, Maoxiang and Liu, Shuming},
  doi          = {10.1007/s13042-022-01709-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1465-1482},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Robust nonparallel support vector machine with privileged information for pattern recognition},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-supervised attribute reduction via attribute
indiscernibility. <em>IJMLC</em>, <em>14</em>(4), 1445–1464. (<a
href="https://doi.org/10.1007/s13042-022-01708-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction based on rough sets plays an important role in data preprocessing. Discernibility pair, as an effective information measurement, has received extensive attention in attribute reduction. Unfortunately, the existing attribute importance measurement strategies based on discernibility pairs do not apply well to partially labeled data. Meanwhile, most of the existing attribute reduction algorithms focus on the relationships between objects and neglect the relationships between attributes, which may bring highly redundant attributes. Under the background of rough set theory, this paper studies the issue of semi-supervised attribute reduction, i.e. attribute reduction for partially labeled data. Firstly, we introduce the concept of discernibility pair based on object indiscernibility and propose a semi-supervised attribute reduction algorithm via the maximum discernibility pair by combining supervised and unsupervised discernibility pair strategies. Secondly, considering the relationships between attributes, we put forward new methods to define the similarity and distinction between attributes by discernibility pairs. Thirdly, we propose a semi-supervised attribute reduction algorithm by indiscernible attribute classes. Finally, comparative experiments indicate that the proposed algorithms are effective.},
  archive      = {J_IJMLC},
  author       = {Dai, Jianhua and Wang, Weisi and Zhang, Chucai and Qu, Shaojun},
  doi          = {10.1007/s13042-022-01708-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1445-1464},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Semi-supervised attribute reduction via attribute indiscernibility},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). KGA: Integrating KPCA and GAN for microbial data
augmentation. <em>IJMLC</em>, <em>14</em>(4), 1427–1444. (<a
href="https://doi.org/10.1007/s13042-022-01707-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The data used for microbial-based disease diagnosis are characterized by small sample sizes, imbalanced categories, high dimensionality, and strong sparsity. They pose challenges to machine learning algorithms that aim to achieve good classification performance. In this paper, we propose a two-stage data augmentation method to enhance training data quality. The first stage is feature transformation. We design a KPCA-based method to map microbial data to a low-rank feature space, resulting in cleaner and more efficient data representation. This processing step addresses high dimensionality and strong sparsity in microbial data. The second stage is data augmentation. New synthetic data are obtained by augmenting the positive samples through the GAN. The misclassification cost is used to control the ratio of positive/negative samples in new data. The combination of the augmented data with the original data constitutes a cost-sensitive dataset, which can increase sample diversity while addressing the imbalance problem. This is more reasonable than traditional sampling methods that resolve the class imbalance. We compare the new method with four popular data augmentation algorithms on 12 imbalanced datasets. The experimental results demonstrate that (1) the samples augmented by the proposed algorithm are more diverse than those generated using compared resampling methods, such as SMOTE_ENN, and (2) the proposed algorithm not only achieves the lowest total misclassification cost but also outperforms other methods in terms of $$F_2$$ and G-mean metrics.},
  archive      = {J_IJMLC},
  author       = {Wen, Liu-Ying and Zhang, Xiao-Min and Li, Qing-Feng and Min, Fan},
  doi          = {10.1007/s13042-022-01707-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1427-1444},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {KGA: Integrating KPCA and GAN for microbial data augmentation},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic feature selection combining standard deviation and
interaction information. <em>IJMLC</em>, <em>14</em>(4), 1407–1426. (<a
href="https://doi.org/10.1007/s13042-022-01706-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection achieves dimensionality reduction by selecting some effective features from the original feature set. However, in the process of feature selection, most conventional methods do not accurately describe various correlations between features and the dynamic changes of the relation, leading to an incomplete definition of the evaluation function and affecting the classification accuracy. In this study, a dynamic feature selection method combining standard deviation and interaction information (DFS-SDII) is proposed. In DFS-SDII, conditional mutual information is introduced to measure the changes in the importance of the selected features for classification. Then, the interaction information is used to measure the synergy between the candidate and selected features. In addition, candidate features with higher importance to the class are selected by standard deviation under the condition of the same score. To evaluate the performance of DFS-SDII, nine state-of-the-art feature selection methods are selected for comparison on 16 benchmark data sets based on the classification accuracy and F-measure. The experimental results show that the proposed method performs better in terms of feature selection and has a higher classification accuracy.},
  archive      = {J_IJMLC},
  author       = {Wu, Peng and Zhang, Qinghua and Wang, Guoyin and Yang, Fan and Xue, Fuzhong},
  doi          = {10.1007/s13042-022-01706-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1407-1426},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dynamic feature selection combining standard deviation and interaction information},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cyclic sequential process of pairwise comparisons with
application to multi-criteria decision making. <em>IJMLC</em>,
<em>14</em>(4), 1391–1405. (<a
href="https://doi.org/10.1007/s13042-022-01705-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The technique of paired comparisons is commonly used for finding an optimal solution to multi-criteria decision-making (MCDM) problems. The process of comparing alternatives is worth investigations due to the limitation and complexity of human cognition. In this paper, we propose a cyclic sequential process of pairwise comparisons to produce a real-valued preference relation without reciprocal property. The non-reciprocal property characterizes the uncertainty experienced by the decision maker (DM). The concepts of consistency and approximate consistency are defined by considering the inherent property of the derived uncertain preference relation. An optimization model is given to elicit the priority vector from uncertain preference relations. A novel yet effective possibility degree formula is established to rank interval numbers. A new decision making model is constructed and illustrated by carrying out numerical examples. As compared to the existing works, a novel process of pairwise comparisons is proposed to generate an uncertain preference relation and cope with the uncertainty in a decision making problem. The proposed model can be used to reduce the workload of providing pairwise comparisons for the DM and reach an acceptable decision.},
  archive      = {J_IJMLC},
  author       = {Liu, Fang and Hu, Yuan-Kai and Wang, Shi-Shan},
  doi          = {10.1007/s13042-022-01705-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1391-1405},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Cyclic sequential process of pairwise comparisons with application to multi-criteria decision making},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Relative entropy-regularized optimal transport on a graph: A
new algorithm and an experimental comparison. <em>IJMLC</em>,
<em>14</em>(4), 1365–1390. (<a
href="https://doi.org/10.1007/s13042-022-01704-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present work investigates a new relative entropy-regularized algorithm for solving the optimal transport on a graph problem within the randomized shortest paths formalism. More precisely, a unit flow is injected into a set of input nodes and collected from a set of output nodes with specified marginals, while minimizing the expected transportation cost, together with a paths-based relative entropy regularization term, providing a randomized routing policy. The main advantage of this new formulation is the fact that it can easily accommodate edge flow capacity constraints which commonly occur in real-world problems. The resulting optimal routing policy, i.e., the probability distribution of following an edge in each node, is Markovian and is computed after constraining the input and output flows to the prescribed marginal probabilities. In addition, experimental comparisons with other recently developed techniques show that the distance measure between nodes derived from the introduced model provides competitive results on semi-supervised classification tasks.},
  archive      = {J_IJMLC},
  author       = {Courtain, Sylvain and Guex, Guillaume and Kivimäki, Ilkka and Saerens, Marco},
  doi          = {10.1007/s13042-022-01704-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1365-1390},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Relative entropy-regularized optimal transport on a graph: A new algorithm and an experimental comparison},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Binary african vultures optimization algorithm for various
optimization problems. <em>IJMLC</em>, <em>14</em>(4), 1333–1364. (<a
href="https://doi.org/10.1007/s13042-022-01703-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one novel meta-heuristic algorithm, African Vultures Optimization Algorithm (AVOA) has been proved to be efficient in solving continuous optimization problems. However, many real-world optimization problems are in the discrete form, and the continuous characteristics of AVOA make it unsuitable for solving discrete optimization problems. Therefore, this article proposes Binary African Vultures Optimization Algorithm (BAVOA) to solve various optimization problems, especially discrete optimization problems. In BAVOA, the X-shaped transfer function is firstly adopted to convert the continuous search space into the binary search space, and then the opposition-based learning strategy and the improved multi-elite strategy are utilized to enhance the optimization ability of BAVOA. Moreover, the performance of BAVOA is evaluated by twenty-three benchmark functions with the relevant Wilcoxon rank sum tests, and the effectiveness of BAVOA is demonstrated by four engineering design problems and one combinational optimization problem. The results demonstrate that BAVOA outperforms eight well-known algorithms in addressing various optimization problems. Source codes of BAVOA are publicly available at: https://www.mathworks.com/matlabcentral/fileexchange/115350-binary-african-vultures-optimization-algorithm},
  archive      = {J_IJMLC},
  author       = {Xi, Mingyang and Song, Qixian and Xu, Min and Zhou, Zhaorong},
  doi          = {10.1007/s13042-022-01703-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1333-1364},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Binary african vultures optimization algorithm for various optimization problems},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neighbor-enhanced graph transition network for session-based
recommendation. <em>IJMLC</em>, <em>14</em>(4), 1317–1331. (<a
href="https://doi.org/10.1007/s13042-022-01702-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The session-based recommendation predicts the next user’s interest item based on an anonymous user–item interaction sequence. However, most existing methods focus on capturing sequential signals or item-transition patterns within the current session while ignoring potential collaborative behaviors among different users from other sessions that could positively affect the recommended performance of the current session. To address these issues, we propose a Neighbor-Enhanced Graph Transition Network , which uses a diverse graph neural network to model complex interactions at the item level between the current session and its neighboring sessions. We create a Current Feature Encoder to investigate the user’s current preference and a Neighbor Feature Encoder to generate useful collaborative information by considering the popularity of item-transition pairs from neighbor sessions. Then, we propose a fusion function that combines the two types of features mentioned above. We use a positional attention mechanism to investigate the impact of items in different positions on the user’s true intention. The experimental results over three real-world datasets demonstrate that our proposed model generally outperforms other state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Yi, Zijing and Song, Rui and Li, Jian and Xu, Hao},
  doi          = {10.1007/s13042-022-01702-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1317-1331},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Neighbor-enhanced graph transition network for session-based recommendation},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep data representation with feature propagation for
semi-supervised learning. <em>IJMLC</em>, <em>14</em>(4), 1303–1316. (<a
href="https://doi.org/10.1007/s13042-022-01701-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based embedding has attracted much attention in the fields of machine learning and pattern recognition. It is becoming an indispensable tool for data representation. It can be useful for all types of learning: unsupervised, semi-supervised, and supervised. In this correspondence, we present a graph-based, deep and flexible method for data representation with feature propagation. The presented framework ensures several desired features such as graph-based regularization, a flexible embedding model, graph-based feature propagation, and a deep learning architecture. The model can be learned layer by layer. In each layer, the nonlinear data representation and the unknown convolved data based regression are jointly estimated with a closed-form solution. We evaluate the proposed system on semi-supervised classification tasks using six public image datasets. These experiments demonstrate the effectiveness of the presented framework, which compares favorably to many competing semi-supervised approaches.},
  archive      = {J_IJMLC},
  author       = {Dornaika, F. and Hoang, V. Truong},
  doi          = {10.1007/s13042-022-01701-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1303-1316},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Deep data representation with feature propagation for semi-supervised learning},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Structure parameter estimation method for microwave device
using dimension reduction network. <em>IJMLC</em>, <em>14</em>(4),
1285–1301. (<a
href="https://doi.org/10.1007/s13042-022-01698-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian process (GP) is a multi-layer perceptron neural network (NN) with infinite units in its hidden layer that could learn effectively, so as a machine learning (ML) method, it has been a sought-after surrogate model in electromagnetics (EM) field. GP can implement complex covariance functions or insert itself into a more complicated probability structure to improve predictive function. When handling the high-dimensional data, however, GP still causes some problems, e.g., precise and efficiency degradation. Hence, we propose a dimension reduction network structure based on GP to strengthen its ability of feature extraction and apply the approach into the inverse surrogate models of microwave devices. In this model, the compressed representation process of input features is dependent on a multi-layer extreme learning machine (ML-ELM), which stacks multiple ELMs-based autoencoders (AEs) by nonorthogonal random parameters including weights and biases of hidden layers. The novelties of this paper are as follows: (1) enormous unlabeled data satisfied with designed requirements are generated randomly, and they are then used to train the parameters of ML-ELM except the last layer to improve its performance, instead of random determination of its weights and biases; (2) parameters of the last layer of the ML-ELM and hyperparameters of GP are fine-tuned by particle swarm optimization (PSO) algorithm based on some labeled data; and (3) we also study on the ML-ELM architecture deeply and draw some rewarding conclusions based on different experimental results of some typical testing functions. Empirical study on the triple-band microwave antenna demonstrates that compared with GP, predictive accuracy of the proposed method is high, considering about compressing for dimensionality of the same data.},
  archive      = {J_IJMLC},
  author       = {Han, Shudan and Tian, Yubo},
  doi          = {10.1007/s13042-022-01698-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1285-1301},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Structure parameter estimation method for microwave device using dimension reduction network},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Probabilistic multiplicative unbalanced linguistic term set
and its application in matrix games. <em>IJMLC</em>, <em>14</em>(4),
1253–1283. (<a
href="https://doi.org/10.1007/s13042-022-01697-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic linguistic term sets (PLTSs) are suitable for enunciating evaluators’ complex linguistic perceptions more accurately within the intricate qualitative setting. Usually, the PLTS is based on a balanced concept and does not serve as a good information representation for an unbalanced qualitative concept. Therefore, to reflect experts’ distinct preferences and uncertainties, this paper proposes a new PLTS called the probabilistic multiplicative unbalanced linguistic term set (PM-ULTS), where both probabilities and non-uniform spacing of the linguistic labels are considered simultaneously. Afterwards, we put forward specific operational laws for the newly constructed PLTS to preserve the resultant linguistic labels and corresponding probability information. Some elementary aggregation operators beneficial in aggregating probabilistic linguistic information in decision-making problems are also constructed, and their excellent properties are addressed. Furthermore, based on the proposed concept, this study initiates the design of a unified two-person linguistic matrix game model with the new PLTS as a parameter. It addresses the imprecise information by the information measure function. Such a two-player probabilistic unbalanced linguistic matrix game is considered a convenient technique for multiple decision scenarios. Additionally, the proposed game model involves a re-translation process to convert the output back into the original probabilistic unbalanced linguistic domain without information loss, thereby escalating the interpretability of the game model compared with other existing uncertain matrix game methodologies. Finally, we discuss the significance of the proposed methodology and concept to question its validity and usefulness by presenting suitable examples.},
  archive      = {J_IJMLC},
  author       = {Malhotra, Tanya and Gupta, Anjana},
  doi          = {10.1007/s13042-022-01697-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1253-1283},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Probabilistic multiplicative unbalanced linguistic term set and its application in matrix games},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient microaneurysms detection approach in retinal
fundus images. <em>IJMLC</em>, <em>14</em>(4), 1235–1252. (<a
href="https://doi.org/10.1007/s13042-022-01696-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy (DR) is one of the retinal disorders and the leading cause of blindness worldwide. Microaneurysms (MA) is the first clinical indication of DR, and the detection of MA helps in early diagnosis. The retinal fundus image analysis helps screen DR through MA detection. In general, the MA detection method consists of preprocessing, enhancement, and classification stages. Preprocessing is crucial to improve the retinal features and reduce the imaging artifacts. Reducing these artifacts is one of the challenging research problems in retinal fundus image analysis. In this paper, a novel improved Non-Local Mean filter (INLMF) is proposed to remove the imaging artifacts. The proposed method is tested on publicly available databases and images collected from Hospital. The proposed method has achieved the best performance metric than the state-of-the-art. The computational time per image is 6.2 sec which is less than other methods.},
  archive      = {J_IJMLC},
  author       = {Mohan, N. Jagan and Murugan, R. and Goel, Tripti and Tanveer, M. and Roy, Parthapratim},
  doi          = {10.1007/s13042-022-01696-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1235-1252},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An efficient microaneurysms detection approach in retinal fundus images},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An incremental approach to feature selection using the
weighted dominance-based neighborhood rough sets. <em>IJMLC</em>,
<em>14</em>(4), 1217–1233. (<a
href="https://doi.org/10.1007/s13042-022-01695-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dominance-based neighborhood rough set (DNRS) is capable to give qualitative and quantitative descriptions of the relations between ordered objects. In spite of its effectiveness in feature selection, DNRS ignores the various significance of features. In fact, different features exert different impacts on decision-making. Once we explore these differences in advance, it is easier to find out features with high correlation and dependency. Likewise, it is inevitable that in big-data era the objects may update from time to time, which calls for efficient attribute reduction. However, the existing approaches are inappropriate for the weighted and ordered data. Motivated by these two deficiencies, first, we assign different weights to conditional attributes and establish the weighted dominance-based neighborhood rough set (WDNRS). Then a kind of conditional entropy in matrix form and ensuing updating principles are put forward to evaluate the significance of the attributes. In addition, grounded on the entropy, we come up with the heuristic algorithm and corresponding incremental mechanism when objects increase. Finally, twelve experiments are carried out to verify that it is effective and efficient for the designed method to select features in dynamic datasets.},
  archive      = {J_IJMLC},
  author       = {Pan, Yanzhou and Xu, Weihua and Ran, Qinwen},
  doi          = {10.1007/s13042-022-01695-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1217-1233},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An incremental approach to feature selection using the weighted dominance-based neighborhood rough sets},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-scale network toward real-world image denoising.
<em>IJMLC</em>, <em>14</em>(4), 1205–1216. (<a
href="https://doi.org/10.1007/s13042-022-01694-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images are inevitably degraded when captured due to the effects of noise, and thus denoising is required. Previous methods remove real-world noise, while also causing issues with over-smoothing image details and loss of edge information. To solve these issues, a multi-scale image denoising network (MSIDNet) is proposed in this paper. We design a residual attention block (RAB) to encode and decode the context well, while introducing a selective kernel feature fusion module to fuse multi-scale features and obtain rich contextual information from low-resolutions to restore more details. A feature extraction block (FEB) is designed to fully extract local and global features then fusion, which obtains rich feature information. Extensive experiments on four real-world image datasets demonstrate that our method has excellent generalization and achieves advanced denoising performance on both peak signal-to-noise ratio and structural similarity. MSIDNet preserves more edge details and improves the over-smoothing issue to enhance the visual effect of denoised images.},
  archive      = {J_IJMLC},
  author       = {Zhou, Lianmin and Zhou, Dongming and Yang, Hao and Yang, Shaoliang},
  doi          = {10.1007/s13042-022-01694-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1205-1216},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-scale network toward real-world image denoising},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new belief entropy measure in the weighted combination
rule under DST with faulty diagnosis and real-life medical application.
<em>IJMLC</em>, <em>14</em>(4), 1179–1203. (<a
href="https://doi.org/10.1007/s13042-022-01693-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Dempster-Shafer’s theory (also called DST or evidence theory or theory of belief function), conflict management is a well-known issue in information fusion. The paper presents a weighted evidence combination method consisting of a new approach to measuring information volume of mass function based on a proposed belief entropy and distance of evidence. The combination rule comprises four key points: firstly, the initial weight is obtained with the help of distance of evidence; secondly, information volume of mass function based on a new belief entropy is measured; thirdly final weight is obtained based on initial weight and information volume of mass function based on new belief entropy and lastly, final fusion is made with the help of Dempster combination rule. Also, it is shown here that the previously proposed approaches produce counterintuitive outcomes when the identical mass value is assigned to two different bodies of evidence (BOE). However, the approach proposed here can handle all such conflicting situations and significantly reduce the uncertainty of decisions. The efficacy of the proposed approach is shown with the help of a numerical experiment where the degree of belief is elevated to 0.9860 when five pieces of evidence conflict, a faulty diagnosis application where belief degree is elevated to 0.889 in comparison with existing works, and an application of real-world in the field of medical diagnosis where the belief degree raised to 0.9841 and the uncertainty of decision is lowered nearly to zero.},
  archive      = {J_IJMLC},
  author       = {Dutta, Palash and Shome, Sonom},
  doi          = {10.1007/s13042-022-01693-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1179-1203},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A new belief entropy measure in the weighted combination rule under DST with faulty diagnosis and real-life medical application},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning label-specific features via neural network for
multi-label classification. <em>IJMLC</em>, <em>14</em>(4), 1161–1177.
(<a href="https://doi.org/10.1007/s13042-022-01692-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-label learning, learning specific features for each label is an effective strategy, and most of the existing multi-label classification methods based on label-specific features commonly use the original feature space to learn specific features for each label directly. Due to the problem of dimensionality disaster in the feature space, it may not be the optimal strategy to directly generate the specific feature of the label in the original feature space. Therefore, this paper proposes a multi-label learning framework that joins neural networks and label-specific features. First, the neural network projects the original feature space to a low-dimensional mapping space to learn potential low-dimensional feature space representations, and this nonlinear feature mapping can mine the potential feature information inside the complex feature space. Then, in the low-dimensional mapping space, specific features of the labels are learned using empirical minimization loss. Finally, a unified multi-label classification model is constructed by considering label correlation and instance similarity issues. Extensive experiments are conducted on 12 different multi-label data sets and demonstrate the better generalizability of our proposed approaches.},
  archive      = {J_IJMLC},
  author       = {Jia, Ling and Sun, Dong and Shi, Yu and Tan, Yi and Gao, Qingwei and Lu, Yixiang},
  doi          = {10.1007/s13042-022-01692-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1161-1177},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Learning label-specific features via neural network for multi-label classification},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Concept reduction in formal concept analysis based on
representative concept matrix. <em>IJMLC</em>, <em>14</em>(4),
1147–1160. (<a
href="https://doi.org/10.1007/s13042-022-01691-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reduction theory is an important topic in formal concept analysis, and the research of reduction theory generally focuses on attribute reduction. Attribute reduction deletes redundant attributes and simplifies formal context. Nevertheless, it may lose part of original information of formal context. As a new direction of knowledge reduction, concept reduction avoids the defects of information loss caused by attribute reduction and enriches reduction theory. Concept reduction not only preserves the binary relation of a formal context, but also reduces the number of formal concepts. Furthermore, the information of formal context can be expressed simply and completely, and the complexity of solving problems with formal concept analysis can be reduced. In this paper, the definition of representative concept matrix is given to visualize the connection between concepts and binary relation. Then, the method for calculating concept reducts by representative concept matrix is obtained, and two simplified representative concept matrices named the clarified representative concept matrix and the minimal representative concept matrix are proposed. In addition, an algorithm for obtaining the minimal representative concept matrix is presented and compared with the previous algorithm. Finally, from the perspective of concept consistent set and minimal representative concept matrix respectively, the characteristics of three types of concepts, i.e., core concepts, relatively necessary concepts and absolutely unnecessary concepts, are discussed.},
  archive      = {J_IJMLC},
  author       = {Zhao, Siyu and Qi, Jianjun and Li, Junan and Wei, Ling},
  doi          = {10.1007/s13042-022-01691-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1147-1160},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Concept reduction in formal concept analysis based on representative concept matrix},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multiple criteria ensemble pruning method for binary
classification based on d-s theory of evidence. <em>IJMLC</em>,
<em>14</em>(4), 1133–1146. (<a
href="https://doi.org/10.1007/s13042-022-01690-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble pruning becomes an important stage in multiple classifier systems, and it has been widely applied to solve binary classification problems. Diversity and performance measures are two widely used evaluation methods to build the selection criterion for ensemble pruning. However, few works consider both of them simultaneously, and they usually use one algorithm to measure the diversity or performance, which may not be enough to capture all the relevant diversities and performance of the base classifiers. To solve this problem, we propose a multiple criteria ensemble pruning method by employing multiple diversity and performance measures to capture the base classifiers’ diversity and evaluate their classification ability respectively. Moreover, a multi-criteria decision making method, based on fuzzy soft set and Dempster-Shafer theory of evidence, is used to build the final selection criterion, which can make a good trade-off between the diversity and performance measures. With sixteen binary data sets, the experimental studies show its effectivity and superiority for ensemble pruning over six state-of-the-art benchmark methods.},
  archive      = {J_IJMLC},
  author       = {Qiu, Jing and Xiao, Zhi and Zhong, Bo},
  doi          = {10.1007/s13042-022-01690-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1133-1146},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A multiple criteria ensemble pruning method for binary classification based on D-S theory of evidence},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-modality deep forest for hand motion recognition via
fusing sEMG and acceleration signals. <em>IJMLC</em>, <em>14</em>(4),
1119–1131. (<a
href="https://doi.org/10.1007/s13042-022-01687-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bio-signal based hand motion recognition plays a critical role in the tasks of human-machine interaction, such as the natural control of multifunctional prostheses. Although a large number of classification technologies have been taken to improve the motion recognition accuracy, it is still a challenge to achieve acceptable performance for multiple modality input. This study proposes a multi-modality deep forest (MMDF) framework to identify hand motions, in which surface electromyographic signals (sEMG) and acceleration signals (ACC) are fused at the input level. The proposed MMDF framework constitutes of three main stages, sEMG and ACC feature extraction, feature dimension reduction, and a cascade structure deep forest for classification. A public database “Ninapro DB7” is used to evaluate the performance of the proposed framework, and the experimental results show that it can achieve a significantly higher accuracy than that of competitors. Besides, our experimental results also show that MMDF outperforms other traditional classifiers with the input of the single modality of sEMG signals. In sum, this study verifies that ACC signals can be an excellent supplementary for sEMG, and MMDF is a plausible solution to fuse mulit-modality bio-signals for human motion recognition.},
  archive      = {J_IJMLC},
  author       = {Fang, Yinfeng and Lu, Huiqiao and Liu, Han},
  doi          = {10.1007/s13042-022-01687-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1119-1131},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-modality deep forest for hand motion recognition via fusing sEMG and acceleration signals},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fine-grained image recognition via trusted multi-granularity
information fusion. <em>IJMLC</em>, <em>14</em>(4), 1105–1117. (<a
href="https://doi.org/10.1007/s13042-022-01685-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained image recognition (FGIR) is more challenging than general image recognition tasks due to the inherently subtle object variation. The existing FGIR methods are mainly based on single-granularity feature fusion, the extracted fused features often cannot fully reflect the characteristics of the object, and the recognition results based on the fused feature also lack interpretability. To solve this problem, we propose a novel end-to-end trusted multi-granularity information fusion (TMGIF) model for weakly-supervised fine-grained image recognition. It can automatically extract multi-granularity information representation for a fine-grained image, further evaluate the quality of information granules, and then progressively fuse multi-granularity information according to the quality to obtain a reliable and interpretable recognition result. We evaluate TMGIF on three standard benchmark datasets, and demonstrate the proposed method can provide competitive results.},
  archive      = {J_IJMLC},
  author       = {Yu, Ying and Tang, Hong and Qian, Jin and Zhu, Zhiliang and Cai, Zhen and Lv, Jingqin},
  doi          = {10.1007/s13042-022-01685-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1105-1117},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fine-grained image recognition via trusted multi-granularity information fusion},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimized trajectory planning for the time efficient
navigation of mobile robot in constrained environment. <em>IJMLC</em>,
<em>14</em>(4), 1079–1103. (<a
href="https://doi.org/10.1007/s13042-022-01684-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous navigation is a significant segment of mobile robotics, and for reliable autonomous navigation, optimal trajectory planning is the fundamental requirement. In mobile robotics, planning algorithms are implemented to attain optimality in trajectory planning by solving the problems such as path length minimization, smoother trajectories, low computational load, time/ space complexity, etc., that degrade the performance of the path planning technique. This research paper primarily focuses on generating smooth trajectories with the shortest path length by linking the Bidirectional Rapidly exploring Random Tree (B-RRT) with a modified Bezier curve technique termed Smooth-BRRT (S-BRRT). The proposed S-BRRT technique generates smoother trajectories by considering the high number of control points associated with the Bezier curve technique. The selection criteria for control points will be adaptive, which means the number of control points may increase or decrease depending upon the path length, grid cell size, mobile robot dimension, maximum acceleration of mobile robot, etc. The proposed S-BRRT technique is implemented in various simulated environments, and it is experimentally obtained that the path length is reduced by 15.03\%, the number of sharp turns is reduced by 100\%, and time lag is reduced by 27.01\%. The proposed S-BRRT technique is also trialed and tested in various real-world experiments. The result shows a 100\% reduction in the collision, the time lag is reduced by 66.23\%, and the velocity error is reduced to 57.52\%, concerning the results obtained with renowned conventional approaches.},
  archive      = {J_IJMLC},
  author       = {Singh, Ravinder},
  doi          = {10.1007/s13042-022-01684-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1079-1103},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Optimized trajectory planning for the time efficient navigation of mobile robot in constrained environment},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Balance-driven automatic clustering for probability density
functions using metaheuristic optimization. <em>IJMLC</em>,
<em>14</em>(4), 1063–1078. (<a
href="https://doi.org/10.1007/s13042-022-01683-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For solving the clustering for probability density functions (CDF) problem with a given number of clusters, the metaheuristic optimization (MO) algorithms have been widely studied because of their advantages in searching for the global optimum. However, the existing approaches cannot be directly extended to the automatic CDF problem for determining the number of clusters k. Besides, balance-driven clustering, an essential research direction recently developed in the problem of discrete-element clustering, has not been considered in the field of CDF. This paper pioneers a technique to apply an MO algorithm for resolving the balance-driven automatic CDF. The proposed method not only can automatically determine the number of clusters but also can approximate the global optimal solution in which both the clustering compactness and the clusters’ size similarity are considered. The experiments on one-dimensional and multidimensional probability density functions demonstrate that the new method possesses higher quality clustering solutions than the other conventional techniques. The proposed method is also applied in analyzing the difficulty levels of entrance exam questions.},
  archive      = {J_IJMLC},
  author       = {Nguyen-Trang, Thao and Nguyen-Thoi, Trung and Nguyen-Thi, Kim-Ngan and Vo-Van, Tai},
  doi          = {10.1007/s13042-022-01683-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1063-1078},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Balance-driven automatic clustering for probability density functions using metaheuristic optimization},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recurrent graph encoder for syntax-aware neural machine
translation. <em>IJMLC</em>, <em>14</em>(4), 1053–1062. (<a
href="https://doi.org/10.1007/s13042-022-01682-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-attention networks (SAN) have achieved promising performance in a variety of NLP tasks, e.g. neural machine translation (NMT), as they can directly build dependencies among words. But it is weaker at learning positional information than recurrent neural networks (RNN). Natural questions arise: (1) Can we design a component with RNN by directly guiding the syntax dependencies for it? (2) Whether such syntax enhanced sequence modeling component benefits existing NMT structures, e.g. RNN-based NMT and Transformer-based NMT. To answer above question, we propose a simple yet effective recurrent graph syntax encoder, dubbed RGSE, to utilize off-the-shelf syntax dependencies and its intrinsic recurrence property, such that RGSE models syntactic dependencies and sequential information (i.e. word order) simultaneously. Experimental studies on various neural machine translation tasks demonstrate that RGSE equipped RNN and Transformer models could gain consistent significant improvements over several strong syntax-aware benchmarks, with minuscule parameters increases. The extensive analysis further illustrates that RGSE does improve the syntactic and semantic preservation ability than SAN, additionally, shows superior robustness to defend syntactic noise than existing syntax-aware NMT models.},
  archive      = {J_IJMLC},
  author       = {Ding, Liang and Wang, Longyue and Liu, Siyou},
  doi          = {10.1007/s13042-022-01682-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1053-1062},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Recurrent graph encoder for syntax-aware neural machine translation},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spectral–spatial discriminative broad graph convolution
networks for hyperspectral image classification. <em>IJMLC</em>,
<em>14</em>(3), 1037–1051. (<a
href="https://doi.org/10.1007/s13042-022-01680-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCN) can provide excellent performance in hyperspectral image classification due to their ability to capture feature representations. However, the loss function of GCN model only uses labeled data for model training, and does not consider the relationship between inter-class spacing and intra-class spacing of sample features. It is difficult to ensure effective separation between samples and sufficient aggregation within samples, which limits the classification performance of GCN. To address these issues, we proposed a discriminative broad graph convolution network for hyperspectral image classification (DBGCN). Firstly, we use multiple edge preserving filters to extract spatial spectral features, and then use PCA to fuse the spatial spectral joint features obtained by edge preserving filters. Secondly, graph convolution was used to obtain the deep-level features of the hyperspectral image in the non-Euclidean domain. Finally, the intra-class divergence and inter-class divergence matrix were calculated according to the obtained features, and the weights of the fully connected layer were then trained such that DBGCN exhibited stronger discriminative ability and achieved better classification results. The experimental results show that the proposed model was superior to the state-of-the-art results.},
  archive      = {J_IJMLC},
  author       = {Wang, Zhe and Li, Jing and Zhang, Taotao and Yuan, Shengzhi},
  doi          = {10.1007/s13042-022-01680-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {1037-1051},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Spectral–spatial discriminative broad graph convolution networks for hyperspectral image classification},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sparse multi-label feature selection via dynamic graph
manifold regularization. <em>IJMLC</em>, <em>14</em>(3), 1021–1036. (<a
href="https://doi.org/10.1007/s13042-022-01679-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label feature selection is a hot topic in multi-label high-dimensional data processing. However, some multi-label feature selection models use manifold graphs. Due to its fixed graph matrix, the model performance is poor, and learning a better fundamental graph matrix is also an urgent problem. Therefore, a sparse multi-label feature selection method is proposed via dynamic graph manifold learning (DMMFS). In this method, the sample space is mapped to the pseudo-label space with a real-label base manifold structure through linear mapping. Then, the Frobenius norm constructed the dynamic graph matrix, and the mutual constraint between the weight matrix and dynamic graph matrix is realized by feature manifold. Finally, experimental comparisons are made on eight multi-label reference data sets with seven of the latest methods. The experimental results prove the superiority of DMMFS.},
  archive      = {J_IJMLC},
  author       = {Zhang, Yao and Ma, Yingcang},
  doi          = {10.1007/s13042-022-01679-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {1021-1036},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Sparse multi-label feature selection via dynamic graph manifold regularization},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Across-task neural architecture search via meta learning.
<em>IJMLC</em>, <em>14</em>(3), 1003–1019. (<a
href="https://doi.org/10.1007/s13042-022-01678-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adequate labeled data and expensive compute resources are the prerequisites for the success of neural architecture search (NAS). It is challenging to apply NAS in meta-learning scenarios with limited compute resources and data. In this paper, an across-task neural architecture search (AT-NAS) method is proposed to address this problem via combining gradient-based meta-learning with EA-based NAS to learn over the distribution of tasks. The supernet is learned over an entire set of tasks by meta learning. Architecture encodes of subnets sampled from the supernet are iteratively adapted by evolutionary algorithms while simultaneously searching for a task-sensitive meta-network. The searched meta-network can adapt to a novel task via a few learning steps and it only costs a little search time. Empirical results show that AT-NAS achieves excellent performance in few-shot classification. The performance of AT-NAS on classification benchmarks is comparable to that of models searched from scratch, by adapting the architecture in less than an hour from a 5-GPU-day pretrained meta-network.},
  archive      = {J_IJMLC},
  author       = {Rong, Jingtao and Yu, Xinyi and Zhang, Mingyang and Ou, Linlin},
  doi          = {10.1007/s13042-022-01678-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {1003-1019},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Across-task neural architecture search via meta learning},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid sampling-based contrastive learning for imbalanced
node classification. <em>IJMLC</em>, <em>14</em>(3), 989–1001. (<a
href="https://doi.org/10.1007/s13042-022-01677-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced node classification is a vital task because it widely exists in many real-world applications, such as financial fraud detection, anti-money laundering, drug reaction prediction and so on. However, many recent methods are for balanced graph-structured datasets, and do not perform well on imbalanced data. Therefore, we propose a hybrid sampling-based contrastive learning method (HSCL) for imbalanced node classification to alleviate this problem. The core of our method is to adopt the hybrid sampling method in contrastive learning, that is, undersampling majority classes and oversampling minority classes, to achieve a balance of samples from different classes in contrastive learning and thus obtain a discriminative representation. HSCL has been evaluated extensively on five real-world data sets. Experimental results show that the proposed method obtains better performance than other state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Cui, Caixia and Wang, Jie and Wei, Wei and Liang, Jiye},
  doi          = {10.1007/s13042-022-01677-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {989-1001},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Hybrid sampling-based contrastive learning for imbalanced node classification},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CovidViT: A novel neural network with self-attention
mechanism to detect covid-19 through x-ray images. <em>IJMLC</em>,
<em>14</em>(3), 973–987. (<a
href="https://doi.org/10.1007/s13042-022-01676-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the emergence of the novel coronavirus in December 2019, it has rapidly swept across the globe, with a huge impact on daily life, public health and the economy around the world. There is an urgent necessary for a rapid and economical detection method for the Covid-19. In this study, we used the transformers-based deep learning method to analyze the chest X-rays of normal, Covid-19 and viral pneumonia patients. Covid-Vision-Transformers (CovidViT) is proposed to detect Covid-19 cases through X-ray images. CovidViT is based on transformers block with the self-attention mechanism. In order to demonstrate its superiority, this research is also compared with other popular deep learning models, and the experimental result shows CovidViT outperforms other deep learning models and achieves 98.0\% accuracy on test set, which means that the proposed model is excellent in Covid-19 detection. Besides, an online system for quick Covid-19 diagnosis is built on http://yanghang.site/covid19 .},
  archive      = {J_IJMLC},
  author       = {Yang, Hang and Wang, Liyang and Xu, Yitian and Liu, Xuhua},
  doi          = {10.1007/s13042-022-01676-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {973-987},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {CovidViT: A novel neural network with self-attention mechanism to detect covid-19 through X-ray images},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiview deep learning-based attack to break text-CAPTCHAs.
<em>IJMLC</em>, <em>14</em>(3), 959–972. (<a
href="https://doi.org/10.1007/s13042-022-01675-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Completely Automated Public Turing Test To Tell Computer and Humans Apart (CAPTCHA) is a computer program that prevents malicious computer users. Text-CAPTCHA schemes utilize less-computational costs. Hence, they are the most popularly used. This paper investigates the effectiveness of state-of-the-art (SOTA) text-CAPTCHA schemes, proposes a Multiview deep learning system to break them, and highlights their weaknesses. Rather than the usual single-view feature extraction, the proposed model explores correlational features from multiple views to increase the model’s generalization and classification accuracy. The model combines convolutional neural networks and recurrent networks to preserve the input text-CAPTCHA’s spatial and sequential order. The proposed system has successfully achieved average accuracies ranging from 93.6\% to 100\%, and the average time to break a text-CAPTCHA scheme ranges from 0.0032 to 0.21 seconds on eight different datasets. Furthermore, an ablation study on 71 human users was conducted to evaluate the effectiveness of the schemes. The results demonstrated that the proposed system effectively outperforms the human users whom the schemes were designed to serve. Lastly, when compared with existing systems, the proposed system outperforms existing SOTA systems with an accuracy gap of almost 40\% higher.},
  archive      = {J_IJMLC},
  author       = {Yusuf, Mukhtar Opeyemi and Srivastava, Divya and Singh, Deepak and Rathor, Vijaypal Singh},
  doi          = {10.1007/s13042-022-01675-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {959-972},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multiview deep learning-based attack to break text-CAPTCHAs},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A stochastic variance-reduced coordinate descent algorithm
for learning sparse bayesian network from discrete high-dimensional
data. <em>IJMLC</em>, <em>14</em>(3), 947–958. (<a
href="https://doi.org/10.1007/s13042-022-01674-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of learning a sparse structure Bayesian network from high-dimensional discrete data. Compared to continuous Bayesian networks, learning a discrete Bayesian network is a challenging problem due to the large parameter space. Although many approaches have been developed for learning continuous Bayesian networks, few approaches have been proposed for the discrete ones. In this paper, we address learning Bayesian networks as an optimization problem and propose a score function which guarantees the learnt structure to be a sparse directed acyclic graph. Besides, we implement a block-wised stochastic coordinate descent algorithm to optimize the score function. Specifically, we use a variance reducing method in our optimization algorithm to make the algorithm work efficiently for high-dimensional data. The proposed approach is applied to synthetic data from well-known benchmark networks. The quality, scalability, and robustness of the constructed network are measured. Compared to some competitive approaches, the results reveal that our algorithm outperforms some of the well-known proposed methods.},
  archive      = {J_IJMLC},
  author       = {Shajoonnezhad, Nazanin and Nikanjam, Amin},
  doi          = {10.1007/s13042-022-01674-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {947-958},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A stochastic variance-reduced coordinate descent algorithm for learning sparse bayesian network from discrete high-dimensional data},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A working likelihood approach to support vector regression
with a data-driven insensitivity parameter. <em>IJMLC</em>,
<em>14</em>(3), 929–945. (<a
href="https://doi.org/10.1007/s13042-022-01672-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The insensitivity parameter in support vector regression determines the set of support vectors that greatly impacts the prediction. A data-driven approach is proposed to determine an approximate value for this insensitivity parameter by minimizing a generalized loss function originating from the likelihood principle. This data-driven support vector regression also statistically standardizes samples using the scale of noises different from conventional response scaling method. Statistical standardization together with probabilistic regularization based on a working likelihood function produces data-dependent values for the hyperparameters including the insensitivity parameter. The exact asymptotical solutions are provided when the noises are normally distributed. Nonlinear and linear numerical simulations with three types of noises ( $$\epsilon$$ -Laplacian distribution, normal distribution, and uniform distribution), and in addition, five real benchmark data sets, are used to test the capacity of the proposed method. Based on all the simulations and the five case studies, the proposed support vector regression using a working likelihood, data-driven insensitivity parameter is superior and has lower computational costs.},
  archive      = {J_IJMLC},
  author       = {Wu, Jinran and Wang, You-Gan},
  doi          = {10.1007/s13042-022-01672-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {929-945},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A working likelihood approach to support vector regression with a data-driven insensitivity parameter},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attention matching network for few-shot learning in the
syndrome differentiation of cerebral stroke. <em>IJMLC</em>,
<em>14</em>(3), 911–927. (<a
href="https://doi.org/10.1007/s13042-022-01671-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Treatment based on Syndrome Differentiation is one of the most important characteristics of Traditional Chinese medicine (TCM). In recent years, Artificial Intelligence (AI) and Deep Learning has played a great role in promoting the TCM computer aided diagnosis technology. However, the performance of previous intelligent TCM AI models is limited due to their dependence on clinical medical records. In view of the above problems, this paper improves the framework of traditional few-shot learning framework and proposes a Hybrid Dual-Attentive Matching Network for syndrome differentiation of TCM six meridians, which can explore the law of syndrome differentiation from a small number of medical records and TCM literature resources. To be specific, the model involves two stages: pre-training stage and mate-learning stage. In the first stage, the network trains a classifier on pre-training dataset to get an encoder with some priori knowledge. In the second stage, there are three modules: fusion embedding module for the learning of meta information, hybrid dual-attention module for the getting of key characters and correlation between features and matching module for classification. When testing on our data set with 1134 traditional Chinese medical record of Cerebral Stroke patients, the result of accuracy could be the average precision of 82.39\%. The paper is the first attempt of few-shot learning in the syndrome differentiation of six meridians tasks, demonstrating the feasibility of this method in TCM prediction. Besides, the dual-attention mechanism enhances the representation of samples by assigning amplifying the importance weights to each feature, which facilitates the classification performances.},
  archive      = {J_IJMLC},
  author       = {Zhao, Zijuan and Song, Kai and Ren, Xueting and Qiang, Yan and Zhao, Juanjuan and Hou, Jiaxin and Zhu, Junyi and Xiao, Ning and Zhang, Junlong},
  doi          = {10.1007/s13042-022-01671-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {911-927},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Attention matching network for few-shot learning in the syndrome differentiation of cerebral stroke},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel metaheuristic optimisation approach for text
sentiment analysis. <em>IJMLC</em>, <em>14</em>(3), 889–909. (<a
href="https://doi.org/10.1007/s13042-022-01670-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated sentiment analysis is considered an area in natural language processing research that seeks to understand a text author&#39;s mood, thoughts, and feelings. New opportunities and challenges have arisen in this field due to the popularity and accessibility of a variety of resources of ideas, such as online review websites, personal blogs, and social media. Feature selection, which can be conducted using metaheuristic algorithms, is one of the steps of sentiment analysis. It is crucial to use high-performing algorithms for feature selection. This paper applies the Horse herd Optimisation Algorithm (HOA) for feature selection in text sentiment analysis. HOA is a metaheuristic algorithm and uses six key behaviours to simulate the social performance of horses of various ages, to solve high-dimensional optimisation problems. In order to improve HOA, this paper adds another behaviour of horses to the basic algorithm; thus, the new algorithm uses seven key behaviours of horses of different ages to imitate their social performance. It is then discretised and converted to a multi-objective algorithm. The improved algorithm&#39;s performance is evaluated using 15 CEC benchmark functions, and the results are compared to the Binary Social Spider Algorithm, the Binary Grey Wolf Optimizer, and the Binary Butterfly Optimization Algorithm. The new algorithm, the Multi-objective Binary Horse herd Optimisation Algorithm (MBHOA), excels at solving high-dimensional complex problems. To evaluate the algorithm&#39;s performance in feature selection, as a practical example, it is employed in text sentiment analysis and examined on various data sets. The simulation results indicate that MBHOA has a better performance in analysing sentiment compared to similar approaches.},
  archive      = {J_IJMLC},
  author       = {Hosseinalipour, Ali and Ghanbarzadeh, Reza},
  doi          = {10.1007/s13042-022-01670-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {889-909},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel metaheuristic optimisation approach for text sentiment analysis},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Research on the assessment of project-driven immersion
teaching in extreme programming with neutrosophic linguistic
information. <em>IJMLC</em>, <em>14</em>(3), 873–888. (<a
href="https://doi.org/10.1007/s13042-022-01669-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The assessment of project-driven immersion teaching in extreme programming is quite vital for reducing the workload of pre-implementation documents, enabling students to see the project implementation results as soon as possible, which can greatly improve students’ learning initiative and better understand the course system of software engineering. When assessing the teaching effectiveness of project-driven immersion teaching in extreme programming, the primary issue involves great uncertainty. Neutrosophic linguistic set, portrayed by three membership degrees to linguistic variable, is an effective tool to seize uncertainty. In this paper, the objective weight is calculated by CRITIC (Criteria Importance Through Inter-criteria Correlation) method while the integrated weight is determined by synchronously reflecting subjective information and objective information. Then, neutrosophic linguistic MCDM (Multi-Criteria Decision Making) algorithm based CoCoSo (Combined Compromise Solution) is presented for solving counterintuitive phenomenon. Lastly, the effectiveness of the developed method is verified by the effect of project-driven immersion teaching in extreme programming assessment.},
  archive      = {J_IJMLC},
  author       = {Peng, Xindong and Dai, Jingguo and Smarandache, Florentin},
  doi          = {10.1007/s13042-022-01669-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {873-888},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Research on the assessment of project-driven immersion teaching in extreme programming with neutrosophic linguistic information},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accurate neural network classification model for
schizophrenia disease based on electroencephalogram data.
<em>IJMLC</em>, <em>14</em>(3), 861–872. (<a
href="https://doi.org/10.1007/s13042-022-01668-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalogram is a useful interface system that translates the human electrical brain activity into voltage signals. By these means, the recorded brain waves can be employed to characterize, classify, or diagnose mental disorders. A novel neural network model to classify patients with schizophrenia based on electroencephalograms is presented. The proposed model decomposes the multichannel electroencephalogram records into a group of multivariate novel radial basis functions using a fuzzy means algorithm. The decomposition permits to extract different electroencephalogram channel information and distinguish between two sort of classes i.e., schizophrenic patients and healthy controls. Results show improved accuracy compared to classical algorithms reported in the literature i.e., Support Vector Machine, Bayesian Linear Discriminant Analysis, Decision Tree, Gaussian Naive Bayes, Random Forest, K-Nearest Neighbour, Convolutional Neuronal Network, or Adaboost. As a result, the method presented in this paper achieves the highest balanced accuracy, recall, precision and F1 score values, close to 93\% in all cases. The model presented in this paper may be integrated in real time tools involved during the diagnostic of schizophrenia.},
  archive      = {J_IJMLC},
  author       = {Luján, Miguel Ángel and Sotos, Jorge Mateo and Santos, José L. and Borja, Alejandro L.},
  doi          = {10.1007/s13042-022-01668-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {861-872},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Accurate neural network classification model for schizophrenia disease based on electroencephalogram data},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel message passing neural network based on neighborhood
expansion. <em>IJMLC</em>, <em>14</em>(3), 849–860. (<a
href="https://doi.org/10.1007/s13042-022-01667-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most message passing neural networks (MPNNs) are widely used for assortative network representation learning under the assumption of homophily between connected nodes. However, this fundamental assumption is inconsistent with the heterophily of disassortative networks (DNs) in many real-world applications. Therefore, we propose a novel MPNN called NEDA based on neighborhood expansion for disassortative network representation learning (DNRL). Specifically, our NEDA first performs neighborhood expansion to seek more informative nodes for aggregation and then performs data augmentation to speed up the optimization process of a set of parameter matrices at the maximum available training data with minimal computational cost. To evaluate the performance of NEDA comprehensively, we perform several experiments on benchmark disassortative network datasets with variable sizes, where the results demonstrate the effectiveness of our NEDA model. The code is publicly available at https://github.com/xueyanfeng/NEDA .},
  archive      = {J_IJMLC},
  author       = {Xue, Yanfeng and Jin, Zhen and Apasiba, Abeo Timothy},
  doi          = {10.1007/s13042-022-01667-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {849-860},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel message passing neural network based on neighborhood expansion},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Composite adaptive fuzzy backstepping control of uncertain
fractional-order nonlinear systems with quantized input. <em>IJMLC</em>,
<em>14</em>(3), 833–847. (<a
href="https://doi.org/10.1007/s13042-022-01666-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the adaptive fuzzy backstepping control of strict-feedback fractional-order nonlinear systems subject to quantized input with known and unknown quantization parameters. A command filter is designed to finish off the “explosion of complexity” issue caused by differentiating virtual control inputs repeatedly in each backstepping step, and a compensated signal is implemented to reduce the negative impact of filtered errors. In addition, the prediction error calculated by a fractional-order serial-parallel model is combined into the fuzzy adaptation law so that functional uncertainties can be accurately approximated by fuzzy logic systems. Importantly, the control input is forced to pass through a hyperbolic tangent function, and a parameter identifier is developed to identify unknown quantization parameters, which can achieve the purpose of compensating quantization errors. The final quantized input signal can ensure that tracking errors converge to a small region, and all the signals involved keep semi-globally uniformly bounded based on the fractional Lyapunov stability criterion. Finally, the availability of the used method is testified through two simulation experiments.},
  archive      = {J_IJMLC},
  author       = {Qiu, Hongling and Liu, Heng and Zhang, Xiulan},
  doi          = {10.1007/s13042-022-01666-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {833-847},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Composite adaptive fuzzy backstepping control of uncertain fractional-order nonlinear systems with quantized input},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiple heterogeneous network representation learning based
on multi-granularity fusion. <em>IJMLC</em>, <em>14</em>(3), 817–832.
(<a href="https://doi.org/10.1007/s13042-022-01665-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous network representation learning shows its superior capacity in complex network analysis. It aims to embed nodes into a low-dimensional space and pursues a meaningful vector representation for each node. At present, the research of heterogeneous networks mainly focuses on the fusion of network structure information, semantic information, and attribute information. However, how to effectively extract neighboring structure information and accurately extract semantic information are still open problems. Furthermore, few people consider the difference between the importance of low-order structural information and high-order semantic information. In this paper, a multiple heterogeneous network representation learning framework based on multi-granularity information fusion called MHRL is proposed to solve these problems. MHRL considers the structural and semantic information of the heterogeneous network as different information grains, and uses different encoders to obtain structural and semantic embeddings. Then, MHRL uses a biased contrastive fusion method to effectively fuse structural embeddings and semantic embeddings. Extensive experiments on three real-world datasets show that the proposed method is significantly better than the state-of-the-art baselines in classification, clustering and visualization.},
  archive      = {J_IJMLC},
  author       = {Liu, Manyi and Wang, Guoyin and Hu, Jun and Chen, Ke},
  doi          = {10.1007/s13042-022-01665-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {817-832},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multiple heterogeneous network representation learning based on multi-granularity fusion},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature selection based on a hybrid simplified particle
swarm optimization algorithm with maximum separation and minimum
redundancy. <em>IJMLC</em>, <em>14</em>(3), 789–816. (<a
href="https://doi.org/10.1007/s13042-022-01663-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is an important technique of data processing in the field of machine learning and data mining. Its goal is to select the feature subset with the maximum classification accuracy and the minimum number. Using the particle swarm algorithm to find the optimal sunset in the high-dimensional data set is faced with the problems of falling into the local optimum and expensive calculation, resulting in a decrease in classification accuracy. Focused on these, this paper proposes a hybrid simplified PSO-based feature selection algorithm with the elite strategy (HECSPSO). It has the following improvements: (1) In the stage of population initialization, according to the separation performance of features, the conditional separation probability ( $$S_{-}\mathrm{{probability}}$$ ) of features is redefined, on the basis of which a new population initialization strategy is proposed. (2) In order to further improve the convergence speed of the algorithm, this paper proposes the addition and deletion criterion of maximum separation-minimum redundancy according to the separation and redundancy of features, which is called elite strategy. (3) In order to simplify the complexity of the model, a simplified particle swarm optimization algorithm is proposed. The evolution process is controlled only by the position, which simplifies the iterative process of particle swarm and avoids the problems of slow convergence and low precision caused by particle velocity. (4) In order to avoid the algorithm falling into local optimum, the chaotic mechanism is used as the local search operator near the known solutions. In order to make a comprehensive evaluation, the proposed method is compared with other algorithms based on particle swarm optimization. On the 16 data sets of UCI (University of California Irvine Machine Learning Repository), these methods are compared and evaluated in three aspects: the classification accuracy, the selected feature subset size, and the number of iterations for the algorithm convergence. The results show that the proposed algorithm can achieve a feature subset with better performance, and is a highly competitive algorithm for feature selection.},
  archive      = {J_IJMLC},
  author       = {Sun, Liqin and Yang, Youlong and Liu, Yuanyuan and Ning, Tong},
  doi          = {10.1007/s13042-022-01663-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {789-816},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Feature selection based on a hybrid simplified particle swarm optimization algorithm with maximum separation and minimum redundancy},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Perturbation-based oversampling technique for imbalanced
classification problems. <em>IJMLC</em>, <em>14</em>(3), 773–787. (<a
href="https://doi.org/10.1007/s13042-022-01662-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a simple yet effective idea, perturbation-based oversampling (POS), to tackle imbalanced classification problems. In this method, we perturb each feature of a given minority instance to generate a new instance. The originality and advantage of the POS is that a hyperparameter p is introduced to control the variance of the perturbation, which provides flexibility to adapt the algorithm to data with different characteristics. Experimental results yielded by using five types of classifiers and 11 performance metrics on 103 imbalanced datasets show that the POS offers comparable or better results than those yielded by 11 reference methods in terms of multiple performance metrics. An important finding of this work is that a simple perturbation-based oversampling method is able to yield better classification results than many advanced oversampling methods by controlling the variance of input perturbation. This reminds us it may need to conduct comparisons with simple oversampling methods, e.g., POS, when designing new oversampling approaches.},
  archive      = {J_IJMLC},
  author       = {Zhang, Jianjun and Wang, Ting and Ng, Wing W. Y. and Pedrycz, Witold},
  doi          = {10.1007/s13042-022-01662-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {773-787},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Perturbation-based oversampling technique for imbalanced classification problems},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning exclusive discriminative semantic information for
zero-shot learning. <em>IJMLC</em>, <em>14</em>(3), 761–772. (<a
href="https://doi.org/10.1007/s13042-022-01661-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot learning (ZSL) aims to recognize unseen classes relying on the knowledge transferred from seen categories. This study presents new methods to solve two main challenges in ZSL. First, as human-annotated semantics are not discriminative enough to identify unseen classes, we propose constructing a novel latent semantic space based on the semantic attributes and designing a class-wise classifier with class-specific information maximize the discrimination of the latent semantics. Besides, to alleviate the common space’s semantic overlapping problem, we first propose constructing exclusive latent class prototypes by exclusive lasso (EL). Second, since previous ZSL methods learn visual-semantic projection between visual features and corresponding single class-level semantics directly, i.e., one-vs-all projection, which neglects the interference caused by background and noises in the image, we leverage the simple quadratic regression to soften this hard constraint. The proposed new model also alleviates the inherent domain shift problem by adopting the dual semantic auto-encoder to connect visual space, semantic space, and latent space, respectively. Comprehensive experiments on five benchmark datasets demonstrate the effectiveness of the proposed model.},
  archive      = {J_IJMLC},
  author       = {Mi, Jian-Xun and Zhang, Zhonghao and Tai, Debao and Zhou, Li-Fang and Jia, Wei},
  doi          = {10.1007/s13042-022-01661-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {761-772},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Learning exclusive discriminative semantic information for zero-shot learning},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). CNN-LDNF: An image feature representation approach with
multi-space mapping. <em>IJMLC</em>, <em>14</em>(3), 739–759. (<a
href="https://doi.org/10.1007/s13042-022-01660-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolution neural network (CNN) has achieved remarkable success in feature representation. However, the feature representation ability of CNN is susceptible to high intersections among classes in the datasets. The features extracted by CNN models from these datasets tend to be no-Gaussian distribution in each category and non-homogeneous distributions of different types. To address this issue, we proposed a feature representation approach based on convolutional operations and distribution transformation called CNN-LDNF. The proposed approach implements convolutional and pooling operations to catch features in original spaces. More specially, a linear discriminative normalizing flow (LDNF) model is designed to build a bijective transformation for balancing the intervals among classes, which maps the feature from the original feature space to Gaussian space. Moreover, a maximum likelihood function is explored to train LDNF. Ultimately, the proposed CNN-LDNF produces the following accuracies: 97.35\% on marine organism dataset, 99.37\% on Oxford-IIIT pet dataset, and 94.56\% on vehicle identification dataset. Extensive experiments indicate that our proposed approach achieves significant feature representation for visual recognition tasks.},
  archive      = {J_IJMLC},
  author       = {Li, Jie and Wang, Yifan and Luo, Chongju and Zhou, Weixi and Dong, Zhicheng},
  doi          = {10.1007/s13042-022-01660-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {739-759},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {CNN-LDNF: An image feature representation approach with multi-space mapping},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). UUGAN: A GAN-based approach towards underwater image
enhancement using non-pairwise supervision. <em>IJMLC</em>,
<em>14</em>(3), 725–738. (<a
href="https://doi.org/10.1007/s13042-022-01659-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater image enhancement has become an emerging research field in recent years. Among various research studies, methods based on deep learning have gained a foothold and gradually expanded their influences. Most of these methods need pairs of training images, but due to the complexity of the underwater environment, it is challenging for us to obtain such expected datasets. Considering this problem, this paper explores an underwater image enhancement approach based on the unsupervised training mode. Concretely, a generative adversarial network (GAN) without pairwise image training is proposed, called UUGAN. It aims to bring the visual effects of expert images to the raw images. Our model has three parts, broadly speaking. Firstly, a GAN network based on an encoder-decoder is constructed; and secondly, a bridge connection scheme with intermediate layer feature transition is proposed. Thirdly, a loss function with multi-input constraints is applied. To demonstrate the effectiveness of UUGAN, we evaluate it on several real-world and synthetic datasets and compare it with some excellent methods. In the qualitative and quantitative comparison experiments, our methods have achieved remarkable results.},
  archive      = {J_IJMLC},
  author       = {Xu, Huipu and Long, Xiangyang and Wang, Min},
  doi          = {10.1007/s13042-022-01659-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {725-738},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {UUGAN: A GAN-based approach towards underwater image enhancement using non-pairwise supervision},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of multi-label classification based on supervised
and semi-supervised learning. <em>IJMLC</em>, <em>14</em>(3), 697–724.
(<a href="https://doi.org/10.1007/s13042-022-01658-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label classification algorithms based on supervised learning use all the labeled data to train classifiers. However, in real life, many of the data are unlabeled, and it is costly to label all the data needed. Multi-label classification algorithms based on semi-supervised learning can use both labeled and unlabeled data to train classifiers, resulting in better-performing models. In this paper, we first review supervised learning classification algorithms in terms of label non-correlation and label correlation and semi-supervised learning classification algorithms in terms of inductive methods and transductive methods. After that, multi-label classification algorithms are introduced from the application areas of image, text, music and video. Subsequently, evaluation metrics and datasets are briefly introduced. Finally, research directions in complex concept drift, label complex correlation, feature selection and class imbalance are presented.},
  archive      = {J_IJMLC},
  author       = {Han, Meng and Wu, Hongxin and Chen, Zhiqiang and Li, Muhang and Zhang, Xilong},
  doi          = {10.1007/s13042-022-01658-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {697-724},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A survey of multi-label classification based on supervised and semi-supervised learning},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). VESC: A new variational autoencoder based model for anomaly
detection. <em>IJMLC</em>, <em>14</em>(3), 683–696. (<a
href="https://doi.org/10.1007/s13042-022-01657-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is a hot and practical problem. Most of the existing research is based on the model of the generative model, which judges abnormalities by comparing the data errors between original samples and reconstruction samples. Among them, Variational AutoEncoder (VAE) is widely used, but it has the problem of over-generalization. In this paper, we design an unsupervised deep learning anomaly detection method named VESC and propose the recursive reconstruction strategy. VESC adopts the idea of data compression and three structures on the basis of the original VAE, namely spatial constrained network, reformer structure, and re-encoder. The recursive reconstruction strategy can improve the accuracy of the model by increasing the number and typicality of training samples, and it can apply to most unsupervised learning methods. Experimental results of several benchmarks show that our model outperforms state-of-the-art anomaly detection methods. And our proposed strategy can improve the detection results of the original model.},
  archive      = {J_IJMLC},
  author       = {Zhang, Chunkai and Wang, Xinyu and Zhang, Jiahua and Li, Shaocong and Zhang, Hanyu and Liu, Chuanyi and Han, Peiyi},
  doi          = {10.1007/s13042-022-01657-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {683-696},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {VESC: A new variational autoencoder based model for anomaly detection},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved harris hawks optimizer combined with extremal
optimization. <em>IJMLC</em>, <em>14</em>(3), 655–682. (<a
href="https://doi.org/10.1007/s13042-022-01656-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Harris Hawks optimizer (HHO) is a new swarm intelligence optimization algorithm proposed in recent years. It seeks the optimal solution by simulating the predation strategy of Harris hawks and many previous experiments show that HHO has a good effect on solving optimization problems. However, HHO also has the shortcomings of low convergence accuracy and easy to fall into local optimum. In order to improve the performance of HHO, an improved HHO hybridized with extremal optimization (IHHO-EO) is proposed. Aiming at the defect of insufficient information utilization and excessive randomization in the exploration phase of the algorithm, the own historical optimal position of Harris hawks is introduced to better guide the individuals to search for better positions and improve the global search ability. Secondly, a nonlinear prey energy escaping factor is proposed to better balance the exploration and exploitation phases. Thirdly, refracted opposition-based learning (ROBL) with a dynamic parameter is proposed and combined with HHO, which can improve the quality of solutions and convergence speed. Finally, the exploitation ability is improved by performing EO operation which has strong local search ability. The proposed algorithm is applied to 23 classical benchmark test functions and 29 CEC2017 test functions. IHHO-EO is compared with HHO, other newly proposed optimization algorithms and some improved variants of HHO. The experimental results verify the effectiveness of the added strategies. In addition, the proposed approach is applied to solving the pressure vessel design problem. The results show that IHHO-EO has an excellent performance in terms of accuracy, reliability and statistical tests.},
  archive      = {J_IJMLC},
  author       = {Zhang, Hai-Lin and Chen, Min-Rong and Li, Pei-Shan and Huang, Jun-Jie},
  doi          = {10.1007/s13042-022-01656-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {655-682},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An improved harris hawks optimizer combined with extremal optimization},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Image retrieval using dual-weighted deep feature descriptor.
<em>IJMLC</em>, <em>14</em>(3), 643–653. (<a
href="https://doi.org/10.1007/s13042-022-01654-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying deep convolutional features to image retrieval has become the mainstream method in the field of image retrieval. However, the discriminative power of deep convolutional features needs to be further improved. So far, low-level features have not been used to enhance representation. Furthermore, the compatibility of low-level features and deep features remains challenging. To address these problems, we propose an aggregation method that combines low-level features and deep features for image retrieval. The highlights are: (1) We propose a novel similarity weight to complement the advantages of the intrinsic information in each feature type, thereby improving the discriminative power of deep convolutional features. (2) We introduce a feature loss weight to calculate the diversity between texture features and deep features, which effectively utilizes the complementary advantages of each feature type. (3) We propose a novel representation for image retrieval, named the dual-weighted deep feature descriptor. It not only strengthens the discriminative power of the intrinsic information within feature maps, but also avoids the spatial weighting from mistakenly removing useful information. Experiments demonstrate that our method outperforms some state-of-the-art methods on five benchmark datasets. It is not only simpler to implement, as it does not require complex processes such as retraining a convolutional neural network model, but also has low experimental requirements.},
  archive      = {J_IJMLC},
  author       = {Lu, Zhou and Liu, Guang-Hai and Lu, Fen and Zhang, Bo-Jian},
  doi          = {10.1007/s13042-022-01654-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {643-653},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Image retrieval using dual-weighted deep feature descriptor},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Event detection based on the label attention mechanism.
<em>IJMLC</em>, <em>14</em>(2), 633–641. (<a
href="https://doi.org/10.1007/s13042-022-01655-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event detection is an important subtask of event extraction. The goal of event detection (ED) is to detect the occurrences of events and categorize their descriptions in the text. Previous work solved this task by recognizing and classifying event triggers. As a result, existing approaches to the task of event detection require both manually annotated triggers and event types in training data. However, some texts have no triggers, and some triggers are ambiguous. Moreover, triggers are nonessential to event detection, and annotation of the training corpus is expensive and time-consuming. To address this problem, we propose a novel framework called the event detection model based on the label attention mechanism (EDLA), which does not depend on triggers but rather models the task as a text multilabel classification task. Additionally, our model considers the semantic information of event labels, which increases the model&#39;s semantic understanding of labels. Experimental results using the DuEE dataset demonstrate its effectiveness, including increasing the F1-score of event classification to 95.8\% and providing an increase of 6.0 in the F1-score over the traditional pipeline methods. It obtains new state-of-the-art results on the event detection task.},
  archive      = {J_IJMLC},
  author       = {Cheng, Qing and Fu, Yanghui and Huang, Jincai and Cheng, Guangquan and Du, Hang},
  doi          = {10.1007/s13042-022-01655-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {633-641},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Event detection based on the label attention mechanism},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TSFNFS: Two-stage-fuzzy-neighborhood feature selection with
binary whale optimization algorithm. <em>IJMLC</em>, <em>14</em>(2),
609–631. (<a href="https://doi.org/10.1007/s13042-022-01653-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimal global feature subset cannot be found easily due to the high cost, and most swarm intelligence optimization-based feature selection methods are inefficient in handling high-dimensional data. In this study, a two-stage feature selection model based on fuzzy neighborhood rough sets (FNRS) and binary whale optimization algorithm (BWOA) is developed. First, to denote the fuzziness of samples for mixed data with symbolic and numerical features, fuzzy neighborhood similarity is presented to study the similarity matrix and fuzzy membership degree, and the lower and upper approximations can be developed to present new FNRS model. Fuzzy neighborhood-based uncertainty measures such as dependence degree, knowledge granularity, and entropy measures are studied. From the viewpoints of algebra and information, fuzzy knowledge granularity conditional entropy is presented to form a preselected feature reduction set in the first stage. Second, the cosine curve change is added to develop a new control factor, which slows down the convergence rate of BWOA in the early iteration to fully explore the global, and accelerates the convergence rate in the late iteration. Integrating dependence degree with fuzzy knowledge granularity conditional entropy, a new fitness function is designed for selecting an optimal feature subset in this second stage. Two strategies are fused to avoid BWOA falling into the local optimum: the population partition strategy with the adaptive neighborhood search radius to divide the whale population and the local interference strategy of the elite subgroup to adjust the whale position update. Finally, a two-stage feature selection algorithm is designed, where the Fisher score algorithm is employed to preliminarily delete those redundancy features of high-dimensional datasets. Experiments on six UCI datasets and five gene expression datasets show that our algorithm is valid compared to other related algorithms.},
  archive      = {J_IJMLC},
  author       = {Sun, Lin and Wang, Xinya and Ding, Weiping and Xu, Jiucheng and Meng, Huili},
  doi          = {10.1007/s13042-022-01653-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {609-631},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {TSFNFS: Two-stage-fuzzy-neighborhood feature selection with binary whale optimization algorithm},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A two-stage personalized feedback mechanism considering
dynamic interactive behavior under social network in large-group
emergency task scheduling schemes selection. <em>IJMLC</em>,
<em>14</em>(2), 587–607. (<a
href="https://doi.org/10.1007/s13042-022-01652-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergencies such as natural disasters frequently occur around the world. Large-group emergency evaluation (LGEE) based on Earth observation satellite data is a new model that can potentially reduce the negative impacts of such emergencies. However, in real situations, the different interest preferences and diverse educational backgrounds of evaluators in the evaluation group may cause conflictive preferences, leading to low confidence in the results, which will affect the effect of LGEE. Therefore, this paper aims to devise a two-stage personalized feedback mechanism driven by the dynamic interactive behavior under a social trust relationship to coordinate evaluators’ opinions with conflicting opinions in the LGEE. Firstly, we introduce a family of probabilistic linguistic trust-propagation operators to obtain the complete trust relationship among the group using Archimedean t-norms and then determine the weights of evaluators and the weights associated with each pair of evaluators. Secondly, a Louvain method is used to divide the entire group into several subgroups to reduce computational complexity. Next, a two-stage personalized feedback mechanism is built to manage the consensus levels of intra and inter subgroups by describing the dynamic interactive behavior during the evaluation process. The first stage is to assist evaluators in achieving the consensus within the subgroup. The second stage is devoted to reaching an agreement of each subgroup to the global group. Finally, a case study of the selection problem in emergency task scheduling schemes is undertaken to verify the practicality and validity of the proposed method, followed by some comparative analysis and discussion.},
  archive      = {J_IJMLC},
  author       = {Wang, Yanjun and Yan, Bing and Hu, Xiaoxuan and Xia, Wei and Ma, Huawei and Jin, Peng},
  doi          = {10.1007/s13042-022-01652-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {587-607},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A two-stage personalized feedback mechanism considering dynamic interactive behavior under social network in large-group emergency task scheduling schemes selection},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Two-stage semi-supervised clustering ensemble framework
based on constraint weight. <em>IJMLC</em>, <em>14</em>(2), 567–586. (<a
href="https://doi.org/10.1007/s13042-022-01651-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised clustering ensemble introduces partial supervised information, usually pairwise constraints, to achieve better performance than clustering ensemble. Although it has been successful in many aspects, there are still several limitations that need to be further improved. Firstly, supervised information is only utilized in ensemble generation, but not in the consensus process. Secondly, all clustering solutions participate in getting a final partition without considering redundancy among clustering solutions. Thirdly, each cluster in the same clustering solution is treated equally, which neglects the influence of different clusters to the final clustering result. To address these issues, we propose a two-stage semi-supervised clustering ensemble framework which considers both ensemble member selection and the weighting of clusters. Especially, we define the weight of each pairwise constraint to assist ensemble members selection and the weighting of clusters. In the first stage, a subset of clustering solutions is obtained based on the quality and diversity of clustering solutions in consideration of supervised information. In the second stage, the quality of each cluster is determined by the consistency of unsupervised and supervised information. For the unsupervised information consistency of a cluster, we consider evaluating it by the consistency of a cluster relative to all clustering solutions. For the supervised information consistency of a cluster, it depends on how satisfied a cluster is with the supervised information. In the end, the final partition is achieved by a weighted co-association matrix as consensus function. Experimental results on various datasets show that the proposed framework outperforms most of state-of-the-art clustering algorithms.},
  archive      = {J_IJMLC},
  author       = {Zhang, Ding and Yang, Youlong and Qiu, Haiquan},
  doi          = {10.1007/s13042-022-01651-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {567-586},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Two-stage semi-supervised clustering ensemble framework based on constraint weight},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel adaptive methodology for removing spurious
components in a modified incremental gaussian mixture model.
<em>IJMLC</em>, <em>14</em>(2), 551–566. (<a
href="https://doi.org/10.1007/s13042-022-01649-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regarding the computational complexity of the update procedure in the fast incremental Gaussian mixture model (FIGMM) and no efficiency for removing the spurious component in the incremental Gaussian mixture model (IGMM), this study proposes a novel algorithm called the modified incremental Gaussian mixture model (MIGMM) which is an improvement of FIGMM, and a novel adaptive methodology for removing spurious components in the MIGMM. The major contributions in this study are twofold. Firstly, a more simple and efficient prediction matrix update, which is the core of the update procedure in the MIGMM algorithm, is proposed compared to that described in FIGMM. Secondly, an effective exponential model ( $$p_{\mathrm {_{Thv}}}$$ ) related to the number of output components generated in MIGMM, combined with the Mahalanobis distance-based logical matrix (LM), is proposed to remove spurious components and determine the correct components. Based on the highlighted contributions, regarding the removal of spurious components, comparative experiments studied on synthetic and real data sets show that the proposed framework performs robustly compared with other famous information criteria used to determine the number of components. The performance evaluation of IGMM compared with other efficient unsupervised algorithms is verified by conducting on both synthetic and real-world data sets.},
  archive      = {J_IJMLC},
  author       = {Sun, Shuping and Tong, Yaonan and Zhang, Biqiang and Yang, Bowen and Yan, Long and He, Peiguang and Xu, Hong},
  doi          = {10.1007/s13042-022-01649-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {551-566},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel adaptive methodology for removing spurious components in a modified incremental gaussian mixture model},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attention-based adaptive context network for anchor-free
instance segmentation. <em>IJMLC</em>, <em>14</em>(2), 537–549. (<a
href="https://doi.org/10.1007/s13042-022-01648-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is crucial to obtain accurate and efficient instance segmentation masks in many modern applications such as automatic pilot and robotic manipulation. In this paper, we propose a straightforward and flexible two-stage framework for instance segmentation, which simultaneously generates box-level localization information in an image and instance-level segmentation information for each instance. We name this framework as Attention-based Adaptive Context Network for anchor-free Instance Segmentation (ContextMask), which extends the object detector FCOS (Fully Convolutional One-stage Object Detection) by adding a novel multi-scale adaptive context-guided mask (MACG-Mask) branch containing an adaptive context network and a MaskIoU branch. The adaptive context network is to combine the global context in predicted bounding boxes and the MaskIoU branch is to evaluate the quality of the predicted masks. With the development of deep convolutional neural networks, the network continues to deepen so that it is difficult to balance spatial information and semantic information well. To address the issue, we design a weighted FPN, which obtains feature maps with balance-well spatial and semantic information by concatenating and weighting feature maps of different resolutions. Besides, we also propose an attention-based head, which adds spatial attention and channel attention module to make each pixel have a unique weight to solve the problem of large-scale variant of objects. We verify ContextMask’s effectiveness on the fine-annotations Cityscapes and COCO dataset. ContextMask outperforms state-of-the-art methods and achieves $$38.4\%$$ AP on the Cityscapes dataset and 39.0 $$\%$$ AP on the COCO dataset.},
  archive      = {J_IJMLC},
  author       = {Zhang, Tong and Zhang, Guoshan and Yan, Min and Zhang, Yueming},
  doi          = {10.1007/s13042-022-01648-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {537-549},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Attention-based adaptive context network for anchor-free instance segmentation},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on federated learning: Challenges and applications.
<em>IJMLC</em>, <em>14</em>(2), 513–535. (<a
href="https://doi.org/10.1007/s13042-022-01647-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a secure distributed machine learning paradigm that addresses the issue of data silos in building a joint model. Its unique distributed training mode and the advantages of security aggregation mechanism are very suitable for various practical applications with strict privacy requirements. However, with the deployment of FL mode into practical application, some bottlenecks appear in the FL training process, which affects the performance and efficiency of the FL model in practical applications. Therefore, more researchers have paid attention to the challenges of FL and sought for various effective research methods to solve these current bottlenecks. And various research achievements of FL have been made to promote the intelligent development of all application areas with privacy restriction. This paper systematically introduces the current researches in FL from five aspects: the basics knowledge of FL, privacy and security protection mechanisms in FL, communication overhead challenges and heterogeneity problems of FL. Furthermore, we make a comprehensive summary of the research in practical applications and prospect the future research directions of FL.},
  archive      = {J_IJMLC},
  author       = {Wen, Jie and Zhang, Zhixia and Lan, Yang and Cui, Zhihua and Cai, Jianghui and Zhang, Wensheng},
  doi          = {10.1007/s13042-022-01647-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {513-535},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A survey on federated learning: Challenges and applications},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-domain pattern classification with heterogeneous
distribution adaptation. <em>IJMLC</em>, <em>14</em>(2), 495–511. (<a
href="https://doi.org/10.1007/s13042-022-01646-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous domain adaptation (HDA) aims to learn a classification model to label the target samples given the source domain training data, with distinct distribution and difference in feature type or dimension. Most previous HDA methods solve the problem through the mapping of source and target domains into a domain invariant feature subspace to minimize the discrepancies across domains. However, the intrinsic properties of data is lost in such alignment strategy, which reduces the performance of model generalization. In this paper, we propose a novel approch called as Cross-Domain Pattern Classification with heterogeneous distribution adaptation (CDPC). CDPC preserves the intrinsic properties of data by utilizing the sparse coding method to find a new feature representation of features in a shared subspace. Meanwhile, a sample reweighting approach is proposed to align the probability distribution of source and target domain features into a common subspace. Extensive experiments on several HDA tasks including image to image, text to image and text to text illustrate the superiority of our proposed model against other state-of-the-art HDA methods.},
  archive      = {J_IJMLC},
  author       = {Alipour, Naimeh and Tahmoresnezhad, Jafar},
  doi          = {10.1007/s13042-022-01646-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {495-511},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Cross-domain pattern classification with heterogeneous distribution adaptation},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploiting deep textures for image retrieval.
<em>IJMLC</em>, <em>14</em>(2), 483–494. (<a
href="https://doi.org/10.1007/s13042-022-01645-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep features and texture features each have advantages in image representation. However, exploiting deep textures for image retrieval is challenging because it is difficult to enhance the compatibility of texture features and deep features. To address this problem, we propose a novel image-retrieval method named the deep texture feature histogram (DTFH). The main highlights are: (1) We propose a novel method for identifying effective, limited-effectiveness, or non-valid feature maps via ranking based on Haralick’s statistics, which can help understand image content and identify objects, as these statistics have clear physical significance. (2) We use Gabor filtering to mimic the human orientation-selection mechanism, which allows deep texture features to contain a good representation of orientation, thereby enhancing discriminative power. (3) We combine the advantages of classical texture features and deep features to provide a compact representation. This provides a new, yet simple way to exploit deep features via the use of traditional classical texture features. Comparative experiments demonstrate that deep texture features provide highly competitive performance in image retrieval in terms of mean average precision (mAP), and provide new insights into the exploitation of traditional texture features and deep features.},
  archive      = {J_IJMLC},
  author       = {Liu, Guang-Hai and Yang, Jing-Yu},
  doi          = {10.1007/s13042-022-01645-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {483-494},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Exploiting deep textures for image retrieval},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). D2TS: A dual diversity tree selection approach to pruning of
random forests. <em>IJMLC</em>, <em>14</em>(2), 467–481. (<a
href="https://doi.org/10.1007/s13042-022-01644-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random Forest is one of the most effective classification techniques. It is an ensemble technique with typically decision trees as its classifiers. Each tree votes for an outcome when a new instance is being classified, and a majority vote is taken to decide the final output. Two main factors play an essential role in Random Forests performance, namely diversity among trees in the forest and their number. Higher diversity increases prediction accuracy, whereas lower numbers of trees result in faster predictions. This paper aims at optimizing these two factors by using clustering analysis of trees in order to prune correlated trees while keeping outlier trees to maintain diversity. We group the trees into clusters and only take a number of representatives from each cluster while also keeping some or all of the outliers to preserve diversity. The resulting subset of trees will constitute a random forest of a reduced size. We will use the Density-Based Spatial Clustering of Applications with Noise (DBSCAN) algorithm for clustering. DBSCAN is one of the most commonly used clustering techniques and is immune to outliers. We will use DBSCAN to (i) group trees in clusters based on their prediction behaviour and (ii) identify outliers. Each of the clustered and outlier trees bring an element of diversity into the pruned random forest, thus giving our approach its dual diversity aspect. Our approach achieved up to a 99\% pruning level while resulting in similar, or even better, accuracy compared to the original forests for 19 public datasets with varying properties. Our source code is publicly available on GitHub.},
  archive      = {J_IJMLC},
  author       = {Ragab Hassen, Hani and Alabdeen, Yassin Zain and Gaber, Mohamed Medhat and Sharma, Megha},
  doi          = {10.1007/s13042-022-01644-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {467-481},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {D2TS: A dual diversity tree selection approach to pruning of random forests},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Complete interest propagation from part for visual relation
of interest detection. <em>IJMLC</em>, <em>14</em>(2), 455–465. (<a
href="https://doi.org/10.1007/s13042-022-01603-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual relation detection (VRD) is proposed to describe an image with visual relation triplets in the form of . As a further extension of the traditional VRD task, visual relation of interest detection (VROID) is proposed to obtain visual relations of interest, i.e., visual relations are semantically important for expressing the main content of an image. In this paper, we propose a complete interest propagation from part (CIPFP) method for VROID, which exploits semantic parts and propagates interest along part-instance-relation. Specifically, the interest in CIPFP is propagated from parts to part pairs, from parts to instances, from part pairs to instance pairs, from instances to instance pairs, from parts to relation triplets and from instance pairs to relation triplets. We conduct substantial experiments to validate the effectiveness of the CIPFP method and the components in CIPFP.},
  archive      = {J_IJMLC},
  author       = {Zhou, You and Yu, Fan},
  doi          = {10.1007/s13042-022-01603-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {455-465},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Complete interest propagation from part for visual relation of interest detection},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-stage fusion instance learning method for anomalous
event detection in videos. <em>IJMLC</em>, <em>14</em>(2), 445–454. (<a
href="https://doi.org/10.1007/s13042-022-01572-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomalous event detection in giant amount surveillance footage in real world is currently an active research area. Variery and rareness of the anomaly events is still a thorny challenge to deal with. In this paper, we propose a multi-stage fusion instance learning method (MFIL) for inferring anomalous event pattern and predicting anomaly appearance in videos. We propose object-aware model and action-aware model to represent regularities of human objects and actions among frames exploiting cascaded deep network models. Furthermore we improve and represent fusion instance learning method for fetching and maximizing anomaly scores via object and action regularities in anomalous sequences from videos. We validate the performance of MFIL on action movie and UCF-Crime respectively, both contain anomalous and violent events. Experimental results demonstrated that MFIL is effective for anomalous event detection in videos gathered from real world.},
  archive      = {J_IJMLC},
  author       = {Cheng, Jian and Zhang, Fengquan and Wang, Guiling and Zhang, Wancai},
  doi          = {10.1007/s13042-022-01572-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {445-454},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A multi-stage fusion instance learning method for anomalous event detection in videos},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Device-free indoor localization based on sparse coding with
nonconvex regularization and adaptive relaxation localization criteria.
<em>IJMLC</em>, <em>14</em>(2), 429–443. (<a
href="https://doi.org/10.1007/s13042-022-01559-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering practical device-free localization (DFL), the localization precision is usually proportional to the sensor density, with an ordinary arrangement. A better localization performance generally indicates a higher density of the sensor nodes that need to be deployed. To overcome this problem, we propose a new framework for dispatching sensor nodes. Regarding this framework, only few sensor nodes are applied to achieve an excellent localization performance. We consider the DFL problem as a sparse coding problem. To maintain the convexity of the cost function for more accurate solutions, we introduce the generalized minimax-concave (GMC) regularization to approximate the $$\ell _0$$ -norm regularization. The global optimal solution can be identified by adopting the forward-backward splitting algorithm (FBS). Furthermore, the localization error is further decreased by the proposed adaptive relaxation localization (ARL) criteria for target localization. We tackled two experimental scenes in a real laboratory and compared the performance of the proposed algorithm with that of other algorithms using different regularizations. The experimental results show 100 $$\%$$ grid localization accuracy under the $$0.5 \times 0.5$$ m grid scene. After adopting the ARL criteria, the average localization error decreased from 0.098 to 0.053 m in the $$0.25\times 0.25$$ m grid scene, with an increased rate of 45.9 $$\%$$ . This is the best performance compared to state-of-the-art framework.},
  archive      = {J_IJMLC},
  author       = {Zhang, Kangkang and Tan, Benying and Ding, Shuxue and Li, Yujie and Li, Guangwei},
  doi          = {10.1007/s13042-022-01559-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {429-443},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Device-free indoor localization based on sparse coding with nonconvex regularization and adaptive relaxation localization criteria},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Disentangling latent space better for few-shot
image-to-image translation. <em>IJMLC</em>, <em>14</em>(2), 419–427. (<a
href="https://doi.org/10.1007/s13042-022-01552-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an unpaired image-to-image translation, the main concept is to learn an underlying mapping between the source and target domains. Previous approaches required large numbers of data from both domains to learn this mapping. However, under a few-shot condition, that is, few-shot image-to-image translation, only one domain can meet the required number of data , and thus, the underlying mapping becomes ill-conditioned owing to the limited data as well as the imbalanced distribution of the two domains. We argue that a powerful model with a better disentangled representation of the latent space can better tackle the more challenging few-shot image-to-image translation . Motivated by this, under a partially-shared assumption, we propose a better disentanglement of the content and style latent space using a domain-specific style latent classifier and a domain-shared cross-content latent discriminator. Moreover, we design asymmetric weak/strong domain discriminators to achieve a better translation performance with limited data within the few-shot domain. Furthermore, our method can be easily embedded into any latent space disentangled model of an image-to-image translation for a few-shot setting. Subjective evaluation and objective evaluation results both show that compared with other state-of-the-art methods, the images synthesized by our method have higher fidelity while maintaining certain diversity.},
  archive      = {J_IJMLC},
  author       = {Liu, Peng and Wang, Yueyue and Du, Angang and Zhang, Liqiang and Wei, Bin and Gu, Zhaorui and Wang, Xiaodong and Zheng, Haiyong and Li, Juan},
  doi          = {10.1007/s13042-022-01552-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {419-427},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Disentangling latent space better for few-shot image-to-image translation},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global attention network for collaborative saliency
detection. <em>IJMLC</em>, <em>14</em>(2), 407–417. (<a
href="https://doi.org/10.1007/s13042-022-01531-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative saliency (cosaliency) detection aims to identify common and saliency objects or regions in a set of related images. The major challenge to address is how to extract useful information on single images and image groups to express collaborative saliency cues. In this paper, we propose a global attention network for cosaliency detection to extract individual features from the feature enhancement module (FEM). Then to capture useful global information, the global information module (GIM) is applied to all individual features to obtain individual cues, and finally, group collaborative cues are obtained by the collaboration correlation module (CCM). Specifically, the channel attention module and spatial attention module are plugged into the convolution feature network. To increase global context information, we perform global information module (GIM) on the preprocessed features and embed nonlocal modules in the backbone network and adopt global average pooling to extract global semantic representation vector as individual cues. Then, we build a collaborative correlation module (CCM) to extract collaborative and consistent information by calculating the correlation between the individual features of the input image and individual cues in the collaborative correlation module. We evaluate our method on two cosaliency detection benchmark datasets (CoSal2015, iCoSeg). Extensive experiments demonstrate the effectiveness of the proposed model, in most cases our method exceeds the state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Li, Ce and Xuan, Shuxing and Liu, Fenghua and Chang, Enbing and Wu, Hailei},
  doi          = {10.1007/s13042-022-01531-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {407-417},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Global attention network for collaborative saliency detection},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid-attention semantic segmentation network for remote
sensing interpretation in land-use surveillance. <em>IJMLC</em>,
<em>14</em>(2), 395–406. (<a
href="https://doi.org/10.1007/s13042-022-01517-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing interpretation for surveillance of land use often needs to mark out construction disturbance on satellite imagery, such as illegal buildings or spoil area. These disturbance region annotated by a set of surveillance rules contain the corresponding image characteristics which are regarded as semantic information in computer vision. Different from the natural Landscapes interpretation, the semantic information of construciton disturbance region shows more complex to extract with lack of available training dataset and interference of the various sizes of targets. This paper proposes a hybrid attention semantic segmentation network (HAssNet) which can extract the target and its surroundings through a large receptive field for multi-scale targets. Based on the full convolutional networks (FCN), spatial attention mechanism is firstly introduced to acquire the position of segmentation target with the global correlations, so that the small targets in large scale scene are guaranteed not to be omitted in semantic features extraction. Secondly, channel attention mechanism is designed to assign higher weights to task-related channels for semantic consistency. Experimental results on an open remote sensing dataset show that HAssNet achieves average 6.7\% improvement in mIoU than the state-of-the-art segmentation networks. In a land use surveillance project, HAssNet shows considerable performance compared with manual interpretation.},
  archive      = {J_IJMLC},
  author       = {Lv, Ning and Zhang, Zenghui and Li, Cong and Deng, Jiaxuan and Su, Tao and Chen, Chen and Zhou, Yang},
  doi          = {10.1007/s13042-022-01517-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {395-406},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A hybrid-attention semantic segmentation network for remote sensing interpretation in land-use surveillance},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Small target deep convolution recognition algorithm based on
improved YOLOv4. <em>IJMLC</em>, <em>14</em>(2), 387–394. (<a
href="https://doi.org/10.1007/s13042-021-01496-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the mainstream object detectors are unable to handle the problem of small object detection. Therefore, we proposed a small target deep convolution recognition algorithm which was based on the improved YOLOv4 network. Firstly, in order to obtain more object feature information and improve the detection efficiency of multi-scale small objects, spatial pyramid pooling with different pooling core sizes was introduced; To improve the value of the anchor frame, an improved adaptive anchor structure was proposed; finally, for enhancing the learning ability of the neural network and reduce the calculation cost, two cross stage partial parallel structures are adopted. In order to verify the feasibility of our algorithm, this paper uses small and micro electronic components in the industrial assembly line to construct a data set. Experiments show that compared with the original YOLOv4, the average detection speed and accuracy of the improved network are increased by about 30\% and 7\% respectively.},
  archive      = {J_IJMLC},
  author       = {Li, Fudong and Gao, Dongyang and Yang, Yuequan and Zhu, Junwu},
  doi          = {10.1007/s13042-021-01496-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {387-394},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Small target deep convolution recognition algorithm based on improved YOLOv4},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning relations in human-like style for few-shot
fine-grained image classification. <em>IJMLC</em>, <em>14</em>(2),
377–385. (<a href="https://doi.org/10.1007/s13042-021-01473-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained classification is a challenging problem with small inter-class variance and large intra-class variance. It becomes more difficult when only a few labeled training samples are available. Inspired by the procedure of human recognition that two similar objects are usually distinguished by comparing their key parts, we develop a novel few-shot fine-grained classification method, which learns to model the inter-class boundaries in human-like style, i.e., extracting key-part structure information of objects and performing part-by-part comparison. To this end, we first extract the key parts of objects by using the designed key-part detector, which are then encoded by our structure encoder for the final comparison. To tackle with the scarce labeled samples, we train the proposed network under the metric-based few-shot learning methodology. Experiments on benchmark datasets demonstrate the effectiveness of the proposed method compared with the state-of-the-art counterparts. Besides, extensive investigations are conducted to verify the contributions of the key components of our method.},
  archive      = {J_IJMLC},
  author       = {Li, Shenming and Feng, Lin and Xue, Linsong and Wang, Yifan and Wang, Dong},
  doi          = {10.1007/s13042-021-01473-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {377-385},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Learning relations in human-like style for few-shot fine-grained image classification},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Locality-constrained weighted collaborative-competitive
representation for classification. <em>IJMLC</em>, <em>14</em>(2),
363–376. (<a href="https://doi.org/10.1007/s13042-021-01461-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to represent and classify a testing sample for the representation-based classification (RBC) plays an important role in the filed of pattern recognition. As a typical kind of the representation-based classification with promising performance, collaborative representation-based classification (CRC) adopts all the training samples to collaboratively represent and then classify each testing sample with the reconstructive residuals among all the classes. However, most of the CRC methods fail to make full use of the localities and discrimination information of data in collaborative representation. To address this issue to further improve the classification performance, we design a novel supervised CRC method entitled locality-constrained weighted collaborative-competitive representation-based classification (LWCCRC). In the proposed method, the localities of data are taken into account by using the positive and negative nearest samples of each testing sample with their corresponding weighted constraints. Such devised locality-constrained weighted term can model the similarity and natural discrimination information contained in the neighborhood region for each testing sample to obtain the favorable representation. Moreover, a competitive constraint is introduced to enhance pattern discrimination among the categorical collaborative representations. To explore the effectiveness of our proposed LWCCRC, the extensive experiments are carried out on three different types of data sets. The experimental results demonstrate that the proposed LWCCRC significantly outperforms the recent state-of-the-art CRC methods.},
  archive      = {J_IJMLC},
  author       = {Gou, Jianping and Xiong, Xiangshuo and Wu, Hongwei and Du, Lan and Zeng, Shaoning and Yuan, Yunhao and Ou, Weihua},
  doi          = {10.1007/s13042-021-01461-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {363-376},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Locality-constrained weighted collaborative-competitive representation for classification},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Introduction to meta learning for internet of multimedia
things. <em>IJMLC</em>, <em>14</em>(2), 361–362. (<a
href="https://doi.org/10.1007/s13042-022-01700-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJMLC},
  author       = {Lu, Huimin and Wang, Yichuan and Li, Yujie},
  doi          = {10.1007/s13042-022-01700-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {361-362},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Introduction to meta learning for internet of multimedia things},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Effective weight function in graphs-based discriminant
neighborhood embedding. <em>IJMLC</em>, <em>14</em>(1), 347–360. (<a
href="https://doi.org/10.1007/s13042-022-01643-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph embedding-based discriminative dimensionality reduction has attracted much more attention over the past few decades. In constructing adjacent graphs in graph embedding, the weight functions are crucial. The weight function is always found experimentally in practice. So far, there is no any theorem to guide the selection of weight functions. In this study, from the view point of hypothesis-margin, a theoretical framework has been presented to answer the problem above, which can guarantee the fact that the selected weight functions based on the proposed theorem can achieve large hypothesis-margin between near neighbors, improving the classification performance. Then, based on the proposed framework, we design a series of more discriminant weight functions. Sequentially, by constructing double adjacency graphs, we propose a more effective weighted double adjacency graphs-based discriminant neighborhood embedding (WDAG-DNE). Experimental results illustrate that the proposed theorem and WDAG-DNE are more effective.},
  archive      = {J_IJMLC},
  author       = {Zhao, Guodong and Zhou, Zhiyong and Sun, Li and Zhang, Junming},
  doi          = {10.1007/s13042-022-01643-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {347-360},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Effective weight function in graphs-based discriminant neighborhood embedding},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving large-scale global optimization problems and
engineering design problems using a novel biogeography-based
optimization with lévy and brownian movements. <em>IJMLC</em>,
<em>14</em>(1), 313–346. (<a
href="https://doi.org/10.1007/s13042-022-01642-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To make biogeography-based optimization (BBO) suitable for large-scale optimization problems, this paper proposes a novel BBO variant based on marine predators algorithm (MPA) and steepest descent (SD) method, named BBOMPSD. Firstly, the example learning strategy is used to eliminate the damage of inferior solutions to superior solutions. Secondly, the hybrid migration operator is designed to make the population move rapidly to the global optimal solution, which improves the convergence speed and accuracy. Then, the Lévy and Brownian movements in MPA is combined with BBO to make the algorithm effectively balance the exploitation and exploration. BBOMPSD realizes free switching between local search and global search through the two movements. Finally, the SD method is merged with BBO, which further improves the convergence accuracy. Meanwhile, the sequence convergence model is established to prove the convergence of BBOMPSD. Comparing BBOMPSD with standard BBO, seven advanced BBO variants and seven state-of-the-art evolutionary algorithms on 24 benchmark functions and CEC2017 test set, the experimental results show that BBOMPSD outperforms all compared algorithms, and the dimension of solving global optimization problems can reach 5000. Applying it to engineering design problems, the results demonstrate that the proposed algorithm is also effective on real-world constrained optimization problems.},
  archive      = {J_IJMLC},
  author       = {Zhang, Ziyu and Gao, Yuelin},
  doi          = {10.1007/s13042-022-01642-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {313-346},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Solving large-scale global optimization problems and engineering design problems using a novel biogeography-based optimization with lévy and brownian movements},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modular transfer learning with transition mismatch
compensation for excessive disturbance rejection. <em>IJMLC</em>,
<em>14</em>(1), 295–311. (<a
href="https://doi.org/10.1007/s13042-022-01641-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater robots in shallow waters usually suffer from strong wave forces, which may frequently exceed robot’s control constraints. Learning-based controllers are suitable for disturbance rejection control, but the excessive disturbances heavily affect the state transition in Markov Decision Process (MDP) or Partially Observable Markov Decision Process (POMDP). This issue is amplified by training-test model mismatch. In this paper, we propose a transfer reinforcement learning algorithm using Transition Mismatch Compensation (TMC), that learns an additional compensatory policy through minimizing mismatch of transitions predicted by the two dynamics models of the source and target tasks. A modular network of learning policies is applied, composed of a Generalized Control Policy (GCP) and an Online Disturbance Identification Model (ODI). GCP is first trained over a wide array of disturbance waveforms. ODI then learns to use past states and actions of the system to predict the disturbance waveforms which are provided as input to GCP (along with the system state). We demonstrated on a pose regulation task in simulation that TMC is able to successfully reject the disturbances and stabilize the robot under an empirical model of the robot system, meanwhile improve sample efficiency.},
  archive      = {J_IJMLC},
  author       = {Wang, Tianming and Lu, Wenjie and Yu, Huan and Liu, Dikai},
  doi          = {10.1007/s13042-022-01641-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {295-311},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Modular transfer learning with transition mismatch compensation for excessive disturbance rejection},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge transfer based hierarchical few-shot learning via
tree-structured knowledge graph. <em>IJMLC</em>, <em>14</em>(1),
281–294. (<a href="https://doi.org/10.1007/s13042-022-01640-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning poses a great challenge for obtaining a classifier that recognizes new classes from a few labeled examples. Existing solutions perform well by leveraging meta-learning models driven by data information. However, these models only utilize the flat data information and ignore the existing hierarchical knowledge structure among classes. In this paper, we propose a knowledge transfer based hierarchical few-shot learning model, which takes advantage of a tree-structured knowledge graph to facilitate the classification results. First, we consider a tree-structured class hierarchy according to the semantic information among classes as a knowledge graph to alleviate the low-data problem. Second, we divide the tree structure into class structure and data, and build a multi-layer classifier to obtain classification results in the two parts. Finally, we consider the tradeoff between structure loss and data loss for hierarchical few-shot learning, which takes class structure information to assist learning. Experimental results on benchmark datasets show that our model outperforms several state-of-the-art models.},
  archive      = {J_IJMLC},
  author       = {Zhang, Zhong and Wu, Zhiping and Zhao, Hong and Hu, Minjie},
  doi          = {10.1007/s13042-022-01640-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {281-294},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Knowledge transfer based hierarchical few-shot learning via tree-structured knowledge graph},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continual portfolio selection in dynamic environments via
incremental reinforcement learning. <em>IJMLC</em>, <em>14</em>(1),
269–279. (<a href="https://doi.org/10.1007/s13042-022-01639-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Portfolio selection, as an important topic in the finance community, has attracted increased attention from artificial intelligence practitioners. Recently, the reinforcement learning (RL) paradigm, with the self-learning and model-free property, provides a promising candidate to solve complex portfolio selection tasks. Traditional research on RL-based portfolio selection focuses on batch-mode stationary problems, where all the market data is assumed to be available for the one-time training process. However, the real-world financial markets are often dynamic where the streaming data increments with new patterns keep emerging continually. In the paper, we address the continual portfolio selection problem in such dynamic environments. We propose to utilize the incremental RL approach with a two-step solution for efficiently adjusting the existing portfolio policy to a new one when the market changes as a new data increment comes. The first step, policy relaxation, forces the agent to execute a relaxed policy for encouraging a sufficient exploration in the new market. The second step, importance weighting, puts emphasis on learning samples consisting of more new information for stimulating the existing portfolio policy to more rapidly adapt to the new market. Evaluation results on real-world portfolio tasks verify the effectiveness and superiority of our method for addressing the continual portfolio selection in dynamic environments.},
  archive      = {J_IJMLC},
  author       = {Liu, Shu and Wang, Bo and Li, Huaxiong and Chen, Chunlin and Wang, Zhi},
  doi          = {10.1007/s13042-022-01639-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {269-279},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Continual portfolio selection in dynamic environments via incremental reinforcement learning},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Observer-based mixed <span
class="math display"><em>H</em><sub>∞</sub></span> and passive control
for t-s fuzzy semi-markovian jump systems with time-varying delay via
sliding mode method. <em>IJMLC</em>, <em>14</em>(1), 253–268. (<a
href="https://doi.org/10.1007/s13042-022-01638-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents the subject of the Takagi–Sugeno fuzzy sliding mode approach for nonlinear semi-Markovian mode-dependent delay switching systems. In addition, the mixed $$H_{\infty }$$ /passive performance was considered. The non-fragile observer is introduced to reconstruct variables, such that the error dynamics are obtained. By raising a novel fuzzy integral sliding surface function on the probability space, the new closed-loop sliding mode dynamic constitutes by observer and estimate systems satisfies both the mixed $$H_{\infty }$$ /passive performance index and the stochastic stable as the new model-dependent Lyapunov–Krasovskii function is established. Moreover, sufficient conditions are carried out based on linear matrix inequality (LMI), which ensures the results of our work can be verified by the feasibility problem in terms of LMI. Then the sliding mode control is designed to make the system&#39;s trajectory reach the predefined sliding surface. Finally, four numerical examples are given to testify the availability and less conservatism of the theoretical method.},
  archive      = {J_IJMLC},
  author       = {Wei, Zhiqi and Li, Huan and Ma, Yuechao},
  doi          = {10.1007/s13042-022-01638-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {253-268},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Observer-based mixed $$H_{\infty }$$ and passive control for T-S fuzzy semi-markovian jump systems with time-varying delay via sliding mode method},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Merits of bayesian networks in overcoming small data
challenges: A meta-model for handling missing data. <em>IJMLC</em>,
<em>14</em>(1), 229–251. (<a
href="https://doi.org/10.1007/s13042-022-01577-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The abundant availability of data in Big Data era has helped achieving significant advances in the machine learning field. However, many datasets appear with incompleteness from different perspectives such as values, labels, annotations and records. By discarding the records yielding ambiguousness, the exploitable data settles down to a small, sometimes ineffective, portion. Making the most of this small portion is burdensome because it usually yields overfitted models. In this paper we propose a new taxonomy for data missingness, in the machine learning context, along with a new metamodel to address the missing data problem within real and open data. Our proposed methodology relies on a H2S Kernel whose ultimate goal is the effective learning of a generalized Bayesian network from small input datasets. Our contributions are motivated by the strong probabilistic foundation of the Bayesian network, on the one hand, and on the ensemble learning effectiveness, on the other hand. The highlights of our kernel are the new strategy for multiple Bayesian network structure learning and the novel technique for the weighted fusion of Bayesian network structures. To harness on the richness of the merged network in terms of knowledge, we propose four H2S-derived systems to address the missing values/records impacts involving the annotation, the balancing, missing values imputation and data over-sampling. We combine these systems into a meta-model, and we perform a step-by-step experimental study. The obtained results showcase the efficiency of our contributions to deal with multi-class problems and with extremely small datasets.},
  archive      = {J_IJMLC},
  author       = {Ameur, Hanen and Njah, Hasna and Jamoussi, Salma},
  doi          = {10.1007/s13042-022-01577-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {229-251},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Merits of bayesian networks in overcoming small data challenges: A meta-model for handling missing data},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novelty detection approach to effectively predict
conversion from mild cognitive impairment to alzheimer’s disease.
<em>IJMLC</em>, <em>14</em>(1), 213–228. (<a
href="https://doi.org/10.1007/s13042-022-01570-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately recognising patients with progressive mild cognitive impairment (pMCI) who will develop Alzheimer’s disease (AD) in subsequent years is very important, as early identification of those patients will enable interventions to potentially reduce the number of those transitioning from MCI to AD. Most studies in this area have concentrated on high-dimensional neuroimaging data with supervised binary/multi-class classification algorithms. However, neuroimaging data is more costly to obtain than non-imaging, and healthcare datasets are normally imbalanced which may reduce classification performance and reliability. To address these challenges, we proposed a new strategy that employs unsupervised novelty detection (ND) techniques to predict pMCI from the AD neuroimaging initiative non-imaging data. ND algorithms, including the k-nearest neighbours (kNN), k-means, Gaussian mixture model (GMM), isolation forest (IF) and extreme learning machine (ELM), were employed and compared with supervised binary support vector machine (SVM) and random forest (RF). We introduced optimisation with nested cross-validation and focused on maximising the adjusted F measure to ensure maximum generalisation of the proposed system by minimising false negative rates. Our extensive experimental results show that ND algorithms (0.727 ± 0.029 kNN, 0.7179 ± 0.0523 GMM, 0.7276 ± 0.0281 ELM) obtained comparable performance to supervised binary SVM (0.7359 ± 0.0451) with 20\% stable MCI misclassification tolerance and were significantly better than RF (0.4771 ± 0.0167). Moreover, we found that the non-invasive, readily obtainable, and cost-effective cognitive and functional assessment was the most efficient predictor for predicting the pMCI within 2 years with ND techniques. Importantly, we presented an accessible and cost-effective approach to pMCI prediction, which does not require labelled data.},
  archive      = {J_IJMLC},
  author       = {Liu, Shuo and Cao, Yi and Liu, Junxiu and Ding, Xuemei and Coyle, Damien},
  doi          = {10.1007/s13042-022-01570-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {213-228},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novelty detection approach to effectively predict conversion from mild cognitive impairment to alzheimer’s disease},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fractional mega trend diffusion function-based feature
extraction for plant disease prediction. <em>IJMLC</em>, <em>14</em>(1),
187–212. (<a href="https://doi.org/10.1007/s13042-022-01562-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plant diseases can severely degrade the quality and productivity of any crop. Hence, an automated forecasting model can be developed to help the farmers and agricultural experts for early detection and on-time treatment of plant diseases. However, precise identification and classification of plant diseases becomes tedious when the dataset is small-sized. This motivated us to design a feature extraction technique that can produce more relevant features for small-sized datasets by performing some operations on the original features. Thus, the current study contributes towards an accurate and speedy detection of plant diseases by proposing an innovative technique, namely, Fractional Mega Trend Diffusion (FMTD) function-based feature extraction technique. The proposed feature extraction technique, i.e., FMTD Function-based Fuzzy Transformation (FFFT) extends a small dataset into a high dimensional feature space by computing new features using a novel FMTD function. In this research, two small plant diseases datasets, namely Tomato Early Blight Disease (TomEBD) and Tomato Powdery Mildew Disease (TPMD) have been used to validate the proposed approach. Resampling techniques have also been implemented in this paper to balance the imbalanced datasets and afterwards, Optimized Kernel Extreme Learning Machine (OKELM) algorithm has been used for the classification purpose. A genetic algorithm has also been used for parameter optimization while performing feature extraction and classification. The results of this study indicate that the proposed approach has achieved the accuracy ranging between 70 and 89.47\% for the TomEBD dataset and between 92.27 and 100\% for the TPMD dataset. The performance of the proposed approach is also tested for its efficiency using three benchmarking datasets. Conclusively, the proposed approach performed remarkably well for all the three datasets.},
  archive      = {J_IJMLC},
  author       = {Bhatia, Anshul and Chug, Anuradha and Singh, Amit Prakash and Singh, Dinesh},
  doi          = {10.1007/s13042-022-01562-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {187-212},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fractional mega trend diffusion function-based feature extraction for plant disease prediction},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tuning of data augmentation hyperparameters in deep learning
to building construction image classification with small datasets.
<em>IJMLC</em>, <em>14</em>(1), 171–186. (<a
href="https://doi.org/10.1007/s13042-022-01555-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning methods have important applications in the building construction image classification field. One challenge of this application is Convolutional Neural Networks adoption in a small datasets. This paper proposes a rigorous methodology for tuning of Data Augmentation hyperparameters in Deep Learning to building construction image classification, especially to vegetation recognition in facades and roofs structure analysis. In order to do that, Logistic Regression models were used to analyze the performance of Convolutional Neural Networks trained from 128 combinations of transformations in the images. Experiments were carried out with three architectures of Deep Learning from the literature using the Keras library. The results show that the recommended configuration (Height Shift Range = 0.2; Width Shift Range = 0.2; Zoom Range =0.2) reached an accuracy of $$95.6\%$$ in the test step of first case study. In addition, the hyperparameters recommended by proposed method also achieved the best test results for second case study: $$93.3\%$$ .},
  archive      = {J_IJMLC},
  author       = {Ottoni, André Luiz C. and de Amorim, Raphael M. and Novo, Marcela S. and Costa, Dayana B.},
  doi          = {10.1007/s13042-022-01555-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {171-186},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Tuning of data augmentation hyperparameters in deep learning to building construction image classification with small datasets},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using a small dataset to classify strength-interactions with
an elastic display: A case study for the screening of autism spectrum
disorder. <em>IJMLC</em>, <em>14</em>(1), 151–169. (<a
href="https://doi.org/10.1007/s13042-022-01554-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health data collection of children with autism spectrum disorder (ASD) is challenging, time-consuming, and expensive; thus, working with small datasets is inevitable in this area. The diagnosis rate in ASD is low, leading to several challenges, including imbalance classes, potential overfitting, and sampling bias, making it difficult to show its potential in real-life situations. This paper presents a data analytics pilot-case study using a small dataset leveraging domain-specific knowledge to uncover differences between the gestural patterns of children with ASD and neurotypicals. We collected data from 59 children using an elastic display we developed during a sensing campaign and 9 children using the elastic display as part of a therapeutic program. We extracted strength-related features and selected the most relevant ones based on how the motor atypicality of children with ASD influences their interactions: children with ASD make smaller and narrower gestures and experience variations in the use of strength. The proposed machine learning models can correctly classify children with ASD with 97.3\% precision and recall even if the classes are unbalanced. Increasing the size of the dataset via synthetic data improved the model precision to 99\%. We finish discussing the importance of leveraging domain-specific knowledge in the learning process to successfully cope with some of the challenges faced when working with small datasets in a concrete, real-life scenario.},
  archive      = {J_IJMLC},
  author       = {Monarca, Ivonne and Cibrian, Franceli L. and Chavez, Edgar and Tentori, Monica},
  doi          = {10.1007/s13042-022-01554-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {151-169},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Using a small dataset to classify strength-interactions with an elastic display: A case study for the screening of autism spectrum disorder},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data augmentation in natural language processing: A novel
text generation approach for long and short text classifiers.
<em>IJMLC</em>, <em>14</em>(1), 135–150. (<a
href="https://doi.org/10.1007/s13042-022-01553-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many cases of machine learning, research suggests that the development of training data might have a higher relevance than the choice and modelling of classifiers themselves. Thus, data augmentation methods have been developed to improve classifiers by artificially created training data. In NLP, there is the challenge of establishing universal rules for text transformations which provide new linguistic patterns. In this paper, we present and evaluate a text generation method suitable to increase the performance of classifiers for long and short texts. We achieved promising improvements when evaluating short as well as long text tasks with the enhancement by our text generation method. Especially with regard to small data analytics, additive accuracy gains of up to 15.53\% and 3.56\% are achieved within a constructed low data regime, compared to the no augmentation baseline and another data augmentation technique. As the current track of these constructed regimes is not universally applicable, we also show major improvements in several real world low data tasks (up to +4.84 F1-score). Since we are evaluating the method from many perspectives (in total 11 datasets), we also observe situations where the method might not be suitable. We discuss implications and patterns for the successful application of our approach on different types of datasets.},
  archive      = {J_IJMLC},
  author       = {Bayer, Markus and Kaufhold, Marc-André and Buchhold, Björn and Keller, Marcel and Dallmeyer, Jörg and Reuter, Christian},
  doi          = {10.1007/s13042-022-01553-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {135-150},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Data augmentation in natural language processing: A novel text generation approach for long and short text classifiers},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Data augmentation for aspect-based sentiment analysis.
<em>IJMLC</em>, <em>14</em>(1), 125–133. (<a
href="https://doi.org/10.1007/s13042-022-01535-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning has been widely used in the field of natural language processing (NLP), achieving spectacular successes in various NLP tasks. These successes are largely due to its capability to automatically learn feature representations from text data. However, the performance of deep learning in NLP can be negatively affected by a lack of sufficiently large labeled corpus for training, resulting in limited improvement in performance. Data augmentation overcomes this small data problem by expanding the sample size for the classes of data in the training corpus. This paper introduces the data augmentation for aspect-based sentiment analysis (ABSA), a classical research topic in NLP that has been applied in various fileds. The study aims to enhance the classification performance of ABSA through various augmentation strategies. Two specific augmentation strategies are presented, part-of-speech (PoS) wise synonym substitution (PWSS) and dependency relation-based word swap (DRAWS), which augment data using PoS, external domain knowledge, and syntactic dependency. These strategies are evaluated through extensive experimentation on four public datasets using three representative deep learning models—aspect-specific graph convolutional network (ASGCN), content attention-based aspect-based sentiment classification (CABASC), and long short-term memory (LSTM) network. Compared with the results without data augmentation, our augmentation strategies achieve a performance gain of up to 11.49\% on Macro-F1, with the lowest gain being 2.9\%. The experimental results demonstrate that the proposed data augmentation strategies are very useful for training deep learning models on small data corpus.},
  archive      = {J_IJMLC},
  author       = {Li, Guangmin and Wang, Hui and Ding, Yi and Zhou, Kangan and Yan, Xiaowei},
  doi          = {10.1007/s13042-022-01535-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {125-133},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Data augmentation for aspect-based sentiment analysis},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Faster quantum ridge regression algorithm for prediction.
<em>IJMLC</em>, <em>14</em>(1), 117–124. (<a
href="https://doi.org/10.1007/s13042-022-01526-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a quantum algorithm based on ridge regression model is proposed. The proposed quantum algorithm consists of two parts. One is the first quantum sub-algorithm to efficiently generate predictive values for new inputs. The non-sparse Hamiltonian simulation technique is applied to simulate the data matrix that is generally non-sparse. Therefore, there is no need to expand the data matrix into a larger sparse Hermitian matrix, and the predictive results can be obtained without projection operation at the end of the first sub-algorithm, which makes it more feasible. The other is to determine a reasonable regularization parameter. To achieve this goal, the second sub-algorithm is proposed. In the second sub-algorithm, the suitable one is selected from some candidates using phase estimation algorithm and the controlled rotation operation. In this way, the whole training dataset can be calculated in parallel, which greatly reduces the time complexity. In addition, it is shown that the proposed quantum ridge regression algorithms can achieve exponential speedup over the classical counterpart when the rank of the data matrix is low.},
  archive      = {J_IJMLC},
  author       = {Chen, Menghan and Yu, Chaohua and Guo, Gongde and Lin, Song},
  doi          = {10.1007/s13042-022-01526-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {117-124},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Faster quantum ridge regression algorithm for prediction},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An iterative recommendation model of supporting personalized
learning based on schematic patterns mining from schema-enhanced
contexts of problem-solving. <em>IJMLC</em>, <em>14</em>(1), 93–115. (<a
href="https://doi.org/10.1007/s13042-022-01525-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on schema-enhanced formal concept analysis and three-way decisions theory, this paper develops a method of supporting personalized learning by which students can benefit from instructional design over problems. Particularly, we discuss the feasibility of integrating Ausubel’s meaningful learning theory and schema theory with formal concept analysis towards data analysis in problem-solving scenarios. Subsequently, we extend the classical formal concept analysis by incorporating a schematic implication structure on attributes of a context. Then, by applying three-way decisions into the context of problem-solving, we propose a strategy of classifying objects according to a certain attribute and a method of stratifying the involved attributes of a set of objects. Furthermore, as an application of three-way decisions with a greater generality, we develop an iterative recommendation model of supporting personalized learning in the context of problem-solving. Finally, we give an illustrative data experiment to demonstrate the mechanism of the model.},
  archive      = {J_IJMLC},
  author       = {Guo, Lankun and Jia, Zhenhua and Ma, Guozhi and Li, Jinhai},
  doi          = {10.1007/s13042-022-01525-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {93-115},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An iterative recommendation model of supporting personalized learning based on schematic patterns mining from schema-enhanced contexts of problem-solving},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distance metric learning with local multiple kernel
embedding. <em>IJMLC</em>, <em>14</em>(1), 79–92. (<a
href="https://doi.org/10.1007/s13042-021-01487-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distance metric learning aims to learn a data-dependent similarity measure, which is widely employed in machine learning. Recently, metric learning algorithms that incorporate multiple kernel learning have shown promising outcomes for classification tasks. However, the multiple kernel learning part of the existing metric learning with multiple kernel just uses a linear combination form of different kernel functions, where each kernel shares the same weight in the entire input space, thus the potential local structure of samples located at different locations in the input space is ignored. To address the aforementioned issues, in this paper, we propose a distance metric learning approach with local multiple kernel embedding (DMLLMK) for small datasets. The weight of each kernel function in DMLLMK is assigned locally, so that there are many different values of weight in each kernel space. This local weight method enables metric learning to capture more information in the data. Our proposed DMLLMK adjusts the kernel weight by using a gating function; moreover, the kernel weight locally depends on the input data. The metric of metric learning and the parameters of the gating function are optimized simultaneously by an alternating learning process. The DMLLMK makes metric learning applicable to small datasets by constructing constraints on the set of similar pairs and dissimilar pairs such that some data are reused, and they produce different constraints on the model. In addition, regularization techniques are used to keep DMLLMK more conservative and prevent overfitting on small data. The experimental results of our proposed method when compared with other metric learning methods on the benchmark dataset show that our proposed DMLLMK is effective.},
  archive      = {J_IJMLC},
  author       = {Zhang, Qingshuo and Tsang, Eric C. C. and He, Qiang and Hu, Meng},
  doi          = {10.1007/s13042-021-01487-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {79-92},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Distance metric learning with local multiple kernel embedding},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Micro-extended belief rule-based system with activation
factor and parameter optimization for industrial cost prediction.
<em>IJMLC</em>, <em>14</em>(1), 63–78. (<a
href="https://doi.org/10.1007/s13042-021-01485-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial cost is a comprehensive indicator to reflect industrial behaviors, whereas industrial data with annotation are rare because the annotation process is very expensive. Data increment transformation is a feasible solution to enrich annotated industrial data, but it bring a new challenge in system modeling because the size of transformational data is the quadratical relationship with that of collected data, and even turn into big data problem. Hence, a novel rule-based system proposed for handling big data problems, called micro-extended belief rule-based system (Micro-EBRBS), is introduced for industrial cost prediction. Firstly, the Micro-EBRBS is improved by (1) the use of activation factor to revise the calculation of individual matching degrees; (2) the use of parameter optimization to determine the optimal value of basic parameters. Afterwards, on the basis of data increment transformation, a novel industrial cost prediction model, called data increment-based Micro-EBRBS (DIME) model, is developed to accurately predict industrial costs. In case study, 13 state-own holding industries with historical data from 1999 to 2019 in China are used to illustrate the effectiveness of the DIME model. Comparative results show that the DIME model is more accurate than some existing models in industrial cost prediction.},
  archive      = {J_IJMLC},
  author       = {Wang, Suhui and Ye, Fei-Fei and Yang, Long-Hao and Liu, Jun and Wang, Hui and Martínez, Luis},
  doi          = {10.1007/s13042-021-01485-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {63-78},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Micro-extended belief rule-based system with activation factor and parameter optimization for industrial cost prediction},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalized dice measures of single valued neutrosophic
type-2 hesitant fuzzy sets and their application to multi-criteria
decision making problems. <em>IJMLC</em>, <em>14</em>(1), 33–62. (<a
href="https://doi.org/10.1007/s13042-021-01480-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop single valued neutrosophic type-2 hesitant fuzzy sets (SVNT2HFS), presented as a variation of single valued neutrosophic fuzzy sets and type-2 hesitant fuzzy sets that includes truth, indeterminacy, falsity sets but these parts have been determined from type-2 fuzzy elements with motivation of single valued neutrosophic hesitant fuzzy set (SVNHFS) and Interval neutrosophic hesitant fuzzy set (INHFS). The proposed cluster can present more advantages than SVNHFS and INHFS for decision makers because it can provide a wide scala while membership values are being appointed by experts. Also, SVNHFS, INHFS are special cases of SVNT2HFS as indicated into comparison analysis. Therefore, our cluster has more knowledge capacity. Then, we give some basic dice measures, weighted dice measures, generalized dice measures and generalized weighted dice measures between two SVNT2HFSs. In here, generalized dice measures of SVNT2HFS propose more flexible relation for different values of $$\lambda$$ change according to decision maker’s need and requirements. Also, we offer a decision making method and survey similarity between obtained an optimal solution and decision maker’s ideas by using dice measures, weighted dice measures, generalized dice measures and generalized weighted dice measures. At the end of the paper, two illustrative examples and two comparative analysis are proposed to show the practicality and effectiveness of our measures.},
  archive      = {J_IJMLC},
  author       = {Özlü, Şerif},
  doi          = {10.1007/s13042-021-01480-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {33-62},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Generalized dice measures of single valued neutrosophic type-2 hesitant fuzzy sets and their application to multi-criteria decision making problems},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Implement an uncertain vector approach to solve
entropy-based four-dimensional transportation problems with discounted
costs. <em>IJMLC</em>, <em>14</em>(1), 3–31. (<a
href="https://doi.org/10.1007/s13042-021-01457-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research paper, using uncertainty theory we introduced and developed entropy-based uncertain four-dimensional transportation problem with fixed charges, discounted costs, and vehicle costs. In this transportation system, we considered a discount policy on the transportation cost which depends on the basis of the transported amount. Here, the discounted costs are in the form of all unit discounts (AlUD), incremental quantity discounts (InQD), and the combination of these two. The main objective is to minimize the total transportation cost via maximum entropy which ensures the number of items to be transported from some source to some destinations by some conveyances through some routes. For optimizing the proposed model, using uncertain programming techniques, we have developed two different models such as expected value programming model and expected constrained programming model. Then, Using minimizing distance method and linear weighted method we formulated and solved the equivalent deterministic transformation of these two constructed models. Finally, to show the application of the proposed models and methods we presented a numerical example with optimal results.},
  archive      = {J_IJMLC},
  author       = {Sahoo, Palash and Jana, Dipak Kumar and Pramanik, Sutapa and Panigrahi, Goutam},
  doi          = {10.1007/s13042-021-01457-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {3-31},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Implement an uncertain vector approach to solve entropy-based four-dimensional transportation problems with discounted costs},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Special issue on small data analytics. <em>IJMLC</em>,
<em>14</em>(1), 1–2. (<a
href="https://doi.org/10.1007/s13042-022-01699-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJMLC},
  author       = {Wang, Hui and Duentsch, Ivo and Guo, Gongde and Khan, Sadiq Ali},
  doi          = {10.1007/s13042-022-01699-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Special issue on small data analytics},
  volume       = {14},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
