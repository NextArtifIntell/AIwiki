<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>CC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="cc---141">CC - 141</h2>
<ul>
<li><details>
<summary>
(2023). Cognitively inspired group decision-making with linguistic
q-rung orthopair fuzzy preference relations. <em>CC</em>,
<em>15</em>(6), 2216–2231. (<a
href="https://doi.org/10.1007/s12559-023-10183-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In actual decision-making problems, it is very difficult to appropriately depict the cognitive information of the relevant experts because cognition is usually diverse and contains uncertainties and fuzziness. The recently introduced linguistic q-rung orthopair fuzzy set (Lq-ROFS), which determines the linguistic preferred degree and linguistic nonpreferred degree within a wider space, has been shown to be effective in representing cognitive information. However, the corresponding preference relation has yet to be studied. Pairwise comparison is an effective way for decision-makers to express their preferences, especially when cognition is complex and indeterminate. Therefore, this paper employs linguistic q-rung orthopair fuzzy preference relations (Lq-ROFPRs) to express the cognitive information of experts. The additive consistency of Lq-ROFPR is introduced to rank the objects, and a consistency-based model is built to obtain the normalized linguistic q-rung orthopair fuzzy priority weight vector (Lq-ROFPWV). Then, several models are constructed to estimate missing values and improve the additive consistency level. For the group decision-making (GDM) problem, a model is first built with which to gain the weights of decision-makers. When group consensus is not achieved, a consensus-reaching model is designed as a means of increasing the consensus level. This study designs a decision support model to address GDM problem with incomplete Lq-ROFPRs and presents a step-by-step algorithm. The proposed method is utilized to assess four Chinese shopping platforms, and the comprehensive ranking result is reasonable and reliable. This is the first time to investigate GDM with Lq-ROFPRs based on consistency and consensus analysis, the newly studied Lq-ROFPRs not only extend the applications for linguistic preference relations but also endow experts with more flexibility in denoting their cognitive preferences. Compared to the latest published work in this domain, the novel approach conducts a reasonable decision-making process and has some advantages.},
  archive      = {J_CC},
  author       = {Li, Tao and Zhang, Liyuan},
  doi          = {10.1007/s12559-023-10183-y},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2216-2231},
  shortjournal = {Cogn. Comput.},
  title        = {Cognitively inspired group decision-making with linguistic q-rung orthopair fuzzy preference relations},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A biologically-inspired sparse self-representation approach
for projected fuzzy double c-means clustering. <em>CC</em>,
<em>15</em>(6), 2202–2215. (<a
href="https://doi.org/10.1007/s12559-023-10185-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data redundancy is frequently encountered in biologically data. Locality preserving projection (LPP) is a dimensionality reduction approach to mitigate the data redundancy while preserving the substantial geometry inspired by biological processes. Its application can contribute promisingly to the fuzzy c-means (FCM) clustering. However, the existing locality preserving based FCM clustering methods that combine LPP with FCM focus only on the local information, probably resulting in somewhat conservatism. A novel FCM clustering method, namely, projected fuzzy double c-means clustering using sparse self-representation (PFD SSR), is developed in this paper. The main idea of PFD SSR is three-fold: (1) Inspired by biological processes, a so-called sparse self-representation (SSR) method is employed. Hence, the global data distribution is investigated so as to enhance the clustering performance; (2) LPP is utilized to handle both the raw data and the dictionary matrix obtained by SSR, which greatly reduces the feature dimensions and solidly preserves the intrinsic data distribution. In addition, the regularization terms of these two achievements under projection are introduced to the FCM’s objective function, which helps reduce the risk of being trapped into local optima during the model training; and (3) the alternative direction technique is applied to learn the model. The experimental results on 11 datasets including 6 biologically data sets demonstrated the proposed method outperforms the state-of-art clustering methods. The proposed subspace clustering method has a good ability of handling the high-dimensional data, especially biological data.},
  archive      = {J_CC},
  author       = {Tian, Xin and Sun, Cun and Sun, Ying and Song, Yan and Wei, Guoliang and Yu, Hui and Li, Ming},
  doi          = {10.1007/s12559-023-10185-w},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2202-2215},
  shortjournal = {Cogn. Comput.},
  title        = {A biologically-inspired sparse self-representation approach for projected fuzzy double C-means clustering},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning-based sign language recognition system for
cognitive development. <em>CC</em>, <em>15</em>(6), 2189–2201. (<a
href="https://doi.org/10.1007/s12559-023-10182-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information in sign language (SL) is transmitted in large part by the movement, positioning, and shape of the hands as well as body language and facial emotions. Systems that recognize sign language can help with the problem that sign language is not widely used despite the large number of individuals who need to use it, and they can give hearing-impaired and deaf people a more practical way of life, employment, and education. Despite the fact that facial features are treated to be fundamental for humans to comprehend sign language, few earlier research work have inspected their cognitive importance for automatic SL recognition systems. To address this problem, this paper comes up with a novel manual and non-manual gesture recognition framework (MNM-VGG16) for the deaf and mute people. The framework employs a convolutional neural network, renowned as VGG-16 net, for implementing a trained model on an amply used video dataset by employing a component that learns the Multimodal Spatial Representation (MSR) of various modalities. The Multimodal Temporal Representation (MTR) component shapes temporal corrections from independent and dependent pathways to analyze the cooperation of different modalities. A cooperative optimization scheme, summarized by the employment of multi-scale perception component, is applied to make the finest of various modalities sources for sign language recognition. To validate the efficiency of MNM-VGG16, we carried out experiments on three large-scale sign language benchmarks: CSL Split II, SIGNUM, and RWTH-PHOENIX-Weather 2014. Experimental results prove that the suggested framework reaches new state-of-the-art achievement on all three benchmarks, and this attainment is noted by the reduction of the word error rate (WER) on test set by 14.2%, 13.7%, and 11.2%, respectively. In this paper, we offer the MNM-VGG16 hybrid method, which recognizes SL words by combining manual and non-manual features. This method demonstrates the significance of jointly modeling various body parts for SL recognition.},
  archive      = {J_CC},
  author       = {Jebali, Maher and Dakhli, Abdesselem and Bakari, Wided},
  doi          = {10.1007/s12559-023-10182-z},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2189-2201},
  shortjournal = {Cogn. Comput.},
  title        = {Deep learning-based sign language recognition system for cognitive development},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved grey wolf optimization–based convolutional
neural network for the segmentation of COVID-19 lungs–infected parts.
<em>CC</em>, <em>15</em>(6), 2175–2188. (<a
href="https://doi.org/10.1007/s12559-023-10180-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The coronavirus outbreak is a recent pandemic that destroyed most of the lives, economy, and livelihoods. The detection of COVID-19 is the main aim to detect and provide better treatment for patients to mitigate its impact. In addition, it is necessary to diagnose the disease swiftly with upgraded technologies. This can be achieved by CT image scanning. This provides the fastest detection of the disease. Moreover, it can also be used to diagnose the percentage of the affected lung areas. To perform this fastly, we propose a novel approach known as Convolutional Neural Network (CNN)–based Improved Grey Wolf Optimization (IGWO) algorithm. The proposed CNN utilizes a SegNet-based approach which can be used to detect the affected area in the lungs by using the encoder and decoder steps. The encoder in this approach uses three types of CNN architecture. First, the decoder is used to reconstruct the images. The overfitting issues during the iterations and complexities are reduced by adopting the IGWO approach. The experimental analysis depicts that the proposed approach effectively segments the CT images and promptly diagnoses the affected lung area.},
  archive      = {J_CC},
  author       = {Sridhar, P. and Ramasamy, Jayaraj and Kumar, Ravi and Ramanathan, Ramakrishnan and Nayak, Rakesh and Tholkapiyan, M.},
  doi          = {10.1007/s12559-023-10180-1},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2175-2188},
  shortjournal = {Cogn. Comput.},
  title        = {An improved grey wolf Optimization–Based convolutional neural network for the segmentation of COVID-19 Lungs–Infected parts},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An optimized ensemble support vector machine-based extreme
learning model for real-time big data analytics and disaster prediction.
<em>CC</em>, <em>15</em>(6), 2152–2174. (<a
href="https://doi.org/10.1007/s12559-023-10176-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capacity to interact with environments, understand them, and make judgments on time defines smartness, the foundation of smart cities, and civilizations. The main motivation of this study is to satisfy the need for a real-time disaster-related application that increases the demand for novel techniques that are scalable with big data. The main aim of this paper is to analyze the input data to find the crucial features and accurately classify them into their appropriate disaster class with the help of social media. The disaster dataset contains numerous features which increase the dimensionality of the dataset. The existing techniques consume higher runtime memory for large training datasets and suffered from different drawbacks such as oversampling, computational cost, low speed, data imbalance, concept drift, and computational complexity. To overcome these drawbacks, this study presents a novel city councils evolution (CCE)-optimized ensemble support vector machine-based extreme learning machine (ESVM-ELM) model on Apache Spark for predicting disaster events in big data. The traditional serial processing issue is overcome in this paper using an appropriate parallelization technique which improves the speedup of the model and improves the time taken for classification. The ESVM-ELM model performs well with imbalanced datasets and handles the concept drift problem efficiently. The use of the CCE algorithm for optimizing the ESVM-ELM model offers improved accuracy, a better convergence rate, and minimal computational complexity. The efficiency of our model is demonstrated by validation using the disaster tweets dataset and comparison with the four underlying approaches, namely, naïve Bayes, ELM, FCM, and Log-Based Abnormal Task Detection. The cross-validation method is utilized in this paper to generate an ensemble of ELM classifiers for decision-making utilizing an ESVM-ELM algorithm. The proposed model offers improvements in terms of accuracy, precision, recall, and F-measure values when compared to different baseline models. The experimental results demonstrated the efficiency of the ESVM-ELM model in improving the prediction accuracy, speedup, and scale-up for big data classification with reasonable processing time.},
  archive      = {J_CC},
  author       = {Jagadeesan, J. and D., Subashree and Kirupanithi, D. Nancy},
  doi          = {10.1007/s12559-023-10176-x},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2152-2174},
  shortjournal = {Cogn. Comput.},
  title        = {An optimized ensemble support vector machine-based extreme learning model for real-time big data analytics and disaster prediction},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bifurcation analysis of a fractional-order bidirectional
associative memory neural network with multiple delays. <em>CC</em>,
<em>15</em>(6), 2132–2151. (<a
href="https://doi.org/10.1007/s12559-023-10178-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bidirectional associative memory (BAM) neural network has the capability to store hetero-associative pattern pairs, which has high requirements for stability. This paper inquires into Hopf bifurcation of fractional-order bidirectional associative memory neural network (FOBAMNN) and implants three types of delays into the FOBAMNN. Namely leakage delay, self-connection delay, and communication delay, both of which are unequal. Drawing support from matrix eigenvalue theory, stability theory of fractional differential equations and bifurcation technology, The delay-dependent stability criterion and bifurcation point of the model are established by exploiting the characteristic polynomial. Afterwards, the self-connection delay or leakage delay is selected as the bifurcation parameter, and the unselected delay of the two is fixed in its stable interval, so as to obtain the condition of bifurcation. The results show that different types of delay affect the stability of the system. Simultaneously, once the delay outreaches the critical value of bifurcation, the stability of the model will be wrecked. Thereupon, in the application, we should adopt small delays to maintain the stability of the system. We illustrate that the leakage delay and self-connection delay can affect the stability of FOBAMNN. And the calculation method of the critical value of the delay will also be given. At length, the authenticity of the developed key fruits is  elucidated via numerical simulations.},
  archive      = {J_CC},
  author       = {Wang, Huanan and Huang, Chengdai and Cao, Jinde and Abdel-Aty, Mahmoud},
  doi          = {10.1007/s12559-023-10178-9},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2132-2151},
  shortjournal = {Cogn. Comput.},
  title        = {Bifurcation analysis of a fractional-order bidirectional associative memory neural network with multiple delays},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A perceptually adaptive long-term tracking method for the
complete occlusion and disappearance of a target. <em>CC</em>,
<em>15</em>(6), 2120–2131. (<a
href="https://doi.org/10.1007/s12559-023-10173-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, tracking algorithms based on correlation filtering have been widely considered because of their high real-time performance. However, most of these algorithms do not consider the reliability of tracking results; thus, model drift is often a challenge in long-term target tracking. Moreover, the target is significantly occluded or disappears in long-term target tracking, hence the need for research to address such complexities. This paper proposes a long-term tracking framework comprising a tracking and re-detection module. The tracking module is based on the efficient convolution operator target-tracking algorithm (ECO) (Danelljan et al. in Proc IEEE Conf Comput Vis Pattern Recognit, 1). To redetect a lost target, a tracking uncertainty estimation method is developed that evaluates the tracking results of each image. Furthermore, an adaptive model-updating method is proposed, which can reduce the number of model updates and improve the robustness of the tracking algorithm. The model is inspired by long and short-term memory pool mechanisms of the brain, applying both mechanisms to the traditional tracking algorithm to improve long-term tracking. The memory model is effectively integrated into a brain-inspired visual long-term tracker through mutual learning and inspiration from computer and biological vision. In addition, the brain-inspired visual model can be made bio-cognitive on a small hardware platform with limited computing power. Central processing unit (CPU)-based experiments using two data sets, UAV20L (Mueller et al. in Eur Conf Comput Vision, 2) and UAV123 (Wu et al. in Proc IEEE Conf Comput Vis Pattern Recognit, 3), confirmed that the proposed method runs faster than 30fps. Furthermore, the long-term tracking test using the UAV20L data set showed that the proposed method performs better than any other method by 39%. Compared with conventional tracking methods, the proposed method has better performance in terms of coverage rate and positioning accuracy.},
  archive      = {J_CC},
  author       = {Chen, Lu and Li, Gun and Zhao, Kunqi and Zhang, Guiping and Zhu, Xingyu},
  doi          = {10.1007/s12559-023-10173-0},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2120-2131},
  shortjournal = {Cogn. Comput.},
  title        = {A perceptually adaptive long-term tracking method for the complete occlusion and disappearance of a target},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel weighted averaging operator of linguistic
interval-valued intuitionistic fuzzy numbers for cognitively inspired
decision-making. <em>CC</em>, <em>15</em>(6), 2101–2119. (<a
href="https://doi.org/10.1007/s12559-023-10167-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An aggregation operator of linguistic interval-valued intuitionistic fuzzy numbers (LIVIFNs) is an important tool for solving cognitively inspired decision-making problems with LIVIFNs. So far, many aggregation operators of LIVIFNs have been presented. Each of these operators works well in its specific context. But they are not always monotone because their operational rules are not always invariant and persistent. Dempster-Shafer evidence theory, a general framework for modelling epistemic uncertainty, was found to provide the capability for operational rules of fuzzy numbers to overcome these limitations. In this paper, a weighted averaging operator of LIVIFNs based on Dempster-Shafer evidence theory for cognitively inspired decision-making is proposed. Firstly, Dempster-Shafer evidence theory is introduced into linguistic interval-valued intuitionistic fuzzy environment and a definition of LIVIFNs under this theory is given. Based on this, four novel operational rules of LIVIFNs are developed and proved to be always invariant and persistent. Using the developed operational rules, a new weighted averaging operator of LIVIFNs is constructed and proved to be always monotone. Based on the constructed operator, a method for solving cognitively inspired decision-making problems with LIVIFNs is presented. The application of the presented method is illustrated via a numerical example. The effectiveness and advantage of the method are demonstrated via quantitative comparisons with several existing methods. For the numerical example, the best alternative determined by the presented method is exactly the same as that determined by other comparison methods. For some specific problems, only the presented method can generate intuitive ranking results. The demonstration results suggest that the presented method is effective in solving cognitively inspired decision-making problems with LIVIFNs. Furthermore, the method will not produce counterintuitive ranking results since its operational rules are always invariant and persistent and its aggregation operator is always monotone.},
  archive      = {J_CC},
  author       = {Qin, Yuchu and Qi, Qunfen and Shi, Peizhi and Scott, Paul J. and Jiang, Xiangqian},
  doi          = {10.1007/s12559-023-10167-y},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2101-2119},
  shortjournal = {Cogn. Comput.},
  title        = {A novel weighted averaging operator of linguistic interval-valued intuitionistic fuzzy numbers for cognitively inspired decision-making},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic gesture recognition based on deep 3D natural
networks. <em>CC</em>, <em>15</em>(6), 2087–2100. (<a
href="https://doi.org/10.1007/s12559-023-10177-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The process of establishing contact with a computer through gestures still faces many bottlenecks that need to be solved, one of which is how to accurately recognize dynamic gestures. The traditional 3D convolution operation is transformed into a separable convolution operation based on separable convolution. The larger convolution kernel is transformed into smaller convolution and point convolution operations in the depth direction of the input data. The purpose of extracting and modeling the features of the input data is achieved, as well as the purpose of reducing the amount of calculation for the 3D convolution operation. Therefore, a long and short time memory network (which is more sensitive to temporal features) is introduced in the underlying network structure to memorize and model the relevant temporal information. Additionally, in order to overcome the adverse effects of the external background environment, an attention mechanism is also introduced into the structure to achieve suppression of the irrelevant background. On the basis of the existing research, by fusing the information of different modalities, the designed related experiments verify that the fusion operation is better than the recognition effect of single-modal information in dynamic gesture tasks. The experimental results show that three network structures, the efficient extraction of dynamic gesture features, and better recognition performance on the validation set of the IsoGD dataset can all be achieved. We propose a new method for dynamic gesture recognition, and the proposed model effectively improves the accuracy of gesture recognition.},
  archive      = {J_CC},
  author       = {Tie, Yun and Zhang, Xunlei and Chen, Jie and Qi, Lin and Tie, Jiessie},
  doi          = {10.1007/s12559-023-10177-w},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2087-2100},
  shortjournal = {Cogn. Comput.},
  title        = {Dynamic gesture recognition based on deep 3D natural networks},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of cognitive test scores from variable length
multimodal data in alzheimer’s disease. <em>CC</em>, <em>15</em>(6),
2062–2086. (<a
href="https://doi.org/10.1007/s12559-023-10169-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) is a neurogenerative condition characterized by sharp cognitive decline with no confirmed effective treatment or cure. This makes it critically important to identify the symptoms of Alzheimer’s disease in its early stages before significant cognitive deterioration has taken hold and even before any brain morphology and neuropathology are noticeable. In this study, five different multimodal deep neural networks (MDNN), with different architectures, in search of an optimal model for predicting the cognitive test scores for the Mini-Mental State Examination (MMSE) and the modified Alzheimer’s Disease Assessment Scale (ADAS-CoG13) over a span of 60 months (5 years). The multimodal data utilized to train and test the proposed models were obtained from the Alzheimer’s Disease Neuroimaging Initiative study and includes cerebrospinal fluid (CSF) levels of tau and beta-amyloid, structural measures from magnetic resonance imaging (MRI), functional and metabolic measures from positron emission tomography (PET), and cognitive scores from the neuropsychological tests (Cog). The models developed herein delve into two main issues: (1) application merits of single-task vs. multitask for predicting future cognitive scores and (2) whether time-varying input data are better suited than specific timepoints for optimizing prediction results. This model yields a high of 90.27% (SD = 1.36) prediction accuracy (correlation) at 6 months after the initial visit to a lower 79.91% (SD = 8.84) prediction accuracy at 60 months. The analysis provided is comprehensive as it determines the predictions at all other timepoints and all MDNN models include converters in the CN and MCI groups (CNc, MCIc) and all the unstable groups in the CN and MCI groups (CNun and MCIun) that reverted to CN from MCI and to MCI from AD, so as not to bias the results. The results show that the best performance is achieved by a multimodal combined single-task long short-term memory (LSTM) regressor with an input sequence length of 2 data points (2 visits, 6 months apart) augmented with a pretrained Neural Network Estimator to fill in for the missing values.},
  archive      = {J_CC},
  author       = {Morar, Ulyana and Martin, Harold and M., Robin P. and Izquierdo, Walter and Zarafshan, Elaheh and Forouzannezhad, Parisa and Unger, Elona and Cabrerizo, Mercedes and Curiel Cid, Rosie E. and Rosselli, Monica and Barreto, Armando and Rishe, Naphtali and Vaillancourt, David E. and DeKosky, Steven T. and Loewenstein, David and Duara, Ranjan and Adjouadi, Malek},
  doi          = {10.1007/s12559-023-10169-w},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2062-2086},
  shortjournal = {Cogn. Comput.},
  title        = {Prediction of cognitive test scores from variable length multimodal data in alzheimer’s disease},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MCCFNet: Multi-channel color fusion network for cognitive
classification of traditional chinese paintings. <em>CC</em>,
<em>15</em>(6), 2050–2061. (<a
href="https://doi.org/10.1007/s12559-023-10172-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computational modeling and analysis of traditional Chinese painting rely heavily on cognitive classification based on visual perception. This approach is crucial for understanding and identifying artworks created by different artists. However, the effective integration of visual perception into artificial intelligence (AI) models remains largely unexplored. Additionally, the classification research of Chinese painting faces certain challenges, such as insufficient investigation into the specific characteristics of painting images for author classification and recognition. To address these issues, we propose a novel framework called multi-channel color fusion network (MCCFNet), which aims to extract visual features from diverse color perspectives. By considering multiple color channels, MCCFNet enhances the ability of AI models to capture intricate details and nuances present in Chinese painting. To improve the performance of the DenseNet model, we introduce a regional weighted pooling (RWP) strategy specifically designed for the DenseNet169 architecture. This strategy enhances the extraction of highly discriminative features. In our experimental evaluation, we comprehensively compared the performance of our proposed MCCFNet model against six state-of-the-art models. The comparison was conducted on a dataset consisting of 2436 TCP samples, derived from the works of 10 renowned Chinese artists. The evaluation metrics employed for performance assessment were Top-1 Accuracy and the area under the curve (AUC). The experimental results have shown that our proposed MCCFNet model significantly outperform all other benchmarking methods with the highest classification accuracy of 98.68%. Meanwhile, the classification accuracy of any deep learning models on TCP can be much improved when adopting our proposed framework.},
  archive      = {J_CC},
  author       = {Geng, Jing and Zhang, Xin and Yan, Yijun and Sun, Meijun and Zhang, Huiyuan and Assaad, Maher and Ren, Jinchang and Li, Xiaoquan},
  doi          = {10.1007/s12559-023-10172-1},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2050-2061},
  shortjournal = {Cogn. Comput.},
  title        = {MCCFNet: Multi-channel color fusion network for cognitive classification of traditional chinese paintings},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AS-3DFCN: Automatically seeking 3DFCN-based brain tumor
segmentation. <em>CC</em>, <em>15</em>(6), 2034–2049. (<a
href="https://doi.org/10.1007/s12559-023-10168-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural network, an optimization technique inspired by biological visual cortex, is widely used in pattern recognition, information processing, and other fields, and it has a good ability to solve nonlinear problems. However, there are some disadvantages, such as its uninterpretability, high computational cost, and GPU consumption, which make its structural design difficult. As a result, the existing neural networks require manual design by experts, and numerous experiments have been conducted to assess their effectiveness. In order to reduce the difficulty of designing neural networks manually, and to design more effective networks to solve problems, we propose a model for automatically seeking 3D fully convolutional network (AS-3DFCN) based on genetic algorithm. Firstly, we suggest an AS-3DFCN that defines the search space as a directed graph. Secondly, in order to improve the segmentation accuracy of our model for brain tumor images, the genetic algorithm is applied to search an ideal topology network. Finally, we evaluate the effectiveness of our proposed algorithm using the MICCAI-BraTS2018-2020 public datasets. After comparing with other manually designed fully convolutional networks, our method outperforms many other advanced methods, with average Dice coefficients of 84.7, 83.1, and 83.3; average Hausdorff measures of 4.32, 4.88, and 13.5; and parameter quantities of only 5.34M. It has also shown that our model has fewer parameters, can automatically seek the optimum network topology, and can segment brain tumor images more accurately.},
  archive      = {J_CC},
  author       = {Liu, Ruihua and Nan, Haoyu and Zou, Yangyang and Xie, Ting},
  doi          = {10.1007/s12559-023-10168-x},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2034-2049},
  shortjournal = {Cogn. Comput.},
  title        = {AS-3DFCN: Automatically seeking 3DFCN-based brain tumor segmentation},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Snapture—a novel neural architecture for combined static and
dynamic hand gesture recognition. <em>CC</em>, <em>15</em>(6),
2014–2033. (<a
href="https://doi.org/10.1007/s12559-023-10174-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As robots are expected to get more involved in people’s everyday lives, frameworks that enable intuitive user interfaces are in demand. Hand gesture recognition systems provide a natural way of communication and, thus, are an integral part of seamless human-robot interaction (HRI). Recent years have witnessed an immense evolution of computational models powered by deep learning. However, state-of-the-art models fall short of expanding across different gesture domains, such as emblems and co-speech. In this paper, we propose a novel hybrid hand gesture recognition system. Our Snapture architecture enables learning both static and dynamic gestures: by capturing a so-called snapshot of the gesture performance at its peak, we integrate the hand pose and the dynamic movement. Moreover, we present a method for analyzing the motion profile of a gesture to uncover its dynamic characteristics, which allows regulating a static channel based on the amount of motion. Our evaluation demonstrates the superiority of our approach on two gesture benchmarks compared to a state-of-the-art CNNLSTM baseline. Our analysis on a gesture class basis unveils the potential of our Snapture architecture for performance improvements using RGB data. Thanks to its modular implementation, our framework allows the integration of other multimodal data, like facial expressions and head tracking, which are essential cues in HRI scenarios, into one architecture. Thus, our work contributes both to integrative gesture recognition research and machine learning applications for non-verbal communication with robots.},
  archive      = {J_CC},
  author       = {Ali, Hassan and Jirak, Doreen and Wermter, Stefan},
  doi          = {10.1007/s12559-023-10174-z},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2014-2033},
  shortjournal = {Cogn. Comput.},
  title        = {Snapture—a novel neural architecture for combined static and dynamic hand gesture recognition},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel, cognitively inspired, unified graph-based
multi-task framework for information extraction. <em>CC</em>,
<em>15</em>(6), 2004–2013. (<a
href="https://doi.org/10.1007/s12559-023-10163-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information extraction (IE) transforms unstructured textual sources into structured knowledge, closely resembling human reasoning. IE involves several subtasks, such as named entity recognition (NER), relation extraction (RE), and coreference resolution (CR). The early IE models tend to treat each subtask as a separate task or to apply a sequential pipeline approach, which can lead to cascading errors and obfuscation of the inherent relationship between tasks. Recent research has shown that it is advantageous to incorporate the interdependence of subtasks and optimize performance through joint learning. However, they do not properly model the interaction between tasks, either by modeling the subtasks sequentially or by using shared input data. Inspired by human reasoning, a graph-based multitask IE framework is presented that facilitates the interaction between several IE tasks capable of capturing both local and global information. Graphs were constructed by selecting the most confident entity spans and coupling them with a confidence-weighted relation type and a confidence-weighted coreference. Additionally, in the study, a dynamic span graph approach was employed, where span updates were propagated across both the coreference and the relation graph. This allowed useful information to be learned from a broader context by enhancing interaction across different IE tasks. The input data were globally shared, and the interaction between subtasks was fully exploited, avoiding cascading errors. Experiments demonstrate that the proposed multitask IE framework outperforms the state-of-the-art in multiple information extraction tasks spanning a variety of datasets. The relative error reductions range from 0.19 to 3.74%. This paper presents the feasibility of a cognitively-inspired unified graph-based information extraction framework, which is shown to achieve state-of-the-art results on multiple IE tasks across various domains. The framework’s ability to enhance interaction across tasks allows it to learn valuable information from a broader context.},
  archive      = {J_CC},
  author       = {Zheng, Yandan and Tuan, Luu Anh},
  doi          = {10.1007/s12559-023-10163-2},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2004-2013},
  shortjournal = {Cogn. Comput.},
  title        = {A novel, cognitively inspired, unified graph-based multi-task framework for information extraction},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A cognitive uncertainty calculation method based on
probabilistic linguistic term set and applications in geopolitical risk
assessment. <em>CC</em>, <em>15</em>(6), 1988–2003. (<a
href="https://doi.org/10.1007/s12559-023-10166-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Risk is essentially uncertain, including objective uncertainty of natural attributes and subjective uncertainty of human cognition. The latter is associated with human cognitive thinking and social consciousness, making it challenging to quantify and articulate. Therefore, appropriately managing cognitive uncertainty is essential to achieve successful risk management. In situations involving political environments, decision-makers may rely on judgment or other qualitative information, which can be less reliable or more subjective. Therefore, using cognitive computing methods can provide significant benefits in quantifying and managing cognitive uncertainty. We propose a novel approach that utilizes a probabilistic linguistic quantification method for qualitative evaluation information. This method accounts for both the cognitive uncertainty and statistical uncertainty of decision-makers. To quantify the practical cognitive risk context in the risk evaluation, we propose a new probabilistic linguistic distance measure that quantifies the influence of experts’ subjective preference context in the risk environment. Furthermore, to represent both the risk-averse attitudes and the cognitive uncertainty context of the decision-makers, we propose an improved version of the prospect theory, which considers. This enables a more accurate representation of the practical cognitive decision-making processes. Subsequently, we construct a cognitive uncertainty evaluation model based on the probabilistic linguistic measurement and apply it to comprehensive risk assessment for geopolitical environments. Analysis of the risk assessment outcomes and comparative experiments indicate that the proposed methods can quantitatively assess and calculate decision-makers’ cognitive risk preferences while providing more accurate risk assessment outcomes. This study offers a novel and convenient tool to research risk evaluations focused on cognitive uncertainties.},
  archive      = {J_CC},
  author       = {Zhang, Yaojia and Gong, Zaiwu and Hao, Zhinan and Xu, Jing},
  doi          = {10.1007/s12559-023-10166-z},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1988-2003},
  shortjournal = {Cogn. Comput.},
  title        = {A cognitive uncertainty calculation method based on probabilistic linguistic term set and applications in geopolitical risk assessment},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning sentiment-enhanced word representations by fusing
external hybrid sentiment knowledge. <em>CC</em>, <em>15</em>(6),
1973–1987. (<a
href="https://doi.org/10.1007/s12559-023-10164-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Word representation learning is a fundamental technique in cognitive computation that plays a crucial role in enabling machines to understand and process human language. By representing words as vectors in a high-dimensional space, computers can perform complex natural language processing tasks such as sentiment analysis. However, most word representation learning models are trained in open-domain corpora, which results in suboptimal performance in domain-specific tasks. To address this problem, we propose a unified learning framework that leverages external hybrid sentiment knowledge to enhance the sentiment information of word distributed representations. Specifically, we automatically acquire domain- and target-dependent sentiment knowledge from multiple sources. To mitigate knowledge noise, we introduce knowledge expectation and knowledge context weights to filter the acquired knowledge items. Finally, we integrate the filtered sentiment knowledge into the word distributed representations via a learning framework to enrich their semantic information. Extensive experiments are conducted to verify the effectiveness of enhancing sentiment information in word representations for different sentiment analysis tasks. The experimental results show that the proposed models significantly outperform state-of-the-art baselines. Our work demonstrates the advantages of sentiment-enhanced word representations in sentiment analysis tasks and provides insights into the acquisition and fusion of sentiment knowledge from different domains for generating word representations with richer semantics.},
  archive      = {J_CC},
  author       = {Li, You and Lin, Zhizhou and Lin, Yuming and Yin, Jinhui and Chang, Liang},
  doi          = {10.1007/s12559-023-10164-1},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1973-1987},
  shortjournal = {Cogn. Comput.},
  title        = {Learning sentiment-enhanced word representations by fusing external hybrid sentiment knowledge},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combining informative regions and clips for detecting
depression from facial expressions. <em>CC</em>, <em>15</em>(6),
1961–1972. (<a
href="https://doi.org/10.1007/s12559-023-10157-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence methods are widely applied to depression recognition and provide an objective solution. Many effective automated methods for detecting depression use facial expressions, which are strong indicators of psychiatric disorders. However, existing approaches ignore the uneven distribution of depression information in time and space. Therefore, these approaches have limitations in their ability to form discriminative depression representations. In this paper, we propose a framework based on information regions and clips for depression detection. Specifically, we first divide the regions of interest (ROIs), which are regarded as spatially informative regions, according to pathological knowledge of depression. Following this, the local-MHHLBP-BiLSTM (LMB) module is proposed as a feature extractor to exploit short-term and long-term temporal information. Finally, an improved attention mechanism with a balancing factor is introduced into LMB to increase attention to information segments. The proposed model performs tenfold cross-validation on our 150-subject video dataset and outperforms most state-of-the-art approaches with accuracy = 0.757, precision = 0.767, recall = 0.786, and F1 score = 0.761. The obtained results demonstrate that focusing on information regions, and clips can effectively reduce the error in depression diagnosis. More importantly, we observe that the area near the eye is fairly informative and that depressed individuals blink more frequently.},
  archive      = {J_CC},
  author       = {Yuan, Xiaoyan and Liu, Zhenyu and Chen, Qiongqiong and Li, Gang and Ding, Zhijie and Shangguan, Zixuan and Hu, Bin},
  doi          = {10.1007/s12559-023-10157-0},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1961-1972},
  shortjournal = {Cogn. Comput.},
  title        = {Combining informative regions and clips for detecting depression from facial expressions},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fine-grained truck re-identification: A challenge.
<em>CC</em>, <em>15</em>(6), 1947–1960. (<a
href="https://doi.org/10.1007/s12559-023-10162-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In intelligent transportation and smart city, truck re-identification (Re-ID) is a crucial task in controlling traffic violations of laws and regulations, especially in the absence of satellite positioning and license plate information. There are many specific fine-grained types in trucks compared to common person and vehicle Re-ID, which hinders the direct application of person and vehicle Re-ID methods to truck Re-ID. In this work, we contribute a new truck image dataset, named Truck-ID, for truck Re-ID specifically. The dataset contains 32,353 images of trucks from 7 monitoring sites of real traffic surveillance, including 13,137 license plate IDs. According to the difficulty of truck Re-ID, the gallery of Truck-ID dataset is further divided into three sub-datasets to evaluate the quality of different truck Re-ID models more comprehensively. Furthermore, we propose an effective Double Granularity Network (DGN) for truck Re-ID, which considers both global and local features of truck by focusing on truck head and body separately. Experiments show that DGN can effectively integrate global and local features to achieve robust fine-grained truck Re-ID. Our work provides a benchmark dataset for truck Re-ID and a baseline network for both research and industrial communities. The Truck-ID dataset and DGN codes are available at: https://pan.baidu.com/s/18Vc6NOiipGLLvcKj8U75Hw . Although the proposed DGN is relatively simple and easy to implement, it is effective in learning discriminative features of trucks and has remarkable performance in targeting truck re-identification. The Truck-ID dataset we made can promote the development of re-identification in the truck field.},
  archive      = {J_CC},
  author       = {Chen, Si-Bao and Lin, Zi-Han and Ding, Chris H. Q. and Luo, Bin},
  doi          = {10.1007/s12559-023-10162-3},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1947-1960},
  shortjournal = {Cogn. Comput.},
  title        = {Fine-grained truck re-identification: A challenge},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep triply attention network for RGBT tracking.
<em>CC</em>, <em>15</em>(6), 1934–1946. (<a
href="https://doi.org/10.1007/s12559-023-10158-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-Thermal (RGBT) tracking has gained significant attention in the field of computer vision due to its wide range of applications in video surveillance, autonomous driving, and human-computer interaction. This paper focuses on achieving a robust fusion of different modalities for RGBT tracking through attention modeling. We propose an effective triply attentive network for robust RGBT tracking, which consists of a local attention module, a cross-modality co-attention module, and a global attention module. The local attention module enables the tracker to focus on target regions while considering background interference, generated through backpropagation of the score map with respect to the RGB and thermal image pair. To enhance the interaction of different modalities in feature learning, we introduce a co-attention module that selects more discriminative features for both the visible (RGB) and thermal modalities simultaneously. To compensate for the limitations of local sampling, we incorporate a global attention module based on multi-modal information to compute high-quality global proposals. This module not only complements the local search strategy but also re-tracks lost targets when they come back into view. Extensive experiments conducted on three RGBT tracking datasets demonstrate that our proposed method outperforms other RGBT trackers, achieving more competitive results. Specifically, on the LasHeR dataset, the precision rate, normalized precision rate, and success rate reach 57.5%, 51.6%, and 41.0%, respectively. The above state-of-the-art experimental results confirm the effectiveness of our method in exploring the complementary advantages between modalities and achieving robust visual tracking.},
  archive      = {J_CC},
  author       = {Yang, Rui and Wang, Xiao and Zhu, Yabin and Tang, Jin},
  doi          = {10.1007/s12559-023-10158-z},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1934-1946},
  shortjournal = {Cogn. Comput.},
  title        = {Deep triply attention network for RGBT tracking},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A benchmark dual-modality dental imaging dataset and a novel
cognitively inspired pipeline for high-resolution dental point cloud
synthesis. <em>CC</em>, <em>15</em>(6), 1922–1933. (<a
href="https://doi.org/10.1007/s12559-023-10161-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical 3D models based on point cloud data have important medical implications in orthodontics, oral cultivation, dental restoration, and surgical navigation. The dental 3D models are usually obtained by cone beam computed tomography (CBCT) image reconstruction or intraoral scanning. Due to the cost and the resolution limit of different collecting devices, the final 3D point cloud dataset is often unable to achieve an ideal resolution. Especially in the process of reconstructing dental 3D models by CBCT, the data quality of the point cloud can often be negatively affected by the limited physical resolution, the mutual occlusion of target tissues, and the inaccuracy of the reconstruction algorithm. As a consequence, the point cloud reconstructed from CBCT is often sparse, uneven, and noisy with low resolution. We develop a novel cognitive-inspired CBCT-to-intraoral scanning imaging pipeline named Image to Dental point cloud (I2DP) using cognitively inspired crown segmentation and point cloud upsampling techniques. Since there is no publicly available dual-modality paired dental dataset, we implement our method on the private Fudan dual-modality dental imaging (FDDI) dataset. The FDDI dataset includes 66 paired data of CBCT dental 3D models and intraoral scanning dental 3D models. We show that the 3D mesh surface model reconstructed from PU-GCN with a dense oral scanning input achieves satisfactory smoothness, which demonstrates the effectiveness of our I2DP pipeline. The FDDI dataset, as a dual-modality benchmark dataset, provides a benchmark for the point cloud upsampling task, which in turn facilitates the development of novel algorithms for the tooth point cloud segmentation, registration, and many other tasks.},
  archive      = {J_CC},
  author       = {Yu, Zekuan and Li, Meijia and Yang, Jiacheng and Chen, Zilong and Zhang, Huixian and Liu, Weifan and Han, Fang Kai and Liu, Jie},
  doi          = {10.1007/s12559-023-10161-4},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1922-1933},
  shortjournal = {Cogn. Comput.},
  title        = {A benchmark dual-modality dental imaging dataset and a novel cognitively inspired pipeline for high-resolution dental point cloud synthesis},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cognitively enhanced versions of capuchin search algorithm
for feature selection in medical diagnosis: A COVID-19 case study.
<em>CC</em>, <em>15</em>(6), 1884–1921. (<a
href="https://doi.org/10.1007/s12559-023-10149-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) is a crucial area of cognitive computation that demands further studies. It has recently received a lot of attention from researchers working in machine learning and data mining. It is broadly employed in many different applications. Many enhanced strategies have been created for FS methods in cognitive computation to boost the performance of the methods. The goal of this paper is to present three adaptive versions of the capuchin search algorithm (CSA) that each features a better search ability than the parent CSA. These versions are used to select optimal feature subset based on a binary version of each adapted one and the k-Nearest Neighbor (k-NN) classifier. These versions were matured by applying several strategies, including automated control of inertia weight, acceleration coefficients, and other computational factors, to ameliorate search potency and convergence speed of CSA. In the velocity model of CSA, some growth computational functions, known as exponential, power, and S-shaped functions, were adopted to evolve three versions of CSA, referred to as exponential CSA (ECSA), power CSA (PCSA), and S-shaped CSA (SCSA), respectively. The results of the proposed FS methods on 24 benchmark datasets with different dimensions from various repositories were compared with other k-NN based FS methods from the literature. The results revealed that the proposed methods significantly outperformed the performance of CSA and other well-established FS methods in several relevant criteria. In particular, among the 24 datasets considered, the proposed binary ECSA, which yielded the best overall results among all other proposed versions, is able to excel the others in 18 datasets in terms of classification accuracy, 13 datasets in terms of specificity, 10 datasets in terms of sensitivity, and 14 datasets in terms of fitness values. Simply put, the results on 15, 9, and 5 datasets out of the 24 datasets studied showed that the performance levels of the binary ECSA, PCSA, and SCSA are over 90% in respect of specificity, sensitivity, and accuracy measures, respectively. The thorough results via different comparisons divulge the efficiency of the proposed methods in widening the classification accuracy compared to other methods, ensuring the ability of the proposed methods in exploring the feature space and selecting the most useful features for classification studies.},
  archive      = {J_CC},
  author       = {Braik, Malik and Awadallah, Mohammed A. and Al-Betar, Mohammed Azmi and Hammouri, Abdelaziz I. and Alzubi, Omar A.},
  doi          = {10.1007/s12559-023-10149-0},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1884-1921},
  shortjournal = {Cogn. Comput.},
  title        = {Cognitively enhanced versions of capuchin search algorithm for feature selection in medical diagnosis: A COVID-19 case study},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lightweight multi-modal representation learning for RGB
salient object detection. <em>CC</em>, <em>15</em>(6), 1868–1883. (<a
href="https://doi.org/10.1007/s12559-023-10148-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of salient object detection (SOD) often faces various challenges such as complex backgrounds and low appearance contrast. Depth information, which reflects the geometric shape of an object’s surface, can be used as a supplement to visible information and receives increasing interest in SOD. However, depth sensors suffer from limited conditions and range (e.g., 4–5 ms at most in indoor scenes), and the imaging quality is usually low. We design a lightweight network in order to infer depth features while reducing computational complexities, which only needs a few parameters to effectively capture depth-specific features by fusing high-level features from the RGB modality. Both RGB features and inferred depth features might contain noises, and thus we design a fusion network, which includes a self-attention-based feature interaction module and a foreground-background enhancement module, to achieve an adaptive fusion of RGB and depth features. In addition, we introduce a multi-scale fusion module with different dilated convolutions to leverage useful local and global context clues. Experimental results on five benchmark datasets show that our approach significantly outperforms the state-of-the-art RGBD SOD methods, and also performs comparably against the state-of-the-art RGB SOD methods. The experimental results show that our multi-modal representation learning method can deal with the imaging limitations of single-modality data for RGB salient object detection, and the experimental results on multiple RGBD and RGB SOD datasets illustrate the effectiveness of our method.},
  archive      = {J_CC},
  author       = {Xiao, Yun and Huang, Yameng and Li, Chenglong and Liu, Lei and Zhou, Aiwu and Tang, Jin},
  doi          = {10.1007/s12559-023-10148-1},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1868-1883},
  shortjournal = {Cogn. Comput.},
  title        = {Lightweight multi-modal representation learning for RGB salient object detection},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Insight into hopf bifurcation and control methods in
fractional order BAM neural networks incorporating symmetric structure
and delay. <em>CC</em>, <em>15</em>(6), 1825–1867. (<a
href="https://doi.org/10.1007/s12559-023-10155-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The trait of solution, bifurcation mechanism, and stability of delayed BAM neural network models have attracted great attention from many scholars. But the exploration about the stability aspect and bifurcation mechanism of fractional delayed BAM neural network models is relatively few. This work will focus on the stability aspect and bifurcation mechanism of fractional delayed BAM neural network models. Lipschitz condition, Laplace transform, construction of a proper function, stability criterion, and bifurcation principle of fractional delayed dynamical system, delayed feedback controller, dislocated feedback controller, and Matlab simulation technique are exploited. The criteria on the boundedness, existence, and uniqueness of solutions to fractional delayed BAM neural network models are gained. A new delay-independent bifurcation criterion and stability of the formulated neural network models is acquired. Delayed feedback controller and dislocated feedback controller are effectually utilized to dominate the time of generation of bifurcation and stability domain of the formulated neural network models. MATLAB simulation experiments are provided to substantiate the acquired primary outcomes. The gained theoretical outcomes of this article possess tremendous theoretical significance in devising and running the fractional delayed BAM neural network models.},
  archive      = {J_CC},
  author       = {Li, Peiluan and Lu, Yuejing and Xu, Changjin and Ren, Jing},
  doi          = {10.1007/s12559-023-10155-2},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1825-1867},
  shortjournal = {Cogn. Comput.},
  title        = {Insight into hopf bifurcation and control methods in fractional order BAM neural networks incorporating symmetric structure and delay},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The antagonistic alterations of cerebellar functional
segregation and integration in athletes with fast demands of
visual-motor coordination. <em>CC</em>, <em>15</em>(6), 1813–1824. (<a
href="https://doi.org/10.1007/s12559-023-10150-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theoretical foundation of brain-computer interface partly lies in the neural mechanism of motor function plasticity. There has been extensive research on the functional neuroplasticity induced by motor skill training in the human cerebral cortex; however, less is known about the specifics within the cerebellum. The present study employed resting-state functional magnetic resonance imaging (fMRI) data from athletes and matched non-athlete controls to investigate the adaptation of cerebellar functional segregation and integration in athletes who require rapid visual-motor coordination. First, this study utilized a data-driven blind-deconvolution hemodynamic response functions (HRF) retrieval technique to estimate voxel-wise HRF that represent local functional segregation. Second, the study quantified effective connectivity using conditional Granger causality (CGC) analysis as a means of characterizing directed functional integration. Lastly, the logistic regression classification model was applied to evaluating the importance of those significant features in two groups’ comparison. The athletes exhibited greater HRF response heights in the visual-spatial cognitive regions, but lower excitatory/inhibitory effects between these regions and the motor execution areas in the cerebellum when compared to the control group. These findings suggested that there was improved local functional segregation within the visual-spatial cognitive regions, as well as reduced functional integration between these regions and the motor execution areas in the cerebellum among athletes. Our results suggested the antagonistic alterations of cerebellar functional segregation and integration induced by motor skill training, and consequently to accelerate the reaction, movement planning, and execution in athletes who required fast demands of visual-motor coordination. Our findings shed new light on how motor skill training drove neuroplasticity within the cerebellum and offered a deeper understanding of the complementary hypotheses of neural efficiency and neural proficiency that underlay optimal athletic performance.},
  archive      = {J_CC},
  author       = {Zhou, Weiqi and Wu, Jueyan and Li, Yan and Li, Jie and Sun, Mengli and Li, Rong and Yang, Chengbo and Zhang, Mu and Gong, Lisha and Yu, Jiali and Leng, Jinsong and Chen, Qin and Lu, Fengmei and Chen, Huafu and Gao, Qing},
  doi          = {10.1007/s12559-023-10150-7},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1813-1824},
  shortjournal = {Cogn. Comput.},
  title        = {The antagonistic alterations of cerebellar functional segregation and integration in athletes with fast demands of visual-motor coordination},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence for cognitive health assessment:
State-of-the-art, open challenges and future directions. <em>CC</em>,
<em>15</em>(6), 1767–1812. (<a
href="https://doi.org/10.1007/s12559-023-10153-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The subjectivity and inaccuracy of in-clinic Cognitive Health Assessments (CHA) have led many researchers to explore ways to automate the process to make it more objective and to facilitate the needs of the healthcare industry. Artificial Intelligence (AI) and machine learning (ML) have emerged as the most promising approaches to automate the CHA process. In this paper, we explore the background of CHA and delve into the extensive research recently undertaken in this domain to provide a comprehensive survey of the state-of-the-art. In particular, a careful selection of significant works published in the literature is reviewed to elaborate a range of enabling technologies and AI/ML techniques used for CHA, including conventional supervised and unsupervised machine learning, deep learning, reinforcement learning, natural language processing, and image processing techniques. Furthermore, we provide an overview of various means of data acquisition and the benchmark datasets. Finally, we discuss open issues and challenges in using AI and ML for CHA along with some possible solutions. In summary, this paper presents CHA tools, lists various data acquisition methods for CHA, provides technological advancements, presents the usage of AI for CHA, and open issues, challenges in the CHA domain. We hope this first-of-its-kind survey paper will significantly contribute to identifying research gaps in the complex and rapidly evolving interdisciplinary mental health field.},
  archive      = {J_CC},
  author       = {Javed, Abdul Rehman and Saadia, Ayesha and Mughal, Huma and Gadekallu, Thippa Reddy and Rizwan, Muhammad and Maddikunta, Praveen Kumar Reddy and Mahmud, Mufti and Liyanage, Madhusanka and Hussain, Amir},
  doi          = {10.1007/s12559-023-10153-4},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1767-1812},
  shortjournal = {Cogn. Comput.},
  title        = {Artificial intelligence for cognitive health assessment: State-of-the-art, open challenges and future directions},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning based traffic prediction method for digital
twin network. <em>CC</em>, <em>15</em>(5), 1748–1766. (<a
href="https://doi.org/10.1007/s12559-023-10136-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network traffic prediction (NTP) can predict future traffic leveraging historical data, which serves as proactive methods for network resource planning, allocation, and management. Besides, NTP can also be applied for load generation in simulated and emulated as well as digital twin networks (DTNs). This paper focuses on accurately predicting background traffic matrix (TM) of typical local area network (LAN) for traffic synchronization in DTN. A survey is firstly conducted on DTN, conventional model, and deep learning based NTP methods. Then, as the major contribution, a linear feature enhanced convolutional long short-term memory (ConvLSTM) model based NTP method is proposed for LAN. An autoregressive unit is integrated into the ConvLSTM model to improve its linear prediction ability. In addition, this paper further optimizes the proposed model from both spatial and channel-wise dimensions. Particularly, a traffic pattern attention (TPA) block and a squeeze &amp; excitation (SE) block are derived and added to the enhanced ConvLSTM (eConvLSTM) model. Comparative experiments demonstrate that the eConvLSTM model outperforms all the baselines. It can improve the prediction accuracy by reducing the mean square error (MSE) up to 10.6% for one-hop prediction and 16.8% for multi-hops prediction, compared to the legacy CovnLSTM model, with still satisfying the efficiency requirements. The further enhancement of the eConvLSTM model can additionally reduce the MSE about 2.1% for one-hop prediction and 4.2% for multi-hops prediction, with slightly degrading efficiency. The proposed eConvLSTM model based NTP method can play a vital role on DTN traffic synchronization.},
  archive      = {J_CC},
  author       = {Lai, Junyu and Chen, Zhiyong and Zhu, Junhong and Ma, Wanyi and Gan, Lianqiang and Xie, Siyu and Li, Gun},
  doi          = {10.1007/s12559-023-10136-5},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1748-1766},
  shortjournal = {Cogn. Comput.},
  title        = {Deep learning based traffic prediction method for digital twin network},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Image retrieval using object semantic aggregation histogram.
<em>CC</em>, <em>15</em>(5), 1736–1747. (<a
href="https://doi.org/10.1007/s12559-023-10143-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulating primates’ ability to make fine visual discriminations for extracting visual features remains a challenge. To address this issue, a novel method was proposed, which was named the object semantic aggregation histogram. By using the developed method, the mid-level object features and high-level semantic features can be aggregated into a discriminative compact representation for image retrieval. The proposed method includes three main highlights: (1) two adaptive semantic kernels were proposed to bridge the object features and semantic features. It can serve as a connecting link for detailed object representation. (2) Both object and semantic features were aggregated to provide a discriminative representation by depicting the target objects, semantic cognition, and spatial layouts. This approach is consistent with the coarse-to-fine nature of perception in the visual hierarchy. (3) A simple yet generic method was introduced to implement dimensionality reduction and whitening. It can provide a good choice of using various regularizations to decide optimal compact representation. Experiments on benchmark datasets confirmed that the proposed method can effectively improve the retrieval performance in terms of mAP. The mAPs of the proposed method using 128-dimensionality representation were significantly greater than that of the CroW, SBA, DSFH, and DTFH methods by 0.042, 0.035, 0.061, and 0.029 on the Oxford5k dataset and by 0.019, 0.017, 0.083, and 0.034 on the Holidays dataset. The proposed method is regarded as an effective and competitive method of aggregating multiple visual hierarchy features, while no complex handcrafting or training is required.},
  archive      = {J_CC},
  author       = {Lu, Fen and Liu, Guang-Hai},
  doi          = {10.1007/s12559-023-10143-6},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1736-1747},
  shortjournal = {Cogn. Comput.},
  title        = {Image retrieval using object semantic aggregation histogram},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Few-shot object detection with weight imprinting.
<em>CC</em>, <em>15</em>(5), 1725–1735. (<a
href="https://doi.org/10.1007/s12559-023-10152-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of few-shot learning is to learn a solution to a problem from limited training samples. In recent years, with the promotion and application of deep neural network–based vision algorithms, the problem of data scarcity has become increasingly prominent. This has prompted comprehensive study on few-shot learning algorithms among academic and industrial communities. This paper first analyzes the bias phenomenon of proposal estimation in the classic transfer learning few-shot object detection paradigm, and then proposes an improved scheme that combines weight imprinting and model decoupling. On the one hand, we extend the weight imprinting algorithm on the general Faster R-CNN framework to enhance the fine-tuning performance; on the other hand, we exploit model decoupling to minimize the over-fitting in data-scarce scenarios. Our proposed method achieves 12.3, 15.0, and 18.9 (nAP) top accuracy on novel set of COCO under 5-shot, 10-shot, and 30-shot settings, and achieves 57.7 and 60.2 (nAP50) top accuracy on novel set of VOC Split 3 under 5-shot and 10-shot settings. Compared with the latest published studies, our proposed method provides a competitive detection performance on novel categories only via fine-tuning. Moreover, it retains the original architecture of the network and is practical in real industrial scenarios.},
  archive      = {J_CC},
  author       = {Yan, Dingtian and Huang, Jitao and Sun, Hai and Ding, Fuqiang},
  doi          = {10.1007/s12559-023-10152-5},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1725-1735},
  shortjournal = {Cogn. Comput.},
  title        = {Few-shot object detection with weight imprinting},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An interpretable neuro-symbolic model for raven’s
progressive matrices reasoning. <em>CC</em>, <em>15</em>(5), 1703–1724.
(<a href="https://doi.org/10.1007/s12559-023-10154-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Raven’s Progressive Matrices (RPM) have been widely used as standard intelligence tests for human participants. Humans solve RPM problems in a hierarchical manner, perceiving conceptual features at different levels and inferring the latent rules governing the matrix using cognitive maps. Although the latest AI algorithms can surpass human performance, little effort has been made to build a model that solves RPM problems in a human-like hierarchical manner. We built a human-like hierarchical neuro-symbolic model to solve RPM problems. The proposed model consists of a semantic-VAE (sVAE) perceptual module and a cognitive map reasoning back-end (CMRB). The supervised sVAE extracts the hierarchical visual features of RPMs by perceiving the structural organization of RPMs through a convolutional neural network and disentangles objects into semantically understandable features. Based on these semantic features, the CMRB predicts the semantic features of objects in the missing field using cognitive maps generated by supervised learning or manually designed. The answer image was generated by sVAE using the semantic features predicted by CMRB. The proposed model achieved state-of-the-art performance on three benchmarks datasets—RAVEN, I-RAVEN, and RAVEN-fair—generalizes well to RPMs containing objects with untrained feature dimensions, mimics human cognitive processes when solving RPM problems, achieves interpretability of their hierarchical processes, and can also be applied to some real-world situations that require abstract visual reasoning.},
  archive      = {J_CC},
  author       = {Zhao, Shukuo and You, Hongzhi and Zhang, Ru-Yuan and Si, Bailu and Zhen, Zonglei and Wan, Xiaohong and Wang, Da-Hui},
  doi          = {10.1007/s12559-023-10154-3},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1703-1724},
  shortjournal = {Cogn. Comput.},
  title        = {An interpretable neuro-symbolic model for raven’s progressive matrices reasoning},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving coronary heart disease prediction through machine
learning and an innovative data augmentation technique. <em>CC</em>,
<em>15</em>(5), 1687–1702. (<a
href="https://doi.org/10.1007/s12559-023-10151-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronary heart disease (CHD) is a leading cause of death globally, with over 382,000 deaths in the USA alone in 2020. The early detection of CHD is critical in reducing mortality rates. Artificial intelligence (AI) is a constantly evolving field of computer science that employs computational models to extract insights from past data and provide rapid and accurate predictions for future cases. This paper presents a novel approach that generates an augmented dataset by selectively duplicating misclassified instances during the leave-one-out cross-validation (CV) process to overfit a model. We used a paired machine learning model with an augmented dataset approach to evaluate several classifiers. The comprehensive heart disease dataset [1] served as our base dataset. Our approach achieved higher accuracy than the base dataset, with the bagged decision tree (DT) algorithm outperforming state-of-the-art models and achieving an accuracy of 97.1% in the 10-fold CV test. Further experiments using the Cleveland dataset and the same 10-fold CV test resulted in an even higher accuracy of 99.2%. Combining an augmented dataset and the bagged-DT algorithm holds great promise for early CHD prediction helping reduce CHD mortality rates. The use of AI in early CHD prediction could potentially make a difference between the life and death of the patient.},
  archive      = {J_CC},
  author       = {Al-Ssulami, Abdulrakeeb M. and Alsorori, Randh S. and Azmi, Aqil M. and Aboalsamh, Hatim},
  doi          = {10.1007/s12559-023-10151-6},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1687-1702},
  shortjournal = {Cogn. Comput.},
  title        = {Improving coronary heart disease prediction through machine learning and an innovative data augmentation technique},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep heuristic evolutionary regression model based on the
fusion of BiGRU and BiLSTM. <em>CC</em>, <em>15</em>(5), 1672–1686. (<a
href="https://doi.org/10.1007/s12559-023-10135-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The input for stock market prediction is usually a period of stock price data with time series characteristics, which will keep changing over time and have more complex background relationships. How to effectively mine and fuse multiple heterogeneous data of the stock market is difficult to be handled by traditional recurrent neural networks (RNN). To solve this problem, we divide the regression model into an encoder and decoder structure. In this paper, we first use RNN technique for missing value complementation, then use the fusion model of bidirectional gate recurrent unit (BiGRU) and bidirectional long short-term memory network (BiLSTM) as the encoder to extract. Finally, the group method of data handling (GMDH) model is used as a decoder to obtain stock market prediction results based on the time series data features. A deep heuristic evolutionary regression model (BBGMDH) based on the fusion of BiGRU and BiLSTM is proposed by the above process. We have conducted extensive experiments on four real stock data, and the results show that BBGMDH significantly outperforms existing methods, verifying the effectiveness of the encoding-decoding stepwise regression model in stock price prediction tasks. The reason is that the encoding layer utilizes the powerful time series data processing technology of RNN to effectively extract the hidden features of stock data, and the decoding layer utilizes the GMDH heuristic evolutionary computation method to simulate the “genetic mutation selection evolution” process of an organism for the regression task of stock market prediction, making full use of their complementary properties. We provide a new solution to the regression prediction problem.},
  archive      = {J_CC},
  author       = {Xu, Lixiang and Xu, Wei and Cui, Qingzhe and Li, Mengying and Luo, Bin and Tang, Yuanyan},
  doi          = {10.1007/s12559-023-10135-6},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1672-1686},
  shortjournal = {Cogn. Comput.},
  title        = {Deep heuristic evolutionary regression model based on the fusion of BiGRU and BiLSTM},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Haptic recognition of texture surfaces using semi-supervised
feature learning based on sparse representation. <em>CC</em>,
<em>15</em>(5), 1656–1671. (<a
href="https://doi.org/10.1007/s12559-023-10141-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Haptic cognitive models are used to map the physical stimuli of texture surfaces to subjective haptic cognition, providing robotic systems with intelligent haptic cognition to perform dexterous manipulations in a manner that is similar to that of humans. Nevertheless, there is still the question of how to extract features that are stable and reflect the biological perceptual characteristics as the inputs of the models. To address this issue, a semi-supervised sparse representation method is developed to predict subjective haptic cognitive intensity in different haptic perceptual dimensions of texture surfaces. We conduct standardized interaction and perception experiments on textures that are part of common objects in daily life. Effective data cues sifting, perceptual filtering, and semi-supervised feature extraction steps are conducted in the process of sparse representation to ensure that the source data and features are complete and effective. The results indicate that the haptic cognitive model using the proposed method performs well in fitting and predicting perceptual intensity in the perceptual dimensions of “hardness,” “roughness,” and “slipperiness” for texture surfaces. Compared with previous methods, such as models using multilayer regression and hand-crafted features, the use of standardized interaction, cue sifting, perceptual filtering, and semi-supervised feature extraction could greatly improve the accuracy by improving the completeness of collected data, the effectiveness of features, and simulations of some physiological cognitive mechanisms. The improved method can be implemented to improve the performance of the haptic cognitive model for texture surfaces, and can also inspire research on intelligent cognition and haptic rendering systems.},
  archive      = {J_CC},
  author       = {Shao, Zhiyu and Bao, Jiatong and Li, Jingwei and Tang, Hongru},
  doi          = {10.1007/s12559-023-10141-8},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1656-1671},
  shortjournal = {Cogn. Comput.},
  title        = {Haptic recognition of texture surfaces using semi-supervised feature learning based on sparse representation},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vehicle re-identification by separating representative
spatial features. <em>CC</em>, <em>15</em>(5), 1640–1655. (<a
href="https://doi.org/10.1007/s12559-023-10145-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a complex image classification problem, re-identification (ReID) requires the model to capture diverse representative features of vehicles through different spatial orientation cameras. However, it has been observed that the existing models tend to focus on extracting features with strong discrimination, while ignoring other valuable spatial features. In addition, the existing methods lack effective suppression of noise caused by spatial variations. Inspired by the observation from the human cognition that, the view and direction of the vehicle can be correctly recognized by human beings with only partial representative spatial features observed, in this paper, we propose a novel method to effectively separate representative spatial (SRS) information and non-spatial region discriminative information of vehicles. First, we specifically use an effective network to extract the vehicle keypoint information (e.g., roof and left wheel), and capture the representative local spatial region via the keypoint information. Then, we use the representative spatial features in the local spatial region and the distinguishing discriminative features in the non-spatial region to eliminate the interference arising from the spatial shift while enhancing the robustness of the model. Finally, the global discriminative information and representative spatial information are combined for vehicle re-identification to enhance the performance of the model. We validate the effectiveness of our proposed approach on the vehicle ReID datasets (VehicleID, VeRi-776 and VeRi-Wild). Experimental results show that our method achieves state-of-the-art performance.},
  archive      = {J_CC},
  author       = {Zhou, Wei and Lian, Jiawei and Zhu, Shunzhi and Wu, Yun and Wang, Da-Han},
  doi          = {10.1007/s12559-023-10145-4},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1640-1655},
  shortjournal = {Cogn. Comput.},
  title        = {Vehicle re-identification by separating representative spatial features},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hebbian model to account for musical expertise differences
in a working memory task. <em>CC</em>, <em>15</em>(5), 1620–1639. (<a
href="https://doi.org/10.1007/s12559-023-10138-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The TBRS*C computational model provides a mathematical implementation of the cognitive processes involved in complex span tasks. The logic of the core processes, i.e., encoding, refreshing/time-based decay, and chunking, is based on Hebbian learning, synaptic facilitation, and long-term neural plasticity, respectively. The modeling, however, takes place on a cognitive rather than a physiological level. Chunking is implemented as a process of searching for sequences of memoranda in long-term memory and recoding them as a single unit which increases the efficacy of memory maintenance. Using TBRS*C simulations, the present study investigated how chunking and central working memory processes change with expertise. Hobby musicians and music students completed a complex span task in which sequences of twelve note symbols were presented for serial recall of pitch. After the presentation of each memorandum, participants performed an unknown, notated melody on an electric piano. To manipulate the potential for chunking, we varied whether sequences of memoranda formed meaningful tonal structures (major triads) or arbitrary trichords. Hobby musicians and music students were each split up in a higher-expertise and a lower-expertise group and TBRS*C simulations were performed for each group individually. In the simulations, higher-expertise hobby musicians encoded memoranda more rapidly, invested less time in chunk search, and recognized chunks with a higher chance than lower-expertise hobby musicians. Parameter estimates for music students showed only marginal expertise differences. We conclude that expertise in the TBRS model can be conceptualized by a rapid access to long-term memory and by chunking, which leads to an increase in the opportunity and efficacy of refreshing.},
  archive      = {J_CC},
  author       = {Lörch, Lucas and Lemaire, Benoît and Portrat, Sophie},
  doi          = {10.1007/s12559-023-10138-3},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1620-1639},
  shortjournal = {Cogn. Comput.},
  title        = {A hebbian model to account for musical expertise differences in a working memory task},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cognitive phenomenology neuroscience and computation.
<em>CC</em>, <em>15</em>(5), 1613–1619. (<a
href="https://doi.org/10.1007/s12559-023-10144-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phenomenology is concerned with the first-person experience of or about some object, and is generally related to sensory experience, for example, auditory or visual. Cognitive phenomenology refers to an element of phenomenological experience that does not have a sensory character. Experiences of thought, understanding, and appreciation of meaning are less figurative than the sensory kind and therefore suggest a treatment separate from that related to sensory experience. Where sensory phenomenology is discussed as there being something, it is like to be in a sensory state (of color or some object like a banana), and it is less evident that there is something it is like to think, understand, or recognize meaning. As Strawson [1] puts it: “It’s strange that the existence of cognitive phenomenology is a matter of dispute.” But dispute there is, this paper examines this The Nature of Cognitive Phenomenology and Its Denial and suggests instances from neurology and logical argumentation that CP does exist. In this paper, while the existence phenomenal consciousness is a matter of philosophical debate, the CP of understanding is seen as important to those who work on language understanding in a computational domain. The salient method is a critical examination and comparison of relevant literature in different disciplines. Specifically, one instance of cognitive phenomenology is addressed: the understanding experience. However, the very existence of cognitive phenomenology is a controversial issue in philosophical discourse. Accordingly, in addition to a presentation of cognitive phenomenology, the controversy over its necessity as a concept is examined: a study dismissing CP is presented, and an example (a phenomenal contrast argument) is introduced. New arguments based on formal examples of “understanding” are proposed to further corroborate the existence of CP. Then, in the light of existing work on event-related potentials that measure changes in brain activity patterns under linguistic input, a neural support for cognitive phenomenology is elicited as an additional proof of its existence. The key result is that arguments from neurology and linguistics provide support for the existence of at least one facet of cognitive phenomenology (understanding) with the possibility that such presence could be measurable and extended to other modes. The arguments presented in the paper provide a grounding for using the CP concept in computing, as a complement to synthetic phenomenology.},
  archive      = {J_CC},
  author       = {Sfeir, Neyla and Aleksander, Igor},
  doi          = {10.1007/s12559-023-10144-5},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1613-1619},
  shortjournal = {Cogn. Comput.},
  title        = {Cognitive phenomenology neuroscience and computation},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhanced quantum-secure ensemble intrusion detection
techniques for cloud based on deep learning. <em>CC</em>,
<em>15</em>(5), 1593–1612. (<a
href="https://doi.org/10.1007/s12559-023-10139-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing popularity of cloud computing systems has drawn significant attention from academics and businesses for several decades. However, cloud computing systems are plagued with several concerns, such as privacy, confidentiality, and availability, which can be detrimental to their performance. Intrusion detection has emerged as a critical issue, particularly in detecting new types of intrusions that can compromise the security of cloud systems. Preventive risk models have been developed to check the cloud for potential threats, and the rise of quantum computing attacks necessitates the deployment of an intrusion detection system (IDS) for cloud security risk assessment. This research proposes a unique method for detecting cloud computing intrusions by utilizing the KDDcup 1999, UNSW-NB15, and NSL-KDD datasets to address these concerns. This proposed system is designed to achieve two objectives. Firstly, it analyzes the disadvantages of existing IDS, and secondly, it presents an accuracy enhancement model of IDS. The proposed Ensemble Intrusion Detection Model for Cloud Computing Using Deep Learning (EICDL) is designed to detect intrusions effectively. The performance of the proposed model is compared to modern machine learning methods and existing IDS, and the experimental findings indicate that the EICDL ensemble technique improves detection and can identify subsequent attacks/intrusions with a recall rate of 92.14%. The proposed method EICDL ensemble technique significantly improves the accuracy and efficiency of intrusion detection in cloud systems.},
  archive      = {J_CC},
  author       = {Salvakkam, Dilli Babu and Saravanan, Vijayalakshmi and Jain, Praphula Kumar and Pamula, Rajendra},
  doi          = {10.1007/s12559-023-10139-2},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1593-1612},
  shortjournal = {Cogn. Comput.},
  title        = {Enhanced quantum-secure ensemble intrusion detection techniques for cloud based on deep learning},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tensorized anchor graph learning for large-scale multi-view
clustering. <em>CC</em>, <em>15</em>(5), 1581–1592. (<a
href="https://doi.org/10.1007/s12559-023-10146-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous development of information acquisition technologies, large-scale multi-view data increases rapidly. The enormous computational and storage complexity makes it very challenging to process these data in real-world applications. Most existing multi-view subspace clustering (MVSC) always suffers from quadratic space complexity and quadratic or even cubic time complexity, resulting in extreme limitations for large-scale tasks. Meanwhile, the original data usually contain lots of noise or redundant features, which further enhances the difficulty of the large-scale clustering tasks. This paper proposes a novel MVSC method for efficiently and effectively dealing with large-scale multi-view data, termed as tensorized anchor graph learning (TAGL) for large-scale multi-view clustering. Concretely, TAGL first projects the original multi-view data from the original space into the latent embedding space, where the view-consistent anchor matrix. Meanwhile, we establish the connection between the anchor matrix and the original data to construct multiple view-specific anchor graphs. Furthermore, these anchor graphs are stacked into a graph tensor to capture the high-order correlation. Finally, by developing an effective optimization algorithm, the high-quality anchors, anchor graph, and anchor graph tensor can be jointly learned in a mutually reinforcing way. Experimental results on several big sizes of datasets verify the superiority and validity of TAGL. Therefore, the proposed TAGL can efficiently and effectively handle large-scale data tasks for real-world applications.},
  archive      = {J_CC},
  author       = {Dai, Jian and Ren, Zhenwen and Luo, Yunzhi and Song, Hong and Yang, Jian},
  doi          = {10.1007/s12559-023-10146-3},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1581-1592},
  shortjournal = {Cogn. Comput.},
  title        = {Tensorized anchor graph learning for large-scale multi-view clustering},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BrainNet with connectivity attention for individualized
predictions based on multi-facet connections extracted from
resting-state fMRI data. <em>CC</em>, <em>15</em>(5), 1566–1580. (<a
href="https://doi.org/10.1007/s12559-023-10133-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resting-state functional magnetic resonance imaging (RS-fMRI) has great potential for clinical applications. This study aimed to promote the performance of RS-fMRI-based individualized predictive models by introducing effective feature extraction and utilization strategies and making better use of information hidden in RS-fMRI data. We proposed a novel framework named multi-facet BrainNet with connectivity attention (MFBCA) to fulfill the purpose, and the framework is characterized by the following three strategies. First, in addition to the overwhelmingly popular functional connectivity, we also used distance correlation and weighted directed connectivity as multi-facet inputs for MFBCA. Second, a connectivity attention layer was proposed to force MFBCA to focus more on connections that are important for predictions. Finally, a BrainNet-based architecture with a feature fusion module was introduced to facilitate final predictions. We evaluated the performance of MFBCA with predictions of individuals&#39; age and intelligence quotient as test cases based on three public RS-fMRI datasets. The results indicate that MFBCA can effectively utilize the information hidden in RS-fMRI data and outperform baselines. The predicted-vs-actual correlations for age predictions were 0.876 (7.314 years), 0.873 (8.121 years), and 0.681 (3.865 years), and for IQ predictions was 0.615 (4.287). The connectivity attention layer made it possible for us to determine the connections important for individualized predictions. MFBCA can be widely applied to predictions based on neuroimaging data from which connectivity maps can be extracted. Furthermore, the explicit physiological basis for predictions provided by the connectivity attention layer makes MFBCA a profitable choice for clinical applications.},
  archive      = {J_CC},
  author       = {Ma, Hao and Wu, Fan and Guan, Yun and Xu, Le and Liu, Jiangcong and Tian, Lixia},
  doi          = {10.1007/s12559-023-10133-8},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1566-1580},
  shortjournal = {Cogn. Comput.},
  title        = {BrainNet with connectivity attention for individualized predictions based on multi-facet connections extracted from resting-state fMRI data},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NILRNN: A neocortex-inspired locally recurrent neural
network for unsupervised feature learning in sequential data.
<em>CC</em>, <em>15</em>(5), 1549–1565. (<a
href="https://doi.org/10.1007/s12559-023-10122-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised feature learning refers to the problem of learning useful feature extraction functions from unlabeled data. Despite the great success of deep learning networks in this task in recent years, both for static and for sequential data, these systems can in general still not compete with the high performance of our brain at learning to extract useful representations from its sensory input. We propose the Neocortex-Inspired Locally Recurrent Neural Network: a new neural network for unsupervised feature learning in sequential data that brings ideas from the structure and function of the neocortex to the well-established fields of machine learning and neural networks. By mimicking connection patterns in the feedforward circuits of the neocortex, our system tries to generalize some of the ideas behind the success of convolutional neural networks to types of data other than images. To evaluate the performance of our system at extracting useful features, we have trained different classifiers using those and other learnt features as input and we have compared the obtained accuracies. Our system has shown to outperform other shallow feature learning systems in this task, both in terms of the accuracies achieved and in terms of how fast the classification task is learnt. The results obtained confirm our system as a state-of-the-art shallow feature learning system for sequential data, and suggest that extending it to or integrating it into deep architectures may lead to new successful networks that are competent at dealing with complex sequential tasks.},
  archive      = {J_CC},
  author       = {Van-Horenbeke, Franz A. and Peer, Angelika},
  doi          = {10.1007/s12559-023-10122-x},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1549-1565},
  shortjournal = {Cogn. Comput.},
  title        = {NILRNN: A neocortex-inspired locally recurrent neural network for unsupervised feature learning in sequential data},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Two-way concept-cognitive learning with multi-source fuzzy
context. <em>CC</em>, <em>15</em>(5), 1526–1548. (<a
href="https://doi.org/10.1007/s12559-023-10107-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concepts learning is the most fundamental unit in the process of human cognition in philosophy. Granularity is one of the fundamental concepts of human cognition. The combination of granular computing and concept learning is critical in the cognitive process. Meanwhile, efficiently and accurately using the information collected from different sources is the focus of data mining in the contemporary. Hence, how to sufficiently learn concepts under a multi-sources context is an essential concern in the field of cognition. This paper offers a new thought for two-way concept-cognitive learning based on granular computing in multi-source fuzzy decision tables. Firstly, based on the best possible guarantee of the classification ability, original information from different sources is fused by conditional entropy, which is the kind of multi-source fusion method (i.e., CE-fusion). Secondly, we learn concepts from a given object set, attribute set, or pair of object and attribute sets in the fused information table, and these three types of concept learning algorithms are designed. This analysis shows that two-way concept learning based on multi-source information fusion is a suitable method of multi-source concept learning. Some examples are valuable for applying these theories to deal with practical issues. Our work will provide a convenient novel tool for researching concept-cognitive learning methods with multi-source fuzzy context.},
  archive      = {J_CC},
  author       = {Zhang, Xiaoyan and Guo, Doudou and Xu, Weihua},
  doi          = {10.1007/s12559-023-10107-w},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1526-1548},
  shortjournal = {Cogn. Comput.},
  title        = {Two-way concept-cognitive learning with multi-source fuzzy context},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving whale optimization algorithm with elite strategy
and its application to engineering-design and cloud task scheduling
problems. <em>CC</em>, <em>15</em>(5), 1497–1525. (<a
href="https://doi.org/10.1007/s12559-022-10099-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The whale optimization algorithm (WOA), a biologically inspired optimization technique, is known for its straightforward design and effectiveness. Despite many advantages, it has certain disadvantages, such as a limited exploration capacity and early convergence as a result of the minimal exploration of the search process. The WOA cannot bypass the local solution; consequently, the search is unbalanced. This study introduces a new variant of WOA, namely elite-based WOA (EBWOA), to address the inherent shortcomings of traditional WOA. Unlike the three phases used in the traditional WOA, only the encircling prey and bubble-net attack phases are applied in the new variant. Using the local elite method, exploration will be conducted with an encircling prey phase to ensure some exploitation during exploration. The choice between exploration and exploitation is achieved by introducing a new choice parameter. An inertia weight $${(\omega }_{i})$$ is used in both phases to scour the region. The EBWOA is used to evaluate twenty-five benchmark functions, IEEE CEC 2019 functions, and two design problems and compared to several fundamental techniques and WOA variants. In addition, the EBWOA is used to solve the practical cloud scheduling problem. Performance is compared against a variety of metaheuristics using real cloud workloads by running experiments on the standard CloudSim simulator. Comparing the numerical results of benchmark functions, IEEE CEC 2019 functions, statistical verification, and the solution generation speed of EBWOA confirmed the effectiveness of the proposed EBWOA approach. It has also shown a great improvement over baseline algorithms in creating efficient scheduling solutions by significantly reducing makespan time and energy consumption targets.},
  archive      = {J_CC},
  author       = {Chakraborty, Sanjoy and Saha, Apu Kumar and Chhabra, Amit},
  doi          = {10.1007/s12559-022-10099-z},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1497-1525},
  shortjournal = {Cogn. Comput.},
  title        = {Improving whale optimization algorithm with elite strategy and its application to engineering-design and cloud task scheduling problems},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Latent space exploration and functionalization of a gated
working memory model using conceptors. <em>CC</em>, <em>15</em>(5),
1485–1496. (<a
href="https://doi.org/10.1007/s12559-020-09797-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Working memory is the ability to maintain and manipulate information. We introduce a method based on conceptors that allows us to manipulate information stored in the dynamics (latent space) of a gated working memory model. This latter model is based on a reservoir: a random recurrent network with trainable readouts. It is trained to hold a value in memory given an input stream when a gate signal is on and to maintain this information when the gate is off. The memorized information results in complex dynamics inside the reservoir that can be faithfully captured by a conceptor. Such conceptors allow us to explicitly manipulate this information in order to perform various, but not arbitrary, operations. In this work, we show (1) how working memory can be stabilized or discretized using such conceptors, (2) how such conceptors can be linearly combined to form new memories, and (3) how these conceptors can be extended to a functional role. These preliminary results suggest that conceptors can be used to manipulate the latent space of the working memory even though several results we introduce are not as intuitive as one would expect.},
  archive      = {J_CC},
  author       = {Strock, Anthony and Rougier, Nicolas P. and Hinaut, Xavier},
  doi          = {10.1007/s12559-020-09797-3},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1485-1496},
  shortjournal = {Cogn. Comput.},
  title        = {Latent space exploration and functionalization of a gated working memory model using conceptors},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient implementations of echo state network
cross-validation. <em>CC</em>, <em>15</em>(5), 1470–1484. (<a
href="https://doi.org/10.1007/s12559-021-09849-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-Validation (CV) is still uncommon in time series modeling. Echo State Networks (ESNs), as a prime example of Reservoir Computing (RC) models, are known for their fast and precise one-shot learning, that often benefit from good hyper-parameter tuning. This makes them ideal to change the status quo. We discuss CV of time series for predicting a concrete time interval of interest, suggest several schemes for cross-validating ESNs and introduce an efficient algorithm for implementing them. This algorithm is presented as two levels of optimizations of doing k-fold CV. Training an RC model typically consists of two stages: (i) running the reservoir with the data and (ii) computing the optimal readouts. The first level of our optimization addresses the most computationally expensive part (i) and makes it remain constant irrespective of k. It dramatically reduces reservoir computations in any type of RC system and is enough if k is small. The second level of optimization also makes the (ii) part remain constant irrespective of large k, as long as the dimension of the output is low. We discuss when the proposed validation schemes for ESNs could be beneficial, three options for producing the final model and empirically investigate them on six different real-world datasets, as well as do empirical computation time experiments. We provide the code in an online repository. Proposed CV schemes give better and more stable test performance in all the six different real-world datasets, three task types. Empirical run times confirm our complexity analysis. In most situations, k-fold CV of ESNs and many other RC models can be done for virtually the same time and space complexity as a simple single-split validation. This enables CV to become a standard practice in RC.},
  archive      = {J_CC},
  author       = {Lukoševičius, Mantas and Uselis, Arnas},
  doi          = {10.1007/s12559-021-09849-2},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1470-1484},
  shortjournal = {Cogn. Comput.},
  title        = {Efficient implementations of echo state network cross-validation},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hardware-optimized reservoir computing system for edge
intelligence applications. <em>CC</em>, <em>15</em>(5), 1461–1469. (<a
href="https://doi.org/10.1007/s12559-020-09798-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge artificial intelligence or edge intelligence is an ever-growing research area due to the current popularization of the Internet of Things. Unfortunately, incorporation of artificial intelligence (AI) in smart devices operating at the edge is a challenging task due to the power-hungry characteristics of deep learning implementations, such as convolutional neural networks (CNNs). As a feasible alternative, reservoir computing (RC) has attracted a lot of attention in the field of machine learning due to its promising performance in a wide range of applications. In this work, we propose a simple hardware-optimized circuit design of RC systems presenting high energy-efficiency capacities that fulfill the low power requirements of edge intelligence applications. As a proof of concept, we used the proposed design for the implementation of a low-power audio event detection (AED) application in FPGA. The measurements and simulation results obtained show that the proposed approach may provide significant accuracy with the advantage of presenting ultra-low-power characteristics (the energy efficiency estimated is below the microjoule per inference). These results make the proposed system optimal for edge intelligence applications in which energy efficiency and accuracy are the key issues.},
  archive      = {J_CC},
  author       = {Morán, Alejandro and Canals, Vincent and Galan-Prado, Fabio and Frasser, Christian F. and Radhakrishnan, Dhinakar and Safavi, Saeid and Rosselló, Josep L.},
  doi          = {10.1007/s12559-020-09798-2},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1461-1469},
  shortjournal = {Cogn. Comput.},
  title        = {Hardware-optimized reservoir computing system for edge intelligence applications},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bayesian optimisation of large-scale photonic reservoir
computers. <em>CC</em>, <em>15</em>(5), 1452–1460. (<a
href="https://doi.org/10.1007/s12559-020-09732-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reservoir computing is a growing paradigm for simplified training of recurrent neural networks, with a high potential for hardware implementations. Numerous experiments in optics and electronics yield comparable performance with digital state-of-the-art algorithms. Many of the most recent works in the field focus on large-scale photonic systems, with tens of thousands of physical nodes and arbitrary interconnections. While this trend significantly expands the potential applications of photonic reservoir computing, it also complicates the optimisation of the high number of hyper-parameters of the system. In this work, we propose the use of Bayesian optimisation for efficient exploration of the hyper-parameter space in a minimum number of iteration. We test this approach on a previously reported large-scale experimental system, compare it with the commonly used grid search, and report notable improvements in performance and the number of experimental iterations required to optimise the hyper-parameters. Bayesian optimisation thus has the potential to become the standard method for tuning the hyper-parameters in photonic reservoir computing.},
  archive      = {J_CC},
  author       = {Antonik, Piotr and Marsal, Nicolas and Brunner, Daniel and Rontani, Damien},
  doi          = {10.1007/s12559-020-09732-6},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1452-1460},
  shortjournal = {Cogn. Comput.},
  title        = {Bayesian optimisation of large-scale photonic reservoir computers},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Information processing capacity of spin-based quantum
reservoir computing systems. <em>CC</em>, <em>15</em>(5), 1440–1451. (<a
href="https://doi.org/10.1007/s12559-020-09772-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamical behavior of complex quantum systems can be harnessed for information processing. With this aim, quantum reservoir computing (QRC) with Ising spin networks was recently introduced as a quantum version of classical reservoir computing. In turn, reservoir computing is a neuro-inspired machine learning technique that consists in exploiting dynamical systems to solve nonlinear and temporal tasks. We characterize the performance of the spin-based QRC model with the Information Processing Capacity (IPC), which allows to quantify the computational capabilities of a dynamical system beyond specific tasks. The influence on the IPC of the input injection frequency, time multiplexing, and different measured observables encompassing local spin measurements as well as correlations is addressed. We find conditions for an optimum input driving and provide different alternatives for the choice of the output variables used for the readout. This work establishes a clear picture of the computational capabilities of a quantum network of spins for reservoir computing. Our results pave the way to future research on QRC both from the theoretical and experimental points of view.},
  archive      = {J_CC},
  author       = {Martínez-Peña, R. and Nokkala, J. and Giorgi, G. L. and Zambrini, R. and Soriano, M. C.},
  doi          = {10.1007/s12559-020-09772-y},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1440-1451},
  shortjournal = {Cogn. Comput.},
  title        = {Information processing capacity of spin-based quantum reservoir computing systems},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Echo state networks and long short-term memory for
continuous gesture recognition: A comparative study. <em>CC</em>,
<em>15</em>(5), 1427–1439. (<a
href="https://doi.org/10.1007/s12559-020-09754-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent developments of sensors that allow tracking of human movements and gestures enable rapid progress of applications in domains like medical rehabilitation or robotic control. Especially the inertial measurement unit (IMU) is an excellent device for real-time scenarios as it rapidly delivers data input. Therefore, a computational model must be able to learn gesture sequences in a fast yet robust way. We recently introduced an echo state network (ESN) framework for continuous gesture recognition (Tietz et al., 2019) including novel approaches for gesture spotting, i.e., the automatic detection of the start and end phase of a gesture. Although our results showed good classification performance, we identified significant factors which also negatively impact the performance like subgestures and gesture variability. To address these issues, we include experiments with Long Short-Term Memory (LSTM) networks, which is a state-of-the-art model for sequence processing, to compare the obtained results with our framework and to evaluate their robustness regarding pitfalls in the recognition process. In this study, we analyze the two conceptually different approaches processing continuous, variable-length gesture sequences, which shows interesting results comparing the distinct gesture accomplishments. In addition, our results demonstrate that our ESN framework achieves comparably good performance as the LSTM network but has significantly lower training times. We conclude from the present work that ESNs are viable models for continuous gesture recognition delivering reasonable performance for applications requiring real-time performance as in robotic or rehabilitation tasks. From our discussion of this comparative study, we suggest prospective improvements on both the experimental and network architecture level.},
  archive      = {J_CC},
  author       = {Jirak, Doreen and Tietz, Stephan and Ali, Hassan and Wermter, Stefan},
  doi          = {10.1007/s12559-020-09754-0},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1427-1439},
  shortjournal = {Cogn. Comput.},
  title        = {Echo state networks and long short-term memory for continuous gesture recognition: A comparative study},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Limitations of the recall capabilities in delay-based
reservoir computing systems. <em>CC</em>, <em>15</em>(5), 1419–1426. (<a
href="https://doi.org/10.1007/s12559-020-09733-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyse the memory capacity of a delay-based reservoir computer with a Hopf normal form as nonlinearity and numerically compute the linear as well as the higher order recall capabilities. A possible physical realization could be a laser with external cavity, for which the information is fed via electrical injection. A task-independent quantification of the computational capability of the reservoir system is done via a complete orthonormal set of basis functions. Our results suggest that even for constant readout dimension the total memory capacity is dependent on the ratio between the information input period, also called the clock cycle, and the time delay in the system. Optimal performance is found for a time delay about 1.6 times the clock cycle.},
  archive      = {J_CC},
  author       = {Köster, Felix and Ehlert, Dominik and Lüdge, Kathy},
  doi          = {10.1007/s12559-020-09733-5},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1419-1426},
  shortjournal = {Cogn. Comput.},
  title        = {Limitations of the recall capabilities in delay-based reservoir computing systems},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A reservoir computing approach to word sense disambiguation.
<em>CC</em>, <em>15</em>(5), 1409–1418. (<a
href="https://doi.org/10.1007/s12559-020-09758-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reservoir computing (RC) has emerged as an alternative approach for the development of fast trainable recurrent neural networks (RNNs). It is considered to be biologically plausible due to the similarity between randomly designed artificial reservoir structures and cortical structures in the brain. The paper continues our previous research on the application of a member of the family of RC approaches—the echo state network (ESN)—to the natural language processing (NLP) task of Word Sense Disambiguation (WSD). A novel deep bi-directional ESN (DBiESN) structure is proposed, as well as a novel approach for exploiting reservoirs’ steady states. The models also make use of ESN-enhanced word embeddings. The paper demonstrates that our DBiESN approach offers a good alternative to previously tested BiESN models in the context of the word sense disambiguation task having smaller number of trainable parameters. Although our DBiESN-based model achieves similar accuracy to other popular RNN architectures, we could not outperform the state of the art. However, due to the smaller number of trainable parameters in the reservoir models, in contrast to fully trainable RNNs, it is to be expected that they would have better generalization properties as well as higher potential to increase their accuracy, which should justify further exploration of such architectures.},
  archive      = {J_CC},
  author       = {Simov, Kiril and Koprinkova-Hristova, Petia and Popov, Alexander and Osenova, Petya},
  doi          = {10.1007/s12559-020-09758-w},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1409-1418},
  shortjournal = {Cogn. Comput.},
  title        = {A reservoir computing approach to word sense disambiguation},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Guest editorial: Trends in reservoir computing. <em>CC</em>,
<em>15</em>(5), 1407–1408. (<a
href="https://doi.org/10.1007/s12559-021-09890-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CC},
  author       = {Scardapane, Simone and Gallicchio, Claudio and Micheli, Alessio and Soriano, Miguel C.},
  doi          = {10.1007/s12559-021-09890-1},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1407-1408},
  shortjournal = {Cogn. Comput.},
  title        = {Guest editorial: Trends in reservoir computing},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multidimensional affective analysis for low-resource
languages: A use case with guarani-spanish code-switching language.
<em>CC</em>, <em>15</em>(4), 1391–1406. (<a
href="https://doi.org/10.1007/s12559-023-10165-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on text-based affective computing for Jopara, a code-switching language that combines Guarani and Spanish. First, we collected a dataset of tweets primarily written in Guarani and annotated them for three widely used dimensions in sentiment analysis: (a) emotion recognition, (b) humor detection, and (c) offensive language identification. Then, we developed several neural network models, including large language models specifically designed for Guarani, and compared their performance against off-the-shelf multilingual and Spanish pre-trained models for the aforementioned dimensions. Our experiments show that language models incorporating Guarani during pre-training or pre-fine-tuning consistently achieve the best results, despite limited resources (a single 24-GB GPU and only 800K tokens). Notably, even a Guarani BERT model with just two layers of Transformers shows a favorable balance between accuracy and computational power, likely due to the inherent low-resource nature of the task. We present a comprehensive overview of corpus creation and model development for low-resource languages like Guarani, particularly in the context of its code-switching with Spanish, resulting in Jopara. Our findings shed light on the challenges and strategies involved in analyzing affective language in such linguistic contexts.},
  archive      = {J_CC},
  author       = {Agüero-Torales, Marvin M. and López-Herrera, Antonio G. and Vilares, David},
  doi          = {10.1007/s12559-023-10165-0},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1391-1406},
  shortjournal = {Cogn. Comput.},
  title        = {Multidimensional affective analysis for low-resource languages: A use case with guarani-spanish code-switching language},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A self-attention-based multi-level fusion network for aspect
category sentiment analysis. <em>CC</em>, <em>15</em>(4), 1372–1390. (<a
href="https://doi.org/10.1007/s12559-023-10160-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect category-based sentiment analysis (ACSA) is a fine-grained sentiment analysis approach for predicting the sentiment polarity associated with the different aspect categories in a text. While numerous strategies have incorporated attention mechanisms to generate contextual features for specific aspectual objectives, their sole use may be influenced by the sentiments conveyed in other aspect categories. This can occur when aspectual targets are absent from the sentence and when words carry varying contextual sentiments across multiple aspect categories. This paper introduces the attention-based multi-level feature aggregation (AMFA) network, which simultaneously considers local and global information by applying attention to convolutional filters. It further employs context-guided self-attention modules at multiple levels to efficiently amalgamate learned different aspects and the interactions between contextual features within a cohesive framework. We tested the proposed approach on four public datasets. The results demonstrated the efficiency of our model in extracting more precise semantics and sentiments related to specific feature categories. To examine the practicality of AMFA, we constructed an online review dataset of table grapes from an e-commerce platform, where our model outperformed the baseline models with an accuracy of 88% and a macro-averaged F1 score of 73.23%. We also validated the effectiveness of each AMFA module by testing them separately on all datasets. Experimental results prove that our proposed model is adept at semantically separating aspect embeddings from words in sentences and minimizing the impact of irrelevant information. Additionally, the robustness of our model is substantiated by supplementary experiments conducted on a constructed Chinese dataset.},
  archive      = {J_CC},
  author       = {Tian, Dong and Shi, Jia and Feng, Jianying},
  doi          = {10.1007/s12559-023-10160-5},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1372-1390},
  shortjournal = {Cogn. Comput.},
  title        = {A self-attention-based multi-level fusion network for aspect category sentiment analysis},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integrating economic theory, domain knowledge, and social
knowledge into hybrid sentiment models for predicting crude oil markets.
<em>CC</em>, <em>15</em>(4), 1355–1371. (<a
href="https://doi.org/10.1007/s12559-023-10129-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For several decades, sentiment analysis has been considered a key indicator for assessing market mood and predicting future price changes. Accurately predicting commodity markets requires an understanding of fundamental market dynamics such as the interplay between supply and demand, which are not considered in standard affective models. This paper introduces two domain-specific affective models, CrudeBERT and CrudeBERT+, that adapt sentiment analysis to the crude oil market by incorporating economic theory with common knowledge of the mentioned entities and social knowledge extracted from Google Trends. To evaluate the predictive capabilities of these models, comprehensive experiments were conducted using dynamic time warping to identify the model that best approximates WTI crude oil futures price movements. The evaluation included news headlines and crude oil prices between January 2012 and April 2021. The results show that CrudeBERT+ outperformed RavenPack, BERT, FinBERT, and early CrudeBERT models during the 9-year evaluation period and within most of the individual years that were analyzed. The success of the introduced domain-specific affective models demonstrates the potential of integrating economic theory with sentiment analysis and external knowledge sources to improve the predictive power of financial sentiment analysis models. The experiments also confirm that CrudeBERT+ has the potential to provide valuable insights for decision-making in the crude oil market.},
  archive      = {J_CC},
  author       = {Kaplan, Himmet and Weichselbraun, Albert and Braşoveanu, Adrian M. P.},
  doi          = {10.1007/s12559-023-10129-4},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1355-1371},
  shortjournal = {Cogn. Comput.},
  title        = {Integrating economic theory, domain knowledge, and social knowledge into hybrid sentiment models for predicting crude oil markets},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven dimensional expression generation via
encapsulated variational auto-encoders. <em>CC</em>, <em>15</em>(4),
1342–1354. (<a
href="https://doi.org/10.1007/s12559-021-09973-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concerning facial expression generation, relying on the sheer volume of training data, recent advances on generative models allow high-quality generation of facial expressions free of the laborious facial expression annotating procedure. However, these generative processes have limited relevance to the psychological conceptualised dimensional plane, i.e., the Arousal-Valence two-dimensional plane, resulting in the generation of psychological uninterpretable facial expressions. For this, in this research, we seek to present a novel generative model, targeting learning the psychological compatible (low-dimensional) representations of facial expressions to permit the generation of facial expressions along the psychological conceptualised Arousal-Valence dimensions. To generate Arousal-Valence compatible facial expressions, we resort to a novel form of the data-driven generative model, i.e., the encapsulated variational auto-encoders (EVAE), which is consisted of two connected variational auto-encoders. Two harnessed variational auto-encoders in our EVAE model are concatenated with a tuneable continuous hyper-parameter, which bounds the learning of EVAE. Since this tuneable hyper-parameter, along with the linearly sampled inputs, largely determine the process of generating facial expressions, we hypothesise the correspondence between continuous scales on the hyper-parameter and sampled inputs, and the psychological conceptualised Arousal-Valence dimensions. For empirical validations, two public released facial expression datasets, e.g., the Frey faces and FERG-DB datasets, were employed here to evaluate the dimensional generative performance of our proposed EVAE. Across two datasets, the generated facial expressions along our two hypothesised continuous scales were observed in consistent with the psychological conceptualised Arousal-Valence dimensions. Applied our proposed EVAE model to the Frey faces and FERG-DB facial expression datasets, we demonstrate the feasibility of generating facial expressions along with the conceptualised Arousal-Valence dimensions. In conclusion, to generate facial expressions along the psychological conceptualised Arousal-Valance dimensions, we propose a novel type of generative model, i.e., encapsulated variational auto-encoders (EVAE), allowing the generation process to be disentangled into two tuneable continuous factors. Validated in two publicly available facial expression datasets, we demonstrate the association between these factors and Arousal-Valence dimensions in facial expression generation, deriving the data-driven Arousal-Valence plane in affective computing. Despite its embryonic stage, our research may shed light on the prospect of continuous, dimensional affective computing.},
  archive      = {J_CC},
  author       = {Bai, Wenjun and Quan, Changqin and Luo, Zhi-Wei},
  doi          = {10.1007/s12559-021-09973-z},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1342-1354},
  shortjournal = {Cogn. Comput.},
  title        = {Data-driven dimensional expression generation via encapsulated variational auto-encoders},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). OIAE: Overall improved autoencoder with powerful image
reconstruction and discriminative feature extraction. <em>CC</em>,
<em>15</em>(4), 1334–1341. (<a
href="https://doi.org/10.1007/s12559-022-10000-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an unsupervised learning method, the autoencoder (AE) plays a very important role in model pre-training. However, the current AEs pre-training methods are still faced with the problems of not being able to reconstruct pictures better and mining deeper features. In this paper, we come up with a new AE, overall improved autoencoder (OIAE). Its main contribution is twofold: Wasserstein Generative Adversarial Networks (WGAN) is used to study the relationship between AEs reconstruction ability and pre-training performance and a regularization method is proposed to enable the autoencoder to learn discriminative features. We set up ablation experiments to prove the effectiveness of our two improvements and OIAE and compare them with baseline. The classification accuracy of the OIAE pre-trained classification network improved by 0.74% on the basic dataset and 16.44% on the more difficult dataset. These promising results demonstrate the effectiveness of our method in AEs pre-training tasks.},
  archive      = {J_CC},
  author       = {Zhao, Haifeng and Wu, Haiting and Wang, Xin},
  doi          = {10.1007/s12559-022-10000-y},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1334-1341},
  shortjournal = {Cogn. Comput.},
  title        = {OIAE: Overall improved autoencoder with powerful image reconstruction and discriminative feature extraction},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CCBLA: A lightweight phishing detection model based on CNN,
BiLSTM, and attention mechanism. <em>CC</em>, <em>15</em>(4), 1320–1333.
(<a href="https://doi.org/10.1007/s12559-022-10024-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phishing, in which social engineering techniques such as emails and instant messaging are employed and malicious links are disguised as normal URLs to steal sensitive information, is currently a major threat to networks worldwide. Phishing detection systems generally adopt feature engineering as one of the most important approaches to detect or even prevent phishing attacks. However, the accuracy of feature engineering systems is heavily dependent on the prior knowledge of features. In addition, extracting comprehensive features from different dimensions for high detection accuracy is time-consuming. To address these issues, this paper proposes a lightweight model that combines convolutional neural network (CNN), bi-directional long short-term memory (BiLSTM), and the attention mechanism for phishing detection. The proposed model, called the char-convolutional and BiLSTM with attention mechanism (CCBLA) model, employs deep learning to automatically extract features from target URLs and uses the attention mechanism to weight the importance of the selected features under different roles during phishing detection. The results of experiments conducted on two datasets with different scales show that CCBLA is accurate in phishing attack detection with minimal time consumption.},
  archive      = {J_CC},
  author       = {Zhu, Erzhou and Yuan, Qixiang and Chen, Zhile and Li, Xuejian and Fang, Xianyong},
  doi          = {10.1007/s12559-022-10024-4},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1320-1333},
  shortjournal = {Cogn. Comput.},
  title        = {CCBLA: A lightweight phishing detection model based on CNN, BiLSTM, and attention mechanism},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An attention-driven multi-label image classification with
semantic embedding and graph convolutional networks. <em>CC</em>,
<em>15</em>(4), 1308–1319. (<a
href="https://doi.org/10.1007/s12559-021-09977-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label image classification is a fundamental and vital task in computer vision. The latest methods are mostly based on deep learning and exhibit excellent performance in understanding images. However, in previous studies, only capture the image content information has been captured using convolutional neural networks (CNNs), and the semantic structure information and implicit dependencies between labels and image regions have been ignored. Therefore, it is necessary to develop more effective methods for integrating semantic information and visual features in multi-label image classification. In this study, we propose a novel framework for multi-label image classification, named FLNet, which simultaneously takes advantage of the visual features and semantic structure. Specifically, to enhance the association between semantic annotations and image regions, we first integrate the attention mechanism with a CNN to focus on the target regions while ignoring other useless surrounding information and then employ graph convolutional network (GCN) to capture the structure information between multiple labels. Based on our architecture, we also introduce the lateral connections to repeatedly inject the label system into the CNN backbone during the GCN learning process to improve performance and, consequently, learn interdependent classifiers for each image label. We apply our method to multi-label image classification. The experiments on two public multi-label benchmark datasets, namely, MS-COCO and PASCAL visual object classes challenge (VOC 2007), demonstrate that our approach outperforms other existing state-of-the-art methods. Our method learns specific target regions and enhances the association between labels and image regions by using semantic information and attention mechanism. Thus, we combine the advantages of both visual and semantic information to further improve the image classification performance. Finally, the correctness and effectiveness of the proposed method are proven by visualizing the classifier results.},
  archive      = {J_CC},
  author       = {Sun, Dengdi and Ma, Leilei and Ding, Zhuanlian and Luo, Bin},
  doi          = {10.1007/s12559-021-09977-9},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1308-1319},
  shortjournal = {Cogn. Comput.},
  title        = {An attention-driven multi-label image classification with semantic embedding and graph convolutional networks},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-branch bounding box regression for object detection.
<em>CC</em>, <em>15</em>(4), 1300–1307. (<a
href="https://doi.org/10.1007/s12559-021-09983-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Localization and classification are two important components in the task of visual object detection. In recent years, object detectors have increasingly focused on creating various localization branches. Bounding box regression is vital for two-stage detectors. Therefore, we propose a multi-branch bounding box regression method called Multi-Branch R-CNN for robust object localization. Multi-Branch R-CNN is composed of the fully connected head and the fully convolutional head. The fully convolutional head focuses on the utilization of spatial semantics. It is complementary to the fully connected head that prefers local features. The features extracted from the two localization branches are fused, then flow to the next stage for classification and regression. The two branches cooperate to predict more precise localization, which significantly improves the performance of the detector. Extensive experiments were conducted on public PASCAL VOC and MS COCO benchmarks. On the COCO dataset, our Multi-Branch R-CNN with ResNet-101 backbone achieved state-of-the-art single model results by obtaining an mAP of 43.2. Extensive comparative experiments prove the effectiveness of the proposed method.},
  archive      = {J_CC},
  author       = {Yuan, Hui-Shen and Chen, Si-Bao and Luo, Bin and Huang, Hao and Li, Qiang},
  doi          = {10.1007/s12559-021-09983-x},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1300-1307},
  shortjournal = {Cogn. Comput.},
  title        = {Multi-branch bounding box regression for object detection},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatiotemporal EEG dynamics of prospective memory in ageing
and mild cognitive impairment. <em>CC</em>, <em>15</em>(4), 1273–1299.
(<a href="https://doi.org/10.1007/s12559-022-10075-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prospective memory (PM, the memory of future intentions) is one of the first complaints of those that develop dementia-related disease. Little is known about the neurophysiology of PM in ageing and those with mild cognitive impairment (MCI). By using a novel artificial neural network to investigate the spatial and temporal features of PM related brain activity, new insights can be uncovered. Young adults (n = 30), healthy older adults (n = 39) and older adults with MCI (n = 27) completed a working memory and two PM (perceptual, conceptual) tasks. Time-locked electroencephalographic potentials (ERPs) from 128-electrodes were analysed using a brain-inspired spiking neural network (SNN) architecture. Local and global connectivity from the SNNs was then evaluated. SNNs outperformed other machine learning methods in classification of brain activity between younger, older and older adults with MCI. SNNs trained using PM related brain activity had better classification accuracy than working memory related brain activity. In general, younger adults exhibited greater local cluster connectivity compared to both older adult groups. Older adults with MCI demonstrated decreased global connectivity in response to working memory and perceptual PM tasks but increased connectivity in the conceptual PM models relative to younger and healthy older adults. SNNs can provide a useful method for differentiating between those with and without MCI. Using brain activity related to PM in combination with SNNs may provide a sensitive biomarker for detecting cognitive decline. Cognitively demanding tasks may increase the amount connectivity in older adults with MCI as a means of compensation.},
  archive      = {J_CC},
  author       = {Crook-Rumsey, Mark and Howard, Christina J. and Doborjeh, Zohreh and Doborjeh, Maryam and Ramos, Josafath Israel Espinosa and Kasabov, Nikola and Sumich, Alexander},
  doi          = {10.1007/s12559-022-10075-7},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1273-1299},
  shortjournal = {Cogn. Comput.},
  title        = {Spatiotemporal EEG dynamics of prospective memory in ageing and mild cognitive impairment},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The spiking rates inspired encoder and decoder for spiking
neural networks: An illustration of hand gesture recognition.
<em>CC</em>, <em>15</em>(4), 1257–1272. (<a
href="https://doi.org/10.1007/s12559-022-10027-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spiking neural network (SNN) is the third generation of artificial neural networks. The transmission and expression of information in SNN are performed by spike trains, making the SNN have the advantages of high calculation speed and low power consumption. Recently, researchers have employed the SNN to recognize surface electromyography (sEMG) signals, but problems are still left. The sEMG encoders may cause information loss, and the network decoders may cause poor training performance. The strength of the neuron stimulated can be expressed by the frequency of the input or output spikes (namely firing rate). Inspired by the firing rate principle, we proposed the smoothed frequency-domain decomposition encoder, which converts the sEMG to spike trains. Furthermore, we also proposed the network efferent energy decoder, which converts the network output to recognizing results. The employed SNN is a three-layer fully-connected network trained by the grey wolf optimizer. The proposed methods are verified by a hand gestures recognition task. A total of 11 subjects participated in the experiment, and sEMG signals were acquired from five commonly used hand gestures by three sEMG sensors. The results indicate that the loss function can be reduced to below 0.4, and the average gesture recognizing accuracy is 91.21%. These results show the potential of using the proposed methods for the actual prosthesis. In the future, we will optimize the SNN training method to improve the training speed and stability.},
  archive      = {J_CC},
  author       = {Yang, Yikang and Ren, Jia and Duan, Feng},
  doi          = {10.1007/s12559-022-10027-1},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1257-1272},
  shortjournal = {Cogn. Comput.},
  title        = {The spiking rates inspired encoder and decoder for spiking neural networks: An illustration of hand gesture recognition},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 1D multi-point local ternary pattern: A novel feature
extraction method for analyzing cognitive engagement of students in
flipped learning pedagogy. <em>CC</em>, <em>15</em>(4), 1243–1256. (<a
href="https://doi.org/10.1007/s12559-022-10023-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flipped learning is a blended learning method based on academic engagement of students online (outside class) and offline (inside class). In this learning pedagogy, students receive lesson any time from lecture videos pre-loaded on digital platform at their convenience places and it is followed by in-classroom activities such as doubt clearing, problem solving, etc. However, students are constantly exposed to high levels of distraction in this age of the Internet. Therefore, it is hard for an instructor to know whether a student has paid attention while watching pre-loaded lecture video. In order to analyze attention level of individual students, captured brain signal or electroencephalogram (EEG) of students can be utilized. In this study, we utilize a popular feature extraction technique called Local Binary Pattern (LBP) and improvise it to develop an enhanced feature selection method. The adapted feature selection method termed as 1D Multi-Point Local Ternary Pattern (1D MP-LTP) is used to extract unique features from collected electroencephalogram (EEG) signals. Standard classification techniques are exploited to classify the attention level of students. Experiments are conducted with the data captured at Intelligent Data Analysis Lab, NIT Rourkela, to show effectiveness of the proposed feature extraction technique. The proposed 1D Multi-Point Local Ternary Pattern (1D MP-LTP)-based classification techniques outperform traditional and state-of-the-art classification techniques using LBP. This research can be helpful for instructors to identify students who need special care for improving their learning ability. Researchers in educational technology can extend this work by adopting this methodology in other online teaching pedagogy such as Massive Open Online Courses (MOOC).},
  archive      = {J_CC},
  author       = {Shaw, Rabi and Mohanty, Chinmay and Patra, Bidyut Kr. and Pradhan, Animesh},
  doi          = {10.1007/s12559-022-10023-5},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1243-1256},
  shortjournal = {Cogn. Comput.},
  title        = {1D multi-point local ternary pattern: A novel feature extraction method for analyzing cognitive engagement of students in flipped learning pedagogy},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Heterogeneous axonal delay improves the spiking activity
propagation on a toroidal network. <em>CC</em>, <em>15</em>(4),
1231–1242. (<a
href="https://doi.org/10.1007/s12559-022-10034-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several studies have looked into how noise affects neural networks and actual brains as evidenced by transcranial random noise stimulation, which improves cognitive performance. This research aims to broaden this understanding by concentrating on the network structural heterogeneity realized by adding noise to a neural model network’s axonal propagation delay. We utilized the pyNEST neural network simulator to model a network of 400 artificial Izhikevich neurons connected by a folded von Neumann neighborhood to form a toroidal shape where axonal propagation noise simulates a variable spatial spacing between neurons. In this network only one neuron is regularly spiking at first because it is specifically stimulated by a 10mA external current, while all the other neurons have no external input and are stimulated solely by the activity of their neighbors. The forward propagation of the spiking wave from the original neuron to its neighbors, and then to distant nodes on the toroidal network, was investigated. For each simulation, we recorded the activity of all the network changing several parameters to verify differences of spike activity in different positions on the torus. By manipulating heterogeneity, we discovered that adding noise helps the signal reach distant neurons in 20% less time, compared to when there is no heterogeneity. We demonstrated for the first time that structural heterogeneity in a neural network can favor the propagation of spiking waves. This result is in line with other findings that suggest that a certain level of noise is good for the brain, extending this concept to the network physical structure.},
  archive      = {J_CC},
  author       = {Salustri, Marcello and Micheletto, Ruggero},
  doi          = {10.1007/s12559-022-10034-2},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1231-1242},
  shortjournal = {Cogn. Comput.},
  title        = {Heterogeneous axonal delay improves the spiking activity propagation on a toroidal network},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Organization and priming of long-term memory representations
with two-phase plasticity. <em>CC</em>, <em>15</em>(4), 1211–1230. (<a
href="https://doi.org/10.1007/s12559-022-10021-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recurrent neural networks in the brain, memories are represented by so-called Hebbian cell assemblies. Such assemblies are groups of neurons with particularly strong synaptic connections formed by synaptic plasticity and consolidated by synaptic tagging and capture (STC). To link these synaptic mechanisms to long-term memory on the level of cognition and behavior, their functional implications on the level of neural networks have to be understood. We employ a biologically detailed recurrent network of spiking neurons featuring synaptic plasticity and STC to model the learning and consolidation of long-term memory representations. Using this, we investigate the effects of different organizational paradigms, and of priming stimulation, on the functionality of multiple memory representations. We quantify these effects by the spontaneous activation of memory representations driven by background noise. We find that the learning order of the memory representations significantly biases the likelihood of activation towards more recently learned representations, and that hub-like overlap structure counters this effect. We identify long-term depression as the mechanism underlying these findings. Finally, we demonstrate that STC has functional consequences for the interaction of long-term memory representations: 1. intermediate consolidation in between learning the individual representations strongly alters the previously described effects, and 2. STC enables the priming of a long-term memory representation on a timescale of minutes to hours. Our findings show how synaptic and neuronal mechanisms can provide an explanatory basis for known cognitive effects.},
  archive      = {J_CC},
  author       = {Luboeinski, Jannik and Tetzlaff, Christian},
  doi          = {10.1007/s12559-022-10021-7},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1211-1230},
  shortjournal = {Cogn. Comput.},
  title        = {Organization and priming of long-term memory representations with two-phase plasticity},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust resting-state dynamics in a large-scale spiking
neural network model of area CA3 in the mouse hippocampus. <em>CC</em>,
<em>15</em>(4), 1190–1210. (<a
href="https://doi.org/10.1007/s12559-021-09954-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hippocampal area CA3 performs the critical auto-associative function underlying pattern completion in episodic memory. Without external inputs, the electrical activity of this neural circuit reflects the spontaneous spiking interplay among glutamatergic Pyramidal neurons and GABAergic interneurons. However, the network mechanisms underlying these resting-state firing patterns are poorly understood. Leveraging the Hippocampome.org knowledge base, we developed a data-driven, large-scale spiking neural network (SNN) model of mouse CA3 with 8 neuron types, 90,000 neurons, 51 neuron-type specific connections, and 250,000,000 synapses. We instantiated the SNN in the CARLsim4 multi-GPU simulation environment using the Izhikevich and Tsodyks-Markram formalisms for neuronal and synaptic dynamics, respectively. We analyzed the resultant population activity upon transient activation. The SNN settled into stable oscillations with a biologically plausible grand-average firing frequency, which was robust relative to a wide range of transient activation. The diverse firing patterns of individual neuron types were consistent with existing knowledge of cell type-specific activity in vivo. Altered network structures that lacked neuron- or connection-type specificity were neither stable nor robust, highlighting the importance of neuron type circuitry. Additionally, external inputs reflecting dentate mossy fibers shifted the observed rhythms to the gamma band. We freely released the CARLsim4-Hippocampome framework on GitHub to test hippocampal hypotheses. Our SNN may be useful to investigate the circuit mechanisms underlying the computational functions of CA3. Moreover, our approach can be scaled to the whole hippocampal formation, which may contribute to elucidating how the unique neuronal architecture of this system subserves its crucial cognitive roles.},
  archive      = {J_CC},
  author       = {Kopsick, Jeffrey D. and Tecuatl, Carolina and Moradi, Keivan and Attili, Sarojini M. and Kashyap, Hirak J. and Xing, Jinwei and Chen, Kexin and Krichmar, Jeffrey L. and Ascoli, Giorgio A.},
  doi          = {10.1007/s12559-021-09954-2},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1190-1210},
  shortjournal = {Cogn. Comput.},
  title        = {Robust resting-state dynamics in a large-scale spiking neural network model of area CA3 in the mouse hippocampus},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spiking recurrent neural networks represent task-relevant
neural sequences in rule-dependent computation. <em>CC</em>,
<em>15</em>(4), 1167–1189. (<a
href="https://doi.org/10.1007/s12559-022-09994-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prefrontal cortical neurons play essential roles in performing rule-dependent tasks and working memory-based decision making. Motivated by PFC recordings of task-performing mice, we developed an excitatory–inhibitory spiking recurrent neural network (SRNN) to perform a rule-dependent two-alternative forced choice (2AFC) task. We imposed several important biological constraints onto the SRNN and adapted spike frequency adaptation (SFA) and SuperSpike gradient methods to train the SRNN efficiently. The trained SRNN produced emergent rule-specific tunings in single-unit representations, showing rule-dependent population dynamics that resembled experimentally observed data. Under various test conditions, we manipulated the SRNN parameters or configuration in computer simulations, and we investigated the impacts of rule-coding error, delay duration, recurrent weight connectivity and sparsity, and excitation/inhibition (E/I) balance on both task performance and neural representations. Overall, our modeling study provides a computational framework to understand neuronal representations at a fine timescale during working memory and cognitive control and provides new experimentally testable hypotheses in future experiments.},
  archive      = {J_CC},
  author       = {Xue, Xiaohe and Wimmer, Ralf D. and Halassa, Michael M. and Chen, Zhe Sage},
  doi          = {10.1007/s12559-022-09994-2},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1167-1189},
  shortjournal = {Cogn. Comput.},
  title        = {Spiking recurrent neural networks represent task-relevant neural sequences in rule-dependent computation},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spiking memory policy with population-encoding for partially
observable markov decision process problems. <em>CC</em>,
<em>15</em>(4), 1153–1166. (<a
href="https://doi.org/10.1007/s12559-022-10030-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural network (SNN), as the next-generation neural network inspired by the human brain, has been proved to be promising for constructing energy-efficient systems due to its inherent property of dynamic representation and information processing mechanism. For applications in deep reinforcement learning (DRL), however, the actual performance of SNNs is usually weaker than that of deep neural networks in high-dimensional continuous control. Related studies have shown that SNN suffers from insufficient model representation capacity and ineffective parameter training methods. To advance SNN to the practical application level, we aim at challenging partially observable Markov decision process (POMDP) high-dimensional control problems. Based on Twin Delayed Deep Deterministic Policy Gradient algorithm (TD3), we propose a Spiking Memory TD3 algorithm (SM-TD3), which is a hybrid training framework of a spiking Long Short-Term Memory (Spiking-LSTM) policy network and a deep critic network. The policy leverages population-encoding to improve input encoding precision, spiking-LSTM to provide memory function, and spatio-temporal backpropagation to train parameters. We use the Pybullet benchmark to test the performance of SM-TD3 and set up comparisons in three cases of full-observation Markov decision process (MDP), random noise, and random sensor missing. The results show that SM-TD3 with SNN energy-efficient framework solves the POMDP problems under large-scale and high-dimensional tasks. It reaches the same performance level as the deep LSTM-TD3 algorithm. At the same time, SM-TD3 still has competitive robustness when transferred to the same environment in different situations. Finally, we analyze the energy consumption of SM-TD3. Compared with the energy consumption of deep LSTM-TD3, the energy consumption of SM-TD3 is only $$20\%~50\%$$ of that. Facing the practical application level, the proposed SM-TD3 provides an effective solution for both high-performance and energy-efficient.},
  archive      = {J_CC},
  author       = {Cheng, Hao and Duan, Feng and He, Maochang},
  doi          = {10.1007/s12559-022-10030-6},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1153-1166},
  shortjournal = {Cogn. Comput.},
  title        = {Spiking memory policy with population-encoding for partially observable markov decision process problems},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neurolib: A simulation framework for whole-brain neural mass
modeling. <em>CC</em>, <em>15</em>(4), 1132–1152. (<a
href="https://doi.org/10.1007/s12559-021-09931-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {neurolib is a computational framework for whole-brain modeling written in Python. It provides a set of neural mass models that represent the average activity of a brain region on a mesoscopic scale. In a whole-brain network model, brain regions are connected with each other based on biologically informed structural connectivity, i.e., the connectome of the brain. neurolib can load structural and functional datasets, set up a whole-brain model, manage its parameters, simulate it, and organize its outputs for later analysis. The activity of each brain region can be converted into a simulated BOLD signal in order to calibrate the model against empirical data from functional magnetic resonance imaging (fMRI). Extensive model analysis is made possible using a parameter exploration module, which allows one to characterize a model’s behavior as a function of changing parameters. An optimization module is provided for fitting models to multimodal empirical data using evolutionary algorithms. neurolib is designed to be extendable and allows for easy implementation of custom neural mass models, offering a versatile platform for computational neuroscientists for prototyping models, managing large numerical experiments, studying the structure–function relationship of brain networks, and for performing in-silico optimization of whole-brain models.},
  archive      = {J_CC},
  author       = {Cakan, Caglar and Jajcay, Nikola and Obermayer, Klaus},
  doi          = {10.1007/s12559-021-09931-9},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1132-1152},
  shortjournal = {Cogn. Comput.},
  title        = {Neurolib: A simulation framework for whole-brain neural mass modeling},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Testing an explicit method for multi-compartment neuron
model simulation on a GPU. <em>CC</em>, <em>15</em>(4), 1118–1131. (<a
href="https://doi.org/10.1007/s12559-021-09942-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale simulation of multi-compartment models is important for understanding the role of morphological structures of individual neurons for information processing in the brain. In a simulation, partial differential equations (PDEs) that describe the dynamics of neurons have to be solved numerically for each time step. To solve PDEs, numerical methods called implicit methods are used for stability. Implicit methods need to solve simultaneous equations, which can make numerical simulation slow on graphics processing units (GPUs) hardware accelerators for parallel computing. To overcome this problem, we investigated the use of explicit methods for multi-compartment model simulation. We applied the Runge–Kutta–Chebyshev (RKC) method to several cerebellar neuron models including Purkinje cells, granule cells, Golgi cells, and inferior olive cells. Next, we implemented a cerebellar cortical model composed of granule cells, Golgi cells, and Purkinje cells, while using different numerical methods for different cell types. Although explicit methods can be unstable against PDEs, using the RKC method showed sufficient stability for most cases, better computational performance than implicit methods on a GPU, and good reproducibility. In the network simulation, choosing the suitable numerical methods for each cell type achieved faster simulation than that used an implicit method solely. Our results suggest that explicit methods are applicable to multi-compartment models and can accelerate computational speed of simulations. Furthermore, to conduct large-scale simulation of multi-compartment models, choosing efficient numerical methods will be more important.},
  archive      = {J_CC},
  author       = {Kobayashi, Taira and Kuriyama, Rin and Yamazaki, Tadashi},
  doi          = {10.1007/s12559-021-09942-6},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1118-1131},
  shortjournal = {Cogn. Comput.},
  title        = {Testing an explicit method for multi-compartment neuron model simulation on a GPU},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detection of autism spectrum disorder using fMRI functional
connectivity with feature selection and deep learning. <em>CC</em>,
<em>15</em>(4), 1106–1117. (<a
href="https://doi.org/10.1007/s12559-021-09981-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism spectrum disorder (ASD) is notoriously difficult to diagnose despite having a high prevalence. Existing studies have shifted toward using neuroimaging data to enhance the clinical applicability and the effectiveness of the diagnostic results. However, the time and financial resources required to scan neuroimages restrict the scale of the datasets and further weaken the generalization ability of the statistical results. Furthermore, multi-site datasets collected by multiple worldwide institutions make it difficult to apply machine learning methods due to their heterogeneity. We propose a deep learning approach combined with the F-score feature selection method for ASD diagnosis using a functional magnetic resonance imaging (fMRI) dataset. The proposed method is evaluated on the worldwide fMRI dataset, known as ABIDE (Autism Brain Imaging Data Exchange). The fMRI functional connectivity features selected using our method can achieve an average accuracy of 64.53% on intra-site datasets and an accuracy of 70.9% on the whole ABIDE dataset. Moreover, based on the selected features, the network topology analysis showed a significant decrease in the path length and the cluster coefficient in ASD, indicating a loss of small-world architecture to a random network. The altered brain network may provide insight into the underlying pathology of ASD, and the functional connectivity features selected by our method may serve as biomarkers.},
  archive      = {J_CC},
  author       = {Zhang, Jin and Feng, Fan and Han, Tianyi and Gong, Xiaoli and Duan, Feng},
  doi          = {10.1007/s12559-021-09981-z},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1106-1117},
  shortjournal = {Cogn. Comput.},
  title        = {Detection of autism spectrum disorder using fMRI functional connectivity with feature selection and deep learning},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Brain simulation and spiking neural networks. <em>CC</em>,
<em>15</em>(4), 1103–1105. (<a
href="https://doi.org/10.1007/s12559-023-10156-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CC},
  author       = {Sun, Zhe and Cutsuridis, Vassilis and Caiafa, Cesar F. and Solé-Casals, Jordi},
  doi          = {10.1007/s12559-023-10156-1},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1103-1105},
  shortjournal = {Cogn. Comput.},
  title        = {Brain simulation and spiking neural networks},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning-based stock trending prediction by incorporating
technical indicators and social media sentiment. <em>CC</em>,
<em>15</em>(3), 1092–1102. (<a
href="https://doi.org/10.1007/s12559-023-10125-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock trending prediction is a challenging task due to its dynamic and nonlinear characteristics. With the development of social platform and artificial intelligence (AI), incorporating timely news and social media information into stock trending models becomes possible. However, most of the existing works focus on classification or regression problems when predicting stock market trending without fully considering the effects of different influence factors in different phases. To address this gap, this research solves stock trending prediction problem utilizing both technical indicators and sentiments of the social media text as influence factors in different situations. A 3-phase hybrid model is proposed where daily sentiment values and technical indicators are considered when predicting the trends of the stocks. The proposed method leverages both traditional learning and deep learning methods as the core predictors in different phases. Accuracy and F1-score are used to evaluate the performance of the proposed method. Incorporating the technical indicators and social media sentiments, the performance of the proposed method with different learning-based methods as core predictors is analyzed and compared in different situations. Specifically, multi-layer perceptron (MLP), naïve bayes (NB), decision tree (DT), logistic regression (LR), random forest (RF), extreme gradient boosting (XGBoost), long short-term memory (LSTM), and convolutional neural networks (CNN) are leveraged as the core learning predictor module, with different combinations of the degree of involvement of technical and sentiment information. The result demonstrates the effectiveness of the proposed method with an accuracy of 73.41% and F1-score of 84.19%. The result also shows that various learning-based methods perform differently for the prediction of different stocks. This research not only demonstrates the merits of the proposed method, it also shows that integrating social opinions with technical indicators is a right direction for enhancing the performance of learning-based stock market trending analysis methods.},
  archive      = {J_CC},
  author       = {Wang, Zhaoxia and Hu, Zhenda and Li, Fang and Ho, Seng-Beng and Cambria, Erik},
  doi          = {10.1007/s12559-023-10125-8},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1092-1102},
  shortjournal = {Cogn. Comput.},
  title        = {Learning-based stock trending prediction by incorporating technical indicators and social media sentiment},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CSAT-FTCN: A fuzzy-oriented model with contextual
self-attention network for multimodal emotion recognition. <em>CC</em>,
<em>15</em>(3), 1082–1091. (<a
href="https://doi.org/10.1007/s12559-023-10119-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal emotion analysis has become a hot trend because of its wide applications, such as the question-answering system. However, in a real-world scenario, people usually have mixed or partial emotions about evaluating objects. In this paper, we introduce a fuzzy temporal convolutional network based on contextual self-attention (CSAT-FTCN) to address these challenges, which has a membership function modeling various fuzzy emotions for understanding emotions in a more profound sense. Moreover, the CSAT-FTCN can obtain the dependency relationships of target utterances on internal own key information and external contextual information to understand emotions in a more profound sense. Additionally, as for multi-modality data, we introduce an attention fusion (ATF) mechanism to capture the dependency relationship between different modality information. The experimental results show that our CSAT-FTCN outperforms state-of-the-art models on tested datasets. The CSAT-FTCN network provides a novel method for multimodal emotion analysis.},
  archive      = {J_CC},
  author       = {Jiang, Dazhi and Liu, Hao and Wei, Runguo and Tu, Geng},
  doi          = {10.1007/s12559-023-10119-6},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1082-1091},
  shortjournal = {Cogn. Comput.},
  title        = {CSAT-FTCN: A fuzzy-oriented model with contextual self-attention network for multimodal emotion recognition},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving sentiment classification performance through
coaching architectures. <em>CC</em>, <em>15</em>(3), 1065–1081. (<a
href="https://doi.org/10.1007/s12559-022-10018-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent systems have been developed for years to solve specific tasks automatically. An important issue emerges when the information used by these systems exhibits a dynamic nature and evolves. This fact adds a level of complexity that makes these systems prone to a noticeable worsening of their performance. Thus, their capabilities have to be upgraded to address these new requirements. Furthermore, this problem is even more challenging when the information comes from human individuals and their interactions through language. This issue happens more easily and forcefully in the specific domain of Sentiment Analysis, where feelings and opinions of humans are in constant evolution. In this context, systems are trained with an enormous corpus of textual content, or they include an extensive set of words and their related sentiment values. These solutions are usually static and generic, making their manual upgrading almost unworkable. In this paper, an automatic and interactive coaching architecture is proposed. It includes a ML framework and a dictionary-based system both trained for a specific domain. These systems converse about the outcomes obtained during their respective learning stages by simulating human interactive coaching sessions. This leads to an Active Learning process where the dictionary-based system acquires new information and improves its performance. More than 800, 000 tweets have been gathered and processed for experiments. Outstanding results were obtained when the proposed architecture was used. Also, the lexicon was updated with the prior and new words related to the corpus used which is important to reach a better sentiment analysis classification.},
  archive      = {J_CC},
  author       = {Fernández-Isabel, Alberto and Cabezas, Javier and Moctezuma, Daniela and de Diego, Isaac Martín},
  doi          = {10.1007/s12559-022-10018-2},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1065-1081},
  shortjournal = {Cogn. Comput.},
  title        = {Improving sentiment classification performance through coaching architectures},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint and individual feature fusion hashing for multi-modal
retrieval. <em>CC</em>, <em>15</em>(3), 1053–1064. (<a
href="https://doi.org/10.1007/s12559-022-10086-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised multi-modal hashing has received considerable attention in large-scale multimedia retrieval areas since its low storage and high search speed. Existing unsupervised multi-modal hashing methods usually aim to mine the complementary information and the structural information for different modalities and preserve them in low-dimensional discrete space. The main limitations are two folds: (1) The shared semantic properties and the specific-modality information between multi-modal data are not explored simultaneously, which limits the improvement of retrieval accuracy. (2) Most multi-modal hashing methods with rough fusion manners cause greatly the information loss. In this paper, we present an unsupervised Joint and Individual Feature Fusion Hashing (JIFFH) that jointly performs the unified feature learning and individual feature learning. A two-layer fusion architecture with an adaptive weighting scheme is adopted to fuse effectively the common semantic properties and the specific-modality data information. The experimental results on three public multi-modal datasets show that our proposed method is better than state-of-the-art unsupervised multi-modal hashing methods. In conclusion, the proposed JIFFH method is very effective to learn discriminative hash codes and can boost retrieval performance.},
  archive      = {J_CC},
  author       = {Yu, Jun and Zheng, Yukun and Wang, Yinglin and Li, Zuhe and Zhu, Liang},
  doi          = {10.1007/s12559-022-10086-4},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1053-1064},
  shortjournal = {Cogn. Comput.},
  title        = {Joint and individual feature fusion hashing for multi-modal retrieval},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A dense-layered deep neural model-based classification of
brain hemorrhages using head computer tomography images. <em>CC</em>,
<em>15</em>(3), 1042–1052. (<a
href="https://doi.org/10.1007/s12559-022-10090-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) refers to the ability to learn, remember, predict, and make an optimal judgment based on Computer-assisted Design (CAD) Systems. Traditional CAD algorithms and methods on head CT scans focused on the automatic recognition, segmentation, and classification of the abnormalities. But, these approaches were encountered with several limitations like (i) smaller dataset size, (ii) negative Transfer Learning, and (iii) improper localization. This paper proposed the new dense-layered deep neural model to classify brain hemorrhages using head CT scans. The proposed model is the ten-layered network having dense blocks with skip connections. It uses the cross-chained connection between dense blocks to minimize gradient loss while training. Later, the last layer of the model is extended with Grad-Cam for localization of the affected cell regions. The model performance is evaluated on a dataset of head CT scans of size 427.25GB. The dataset is partitioned into 752,800 images in the training set and 121,232 images in the testing set. The experimentation results achieved an accuracy of 98.32% with a mean logarithmic loss of 0.06487. The average classification accuracy of the proposed model on multiple-class hemorrhages is 98.27%. The experimentation results are found satisfactory having the best AUC-ROC accuracy of 98.32%. The comparative analysis of the model with other traditional deep neural networks proves the efficacy of the model in predicting results. Also, in comparison with other methods, the gained results are found satisfactory with an increase in the accuracy of 1.3%.},
  archive      = {J_CC},
  author       = {Vidyarthi, Ankit},
  doi          = {10.1007/s12559-022-10090-8},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1042-1052},
  shortjournal = {Cogn. Comput.},
  title        = {A dense-layered deep neural model-based classification of brain hemorrhages using head computer tomography images},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel stock index direction prediction based on dual
classifier coupling and investor sentiment analysis. <em>CC</em>,
<em>15</em>(3), 1023–1041. (<a
href="https://doi.org/10.1007/s12559-023-10137-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of stock trends is of great crucial to guiding investment management and financial policymaking. In recent years, text content generated by investors on various media platforms has had a big impact on stock movements. However, most of the existing studies apply equal weight to the text content to construct the sentiment index and ignore the fact that the influence of the sentiment index on the stock market will decrease with the increase of time interval. In this paper, we propose a model based on dual classifier coupling and sentiment analysis to study the trend of stock index. (1) We come up with a sentiment index weighted based on the reading volume to predict the trend of the stock index. (2) The exponentially weighted moving average (EWMA) model is used to modify the weighted sentiment index to obtain the modified sentiment index. (3) The maximum information coefficient (MIC) is applied to calculate the correlation between the closing price of the stock index and the modified sentiment index to obtain the best-modified sentiment index. (4) Two frequently used classifiers, convolutional neural network (CNN) and support vector machine (SVM), are used to build a dual-classifier coupling prediction model and adopt it for the final classification prediction. Two Chinese stock indexes (SSE 50 and CSI 300) are used to evaluate the predictive effect of the proposed model. In the practice case of the SSE 50 Index, the precision, accuracy, recall rate, F1-score, and AUC reached 81.38%, 80.99%, 80.99%, 81.04%, and 81.22%, respectively, after adding the modified sentiment index. In the practical case of the CSI 300 Index, the precision, accuracy, recall rate, F1-score, and AUC reached 80.07%, 80.07%, 80.07%, 80.06%, and 80.03%, respectively, after adding the modified sentiment index. It can be found through the experimental results that adding the investor sentiment index can advance the trend prediction of the stock index, and adding the modified sentiment index has a more obvious improvement effect. After adding the modified investor sentiment index, the prediction results of our proposed two-classifier coupled CNN-SVM model are much better than other benchmark models.},
  archive      = {J_CC},
  author       = {Wang, Jujie and Zhu, Shuzhou},
  doi          = {10.1007/s12559-023-10137-4},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1023-1041},
  shortjournal = {Cogn. Comput.},
  title        = {A novel stock index direction prediction based on dual classifier coupling and investor sentiment analysis},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-scale convolutional neural network for temporal
knowledge graph completion. <em>CC</em>, <em>15</em>(3), 1016–1022. (<a
href="https://doi.org/10.1007/s12559-023-10134-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph completion is a critical task in natural language processing. The task becomes more challenging on temporal knowledge graph, where each fact is associated with a timestamp. Currently, cognitive science has revealed that the time-dependent historical experience can activate the neurons, and time-related and the static information should be fused to represent the happened facts. Meanwhile, there are correspondence between the CNN model and the biological cortex in several aspects, correspondingly, different levels of cortex information can be described using different sizes of convolution kernels. Most existing methods for temporal knowledge graph completion learn the time-varying relation embeddings by scaling with the number of entities or timestamps, and then use the dot production between the embeddings of entities and relations as the quadruple’s loss. However, the dot product cannot well describe the complex interaction between the embeddings. Inspired by this theory, this paper proposes multi-scale convolutional neural network (MsCNN), which utilizes both static and dynamic information to represent the relations’ embeddings, and uses convolution operation to learn the mutual information between the embeddings of time-varying relations and entities. Besides, multi-scale convolution kernels are utilized to learn the mutual information at different levels. We also verified that with the increase of the dimension of embeddings, the performance increases. The performance of MsCNN on three benchmark datasets achieves state-of-the-art link prediction results. The MsCNN can well fuse the static and temporal information and explore different levels of mutual information between the input embeddings.},
  archive      = {J_CC},
  author       = {Liu, Wei and Wang, Peijie and Zhang, Zhihui and Liu, Qiong},
  doi          = {10.1007/s12559-023-10134-7},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1016-1022},
  shortjournal = {Cogn. Comput.},
  title        = {Multi-scale convolutional neural network for temporal knowledge graph completion},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improvement of facial beauty prediction using artificial
human faces generated by generative adversarial network. <em>CC</em>,
<em>15</em>(3), 998–1015. (<a
href="https://doi.org/10.1007/s12559-023-10117-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human beauty evaluation is a particularly difficult task. This task can be solved using deep learning methods. We propose a new method for determining the attractiveness of a face by using the generation of synthetic data. Our approach uses the generative adversarial network (GAN) to generate an artificial face and then predict the facial beauty of the generated face to improve facial beauty predictions. A study of images with different brightness and contrast showed that the methods using the convolutional neural network (CNN) model have fewer errors than compared to the multilayer perceptron (MLP) model that uses the method. The MLP model only responds to geometric facial proportions, whereas the CNN model additionally responds to changes in face color. Using the synthetic face instead of the real face improves the determination of accuracy of the facial attractiveness. The ability to appreciate facial beauty also opens the way for facial beauty modifications in a latent space. Further research could improve facial normalization in the latent space to improve the accuracy of facial beauty determination.},
  archive      = {J_CC},
  author       = {Laurinavičius, Donatas and Maskeliūnas, Rytis and Damaševičius, Robertas},
  doi          = {10.1007/s12559-023-10117-8},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {998-1015},
  shortjournal = {Cogn. Comput.},
  title        = {Improvement of facial beauty prediction using artificial human faces generated by generative adversarial network},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prototype theory meets word embedding: A novel approach for
text categorization via granular computing. <em>CC</em>, <em>15</em>(3),
976–997. (<a href="https://doi.org/10.1007/s12559-023-10132-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of the information representation and interpretation coming from senses by the brain has plagued scientists for decades. The same problems, from a different perspective, hold in automated Pattern Recognition systems. Specifically, in solving various NLP tasks, an ever better and richer semantic representation of text as a set of features is needed and a plethora of text embedding techniques in algebraic spaces are continuously provided by researchers. These spaces are well suited to be conceived as conceptual spaces in light of the Gärdenfors’s Conceptual Space theory, which, within the Cognitive Science paradigm, seeks a geometrization of thought that bridges the gap between an associative lower level and a symbolic higher level in which information is organized and processed and where inductive reasoning is appropriate. Granular Computing can offer the toolbox for granulating text that can be represented by more abstract entities than words, offering a good hierarchical representation of the text embedded in an algebraic space driving Machine Learning applications, specifically, in text mining tasks. In this paper, the Conceptual Space Theory, the Granular Computing approach and Machine Learning are bound in a novel common framework for solving some text categorization tasks with both standard classifiers suited for working with $$\mathbb {R}^n$$ vectors and a Recurrent Neural Network (RNN) — an LSTM — able to deal with sequences. Instead of working with word vectors, the algorithms process more abstract entities (concepts), where patterns, in a first approach, are obtained through the construction of a symbolic histogram starting from a suitable set of information granules, representing a document as a distribution of concepts. For the RNN case, as a further novelty, a text is represented as a random walk over prototypes within the conceptual space synthesized over a suitable text embedding procedure. A comparison of the performance and a critical discussion are offered for both a neural embedding technique and the well-known LSA, showing how the conceptual level leads also to Knowledge Discovery applications.},
  archive      = {J_CC},
  author       = {De Santis, Enrico and Rizzi, Antonello},
  doi          = {10.1007/s12559-023-10132-9},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {976-997},
  shortjournal = {Cogn. Comput.},
  title        = {Prototype theory meets word embedding: A novel approach for text categorization via granular computing},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A grouping cooperative differential evolution algorithm for
solving partially separable complex optimization problems. <em>CC</em>,
<em>15</em>(3), 956–975. (<a
href="https://doi.org/10.1007/s12559-023-10128-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution (DE) is a widely accepted optimization algorithm inspired by the mechanisms of biological evolution for complex optimization problems. In this paper, we put forward a co-evolutionary differential evolution (CDE) with a differential grouping (DG) mechanism to solve the complex optimization problems in which the variables are partially separable. In the CDE, a complex problem with coupled multivariable is decomposed by DG into certain independent sub-problems easy to be solved. Then polling, upper confidence bound (UCB), and random access are introduced to allocate search resources for multiple decoupled sub-problems, respectively. Finally, success-history-based parameter adaptation for differential evolution (SHADE) is adopted as a search engine to solve each sub-problem. The results of experiments on the CEC2017 show that CDE achieves a competitive search performance compared to other peer algorithms. This study suggests that the combination of DG strategy and polling method can effectively solve the optimization problem with partially separable variables.},
  archive      = {J_CC},
  author       = {Chen, Zuohan and Cao, Jie and Zhao, Fuqing and Zhang, Jianlin},
  doi          = {10.1007/s12559-023-10128-5},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {956-975},
  shortjournal = {Cogn. Comput.},
  title        = {A grouping cooperative differential evolution algorithm for solving partially separable complex optimization problems},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SRFFNet: Self-refine, fusion and feedback for salient object
detection. <em>CC</em>, <em>15</em>(3), 943–955. (<a
href="https://doi.org/10.1007/s12559-023-10130-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many existing salient object detection models have achieved excellent results by fusing the progressive multi-layer features extracted by the backbone network. However, although the convolutional neural network can extract features from different levels, the computer obviously cannot distinguish the helpful information in the feature map. Feature fusion is usually achieved by adding or concatenating different levels of feature maps at the pixel level. However, these operations ignore the connection between multi-level features and global features. At the same time, the traditional U-shaped network structure can easily cause the salient map boundary to be blurred. In this paper, we proposed a Self-refine Fusion Feedback Network (SRFFNet) to solve these problems, which mainly consists of the self-refine module (SRM), feature fusion module (FFM), global optimization module (GOM) and feedback module (FM). Inspired by the cognitive process of biology, we designed a self-refine module based on human self-regulation ability. Similarly, we designed a feature fusion module based on biological diversity to extract diversity feature information. Furthermore, we also designed a feedback module based on biofeedback nerves. Particularly, SRM is used to realize the integration and optimization of the feature information. GOM is to obtain the feature map of global information, which is obtained after processing by the SRM module. FFM adaptively selects the feature information of two adjacent layers and global information for progressive fusion. FM can pass the feature map of the prediction result into the feature layer for the second stage to optimize the final salient map. In addition, we also proposed a weighted loss function to optimize the training loss to achieve better performance. Experimental results demonstrate that the proposed method achieves advanced performance with state-of-the-art methods. The SRFFNet can accurately segment the salient object area and provide clear boundaries and more detailed information.},
  archive      = {J_CC},
  author       = {Wu, Shuang and Zhang, Guangjian},
  doi          = {10.1007/s12559-023-10130-x},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {943-955},
  shortjournal = {Cogn. Comput.},
  title        = {SRFFNet: Self-refine, fusion and feedback for salient object detection},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GLAN: GAN assisted lightweight attention network for
biomedical imaging based diagnostics. <em>CC</em>, <em>15</em>(3),
932–942. (<a href="https://doi.org/10.1007/s12559-023-10131-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manual assessment of biomedical imaging based diagnostics is limited as it is time-consuming and subjective. Bio-inspired diagnostics applications on embedded and mobile devices are becoming more popular as they overcome these limitations and aid in early detection and diagnosis. The neural theory of visual attention puts forward that the processing resources are dedicated to more important information, for resource saving and performance improvement. Moreover, adversarial learning can potentially alleviate the various biases of the human cognitive system. The limited performance of the current lightweight network approaches can be attributed to the absence of above-mentioned properties of the human cognition. Accordingly, we introduce GLAN, a lightweight attention based network that is particularly well suited to embedded and mobile devices. GLAN’s design follows lightweight architecture design principles for encoder-decoder design. To improve performance a twofold novel strategy is adopted. Firstly, we equip the encoder and the decoder with lightweight attention mechanisms to increase their focus and improve segmentation performance. Secondly, adversarial learning is employed with augmentation to increase the generalization ability of the lightweight attention network. e have evaluated our GLAN on three different applications including lung segmentation, digestive tract polyp segmentation and optic disc segmentation. GLAN is quite competitive in terms of segmentation performance while comprehensively outperforming recent alternatives in terms of computational requirements. Specifically, GLAN requires 94.17%, 78.18%, 80.95% and 67.56% less computational parameters as compared with four recent lightweight alternatives. This advocates its application in real-time biomedical imaging diagnostics on embedded and mobile devices in clinical settings.},
  archive      = {J_CC},
  author       = {Naqvi, Syed S. and Langah, Zubair Akhtar and Khan, Haroon Ahmed and Khan, Majid Iqbal and Bashir, Tariq and Razzak, M. I. and Khan, Tariq M.},
  doi          = {10.1007/s12559-023-10131-w},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {932-942},
  shortjournal = {Cogn. Comput.},
  title        = {GLAN: GAN assisted lightweight attention network for biomedical imaging based diagnostics},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Aspect-based sentiment analysis of customer speech data
using deep convolutional neural network and BiLSTM. <em>CC</em>,
<em>15</em>(3), 914–931. (<a
href="https://doi.org/10.1007/s12559-023-10127-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The process of detecting sentiments of particular context from human speech emotions is naturally in-built for humans unlike computers, where it is not possible to process human emotions by a machine for predicting sentiments of a particular context. Though machines can easily understand the content-based information, accessing the real emotion behind it is difficult. Aspect-based sentiment analysis based on speech emotion recognition framework can bridge the gap between these problems. The proposed model helps people with autism spectrum disorder (ASD) to understand other’s sentiments expressed through speech data about the recently purchased product based on various aspects of the product. It is a framework through which different sound discourse documents are characterized into various feelings like happy, sad, anger, and neutral and label the sound with aspect-wise sentiment polarity. This study proposed a hybrid model using deep convolutional neural networks (DCNN) for speech emotion recognition, bidirectional long short term memory (BiLSTM) for speech aspect recognition, and rule-based classifier for aspect-wise sentiment classification. In the existing work, sentiment analysis was carried out on speech data, but aspect-based sentiment analysis on speech data was not carried out successfully. The proposed model extracted standard Mel frequency cepstral coefficient (MFCC) features from customer speech data about product review and generated aspect-wise sentiment label. Enhanced cat swarm optimization (ECSO) algorithm was used for selection features from the extracted feature in the proposed model that improved the overall sentiment classification accuracy. The proposed hybrid framework obtained promising results on sentiment classification accuracy of 93.28%, 91.45%, 92.12%, and 90.45% on four benchmark datasets. The proposed hybrid framework sentiment classification accuracy on these benchmark datasets were compared with other CNN variants and shown better performance. Sentiment classification accuracy of the proposed model with state-of-art methods on the four benchmark datasets was compared and shown better performance. Aspect classification accuracy of the proposed with state-of-art methods on the benchmark datasets was compared and shown better performance. The developed hybrid model using DCNN, BiLSTM, and rule-based classifier outperformed the state-of-art models for aspect-based sentiment analysis by incorporating ECSO algorithm in feature selection process. The proposed model will help to perform aspect-based sentiment analysis on all domains with specified aspect corpus.},
  archive      = {J_CC},
  author       = {Murugaiyan, Sivakumar and Uyyala, Srinivasulu Reddy},
  doi          = {10.1007/s12559-023-10127-6},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {914-931},
  shortjournal = {Cogn. Comput.},
  title        = {Aspect-based sentiment analysis of customer speech data using deep convolutional neural network and BiLSTM},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inductive multi-view semi-supervised learning with a
consensus graph. <em>CC</em>, <em>15</em>(3), 904–913. (<a
href="https://doi.org/10.1007/s12559-023-10123-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs have a crucial impact on the performance of any graph-based semi-supervised learning method, so their construction should be carefully considered. In this letter, and in the context of semi-supervised learning, we will address graph-based semi-supervised learning employing multiple views for the data. The notion of data smoothness is another missing concept in graph construction that should be considered when constructing graphs. Compared to a single feature, using multiple sources of information can increase the efficiency of the post-processing task that adopts the constructed graph. Therefore, we present an approach that merges the notions of data smoothness and label smoothness with label fitness and projection matrix calculation. Moreover, two or more views are merged to exploit the information hidden in different features. Experiments performed with image databases show the superiority of the proposed approach compared to single features and other competing fusion algorithms. Compared to recent fusion methods, the introduced scheme improved the semi-supervised classification performance. For example, on the MNIST dataset with 20 labeled images per class, the average improvement due to the proposed labeling inference was 4.4%. The proposed method is inductive and computes a linear mapping to obtain the label of unseen or test patterns.},
  archive      = {J_CC},
  author       = {Ziraki, N. and Bosaghzadeh, A. and Dornaika, F. and Ibrahim, Z. and Barrena, N.},
  doi          = {10.1007/s12559-023-10123-w},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {904-913},
  shortjournal = {Cogn. Comput.},
  title        = {Inductive multi-view semi-supervised learning with a consensus graph},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). OISVM: Optimal incremental support vector machine-based EEG
classification for brain-computer interface model. <em>CC</em>,
<em>15</em>(3), 888–903. (<a
href="https://doi.org/10.1007/s12559-023-10120-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The brain-computer interface (BCI) is a field of computer science where users can interact with devices in terms of brain signals. The brain signals are mimicked from the motor cortex without straining those muscles and without visualizing motor activity. By inserting various electrodes in the subject’s head, electroencephalography (EEG) is a technique used to capture the electrical patterns produced by the brain. The primary function of the EEG-based BCI is to track neural activity in the brain and convert it into signals or decisions. This paper presents a capuchin search algorithm (CSA)-optimized incremental support vector machine (ISVM) for the interpretation and classification of EEG-based BCI. The CSA is mainly incorporated to optimize the penalty and kernel parameters of the ISVM algorithm. The main aim of this paper is to aid in improving the interaction of stroke patients via computers by monitoring their thoughts. The features (electric signals), which contribute more to the output variable (hand movements), are identified via the sparse principal component analysis (SPCA) method. The proposed model is mainly trained and tested using the Berlin brain-computer interface (BCI) competition III datasets 4a and BCI competition IV datasets. The efficiency of the proposed model in analyzing the cortical sources is identified via different performance metrics such as accuracy, precision, F-score, etc. The proposed model offers accuracy, F1-score, and recall values of 92.24, 93.12, and 93.35%, respectively, which shows its efficiency in identifying hand, foot, or tongue movements.},
  archive      = {J_CC},
  author       = {Thanigaivelu, P. S. and Sridhar, S. S. and Sulthana, S. Fouziya},
  doi          = {10.1007/s12559-023-10120-z},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {888-903},
  shortjournal = {Cogn. Comput.},
  title        = {OISVM: Optimal incremental support vector machine-based EEG classification for brain-computer interface model},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Complex cubic fuzzy einstein averaging aggregation
operators: Application to decision-making problems. <em>CC</em>,
<em>15</em>(3), 869–887. (<a
href="https://doi.org/10.1007/s12559-022-10100-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different complex fuzzy sets are reported in the literature as the generalizations of fuzzy sets. Complex cubic fuzzy sets are also among those complex fuzzy sets, extensions of cubic sets. The main task is using complex cubic fuzzy sets in decision-making problems, and we propose some aggregation operators. We introduce the concept of complex cubic fuzzy ordered and hybrid weighted averaging operators using Einstein’s sum, product, scalar, and exponential multiplication. We discuss some algebraic operations of complex cubic fuzzy sets (CCFS) and their structural properties. We develop three arithmetic averaging operators: complex cubic fuzzy Einstein weighted averaging (CCFEWA), complex cubic fuzzy Einstein ordered weighted averaging (CCFEOWA), and complex cubic fuzzy Einstein hybrid weighted averaging (CCFEHWA) operators. The CCFEHWA operator generalizes both the CCFEWA and CCFEOWA operators. We apply the CCFEHWA operator to multiple attribute decision-making with complex cubic fuzzy data. In the end, we discuss a numerical example with comparative analysis.},
  archive      = {J_CC},
  author       = {Tanoli, Muhammad Naeem Khan and Gulistan, Muhammad and Amin, Fazli and Khan, Zahid and Al-Shamiri, Mohammed M.},
  doi          = {10.1007/s12559-022-10100-9},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {869-887},
  shortjournal = {Cogn. Comput.},
  title        = {Complex cubic fuzzy einstein averaging aggregation operators: Application to decision-making problems},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human vision attention mechanism-inspired temporal-spatial
feature pyramid for video saliency detection. <em>CC</em>,
<em>15</em>(3), 856–868. (<a
href="https://doi.org/10.1007/s12559-023-10114-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the human vision attention mechanism, the human vision system uses multilevel features to extract accurate visual saliency information, so multilevel features are important for saliency detection. On the basis of the numerous biological frameworks for visual information processing, we find that better combination and use of multilevel features with time information can greatly improve the accuracy of the video saliency model. The proposed TSFP-Net has the advantages of much higher prediction precision, simple structure, second smallest size, and the third fastest running time compared to the state-of-the-art methods. The encoder extracts multiscale temporal-spatial features from the input continuous video frames and then constructs a temporal-spatial feature pyramid through temporal-spatial convolution and top-down feature integration. The decoder performs hierarchical decoding of temporal-spatial features from different scales and finally produces a saliency map from the integration of multiple video frames. Our model is simple yet effective and can run in real time. We perform abundant experiments, and the results indicate that the well-designed structure can significantly improve the precision of video saliency detection. Experimental results on three purely visual video saliency benchmarks demonstrate that our method outperforms the existing state-of-the-art methods.},
  archive      = {J_CC},
  author       = {Chang, Qinyao and Zhu, Shiping},
  doi          = {10.1007/s12559-023-10114-x},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {856-868},
  shortjournal = {Cogn. Comput.},
  title        = {Human vision attention mechanism-inspired temporal-spatial feature pyramid for video saliency detection},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Double-level multi-attribute group decision-making method
based on intuitionistic fuzzy theory and evidence reasoning.
<em>CC</em>, <em>15</em>(3), 838–855. (<a
href="https://doi.org/10.1007/s12559-023-10109-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intuitionistic fuzzy (IF) theory and evidence reasoning (ER) are two commonly used tools in the decision-making process. They have their own advantages and disadvantages in information expression and information aggregation. How to use these two methods’ strengths to make up for each other’s shortcomings in the decision-making process is a very interesting topic. We refine IF expressions of decision attributes and develop a conversion formula about membership degree and belief degree, which unifies IF theory and ER. Then, we propose a double-level multi-attribute group decision-making method based on IF theory and ER. In the new method, we study the setting and aggregation of weights under double-level attributes, and optimize the process of information aggregation. The proposed method is verified by a detailed case study, which shows its validity and stability. It is expected that this method, which combines IF theory and ER, will become a useful tool for multi-attribute group decision-making.},
  archive      = {J_CC},
  author       = {Fan, Xuecheng and Xu, Zeshui},
  doi          = {10.1007/s12559-023-10109-8},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {838-855},
  shortjournal = {Cogn. Comput.},
  title        = {Double-level multi-attribute group decision-making method based on intuitionistic fuzzy theory and evidence reasoning},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Aspect based sentiment analysis using long-short term memory
and weighted n-gram graph-cut. <em>CC</em>, <em>15</em>(3), 822–837. (<a
href="https://doi.org/10.1007/s12559-022-10104-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current domain, aspect-based sentiment analysis is a much-explored area in sentiment classification. In this paper, an optimization method, Graph-Cut, is used first time for aspect-based sentiment analysis. In this research, a new concept of N-gram Graph-Cut is applied on aspect-based sentiment analysis. Also, a hybrid approach on a combination of Graph-Cut and long short-term memory (LSTM) algorithm is proposed. In the hybrid approach, knowledge is transferred from 1-g Graph-Cut to LSTM and is applied on two-way and three-way (positive, negative, and neutral) sentiment classification. The 1-g Graph-Cut, 2-g Graph-Cut, and combined 1-g Graph-Cut and LSTM algorithms are applied on restaurant, laptop, and Mams datasets for two-way and three-way classification. It has been observed that for multiword aspect terms in the laptop dataset, it is enhancing the accuracy in both two-way and three-way sentiment classification. Besides, term-based aspect sentiment classification is giving enhanced results in both the ways. Moreover, the proposed hybrid method 1-g Graph-Cut-LSTM gives better accuracy than a single LSTM or CNN model and increases the accuracy by 9% in three-way classification for laptop dataset. One-gram Graph-Cut and 2-g Graph-Cut methods have an advantage over other deep learning methods because they do not require any training, and it is completely unsupervised. The hybrid model 1-g Graph-Cut-LSTM gives better results than LSTM due to the selection of relevant words from a sentence according to its aspect by Graph-Cut method, which is a novel concept.},
  archive      = {J_CC},
  author       = {Nandi, Basanti Pal and Jain, Amita and Tayal, Devendra Kumar},
  doi          = {10.1007/s12559-022-10104-5},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {822-837},
  shortjournal = {Cogn. Comput.},
  title        = {Aspect based sentiment analysis using long-short term memory and weighted N-gram graph-cut},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GLASS: A graph laplacian autoencoder with subspace
clustering regularization for graph clustering. <em>CC</em>,
<em>15</em>(3), 803–821. (<a
href="https://doi.org/10.1007/s12559-022-10098-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph clustering is an important unsupervised learning task in complex network analysis and its latest progress mainly relies on a graph autoencoder (GAE) model. However, these methods have three major drawbacks. (1) Most autoencoder models choose graph convolutional networks (GCNs) as their encoders, but the filters and weight matrices in GCN encoders are entangled, which affects the resulting representation performance. (2) Real graphs are often sparse, requiring multiple-layer propagation to generate effective features, but (GCN) encoders are prone to oversmoothing when multiple layers are stacked. (3) Existing methods ignore the distribution of the node features in the feature space during the embedding stage, making their results unsuitable for clustering tasks. To alleviate these problems, in this paper, we propose a novel graph Laplacian autoencoder with subspace clustering regularization for graph clustering (GLASS). Specifically, we first use Laplacian smoothing filters instead of GCNs for feature propagation and multilayer perceptrons (MLPs) for nonlinear transformations, thereby solving the entanglement between convolutional filters and weight matrices. Considering that multilayer propagation is prone to oversmoothing, we further add residual connections between the Laplacian smoothing filters to enhance the multilayer feature propagation capability of GLASS. In addition, to achieve improved clustering performance, we introduce a regular term for subspace clustering to constrain the autoencoder to obtain the node features that are more representative and suitable for clustering. Experiments on node clustering and image clustering using four widely used network datasets and three image datasets show that our method outperforms other existing state-of-the-art methods. In addition, we verify the effectiveness of the proposed method in link prediction, complexity analysis, parameter analysis, data visualization, and ablation studies. The experimental results demonstrate the effectiveness of our proposed GLASS approach, and that it overcomes the shortcomings of GCN encoders to a large extent. This method not only has the advantage of deeper graph encoding but can also adaptively fit the subspace distribution of the given data, which will effectively inspire research on neural networks and autoencoders.},
  archive      = {J_CC},
  author       = {Sun, Dengdi and Liu, Liang and Luo, Bin and Ding, Zhuanlian},
  doi          = {10.1007/s12559-022-10098-0},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {803-821},
  shortjournal = {Cogn. Comput.},
  title        = {GLASS: A graph laplacian autoencoder with subspace clustering regularization for graph clustering},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dialogue relation extraction with document-level
heterogeneous graph attention networks. <em>CC</em>, <em>15</em>(2),
793–802. (<a href="https://doi.org/10.1007/s12559-023-10110-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a heterogeneous graph attention network to address the problem of dialogue relation extraction. Compared with several popular sequence-based and graph-based models, our method shows superior performance on the benchmark dataset DialogRE. The implementation of this work can be found at https://github.com/declare-lab/dialog-HGAT Dialogue relation extraction aims to detect the relation between pairs of entities mentioned in a multi-party dialogue. It plays an essential role in understanding the deep logic of dialogues and facilitating the development of intelligent dialogue systems. We introduce a heterogeneous graph attention network to model the cross-sentence relations in a conversation. This heterogeneous graph attention network has modeled multi-type features of the conversation, such as utterance, word, speaker, argument, and entity type information. We compare our method with several popular baselines such as convolutional neural networks and long short-term memory, experimental results show our model outperforms the state-of-the-art method by 9.4%/7.8% F1 scores, and 6.6%/3.9% $$F1_c$$ scores in both validation and test sets with only 4.0M parameters. In this work, we present an attention-based heterogeneous graph network to deal with the dialogue relation extraction task in an inductive manner. Experimental results on the dataset DialogRE confirm the effectiveness of our method.},
  archive      = {J_CC},
  author       = {Chen, Hui and Hong, Pengfei and Han, Wei and Majumder, Navonil and Poria, Soujanya},
  doi          = {10.1007/s12559-023-10110-1},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {793-802},
  shortjournal = {Cogn. Comput.},
  title        = {Dialogue relation extraction with document-level heterogeneous graph attention networks},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel attention-guided generative adversarial network for
whisper-to-normal speech conversion. <em>CC</em>, <em>15</em>(2),
778–792. (<a href="https://doi.org/10.1007/s12559-023-10108-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whispered speech is a special voicing style of speech that is employed publicly to protect speech information. It is also the primary pronunciation form for aphonic individuals with laryngectomy for oral communication. Converting whispered speech to normal-voiced speech can significantly improve speech quality and/or speech intelligibility for whisper perception or recognition. Due to the significant voicing style difference between normal speech and whispered speech, it is still a major challenge to estimate normal-voiced speech from its whispered counterpart. Existing whisper-to-normal speech conversion methods aim to learn a nonlinear function of features between whispered speech and its normal counterpart, and the converted normal speech is reconstructed with features selected by the learned function from the training data space. These methods may produce a discontinuous spectrum in successive frames, thus decreasing the speech quality and/or intelligibility of the converted normal speech. This paper proposes a novel generative model (AGAN-W2SC) for whisper-to-normal speech conversion. Unlike the feature mapping model, the proposed AGAN-W2SC model generates a normal speech spectrum from a whispered spectrum. To make the generated spectrum more similar to the reference normal speech, the inner-feature coherence of a whisper as well as the inter-feature coherence between whispered speech and its normal counterpart is modeled in the proposed AGAN-W2SC model. Specifically, a self-attention mechanism is introduced to capture the inner-spectrum structure while a Siamese neural network is adopted to capture the interspectrum structure in the cross-domain. Additionally, the proposed model adopts identity mapping to preserve linguistic information. The proposed AGAN-W2SC is parallel data-free and can be trained at the frame level. Experimental results on whisper-to-normal speech conversion demonstrate the superior performance and effectiveness of the proposed AGAN-W2SC method over all the compared competing methods in terms of speech quality and intelligibility},
  archive      = {J_CC},
  author       = {Gao, Teng and Pan, Qing and Zhou, Jian and Wang, Huabin and Tao, Liang and Kwan, Hon Keung},
  doi          = {10.1007/s12559-023-10108-9},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {778-792},
  shortjournal = {Cogn. Comput.},
  title        = {A novel attention-guided generative adversarial network for whisper-to-normal speech conversion},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep non-linear and unbiased deep decisive pooling
learning–based opinion mining of customer review. <em>CC</em>,
<em>15</em>(2), 765–777. (<a
href="https://doi.org/10.1007/s12559-022-10089-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, opinion mining is becoming a trending research topic. The existing opinion mining detection schemes were used to determine the status of product’s performance, wherein information is disseminated (positive or negative), even though the existing methods did not provide high accuracy and also increase the computational complexity and computation time. To overcome these issues, a deep non-linear and unbiased deep decisive pooling (N-UDDP) learning is proposed in this paper for getting accurate opinion mining of customer review. Initially, the customer reviews are taken from Amazon dataset. Then, the customer reviews are given as input to N-UDDP learning for getting accurate opinion mining of customer review. The proposed N-UDDP learning contains skip-gram input layer, non-linear ReLU-enabled activation function layer, and unbiased decisive pooling layer. The skip-gram input layer is utilized to obtain the computationally efficient features from input customer review. The non-linear ReLU-enabled activation function layer is used to obtain the unique and relevant features through eigenvector generation. Finally, the mining accuracy can be improved via unbiased decisive pooling layer by explicitly incorporating their confidence over the pooling function through decisive rules. Initially, the customer reviews are taken from Amazon dataset. Then, the customer reviews are given as input to N-UDDP learning for getting accurate opinion mining of customer review. The proposed N-UDDP learning contains skip-gram input layer, non-linear ReLU-enabled activation function layer, and unbiased decisive pooling layer. The skip-gram input layer is utilized to obtain the computationally efficient features from input customer review. The non-linear ReLU-enabled activation function layer is used to obtain the unique and relevant features through eigenvector generation. Finally, the mining accuracy can be improved via unbiased decisive pooling layer by explicitly incorporating their confidence over the pooling function through decisive rules. The proposed N-UDDP method attains 10.99%, 44.83%, 17.53%, 11.93%, 11.19%, 53.96%, and 13.285% higher accuracy than the existing methods, like ontology-driven feature engineering, multi-task learning framework, CNN-RNN, NA-DLSTM, MLP, autoencoder, and MV-DNN. The proposed N-UDDP method shows better accuracy by reducing the computational time and overhead.},
  archive      = {J_CC},
  author       = {Kuppusamy, Saraswathi and Thangavel, Renukadevi},
  doi          = {10.1007/s12559-022-10089-1},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {765-777},
  shortjournal = {Cogn. Comput.},
  title        = {Deep non-linear and unbiased deep decisive pooling Learning–Based opinion mining of customer review},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new approach for JPEG steganalysis with a cognitive
evolving ensembler and robust feature selection. <em>CC</em>,
<em>15</em>(2), 751–764. (<a
href="https://doi.org/10.1007/s12559-022-10087-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop a new robust feature selection scheme and an evolving ensemble classifier for stego content classification in a steganalysis framework. Steganalysis vs. steganography is a classical competition between two opposing research areas. Steganography focuses on hiding data within any media source such that the modified content becomes statistically indistinguishable from the original non-modified media. On the other hand, steganalysis focuses on detecting modified media that contains hidden data. Steganalysis includes two major steps, viz., feature extraction and binary classification of the original vs. modified images. The proposed Robust Feature Selection Method along with a Cognitive Evolving Ensemble classifier (RFSM-CEE) uses a Robust Feature Selection Genetic Algorithm (RFSGA) for identifying the robust features. A new measure called Sample Hardness (H) is used to calculate the Classifier Cost and select those training samples with higher sample hardness to train a set of basic classifiers with the robust features. RFSGA uses a specially tailored classifier cost C as the fitness function, which indicates the importance of each basic classifier for further ensembling. The proposed Cognitive Evolving Ensemble classifier (CEE) uses a growing/deleting strategy along with a voting scheme coupled with an Adaptive Ensemble Genetic Algorithm to define the set of basic classifiers for efficient ensembling. CEE uses simple voting rules to make a decision about each sample. Detailed performance evaluation of RFSM-CEE has been carried out by conducting experiments using J-UNIWARD and heuristic Bose-Chaudhuri-Hocquenghem steganography. The data used in these experiments are from BOSSbase and BOWS2 databases, along with Cartesian calibration JPEG Rich Models features. Experimental results clearly indicate major improvements in detection compared to the JPEG steganalysis ensemble classifier proposed by Kodovsky. In this paper a Robust Feature Selection Method along with a Cognitive Evolving Ensemble classifier (RFSM-CEE) focusing on searching for robust features in steganalysis data is presented along with a more accurate classifier to build efficient steganalysis.},
  archive      = {J_CC},
  author       = {Sachnev, Vasily and Sundararajan, Narasimhan and Suresh, Sundaram},
  doi          = {10.1007/s12559-022-10087-3},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {751-764},
  shortjournal = {Cogn. Comput.},
  title        = {A new approach for JPEG steganalysis with a cognitive evolving ensembler and robust feature selection},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A data-driven energy management strategy based on deep
reinforcement learning for microgrid systems. <em>CC</em>,
<em>15</em>(2), 739–750. (<a
href="https://doi.org/10.1007/s12559-022-10106-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the interactions among schedulable equipment and the uncertainty of microgrid (MG) systems, it becomes increasingly difficult to establish accurate mathematical models for energy management. To improve the stability and economy of MGs, a data-driven energy management strategy must be proposed. In this paper, distributed generators (DGs) and an energy storage system (ESS) are taken as the control objects, and a data-driven energy management strategy based on prioritized experience replay soft actor-critic (PERSAC) is proposed for MGs. First, we construct an MG energy management model with the objective of minimizing the operation cost. Second, the energy management model is formulated as a Markov decision process (MDP), and the PERSAC algorithm is used to solve the MDP. Moreover, the sampling rule of the training process is optimized by using the prioritized empirical replay (PER) method. The analysis of numerical examples proves the effectiveness and practicability of the algorithm. By controlling DGs and the ESS, the operation cost of the proposed algorithm is the lowest compared with other algorithms.},
  archive      = {J_CC},
  author       = {Bao, Gang and Xu, Rui},
  doi          = {10.1007/s12559-022-10106-3},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {739-750},
  shortjournal = {Cogn. Comput.},
  title        = {A data-driven energy management strategy based on deep reinforcement learning for microgrid systems},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distance from unimodality for the assessment of opinion
polarization. <em>CC</em>, <em>15</em>(2), 731–738. (<a
href="https://doi.org/10.1007/s12559-022-10088-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Commonsense knowledge is often approximated by the fraction of annotators who classified an item as belonging to the positive class. Instances for which this fraction is equal to or above 50% are considered positive, including however ones that receive polarized opinions. This is a problematic encoding convention that disregards the potentially polarized nature of opinions and which is often employed to estimate subjectivity, sentiment polarity, and toxic language. We present the distance from unimodality (DFU), a novel measure that estimates the extent of polarization on a distribution of opinions and which correlates well with human judgment. We applied DFU to two use cases. The first case concerns tweets created over 9 months during the pandemic. The second case concerns textual posts crowd-annotated for toxicity. We specified the days for which the sentiment-annotated tweets were determined as polarized based on the DFU measure and we found that polarization occurred on different days for two different states in the USA. Regarding toxicity, we found that polarized opinions are more likely by annotators originating from different countries. Moreover, we show that DFU can be exploited as an objective function to train models to predict whether a post will provoke polarized opinions in the future.},
  archive      = {J_CC},
  author       = {Pavlopoulos, John and Likas, Aristidis},
  doi          = {10.1007/s12559-022-10088-2},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {731-738},
  shortjournal = {Cogn. Comput.},
  title        = {Distance from unimodality for the assessment of opinion polarization},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural modeling and real-time environment training of human
binocular stereo visual tracking. <em>CC</em>, <em>15</em>(2), 710–730.
(<a href="https://doi.org/10.1007/s12559-022-10091-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulating the human natural visual system is beneficial for understanding brain intelligence and exploiting new aspects of computer vision. Previous studies have proposed many progressive models and experiments for visual tracking; however, only a few consider all factors involved in visual tracking. Improvements in cross-modal sensory fusion, online physical environment training, and leveraging machine learning are required. In this paper, we present a balanced visual tracking study between neuroscience models and deep-learning methods. In our visual tracking framework, we modify the original region proposal network and interconnect binocular R-CNNs with a new region of interest (RoI) model. Ground frame prediction can be implemented by localization fusion from binocular R-CNNs, as well as external sensory information, such as a dense disparity map. In the behavior stage, visual-motor transformation is implemented through the online training of saccades, pursuit, and vergence networks in the real environment. As demonstrated on a robot, our framework can learn tracking skills through online parameter updates using physical data collected from the robot. The framework achieves performance highly similar to human behaviors and better accuracy than recent models. Moreover, using prediction from our ground vision model to guide binocular, RoI pooling can improve the efficiency of object recognition and localization and reduce visual tracking errors by 27% compared with the original network. In conclusion, this study proposed an effective binocular tracking framework that draws inspiration from brain structures. The performance showed improved accuracy and robustness in tracking random moving targets.},
  archive      = {J_CC},
  author       = {Wang, Jiaguo and Meng, Xianghao and Xu, Hanyuan and Pei, Yang},
  doi          = {10.1007/s12559-022-10091-7},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {710-730},
  shortjournal = {Cogn. Comput.},
  title        = {Neural modeling and real-time environment training of human binocular stereo visual tracking},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel unsupervised spatial–temporal learning mechanism in
a bio-inspired spiking neural network. <em>CC</em>, <em>15</em>(2),
694–709. (<a href="https://doi.org/10.1007/s12559-022-10097-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bio-inspired computing is a powerful platform that develops intelligent machines based on principles of the behavioral and functional mechanisms of the human nervous system. Such machines can be critical tools in expert systems, speech recognition, pattern recognition, and machine vision. In this study, a retinal model is used as input layer of spiking network to convert image pixels to spike trains. The produced spikes are injected into a spiking neural network (SNN) as a second layer, which structure and functioning is inspired by real neuronal networks (i.e. excitatory and inhibitory neurotransmitters as AMPA and GABA currents and spiking neurons). Similarly, an unsupervised, spatial–temporal, and sparse spike-based learning mechanism based on learning processes in the brain was developed to train the spiking neurons in the output layer for recognizing patterns of MNIST and EMNIST datasets with very high accuracy (above 97%) and CIFAR10 with accuracy 92.9%. The proposed spiking pattern recognition network has higher classification accuracy than previous deep spiking networks and has advantages such as higher convergence speed, unsupervised learning, fewer numbers of hyper-parameters and network layers, and ability to learn with the limited number of training data. Finally, by changing the size and stride of the averaging windows in the visual pathway, we can train the network with only 10% of the training datasets, achieving accuracy similar or higher than state-of-the-art deep learning approaches. The ability to achieve high-performance accuracy in pattern recognition networks despite the limited number of training data is one of the most important challenges of neural networks in artificial intelligence. In summary, the novel bio-inspired neuronal network utilizes spiking trains and learns unsupervised and is capable of recognizing complex patterns, similar in performance to advanced neuronal networks using deep learning, and potentially can be implemented in neuromorphic hardware.},
  archive      = {J_CC},
  author       = {Amiri, Masoud and Jafari‬, Amir Homayoun and Makkiabadi, Bahador and Nazari, Soheila},
  doi          = {10.1007/s12559-022-10097-1},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {694-709},
  shortjournal = {Cogn. Comput.},
  title        = {A novel unsupervised Spatial–Temporal learning mechanism in a bio-inspired spiking neural network},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast and general incomplete multi-view adaptive clustering.
<em>CC</em>, <em>15</em>(2), 683–693. (<a
href="https://doi.org/10.1007/s12559-022-10079-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of data collection technologies, multi-view clustering (MVC) has become an emerging research topic. The traditional MVC method cannot process incomplete views. In recent years, although many incomplete multi-view clustering methods have been proposed by many researchers, these methods still suffer from some limitations. For example, these methods all have parameters that need to be adjusted, or have high computational complexity and are not suitable for processing large-scale data. To make matters worse, these methods are not suitable for cases where there are no paired samples among multiple views. The above limitations make existing methods difficult to apply in practice. This paper proposes a Fast and General Incomplete Multi-view Adaptive Clustering (FGPMAC) method. The FGPMAC adopts an adaptive neighbor assignment strategy to independently construct the similarity matrix of each view, thereby it can handle the cases where there are no paired samples among multiple views, and eliminating the necessary to adjust the parameters. Moreover, by adopting a non-iterative approach, FGPMAC has low computational complexity and is suitable for large-scale datasets. Results of experiments on multiple real datasets fully demonstrate the advantages of FGPMAC, such as simplicity, effectiveness and superiority.},
  archive      = {J_CC},
  author       = {Ji, Xia and Yang, Lei and Yao, Sheng and Zhao, Peng and Li, Xuejun},
  doi          = {10.1007/s12559-022-10079-3},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {683-693},
  shortjournal = {Cogn. Comput.},
  title        = {Fast and general incomplete multi-view adaptive clustering},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stein variational gradient descent with multiple kernels.
<em>CC</em>, <em>15</em>(2), 672–682. (<a
href="https://doi.org/10.1007/s12559-022-10069-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian inference is an important research area in cognitive computation due to its ability to reason under uncertainty in machine learning. As a representative algorithm, Stein variational gradient descent (SVGD) and its variants have shown promising successes in approximate inference for complex distributions. In practice, we notice that the kernel used in SVGD-based methods has a decisive effect on the empirical performance. Radial basis function (RBF) kernel with median heuristics is a common choice in previous approaches, but unfortunately, this has proven to be sub-optimal. Inspired by the paradigm of Multiple Kernel Learning (MKL), our solution to this flaw is using a combination of multiple kernels to approximate the optimal kernel, rather than a single one which may limit the performance and flexibility. Specifically, we first extend Kernelized Stein Discrepancy (KSD) to its multiple kernels view called Multiple Kernelized Stein Discrepancy (MKSD) and then leverage MKSD to construct a general algorithm Multiple Kernel SVGD (MK-SVGD). Further, MK-SVGD can automatically assign a weight to each kernel without any other parameters, which means that our method not only gets rid of optimal kernel dependence but also maintains computational efficiency. Experiments on various tasks and models demonstrate that our proposed method consistently matches or outperforms the competing methods.},
  archive      = {J_CC},
  author       = {Ai, Qingzhong and Liu, Shiyu and He, Lirong and Xu, Zenglin},
  doi          = {10.1007/s12559-022-10069-5},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {672-682},
  shortjournal = {Cogn. Comput.},
  title        = {Stein variational gradient descent with multiple kernels},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid convolutional neural network-multilayer perceptron
model for solar radiation prediction. <em>CC</em>, <em>15</em>(2),
645–671. (<a href="https://doi.org/10.1007/s12559-022-10070-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urgent transition from the dependence on fossil fuels towards renewable energies requires more solar photovoltaic power to be connected to the electricity grids, with reliable supply through accurate solar radiation forecasting systems. This study proposes an innovative hybrid method that integrates convolutional neural network (CNN) with multi-layer perceptron (MLP) to generate global solar radiation (GSR) forecasts. The CMLP model first extracts optimal topological and structural features embedded in predictive variables through a CNN-based feature extraction stage followed by an MLP-based predictive model to generate the GSR forecasts. Predictive variables from observed data and global climate models (GCM) are used to predict GSR at six solar farms in Queensland, Australia. A hybrid-wrapper feature selection method using a random forest-recursive feature elimination (RF-RFE) scheme is used to eradicate redundant predictor features to improve the proposed CMLP model efficiency. The CMLP model has been compared and bench-marked against seven artificial intelligence–based and seven temperature-based deterministic models, showing excellent performance at all solar energy study sites tested over daily, monthly, and seasonal scales. The proposed hybrid CMLP model should be explored as a viable modelling tool for solar energy monitoring and forecasting in real-time energy management systems.},
  archive      = {J_CC},
  author       = {Ghimire, Sujan and Nguyen-Huy, Thong and Prasad, Ramendra and Deo, Ravinesh C. and Casillas-Pérez, David and Salcedo-Sanz, Sancho and Bhandari, Binayak},
  doi          = {10.1007/s12559-022-10070-y},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {645-671},
  shortjournal = {Cogn. Comput.},
  title        = {Hybrid convolutional neural network-multilayer perceptron model for solar radiation prediction},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ConvXAI: A system for multimodal interaction with any
black-box explainer. <em>CC</em>, <em>15</em>(2), 613–644. (<a
href="https://doi.org/10.1007/s12559-022-10067-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several studies have addressed the importance of context and users’ knowledge and experience in quantifying the usability and effectiveness of the explanations generated by explainable artificial intelligence (XAI) systems. However, to the best of our knowledge, no component-agnostic system that accounts for this need has yet been built. This paper describes an approach called ConvXAI, which can create a dialogical multimodal interface for any black-box explainer by considering the knowledge and experience of the user. First, we formally extend the state-of-the-art conversational explanation framework by introducing clarification dialogue as an additional dialogue type. We then implement our approach as an off-the-shelf Python tool. To evaluate our framework, we performed a user study including 45 participants divided into three groups based on their level of technology use and job function. Experimental results show that (i) different groups perceive explanations differently; (ii) all groups prefer textual explanations over graphical ones; and (iii) ConvXAI provides clarifications that enhance the usefulness of the original explanations.},
  archive      = {J_CC},
  author       = {Malandri, Lorenzo and Mercorio, Fabio and Mezzanzanica, Mario and Nobani, Navid},
  doi          = {10.1007/s12559-022-10067-7},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {613-644},
  shortjournal = {Cogn. Comput.},
  title        = {ConvXAI: A system for multimodal interaction with any black-box explainer},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring dimensionality reduction techniques in
multilingual transformers. <em>CC</em>, <em>15</em>(2), 590–612. (<a
href="https://doi.org/10.1007/s12559-022-10066-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In scientific literature and industry, semantic and context-aware Natural Language Processing-based solutions have been gaining importance in recent years. The possibilities and performance shown by these models when dealing with complex Human Language Understanding tasks are unquestionable, from conversational agents to the fight against disinformation in social networks. In addition, considerable attention is also being paid to developing multilingual models to tackle the language bottleneck. An increase in size has accompanied the growing need to provide more complex models implementing all these features without being conservative in the number of dimensions required. This paper aims to provide a comprehensive account of the impact of a wide variety of dimensional reduction techniques on the performance of different state-of-the-art multilingual siamese transformers, including unsupervised dimensional reduction techniques such as linear and nonlinear feature extraction, feature selection, and manifold techniques. In order to evaluate the effects of these techniques, we considered the multilingual extended version of Semantic Textual Similarity Benchmark (mSTSb) and two different baseline approaches, one using the embeddings from the pre-trained version of five models and another using their fine-tuned STS version. The results evidence that it is possible to achieve an average reduction of $$91.58\% \pm 2.59\%$$ in the number of dimensions of embeddings from pre-trained models requiring a fitting time $$96.68\% \pm 0.68\%$$ faster than the fine-tuning process. Besides, we achieve $$54.65\% \pm 32.20\%$$ dimensionality reduction in embeddings from fine-tuned models. The results of this study will significantly contribute to the understanding of how different tuning approaches affect performance on semantic-aware tasks and how dimensional reduction techniques deal with the high-dimensional embeddings computed for the STS task and their potential for other highly demanding NLP tasks.},
  archive      = {J_CC},
  author       = {Huertas-García, Álvaro and Martín, Alejandro and Huertas-Tato, Javier and Camacho, David},
  doi          = {10.1007/s12559-022-10066-8},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {590-612},
  shortjournal = {Cogn. Comput.},
  title        = {Exploring dimensionality reduction techniques in multilingual transformers},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Minimum power adversarial attacks in communication signal
modulation classification with deep learning. <em>CC</em>,
<em>15</em>(2), 580–589. (<a
href="https://doi.org/10.1007/s12559-022-10062-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating cognitive radio (CR) technique with wireless networks is an effective way to solve the increasingly crowded spectrum. Automatic modulation classification (AMC) plays an important role in CR. AMC significantly improves the intelligence of CR system by classifying the modulation type and signal parameters of received communication signals. AMC can provide more information for decision making of the CR system. In addition, AMC can help the CR system dynamically adjust the modulation type and coding rate of the communication signal to adapt to different channel qualities, and the AMC technique help eliminate the cost of broadcast modulation type and coding rate. Deep learning (DL) has recently emerged as one most popular method in AMC of communication signals. Despite their success, DL models have recently been shown vulnerable to adversarial attacks in pattern recognition and computer vision. Namely, they can be easily deceived if a small and carefully designed perturbation called an adversarial attack is imposed on the input, typically an image in pattern recognition. Owing to the very different nature of communication signals, it is interesting yet crucially important to study if adversarial perturbation could also fool AMC. In this paper, we make a first attempt to investigate how we can design a special adversarial attack on AMC. we start from the assumption of a linear binary classifier which is further extended to multi-way classifier. We consider the minimum power consumption that is different from existing adversarial perturbation but more reasonable in the context of AMC. We then develop a novel adversarial perturbation generation method that leads to high attack success to communication signals. Experimental results on real data show that the method is able to successfully spoof the 11-class modulation classification at a model with a minimum cost of about − 21 dB in automatic modulation classification task. The visualization results demonstrate that the adversarial perturbation manifests in the time domain as imperceptible undulations of the signal, and in the frequency domain as small noise outside the signal band.},
  archive      = {J_CC},
  author       = {Ke, Da and Wang, Xiang and Huang, Kaizhu and Wang, Haoyuan and Huang, Zhitao},
  doi          = {10.1007/s12559-022-10062-y},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {580-589},
  shortjournal = {Cogn. Comput.},
  title        = {Minimum power adversarial attacks in communication signal modulation classification with deep learning},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Surface defect detection algorithm based on feature-enhanced
YOLO. <em>CC</em>, <em>15</em>(2), 565–579. (<a
href="https://doi.org/10.1007/s12559-022-10061-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface defect detection is a complicated task to achieve both specific class and precise location of each defect. Specifically for industrial scenario, realizing efficient and accuracy-satisfactory surface defect automatic detection is still a big challenge. Therefore, a surface defect detection algorithm based on feature-enhanced YOLO (FE-YOLO) for practical industrial applications is proposed in this paper. For the purpose of efficient detection, we lighten YOLO model by combining deep separable convolution and dense join. And an improved feature pyramid network is proposed to enhance the spatial location correlation for multi-scale detection layer for the sake of high accuracy. Then, a new loss function of prediction box regression is established to boost the detection accuracy under the high Intersection over Union (IoU) threshold and accelerate model convergence. To select anchor boxes of different scale feature detection layers, we propose a statistical-based k-means++ algorithm, which can improve the quality of initial anchors and accelerate the convergence of the proposed model. Two industrial surface defect datasets, NEU-DET dataset and DeepPCB dataset, are used to verify the effectiveness of the proposed FE-YOLO algorithm. Experimental results demonstrate that FE-YOLO algorithm is lightened nearly 80% compared with YOLOV4. The detection speed is better than the other state-of-the-art surface defect detection algorithms. The defects detection accuracy respectively reaches 83.9% and 98.9% for the NEU-DET dataset and DeepPCB dataset, which are better than the state-of-the-art defect detection methods. The end-to-end fast and accurate detection for industrial surface defects is realized.},
  archive      = {J_CC},
  author       = {Xie, Yongfang and Hu, Weitao and Xie, Shiwen and He, Lei},
  doi          = {10.1007/s12559-022-10061-z},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {565-579},
  shortjournal = {Cogn. Comput.},
  title        = {Surface defect detection algorithm based on feature-enhanced YOLO},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). One-stage multi-view clustering with hierarchical attributes
extraction. <em>CC</em>, <em>15</em>(2), 552–564. (<a
href="https://doi.org/10.1007/s12559-022-10060-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering (MVC) has received significant attention, and obtained praiseworthy performance improvement in comparison with signal-view clustering, since it can effectively take advantage of the underlying correlation and structure information of multi-view data. However, existing methods only utilize signal-layer mapping to exploit clustering information, and ignore the underlying hierarchical attribute information in complex and interleaved multi-view data. In this work, we propose a novel MVC method, one-stage multi-view clustering with hierarchical attributes extracting (OS-HAE), to exploit the underlying hierarchical attributes for MVC. Specifically, we learn multiple latent representations from each view by a novel deep matrix factorization (DMF) framework with a layer-wise scheme, so that the learned representations can contain the hierarchical attribute information of original multi-view data. In addition, the samples from the same clusters but from different views are forced to be closer, and samples from different cluster are away from each other in the latent low-dimensional space. Furthermore, we introduce local manifold learning to guide DMF, such that the deepest representations can preserve structure information of original data. Meanwhile, a novel auto-weighted spectral rotating fusion (ASRF) paradigm is proposed to obtain the final clustering indicator matrix directly, so that OS-HAE can avoid obtaining suboptimal results caused by a two-stage strategy. Then, an alternate algorithm is designed to solve the objective function. Experimental results on six datasets demonstrate the advancement and effectiveness of the proposed OS-HAE. Consequently, the proposed method can effectively exploit the hierarchical information of multi-view to improve clustering performance.},
  archive      = {J_CC},
  author       = {Mi, Yong and Dai, Jian and Ren, Zhenwen and You, Xiaojian and Wang, Yanlong},
  doi          = {10.1007/s12559-022-10060-0},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {552-564},
  shortjournal = {Cogn. Comput.},
  title        = {One-stage multi-view clustering with hierarchical attributes extraction},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A boundary regression model for nested named entity
recognition. <em>CC</em>, <em>15</em>(2), 534–551. (<a
href="https://doi.org/10.1007/s12559-022-10058-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognizing named entities (NEs) is commonly treated as a classification problem, and a class tag for a word or an NE candidate in a sentence is predicted. In recent neural network developments, deep structures that map categorized features into continuous representations have been adopted. Using this approach, a dense space saturated with high-order abstract semantic information is unfolded, and the prediction is based on distributed feature representations. In this paper, the positions of NEs in a sentence are represented as continuous values. Then, a regression operation is introduced to regress the boundaries of NEs in a sentence. Based on boundary regression, we design a boundary regression model to support nested NE recognition. It is a multiobjective learning framework that simultaneously predicts the classification score of an NE candidate and refines its spatial location in a sentence. This model was evaluated on the ACE 2005 Chinese and English corpus and the GENIA corpus. State-of-the-art performance was experimentally demonstrated for nested NE recognition, which outperforms related works about 5% and 2% respectively. Our model has the advantage to resolve nested NEs and support boundary regression for locating NEs in a sentence. By sharing parameters for predicting and locating, this model enables more potent nonlinear function approximators to enhance model discriminability.},
  archive      = {J_CC},
  author       = {Chen, Yanping and Wu, Lefei and Zheng, Qinghua and Huang, Ruizhang and Liu, Jun and Deng, Liyuan and Yu, Junhui and Qing, Yongbin and Dong, Bo and Chen, Ping},
  doi          = {10.1007/s12559-022-10058-8},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {534-551},
  shortjournal = {Cogn. Comput.},
  title        = {A boundary regression model for nested named entity recognition},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Green supplier selection mechanism based on information
environment of z-numbers. <em>CC</em>, <em>15</em>(2), 520–533. (<a
href="https://doi.org/10.1007/s12559-022-10055-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the green procurement management of firms, by rigorously evaluating and selecting suppliers, firms can effectively reduce the operation risk and improve the sustainable value-added capacity of supply chain. This paper designs a novel green supplier selection mechanism based on an uncertain information environment. First, a new green supplier evaluation index system is designed by considering the economic, environmental, and social drivers from the perspective of sustainable development. Then, the Z-numbers are applied to describe the fuzziness degree of the decision information and the reliability degree of the fuzzy attribute values. We re-define the possibility degree of trapezoidal fuzzy numbers, and on that basis, we define the possibility degree of Z-numbers. A ranking method based on the possibility degree of Z-numbers is applied to select the green suppliers. Finally, the implementation, applicability, and feasibility of the proposed mechanism are highlighted by providing a decision-making example of green supply selection together with the comparison analysis with the existing methods. From the comparison analysis and discussion, the information processing method in our proposed mechanism can effectively avoid the information loss caused by the direct aggregation of fuzzy information, which shows that the proposed mechanism is more feasible and effective than other congeneric methods. The results suggest that the proposed mechanism of green supplier selection can handle multi-attribute decision-making problems in an uncertain cognitive information environment with Z-numbers, consistent with human cognition.},
  archive      = {J_CC},
  author       = {Rao, Congjun and Gao, Mingyun and Goh, Mark and Xiao, Xinping},
  doi          = {10.1007/s12559-022-10055-x},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {520-533},
  shortjournal = {Cogn. Comput.},
  title        = {Green supplier selection mechanism based on information environment of Z-numbers},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). C-loss-based doubly regularized extreme learning machine.
<em>CC</em>, <em>15</em>(2), 496–519. (<a
href="https://doi.org/10.1007/s12559-022-10050-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extreme learning machine has become a significant learning methodology due to its efficiency. However, extreme learning machine may lead to overfitting since it is highly sensitive to outliers. In this paper, a novel extreme learning machine called the C-loss-based doubly regularized extreme learning machine is presented to handle dimensionality reduction and overfitting problems. The proposed algorithm benefits from both L1 norm and L2 norm and replaces the square loss function with a C-loss function. And the C-loss-based doubly regularized extreme learning machine can complete the feature selection and the training processes simultaneously. Additionally, it can also decrease noise or irrelevant information of data to reduce dimensionality. To show the efficiency in dimension reduction, we test it on the Swiss Roll dataset and obtain high efficiency and stable performance. The experimental results on different types of artificial datasets and benchmark datasets show that the proposed method achieves much better regression results and faster training speed than other compared methods. Performance analysis also shows it significantly decreases the training time, solves the problem of overfitting, and improves generalization ability.},
  archive      = {J_CC},
  author       = {Wu, Qing and Fu, Yan–Lin and Cui, Dong–Shun and Wang, En},
  doi          = {10.1007/s12559-022-10050-2},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {496-519},
  shortjournal = {Cogn. Comput.},
  title        = {C-loss-based doubly regularized extreme learning machine},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning discriminated features based on feature pyramid
networks and attention for multi-scale object detection. <em>CC</em>,
<em>15</em>(2), 486–495. (<a
href="https://doi.org/10.1007/s12559-022-10052-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the research scene in object detection becomes increasingly complex, the extracted feature information needs to be further improved. Many multi-scale feature pyramid network methods have been proposed to improve detection accuracy. However, most of them just follow a simple chain aggregation structure, resulting in not considering the distinction between multi-scale objects. Modern cognitive research presents that human cognitive ability is not a simple image-based matching process. It has an inherent process of information decomposition and reconstruction. Inspired by this theory, a new feature pyramid network model denoted as SuFPN based on discriminative learning is proposed to solve the problem of multi-scale object detection. In SuFPN, the correlation between the underlying location information and the deep feature information is fully considered. Firstly, object features are extracted through top-down path and lateral connection. Then deformable convolution is used to extract object discriminant spatial information. Finally, the attention mechanism is introduced to generate a discriminative feature map with enhanced spatial and channel interdependence, which provides excellent location information for the feature pyramid while considering semantic information. The proposed SuFPN is validated on the PASCAL VOC and COCO datasets. The Average Precision (AP) value reaches 80.0 on the PASCAL VOC dataset, which is 1.7 points higher than the feature pyramid networks (FPN), and 39.2 on the COCO dataset, which is 1.8 points higher than the FPN. The result demonstrates that our SuFPN outperforms other advanced methods in the multi-scale detection precision.},
  archive      = {J_CC},
  author       = {Lu, Yunhua and Su, Minghui and Wang, Yong and Liu, Zhi and Peng, Tao},
  doi          = {10.1007/s12559-022-10052-0},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {486-495},
  shortjournal = {Cogn. Comput.},
  title        = {Learning discriminated features based on feature pyramid networks and attention for multi-scale object detection},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamical bifurcations in a fractional-order neural network
with nonidentical communication delays. <em>CC</em>, <em>15</em>(2),
466–485. (<a href="https://doi.org/10.1007/s12559-022-10045-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the number of investigation fruits on neural networks is growing explosively, the majority of such research effort is devoted to integer-order neural networks, while only a few are on fractional-order neural networks (FONNs). By arguing the associated characteristic equation of the proposed network, we establish delay-dependent stability conditions and the bifurcation point. Then selecting the communication delay as the bifurcation parameter and the other delay as the constant in its stability interval, the conditions for the occurrence of Hopf bifurcation are established. Then, we confirm the conditions by numerical simulation. It is indicated that the stability of the FONN remains unchanged with the lesser control delay, and will not exist once the delay outnumbers its critical value. And we discover that compared with integer-order neural networks the convergence time to the equilibrium point of FONN is shorter for the same system parameters. It detects that fractional orders are able to advance(postpone) the generation of the bifurcations of the developed FONN. The paper demonstrates that the fractional orders have significant effects on the stability of the FONN. Finally, the theoretical results are authenticated by numerical simulations.},
  archive      = {J_CC},
  author       = {Mo, Shansong and Huang, Chengdai and Cao, Jinde and Alsaedi, Ahmed},
  doi          = {10.1007/s12559-022-10045-z},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {466-485},
  shortjournal = {Cogn. Comput.},
  title        = {Dynamical bifurcations in a fractional-order neural network with nonidentical communication delays},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A mixed approach for aggressive political discourse analysis
on twitter. <em>CC</em>, <em>15</em>(2), 440–465. (<a
href="https://doi.org/10.1007/s12559-022-10048-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Political tensions have grown throughout Europe since the beginning of the new century. The consecutive crises led to the rise of different social movements in several countries, in which the political status quo changed. These changes included an increment of the different tensions underlying politics, as has been reported after many other political and economical crises during the twentieth century. This article proposes the study of the political discourse, and its underlying tension, during Madrid’s elections (Spain) in May 2021 by using a mixed approach. To demonstrate if an aggressive tone is used during the campaign, a mixed methodology approach is applied: quantitative computational techniques, related to natural language processing, are used to conduct a first general analysis of the information screened; then, these methods are used for detecting specific trends that can be later filtered and analyzed using a qualitative approach (content analysis), which is also conducted to extract insights about the information found. The main outcomes of this study show that the electoral campaign is not as negative as perceived by the citizens and that there was no relationship between the tone of the discourse and its dissemination. The analysis confirms that the most ideologically extreme parties tend to have a more aggressive language than the moderate ones. The content analysis carried out using our methodology showed that Twitter is used as a sentiment thermometer more than as a way of communicating concrete politics.},
  archive      = {J_CC},
  author       = {Torregrosa, Javier and D’Antonio-Maceiras, Sergio and Villar-Rodríguez, Guillermo and Hussain, Amir and Cambria, Erik and Camacho, David},
  doi          = {10.1007/s12559-022-10048-w},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {440-465},
  shortjournal = {Cogn. Comput.},
  title        = {A mixed approach for aggressive political discourse analysis on twitter},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DLW-NAS: Differentiable light-weight neural architecture
search. <em>CC</em>, <em>15</em>(2), 429–439. (<a
href="https://doi.org/10.1007/s12559-022-10046-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the method of automatically constructing convolutional neural networks based on neural architecture search has attracted wide attention, and greatly reduces the manual intervention and the cost of manual design of neural networks. However, most neural architecture search methods focus on the performance of the model, but ignore the complexity of the model, which makes it difficult to deploy this method on devices with limited resources. In this paper, a novel differentiable light-weight architecture search method named DLW-NAS is proposed, which aims to search convolutional neural networks (CNNs) with remarkable performance as well as a small amount of parameters and floating point operations (FLOPs). Concretely, in order to limit the parameters and FLOPs from the source of neural architecture search (NAS), we build a light-weight search space containing effective light-weight operations. Moreover, we design a differentiable NAS strategy with computation complexity constraints. In addition, we propose a neural architecture optimization method, which makes the topology of the searched architecture sparse. The experimental results show that DLW-NAS achieves 2.73% error rate on CIFAR-10, which is comparable to the state-of-the-art (SOTA) methods. However, it only needs 2.3M parameters and 334M FLOPs, which reduces that of the SOTA DARTS by 30% and 36% in parameters and FLOPs, respectively. The searched model on CIFAR-100 uses only 2.47M parameters and 376M FLOPs with an error rate of only 17.12%. On ImageNet, compared with the SOTA MobileNet, DLW-NAS achieves 3.3% better top-1 accuracy with much fewer parameters and FLOPs.},
  archive      = {J_CC},
  author       = {Li, Shu and Mao, Yuxu and Zhang, Fuchang and Wang, Dong and Zhong, Guoqiang},
  doi          = {10.1007/s12559-022-10046-y},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {429-439},
  shortjournal = {Cogn. Comput.},
  title        = {DLW-NAS: Differentiable light-weight neural architecture search},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Extreme learning machine with kernels for solving elliptic
partial differential equations. <em>CC</em>, <em>15</em>(2), 413–428.
(<a href="https://doi.org/10.1007/s12559-022-10026-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding solutions for partial differential equations based on machine learning methods is an ongoing challenge in applied mathematics. Although machine learning methods have been successfully applied to solve partial differential equations, their practical applications are limited by a large number of variables. In this study, after a strict theoretical derivation, a new method is proposed for solving standard elliptic partial differential equations based on an extreme learning machine with kernels. The parameters of the proposed method (i.e., regularization coefficients and kernel parameters) were obtained by a grid search approach. Three numerical cases combined with some comprehensive indices (mean absolute error, mean squared error and standard deviation) were used to test the performance of the proposed method. The results show that the performance of the proposed method is superior to that of existing methods, including the wavelet neural network optimized with the improved butterfly optimization algorithm. In addition, the proposed method has fewer unknown parameters than previous methods, which makes its calculations more convenient. In this study, the effect of the number of training points on the calculation results is also discussed, and the advantage of the proposed method is that only a few training points are needed to achieve high computational accuracy. In addition, as a case study, the proposed method is successfully applied to simulate the water flow in unsaturated soils. The proposed method provides new insight for solving elliptic partial differential equations.},
  archive      = {J_CC},
  author       = {Li, Shaohong and Liu, Guoguo and Xiao, Shiguo},
  doi          = {10.1007/s12559-022-10026-2},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {413-428},
  shortjournal = {Cogn. Comput.},
  title        = {Extreme learning machine with kernels for solving elliptic partial differential equations},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). UAV landing platform recognition using cognitive computation
combining geometric analysis and computer vision techniques.
<em>CC</em>, <em>15</em>(2), 392–412. (<a
href="https://doi.org/10.1007/s12559-021-09962-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) are excellent tools with extensive demand. During the last phase of landing, they require additional support to that of GPS. This can be achieved through the UAV’s perception system based on its on-board camera and intelligence, and with which decisions can be made as to how to land on a platform (target). A cognitive computation approach is proposed to recognize this target that has been specifically designed to translate human reasoning into computational procedures by computing two probabilities of detection which are combined considering the fuzzy set theory for proper decision-making. The platform design is based on: (1) spectral information in the visible range which are uncommon colors in the UAV’s operating environments (indoors and outdoors) and (2) specific figures in the foreground, which allow partial perception of each figure. We exploit color image properties from specific-colored figures embedded on the platform and which are identified by applying image processing and pattern recognition techniques, including Euclidean Distance Smart Geometric Analysis, to identify the platform in a very efficient and reliable manner. The test strategy uses 800 images captured with a smartphone onboard a quad-rotor UAV. The results verify the proposed method outperforms existing strategies, especially those that do not use color information. Platform recognition is also possible even with only a partial view of the target, due to image capture under adverse conditions. This demonstrates the effectiveness and robustness of the proposed cognitive computing-based perception system.},
  archive      = {J_CC},
  author       = {García-Pulido, J. A. and Pajares, G. and Dormido, S.},
  doi          = {10.1007/s12559-021-09962-2},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {392-412},
  shortjournal = {Cogn. Comput.},
  title        = {UAV landing platform recognition using cognitive computation combining geometric analysis and computer vision techniques},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural mechanisms of the maintenance and manipulation of
gustatory working memory in orbitofrontal cortex. <em>CC</em>,
<em>15</em>(2), 373–391. (<a
href="https://doi.org/10.1007/s12559-022-10035-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Orbitofrontal cortex (OFC) is involved in flavor perception and executive functions of chemical sensations. It integrates multiple sensory modalities to perceive the flavor of foods, and organizes sensory information in selection of behavioral strategies. A recent study has reported that gustatory working memory (WM) is maintained in the OFC of rhesus monkeys. However, the maintenance mechanism remains unclear. Moreover, the manipulation mechanism, or how WM is utilized to guide behavior, also poorly understood. To address these issues, we are concerned with a delayed match-to-sample (DMS) task, and present a model for WM maintenance and manipulation in OFC. The model consists of the networks of gustatory cortex, OFC, and a decision layer. We show that gustatory WM is represented by a sparse activity of OFC neurons, elicited by short-term synaptic plasticity. The intermittent spiking in the sparse activity prevents from reducing the efficacy of short-term synaptic plasticity. The sparse activity codes WM in a functionally latent state, and retrieves WM in a functionally active state as it is needed. In contrast, top-down signals from OFC allows GC neurons to represent the gustatory information relevant to the WM maintained in OFC. We also present a comparison mechanism of a sample and a test stimulus, separated by a delay period. Furthermore, we offer the mechanism by which the synaptic structures of the neural circuits involved in the DMS task are generated via the task training. The results provide a unified view of how WM maintenance is linked to its manipulation.},
  archive      = {J_CC},
  author       = {Antaket, Layla Chadaporn and Kashimori, Yoshiki},
  doi          = {10.1007/s12559-022-10035-1},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {373-391},
  shortjournal = {Cogn. Comput.},
  title        = {Neural mechanisms of the maintenance and manipulation of gustatory working memory in orbitofrontal cortex},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Position-aware attention mechanism–based bi-graph for
dialogue relation extraction. <em>CC</em>, <em>15</em>(1), 359–372. (<a
href="https://doi.org/10.1007/s12559-022-10105-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation extraction in a dialogue scenario aims to extract the relations between entities in a multi-turn dialogue. Unlike the conventional relation extraction task, the dialogue relation cannot yield a result through a single sentence. Therefore, it is essential to model multi-turn dialogue for reasoning. However, dialogue relation extraction easily causes referential ambiguity owing to the low information density in the dialogue dataset and a large amount of pronoun referential information in the dialogue. In addition, most existing models only consider the token-level information interaction and do not fully utilize the interaction between discourses. To address these issues, a graph neural network–based dialogue relation extraction model is proposed using the position-aware refinement mechanism (PAR-DRE) in this paper. Firstly, PAR-DRE models the dependencies between the speaker’s relevant information and various discourse sentences and introduces pronoun reference information to develop the dialogue into a heterogeneous reference dialogue graph. Secondly, a position-aware refinement mechanism is introduced to capture more discriminative features of nodes containing relative location information. On this basis, an entity graph is built by merging the abovementioned nodes, and the path reasoning mechanism is used to infer the relation between entities in the dialogue. The experimental results on the dialogue dataset indicate that the performance of the F1 value of this method is enhanced by 1.25% compared with the current mainstream approaches.},
  archive      = {J_CC},
  author       = {Duan, Guiduo and Dong, Yunrui and Miao, Jiayu and Huang, Tianxi},
  doi          = {10.1007/s12559-022-10105-4},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {359-372},
  shortjournal = {Cogn. Comput.},
  title        = {Position-aware attention Mechanism–Based bi-graph for dialogue relation extraction},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attention mechanism enhanced multi-layer edge perception
network for deep semantic medical segmentation. <em>CC</em>,
<em>15</em>(1), 348–358. (<a
href="https://doi.org/10.1007/s12559-022-10094-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing deep learning–based medical image segmentation methods have achieved gratifying progress, but they still suffer from the coarse boundaries with similar pixels of target. Because the boundary of medical images becomes blurred and the gradient is inconsistent and not apparent, high-resolution images are needed for more accurate segmentation. To tackle these problems, we propose an efficient multi-layer edge perception U-shaped structure for medical image segmentation. In this paper, we present a multi-layer edge perception network for describing more precise edges of medical targets. The U-structure architecture of our network embeds a multi-layer edge perception module, which has the following advantages: (1) connecting different scales and channels to help the network better learn the feature of the medical image via the combination of a pyramid structure and several edge perception modules; (2) a new downsampling block is designed to improve the network’s sensibility to the target boundary. We demonstrate the effectiveness of the proposed model on the DRIVE datasets, and achieve a Dice gain of 0.841 over other models. In this paper, we propose an efficient multi-layer edge perception U-shaped structure for medical image segmentation. A large number of experiments show that the performance of our proposed multi-layer edge perception U-shaped network is significantly better than the traditional segmented network structure.},
  archive      = {J_CC},
  author       = {Sun, Meijun and Li, Pengfei and Ren, Jinchang and Wang, Zheng},
  doi          = {10.1007/s12559-022-10094-4},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {348-358},
  shortjournal = {Cogn. Comput.},
  title        = {Attention mechanism enhanced multi-layer edge perception network for deep semantic medical segmentation},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Aspect sentiment triplet extraction incorporating syntactic
constituency parsing tree and commonsense knowledge graph. <em>CC</em>,
<em>15</em>(1), 337–347. (<a
href="https://doi.org/10.1007/s12559-022-10078-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aspect sentiment triplet extraction (ASTE) task aims to extract the target term and the opinion term, and simultaneously identify the sentiment polarity of target-opinion pairs from the given sentences. While syntactic constituency information and commonsense knowledge are both important and valuable for the ASTE task, only a few studies have explored how to integrate them via flexible graph convolutional networks (GCNs) for this task. To address this gap, this paper proposes a novel end-to-end model, namely GCN-EGTS, which is an enhanced Grid Tagging Scheme (GTS) for ASTE leveraging syntactic constituency parsing tree and a commonsense knowledge graph based on GCNs. Specifically, two types of GCNs are developed to model the information involved, namely span GCN for syntactic constituency parsing tree and relational GCN (R-GCN) for commonsense knowledge graph. In addition, a new loss function is designed by incorporating several constraints for GTS to enhance the original tagging scheme. The extensive experiments on several public datasets demonstrate that GCN-EGTS outperforms the state-of-the-art approaches significantly for the ASTE task based on the evaluation metrics. The outcomes of this research indicate that effectively incorporating syntactic constituency parsing information and commonsense knowledge is a promising direction for the ASTE task.},
  archive      = {J_CC},
  author       = {Hu, Zhenda and Wang, Zhaoxia and Wang, Yinglin and Tan, Ah-Hwee},
  doi          = {10.1007/s12559-022-10078-4},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {337-347},
  shortjournal = {Cogn. Comput.},
  title        = {Aspect sentiment triplet extraction incorporating syntactic constituency parsing tree and commonsense knowledge graph},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). VSCA: A sentence matching model incorporating visual
perception. <em>CC</em>, <em>15</em>(1), 323–336. (<a
href="https://doi.org/10.1007/s12559-022-10074-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stacking multiple layers of attention networks can significantly improve a model’s performance. However, this also increases the model’s time and space complexity, making it difficult for the model to capture detailed information on the underlying features. We propose a novel sentence matching model (VSCA) that uses a new attention mechanism based on variational autoencoders (VAE), which exploits the contextual information in sentences to construct a basic attention feature map and combines it with VAE to generate multiple sets of related attention feature maps for fusion. Furthermore, VSCA introduces a spatial attention mechanism that combines visual perception to capture multilevel semantic information. The experimental results show that our proposed model outperforms pretrained models such as BERT on the LCQMC dataset and performs well on the PAWS-X data. Our work consists of two parts. The first part compares the proposed sentence matching model with state-of-the-art pretrained models such as BERT. The second part conducts innovative research on applying VAE and spatial attention mechanisms in NLP. The experimental results on the related datasets show that the proposed method has satisfactory performance, and VSCA can capture rich attentional information and detailed information with less time and space complexity. This work provides insights into the application of VAE and spatial attention mechanisms in NLP.},
  archive      = {J_CC},
  author       = {Zhang, Zhe and Xiao, Guangli and Qian, Yurong and Ma, Mengnan and Leng, Hongyong and Zhang, Tao},
  doi          = {10.1007/s12559-022-10074-8},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {323-336},
  shortjournal = {Cogn. Comput.},
  title        = {VSCA: A sentence matching model incorporating visual perception},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sentiment analysis and topic mining using a novel deep
attention-based parallel dual-channel model for online course reviews.
<em>CC</em>, <em>15</em>(1), 304–322. (<a
href="https://doi.org/10.1007/s12559-022-10083-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sentiment analysis and topic mining of course reviews are helpful for course improvement and development. In order to improve the quality of online teaching and effectively mine the information such as sentiments contained in course reviews, a novel Deep Attention-based Parallel Dual-Channel Model (DAPDM) is proposed by combining deep learning neural network algorithms. Bidirectional Encoder Representation from Transformers (BERT) is used to train word vectors. Convolutional neural network (CNN) and bi-directional long short-term memory (BiLSTM) with attention mechanism are used to form a dual-channel model to extract sentiment features and enrich semantics. Firstly, a total of 48,501 online course reviews are selected for experiment and analysis. BERT is also used for data enhancement to obtain balanced data. And the data are substituted into DAPDM and 8 other comparative models to verify the model performance. Secondly, the student-course-institution tripartite graph relationship network and the different sentiment feature words co-occurrence network are constructed and visualized to further study the internal relationship among students, courses, and institutions. Finally, the latent dirichlet allocation (LDA) model is used to extract concerns of different sentiments. The classification accuracy, the macro-average of F1 and the weighted average of F1 on DAPDM are respectively improved to 89.44%, 0.8195, and 0.8939 compared with the comparison model. And its receiver operating characteristic (ROC) curve results are optimal. The relationship network can uncover the most popular courses and institutions, and discover that courses serve as a bridge between students and institutions. It is also found that learners’ reviews mainly focus on the course content, technical content, difficulty degree, teachers’ teaching level, etc., which are also the main factors affecting the course learners’ satisfaction with the course. The study can provide theoretical and technical support for the specification and development of online courses.},
  archive      = {J_CC},
  author       = {Yan, Chun and Liu, Jiahui and Liu, Wei and Liu, Xinhong},
  doi          = {10.1007/s12559-022-10083-7},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {304-322},
  shortjournal = {Cogn. Comput.},
  title        = {Sentiment analysis and topic mining using a novel deep attention-based parallel dual-channel model for online course reviews},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TEDT: Transformer-based encoding–decoding translation
network for multimodal sentiment analysis. <em>CC</em>, <em>15</em>(1),
289–303. (<a href="https://doi.org/10.1007/s12559-022-10073-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis is a popular and challenging research topic in natural language processing, but the impact of individual modal data in videos on sentiment analysis results can be different. In the temporal dimension, natural language sentiment is influenced by nonnatural language sentiment, which may enhance or weaken the original sentiment of the current natural language. In addition, there is a general problem of poor quality of nonnatural language features, which essentially hinders the effect of multimodal fusion. To address the above issues, we proposed a multimodal encoding–decoding translation network with a transformer and adopted a joint encoding–decoding method with text as the primary information and sound and image as the secondary information. To reduce the negative impact of nonnatural language data on natural language data, we propose a modality reinforcement cross-attention module to convert nonnatural language features into natural language features to improve their quality and better integrate multimodal features. Moreover, the dynamic filtering mechanism filters out the error information generated in the cross-modal interaction to further improve the final output. We evaluated the proposed method on two multimodal sentiment analysis benchmark datasets (MOSI and MOSEI), and the accuracy of the method was 89.3% and 85.9%, respectively. In addition, our method outperformed the current state-of-the-art methods. Our model can greatly improve the effect of multimodal fusion and more accurately analyze human sentiment.},
  archive      = {J_CC},
  author       = {Wang, Fan and Tian, Shengwei and Yu, Long and Liu, Jing and Wang, Junwen and Li, Kun and Wang, Yongtao},
  doi          = {10.1007/s12559-022-10073-9},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {289-303},
  shortjournal = {Cogn. Comput.},
  title        = {TEDT: Transformer-based Encoding–Decoding translation network for multimodal sentiment analysis},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modelling human word learning and recognition using visually
grounded speech. <em>CC</em>, <em>15</em>(1), 272–288. (<a
href="https://doi.org/10.1007/s12559-022-10059-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many computational models of speech recognition assume that the set of target words is already given. This implies that these models learn to recognise speech in a biologically unrealistic manner, i.e. with prior lexical knowledge and explicit supervision. In contrast, visually grounded speech models learn to recognise speech without prior lexical knowledge by exploiting statistical dependencies between spoken and visual input. While it has previously been shown that visually grounded speech models learn to recognise the presence of words in the input, we explicitly investigate such a model as a model of human speech recognition. We investigate the time course of noun and verb recognition as simulated by the model using a gating paradigm to test whether its recognition is affected by well-known word competition effects in human speech processing. We furthermore investigate whether vector quantisation, a technique for discrete representation learning, aids the model in the discovery and recognition of words. Our experiments show that the model is able to recognise nouns in isolation and even learns to properly differentiate between plural and singular nouns. We also find that recognition is influenced by word competition from the word-initial cohort and neighbourhood density, mirroring word competition effects in human speech comprehension. Lastly, we find no evidence that vector quantisation is helpful in discovering and recognising words, though our gating experiment does show that the LSTM-VQ model is able to recognise the target words earlier.},
  archive      = {J_CC},
  author       = {Merkx, Danny and Scholten, Sebastiaan and Frank, Stefan L. and Ernestus, Mirjam and Scharenborg, Odette},
  doi          = {10.1007/s12559-022-10059-7},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {272-288},
  shortjournal = {Cogn. Comput.},
  title        = {Modelling human word learning and recognition using visually grounded speech},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatically constructing a fine-grained sentiment lexicon
for sentiment analysis. <em>CC</em>, <em>15</em>(1), 254–271. (<a
href="https://doi.org/10.1007/s12559-022-10043-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is an important research area in natural language processing (NLP), and the performance of sentiment analysis models is largely influenced by the quality of sentiment lexicons. Existing sentiment lexicons contain only the sentiment information of words. In this paper, we propose an approach for automatically constructing a fine-grained sentiment lexicon that contains both emotion information and sentiment information to solve the problem that the emotion and sentiment of texts cannot be jointly analyzed. We design an emotion-sentiment transfer method and construct a fine-grained sentiment seed lexicon, and we then expand the sentiment seed lexicon by applying the graph dissemination method to the synonym set. Subsequently, we propose a multi-information fusion method based on neural network to expand the sentiment lexicon based on a corpus. Finally, we generate the Fine-Grained Sentiment Lexicon (FGSL), which contains 40,554 words. FGSL achieves F1 values of 61.97%, 69.58%, and 66.99% on three emotion datasets and 88.19%, 89.31%, and 86.88% on three sentiment datasets. Experimental results on multiple public benchmark datasets illustrate that FGSL achieves significantly better performance in both emotion analysis and sentiment analysis tasks.},
  archive      = {J_CC},
  author       = {Wang, Yabing and Huang, Guimin and Li, Maolin and Li, Yiqun and Zhang, Xiaowei and Li, Hui},
  doi          = {10.1007/s12559-022-10043-1},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {254-271},
  shortjournal = {Cogn. Comput.},
  title        = {Automatically constructing a fine-grained sentiment lexicon for sentiment analysis},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CT radiomic features and clinical biomarkers for predicting
coronary artery disease. <em>CC</em>, <em>15</em>(1), 238–253. (<a
href="https://doi.org/10.1007/s12559-023-10118-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study was aimed to investigate the predictive value of the radiomics features extracted from pericoronaric adipose tissue — around the anterior interventricular artery (IVA) — to assess the condition of coronary arteries compared with the use of clinical characteristics alone (i.e., risk factors). Clinical and radiomic data of 118 patients were retrospectively analyzed. In total, 93 radiomics features were extracted for each ROI around the IVA, and 13 clinical features were used to build different machine learning models finalized to predict the impairment (or otherwise) of coronary arteries. Pericoronaric radiomic features improved prediction above the use of risk factors alone. In fact, with the best model (Random Forest + Mutual Information) the AUROC reached $$0.820 \pm 0.076$$ . As a matter of fact, the combined use of both types of features (i.e., radiomic and clinical) allows for improved performance regardless of the feature selection method used. Experimental findings demonstrated that the use of radiomic features alone achieves better performance than the use of clinical features alone, while the combined use of both clinical and radiomic biomarkers further improves the predictive ability of the models. The main contribution of this work concerns: (i) the implementation of multimodal predictive models, based on both clinical and radiomic features, and (ii) a trusted system to support clinical decision-making processes by means of explainable classifiers and interpretable features.},
  archive      = {J_CC},
  author       = {Militello, Carmelo and Prinzi, Francesco and Sollami, Giulia and Rundo, Leonardo and La Grutta, Ludovico and Vitabile, Salvatore},
  doi          = {10.1007/s12559-023-10118-7},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {238-253},
  shortjournal = {Cogn. Comput.},
  title        = {CT radiomic features and clinical biomarkers for predicting coronary artery disease},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The cognitive makeup of writing: Multivariate analysis of
writing impairments following stroke. <em>CC</em>, <em>15</em>(1),
220–237. (<a href="https://doi.org/10.1007/s12559-023-10111-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Writing is a recently acquired skill to human behavioral repertoire, essential in industrialized societies. In the clinic, writing impairment is evident in one-third of stroke patients. This study aimed to find out the cognitive features that contribute to writing impairment of stroke patients in two different writing systems (logographic and phonological). Cognitive profiles were assessed using the Birmingham Cognitive Screen in two cohorts, China (244 patients) and UK (501 patients). The datasets were analyzed separately using an identical procedure. Elastic net was used to rank the importance of different cognitive abilities (features) to writing skill; and linear support vector machine was used to identify the discriminative features needed to accurately identify the stroke patients with and without writing impairments. The prediction performance was evaluated with the area under the curve (AUC), accuracy (ACC), sensitivity (SEN), and specificity (SPE). For the China cohort, writing numbers, complex figure copy, and number calculation obtained good prediction performance on writing impairments with AUC 0.85 ± 0.06, ACC (89 ± 3) %, SEN (81 ± 10) %, and SPE (90 ± 27) %. Concerning the UK data, writing numbers, number calculation, non-word reading, and auditory sustain attention achieved AUC 0.79 ± 0.04, ACC (83 ± 3) %, SEN (74 ± 9) %, and SPE (84 ± 3) %. A small number of patients in both cohorts (China: 9/69, UK: 24/137), who were impaired in writing, were consistently misclassified. Two patients, one in each cohort, showed selective impairments in writing, while all remaining patients were impaired in attention, language, and/or praxis tasks. The results showed that the capability to write numbers and manipulate them were critical features for predicting writing abilities across writing systems. Reading abilities were not a good predictor of writing impairments across both cohorts. Constructive praxis (measured by complex figure copy) was relevant to impairment classification in characters-based writing (China), while phonological abilities (measured by non-word reading) were important features for impairment prediction in alphabetic writing (UK). A small proportion minority of cases with writing deficits were related to different impairment profiles. The findings in this study highlight the multifaceted nature of writing deficits and the potential use of computation methods for revealing hidden cognitive structures in neuropsychological research.},
  archive      = {J_CC},
  author       = {Chen, Haobo and Yu, Shaode and Pan, Xiaoping and Chen, Yanjia and Zhang, Tian and Li, Ze and Zhou, Jin and Hu, Jianxi and Bickerton, Wai-Ling and Lau, Johnny King and Guo, Aihua and Kong, Anthony Pak Hin and Rotshtein, Pia},
  doi          = {10.1007/s12559-023-10111-0},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {220-237},
  shortjournal = {Cogn. Comput.},
  title        = {The cognitive makeup of writing: Multivariate analysis of writing impairments following stroke},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analysis of gender differences in online handwriting signals
for enhancing e-health and e-security applications. <em>CC</em>,
<em>15</em>(1), 208–219. (<a
href="https://doi.org/10.1007/s12559-023-10116-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handwriting is a complex perceptual–motor skill that is mastered around the age of 8. Although its computerized analysis has been utilized in many biometric and digital health applications, the possible effect of gender is frequently neglected. The aim of this paper is to analyze different online handwritten tasks performed by intact subjects and explore gender differences in commonly used temporal, kinematic, and dynamic features. The differences were explored in the BIOSECUR-ID database. We have identified a significant gender difference in on-surface/in-air time of genuine and skilled forgery signatures, on-surface time in cursive letters and numbers, and pressure, speed, and acceleration in text written in capital letters. Our findings accent the need to consider gender as an important confounding factor in studies dealing with online handwriting signal processing.},
  archive      = {J_CC},
  author       = {Faundez-Zanuy, Marcos and Mekyska, Jiri},
  doi          = {10.1007/s12559-023-10116-9},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {208-219},
  shortjournal = {Cogn. Comput.},
  title        = {Analysis of gender differences in online handwriting signals for enhancing e-health and e-security applications},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cognitive decision-making based on a non-linear similarity
measure using an intuitionistic fuzzy set framework. <em>CC</em>,
<em>15</em>(1), 190–207. (<a
href="https://doi.org/10.1007/s12559-022-10071-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Similarity measure (SM) between two intuitionistic fuzzy sets (IFSs) plays a crucial role in cognitive decision-making, for instance, in cognitive medical diagnosis, pattern recognition, criminal investigation, etc., in dealing with uncertainty. An SM between two IFSs signifies the degree of similarity or the exactness of two IFSs. Inherent inadequacies in SMs may lead to erroneous results; therefore, it is vital and significant to use an efficient SM while dealing with cognitive decision-making (DM) problems in uncertain environments. This study proposes a novel SM of IFSs to enhance the capability of producing fair outcomes in cognitive decision-making problems. The proposed SM has provided the similarity values between different pairs of IFSs, describing its advantages and efficiency, whereas many of the existing SMs have produced contradictory results. Furthermore, the proposed SM has been applied to solve certain biologically inspired cognitive medical diagnosis problems, pattern recognition problems, and criminal investigation problems. The results of the comparative study demonstrate how the proposed SM of IFSs conquers and tides over the shortcomings of the previous existing SMs. Many of the existing SMs produced identical similarity values for different pairs of IFSs, thereby serving as unfit for offering the appropriate exactness of information carried by the pairs of IFSs. Against such a backdrop, the proposed SM selects the best alternative for the cognitive decision-making problems and, hence, in a self-evident manner, evinces its applicability and feasibility in such environments. When delving into the biologically inspired multi-criteria decision-making (MCDM) methods under uncertainty with human cognition, SMs of IFSs serve as one of the essential devices. Accordingly, this study merits attention as it accounts for a veritable fundamental research endeavour with the larger goal of making available consistent and proficient SMs in the literature so that the various MCDM methods become more efficient and reliable. This study attempts to define an advanced and novel SM of IFSs to assist and enrich the MCDM methods using a sophisticated approach.},
  archive      = {J_CC},
  author       = {Talukdar, Pranjal and Dutta, Palash and Goala, Soumendra},
  doi          = {10.1007/s12559-022-10071-x},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {190-207},
  shortjournal = {Cogn. Comput.},
  title        = {Cognitive decision-making based on a non-linear similarity measure using an intuitionistic fuzzy set framework},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accurate emotion recognition utilizing extracted EEG sources
as graph neural network nodes. <em>CC</em>, <em>15</em>(1), 176–189. (<a
href="https://doi.org/10.1007/s12559-022-10077-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated analysis and recognition of human emotion play an important role in the development of a human–computer interface. High temporal resolution of EEG signals enables us to noninvasively study the emotional brain activities. However, one major obstacle in this procedure is extracting the essential information in presence of the low spatial resolution of EEG recordings. The pattern of each emotion is clearly defined by mapping from scalp sensors to brain sources using the standardized low-resolution electromagnetic tomography (sLORETA) method. A graph neural network (GNN) is then used for EEG-based emotion recognition in which sLORETA sources are considered as the nodes of the underlying graph. In the proposed method, the inter-source relations in EEG source signals are encoded in the adjacency matrix of GNN. Finally, the labels of the unseen emotions are recognized using a GNN classifier. The experiments on the recorded EEG dataset by inducing excitement through music (recorded in brain-computer interface research lab, University of Tabriz) indicate that the brain source activity modeling by ESB-G3N significantly improves the accuracy of emotion recognition. Experimental results show classification accuracy of 98.35% for two-class classification of positive and negative emotions. In this paper, we concentrate on extracting active emotional cortical sources using EEG source imaging (ESI) techniques. Auditory stimuli are used to rapidly and efficiently induce emotions in participants (visual stimuli in terms of video/image are either slow or inefficient in inducing emotions). We propose the use of active EEG sources as graph nodes by EEG source-based GNN node (ESB-G3N) algorithm. The results show an absolute improvement of 1–2% over subject-dependent and subject-independent scenarions compared to the existing approaches.},
  archive      = {J_CC},
  author       = {Asadzadeh, Shiva and Rezaii, Tohid Yousefi and Beheshti, Soosan and Meshgini, Saeed},
  doi          = {10.1007/s12559-022-10077-5},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {176-189},
  shortjournal = {Cogn. Comput.},
  title        = {Accurate emotion recognition utilizing extracted EEG sources as graph neural network nodes},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A brain-controlled vehicle system based on steady state
visual evoked potentials. <em>CC</em>, <em>15</em>(1), 159–175. (<a
href="https://doi.org/10.1007/s12559-022-10051-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a human-vehicle cooperative driving system. The objectives of this research are twofold: (1) providing a feasible brain-controlled vehicle (BCV) mode; (2) providing a human-vehicle cooperative control mode. For the first aim, through a brain-computer interface (BCI), we can analyse the EEG signal and get the driving intentions of the driver. For the second aim, the human-vehicle cooperative control is manifested in the BCV combined with the obstacle detection assistance. Considering the potential dangers of driving a real motor vehicle in the outdoor, an obstacle detection module is essential in the human-vehicle cooperative driving system. Obstacle detection and emergency braking can ensure the safety of the driver and the vehicle during driving. EEG system based on steady-state visual evoked potential (SSVEP) is used in the BCI. Simulation and real vehicle driving experiment platform are designed to verify the feasibility of the proposed human-vehicle cooperative driving system. Five subjects participated in the simulation experiment and real the vehicle driving experiment. The outdoor experimental results show that the average accuracy of intention recognition is 90.68 ± 2.96% on the real vehicle platform. In this paper, we verified the feasibility of the SSVEP-based BCV mode and realised the human-vehicle cooperative driving system.},
  archive      = {J_CC},
  author       = {Zhang, Zhao and Han, Shuning and Yi, Huaihai and Duan, Feng and Kang, Fei and Sun, Zhe and Solé-Casals, Jordi and Caiafa, Cesar F.},
  doi          = {10.1007/s12559-022-10051-1},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {159-175},
  shortjournal = {Cogn. Comput.},
  title        = {A brain-controlled vehicle system based on steady state visual evoked potentials},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An investigation to identify optimal setup for automated
assessment of dysarthric intelligibility using deep learning
technologies. <em>CC</em>, <em>15</em>(1), 146–158. (<a
href="https://doi.org/10.1007/s12559-022-10041-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in deep learning have provided an opportunity to improve and automate dysarthria intelligibility assessment, offering a cost-effective, accessible, and less subjective way to assess dysarthric speakers. However, reviewing previous literature in the area determines that the generalization of results on new dysarthric patients was not measured properly or incomplete among the previous studies that yielded very high accuracies due to the gaps in the adopted evaluation methodologies. This is of particular importance as any practical and clinical application of intelligibility assessment approaches must reliably generalize on new patients; otherwise, the clinicians cannot accept the assessment results provided by the system deploying the approach. In this paper, after these gaps are explained, we report on our extensive investigation to propose a deep learning–based dysarthric intelligibility assessment optimal setup. Then, we explain different evaluation strategies that were applied to thoroughly verify how the optimal setup performs with new speakers and across different classes of speech intelligibility. Finally, a comparative study was conducted, benchmarking the performance of our proposed optimal setup against the state of the art by adopting similar strategies previous studies employed. Results indicate an average of 78.2% classification accuracy for unforeseen low intelligibility speakers, 40.6% for moderate intelligibility speakers, and 40.4% for high intelligibility speakers. Furthermore, we noticed a high variance of classification accuracies among individual speakers. Finally, our proposed optimal setup delivered an average of 97.19% classification accuracy when adopting a similar evaluation strategy used by the previous studies.},
  archive      = {J_CC},
  author       = {Hall, Kyle and Huang, Andy and Shahamiri, Seyed Reza},
  doi          = {10.1007/s12559-022-10041-3},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {146-158},
  shortjournal = {Cogn. Comput.},
  title        = {An investigation to identify optimal setup for automated assessment of dysarthric intelligibility using deep learning technologies},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A controlled attention for nested named entity recognition.
<em>CC</em>, <em>15</em>(1), 132–145. (<a
href="https://doi.org/10.1007/s12559-023-10112-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional methods to recognize named entities are conducted as sequence labelling or span classification. They are usually implemented on a raw input without any cue about possible named entities. This method cannot be aware of entity boundaries and learn semantic dependencies between them. Cognitive neuroscience has revealed that foveating stimuli improves the efficiency of processing in terms of acuity. Inspired by this phenomenon, we propose a controlled attention mechanism for recognizing named entities. In our method, instead of feeding a raw input into a neural network, task-related cues are implanted into each sentence to indicate boundaries of possible named entities. Then, the modified sentence is sent into a deep network to learn a discriminative entity-relevant sentence representation. In our experiments, the controlled attention is evaluated on English and Chinese corpora. Comparing with existing models, it shows significant improvement for nested named entity recognition. We achieve the state-of-the-art performance in all evaluation datasets. The controlled attention has three advantages for named entity recognition. First, it enables a neural network to become aware of entity boundaries and construct semantic dependencies relevant to possible entities. Second, implanting entity cues enables a neural network to concentrate on the task-related semantic features while disregarding nonessential information in a sentence. Third, the controlled attention also has the potentiality to be extended for other NLP tasks, e.g., entity relation extraction and event extraction.},
  archive      = {J_CC},
  author       = {Chen, Yanping and Huang, Rong and Pan, Lijun and Huang, Ruizhang and Zheng, Qinghua and Chen, Ping},
  doi          = {10.1007/s12559-023-10112-z},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {132-145},
  shortjournal = {Cogn. Comput.},
  title        = {A controlled attention for nested named entity recognition},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-granularity hierarchical feature extraction for
question-answering understanding. <em>CC</em>, <em>15</em>(1), 121–131.
(<a href="https://doi.org/10.1007/s12559-022-10102-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Question-answering understanding systems are of central importance to many natural language processing tasks. A successful question-answering system first needs to accurately mine the semantics of the problem text and then match the semantic similarity between the question and the answer. Most of the current pre-training language modes use joint coding of questions and answers, a pre-training language model to avoid the problem of feature extraction from multilevel text structure, it through unified advance training ignores text semantic expression in different particle size, different levels of semantic features, and to some extent avoiding the serious problem of semantic understanding. In this paper, we focus on the problem of multi-granularity and multi-level feature expression of text semantics in question and answer understanding, and design a question-answering understanding method for multi-granularity hierarchical features. First, we extract features from two aspects, the traditional language model and the deep matching model, and then fuse these features to construct the similarity matrix, and learn the similarity matrix by designing three different models. Finally, the similarity matrix is learned by three different models, and after sorting, the overall similarity is obtained from the similarity of multiple granularity features. Evaluated by testing on WikiQA public datasets, experiments show that the results of our method are improved by adding the multi-granularity hierarchical feature learning method compared with traditional deep learning methods.},
  archive      = {J_CC},
  author       = {Qin, Xingguo and Zhou, Ya and Huang, Guimin and Li, Maolin and Li, Jun},
  doi          = {10.1007/s12559-022-10102-7},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {121-131},
  shortjournal = {Cogn. Comput.},
  title        = {Multi-granularity hierarchical feature extraction for question-answering understanding},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A developmental approach for training deep belief networks.
<em>CC</em>, <em>15</em>(1), 103–120. (<a
href="https://doi.org/10.1007/s12559-022-10085-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep belief networks (DBNs) are stochastic neural networks that can extract rich internal representations of the environment from the sensory data. DBNs had a catalytic effect in triggering the deep learning revolution, demonstrating for the very first time the feasibility of unsupervised learning in networks with many layers of hidden neurons. These hierarchical architectures incorporate plausible biological and cognitive properties, making them particularly appealing as computational models of human perception and cognition. However, learning in DBNs is usually carried out in a greedy, layer-wise fashion, which does not allow to simulate the holistic maturation of cortical circuits and prevents from modeling cognitive development. Here we present iDBN, an iterative learning algorithm for DBNs that allows to jointly update the connection weights across all layers of the model. We evaluate the proposed iterative algorithm on two different sets of visual stimuli, measuring the generative capabilities of the learned model and its potential to support supervised downstream tasks. We also track network development in terms of graph theoretical properties and investigate the potential extension of iDBN to continual learning scenarios. DBNs trained using our iterative approach achieve a final performance comparable to that of the greedy counterparts, at the same time allowing to accurately analyze the gradual development of internal representations in the deep network and the progressive improvement in task performance. Our work paves the way to the use of iDBN for modeling neurocognitive development.},
  archive      = {J_CC},
  author       = {Zambra, Matteo and Testolin, Alberto and Zorzi, Marco},
  doi          = {10.1007/s12559-022-10085-5},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {103-120},
  shortjournal = {Cogn. Comput.},
  title        = {A developmental approach for training deep belief networks},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural network-based adaptive containment control algorithms
design for nonlinear multiagent systems with switching topologies.
<em>CC</em>, <em>15</em>(1), 90–102. (<a
href="https://doi.org/10.1007/s12559-022-10082-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses the containment control problem of nonlinear multiagent systems with unknown disturbance and switching topology. The novel model of nonlinear multiagent systems is given and the dynamic functions of this model are considered to be continuous. Utilizing the approximation capability of the neural networks to estimate the unknown external disturbance and unknown nonlinear functions in the dynamic functions of nonlinear multiagent systems, which designs disturbance observer and containment controller. The containment control problem can be addressed with the proposed algorithm, applying the Lyapunov functions, graph theory, and inequality techniques. The nonlinear multiagent systems are cooperatively semi-globally uniformly ultimately bounded and at the end of this paper, a simulation example is given to illustrate the effectiveness of the approach proposed.},
  archive      = {J_CC},
  author       = {Huang, Jie and Wang, Xin and Xu, Rui},
  doi          = {10.1007/s12559-022-10082-8},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {90-102},
  shortjournal = {Cogn. Comput.},
  title        = {Neural network-based adaptive containment control algorithms design for nonlinear multiagent systems with switching topologies},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multilayer network-based approach to represent, explore
and handle convolutional neural networks. <em>CC</em>, <em>15</em>(1),
61–89. (<a href="https://doi.org/10.1007/s12559-022-10084-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning techniques and tools have experienced enormous growth and widespread diffusion in recent years. Among the areas where deep learning has become more widespread there are computational biology and cognitive neuroscience. At the same time, the need for tools able to explore, understand, and possibly manipulate, a deep learning model has strongly emerged. We propose an approach to map a deep learning model into a multilayer network. Our approach is tailored to Convolutional Neural Networks (CNN), but can be easily extended to other architectures. In order to show how our mapping approach enables the exploration and management of deep learning networks, we illustrate a technique for compressing a CNN. It detects whether there are convolutional layers that can be pruned without losing too much information and, in the affirmative case, returns a new CNN obtained from the original one by pruning such layers. We prove the effectiveness of the multilayer mapping approach and the corresponding compression algorithm on the VGG16 network and two benchmark datasets, namely MNIST, and CALTECH-101. In the former case, we obtain a 0.56% increase in accuracy, precision, and recall, and a 21.43% decrease in mean epoch time. In the latter case, we obtain an 11.09% increase in accuracy, 22.27% increase in precision, 38.66% increase in recall, and 47.22% decrease in mean epoch time. Finally, we compare our multilayer mapping approach with a similar one based on single layers and show the effectiveness of the former. We show that a multilayer network-based approach is able to capture and represent the complexity of a CNN. Furthermore, it allows several manipulations on it. An extensive experimental analysis described in the paper demonstrates the suitability of our approach and the goodness of its performance.},
  archive      = {J_CC},
  author       = {Amelio, Alessia and Bonifazi, Gianluca and Corradini, Enrico and Ursino, Domenico and Virgili, Luca},
  doi          = {10.1007/s12559-022-10084-6},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {61-89},
  shortjournal = {Cogn. Comput.},
  title        = {A multilayer network-based approach to represent, explore and handle convolutional neural networks},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fixed-time control for memristor-based quaternion-valued
neural networks with discontinuous activation functions. <em>CC</em>,
<em>15</em>(1), 50–60. (<a
href="https://doi.org/10.1007/s12559-022-10057-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the fixed-time synchronization control of quaternion-valued memristive neural networks (QVMNNs). The QVMNN is the extension of real and complex-valued MNNs, and the activation functions considered in this work are assumed to be discontinuous. Due to the noncommutativity of quaternion multiplication, the QVMNNs model is separated into four real-valued systems by utilizing the differential inclusion theory and decomposition method. Based on the sign function, some discontinuous control schemes are developed. By applying the nonsmooth analysis and inequality techniques, some novel criteria for fixed-time synchronization of QVMNNs are derived. Compared with the previous results, the proposed method based on sign function makes the designed controllers more concise and the established criteria more effective and less conservative. Finally, simulations are proposed to demonstrate the validity and practicability of theoretical results.},
  archive      = {J_CC},
  author       = {Wei, Ruoyu and Cao, Jinde and Gorbachev, Sergey},
  doi          = {10.1007/s12559-022-10057-9},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {50-60},
  shortjournal = {Cogn. Comput.},
  title        = {Fixed-time control for memristor-based quaternion-valued neural networks with discontinuous activation functions},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A graph-based deep reinforcement learning approach to
grasping fully occluded objects. <em>CC</em>, <em>15</em>(1), 36–49. (<a
href="https://doi.org/10.1007/s12559-022-10047-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grasping in cluttered scenes is an important issue in robotic manipulation. The cooperation of grasping and pushing actions based on reinforcement learning is an effective means to obtain the target object when it is completely blocked or there is no suitable grasping position around it. When exploring invisible objects, many existing methods depend excessively on model design and redundant grasping actions. We propose a graph-based deep reinforcement learning model to efficiently explore invisible objects and improve the performance for cooperative grasping and pushing tasks. Our model first extracts the state features and then estimates the Q value with different graph Q-Nets according to whether the target object is found. The graph-based Q-learning model contains an encoder, a graph reasoning module and a decoder. The encoder is used to integrate the state features such that the features of one region include those of other regions. The graph reasoning module captures the internal relationships of features between different regions through graph convolution networks. The decoder maps the features transformed by reasoning to the original state features. Our method achieves a 100% success rate in the task of exploring the target object and a success rate of more than 90% in the task of grasping and pushing cooperatively in simulation experiment, which performs better than many existing state-of-the-art methods. Our method is an effective means to help robots obtain completely occluded objects by grasping and pushing cooperation in the cluttered scenes. The verification experiment on the real robot further shows the generalization and practicability of our proposed model.},
  archive      = {J_CC},
  author       = {Zuo, Guoyu and Tong, Jiayuan and Wang, Zihao and Gong, Daoxiong},
  doi          = {10.1007/s12559-022-10047-x},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {36-49},
  shortjournal = {Cogn. Comput.},
  title        = {A graph-based deep reinforcement learning approach to grasping fully occluded objects},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A music cognition–guided framework for multi-pitch
estimation. <em>CC</em>, <em>15</em>(1), 23–35. (<a
href="https://doi.org/10.1007/s12559-022-10031-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the most important subtasks of automatic music transcription (AMT), multi-pitch estimation (MPE) has been studied extensively for predicting the fundamental frequencies in the frames of audio recordings during the past decade. However, how to use music perception and cognition for MPE has not yet been thoroughly investigated. Motivated by this, this demonstrates how to effectively detect the fundamental frequency and the harmonic structure of polyphonic music using a cognitive framework. Inspired by cognitive neuroscience, an integration of the constant Q transform and a state-of-the-art matrix factorization method called shift-invariant probabilistic latent component analysis (SI-PLCA) are proposed to resolve the polyphonic short-time magnitude log-spectra for multiple pitch estimation and source-specific feature extraction. The cognitions of rhythm, harmonic periodicity and instrument timbre are used to guide the analysis of characterizing contiguous notes and the relationship between fundamental frequency and harmonic frequencies for detecting the pitches from the outcomes of SI-PLCA. In the experiment, we compare the performance of proposed MPE system to a number of existing state-of-the-art approaches (seven weak learning methods and four deep learning methods) on three widely used datasets (i.e. MAPS, BACH10 and TRIOS) in terms of F-measure ( $${F}_{1}$$ ) values. The experimental results show that the proposed MPE method provides the best overall performance against other existing methods.},
  archive      = {J_CC},
  author       = {Li, Xiaoquan and Yan, Yijun and Soraghan, John and Wang, Zheng and Ren, Jinchang},
  doi          = {10.1007/s12559-022-10031-5},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {23-35},
  shortjournal = {Cogn. Comput.},
  title        = {A music Cognition–Guided framework for multi-pitch estimation},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IR-capsule: Two-stream network for face forgery detection.
<em>CC</em>, <em>15</em>(1), 13–22. (<a
href="https://doi.org/10.1007/s12559-022-10008-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the emergence of deep learning, generating forged images or videos has become much easier in recent years. Face forgery detection, as a way to detect forgery, is an important topic in digital media forensics. Despite previous works having made remarkable progress, the spatial relationships of each part of the face that has significant forgery clues are seldom explored. To overcome this shortcoming, a two-stream face forgery detection network that fuses Inception ResNet stream and capsule network stream (IR-Capsule) is proposed in this paper, which can learn both conventional facial features and hierarchical pose relationships and angle features between different parts of the face. Furthermore, part of the Inception ResNet V1 model pre-trained on the VGGFACE2 dataset is utilized as an initial feature extractor to reduce overfitting and training time, and a modified capsule loss is proposed for the IR-Capsule network. Experimental results on the challenging FaceForensics++ benchmark show that the proposed IR-Capsule improves accuracy by more than 3% compared with several state-of-the-art methods.},
  archive      = {J_CC},
  author       = {Lin, Kaihan and Han, Weihong and Li, Shudong and Gu, Zhaoquan and Zhao, Huimin and Ren, Jinchang and Zhu, Li and Lv, Jujian},
  doi          = {10.1007/s12559-022-10008-4},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {13-22},
  shortjournal = {Cogn. Comput.},
  title        = {IR-capsule: Two-stream network for face forgery detection},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep, flexible data embedding with graph-based feature
propagation for semi-supervised classification. <em>CC</em>,
<em>15</em>(1), 1–12. (<a
href="https://doi.org/10.1007/s12559-022-10056-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based data representation has recently received much attention in the fields of machine learning and cognitive computation. Deep architectures and the semi-supervised learning paradigm are very closely related to natural cognitive systems. In this paper, and in the context of semi-supervised learning, we will be addressing deep graph-based data representation using a cascade of flexible embedding based on feature propagation over graphs. Inspired by connectionist models, we developed a deep architecture that performs data representation. In each layer, a graph is created over the current representation of the data. This graph is used to aggregate the current features of the input data and provide a layer-specific linear and non-linear representation. The semi-supervised scheme presented simultaneously satisfies several desired properties. These include graph-based regularization of the data structure — a geometrically motivated criterion, flexible non-linear projection (i.e., linear and non-linear projections are jointly estimated), graph-based feature propagation (providing a low-pass filter of the features in each layer), and deep architecture. Our work’s main innovative aspect stems from the fact that each layer employs feature propagation (aggregation) before solving the layer-by-layer projection transformations. The proposed model can be learned layer by layer. In each layer, the non-linear data representation and linear regression are jointly estimated with a closed form solution. The proposed method was evaluated using semi-supervised classification tasks with six image datasets. These experiments demonstrated the effectiveness of the proposed approach, which can compete with a variety of competing semi-supervised methods. Compared to a flexible scheme for data representation, the introduced method improved the performance by 8.5% on average. Compared to a recent deep scheme for data representation, the introduced feature propagation improved the performance by 1.3% on average. The use of feature propagation in each layer can improve the flexible model’s performance.},
  archive      = {J_CC},
  author       = {Dornaika, Fadi},
  doi          = {10.1007/s12559-022-10056-w},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Cogn. Comput.},
  title        = {Deep, flexible data embedding with graph-based feature propagation for semi-supervised classification},
  volume       = {15},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
