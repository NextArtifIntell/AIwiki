<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>CIS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="cis---300">CIS - 300</h2>
<ul>
<li><details>
<summary>
(2023). WRANet: Wavelet integrated residual attention u-net network
for medical image segmentation. <em>CIS</em>, <em>9</em>(6), 6971–6983.
(<a href="https://doi.org/10.1007/s40747-023-01119-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation is crucial for the diagnosis and analysis of disease. Deep convolutional neural network methods have achieved great success in medical image segmentation. However, they are highly susceptible to noise interference during the propagation of the network, where weak noise can dramatically alter the network output. As the network deepens, it can face problems such as gradient explosion and vanishing. To improve the robustness and segmentation performance of the network, we propose a wavelet residual attention network (WRANet) for medical image segmentation. We replace the standard downsampling modules (e.g., maximum pooling and average pooling) in CNNs with discrete wavelet transform, decompose the features into low- and high-frequency components, and remove the high-frequency components to eliminate noise. At the same time, the problem of feature loss can be effectively addressed by introducing an attention mechanism. The combined experimental results show that our method can effectively perform aneurysm segmentation, achieving a Dice score of 78.99%, an IoU score of 68.96%, a precision of 85.21%, and a sensitivity score of 80.98%. In polyp segmentation, a Dice score of 88.89%, an IoU score of 81.74%, a precision rate of 91.32%, and a sensitivity score of 91.07% were achieved. Furthermore, our comparison with state-of-the-art techniques demonstrates the competitiveness of the WRANet network.},
  archive      = {J_CIS},
  author       = {Zhao, Yawu and Wang, Shudong and Zhang, Yulin and Qiao, Sibo and Zhang, Mufei},
  doi          = {10.1007/s40747-023-01119-y},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6971-6983},
  shortjournal = {Complex Intell. Syst.},
  title        = {WRANet: Wavelet integrated residual attention U-net network for medical image segmentation},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DSC-MVSNet: Attention aware cost volume regularization based
on depthwise separable convolution for multi-view stereo. <em>CIS</em>,
<em>9</em>(6), 6953–6969. (<a
href="https://doi.org/10.1007/s40747-023-01106-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has recently been proven to deliver excellent performance in multi-view stereo (MVS). However, it is difficult for deep learning-based MVS approaches to balance their efficiency and effectiveness. Towards this end, we propose the DSC-MVSNet, a novel coarse-to-fine and end-to-end framework for more efficient and more accurate depth estimation in MVS. In particular, we propose an attention aware 3D UNet-shape network, which first uses the depthwise separable convolutions for cost volume regularization. This mechanism enables effective aggregation of information and significantly reduces the model parameters and computation by transforming the ordinary convolution on cost volume as depthwise convolution and pointwise convolution. Besides, a 3D-Attention module is proposed to alleviate the feature mismatching problem in cost volume regularization and aggregate the important information of cost volume in three dimensions (i.e. channel, space, and depth). Moreover, we propose an efficient Feature Transfer Module to upsample the low-resolution (LR) depth map to a high-resolution (HR) depth map to achieve higher accuracy. With extensive experiments on two benchmark datasets, i.e. DTU and Tanks &amp; Temples, we demonstrate that the parameters of our model are significantly reduced to $$25\%$$ of the state-of-the-art model MVSNet. Besides, our method outperforms or maintains on par accuracy with the state-of-the-art models. Our source code is available at https://github.com/zs670980918/DSC-MVSNet .},
  archive      = {J_CIS},
  author       = {Zhang, Song and Wei, Zhiwei and Xu, Wenjia and Zhang, Lili and Wang, Yang and Zhou, Xin and Liu, Junyi},
  doi          = {10.1007/s40747-023-01106-3},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6953-6969},
  shortjournal = {Complex Intell. Syst.},
  title        = {DSC-MVSNet: Attention aware cost volume regularization based on depthwise separable convolution for multi-view stereo},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel driver emotion recognition system based on deep
ensemble classification. <em>CIS</em>, <em>9</em>(6), 6927–6952. (<a
href="https://doi.org/10.1007/s40747-023-01100-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driver emotion classification is an important topic that can raise awareness of driving habits because many drivers are overconfident and unaware of their bad driving habits. Drivers will acquire insight into their poor driving behaviors and be better able to avoid future accidents if their behavior is automatically identified. In this paper, we use different models such as convolutional neural networks, recurrent neural networks, and multi-layer perceptron classification models to construct an ensemble convolutional neural network-based enhanced driver facial expression recognition model. First, the faces of the drivers are discovered using the faster region-based convolutional neural network (R-CNN) model, which can recognize faces in real-time and offline video reliably and effectively. The feature-fusing technique is utilized to integrate the features extracted from three CNN models, and the fused features are then used to train the suggested ensemble classification model. To increase the accuracy and efficiency of face detection, a new convolutional neural network block (InceptionV3) replaces the improved Faster R-CNN feature-learning block. To evaluate the proposed face detection and driver facial expression recognition (DFER) datasets, we achieved an accuracy of 98.01%, 99.53%, 99.27%, 96.81%, and 99.90% on the JAFFE, CK+, FER-2013, AffectNet, and custom-developed datasets, respectively. The custom-developed dataset has been recorded as the best among all under the simulation environment.},
  archive      = {J_CIS},
  author       = {Zaman, Khalid and Zhaoyun, Sun and Shah, Babar and Hussain, Tariq and Shah, Sayyed Mudassar and Ali, Farman and Khan, Umer Sadiq},
  doi          = {10.1007/s40747-023-01100-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6927-6952},
  shortjournal = {Complex Intell. Syst.},
  title        = {A novel driver emotion recognition system based on deep ensemble classification},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Heterogeneous differential evolution particle swarm
optimization with local search. <em>CIS</em>, <em>9</em>(6), 6905–6925.
(<a href="https://doi.org/10.1007/s40747-023-01082-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To develop a high performance and widely applicable particle swarm optimization (PSO) algorithm, a heterogeneous differential evolution particle swarm optimization (HeDE-PSO) is proposed in this study. HeDE-PSO adopts two differential evolution (DE) mutants to construct different characteristics of learning exemplars for PSO, one DE mutant is for enhancing exploration and the other is for enhance exploitation. To further improve search accuracy in the late stage of optimization, the BFGS (Broyden–Fletcher–Goldfarb–Shanno) local search is employed. To assess the performance of HeDE-PSO, it is tested on the CEC2017 test suite and the industrial refrigeration system design problem. The test results are compared with seven recent PSO algorithms, JADE (adaptive differential evolution with optional external archive) and four meta-heuristics. The comparison results show that with two DE mutants to construct learning exemplars, HeDE-PSO can balance exploration and exploitation and obtains strong adaptability on different kinds of optimization problems. On 10-dimensional functions and 30-dimensional functions, HeDE-PSO is only outperformed by the most competitive PSO algorithm on seven and six functions, respectively. HeDE-PSO obtains the best performance on sixteen 10-dimensional functions and seventeen-30 dimensional functions. Moreover, HeDE-PSO outperforms other compared PSO algorithms on the industrial refrigeration system design problem.},
  archive      = {J_CIS},
  author       = {Lin, Anping and Liu, Dong and Li, Zhongqi and Hasanien, Hany M. and Shi, Yaoting},
  doi          = {10.1007/s40747-023-01082-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6905-6925},
  shortjournal = {Complex Intell. Syst.},
  title        = {Heterogeneous differential evolution particle swarm optimization with local search},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A federated learning algorithm using parallel-ensemble
method on non-IID datasets. <em>CIS</em>, <em>9</em>(6), 6891–6903. (<a
href="https://doi.org/10.1007/s40747-023-01110-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional federated learning algorithms suffer from considerable performance reduction with non-identically and independently distributed datasets. This paper proposes a federated learning algorithm based on parallel-ensemble learning, which improves performance for image classification on these datasets. The training process of this algorithm includes basic federation learning and meta federation learning. First, several basic models are trained through cross-validation of federated learning, and then the meta-model is trained using the prediction results of the validation sets. In the training process, the training of different basic models is parallel. In prediction, meta-model is used to aggregate the output of the basic models to get the final prediction results. Our algorithm can achieve higher accuracy than traditional federated learning when using non-independent identically distributed datasets for image classification. Our algorithm aggregates different models through federated learning based on parallel-ensemble method, and improves the image classification performance of federated learning on non-independent identically distributed datasets.},
  archive      = {J_CIS},
  author       = {Yu, Haoran and Wu, Chang and Yu, Haixin and Wei, Xuelin and Liu, Siyan and Zhang, Ying},
  doi          = {10.1007/s40747-023-01110-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6891-6903},
  shortjournal = {Complex Intell. Syst.},
  title        = {A federated learning algorithm using parallel-ensemble method on non-IID datasets},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A pairwise ranking estimation model for surrogate-assisted
evolutionary algorithms. <em>CIS</em>, <em>9</em>(6), 6875–6890. (<a
href="https://doi.org/10.1007/s40747-023-01113-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate-assisted evolutionary algorithms (SAEAs) have attracted considerable attention for reducing the computation time required by an EA on computationally expensive optimization problems. In such algorithms, a surrogate model estimates the solution evaluation with a low computing cost and is used to obtain promising solutions to which the accurate evaluation with an expensive computation cost is then applied. This study proposes a novel pairwise ranking surrogate model called the Extreme Learning-machine-based DirectRanker (ELDR). ELDR integrates two machine learning models: extreme learning machine (ELM) and DirectRanker (DR). ELM is a single-layer neural network capable of fast learning, whereas DR uses pairwise learning to rank using a neural network developed mainly for information retrieval. To investigate the effectiveness of the proposed surrogate model, this study first examined the estimation accuracy of ELDR. Subsequently, ELDR was incorporated into a state-of-the-art SAEA and compared with existing SAEAs on well-known real-valued optimization benchmark problems. The experimental results revealed that ELDR has a high estimation accuracy even on high-dimensional problems with a small amount of training data. In addition, the SAEA using ELDR exhibited a high search performance compared with other existing SAEAs, especially on high-dimensional problems.},
  archive      = {J_CIS},
  author       = {Harada, Tomohiro},
  doi          = {10.1007/s40747-023-01113-4},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6875-6890},
  shortjournal = {Complex Intell. Syst.},
  title        = {A pairwise ranking estimation model for surrogate-assisted evolutionary algorithms},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Auto-weighted multiple kernel tensor clustering.
<em>CIS</em>, <em>9</em>(6), 6863–6874. (<a
href="https://doi.org/10.1007/s40747-023-01112-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple kernel subspace clustering (MKSC) has attracted intensive attention since its powerful capability of exploring consensus information by generating a high-quality affinity graph from multiple base kernels. However, the existing MKSC methods still exist the following limitations: (1) they essentially neglect the high-order correlations hidden in different base kernels; and (2) they perform candidate affinity graph learning and consensus affinity graph learning in two separate steps, where suboptimal solution may be obtained. To alleviate these problems, a novel MKSC method, namely auto-weighted multiple kernel tensor clustering (AMKTC), is proposed. Specifically, AMKTC first integrates the consensus affinity graph learning and candidate affinity graph learning into a unified framework, where the optimal goal can be achieved by making these two learning processes negotiate with each other. Further, an auto-weighted fusion scheme with one-step manner is proposed to learn the final consensus affinity graph, where the reasonable weights will be automatically learned for each candidate graph. Finally, the essential high-order correlations between multiple base kernels can be captured by leveraging tensor-singular value decomposition (t-SVD)-based tensor nuclear norm constraint on a 3-order graph tensor. Experiments on seven benchmark datasets with eleven comparison methods demonstrate that our method achieves state-of-the-art clustering performance.},
  archive      = {J_CIS},
  author       = {Wang, Yanlong and Liu, Jinhua and Chang, Cun and Ren, Zhenwen},
  doi          = {10.1007/s40747-023-01112-5},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6863-6874},
  shortjournal = {Complex Intell. Syst.},
  title        = {Auto-weighted multiple kernel tensor clustering},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-task evolutionary optimization of multi-echelon
location routing problems via a hierarchical fuzzy graph. <em>CIS</em>,
<em>9</em>(6), 6845–6862. (<a
href="https://doi.org/10.1007/s40747-023-01109-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-echelon location-routing problems (ME-LRPs) deal with determining the location of facilities and the routes of vehicles on multi-echelon routing tasks. Since the assignment relationship in multi-echelon routing tasks is uncertain and varying, ME-LRPs are very challenging to solve, especially when the number of the echelons increases. In this study, the ME-LRP is formulated as a hierarchical fuzzy graph, in which high-order fuzzy sets are constructed to represent the uncertain assignment relationship as different routing tasks and cross-task operators are used for routing task selection. Then, an evolutionary multi-tasking optimization algorithm is designed to simultaneously solve the multiple routing tasks. To alleviate negative transfer between the different routing tasks, multi-echelon assignment information is considered together with associated routing task selection in multi-tasking evolution optimization. The experimental results on multi-echelon routing benchmark problems demonstrate the competitiveness of the proposed method.},
  archive      = {J_CIS},
  author       = {Yan, Xueming and Jin, Yaochu and Ke, Xiaohua and Hao, Zhifeng},
  doi          = {10.1007/s40747-023-01109-0},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6845-6862},
  shortjournal = {Complex Intell. Syst.},
  title        = {Multi-task evolutionary optimization of multi-echelon location routing problems via a hierarchical fuzzy graph},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel fractional-order flocking algorithm for large-scale
UAV swarms. <em>CIS</em>, <em>9</em>(6), 6831–6844. (<a
href="https://doi.org/10.1007/s40747-023-01107-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rate of convergence is a vital factor in determining the outcome of the mission execution of unmanned aerial vehicle (UAV) swarms. However, the difficulty of developing a rapid convergence strategy increases dramatically with the growth of swarm scale. In the present work, a novel fractional-order flocking algorithm (FOFA) is proposed for large-scale UAV swarms. First, based on the interaction rules of repulsion, attraction and alignment among swarm individuals, fractional calculus is introduced to replace traditional integer-order velocity updating, which enables UAVs to utilize historical information during flight. Subsequently, the convergence of the algorithm is theoretically analyzed. Some sufficient convergence conditions for the FOFA are presented by exploiting graph theory. Finally, the simulation results validate that our proposed FOFA performs much better than traditional flocking algorithms in terms of convergence rate. Meanwhile, the relationships between the fractional order of the FOFA and the convergence time of the UAV swarm are discussed. We find that under certain conditions, the fractional order is strongly correlated with the convergence rate of the UAV swarm; that is, a small fractional order (more consideration of historical information) leads to better performance. Moreover, the fractional order can be used as an important parameter to control the convergence rate of a large-scale UAV swarm.},
  archive      = {J_CIS},
  author       = {Chen, Haotian and He, Ming and Liu, Jintao and Xu, Peng and Cao, Xianghui and Han, Wei and Yuan, Guodong},
  doi          = {10.1007/s40747-023-01107-2},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6831-6844},
  shortjournal = {Complex Intell. Syst.},
  title        = {A novel fractional-order flocking algorithm for large-scale UAV swarms},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). New XAI tools for selecting suitable 3D printing facilities
in ubiquitous manufacturing. <em>CIS</em>, <em>9</em>(6), 6813–6829. (<a
href="https://doi.org/10.1007/s40747-023-01104-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several artificial intelligence (AI) technologies have been applied to assist in the selection of suitable three-dimensional (3D) printing facilities in ubiquitous manufacturing (UM). However, AI applications in this field may not be easily understood or communicated with, especially for decision-makers without relevant background knowledge, hindering the widespread acceptance of such applications. Explainable AI (XAI) has been proposed to address this problem. This study first reviews existing XAI techniques to explain AI applications in selecting suitable 3D printing facilities in UM. This study addresses the deficiencies of existing XAI applications by proposing four new XAI techniques: (1) a gradient bar chart with baseline, (2) a group gradient bar chart, (3) a manually adjustable gradient bar chart, and (4) a bidirectional scatterplot. The proposed methodology was applied to a case in the literature to demonstrate its effectiveness. The bidirectional scatterplot results from the experiment demonstrated the suitability of the 3D printing facilities in terms of their proximity. Furthermore, manually adjustable gradient bars increased the effectiveness of the AI application by decision-makers subjectively adjusting the derived weights. Furthermore, only the proposed methodology fulfilled most requirements for an effective XAI tool in this AI application.},
  archive      = {J_CIS},
  author       = {Wang, Yu-Cheng and Chen, Toly},
  doi          = {10.1007/s40747-023-01104-5},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6813-6829},
  shortjournal = {Complex Intell. Syst.},
  title        = {New XAI tools for selecting suitable 3D printing facilities in ubiquitous manufacturing},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Energy management for wearable medical devices based on
gaining–sharing knowledge algorithm. <em>CIS</em>, <em>9</em>(6),
6797–6811. (<a
href="https://doi.org/10.1007/s40747-023-01101-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wearable devices are a growing field of research that can have a wide range of applications. The energy harvester is the most common source of power for wearable devices as well as in wireless sensor networks that require a battery-free operation. However, their power is restricted; consequently, power saving is crucial for wearable devices. Finding the best schedule for the various tasks that run on the wearable device can help to reduce power consumption. This paper presents a task scheduler for wearable medical devices based on Gaining–Sharing Knowledge (GSK) algorithm. The purpose of this task scheduler is to handle the tasks of a heart rate sensor and a temperature sensor to optimize the energy consumption throughout wearable medical devices. The proposed GSK-based scheduling algorithm is assessed against the state-of-the-art technique. The data used in our experiments are collected from an in-lab prototype.},
  archive      = {J_CIS},
  author       = {Mohamed, Samah and Nomer, Hazem A. A. and Yousri, Retaj and Mohamed, Ali Wagdy and Soltan, Ahmed and Darweesh, M. Saeed},
  doi          = {10.1007/s40747-023-01101-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6797-6811},
  shortjournal = {Complex Intell. Syst.},
  title        = {Energy management for wearable medical devices based on gaining–sharing knowledge algorithm},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Contour detection network for zero-shot sketch-based image
retrieval. <em>CIS</em>, <em>9</em>(6), 6781–6795. (<a
href="https://doi.org/10.1007/s40747-023-01096-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot sketch-based image retrieval (ZS-SBIR) is a challenging task that involves searching natural images related to a given hand-drawn sketch under the zero-shot scene. The previous approach projected image and sketch features into a low-dimensional common space for retrieval, and used semantic features to transfer the knowledge of seen to unseen classes. However, it is not effective enough to align multimodal features when projecting them into a common space, since the styles and contents of sketches and natural images are different and they are not one-to-one correspondence. To solve this problem, we propose a novel three-branch joint training network with contour detection network (called CDNNet) for the ZS-SBIR task, which uses contour maps as a bridge to align sketches and natural images to alleviate the domain gap. Specifically, we use semantic metrics to constrain the relationship between contour images and natural images and between contour images and sketches, so that natural image and sketch features can be aligned in the common space. Meanwhile, we further employ second-order attention to capture target subject information to increase the performance of retrieval descriptors. In addition, we use a teacher model and word embedding method to transfer the knowledge of the seen to the unseen classes. Extensive experiments on two large-scale datasets demonstrate that our proposed approach outperforms state-of-the-art CNN-based models: it improves by 2.6% on the Sketchy and 1.2% on TU-Berlin datasets in terms of mAP.},
  archive      = {J_CIS},
  author       = {Zhang, Qing and Zhang, Jing and Su, Xiangdong and Bao, Feilong and Gao, Guanglai},
  doi          = {10.1007/s40747-023-01096-2},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6781-6795},
  shortjournal = {Complex Intell. Syst.},
  title        = {Contour detection network for zero-shot sketch-based image retrieval},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A decoupling method for solving the multi-agent path finding
problem. <em>CIS</em>, <em>9</em>(6), 6767–6780. (<a
href="https://doi.org/10.1007/s40747-023-01088-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many existing multi-agent path finding (MAPF) solvers focus on completeness, speed, or optimization. However, completeness and rapidity are usually in conflict with each other, which makes these algorithms far from satisfactory in practical applications. Motivated by this realistic requirement, we propose an efficient decoupling method to accelerate the solution of large MAPF problems. First, we define the concept of ‘non-essential vertex’-vertices which are not needed to solve a MAPF problem, and a scheme to identify them. Then, a decoupling scheme based on ‘non-essential vertex’ is proposed, which will assign higher priorities to agents whose goal positions are non-essential vertices and lower priorities to agents whose start positions are non-essential vertices. That is, invoking our decoupling algorithm can decouple any given MAPF problem into three subproblems while maintaining the completeness of the solution. All three sub-MAPF problems can be solved sequentially by a complete solver (e.g., CBS or EECBS, etc.), and two of them can also be solved by a prioritized planning algorithm. We have conducted several experiments in different workspaces, and the statistical results show that the proposed decoupling method significantly improves the speed and success rate of existing MAPF solvers with almost no degradation in solution quality when solving problems with high agent density. In addition, the solving efficiency can be further improved if the prioritized planning algorithm is invoked to solve the first and third sub-MAPF problems.},
  archive      = {J_CIS},
  author       = {Liao, Bin and Zhu, Shenrui and Hua, Yi and Wan, Fangyi and Qing, Xinlin},
  doi          = {10.1007/s40747-023-01088-2},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6767-6780},
  shortjournal = {Complex Intell. Syst.},
  title        = {A decoupling method for solving the multi-agent path finding problem},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LEA u-net: A u-net-based deep learning framework with local
feature enhancement and attention for retinal vessel segmentation.
<em>CIS</em>, <em>9</em>(6), 6753–6766. (<a
href="https://doi.org/10.1007/s40747-023-01095-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature extraction of the retinal blood vessel is one of the crucial tasks in the prediction of ophthalmologic diseases. Important features are extracted based on image segmentation results. The efficiency of vessel segmentation methods could help doctors in the diagnostic of several relevant diseases as early as possible. Recently, U-Net has achieved good results in many medical image segmentation tasks, especially for images of blood vessels. However, due to the limitation of the network structure, some small features could be lost in the transmission process. As a result, there are still many research gaps for U-Net-based retinal vessel segmentation works. In this paper, we propose an improved U-Net based model to segment images of retinal vessels. The improvement focuses on U-Net from two aspects: designing a local feature enhancement module composed of dilated convolution and $$1\times 1$$ convolution to enhance the feature extraction of tiny vessels; integrating an attention mechanism with skip connection of the network to highlight features related to vessel segmentation information taken from the down-sampling part to the up-sampling part. The performance of the proposed model was evaluated and compared with several published state-of-the-art approaches on the same public dataset—DRIVE, and the proposed method achieved an accuracy of 0.9563, F1-score of 0.823, TPR of 0.7983, and TNR of 0.9793. The AUC of PRC is 0.9109 and the AUC of ROC is 0.9794. The results proved the potential for clinical applications.},
  archive      = {J_CIS},
  author       = {Ouyang, Jihong and Liu, Siguang and Peng, Hao and Garg, Harish and Thanh, Dang N. H.},
  doi          = {10.1007/s40747-023-01095-3},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6753-6766},
  shortjournal = {Complex Intell. Syst.},
  title        = {LEA U-net: A U-net-based deep learning framework with local feature enhancement and attention for retinal vessel segmentation},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bi-preference linkage-driven artificial bee colony algorithm
with multi-operator fusion. <em>CIS</em>, <em>9</em>(6), 6729–6751. (<a
href="https://doi.org/10.1007/s40747-023-01085-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The artificial bee colony algorithm (ABC) struggles in handling complex optimization problems with high dimensions in light of its search operators’ strong exploration and weak exploitation properties. To tackle this situation, in this study, we propose a bi-preference linkage-driven ABC algorithm with multi-operator fusion, named BPLABC. BPLABC couples a preference-free stochastic search operator with a global best-guided search operator in the employed bee phase to maintain the population diversity while enhancing the population quality. During the onlooker bee phase, a tailored bi-type elite-guided exploitation mechanism is employed to regulate the exploitation intensity of the promising elite nectar sources selected via a new roulette selection probability calculation paradigm. To discourage the onlooker bees from slipping into local traps, after the scout bee phase, an auxiliary adversarial search operator is assembled to tug certain promising elite solutions away from the present pseudo-global best solution. To illustrate the effectiveness and efficiency of BPLABC, two sets of test suits consisting of 23 benchmark problems, 30 complex CEC2014 functions, and two real-world problems are picked for testing. Experimental results showed that BPLABC can achieve superior or equivalent performance to several representative ABC variants on the majority of the tested problems.},
  archive      = {J_CIS},
  author       = {Yu, Haibo and Kang, Yaxin and Kang, Li and Zeng, Jianchao},
  doi          = {10.1007/s40747-023-01085-5},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6729-6751},
  shortjournal = {Complex Intell. Syst.},
  title        = {Bi-preference linkage-driven artificial bee colony algorithm with multi-operator fusion},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multifactorial evolutionary algorithm with adaptive transfer
strategy based on decision tree. <em>CIS</em>, <em>9</em>(6), 6697–6728.
(<a href="https://doi.org/10.1007/s40747-023-01105-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multifactorial optimization (MFO) is a kind of optimization problem that has attracted considerable attention in recent years. The multifactorial evolutionary algorithm utilizes the implicit genetic transfer mechanism characterized by knowledge transfer to conduct evolutionary multitasking simultaneously. Therefore, the effectiveness of knowledge transfer significantly affects the performance of the algorithm. To achieve positive knowledge transfer, this paper proposed an evolutionary multitasking optimization algorithm with adaptive transfer strategy based on the decision tree (EMT-ADT). To evaluate the useful knowledge contained in the transferred individuals, this paper defines an evaluation indicator to quantify the transfer ability of each individual. Furthermore, a decision tree is constructed to predict the transfer ability of transferred individuals. Based on the prediction results, promising positive-transferred individuals are selected to transfer knowledge, which can effectively improve the performance of the algorithm. Finally, CEC2017 MFO benchmark problems, WCCI20-MTSO and WCCI20-MaTSO benchmark problems are used to verify the performance of the proposed algorithm EMT-ADT. Experimental results demonstrate the competiveness of EMT-ADT compared with some state-of-the-art algorithms.},
  archive      = {J_CIS},
  author       = {Li, Wei and Gao, Xinyu and Wang, Lei},
  doi          = {10.1007/s40747-023-01105-4},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6697-6728},
  shortjournal = {Complex Intell. Syst.},
  title        = {Multifactorial evolutionary algorithm with adaptive transfer strategy based on decision tree},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Selection of suitable biomass conservation process
techniques: A versatile approach to normal wiggly interval-valued
hesitant fuzzy set using multi-criteria decision making. <em>CIS</em>,
<em>9</em>(6), 6681–6695. (<a
href="https://doi.org/10.1007/s40747-023-01097-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A country that relies on developing industrialization and GDP requires a lot of energy. Biomass is emerging as one of the possible renewable energy resources that may be used to generate energy. Through the proper channels, such as chemical, biochemical, and thermochemical processes, it can be turned into electricity. In the context of India, the potential sources of biomass can be broken down into agricultural waste, tanning waste, sewage, vegetable waste, food, meat waste, and liquor waste. Each form of biomass energy so extracted has advantages and downsides, so determining which one is best is crucial to reaping the most benefits. The selection of biomass conversion methods is especially significant since it requires a careful study of multiple factors, which can be aided by fuzzy multi-criteria decision-making (MCDM) models. This paper proposes the normal wiggly interval-valued hesitant fuzzy-based decision-making trial and evaluation laboratory model (DEMATEL) and the Preference Ranking Organization METHod for Enrichment of Evaluations II (PROMETHEE) for assessing the problem of determining a workable biomass production technique. The proposed framework is used to assess the production processes under consideration based on parameters such as fuel cost, technical cost, environmental safety, and $$CO_2$$ emission levels. Bioethanol has been developed as a viable industrial option due to its low carbon footprint and environmental viability. Furthermore, the superiority of the suggested model is demonstrated by comparing the results to other current methodologies. According to comparative study, the suggested framework might be developed to handle complex scenarios with many variables.},
  archive      = {J_CIS},
  author       = {Narayanamoorthy, Samayan and Ramya, L. and Gunasekaran, Angappa and Kalaiselvan, Samayan and Kang, Daekook},
  doi          = {10.1007/s40747-023-01097-1},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6681-6695},
  shortjournal = {Complex Intell. Syst.},
  title        = {Selection of suitable biomass conservation process techniques: A versatile approach to normal wiggly interval-valued hesitant fuzzy set using multi-criteria decision making},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A biologically inspired decision-making system for the
autonomous adaptive behavior of social robots. <em>CIS</em>,
<em>9</em>(6), 6661–6679. (<a
href="https://doi.org/10.1007/s40747-023-01077-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The decisions made by social robots while they fulfill their tasks have a strong influence on their performance. In these contexts, autonomous social robots must exhibit adaptive and social-based behavior to make appropriate decisions and operate correctly in complex and dynamic scenarios. This paper presents a Decision-Making System for social robots working on long-term interactions like cognitive stimulation or entertainment. The Decision-making System employs the robot’s sensors, user information, and a biologically inspired module to replicate how human behavior emerges in the robot. Besides, the system personalizes the interaction to maintain the users’ engagement while adapting to their features and preferences, overcoming possible interaction limitations. The system evaluation was in terms of usability, performance metrics, and user perceptions. We used the Mini social robot as the device where we integrated the architecture and carried out the experimentation. The usability evaluation consisted of 30 participants interacting with the autonomous robot in 30 min sessions. Then, 19 participants evaluated their perceptions of robot attributes of the Godspeed questionnaire by playing with the robot in 30 min sessions. The participants rated the Decision-making System with excellent usability (81.08 out of 100 points), perceiving the robot as intelligent (4.28 out of 5), animated (4.07 out of 5), and likable (4.16 out of 5). However, they also rated Mini as unsafe (security perceived as 3.15 out of 5), probably because users could not influence the robot’s decisions.},
  archive      = {J_CIS},
  author       = {Maroto-Gómez, Marcos and Castro-González, Álvaro and Malfaz, María and Salichs, Miguel Ángel},
  doi          = {10.1007/s40747-023-01077-5},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6661-6679},
  shortjournal = {Complex Intell. Syst.},
  title        = {A biologically inspired decision-making system for the autonomous adaptive behavior of social robots},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). KPRLN: Deep knowledge preference-aware reinforcement
learning network for recommendation. <em>CIS</em>, <em>9</em>(6),
6645–6659. (<a
href="https://doi.org/10.1007/s40747-023-01083-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User preference information plays an important role in knowledge graph-based recommender systems, which is reflected in users having different preferences for each entity–relation pair in the knowledge graph. Existing approaches have not modeled this fine-grained user preference feature well, as affecting the performance of recommender systems. In this paper, we propose a deep knowledge preference-aware reinforcement learning network (KPRLN) for the recommendation, which builds paths between user’s historical interaction items in the knowledge graph, learns the preference features of each user–entity–relation and generates the weighted knowledge graph with fine-grained preference features. First, we proposed a hierarchical propagation path construction method to address the problems of the pendant entity and long path exploration in the knowledge graph. The method expands outward to form clusters centered on items and uses them to represent the starting and target states in reinforcement learning. With the iteration of clusters, we can better learn the pendant entity preference and explore farther paths. Besides, we design an attention graph convolutional network, which focuses on more influential entity–relation pairs, to aggregate user and item higher order representations that contain fine-grained preference features. Finally, extensive experiments on two real-world datasets demonstrate that our method outperforms other state-of-the-art baselines.},
  archive      = {J_CIS},
  author       = {Wu, Di and Tang, Mingjing and Zhang, Shu and You, Ao and Gao, Wei},
  doi          = {10.1007/s40747-023-01083-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6645-6659},
  shortjournal = {Complex Intell. Syst.},
  title        = {KPRLN: Deep knowledge preference-aware reinforcement learning network for recommendation},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A particle swarm optimization algorithm based on
diversity-driven fusion of opposing phase selection strategies.
<em>CIS</em>, <em>9</em>(6), 6611–6643. (<a
href="https://doi.org/10.1007/s40747-023-01069-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Opposition-based learning (OBL) is often embedded in intelligent optimization algorithms to solve practical engineering and mathematical problems, but the combinatorial problems among different OBL variants are rarely studied. To this end, we propose a novel OBL variant based on the principle of optical imaging, which combines two novel types of quasi-opposite learning and extended opposite learning, called diversity-driven fused opposition learning (SQOBL). First, a density center based on a neighborhood model is proposed. Based on the rapid convergence of the centroid, combined the advantages of density and centroid to construct a double mean center (DMC) to replace the original center point in quasi-opposite learning based on the principle of refraction. Secondly, an extended opposite learning method based on optical refraction imaging is proposed. Diversity is then exploited to drive different opposing learning strategies at different stages of evolution, thus controlling the exploration and utilization of the algorithm. Finally, SQOBL was embedded in the PSO with eight others representative OBL variants to find the most optimal solution for a test suite. In addition, 8 novel intelligent optimization algorithms and the first three algorithms were selected to evaluate the performance of the latest CEC2022 benchmark test set and realistic constrained optimization problems. Experiments with 56 test functions and 3 real-world constraint optimization problems show that the proposed SQOBL has good integrative properties in CEC2015, CEC2017, CEC2020, and CEC2022 test suites.},
  archive      = {J_CIS},
  author       = {Xu, Jiucheng and Xu, Shihui and Zhang, Lei and Zhou, Changshun and Han, Ziqin},
  doi          = {10.1007/s40747-023-01069-5},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6611-6643},
  shortjournal = {Complex Intell. Syst.},
  title        = {A particle swarm optimization algorithm based on diversity-driven fusion of opposing phase selection strategies},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-population cooperative teaching–learning-based
optimization for nonlinear equation systems. <em>CIS</em>,
<em>9</em>(6), 6593–6609. (<a
href="https://doi.org/10.1007/s40747-023-01074-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving nonlinear equation systems (NESs) requires locating different roots in one run. To effectively deal with NESs, a multi-population cooperative teaching–learning-based optimization, named MCTLBO, is presented. The innovations of MCTLBO are as follows: (i) two niching technique (crowding and improved speciation) are integrated into the algorithm to enhance population diversity; (ii) an adaptive selection scheme is proposed to select the learning rules in the teaching phase; (iii) the new learning rules based on experience learning are developed to promote the search efficiency in the teaching and learning phases. MCTLBO was tested on 30 classical problems and the experimental results show that MCTLBO has better root finding performance than other algorithms. In addition, MCTLBO achieves competitive results in eighteen new test sets.},
  archive      = {J_CIS},
  author       = {Zuowen, Liao and Shuijia, Li and Wenyin, Gong and Qiong, Gu},
  doi          = {10.1007/s40747-023-01074-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6593-6609},
  shortjournal = {Complex Intell. Syst.},
  title        = {Multi-population cooperative teaching–learning-based optimization for nonlinear equation systems},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fake news detection based on a hybrid BERT and LightGBM
models. <em>CIS</em>, <em>9</em>(6), 6581–6592. (<a
href="https://doi.org/10.1007/s40747-023-01098-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of social networks and technology, knowing what news to believe and what not to believe become a challenge in this digital era. Fake news is defined as provably erroneous information transmitted intending to defraud. This kind of misinformation poses a serious threat to social cohesion and well-being, since it fosters political polarisation and can destabilize trust in the government or the service provided. As a result, fake news detection has emerged as an important field of study, with the goal of identifying whether a certain piece of content is real or fake. In this paper, we propose a novel hybrid fake news detection system that combines a BERT-based (bidirectional encoder representations from transformers) with a light gradient boosting machine (LightGBM) model. We compare the performance of the proposed method to four different classification approaches using different word embedding techniques on three real-world fake news datasets to validate the performance of the proposed method compared to other methods. The proposed method is evaluated to detect fake news based on the headline-only or full text of the news content. The results show the superiority of the proposed method for fake news detection compared to many state-of-the-art methods.},
  archive      = {J_CIS},
  author       = {Essa, Ehab and Omar, Karima and Alqahtani, Ali},
  doi          = {10.1007/s40747-023-01098-0},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6581-6592},
  shortjournal = {Complex Intell. Syst.},
  title        = {Fake news detection based on a hybrid BERT and LightGBM models},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transferable adversarial masked self-distillation for
unsupervised domain adaptation. <em>CIS</em>, <em>9</em>(6), 6567–6580.
(<a href="https://doi.org/10.1007/s40747-023-01094-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) aims to transfer knowledge from a labeled source domain to a related unlabeled target domain. Most existing works focus on minimizing the domain discrepancy to learn global domain-invariant representation using CNN-based architecture while ignoring both transferable and discriminative local representation, e.g, pixel-level and patch-level representation. In this paper, we propose the Transferable Adversarial Masked Self-distillation based on Vision Transformer architecture to enhance the transferability of UDA, named TAMS. Specifically, TAMS jointly optimizes three objectives to learn both task-specific class-level global representation and domain-specific local representation. First, we introduce adversarial masked self-distillation objective to distill representation from a full image to the representation predicted from a masked image, which aims to learn task-specific global class-level representation. Second, we introduce masked image modeling objectives to learn local pixel-level representation. Third, we introduce an adversarial weighted cross-domain adaptation objective to capture discriminative potentials of patch tokens, which aims to learn both transferable and discriminative domain-specific patch-level representation. Extensive studies on four benchmarks and the experimental results show that our proposed method can achieve remarkable improvements compared to previous state-of-the-art UDA methods.},
  archive      = {J_CIS},
  author       = {Xia, Yuelong and Yun, Li-Jun and Yang, Chengfu},
  doi          = {10.1007/s40747-023-01094-4},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6567-6580},
  shortjournal = {Complex Intell. Syst.},
  title        = {Transferable adversarial masked self-distillation for unsupervised domain adaptation},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Document-level relation extraction based on sememe
knowledge-enhanced abstract meaning representation and reasoning.
<em>CIS</em>, <em>9</em>(6), 6553–6566. (<a
href="https://doi.org/10.1007/s40747-023-01084-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document-level relation extraction is a challenging task in information extraction, as it involves identifying semantic relations between entities that are dispersed throughout a document. Existing graph-based approaches often rely on simplistic methods to construct text graphs, which do not provide enough lexical and semantic information to accurately predict the relations between entity pairs. In this paper, we introduce a document-level relation extraction method called SKAMRR (Sememe Knowledge-enhanced Abstract Meaning Representation and Reasoning). First, we generate document-level abstract meaning representation graphs using rules and acquire entity nodes’ features through sufficient information propagation. Next, we construct inference graphs for entity pairs and utilize graph neural networks to obtain their representations for relation classification. Additionally, we propose the global adaptive loss to address the issue of long-tailed data. We conduct extensive experiments on four datasets DocRE, CDR, GDA, and HacRED. Our model achieves competitive results and its performance outperforms previous state-of-the-art methods on four datasets.},
  archive      = {J_CIS},
  author       = {Zhao, Qihui and Gao, Tianhan and Guo, Nan},
  doi          = {10.1007/s40747-023-01084-6},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6553-6566},
  shortjournal = {Complex Intell. Syst.},
  title        = {Document-level relation extraction based on sememe knowledge-enhanced abstract meaning representation and reasoning},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pseudo-supervised image clustering based on meta-features.
<em>CIS</em>, <em>9</em>(6), 6541–6551. (<a
href="https://doi.org/10.1007/s40747-023-01081-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stable semantics is a prerequisite for achieving excellent image clustering. However, most current methods suffer from inaccurate class semantic estimation, which limits the clustering performance. For the sake of addressing the issue, we propose a pseudo-supervised clustering framework based on meta-features. First, the framework mines meta-semantic features (i.e., meta-features) of image categories based on instance-level features, which not only preserves instance-level information but also ensures the semantic robustness of meta-features. Ulteriorly, we propagate pseudo-labels to its global neighbor samples with meta-features as the center, which effectively avoids the accumulation of errors caused by the misclassification of samples at the cluster boundary. Finally, we exploit the cross-entropy loss with label smoothing to optimize the pseudo-label optimization network. This optimization method not only achieves a direct mapping from features to stable semantic labels, but also effectively avoids suboptimal solutions caused by multi-level optimization. Extensive experiments demonstrate that our method significantly outperforms twenty-one competing clustering methods on six challenging datasets.},
  archive      = {J_CIS},
  author       = {Wang, Hao and Shao, Youjia and Yang, Tongsen and Zhao, Wencang},
  doi          = {10.1007/s40747-023-01081-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6541-6551},
  shortjournal = {Complex Intell. Syst.},
  title        = {Pseudo-supervised image clustering based on meta-features},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient image blur detection via hierarchical edge
guidance and region complementation. <em>CIS</em>, <em>9</em>(6),
6523–6540. (<a
href="https://doi.org/10.1007/s40747-023-01093-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blur detection is aimed to recognize the blurry pixels from a given image, which is increasingly valued in vision-centered applications. Albeit great improvement achieved by recent deep learning-based methods, the overweight model and rough boundary still pose challenges to blur detection. In this paper, we propose a Hierarchical Edge-guided Region-complemented Network (HER-Net) to tackle the above issues in quest of a favorable accuracy–complexity trade-off. First, we propose novel olive-shaped and pear-shaped inverted bottleneck structures based on large-kernel depth-wise convolutions to build a very concise architecture. Second, we provoke and exploit region-concerned and edge-concerned morphological priors to refine the boundary. To this end, we propose a reverse-region spatial attention to mine the complementary affinities between blurry and sharp regions so as to enrich the residual details around the boundary. In addition, we propose an edge spatial attention to guide the edge-concerned cues to emphasize the features related to the boundary. Both attentions are embedded into the model with hierarchical manners. Extensive experiments on three benchmark datasets demonstrate that the proposed method can achieve better detection performance using fewer parameters and lower floating-point operations compared to competitive methods. It proves the efficiency and effectiveness of our method in blur detection task.},
  archive      = {J_CIS},
  author       = {Wang, Xuewei and Liang, Xiao and Li, Shaohua and Zheng, Jinjin},
  doi          = {10.1007/s40747-023-01093-5},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6523-6540},
  shortjournal = {Complex Intell. Syst.},
  title        = {Efficient image blur detection via hierarchical edge guidance and region complementation},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A practical type-3 fuzzy control for mobile robots:
Predictive and boltzmann-based learning. <em>CIS</em>, <em>9</em>(6),
6509–6522. (<a
href="https://doi.org/10.1007/s40747-023-01086-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents an innovative path-following scheme using a new intelligent type-3 fuzzy system for mobile robots. By designing a non-singleton FS and incorporating error measurement signals, this system is able to handle natural disturbances and dynamics uncertainties. To further enhance accuracy, a Boltzmann machine (BM) models tracking errors and predicts compensators. A parallel supervisor is also included in the central controller to ensure robustness. The BM model is trained using contrastive divergence, while adaptive rules extracted from a stability theorem train the NT3FS. Simulation results using chaotic reference signals show that the proposed scheme is accurate and robust, even in the face of unknown dynamics and disturbances. Moreover, a practical implementation on a real-world robot proves the feasibility of the designed controller. To watch a short video of the scheme in action, visit shorturl.at/imoCH.},
  archive      = {J_CIS},
  author       = {Alkabaa, Abdulaziz S. and Taylan, Osman and Balubaid, Muhammed and Zhang, Chunwei and Mohammadzadeh, Ardashir},
  doi          = {10.1007/s40747-023-01086-4},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6509-6522},
  shortjournal = {Complex Intell. Syst.},
  title        = {A practical type-3 fuzzy control for mobile robots: Predictive and boltzmann-based learning},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A domain semantics-enhanced relation extraction model for
identifying the railway safety risk. <em>CIS</em>, <em>9</em>(6),
6493–6507. (<a
href="https://doi.org/10.1007/s40747-023-01075-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of railway safety risk is important in ensuring continuous and stable railway operations. Most works fail to consider the important relation between detected objects. In addition, poor domain semantics directly degrades the final performance due to difficulty in understanding railway text. To solve these challenging issues, we introduce the triple knowledge from knowledge graph to model the railway safety risk with the knowledge interconnection mode. Afterward, we recast the identification of railway safety risk as the relation extraction task, and propose a novel and effective Domain Semantics-Enhanced Relation Extraction (DSERE) model. Specifically, we design a domain semantics-enhanced transformer mechanism that automatically enhances the railway semantics from a dedicated railway lexicon. We further introduce piece-wise convolution neural networks to explore the fine-grained features contained in the structure of triple knowledge. With the domain semantics and fine-grained features, our model can fully understand the domain text and thus improve the performance of relation classification. Finally, the DSERE model is used to identify the railway safety risk of south zone of China Railway, and achieves 81.84% AUC and 76.00% F1 scores on the real-world dataset showing the superiority of our proposed model.},
  archive      = {J_CIS},
  author       = {Wang, Youwei and Zhu, Chengying and Guo, Qiang and Ye, Yangdong},
  doi          = {10.1007/s40747-023-01075-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6493-6507},
  shortjournal = {Complex Intell. Syst.},
  title        = {A domain semantics-enhanced relation extraction model for identifying the railway safety risk},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sleep-wakeup scheduling algorithm for lifespan maximization
of directional sensor networks: A discrete cuckoo search optimization
algorithm. <em>CIS</em>, <em>9</em>(6), 6459–6491. (<a
href="https://doi.org/10.1007/s40747-023-01078-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Directional sensor networks (DSNs) are ad-hoc networks which are utilized in different industrial applications. Their usual engagements are to monitor and to perform the coverage of all specific targets in the observing fields permanently. These kinds of networks include numerous configurable directional sensors in which they can be utilized in one of the possible directions along with the one of their adjustable ranges. Although the energy harvesting methodology is being applied for these battery-hungry applications, the battery management and network lifetime maximization are still prominent challenges. In this paper, the network lifetime extension is formulated to a discrete optimization problem which is a famous non-deterministic polynomial time hardness (NP-Hard) problem. To solve this combinatorial problem, a discrete cuckoo search algorithm (D-CSA) is designed and is called in several rounds. A cover is a sub set of configured sensors capable of monitoring all targets in the observing field. In each round, the most efficient cover is constituted along with its activation time. In the determined activation time, the sensors in the cover are scheduled in wakeup mode whereas others are set in sleep mode to save energy. Despite other meta-heuristic algorithms, this proposed algorithm utilizes the novel defined discrete walking around procedures that makes to reach a good balance between exploration and exploitation in this complex search space. The proposed algorithm has been tested in different scenarios to be evaluated. The simulation results in the variety circumstances prove the superiority of the proposed algorithm is about 20.29%, 19.55%, 14.40%, 14.51%, 7.70% and 8.03% in term of average lifespan improvement against H-MNLAR, Hm-LifMax-BC, GA, ACOSC, H-GATS, and HDPSO algorithms, respectively. The results also show the high potential scalability of the proposed algorithm.},
  archive      = {J_CIS},
  author       = {Mortazavi, Mir Gholamreza and Hosseini Shirvani, Mirsaeid and Dana, Arash and Fathy, Mahmood},
  doi          = {10.1007/s40747-023-01078-4},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6459-6491},
  shortjournal = {Complex Intell. Syst.},
  title        = {Sleep-wakeup scheduling algorithm for lifespan maximization of directional sensor networks: A discrete cuckoo search optimization algorithm},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HRCTNet: A hybrid network with high-resolution
representation for object detection in UAV image. <em>CIS</em>,
<em>9</em>(6), 6437–6457. (<a
href="https://doi.org/10.1007/s40747-023-01076-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in unmanned aerial vehicle (UAV) images has attracted the increasing attention of researchers in recent years. However, it is challenging for small object detection using conventional detection methods because less location and semantic information are extracted from the feature maps of UAV images. To remedy this problem, three new feature extraction modules are proposed in this paper to refine the feature maps for small objects in UAV images. Namely, Small-Kernel-Block (SKBlock), Large-Kernel-Block (LKBlock), and Conv-Trans-Block (CTBlock), respectively. Based on these three modules, a novel backbone called High-Resolution Conv-Trans Network (HRCTNet) is proposed. Additionally, an activation function Acon is deployed in our network to reduce the possibility of dying ReLU and remove redundant features. Based on the characteristics of extreme imbalanced labels in UAV image datasets, a loss function Ployloss is adopted to train HRCTNet. To verify the effectiveness of the proposed HRCTNet, corresponding experiments have been conducted on several datasets. On VisDrone dataset, HRCTNet achieves 49.5% on AP50 and 29.1% on AP, respectively. As on COCO dataset, with limited FLOPs, HRCTNet achieves 37.9% on AP and 24.1% on APS. The experimental results demonstrate that HRCTNet outperforms the existing methods for object detection in UAV images.},
  archive      = {J_CIS},
  author       = {Xing, Wenjie and Cui, Zhenchao and Qi, Jing},
  doi          = {10.1007/s40747-023-01076-6},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6437-6457},
  shortjournal = {Complex Intell. Syst.},
  title        = {HRCTNet: A hybrid network with high-resolution representation for object detection in UAV image},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DMBR-net: Deep multiple-resolution bilateral network for
real-time and accurate semantic segmentation. <em>CIS</em>,
<em>9</em>(6), 6427–6436. (<a
href="https://doi.org/10.1007/s40747-023-01046-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been proved that the two-branch network architecture for real-time semantic segmentation is effectiveness. However, existing methods still can not obtain sufficient context information and sufficient detailed information, which limits the improvement of the accuracy of existed two-branch methods. In this paper, we proposed a real-time high-precision semantic segmentation network based on a novel multi-resolution feature fusion module, an auxiliary feature extracting module, an upsampling module and multi-ASPP(atrous spatial pyramid pooling) module. We designed a feature fusion module, which is integrated with sufficient features of different resolutions to help the network get both sufficient semantic information and sufficient detailed information. We also studied the effect of the side-branch architecture on the network, and made new discoveries that the role of the side-branch is more than regularization, it may either slow down the convergence or accelerate the convergence by influencing the gradient of different layers of the network, which is dependent on the parameters of the network and the input data. Based on the new discoveries about the side-branch architecture, we used a side-branch auxiliary feature extraction layer in the network to improve the performance of the network. We also designed an upsampling module, which can get better detailed information than the original upsampling module. In addition, we also re-considered the locations and number of atrous spatial pyramid pooling (ASPP) modules, and modified the network architecture according to the experimental results to further improve the performance of the network. We proposed a network based on the above study. We named this network Deep Multiple-resolution Bilateral Network for Real-time, referred to as DMBR-Net. The network proposed in the paper achieved 81.3% mIoU(Mean Intersection over Union) at 110FPS on the Cityscapes validation dataset, 80.7% mIoU at 104FPS on the CamVid test dataset, 32.2% mIoU at 78FPS on the COCO-Stuff test dataset.},
  archive      = {J_CIS},
  author       = {Meng, Pengfei and Jia, Shuangcheng and Li, Qian},
  doi          = {10.1007/s40747-023-01046-y},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6427-6436},
  shortjournal = {Complex Intell. Syst.},
  title        = {DMBR-net: Deep multiple-resolution bilateral network for real-time and accurate semantic segmentation},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A dynamic multi-attribute group decision-making method with
r-numbers based on MEREC and CoCoSo method. <em>CIS</em>, <em>9</em>(6),
6393–6426. (<a
href="https://doi.org/10.1007/s40747-023-01032-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multi-attribute group decision-making (DMAGDM) is a widespread practice in which evaluations are provided by multiple decision-makers at various times and early evaluations impact later evaluations. Additionally, attributes and alternatives can be added or removed over time. An R-numbers DMAGDM method is developed based on the advantages of R-numbers in capturing risks. This paper introduces the R-numbers Einstein weighted averaging (RNEWA) operator and R-numbers weighted Einstein geometric (RNEWG) operator, which are distinct from conventional algebraic operations, and examines their properties. Moreover, an expert weight determination model is constructed using the similarity measure of R-numbers. The attribute weight determination model in the R-numbers environment is also proposed with the method based on the criteria removal effects method (MEREC). A static rating calculation model, which utilizes the combination compromise solution (CoCoSo) method in the R-numbers environment, is built using the RNEWA operator and RNEWG operator. Furthermore, a new dynamic rating calculation model is proposed which does not require storage of all decision information over time. Finally, the applicability and effectiveness of the R-numbers DMAGDM method is demonstrated through a case study on supply chain risk assessment of manufacturing enterprises.},
  archive      = {J_CIS},
  author       = {Cheng, Rui and Fan, Jianping and Wu, Meiqin},
  doi          = {10.1007/s40747-023-01032-4},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6393-6426},
  shortjournal = {Complex Intell. Syst.},
  title        = {A dynamic multi-attribute group decision-making method with R-numbers based on MEREC and CoCoSo method},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantum algorithms: Applications, criteria and metrics.
<em>CIS</em>, <em>9</em>(6), 6373–6392. (<a
href="https://doi.org/10.1007/s40747-023-01073-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of data processing and IoT communication it is possible to develop more robust solutions by combining quantum algorithms with metaheuristics. Said solutions can be applied in the industry and be measured using metrics associated with complexity, efficiency, processing, and accuracy. An extensive bibliographical review is carried out to determine which is the most efficient and effective hybrid algorithm that can be applied to a real experimental case, which aims to improve communication to reduce occupational risks. Criteria, metrics, and experimental results were obtained, in which it is shown that the quantum genetic algorithm is better than the genetic algorithm. A detailed discussion on the objective function, the convergence to the global optimum, and the need to improve the obtained solutions is given. The conclusions raise new aspects that need investigation.},
  archive      = {J_CIS},
  author       = {Durán, Claudia and Carrasco, Raúl and Soto, Ismael and Galeas, Ignacio and Azócar, José and Peña, Victoria and Lara-Salazar, Sebastián and Gutierrez, Sebastián},
  doi          = {10.1007/s40747-023-01073-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6373-6392},
  shortjournal = {Complex Intell. Syst.},
  title        = {Quantum algorithms: Applications, criteria and metrics},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A spatial–spectral adaptive learning model for textile
defect images recognition with few labeled data. <em>CIS</em>,
<em>9</em>(6), 6359–6371. (<a
href="https://doi.org/10.1007/s40747-023-01070-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Textile defect recognition is a significant technique in the production processes of the textile industry. However, in the practical processes, it is hard to acquire large amounts of textile defect samples. Meanwhile, the textile samples with correct defect labels are rare. To address these two limitations, in this paper, we propose a novel semi-supervised graph convolutional network for few labeled textile defect recognition. First, we construct the graph convolutional network and convolution neural network to extract spectral features and spatial features. Second, the adaptive convolution structure is proposed to generate adaptive kernels according to their dynamically learned features. Finally, the spatial–spectral adaptive unified learning network (SSA-ULNet) is built for limited labeled defective samples, and graph-based semi-supervised learning is constructed. The textile defect recognition model can extract the textile image features through the image descriptors, enabling the whole network to be end-to-end trainable. To evaluate the proposed method, one public dataset and two unique self-built textile defect datasets are used to textile defect recognition. The evaluation results demonstrate that the proposed SSA-ULNet obviously outperforms existing state-of-the-art deep learning methods.},
  archive      = {J_CIS},
  author       = {Zhang, Yuan and Han, Tao and Wei, Bing and Hao, Kuangrong and Gao, Lei},
  doi          = {10.1007/s40747-023-01070-y},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6359-6371},
  shortjournal = {Complex Intell. Syst.},
  title        = {A spatial–spectral adaptive learning model for textile defect images recognition with few labeled data},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Salient object detection for RGBD video via spatial
interaction and depth-based boundary refinement. <em>CIS</em>,
<em>9</em>(6), 6343–6358. (<a
href="https://doi.org/10.1007/s40747-023-01072-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently proposed state-of-the-art saliency detection models rely heavily on labeled datasets and rarely focus on perfect RGBD feature fusion, which lowers their generalization ability. In this paper, we propose a depth-based interaction and refinement network (DIR-Net) to fully leverage the depth information provided with RGB images to generate and refine the corresponding saliency segmentation maps. In total, three modules are included in our framework. A depth-based refinement module (DRM) and an RGB module work in parallel while coordinating via interactive spatial guidance modules (ISGMs), which utilize spatial and channel attention computed from both depth features and RGB features. In each layer, the features in both modules are refined and guided by the spatial information obtained from the other module through ISGMs. In the RGB module, before sending the depth-guided feature map to the decoder, a convolutional gated recurrent unit (ConvGRU)-based block is introduced to handle temporal information. Thinking about the clear movement information in RGB features, the block also guides temporal information in DRM. By merging the results from both the DRM and RGB modules, a segmentation map with distinct boundaries is generated. Considering the lack of depth images in popular public datasets, we utilize a depth estimation network that incorporates manual postprocessing-based correction to generate depth images on the DAVIS and UVSD datasets. The state-of-the-art performance achieved on both the original and new datasets illustrates the advantage of our RGBD feature fusion strategy, with a real-time speed of 19 fps on a single GPU.},
  archive      = {J_CIS},
  author       = {Zhang, Yujian and Zhang, Ziyan and Zhang, Ping and Xu, Mengnan},
  doi          = {10.1007/s40747-023-01072-w},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6343-6358},
  shortjournal = {Complex Intell. Syst.},
  title        = {Salient object detection for RGBD video via spatial interaction and depth-based boundary refinement},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new weighted extreme learning machine based on elastic net
regularization embedded exponential regularized discriminative
dictionary learning for image classification. <em>CIS</em>,
<em>9</em>(6), 6329–6342. (<a
href="https://doi.org/10.1007/s40747-023-01065-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well known that discriminative sparse representation can significantly improve the performance of image classification. However, there remain several tricky issues to be addressed due to the unsatisfied performance and high time consumption. In this paper, a novel classification framework called weighted extreme learning machine exponential regularized discriminative dictionary learning (WELM-ERDDL) is proposed to address these issues. The main contributions of this paper include (1) the WELM is embedded with ERDDL via exponential regularized linear discriminative analysis (ERLDA) for feature mappings while enabling nonlinear and diverse feature representation; (2) in the ELM learning process, the elastic net regularization is utilized to optimize more robust and meaningful output weights; (3) an effective weight update rule is designed for WELM. To verify the effectiveness of the proposed method, several experiments are conducted on real-world image classification databases. The results show that the proposed WELM-ERDDL framework is even more efficient than other state-of-the-art algorithms in general.},
  archive      = {J_CIS},
  author       = {Wu, Di and Zhao, PinYi and Wan, Qin},
  doi          = {10.1007/s40747-023-01065-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6329-6342},
  shortjournal = {Complex Intell. Syst.},
  title        = {A new weighted extreme learning machine based on elastic net regularization embedded exponential regularized discriminative dictionary learning for image classification},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attention-based spatial–temporal multi-graph convolutional
networks for casualty prediction of terrorist attacks. <em>CIS</em>,
<em>9</em>(6), 6307–6328. (<a
href="https://doi.org/10.1007/s40747-023-01037-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, terrorism has become an important factor affecting world peace and development. As the time series data of terrorist attacks usually show a high degree of spatial–temporal correlation, the spatial–temporal prediction of casualties in terrorist attacks is still a significant challenge in the field of counter-terrorism. Most of the existing terrorist attack prediction methods lack the ability to model the spatial–temporal dynamic correlation of the time series data of terrorist attacks, so they cannot yield satisfactory prediction results. In this paper, we propose a novel Attention-based spatial–temporal multi-graph convolutional network (AST-MGCN) for casualty prediction of terrorist attacks. Specifically, we construct the spatial adjacency graph and spatial diffusion graph based on the different social-spatial dynamic relationships of terrorist attacks and determine the multi-scale period of time series data of terrorist attacks by using wavelet transform to model the temporal trend, period and closeness properties of terrorist attacks. The AST-MGCN mainly consists of spatial multi-graph convolution for extracting social-spatial features in multi-views and temporal convolution for capturing the transition rules. In addition, we also use the spatial–temporal attention mechanism to effectively capture the most relevant spatial–temporal dynamic information. Experiments on public datasets demonstrate that the proposed model outperforms the state-of-the-art baselines.},
  archive      = {J_CIS},
  author       = {Hou, Zhiwen and Zhou, Yuchen and Wu, Xiaowei and Bu, Fanliang},
  doi          = {10.1007/s40747-023-01037-z},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6307-6328},
  shortjournal = {Complex Intell. Syst.},
  title        = {Attention-based spatial–temporal multi-graph convolutional networks for casualty prediction of terrorist attacks},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generator pyramid for high-resolution image inpainting.
<em>CIS</em>, <em>9</em>(6), 6297–6306. (<a
href="https://doi.org/10.1007/s40747-023-01080-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inpainting high-resolution images with large holes challenges existing deep learning-based image inpainting methods. We present a novel framework—PyramidFill for high-resolution image inpainting, which explicitly disentangles the task into two sub-tasks: content completion and texture synthesis. PyramidFill attempts to complete the content of unknown regions in a lower-resolution image, and synthesize the textures of unknown regions in a higher-resolution image, progressively. Thus, our model consists of a pyramid of fully convolutional GANs, wherein the content GAN is responsible for completing contents in the lowest-resolution masked image, and each texture GAN is responsible for synthesizing textures in a higher-resolution image. Since completing contents and synthesizing textures demand different abilities from generators, we customize different architectures for the content GAN and texture GAN. Experiments on multiple datasets including CelebA-HQ, Places2 and a new natural scenery dataset (NSHQ) with different resolutions demonstrate that PyramidFill generates higher-quality inpainting results than the state-of-the-art methods.},
  archive      = {J_CIS},
  author       = {Cao, Leilei and Yang, Tong and Wang, Yixu and Yan, Bo and Guo, Yandong},
  doi          = {10.1007/s40747-023-01080-w},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6297-6306},
  shortjournal = {Complex Intell. Syst.},
  title        = {Generator pyramid for high-resolution image inpainting},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards computational awareness in autonomous robots: An
empirical study of computational kernels. <em>CIS</em>, <em>9</em>(6),
6269–6295. (<a
href="https://doi.org/10.1007/s40747-023-01059-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The potential impact of autonomous robots on everyday life is evident in emerging applications such as precision agriculture, search and rescue, and infrastructure inspection. However, such applications necessitate operation in unknown and unstructured environments with a broad and sophisticated set of objectives, all under strict computation and power limitations. We therefore argue that the computational kernels enabling robotic autonomy must be scheduled and optimized to guarantee timely and correct behavior, while allowing for reconfiguration of scheduling parameters at runtime. In this paper, we consider a necessary first step towards this goal of computational awareness in autonomous robots: an empirical study of a base set of computational kernels from the resource management perspective. Specifically, we conduct a data-driven study of the timing, power, and memory performance of kernels for localization and mapping, path planning, task allocation, depth estimation, and optical flow, across three embedded computing platforms. We profile and analyze these kernels to provide insight into scheduling and dynamic resource management for computation-aware autonomous robots. Notably, our results show that there is a correlation of kernel performance with a robot’s operational environment, justifying the notion of computation-aware robots and why our work is a crucial step towards this goal.},
  archive      = {J_CIS},
  author       = {Sifat, Ashrarul H. and Bharmal, Burhanuddin and Zeng, Haibo and Huang, Jia-Bin and Jung, Changhee and Williams, Ryan K.},
  doi          = {10.1007/s40747-023-01059-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6269-6295},
  shortjournal = {Complex Intell. Syst.},
  title        = {Towards computational awareness in autonomous robots: An empirical study of computational kernels},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Linear local tangent space alignment with autoencoder.
<em>CIS</em>, <em>9</em>(6), 6255–6268. (<a
href="https://doi.org/10.1007/s40747-023-01055-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear local tangent space alignment (LLTSA) is a classical dimensionality reduction method based on manifold. However, LLTSA and all its variants only consider the one-way mapping from high-dimensional space to low-dimensional space. The projected low-dimensional data may not accurately and effectively “represent” the original samples. This paper proposes a novel LLTSA method based on the linear autoencoder called LLTSA-AE (LLTSA with Autoencoder). The proposed LLTSA-AE is divided into two stages. The conventional process of LLTSA is viewed as the encoding stage, and the additional and important decoding stage is used to reconstruct the original data. Thus, LLTSA-AE makes the low-dimensional embedding data “represent” the original data more accurately and effectively. LLTSA-AE gets the recognition rates of 85.10, 67.45, 75.40 and 86.67% on handwritten Alphadigits, FERET, Georgia Tech. and Yale datasets, which are 9.4, 14.03, 7.35 and 12.39% higher than that of the original LLTSA respectively. Compared with some improved methods of LLTSA, it also obtains better performance. For example, on Handwritten Alphadigits dataset, compared with ALLTSA, OLLTSA, PLLTSA and WLLTSA, the recognition rates of LLTSA-AE are improved by 4.77, 3.96, 7.8 and 8.6% respectively. It shows that LLTSA-AE is an effective dimensionality reduction method.},
  archive      = {J_CIS},
  author       = {Ran, Ruisheng and Wang, Jinping and Fang, Bin},
  doi          = {10.1007/s40747-023-01055-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6255-6268},
  shortjournal = {Complex Intell. Syst.},
  title        = {Linear local tangent space alignment with autoencoder},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weight normalization optimization movie recommendation
algorithm based on three-way neural interaction networks. <em>CIS</em>,
<em>9</em>(6), 6241–6254. (<a
href="https://doi.org/10.1007/s40747-023-01066-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous information networks are increasingly used in recommendation algorithms. However, they lack an explicit representation of meta-paths. In using bidirectional neural interaction models for recommendation models, interaction between users and items is often ignored, with an integral impact on the accuracy of the recommendations. To better apply the interaction information, this study proposes a weight-normalized movie recommendation model (SCLW_MCRec) based on a three-way neural interaction network. The model constructs a three-way neural interaction network $$\langle $$ user, meta-path, item $$\rangle $$ from meta-path contextual information, introducing meta-paths on top of the user-item representation to represent the user-item interaction information. Introduction of a two-layer, one-dimensional convolutional neural network helps capture higher-order interaction features between the user and the item, making the model more powerful in terms of interaction. Adding a dropout layer to the interaction model and using a two-layer convolutional neural network can prevent overfitting and discard irrelevant information features to improve the recommendation. In addition, an extreme cross-entropy loss (argmaxminloss) that incorporates the properties of the argmin and argmax functions is designed to reduce the model loss. A weight-normalization optimization approach is used to better optimize the model and accelerate convergence of the stochastic gradient descent optimization. Compared to current state-of-the-art recommendation models, the SCLW_MCRec model improves the Prec evaluation index by 2.94–35.8%, Recall by 1.15–53.51%, and NDCG by 6.7–49.37% on the MovieLens dataset. The framework provides a significant improvement in recommendation accuracy and also solves the cold-start problem with application of interaction information.},
  archive      = {J_CIS},
  author       = {Liang, Zhenlu and Yang, Zhisheng and Cheng, Jingyong},
  doi          = {10.1007/s40747-023-01066-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6241-6254},
  shortjournal = {Complex Intell. Syst.},
  title        = {Weight normalization optimization movie recommendation algorithm based on three-way neural interaction networks},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Common-weights fuzzy DEA model in the presence of
undesirable outputs with ideal and anti-ideal points: Development and
prospects. <em>CIS</em>, <em>9</em>(6), 6223–6240. (<a
href="https://doi.org/10.1007/s40747-023-01030-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the literature, fuzzy arithmetic approach has been used for solving fuzzy data envelopment analysis (DEA) model in the presence of undesirable outputs by use of ideal and anti-ideal decision-making units (DMUs). In order to obtain the best and the worst fuzzy efficiencies, such an approach allows each DMU to choose the most favorable weights via optimizing its own evaluation that needs to solve various mathematical models. On the one hand, solving one mathematical model to find the best fuzzy efficiency and solving another mathematical model to find the worst fuzzy efficiency for each DMU increase the computational complexity significantly. On the other hand, the fully flexibility of weights leads to the different set of weights that may not be desirable. This paper proposes a common-weight method from two optimistic and pessimistic perspectives in fuzzy environment to determine the common sets of weights (CWS) to compute the best and the worst fuzzy efficiencies of all DMUs. The advantages of using common-weight DEA method based upon fuzzy arithmetic approach are reduction of the computational complexities and evaluation of equitably the best and the worst fuzzy efficiencies on the same base. The proposed approach first solves one linear programming model to compute each of the best and the worst fuzzy efficiencies of all DMUS, and then combines them to find a relative closeness index for the overall assessment. The developed approach is illustrated by a numerical example form the literature and the obtained results are compared with those from the existing ones.},
  archive      = {J_CIS},
  author       = {Majdi, Meysam and Ebrahimnejad, Ali and Azizi, Amir},
  doi          = {10.1007/s40747-023-01030-6},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6223-6240},
  shortjournal = {Complex Intell. Syst.},
  title        = {Common-weights fuzzy DEA model in the presence of undesirable outputs with ideal and anti-ideal points: Development and prospects},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic role discovery and assignment in multi-agent task
decomposition. <em>CIS</em>, <em>9</em>(6), 6211–6222. (<a
href="https://doi.org/10.1007/s40747-023-01071-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective multi-agent teamwork can be facilitated by using personas to decompose goals into lower-level team subtasks through a shared understanding of multi-agent tasks. However, traditional methods for role discovery and assignment are not scalable and fail to adapt to dynamic changes in the environment. To solve this problem, we propose a new framework for learning dynamic role discovery and assignment. We first introduce an action encoder to construct a vector representation for each action based on its characteristics, and define and classify roles from a more comprehensive perspective based on both action differences and action contributions. To rationally assign roles to agents, we propose a representation-based role selection policy based on consideration of role differences and reward horizons, which enables agents to play roles dynamically by dynamically assigning agents with similar abilities to play the same role. Agents playing the same role share their learning of the role, and different roles correspond to different action spaces. We also introduce regularizers to increase the differences between roles and stabilize training by preventing agents from changing roles frequently. Role selection and role policy integrate action representations and role differences in a restricted action space, improving learning efficiency. We conducted experiments in the SMAC benchmark and showed that our method enables effective role discovery and assignment, outperforming the baseline on four of the six scenarios, with an average improvement in win rate of 20 $$\%$$ , and is effective in hard and super hard maps. We also conduct ablation experiments to demonstrate the importance of each component in our approach.},
  archive      = {J_CIS},
  author       = {Xia, Yu and Zhu, Junwu and Zhu, Liucun},
  doi          = {10.1007/s40747-023-01071-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6211-6222},
  shortjournal = {Complex Intell. Syst.},
  title        = {Dynamic role discovery and assignment in multi-agent task decomposition},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing context representations with part-of-speech
information and neighboring signals for question classification.
<em>CIS</em>, <em>9</em>(6), 6191–6209. (<a
href="https://doi.org/10.1007/s40747-023-01067-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Question classification is an essential task in question answering (QA) systems. An effective and efficient question classification model can not only restrict the search space for answers, but also guide the QA system in selecting the optimal knowledge base and search strategy. In recent years, self-attention mechanism has been widely used in question classification for its strength of capturing global dependencies. However, it models all signals with weighted averaging, which is prone to overlooking the relation of neighboring signals. Furthermore, recent research has revealed that part-of-speech (POS) information can be used to determine and reinforce the semantics in sentence representation. In this paper, we propose a POS-aware adjacent relation attention network (POS-ARAN) for question classification, which enhance context representations with POS information and neighboring signals. To consider the local context, we propose an adjacent relation attention mechanism, which incorporates a Gaussian bias via a dynamic window to revise the vanilla self-attention mechanism. Thus, it can capture both the long-term dependency and local representation of semantic relations among words in different sentences. In addition, a POS-aware embedding layer is proposed, which helps to locate the appropriate headwords by syntactic information. Extensive experiments are conducted on Experimental Data for Question Classification (EDQC) dataset and Yahoo! Answers Comprehensive Questions and Answers 1.0, the results demonstrate that our model significantly outperforms the existing methods, achieving 95.59% in coarse-grained level accuracy and 92.91% in fine-grained level accuracy, respectively.},
  archive      = {J_CIS},
  author       = {Gong, Peizhu and Liu, Jin and Xie, Yurong and Liu, Minjie and Zhang, Xiliang},
  doi          = {10.1007/s40747-023-01067-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6191-6209},
  shortjournal = {Complex Intell. Syst.},
  title        = {Enhancing context representations with part-of-speech information and neighboring signals for question classification},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Compact interactive dual-branch network for real-time
semantic segmentation. <em>CIS</em>, <em>9</em>(6), 6177–6190. (<a
href="https://doi.org/10.1007/s40747-023-01063-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional complete dual-branch structure is effective for semantic segmentation tasks. However, it is redundant in some sense. Moreover, the simple additive fusion of the features from the two branches may not achieve the satisfactory performance. To alleviate these two problems, in this paper we propose an efficient compact interactive dual-branch network (CIDNet) for real-time semantic segmentation. Specifically, we first build a compact interactive dual-branch structure by constructing a compact detail branch and a semantic branch. Furthermore, we build a detail-semantic interactive module to fuse several specific stages of the two branches in the backbone network with the corresponding stages of the detail resolution branch. Finally, we propose a dual-branch contextual attention fusion module to deeply fuse the extracted features and predict the final segmentation result. Extensive experiments on Cityscapes and CamVid dataset demonstrate that the proposed CIDNet achieve satisfactory trade-off between segmentation accuracy and inference speed, and outperforms 20 representative real-time semantic segmentation methods.},
  archive      = {J_CIS},
  author       = {Dong, Yongsheng and Yang, Haotian and Pei, Yuanhua and Shen, Longchao and Zheng, Lintao and Li, Peiluan},
  doi          = {10.1007/s40747-023-01063-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6177-6190},
  shortjournal = {Complex Intell. Syst.},
  title        = {Compact interactive dual-branch network for real-time semantic segmentation},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Blockchain-based decentralized trust management in IoT:
Systems, requirements and challenges. <em>CIS</em>, <em>9</em>(6),
6155–6176. (<a
href="https://doi.org/10.1007/s40747-023-01058-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) vision has astoundingly transcended environmental sensing with integrated computing systems and smart devices, providing seamless connectivity among humans, machines, and their environment to cooperate for convenience and economical benefits. Apart from all the tremendous benefits of IoT, this paradigm still suffers from challenges of security and privacy vulnerabilities and demands a secure system for effective utilization of services in real-world IoT scenarios relying on which the IoT consumers expect secure and trustworthy communications. Trust Management (TM), which is a crucial aspect of security, plays a vital role in ensuring the exchange of information in a secure manner and maintaining the reliability of a system by measuring the degree of trust on IoT devices, reducing the uncertainties and risks involved in the systems. Thus, in recent years, Blockchain technology has been utilized for developing security innovations in TM field for different classes of IoT applications. It can provide tamper-proof data by enabling more reliable trust information and integrity verification, ultimately enhancing its availability and privacy when storing and sharing information. This paper provides a comprehensive survey that aims at analyzing and assessing Blockchain-based decentralized trust management systems (BCDTMS) for IoT. The contributions of this study are threefold; first, we provide the comprehensive and comparative analysis of state-of-the-art BCDTMS devised for different IoT classes such as Internet of Medical of Things (IoMT), Internet of Vehicles (IoV), Industrial IoT (IIoT), and Social IoT (SIoT). To make it an extensive study, we perform a detailed assessment of the existing BCDTMS in the literature in the aspects of Blockchain and TM. Second, we present requirements for developing Blockchain-based TM systems for IoT, and third we have highlighted the challenges in the context of using Blockchain for TM in various IoT applications.},
  archive      = {J_CIS},
  author       = {Arshad, Qurat-ul-Ain and Khan, Wazir Zada and Azam, Faisal and Khan, Muhammad Khurram and Yu, Heejung and Zikria, Yousaf Bin},
  doi          = {10.1007/s40747-023-01058-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6155-6176},
  shortjournal = {Complex Intell. Syst.},
  title        = {Blockchain-based decentralized trust management in IoT: Systems, requirements and challenges},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature selection using non-dominant features-guided search
for gene expression profile data. <em>CIS</em>, <em>9</em>(6),
6139–6153. (<a
href="https://doi.org/10.1007/s40747-023-01039-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gene expression profile data have high-dimensionality with a small number of samples. These data characteristics lead to a long training time and low performance in predictive model construction. To address this issue, the paper proposes a feature selection algorithm using non-dominant feature-guide search. The algorithm adopts a filtering framework based on feature sorting and search strategy to overcome the problems of long training time and poor performance. First, the feature pre-selection is completed according to the calculated feature category correlation. Second, a multi-objective optimization feature selection model is constructed. Non-dominant features are defined according to the Pareto dominance theory. Combined with the bidirectional search strategy, the Pareto dominance features under the current category maximum relevance feature are removed one by one. Finally, the optimal feature subset with maximum correlation and minimum redundancy is obtained. Experimental results on six gene expression data sets show that the algorithm is much better than Fisher score, maximum information coefficient, composition of feature relevancy, mini-batch K-means normalized mutual information feature inclusion, and max-Relevance and Min-Redundancy algorithms. Compared to feature selection method based on maximum information coefficient and approximate Markov blanket, the algorithm not only has high computational efficiency but also can obtain better classification capabilities in a smaller dimension.},
  archive      = {J_CIS},
  author       = {Pan, Xiaoying and Sun, Jun and Yu, Huimin and Xue, Yufeng},
  doi          = {10.1007/s40747-023-01039-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6139-6153},
  shortjournal = {Complex Intell. Syst.},
  title        = {Feature selection using non-dominant features-guided search for gene expression profile data},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tiny adversarial multi-objective one-shot neural
architecture search. <em>CIS</em>, <em>9</em>(6), 6117–6138. (<a
href="https://doi.org/10.1007/s40747-023-01139-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widely employed tiny neural networks (TNNs) in mobile devices are vulnerable to adversarial attacks. However, more advanced research on the robustness of TNNs is highly in demand. This work focuses on improving the robustness of TNNs without sacrificing the model’s accuracy. To find the optimal trade-off networks in terms of the adversarial accuracy, clean accuracy, and model size, we present TAM-NAS, a tiny adversarial multi-objective one-shot network architecture search method. First, we build a novel search space comprised of new tiny blocks and channels to establish a balance between the model size and adversarial performance. Then, we demonstrate how the supernet facilitates the acquisition of the optimal subnet under white-box adversarial attacks, provided that the supernet significantly impacts the subnet’s performance. Concretely, we investigate a new adversarial training paradigm by evaluating the adversarial transferability, the width of the supernet, and the distinction between training subnets from scratch and fine-tuning. Finally, we undertake statistical analysis for the layer-wise combination of specific blocks and channels on the first non-dominated front, which can be utilized as a design guideline for the design of TNNs.},
  archive      = {J_CIS},
  author       = {Xie, Guoyang and Wang, Jinbao and Yu, Guo and Lyu, Jiayi and Zheng, Feng and Jin, Yaochu},
  doi          = {10.1007/s40747-023-01139-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6117-6138},
  shortjournal = {Complex Intell. Syst.},
  title        = {Tiny adversarial multi-objective one-shot neural architecture search},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Anti-noise twin-hyperspheres with density fuzzy for binary
classification to imbalanced data with noise. <em>CIS</em>,
<em>9</em>(6), 6103–6116. (<a
href="https://doi.org/10.1007/s40747-023-01089-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents twin-hyperspheres of resisting noise for binary classification to imbalanced data with noise. First, employing the decision of evaluating the contributions created by points for the training of the hyperspheres, then the label density estimator is introduced into the fuzzy membership to quantize the provided contributions, and finally, unknown points can be assigned into corresponding classes. Utilizing the decision, the interference created by the noise hidden in the data is suppressed. Experiment results show that when noise ratio reaches 90%, classification accuracies of the model are 0.802, 0.611 on the synthetic datasets and UCI datasets containing Gaussian noise, respectively. Classification results of the model outperform these of the competitors, and these boundaries learned by the model to separate noise from majority classes and minority classes are superior to these learned by the competitors. Moreover, efforts gained by the proposed density fuzzy are effectiveness in noise resistance; meanwhile, the density fuzzy does not rely on specific classifiers or specific scenarios.},
  archive      = {J_CIS},
  author       = {Zheng, Jian},
  doi          = {10.1007/s40747-023-01089-1},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6103-6116},
  shortjournal = {Complex Intell. Syst.},
  title        = {Anti-noise twin-hyperspheres with density fuzzy for binary classification to imbalanced data with noise},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fuzzy TOPSIS-based privacy measurement in multiple online
social networks. <em>CIS</em>, <em>9</em>(6), 6089–6101. (<a
href="https://doi.org/10.1007/s40747-023-00991-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information leakage has become an urgent problem in multiple Online Social Networks (OSNs). The interactive communication of users has raised several privacy concerns. However, the current related work on privacy measurement only considers the privacy disclosure of user profile settings, ignoring the importance of profile attributes. To solve the efficient measurement problem, we consider the influence of attribute weight on privacy disclosure scores and propose a privacy measurement method by quantifying users’ privacy disclosure scores in social networks. Through introducing Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS), we propose a Privacy Scores calculation model based on Fuzzy TOPSIS decision method (PSFT), that is more accurate calculate users’ privacy disclosure scores and that can improve users’ privacy awareness in multiple OSNs. Users can reasonably set the attribute file configuration based on privacy scores and attribute weight. We conduct extensive experiments on synthetic data set and real data set. The results of the experiments demonstrate the effectiveness of our model.},
  archive      = {J_CIS},
  author       = {Guo, Lijun and Yao, Zhiqiang and Lin, Mingwei and Xu, Zeshui},
  doi          = {10.1007/s40747-023-00991-y},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {12},
  number       = {6},
  pages        = {6089-6101},
  shortjournal = {Complex Intell. Syst.},
  title        = {Fuzzy TOPSIS-based privacy measurement in multiple online social networks},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A distribution information sharing federated learning
approach for medical image data. <em>CIS</em>, <em>9</em>(5), 5625–5636.
(<a href="https://doi.org/10.1007/s40747-023-01035-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, federated learning has been believed to play a considerable role in cross-silo scenarios (e.g., medical institutions) due to its privacy-preserving properties. However, the non-IID problem in federated learning between medical institutions is common, which degrades the performance of traditional federated learning algorithms. To overcome the performance degradation problem, a novelty distribution information sharing federated learning approach (FedDIS) to medical image classification is proposed that reduce non-IIDness across clients by generating data locally at each client with shared medical image data distribution from others while protecting patient privacy. First, a variational autoencoder (VAE) is federally trained, of which the encoder is uesd to map the local original medical images into a hidden space, and the distribution information of the mapped data in the hidden space is estimated and then shared among the clients. Second, the clients augment a new set of image data based on the received distribution information with the decoder of VAE. Finally, the clients use the local dataset along with the augmented dataset to train the final classification model in a federated learning manner. Experiments on the diagnosis task of Alzheimer’s disease MRI dataset and the MNIST data classification task show that the proposed method can significantly improve the performance of federated learning under non-IID cases.},
  archive      = {J_CIS},
  author       = {Zhao, Leiyang and Huang, Jianjun},
  doi          = {10.1007/s40747-023-01035-1},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5625-5636},
  shortjournal = {Complex Intell. Syst.},
  title        = {A distribution information sharing federated learning approach for medical image data},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differentiable channel pruning guided via attention
mechanism: A novel neural network pruning approach. <em>CIS</em>,
<em>9</em>(5), 5611–5624. (<a
href="https://doi.org/10.1007/s40747-023-01022-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural network pruning offers great prospects for facilitating the deployment of deep neural networks on computational resource limited devices. Neural architecture search (NAS) provides an efficient way to automatically seek appropriate neural architecture design for compressed model. It is observed that, for existing NAS-based pruning methods, there is usually a lack of layer information when searching the optimal neural architecture. In this paper, we propose a new NAS approach, namely, differentiable channel pruning method guided via attention mechanism (DCP-A), where the adopted attention mechanism is able to provide layer information to guide the optimization of the pruning policy. The training process is differentiable with Gumbel-softmax sampling, while parameters are optimized under a two-stage training procedure. The neural network block with the shortcut is dedicatedly designed, which is of help to prune the network not only on its width but also on its depth. Extensive experiments are performed to verify the applicability and superiority of the proposed method. Detailed analysis with visualization of the pruned model architecture shows that our proposed DCP-A learns explainable pruning policies.},
  archive      = {J_CIS},
  author       = {Cheng, Hanjing and Wang, Zidong and Ma, Lifeng and Wei, Zhihui and Alsaadi, Fawaz E. and Liu, Xiaohui},
  doi          = {10.1007/s40747-023-01022-6},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5611-5624},
  shortjournal = {Complex Intell. Syst.},
  title        = {Differentiable channel pruning guided via attention mechanism: A novel neural network pruning approach},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reinforcement-learning-based parameter adaptation method for
particle swarm optimization. <em>CIS</em>, <em>9</em>(5), 5585–5609. (<a
href="https://doi.org/10.1007/s40747-023-01012-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle swarm optimization (PSO) is a well-known optimization algorithm that shows good performances in solving different optimization problems. However, the PSO usually suffers from slow convergence. In this article, a reinforcement-learning-based parameter adaptation method (RLAM) is developed to enhance the PSO convergence by designing a network to control the coefficients of the PSO. Moreover, based on the RLAM, a new reinforcement-learning-based PSO (RLPSO) algorithm is designed. To investigate the performance of the RLAM and RLPSO, experiments on 28 CEC 2013 benchmark functions were carried out to compare with other adaptation methods and PSO variants. The reported computational results showed that the proposed RLAM is efficient and effective and that the proposed RLPSO is superior to several state-of-the-art PSO variants.},
  archive      = {J_CIS},
  author       = {Yin, Shiyuan and Jin, Min and Lu, Huaxiang and Gong, Guoliang and Mao, Wenyu and Chen, Gang and Li, Wenchang},
  doi          = {10.1007/s40747-023-01012-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5585-5609},
  shortjournal = {Complex Intell. Syst.},
  title        = {Reinforcement-learning-based parameter adaptation method for particle swarm optimization},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An MRI image automatic diagnosis model for lumbar disc
herniation using semi-supervised learning. <em>CIS</em>, <em>9</em>(5),
5567–5584. (<a
href="https://doi.org/10.1007/s40747-023-00981-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lumbar disc herniation is a common disease that causes low back pain. Due to the high cost of medical diagnosis, as well as a shortage and uneven distribution of medical resources, a system that can automatically analyze and diagnose lumbar spine Magnetic Resonance Imaging (MRI) is becoming an urgent need. This study uses deep learning methods to establish a classifier to diagnose lumbar disc herniation. An MRI classification dataset of lumbar disc herniation consisting of public MRI images is presented and is used to train the proposed classifier. Because a common difficulty in applying computer vision technology to medical images is labeling training data, we use a semi-supervised model training method, while multilayer transverse axial MRI images are used as the model input. In this method, we first use unlabelled MRI images for random self-supervised pre-training and the pre-trained model as a feature extractor for MRI images. Then, all marked cross-sections of each intervertebral disc are used to calculate the feature vector through the feature extractor. The information of all feature vectors is integrated, while a multilayer perceptron is used for classification training. After training, the model achieved 87.11 $$\%$$ accuracy, 87.50 $$\%$$ sensitivity, 86.72 $$\%$$ specificity and 0.9487 AUC (Area Under the ROC Curve) index on the test set. To analyze the rationality of the diagnostic results more quickly, we output the severity of degenerative changes in each region using a heatmap.},
  archive      = {J_CIS},
  author       = {Hou, Chao and Li, Xiaogang and Wang, Hongbo and Zhang, Weiqi and Liu, Fei and Liu, Defeng and Pan, Yuzhen},
  doi          = {10.1007/s40747-023-00981-0},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5567-5584},
  shortjournal = {Complex Intell. Syst.},
  title        = {An MRI image automatic diagnosis model for lumbar disc herniation using semi-supervised learning},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel computerized adaptive testing framework with
decoupled learning selector. <em>CIS</em>, <em>9</em>(5), 5555–5566. (<a
href="https://doi.org/10.1007/s40747-023-01019-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computerized adaptive testing (CAT) targets to accurately assess the student’s proficiency in the required subject/area. The key issue is how to design a question selector that adaptively selects the best-suited questions for each student based on previous performance step by step. Most existing question selectors execute via greedy metric functions (e.g., question information and uncertainty), which can not effectively capture data characteristics. There also exist learning-based question selectors that redefine the CAT problem as a bilevel optimization problem, where the parameter learning of the question selector and the student proficiency estimation model are coupled, which is not flexible enough. To this end, in this paper, we propose a novel CAT framework with Decoupled Learning selector (DL-CAT). Specifically, we first use the currently estimated student ability and question characteristics as input and design a deep learning-based question selector to predict question selection scores. Then, to address the issue that there is no ground truth to measure the quality of the selected question, an approximate ground-truth and a pairwise rank loss function are specially designed to update the parameters of the question selector independently. Extensive experiments on two real datasets demonstrate that our proposed DL-CAT has certain advantages in effectiveness and significant advantages in efficiency.},
  archive      = {J_CIS},
  author       = {Ma, Haiping and Zeng, Yi and Yang, Shangshang and Qin, Chuan and Zhang, Xingyi and Zhang, Limiao},
  doi          = {10.1007/s40747-023-01019-1},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5555-5566},
  shortjournal = {Complex Intell. Syst.},
  title        = {A novel computerized adaptive testing framework with decoupled learning selector},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fuzzy rough copula bayesian network model for solving
complex hospital service quality assessment. <em>CIS</em>,
<em>9</em>(5), 5527–5553. (<a
href="https://doi.org/10.1007/s40747-023-01002-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Healthcare tends to be one of the most complicated sectors, and hospitals exist at the core of healthcare activities. One of the most significant elements in hospitals is service quality level. Moreover, the dependency between factors, dynamic features, as well as objective and subjective uncertainties involved endure challenges to modern decision-making problems. Thus, in this paper, a decision-making approach is developed for hospital service quality assessment, using a Bayesian copula network based on a fuzzy rough set within neighborhood operators as a basis of that to deal with dynamic features as well as objective uncertainties. In the copula Bayesian network model, the Bayesian Network is utilized to illustrate the interrelationships between different factors graphically, while Copula is engaged in obtaining the joint probability distribution. Fuzzy rough set theory within neighborhood operators is employed for the subjective treatment of evidence from decision makers. The efficiency and practicality of the designed method are validated by an analysis of real hospital service quality in Iran. A novel framework for ranking a group of alternatives with consideration of different criteria is proposed by the combination of the Copula Bayesian Network and the extended fuzzy rough set technique. The subjective uncertainty of decision makers’ opinions is dealt with in a novel extension of fuzzy Rough set theory. The results highlighted that the proposed method has merits in reducing uncertainty and assessing the dependency between factors of complicated decision-making problems.},
  archive      = {J_CIS},
  author       = {Li, He and Yazdi, Mohammad and Huang, Hong-Zhong and Huang, Cheng-Geng and Peng, Weiwen and Nedjati, Arman and Adesina, Kehinde A.},
  doi          = {10.1007/s40747-023-01002-w},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5527-5553},
  shortjournal = {Complex Intell. Syst.},
  title        = {A fuzzy rough copula bayesian network model for solving complex hospital service quality assessment},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantification study of mental load state based on
AHP–TOPSIS integration extended with cloud model: Methodological and
experimental research. <em>CIS</em>, <em>9</em>(5), 5501–5525. (<a
href="https://doi.org/10.1007/s40747-023-00994-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mental load affects the work efficiency and mental health of operators, and it has a vital effect on the efficiency and reliability of human–machine systems. In this study, the evaluation index system of operators’ mental load was used to quantitatively evaluate the mental load state of workers. The system was established by selecting indices from the operators’ physiological parameters, subjective feelings, and time perception. We propose an extended cloud evaluation model of mental load states that combines cloud model (CM) theory with analytic hierarchy process (AHP) and technique for order preference by similarity to ideal solution (TOPSIS) and provides mental load levels. An energetic material initiation experiment was conducted to evaluate the mental load state of the operators using the proposed method, and the results of a fuzzy comprehensive evaluation and subjective questionnaire were used to verify the performance of the method. The results show that the extended CM evaluation method scientifically and reliably quantified the mental load state. Applying the AHP-TOPSIS integration extended with the CM theory evaluation method in mental load state evaluation provides a new scientific method for studying the quantification of the mental load state and occupational health of workers in hazardous environments. The results of this study are a reference for assessing the mental state of personnel and analyzing occupational suitability for dangerous posts.},
  archive      = {J_CIS},
  author       = {Zheng, Xin and Hao, Tengteng and Wang, Huiyu and Xu, Kaili},
  doi          = {10.1007/s40747-023-00994-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5501-5525},
  shortjournal = {Complex Intell. Syst.},
  title        = {Quantification study of mental load state based on AHP–TOPSIS integration extended with cloud model: Methodological and experimental research},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A random elite ensemble learning swarm optimizer for
high-dimensional optimization. <em>CIS</em>, <em>9</em>(5), 5467–5500.
(<a href="https://doi.org/10.1007/s40747-023-00993-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional optimization problems are increasingly pervasive in real-world applications nowadays and become harder and harder to optimize due to increasingly interacting variables. To tackle such problems effectively, this paper designs a random elite ensemble learning swarm optimizer (REELSO) by taking inspiration from human observational learning theory. First, this optimizer partitions particles in the current swarm into two exclusive groups: the elite group consisting of the top best particles and the non-elite group containing the rest based on their fitness values. Next, it employs particles in the elite group to build random elite neighbors for each particle in the non-elite group to form a positive learning environment for the non-elite particle to observe. Subsequently, the non-elite particle is updated by cognitively learning from the best elite among the neighbors and collectively learning from all elites in the environment. For one thing, each non-elite particle is directed by superior ones, and thus the convergence of the swarm could be guaranteed. For another, the elite learning environment is randomly formed for each non-elite particle, and hence high swarm diversity could be maintained. Finally, this paper further devises a dynamic partition strategy to divide the swarm into the two groups dynamically during the evolution, so that the swarm gradually changes from exploring the immense solution space to exploiting the found optimal areas without serious diversity loss. With the above mechanisms, the devised REELSO is expected to explore the search space and exploit the found optimal areas properly. Abundant experiments on two popularly used high-dimensional benchmark sets prove that the devised optimizer performs competitively with or even significantly outperforms several state-of-the-art approaches designed for high-dimensional optimization.},
  archive      = {J_CIS},
  author       = {Yang, Qiang and Song, Gong-Wei and Gao, Xu-Dong and Lu, Zhen-Yu and Jeon, Sang-Woon and Zhang, Jun},
  doi          = {10.1007/s40747-023-00993-w},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5467-5500},
  shortjournal = {Complex Intell. Syst.},
  title        = {A random elite ensemble learning swarm optimizer for high-dimensional optimization},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An assessment model for national sustainable development
based on the hybrid DEA and modified TOPSIS techniques. <em>CIS</em>,
<em>9</em>(5), 5449–5466. (<a
href="https://doi.org/10.1007/s40747-023-01034-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessing and improving energy efficiency is crucial for addressing the problems of climate change and global warming. This study evaluates the performance of each Organisation for Economic Cooperation and Development (OECD) nation based on the weights obtained by Data Envelopment Analysis (DEA), combined with a modified Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS) method based on the concept of the aspiration level (called modified TOPSIS-AL). Objective weights are obtained for each country through DEA. This method offers an effective improvement over the previous methods which only use the same subjective weights for the calculation. In addition, our model is also able to account for negative environmental externalities generated during development and provides a comprehensive assessment system for the evaluation of national sustainable development. The findings indicate that the member nations are gradually adopting policies to reduce fossil fuel consumption. However, regional analysis showed that the overall performance of the G7 nations differed significantly from that of the non-G7 nations. The importance of this study lies in the fact that energy consumption not only creates environmental burdens but also affects resource production patterns and productivity. By evaluating the performance of nations in terms of energy efficiency and environmental impact, we aim to address the challenges posed by energy consumption for sustainable development. The proposed hybrid model offers several advantages, including a comprehensive assessment system, consideration of negative externalities, and practical policy recommendations.},
  archive      = {J_CIS},
  author       = {Lin, Sheng-Wei and Lo, Huai-Wei and Gul, Muhammet},
  doi          = {10.1007/s40747-023-01034-2},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5449-5466},
  shortjournal = {Complex Intell. Syst.},
  title        = {An assessment model for national sustainable development based on the hybrid DEA and modified TOPSIS techniques},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reliability-enhanced surrogate-assisted particle swarm
optimization for feature selection and hyperparameter optimization in
landslide displacement prediction. <em>CIS</em>, <em>9</em>(5),
5417–5447. (<a
href="https://doi.org/10.1007/s40747-023-01010-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Landslides are dangerous disasters that are affected by many factors. Neural networks can be used to fit complex observations and predict landslide displacement. However, hyperparameters have a great impact on neural networks, and each evaluation of a hyperparameter requires the construction of a corresponding model and the evaluation of the accuracy of the hyperparameter on the test set. Thus, the evaluation of hyperparameters requires a large amount of time. In addition, not all features are positive factors for predicting landslide displacement, so it is necessary to remove useless and redundant features through feature selection. Although the accuracy of wrapper-based feature selection is higher, it also requires considerable evaluation time. Therefore, in this paper, reliability-enhanced surrogate-assisted particle swarm optimization (RESAPSO), which uses the surrogate model to reduce the number of evaluations and combines PSO with the powerful global optimization ability to simultaneously search the hyperparameters in the long short-term memory (LSTM) neural network and the feature set for predicting landslide displacement is proposed. Specifically, multiple surrogate models are utilized simultaneously, and a Bayesian evaluation strategy is designed to integrate the predictive fitness of multiple surrogate models. To mitigate the influence of an imprecise surrogate model, an intuitional fuzzy set is used to represent individual information. To balance the exploration and development of the algorithm, intuition-fuzzy multiattribute decision-making is used to select the best and most uncertain individuals from the population for updating the surrogate model. The experiments were carried out in CEC2015 and CEC2017. In the experiment, RESAPSO is compared with several well-known and recently proposed SAEAs and verified for its effectiveness and advancement in terms of accuracy, convergence speed, and stability, with the Friedman test ranking first. For the landslide displacement prediction problem, the RESAPSO-LSTM model is established, which effectively solves the feature selection and LSTM hyperparameter optimization and uses less evaluation time while improving the prediction accuracy. The experimental results show that the optimization time of RESAPSO is about one-fifth that of PSO. In the prediction of landslide displacement in the step-like stage, RESAPSO-LSTM has higher prediction accuracy than the contrast model, which can provide a more effective prediction method for the risk warning of a landslide in the severe deformation stage.},
  archive      = {J_CIS},
  author       = {Wang, Yi and Wang, Kanqi and Zhang, Maosheng and Gu, Tianfeng and Zhang, Hui},
  doi          = {10.1007/s40747-023-01010-w},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5417-5447},
  shortjournal = {Complex Intell. Syst.},
  title        = {Reliability-enhanced surrogate-assisted particle swarm optimization for feature selection and hyperparameter optimization in landslide displacement prediction},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A novel ensemble estimation of distribution algorithm with
distribution modification strategies. <em>CIS</em>, <em>9</em>(5),
5377–5416. (<a
href="https://doi.org/10.1007/s40747-023-00975-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The canonical estimation of distribution algorithm (EDA) easily falls into a local optimum with an ill-shaped population distribution, which leads to weak convergence performance and less stability when solving global optimization problems. To overcome this defect, we explore a novel EDA variant with an ensemble of three distribution modification strategies, i.e., archive-based population updating (APU), multileader-based search diversification (MSD), and the triggered distribution shrinkage (TDS) strategy, named E3-EDA. The APU strategy utilizes historical population information to rebuild the search scope and avoid ill-shaped distributions. Moreover, it continuously updates the archive to avoid overfitting the distribution model. The MSD makes full use of the location differences among populations to evolve the sampling toward promising regions. TDS is triggered when the search stagnates, shrinking the distribution scope to achieve local exploitation. Additionally, the E3-EDA performance is evaluated using the CEC 2014 and CEC 2018 test suites on 10-dimensional, 30-dimensional, 50-dimensional and 100-dimensional problems. Moreover, several prominent EDA variants and other top methods from CEC competitions are comprehensively compared with the proposed method. The competitive performance of E3-EDA in solving complex problems is supported by the nonparametric test results.},
  archive      = {J_CIS},
  author       = {Wang, Xiaofei and Li, Yintong and Liang, Yajun and Wu, Bi and Xuan, Yongbo},
  doi          = {10.1007/s40747-023-00975-y},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5377-5416},
  shortjournal = {Complex Intell. Syst.},
  title        = {A novel ensemble estimation of distribution algorithm with distribution modification strategies},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new multi-attribute decision making approach based on new
score function and hybrid weighted score measure in interval-valued
fermatean fuzzy environment. <em>CIS</em>, <em>9</em>(5), 5359–5376. (<a
href="https://doi.org/10.1007/s40747-023-01021-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval-valued Fermatean fuzzy sets (IVFFSs) were introduced as a more effective mathematical tool for handling uncertain information in 2021. In this paper, firstly, a novel score function (SCF) is proposed based on IVFFNs that can distinguish between any two IVFFNs. And then, the novel SCF and hybrid weighted score measure were used to construct a new multi-attribute decision-making (MADM) method. Besides, three cases are used to demonstrate that our proposed method can overcome the disadvantages that the existing approaches cannot obtain the preference orderings of alternatives in some circumstances and involves the existence of division by zero error in the decision procedure. Compared with the two existing MADM methods, our proposed approach has the highest recognition index and the lowest error rate of division by zero. Our proposed method provides a better approach to dealing with the MADM problem in the interval-valued Fermatean fuzzy environment.},
  archive      = {J_CIS},
  author       = {Qin, Hongwu and Peng, Qiangwei and Ma, Xiuqin and Zhan, Jianming},
  doi          = {10.1007/s40747-023-01021-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5359-5376},
  shortjournal = {Complex Intell. Syst.},
  title        = {A new multi-attribute decision making approach based on new score function and hybrid weighted score measure in interval-valued fermatean fuzzy environment},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Picture fuzzy additive ratio assessment method (ARAS) and
VIseKriterijumska optimizacija i kompromisno resenje (VIKOR) method for
multi-attribute decision problem and their application. <em>CIS</em>,
<em>9</em>(5), 5345–5357. (<a
href="https://doi.org/10.1007/s40747-023-01007-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this paper is to study the multi-attribute decision-making problem under the fuzzy picture environment. First, a method to compare the pros and cons of picture fuzzy numbers (PFNs) is introduced in this paper. Second, the correlation coefficient and standard deviation (CCSD) method is used to determine the attribute weight information under the picture fuzzy environment regardless of whether the attribute weight information is partially unknown or completely unknown. Third, the ARAS and VIKOR methods are extended to the picture fuzzy environment, and the proposed PFNs comparison rules are also applied in the PFS-ARAS and PFS-VIKOR methods. Fourth, the problem of green supplier selection in a picture-ambiguous environment is solved by the method proposed in this paper. Finally, the method proposed in this paper is compared with some methods and the results are analyzed.},
  archive      = {J_CIS},
  author       = {Fan, Jianping and Han, Dongshuai and Wu, Meiqin},
  doi          = {10.1007/s40747-023-01007-5},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5345-5357},
  shortjournal = {Complex Intell. Syst.},
  title        = {Picture fuzzy additive ratio assessment method (ARAS) and VIseKriterijumska optimizacija i kompromisno resenje (VIKOR) method for multi-attribute decision problem and their application},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An enterprise adaptive tag extraction method based on
multi-feature dynamic portrait. <em>CIS</em>, <em>9</em>(5), 5333–5344.
(<a href="https://doi.org/10.1007/s40747-023-01029-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User portrait has become a research hot spot in the field of knowledge graph in recent years and the rationality of tag extraction directly affects the quality of user portrait. However, most of the current tag extraction methods for portraits only consider the methods based on word frequency statistics and semantic clustering. These methods have some drawbacks: they cannot effectively discover the preferred themes of the enterprise, dynamically update the portrait tags, and adapt to the needs of the enterprise. In this paper, we propose an enterprise adaptive tag extraction method based on multi-feature dynamic portrait (ATEMDP). ATEMDP first uses K-means to measure the similarity between enterprise texts in preference division, and converts similar enterprise text clustering problems into tag feature clusters to obtain the point cluster structure containing the distribution of tag preference topics. In addition, in the multi-feature selection, the professional domain thesaurus is introduced for feature expansion, and the topic text is introduced into the Bert model as a sample set to discover the potential features of the enterprise text. In the end, in dynamic tag extraction, BiLSTM and CNN are used to extract features, and dynamic preference tags are obtained by updating enterprise text. THUCNews data set and Ente-pku data set are used for simulation, and seven other methods are considered in comparison. The experimental results indicate that ATEMDP is not only superior to other conventional methods in accuracy and F1-score, but also effectively solves the dynamic tagging problem of enterprise portrait.},
  archive      = {J_CIS},
  author       = {Li, Xiang and Ding, Xingshuo and Xie, Qian and Gao, Shangbing and Zhu, Quanyin},
  doi          = {10.1007/s40747-023-01029-z},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5333-5344},
  shortjournal = {Complex Intell. Syst.},
  title        = {An enterprise adaptive tag extraction method based on multi-feature dynamic portrait},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RDQN: Ensemble of deep neural network with reinforcement
learning in classification based on rough set theory for digital
transactional fraud detection. <em>CIS</em>, <em>9</em>(5), 5313–5332.
(<a href="https://doi.org/10.1007/s40747-023-01016-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {All financial sectors are facing the most common frauds, which are digital transactional frauds. Fraudsters have always engaged in illegal activities such as stealing personal information and logging in with unauthorised credentials. Many machine learning algorithms predict whether the transaction is factual or nonfactual but fail to decrease the processing time. Hybrid models are used in this case to identify the fraud in a quick and efficient manner. This article demarcates to construct a novel model, RDQN, i.e., deep reinforcement learning, that combines with the rough set theory. This article has three steps, including data pre-processing to determine the quality of the data, which affects the learning ability of the model, determining the structural relationship and gaining useful features from the data set using rough set theory, and doing a hybridization of DNN (deep neural network) and Q learning, which is called DQN. It uses the MISH activation function and the ReLU activation function in different layers for training dynamics in the neural network. The proposed model classifies and predicts that the transaction belongs to the category implemented by the agents by activating the reward function. The reinforcement-learning agent’s performance improves based on reward assessment. This reward function gives a more precise value for each transaction, and no fraudster can escape from the agent’s sight. This novel approach improves accuracy and reduces processing time by considering the best feature selection during the process.},
  archive      = {J_CIS},
  author       = {Tekkali, Chandana Gouri and Natarajan, Karthika},
  doi          = {10.1007/s40747-023-01016-4},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5313-5332},
  shortjournal = {Complex Intell. Syst.},
  title        = {RDQN: Ensemble of deep neural network with reinforcement learning in classification based on rough set theory for digital transactional fraud detection},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). State estimation for delayed genetic regulatory networks
with reaction diffusion terms and markovian jump. <em>CIS</em>,
<em>9</em>(5), 5297–5311. (<a
href="https://doi.org/10.1007/s40747-023-01001-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust state estimation for delayed genetic regulatory networks with reaction–diffusion terms and uncertainties terms under Dirichlet boundary conditions is addressed in this article. The main purpose of the problem investigation is to design a novel state observer for estimate the true concentrations of mRNA and protein by available measurement outputs. Based on Lyapunov–Krasovskii functions and linear matrix inequalities (LMI), sufficient conditions are given to ensure the robust stability of the estimation error networks. Two examples are presented to illustrate the effectiveness of the proposed approach.},
  archive      = {J_CIS},
  author       = {Zou, Chengye and Zhou, Changjun and Zhang, Qiang and He, Xinyu and Huang, Chun},
  doi          = {10.1007/s40747-023-01001-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5297-5311},
  shortjournal = {Complex Intell. Syst.},
  title        = {State estimation for delayed genetic regulatory networks with reaction diffusion terms and markovian jump},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Characterization of threats in IoT from an MQTT
protocol-oriented dataset. <em>CIS</em>, <em>9</em>(5), 5281–5296. (<a
href="https://doi.org/10.1007/s40747-023-01000-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the cybersecurity of Internet of Thing (IoT) environments is a big challenge. The analysis of network traffic and the use of automated estimators built up with machine learning techniques have been useful in detecting intrusions in traditional networks. Since the IoT networks require new and particular protocols to control the communications between the different devices involved in the networks, the knowledge acquired in the study of general networks may be unuseful some times. The goal of this paper is twofold. On the one hand, we aim to obtain a consistent dataset of the network traffic of an IoT system based on the Message Queue Telemetry Transport protocol (MQTT) and undergoing certain type of attacks. On the other hand, we want to characterize each of these attacks in terms of the minimum possible number of significant variables allowed by this protocol. Obtaining the data set has been achieved by studying the MQTT protocol in depth, while its characterization has been addressed through a hybrid (filter/wrapper) feature selection algorithm based on the idea behind the minimum-redundancy maximum-relevance (mRMR) algorithm. The dataset, together with the feature selection algorithm, carries out a characterization of the different attacks which is optimal in terms of the accuracy of the machine learning models trained on it as well as in terms of the capability of explaining their underlying nature. This confirms the consistency of the dataset.},
  archive      = {J_CIS},
  author       = {Muñoz Castañeda, Ángel Luis and Mata, José Antonio Aveleira and Aláiz-Moretón, Héctor},
  doi          = {10.1007/s40747-023-01000-y},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5281-5296},
  shortjournal = {Complex Intell. Syst.},
  title        = {Characterization of threats in IoT from an MQTT protocol-oriented dataset},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). An ensemble learning model based on differentially private
decision tree. <em>CIS</em>, <em>9</em>(5), 5267–5280. (<a
href="https://doi.org/10.1007/s40747-023-01017-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using differential privacy to provide privacy protection for classification algorithms has become a research hotspot in data mining. In this paper, we analyze the defects in the differentially private decision tree named Maxtree, and propose an improved model DPtree. DPtree can use the Fayyad theorem to process continuous features quickly, and can adjust privacy budget adaptively according to sample category distributions in leaf nodes. Moreover, to overcome the inevitable decline of classification ability of differentially private decision trees, we propose an ensemble learning model for DPtree, namely En-DPtree. In the voting process of En-DPtree, we propose a multi-population quantum genetic algorithm, and introduce immigration operators and elite groups to search the optimal weights for base classifiers. Experiments show that the performance of DPtree is better than Maxtree, and En-DPtree is always superior to other competitive algorithms.},
  archive      = {J_CIS},
  author       = {Niu, Xufeng and Ma, Wenping},
  doi          = {10.1007/s40747-023-01017-3},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5267-5280},
  shortjournal = {Complex Intell. Syst.},
  title        = {An ensemble learning model based on differentially private decision tree},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Keenness for characterizing continuous optimization problems
and predicting differential evolution algorithm performance.
<em>CIS</em>, <em>9</em>(5), 5251–5266. (<a
href="https://doi.org/10.1007/s40747-023-01005-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fitness landscape analysis devotes to characterizing different properties of optimization problems, such as evolvability, sharpness, and neutrality. Although several landscape features have been proposed, only a few of them can be used in practice as predictors of algorithm performance. In this study, the keenness ( $$\textrm{KEE}_{s}$$ ) is proposed to characterize the sharpness of the fitness landscape for continuous optimization problems and predict the performance of the differential evolution algorithm. Specifically, a mirror simple random walk algorithm is designed to construct the relevance between the front and back search points in the sampling. The fitness value of each point is replaced by the specific integer. The values in the set of integers with the same circumstance are computed as the feature scalar using the cumulative calculation mechanism. The results of experimental studies in various functions demonstrate the superiority of $$\textrm{KEE}_{s}$$ in terms of accuracy, reliability, and coverage of samples. Moreover, $$\textrm{KEE}_{s}$$ has shown excellent practicability in the application of differential evolution algorithm performance prediction for continuous optimization problems. Thus, $$\textrm{KEE}_{s}$$ is a new landscape feature for fitness landscape analysis of continuous optimization problems and algorithm performance prediction within limited prior knowledge of the unknown problem.},
  archive      = {J_CIS},
  author       = {Li, Yaxin and Liang, Jing and Yu, Kunjie and Yue, Caitong and Zhang, Yingjie},
  doi          = {10.1007/s40747-023-01005-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5251-5266},
  shortjournal = {Complex Intell. Syst.},
  title        = {Keenness for characterizing continuous optimization problems and predicting differential evolution algorithm performance},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NEDORT: A novel and efficient approach to the data overlap
problem in relational triples. <em>CIS</em>, <em>9</em>(5), 5235–5250.
(<a href="https://doi.org/10.1007/s40747-023-01004-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation triple extraction is a combination of named entity recognition and relation prediction. Early works ignore the problem of data overlap when extracting triples, resulting in poor extraction performance. Subsequent works improve the capability of the model to extract overlapping triples through generative and extractive methods. These works achieve considerable performance but still suffer from some defects, such as poor extraction capability for individual triplets and inappropriate spatial distribution of the data. To solve the above problems, we perform sequence-to-matrix transformation and propose the NEDORT model. NEDORT predicts all subjects in the sentence and then completes the extraction of relation–object pairs. There are overlapping parts between relation–object pairs, so we conduct the conversion of sequence to matrix. We design the Differential Amplified Multi-head Attention method to extract subjects. This method highlights the locations of entities and captures sequence features from multiple dimensions. When performing the extraction of relation–object pairs, we fuse subject and sequence information through the Biaffine method and generate relation–sequence matrices. In addition, we design a multi-layer U-Net network to optimize the matrix representation and improve the extraction performance of the model. Experimental results on two public datasets show that our model outperforms other baseline models on triples of all categories},
  archive      = {J_CIS},
  author       = {Zhang, Zhanjun and Hu, Xiaoru and Zhang, Haoyu and Liu, Jie},
  doi          = {10.1007/s40747-023-01004-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5235-5250},
  shortjournal = {Complex Intell. Syst.},
  title        = {NEDORT: A novel and efficient approach to the data overlap problem in relational triples},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new machine vision detection method for identifying and
screening out various large foreign objects on coal belt conveyor lines.
<em>CIS</em>, <em>9</em>(5), 5221–5234. (<a
href="https://doi.org/10.1007/s40747-023-01011-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large foreign object transporting by coal mine conveyor belt may lead to production safety hazards. To reduce safety accidents during coal mining, a large foreign object detection method based on machine vision is proposed in this paper. An adaptive weighted multi-scale Retinex (MSR) image enhancement algorithm is proposed to improve the captured image quality of the belt conveyor line. An improved multi-scale template matching algorithm is designed by combining the frame difference and area methods to screen and identify large foreign objects mixed in coals. The multi-layer perceptron (MLP) network optimized by the Gray Wolf algorithm is introduced to identify the large objects. Experimental results show that the identification accuracy reaches 98.8% for the large foreign objects. Furthermore, industrial field test is carried out in the Gaoyang coal mine, and the filed test results demonstrate that the identification accuracy of the proposed method is more than 95%. Hence, the proposed method meets the industrial detection requirements and can be used in practices for detecting the large foreign objects.},
  archive      = {J_CIS},
  author       = {Dai, Lili and Zhang, Xu and Gardoni, Paolo and Lu, He and Liu, Xinhua and Królczyk, Grzegorz and Li, Zhixiong},
  doi          = {10.1007/s40747-023-01011-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5221-5234},
  shortjournal = {Complex Intell. Syst.},
  title        = {A new machine vision detection method for identifying and screening out various large foreign objects on coal belt conveyor lines},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FedTCR: Communication-efficient federated learning via
taming computing resources. <em>CIS</em>, <em>9</em>(5), 5199–5219. (<a
href="https://doi.org/10.1007/s40747-023-01006-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) enables clients learning a shared global model from multiple distributed devices while keeping training data locally. Due to the synchronous update mode between server and devices, the straggler problem has become a significant bottleneck for efficient FL. Existing approaches attempt to tackle this issue by using asynchronous-based model aggregation. However, these researches are only from the perspective of changing global model updating manner to mitigate straggler effect. They do not investigate the intrinsic reasons for the generation of the straggler effect, which could not fundamentally solve this problem. Furthermore, asynchronous-based approaches usually ignore those slow-responding but important local updates while frequently aggregating fast-responding ones during the whole training process, which may come with degradation in model accuracy. Thus, we propose FedTCR, a novel Federated learning approach via Taming Computing Resources. FedTCR includes a coarse-grained logical computing cluster construction algorithm (LCC) and a fine-grained intra-cluster collaborative training mechanism (ICT) as part of the FL process. The computing resource heterogeneity among devices and the communication frequency between devices and the server are indirectly tamed during this process, which substantially resolves the straggler problem and significantly improves the communication efficiency for FL. Experimental results show that FedTCR achieves much faster training performance, reducing the communication cost by up to $$8.59\,\times $$ while improving $$13.85\%$$ model accuracy, compared to state-of-the-art FL methods.},
  archive      = {J_CIS},
  author       = {Li, Kaiju and Wang, Hao and Zhang, Qinghua},
  doi          = {10.1007/s40747-023-01006-6},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5199-5219},
  shortjournal = {Complex Intell. Syst.},
  title        = {FedTCR: Communication-efficient federated learning via taming computing resources},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fire and smoke precise detection method based on the
attention mechanism and anchor-free mechanism. <em>CIS</em>,
<em>9</em>(5), 5185–5198. (<a
href="https://doi.org/10.1007/s40747-023-00999-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Substantial natural environmental damage and economic losses are caused by fire. For this problem, automatic fire-smoke detection and identification are needed. Fire-smoke detection methods based on vision still suffer from significant challenges that fail to balance model complexity and accuracy. We propose an improved YOLOv3 fire-smoke detection and identification method to address these problems and include a fire and smoke dataset. The neck module (1) adds an attention mechanism to enhance the ability to extract features from pictures, and (2) uses an anchor-free mechanism in the anchor box mechanism to solve the problem of significant variances in smoke texture, shape, and color in real applications, and (3) uses a lightweight backbone to reduce the model complexity. The proposed dataset is based on VOC, which contains images of complex scenes and high diversity. The dataset includes pictures that (1) combine fire with smoke, (2) only have smoke or fire objects, and (3) contain a single cloud object. The experimental results demonstrate that the method achieves 50.8 AP, which outperforms the suboptimal method by 3.8. Moreover, the inference speed of our method is 13% faster on the GPU than the suboptimal method.},
  archive      = {J_CIS},
  author       = {Sun, Yu and Feng, Jian},
  doi          = {10.1007/s40747-023-00999-4},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5185-5198},
  shortjournal = {Complex Intell. Syst.},
  title        = {Fire and smoke precise detection method based on the attention mechanism and anchor-free mechanism},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Selective quantum ensemble learning inspired by improved
AdaBoost based on local sample information. <em>CIS</em>, <em>9</em>(5),
5173–5183. (<a
href="https://doi.org/10.1007/s40747-023-00996-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In ensemble learning, random subspace technology not only easily loses some important features but also easily produces some redundant subspaces, inevitably leading to the decline of ensemble learning performance. In order to overcome the shortcomings, we propose a new selective quantum ensemble learning model inspired by improved AdaBoost based on local sample information (SELA). Firstly, SELA combines information entropy and random subspace to ensure that the important features of the classification task in each subspace are preserved. Then, we select the base classifier that can balance accuracy and diversity among a group of base classifiers generated based on local AdaBoost in each iteration. Finally, we utilize the quantum genetic algorithm to search optimal weights for base learners in the label prediction process. We use UCI datasets to analyze the impact of important parameters in SELA on classification performance and verify that SELA is usually superior to other competitive algorithms.},
  archive      = {J_CIS},
  author       = {Niu, Xufeng and Ma, Wenping},
  doi          = {10.1007/s40747-023-00996-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5173-5183},
  shortjournal = {Complex Intell. Syst.},
  title        = {Selective quantum ensemble learning inspired by improved AdaBoost based on local sample information},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A co-evolutionary algorithm with elite archive strategy for
generating diverse high-quality satellite range schedules. <em>CIS</em>,
<em>9</em>(5), 5157–5172. (<a
href="https://doi.org/10.1007/s40747-023-01008-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Satellite range scheduling, a multi-constrained combinatorial optimization problem, is crucial to guaranteeing the normal operation and application of onboard satellites. Traditional methods are dedicated to finding one optimal schedule, having ignored the problem may process multiple high-quality schedules. To provide a set of alternative schedules while maintaining the solution quality, we propose a co-evolutionary algorithm with elite archive strategy (COEAS) in this article. In COEAS, two populations are evolved to solve the original and relaxed problem in terms of schedule quality and diversity, respectively. During the evolution, the populations maintain a weak cooperation and only share the information in offspring combination phase. Further, an elite archive strategy is derived to identify and preserve potential stagnated and optimal individuals. In this strategy, the promising individuals would further participate in parent mating and offspring replacement for the dual purpose of maintaining potential optima recovery and fine-tuning the population. The experimental results show that the proposed algorithm is better than comparison algorithms in terms of efficacy (obtaining higher quality schedule), diversity (locating more optimal schedules) and flexibility (providing better alternatives).},
  archive      = {J_CIS},
  author       = {Xiong, Minghui and Xiong, Wei and Liu, Zheng},
  doi          = {10.1007/s40747-023-01008-4},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5157-5172},
  shortjournal = {Complex Intell. Syst.},
  title        = {A co-evolutionary algorithm with elite archive strategy for generating diverse high-quality satellite range schedules},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-organized multi-target trapping of swarm robots with
density-based interaction. <em>CIS</em>, <em>9</em>(5), 5135–5155. (<a
href="https://doi.org/10.1007/s40747-023-01014-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of multi-target trapping in swarm robots can often be solved by global shape planning and target assignment, but it still remains a challenge to achieve fully self-organized multi-target trapping behavior based on local information. In this paper, inspired by the concept of spatial density in physics and biology, we proposed a novel density-based method to enable the swarm robots to entrap multiple targets with either single-ring, multi-ring or multi-subgroup formation in a distributed and self-organized way while neither communication among robots nor encirclement function is required. Each robot’s local spatial density is considered as the main clue for the individual’s motion decision-making and the enclosed configurations emerge from such individual-level interactions rather than being explicitly designed. Numerical simulations and real robotic experiments are conducted to validate the effectiveness of the proposed method. The results show that the proposed self-organized trapping method allows a swarm of robots to entrap multiple moving targets in a stable, flexible, noise-tolerate and size-scalable fashion.},
  archive      = {J_CIS},
  author       = {Lei, Xiaokang and Zhang, Shuai and Xiang, Yalun and Duan, Mengyuan},
  doi          = {10.1007/s40747-023-01014-6},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5135-5155},
  shortjournal = {Complex Intell. Syst.},
  title        = {Self-organized multi-target trapping of swarm robots with density-based interaction},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RetinaMOT: Rethinking anchor-free YOLOv5 for online multiple
object tracking. <em>CIS</em>, <em>9</em>(5), 5115–5133. (<a
href="https://doi.org/10.1007/s40747-023-01009-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, YOLOv5 networks have become a research focus in many fields because they are capable of outperforming state-of-the-art (SOTA) approaches in different computer vision tasks. Nevertheless, there is still room for improvement in YOLOv5 in terms of target tracking. We modified YOLOv5 according to the anchor-free paradigm to be on par with other state-of-the-art tracking paradigms and modified the network backbone to design an efficient module, thus proposing the RetinaYOLO detector, which, after combining state-of-the-art tracking algorithms, achieves state-of-the-art performance: we call it RetinaMOT. To the best of our knowledge, RetinaMOT is the first such approach. The anchor-free paradigm SOTA method for the YOLOv5 architecture and RetinaYOLO outperforms all lightweight YOLO architecture methods on the MS COCO dataset. In this paper, we show the details of the RetinaYOLO backbone, embedding Kalman filtering and the Hungarian algorithm into the network, with one framework used to accomplish two tasks. Our RetinaMOT shows that MOTA metrics reach 74.8, 74.1, and 66.8 on MOT Challenge MOT16, 17, and 20 test datasets, and our method is at the top of the list when compared with state-of-the-art methods.},
  archive      = {J_CIS},
  author       = {Cao, Jie and Zhang, Jianxun and Li, Bowen and Gao, Linfeng and Zhang, Jie},
  doi          = {10.1007/s40747-023-01009-3},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5115-5133},
  shortjournal = {Complex Intell. Syst.},
  title        = {RetinaMOT: Rethinking anchor-free YOLOv5 for online multiple object tracking},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Agent-based modeling of mass shooting case with the
counterforce of policemen. <em>CIS</em>, <em>9</em>(5), 5093–5113. (<a
href="https://doi.org/10.1007/s40747-023-01003-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mass shooting cases have caused large casualties worldwide. The counterforce, such as the policemen, is of great significance to reducing casualties, which is the core issue of social safety governance. Therefore, we model both the killing force and counterforce, to explore the crowd dynamics under the shooting. Taking the “Borderline” shooting in 2018 as the target case, the agent-based modeling is applied to back-calculate this dynamic process and explore key behavior rules of individuals. The real death tolls of three classes of agents (civilians, policemen, &amp; killers) are as the real function, based on which we calculate the gaps between real target case and simulations. Eventually, we obtain three optimal solutions, which achieve the least gap or highest matching degree. Besides, we make counterfactual inferences under the optimal solutions, to explore the strategic interactions between policemen and killers. For strategies of killers, we explore different sizes, positions, and moving patterns of the killers. The optimal size of policemen is four to five, for each one killer. For strategies of policemen, we explore the size, locations, and the response time. It indicates that optimal response time of policemen is thirty to forty shots of the killer, and the death of civilians and policemen can be minimized, and the death probability of the killer can be maximized. These findings help to improve public safety governance for our cities. To effectively deal with sudden shooting terrorist cases, patrol routes, reasonable settings, and swift dispatches of the police (stations) should be considered.},
  archive      = {J_CIS},
  author       = {Lu, Peng and Li, Yan and Wen, Feier and Chen, Dianhan},
  doi          = {10.1007/s40747-023-01003-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5093-5113},
  shortjournal = {Complex Intell. Syst.},
  title        = {Agent-based modeling of mass shooting case with the counterforce of policemen},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LSH-based missing value prediction for abnormal traffic
sensors with privacy protection in edge computing. <em>CIS</em>,
<em>9</em>(5), 5081–5091. (<a
href="https://doi.org/10.1007/s40747-023-00992-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction is an important part of intelligent transportation systems (ITS). However, sensor failures or the transmission distortion often occur in the process of data acquisition, which will inevitably cause the loss or abnormality of traffic flow data transmitted to the edge server. In this situation, it is necessary to share traffic flow data among different platforms. However, existing traffic flow prediction methods are facing two challenges in the process of traffic flow data sharing. First, user privacy is often leaked in the process of sharing traffic data on various platforms. Moreover, with the continuous updating of data, the efficiency and scalability of data sharing between different platforms will become lower and lower. In view of the above challenges, in this paper, we propose a novel prediction method for the missing traffic flow data caused by abnormal sensors, named $$ASMVP_{distr-LSH}$$ based on distributed locality-sensitive hashing (LSH) technique. At last, a case study is presented to illustrate the feasibility and effectiveness of our approach $$ASMVP_{distr-LSH}$$ .},
  archive      = {J_CIS},
  author       = {Gao, Ailing and Liu, Xiaomei and Miao, Ying},
  doi          = {10.1007/s40747-023-00992-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5081-5091},
  shortjournal = {Complex Intell. Syst.},
  title        = {LSH-based missing value prediction for abnormal traffic sensors with privacy protection in edge computing},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Structure-enhanced pairwise feature learning for face
clustering. <em>CIS</em>, <em>9</em>(5), 5063–5080. (<a
href="https://doi.org/10.1007/s40747-023-00982-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face clustering groups massive unlabeled face images according to their underlying identities and has proven to be a valuable tool for data analysis. Most recent studies have utilized graph convolutional networks (GCNs) to explore the structural properties of faces, thereby effectively achieving improved clustering performance. However, these methods usually suffer from computational intractability for large-scale graphs and tend to be sensitive to some postprocessing thresholds that serve to purify the clustering results. To address these issues, in this paper, we consider each pairwise relationship between two samples as a learning unit and infer clustering assignments by evaluating a group of pairwise connections. Specifically, we propose a novel clustering framework, named structure-enhanced pairwise feature learning (SEPFL), which mixes neighborhood information to adaptively produce pairwise representations for cluster identification. In addition, we design a combined density strategy to select representative pairs, thus ensuring training effectiveness and inference efficiency. The extensive experimental results show that SEPFL achieves better performance than other advanced face clustering techniques.},
  archive      = {J_CIS},
  author       = {Li, Shaoying and Li, Jie and Wang, Bincheng and Yao, Wei and Liu, Bo},
  doi          = {10.1007/s40747-023-00982-z},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5063-5080},
  shortjournal = {Complex Intell. Syst.},
  title        = {Structure-enhanced pairwise feature learning for face clustering},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SimGRL: A simple self-supervised graph representation
learning framework via triplets. <em>CIS</em>, <em>9</em>(5), 5049–5062.
(<a href="https://doi.org/10.1007/s40747-023-00997-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, graph contrastive learning (GCL) has achieved remarkable performance in graph representation learning. However, existing GCL methods usually follow a dual-channel encoder network (i.e., Siamese networks), which adds to the complexity of the network architecture. Additionally, these methods overly depend on varied data augmentation techniques, corrupting graph information. Furthermore, they are heavily reliant on large quantities of negative nodes for each object node, which requires tremendous memory costs. To address these issues, we propose a novel and simple graph representation learning framework, named SimGRL. Firstly, our proposed network architecture only contains one encoder based on a graph neural network instead of a dual-channel encoder, which simplifies the network architecture. Then we introduce a distributor to generate triplets to obtain the contrastive views between nodes and their neighbors, avoiding the need for data augmentations. Finally, we design a triplet loss based on adjacency information in graphs that utilizes only one negative node for each object node, reducing memory overhead significantly. Extensive experiments demonstrate that SimGRL achieves competitive performance on node classification and graph classification tasks, especially in terms of running time and memory overhead.},
  archive      = {J_CIS},
  author       = {Huang, Da and Lei, Fangyuan and Zeng, Xi},
  doi          = {10.1007/s40747-023-00997-6},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5049-5062},
  shortjournal = {Complex Intell. Syst.},
  title        = {SimGRL: A simple self-supervised graph representation learning framework via triplets},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differential evolution-based transfer rough clustering
algorithm. <em>CIS</em>, <em>9</em>(5), 5033–5047. (<a
href="https://doi.org/10.1007/s40747-023-00987-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to well processing the uncertainty in data, rough clustering methods have been successfully applied in many fields. However, when the capacity of the available data is limited or the data are disturbed by noise, the rough clustering algorithms always cannot effectively explore the structure of the data. Furthermore, rough clustering algorithms are usually sensitive to the initialized cluster centers and easy to fall into local optimum. To resolve the problems mentioned above, a novel differential evolution-based transfer rough clustering (DE-TRC) algorithm is proposed in this paper. First, transfer learning mechanism is introduced into rough clustering and a transfer rough clustering framework is designed, which utilizes the knowledge from the related domain to assist the clustering task. Then, the objective function of the transfer rough clustering algorithm is optimized by using the differential evolution algorithm to enhance the robustness of the algorithm. It can overcome the sensitivity to initialized cluster centers and meanwhile achieve the global optimal clustering. The proposed algorithm is validated on different synthetic and real-world datasets. Experimental results demonstrate the effectiveness of the proposed algorithm in comparison with both traditional rough clustering algorithms and other state-of-the-art clustering algorithms.},
  archive      = {J_CIS},
  author       = {Zhao, Feng and Wang, Chaofei and Liu, Hanqiang},
  doi          = {10.1007/s40747-023-00987-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5033-5047},
  shortjournal = {Complex Intell. Syst.},
  title        = {Differential evolution-based transfer rough clustering algorithm},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-criteria decision-making of manufacturing resources
allocation for complex product system based on intuitionistic fuzzy
information entropy and TOPSIS. <em>CIS</em>, <em>9</em>(5), 5013–5032.
(<a href="https://doi.org/10.1007/s40747-022-00960-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manufacturing resources allocation (MRA) is important area, and a significant challenge is encountered when considering high value, customized, complex structure and long lifespan of complex product system (CoPS). The relationship between uncertainty factors (i.e., inputs and outputs) of processes in CoPS’s manufacturing, operation and maintenance needs comprehensive trade-offs in the preliminary MRA stage. Meanwhile, the CoPS’s MRA schemes are contradictory from a customer’s perspective with different emphasis on operating cost related to operation and maintenance stage. These problems are unavailable in traditional expressions for model and objective function. In this paper, a new variant of MRA multi-criteria decision-making (MCDM) model of CoPS (MRA&amp;CoPS) is developed to evaluate MRA schemes with considering CoPS’s lifecycle. Meanwhile, considering characteristics of CoPS and customer-involved MRA process, the three-layer criteria cumulative model is established. In the proposed method, intuitionistic fuzzy sets (IFSs) based subjective–objective hybrid fuzzy method is presented to deal with uncertainty of evaluation criteria. The weights of criteria are determined by the proposed intuitionistic fuzzy information entropy (IFIE). The hybrid IFIE-TOPSIS method is proposed to obtain the optimum MRA scheme by ranking results. An example of CoPS’s MRA in a case enterprise is addressed to verify the rationality and validity of the proposed method. The results show that the proposed method is more preferable and robust in MCDM problem of MRA&amp;CoPS.},
  archive      = {J_CIS},
  author       = {Luo, Xu and Guo, Shunsheng and Du, Baigang and Guo, Jun and Jiang, Peng and Tan, Tian},
  doi          = {10.1007/s40747-022-00960-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {5013-5032},
  shortjournal = {Complex Intell. Syst.},
  title        = {Multi-criteria decision-making of manufacturing resources allocation for complex product system based on intuitionistic fuzzy information entropy and TOPSIS},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lightweight dense video captioning with cross-modal
attention and knowledge-enhanced unbiased scene graph. <em>CIS</em>,
<em>9</em>(5), 4995–5012. (<a
href="https://doi.org/10.1007/s40747-023-00998-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dense video captioning (DVC) aims at generating description for each scene in a video. Despite attractive progress for this task, previous works usually only concentrate on exploiting visual features while neglecting audio information in the video, resulting in inaccurate scene event location. In this article, we propose a novel DVC model named CMCR, which is mainly composed of a cross-modal processing (CM) module and a commonsense reasoning (CR) module. CM utilizes a cross-modal attention mechanism to encode data in different modalities. An event refactoring algorithm is proposed to deal with inaccurate event localization caused by overlapping events. Besides, a shared encoder is utilized to reduce model redundancy. CR optimizes the logic of generated captions with both heterogeneous prior knowledge and entities’ association reasoning achieved by building a knowledge-enhanced unbiased scene graph. Extensive experiments are conducted on ActivityNet Captions dataset, the results demonstrate that our model achieves better performance than state-of-the-art methods. To better understand the performance achieved by CMCR, we also apply ablation experiments to analyze the contributions of different modules.},
  archive      = {J_CIS},
  author       = {Han, Shixing and Liu, Jin and Zhang, Jinyingming and Gong, Peizhu and Zhang, Xiliang and He, Huihua},
  doi          = {10.1007/s40747-023-00998-5},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {4995-5012},
  shortjournal = {Complex Intell. Syst.},
  title        = {Lightweight dense video captioning with cross-modal attention and knowledge-enhanced unbiased scene graph},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evolutionary multiobjective optimization via efficient
sampling-based offspring generation. <em>CIS</em>, <em>9</em>(5),
4977–4993. (<a
href="https://doi.org/10.1007/s40747-023-00990-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rising number of large-scale multiobjective optimization problems from academia and industries, some evolutionary algorithms (EAs) with different decision variable handling strategies have been proposed in recent years. They mainly emphasize the balance between convergence enhancement and diversity maintenance for multiobjective optimization but ignore the local search tailored for large-scale optimization. Consequently, most existing EAs can hardly obtain the global or local optima. To address this issue, we propose an efficient sampling-based offspring generation method for large-scale multiobjective optimization, where convergence enhancement and diversity maintenance, together with ad hoc local search, are considered. First, the decision variables are dynamically classified into two types for solving large-scale decision space in a divide-and-conquer manner. Then, a convergence-related sampling strategy is designed to handle those decision variables related to convergence enhancement. Two additional sampling strategies are proposed for diversity maintenance and local search, respectively. Experimental results on problems with up to 5000 decision variables have indicated the effectiveness of the algorithm in large-scale multiobjective optimization.},
  archive      = {J_CIS},
  author       = {He, Cheng and Li, Lianghao and Cheng, Ran and Jin, Yaochu},
  doi          = {10.1007/s40747-023-00990-z},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {4977-4993},
  shortjournal = {Complex Intell. Syst.},
  title        = {Evolutionary multiobjective optimization via efficient sampling-based offspring generation},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BPLC + NOSO: Backpropagation of errors based on latency code
with neurons that only spike once at most. <em>CIS</em>, <em>9</em>(5),
4959–4976. (<a
href="https://doi.org/10.1007/s40747-023-00983-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For mathematical completeness, we propose an error-backpropagation algorithm based on latency code (BPLC) with spiking neurons conforming to the spike–response model but allowed to spike once at most (NOSOs). BPLC is based on gradients derived without approximation unlike previous temporal code-based error-backpropagation algorithms. The latency code uses the spiking latency (period from the first input spike to spiking) as a measure of neuronal activity. To support the latency code, we introduce a minimum-latency pooling layer that passes the spike of the minimum latency only for a given patch. We also introduce a symmetric dual threshold for spiking (i) to avoid the dead neuron issue and (ii) to confine a potential distribution to the range between the symmetric thresholds. Given that the number of spikes (rather than timesteps) is the major cause of inference delay for digital neuromorphic hardware, NOSONets trained using BPLC likely reduce inference delay significantly. To identify the feasibility of BPLC + NOSO, we trained CNN-based NOSONets on Fashion-MNIST and CIFAR-10. The classification accuracy on CIFAR-10 exceeds the state-of-the-art result from an SNN of the same depth and width by approximately 2%. Additionally, the number of spikes for inference is significantly reduced (by approximately one order of magnitude), highlighting a significant reduction in inference delay.},
  archive      = {J_CIS},
  author       = {Jin, Seong Min and Kim, Dohun and Yoo, Dong Hyung and Eshraghian, Jason and Jeong, Doo Seok},
  doi          = {10.1007/s40747-023-00983-y},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {4959-4976},
  shortjournal = {Complex Intell. Syst.},
  title        = {BPLC + NOSO: Backpropagation of errors based on latency code with neurons that only spike once at most},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-objective two-stage emergent blood
transshipment-allocation in COVID-19 epidemic. <em>CIS</em>,
<em>9</em>(5), 4939–4957. (<a
href="https://doi.org/10.1007/s40747-023-00976-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of blood transshipment and allocation in the context of the COVID-19 epidemic has many new characteristics, such as two-stage, trans-regional, and multi-modal transportation. Considering these new characteristics, we propose a novel multi-objective optimization model for the two-stage emergent blood transshipment-allocation. The objectives considered are to optimize the quality of transshipped blood, the satisfaction of blood demand, and the overall cost including shortage penalty. An improved integer encoded hybrid multi-objective whale optimization algorithm (MOWOA) with greedy rules is then designed to solve the model. Numerical experiments demonstrate that our two-stage model is superior to one-stage optimization methods on all objectives. The degree of improvement ranges from 0.69 to 66.26%.},
  archive      = {J_CIS},
  author       = {Zhou, Yufeng and Cheng, Jiahao and Wu, Changzhi and Teo, Kok Lay},
  doi          = {10.1007/s40747-023-00976-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {4939-4957},
  shortjournal = {Complex Intell. Syst.},
  title        = {Multi-objective two-stage emergent blood transshipment-allocation in COVID-19 epidemic},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A efficient and robust privacy-preserving framework for
cross-device federated learning. <em>CIS</em>, <em>9</em>(5), 4923–4937.
(<a href="https://doi.org/10.1007/s40747-023-00978-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To ensure no private information is leaked in the aggregation phase in federated learning (FL), many frameworks use homomorphic encryption (HE) to mask local model updates. However, the heavy overheads of these frameworks make them unsuitable for cross-device FL, where the clients are a huge number of mobile and edge devices with limited computing resources. Even worse, some of them also fail to manage the dynamic changes of clients. To overcome these shortcomings, we propose a threshold multi-key HE scheme tMK-CKKS and design an efficient and robust privacy-preserving FL framework. Robustness means that our framework allows clients to join in or drop out during the training process. Besides, because our tMK-CKKS scheme can pack multiple messages in a single ciphertext, our framework significantly reduces the computation and communication overhead. Moreover, the threshold mechanism in tMK-CKKS ensures that our framework can resist collusion attacks between the server and no more than t (threshold value) curious internal clients. Finally, we implement our framework in FedML and conduct extensive experiments to evaluate our framework. Utility evaluations on 6 benchmark datasets show that our framework can protect privacy without sacrificing the model accuracy. Efficiency evaluations on 4 typical deep learning models demonstrate that: our framework can speed up the computation by at least 1.21 $$\times $$ over xMK-CKKS-based framework, 15.84 $$\times $$ over Batchcrypt-based framework, and 20.30 $$\times $$ over CRT-Paillier-based framework. Our framework can reduce the communication burden by at least 8.61 MB over Batchcrypt-based framework, 35.36 MB over xMK-CKKS-based framework and 42.58 MB over CRT-Paillier-based framework. The advantages in both computation and communication expand with the size of deep learning models.},
  archive      = {J_CIS},
  author       = {Du, Weidong and Li, Min and Wu, Liqiang and Han, Yiliang and Zhou, Tanping and Yang, Xiaoyuan},
  doi          = {10.1007/s40747-023-00978-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {4923-4937},
  shortjournal = {Complex Intell. Syst.},
  title        = {A efficient and robust privacy-preserving framework for cross-device federated learning},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient state representation with artificial potential
fields for reinforcement learning. <em>CIS</em>, <em>9</em>(5),
4911–4922. (<a
href="https://doi.org/10.1007/s40747-023-00995-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the complex tasks environment, efficient state feature learning is a key factor to improve the performance of the agent’s policy. When encountering a similar new environment, reinforcement learning agents usually need to learn from scratch. However, humans naturally have a common sense of the environment and are able to use prior knowledge to extract environmental state features. Although the prior knowledge may not be fully applicable to the new environment, it is able to speed up the learning process of the state feature. Taking this inspiration, we propose an artificial potential field-based reinforcement learning (APF-RL) method. The method consists of an artificial potential field state feature abstractor (APF-SA) and an artificial potential field intrinsic reward model (APF-IR). The APF-SA can introduce human knowledge to accelerate the learning process of the state feature. The APF-IR can generate an intrinsic reward to reduce the invalid exploration and guide the learning of the agent’s policy. We conduct experiments on PySC2 with different mini-games. The experimental results show that the APF-RL method achieves improvement in the learning efficiency compared to the benchmarks.},
  archive      = {J_CIS},
  author       = {Jiang, Hao and Li, Shengze and Zhang, Jieyuan and Zhu, Yuqi and Xu, Xinhai and Liu, Donghong},
  doi          = {10.1007/s40747-023-00995-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {4911-4922},
  shortjournal = {Complex Intell. Syst.},
  title        = {Efficient state representation with artificial potential fields for reinforcement learning},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Developing explicit customer preference models using fuzzy
regression with nonlinear structure. <em>CIS</em>, <em>9</em>(5),
4899–4909. (<a
href="https://doi.org/10.1007/s40747-023-00986-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In online sales platforms, product design attributes influence consumer preferences, and consumer preferences also have a significant impact on future product design optimization and iteration. Online review data are the most intuitive feedback from consumers on products. Using the value of online review information to explore consumer preferences is the key to optimize the products, improve consumer satisfaction and meet consumer requirements. Therefore, the study of consumer preferences based on online reviews is of great importance. However, in previous research on consumer preferences based on online reviews, few studies have modeled consumer preferences. The models often suffer from the nonlinear structure and the fuzzy coefficients, making it challenging to build explicit models. Therefore, this study adopts a fuzzy regression approach with a nonlinear structure to model consumer preferences based on online reviews to provide reference and insight for subsequent studies. First, smartwatches were selected as the research object, and the sentiment scores of product reviews under different topics were obtained by text mining on the product online data. Second, a polynomial structure between product attributes and consumer preferences was generated to investigate the association between them further. Afterward, based on the existing polynomial structure, the fuzzy coefficients of each item in the structure were determined by the fuzzy regression approach. Finally, the mean relative error and mean systematic confidence of the fuzzy regression with nonlinear structure method were numerically calculated and compared with fuzzy least squares regression, fuzzy regression, adaptive neuro fuzzy inference system (ANFIS) and K-means-based ANFIS, and it was found that the proposed method was relatively more effective in modeling consumer preferences.},
  archive      = {J_CIS},
  author       = {Jiang, Huimin and Wu, Xianhui and Sabetzadeh, Farzad and Chan, Kit Yan},
  doi          = {10.1007/s40747-023-00986-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {4899-4909},
  shortjournal = {Complex Intell. Syst.},
  title        = {Developing explicit customer preference models using fuzzy regression with nonlinear structure},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cooperative multi-agent target searching: A deep
reinforcement learning approach based on parallel hindsight experience
replay. <em>CIS</em>, <em>9</em>(5), 4887–4898. (<a
href="https://doi.org/10.1007/s40747-023-00985-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent multi-target search strategies can be utilized in complex scenarios such as post-disaster search and rescue by unmanned aerial vehicles. To solve the problem of fixed target and trajectory, the current multi-agent multi-target search strategies are mainly based on deep reinforcement learning (DRL). However, the training of agents by the DRL tend to be brittle due to their sensitivity to the training environment, which makes the strategies learned by the agents fall into local optima frequently, resulting in poor system robustness. Additionally, sparse rewards in DRL will lead to the problems such as difficulty in system convergence and low utilization efficiency of the sampled data. To address the problem that the robustness of the agents is weakened and the sparse rewards exist in the multi-objective search environment, we propose a MiniMax Multi-agent Deep Deterministic Policy Gradient based on the Parallel Hindsight Experience Replay (PHER-M3DDPG) algorithm, which adopts the framework of centralized training and decentralized execution in continuous action space. To enhance the system robustness, the PHER-M3DDPG algorithm employs a minimax learning architecture, which adaptively adjusts the learning strategy of agents by involving adversarial disturbances. In addition, to solve the sparse rewards problem, the PHER-M3DDPG algorithm adopts a parallel hindsight experience replay mechanism to increase the efficiency of data utilization by involving virtual learning targets and batch processing of the sampled data. Simulation results show that the PHER-M3DDPG algorithm outperforms the existing algorithms in terms of convergence speed and the task completion time in a multi-target search environment.},
  archive      = {J_CIS},
  author       = {Zhou, Yi and Liu, Zhixiang and Shi, Huaguang and Li, Si and Ning, Nianwen and Liu, Fuqiang and Gao, Xiaozhi},
  doi          = {10.1007/s40747-023-00985-w},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {4887-4898},
  shortjournal = {Complex Intell. Syst.},
  title        = {Cooperative multi-agent target searching: A deep reinforcement learning approach based on parallel hindsight experience replay},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust tracking control of unknown models for space in-cabin
robots with a pneumatic continuum arm. <em>CIS</em>, <em>9</em>(5),
4869–4885. (<a
href="https://doi.org/10.1007/s40747-023-00980-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The service robots of space station in-cabin have attracted more and more attention. The space in-cabin robot with a pneumatic continuum arm is studied in this paper. It could be safer, more efficient and more flexible than the space rigid robot. However, the coupling motion of the moving base and the pneumatic continuum continuous arm brings a new challenge for controlling the end-effector to track the desired path. In this paper, a new control method based on the zeroing neural network (ZNN) is developed to solve the high-precision kinematics trajectory tracking control problem of unknown models. The real-time Jacobian matrix of the in-cabin robots with a pneumatic continuum arm is estimated by the input–output information when the parameter and the structure of the kinematic model are unknown. Moreover, this paper also employs a modified activation function power-sigmoid activation function (PSAF) to improve the robustness. In addition, it is proved through the Lyapunov stability theory that the proposed control approach is convergent and stable. Finally, the simulation results are given to show the effectiveness and robustness of the proposed control method for space in-cabin robots with a pneumatic continuum arm.},
  archive      = {J_CIS},
  author       = {Wang, Hui and Ma, Ke and Wu, Sihuan and Li, Minghao and Lian, Xiaobin and Zhang, Jinxiu},
  doi          = {10.1007/s40747-023-00980-1},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {4869-4885},
  shortjournal = {Complex Intell. Syst.},
  title        = {Robust tracking control of unknown models for space in-cabin robots with a pneumatic continuum arm},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A collaborative path planning method for mobile cable-driven
parallel robots in a constrained environment with considering kinematic
stability. <em>CIS</em>, <em>9</em>(5), 4857–4868. (<a
href="https://doi.org/10.1007/s40747-022-00915-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile cable-driven parallel robot (MCDPR) is a variant of cable-driven parallel robots (CDPRs) by mounting several mobile bases to replace the conventional fixed frame. The novel modification of adding mobile bases leads MCDPRs being highly flexible and have great potential for complex environments. However, the issue of coupled mobile bases introduces actuated kinematic redundancies which present challenges for path planning. In this paper, we propose a collaborative path planning method for MCDPRs, and it allows the robot to deal with complex internal and external constraints in a high-dimensional state space efficiently. The proposed method quickly generates feasible paths for coupled mobile bases using the adaptive goal-biased rapidly exploring random tree (RRT) method, in which the adaptive sampling method is developed to enhance efficiency. Based on the feasible path of the mobile base, we proposed a grid-based search method to determine the position of the end-effector with considering the stability and kinematic performances. Furthermore, the planned paths are post-processed with the cubic splines to obtain continuous profiles for the robot. Finally, the proposed method is validated through the dynamic simulation software (CoppeliaSim) and experiments based on a MCDPR prototype with an eight-cable-driven parallel robot mounted on four mobile bases.},
  archive      = {J_CIS},
  author       = {Xu, Jiajun and Kim, Byeong-Geon and Park, Kyoung-Su},
  doi          = {10.1007/s40747-022-00915-2},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {4857-4868},
  shortjournal = {Complex Intell. Syst.},
  title        = {A collaborative path planning method for mobile cable-driven parallel robots in a constrained environment with considering kinematic stability},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ST-MAE: Robust lane detection in continuous multi-frame
driving scenes based on a deep hybrid network. <em>CIS</em>,
<em>9</em>(5), 4837–4855. (<a
href="https://doi.org/10.1007/s40747-022-00909-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lane detection is one of the key techniques to realize advanced driving assistance and automatic driving. However, lane detection networks based on deep learning have significant shortcomings. The detection results are often unsatisfactory when there are shadows, degraded lane markings, and vehicle occlusion lanes. Therefore, a continuous multi-frame image sequence lane detection network is proposed. Specifically, the continuous six-frame image sequence is input into the network, in which the scene information of each frame image is extracted by an encoder composed of Swin Transformer blocks and input into the PredRNN. Continuous multi-frame of the driving scene is modeled as time-series by ST-LSTM blocks, and then, the shape changes and motion trajectory in the spatiotemporal sequence are effectively modeled. Finally, through the decoder composed of Swin Transformer blocks, the features are obtained and reconstructed to complete the detection task. Extensive experiments on two large-scale datasets demonstrate that the proposed method outperforms the competing methods in lane detection, especially in handling difficult situations. Experiments are carried out based on the TuSimple dataset. The results show: for easy scenes, the validation accuracy is 97.46%, the test accuracy is 97.37%, and the precision is 0.865. For complex scenes, the validation accuracy is 97.38%, the test accuracy is 97.29%, and the precision is 0.859. The running time is 4.4 ms. Experiments are carried out based on the CULane dataset. The results show that, for easy scenes, the validation accuracy is 97.03%, the test accuracy is 96.84%, and the precision is 0.837. For complex scenes, the validation accuracy is 96.18%, the test accuracy is 95.92%, and the precision is 0.829. The running time is 6.5 ms.},
  archive      = {J_CIS},
  author       = {Zhang, Rongyun and Du, Yufeng and Shi, Peicheng and Zhao, Lifeng and Liu, Yaming and Li, Haoran},
  doi          = {10.1007/s40747-022-00909-0},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {4837-4855},
  shortjournal = {Complex Intell. Syst.},
  title        = {ST-MAE: Robust lane detection in continuous multi-frame driving scenes based on a deep hybrid network},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient s-box construction based on quantum-inspired
quantum walks with PSO algorithm and its application to image
cryptosystem. <em>CIS</em>, <em>9</em>(5), 4817–4835. (<a
href="https://doi.org/10.1007/s40747-023-00988-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Amidst the growth of the internet and communication technologies, the requirements for the security of data transmitted via these technologies are increasing. Visual data, like images and videos, are commonly utilized for representing the majority of data due to its having more detailed information. Until now, the physical implementation of quantum computers does not have enough capability for hacking any traditional image cryptosystem, but amidst the growth of quantum resources, enough capability may be available in the near future. Most data represented by images has a long lifetime, like personal, medical, military, etc. Therefore, new quantum-inspired-based designs for image cryptosystems are required to be performed on digital resources and have the capability of defying the potential attacks from digital and quantum resources. In this study, a new substitution box (S-box) mechanism is proposed, which is based on quantum-inspired quantum walks, Hénon map, and a customized particle swarm optimization algorithm. Performance analysis of the suggested S-box proves its effectiveness and its reliability in designing various cryptosystems. Based on the effectiveness of the presented S-box, a new image cryptosystem is proposed, in which its experiential outcomes prove its efficacy and security against various attacks. The average outcome of entropy is 7.99977, UACI is 33.484%, NPCR is 99.618%, and Chi-square is 249.481 for the constructed cipher images.},
  archive      = {J_CIS},
  author       = {Abd-El-Atty, Bassem},
  doi          = {10.1007/s40747-023-00988-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {4817-4835},
  shortjournal = {Complex Intell. Syst.},
  title        = {Efficient S-box construction based on quantum-inspired quantum walks with PSO algorithm and its application to image cryptosystem},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BRCE: Bi-roles co-evolution for energy-efficient distributed
heterogeneous permutation flow shop scheduling with flexible machine
speed. <em>CIS</em>, <em>9</em>(5), 4805–4816. (<a
href="https://doi.org/10.1007/s40747-023-00984-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed manufacturing is the mainstream model to accelerate production. However, the heterogeneous production environment makes engineer hard to find the optimal scheduling. This work investigates the energy-efficient distributed heterogeneous permutation flow scheduling problem with flexible machine speed (DHPFSP-FMS) with minimizing makespan and energy consumption simultaneously. In DHPFSP-FMS, the local search misleads the population falling into local optima which reduces the convergence and diversity. To solve this problem, a bi-roles co-evolutionary algorithm is proposed which contains the following improvements: First, the global search and local search is divided into two swarms producer and consumer to balance computation. Second, three heuristic rules are designed to get a high-quality initialization population. Next, five problem-based local search strategies are designed to accelerate converging. Then, an efficient energy-saving strategy is presented to save energy. Finally, to verify the performance of the proposed algorithm, 22 instances are generated based on the Taillard benchmark, and a number of numerical experiments are adopted. The experiment results state that our algorithm is superior to the state-of-arts and more efficient for DHPFSP-FMS.},
  archive      = {J_CIS},
  author       = {Huang, Kuihua and Li, Rui and Gong, Wenyin and Wang, Rui and Wei, Heng},
  doi          = {10.1007/s40747-023-00984-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {4805-4816},
  shortjournal = {Complex Intell. Syst.},
  title        = {BRCE: Bi-roles co-evolution for energy-efficient distributed heterogeneous permutation flow shop scheduling with flexible machine speed},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A visually meaningful double-image encryption scheme using
2D compressive sensing and multi-rule DNA encoding. <em>CIS</em>,
<em>9</em>(5), 4783–4803. (<a
href="https://doi.org/10.1007/s40747-023-00989-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A visually meaningful double-image encryption scheme using 2D compressive sensing and multi-rule DNA encoding is presented. First, scrambling, diffusing and 2D compressive sensing are performed on the two plain images, and two privacy images are obtained, respectively. Then, the two privacy images are re-encrypted using DNA encoding theory to obtain two secret images. Finally, integer wavelet transform (IWT) is performed on the carrier image to obtain the wavelet coefficients, then the two secret images are embedded into the wavelet coefficients and 2k correction is performed, and the obtained result is processed by inverse IWT to obtain a visually meaningful encrypted image. DNA encoding rules selected for the pixel values of different positions in the two privacy images, and DNA operations performed between the two privacy images and the key streams at different positions are controlled by the chaotic system. The application of 2D compressive sensing reduces the amount of data, thus increasing the encryption capacity of the system. The introduction of DNA encoding theory and the double-image embedding process increases the security of the system. The simulation results demonstrate the feasibility of the scheme, and it has high data security and visual security.},
  archive      = {J_CIS},
  author       = {Huo, Dongming and Qiu, Yueyou and Han, Chao and Wei, Lisheng and Hong, Yao and Zhu, Zhilong and Zhou, Xin},
  doi          = {10.1007/s40747-023-00989-6},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {4783-4803},
  shortjournal = {Complex Intell. Syst.},
  title        = {A visually meaningful double-image encryption scheme using 2D compressive sensing and multi-rule DNA encoding},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Designing pentapartitioned neutrosophic cubic set
aggregation operator-based air pollution decision-making model.
<em>CIS</em>, <em>9</em>(5), 4765–4782. (<a
href="https://doi.org/10.1007/s40747-023-00971-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Environmental pollution is a global concern that has economic and health implications. Therefore, proper estimation using precise modeling can help in decision-making to address this externality. In science and engineering, there are a lot of different theories to help deal with the complex frame of the environment. The prime objective of these theories is to impart a plan of action to handle fuzzy data more precisely. Furthermore, humans need a platform that can correctly assign a value to optimize credence in a belief system. The indeterminacy is further classified into contradiction, ignorance, and unknown by a pentapartitioned neutrosophic set. On the other hand, a cubic set characterizes both the combined and the crisp value. The study introduces pentapartitioned neutrosophic cubic set, as it illustrates all of these attributes, allowing credence to be appropriately handled. The study also explained its operational laws and aggregation operators. Finally, this technique is used to develop and evaluate the air pollution models in major Pakistani cities like Karachi, Lahore, Islamabad, and Peshawar. It will help the legislators to reevaluate current policies to mitigate this externality.},
  archive      = {J_CIS},
  author       = {Li, Yi-ming and Khan, Majid and Khurshid, Adnan and Gulistan, Muhammad and Rehman, Ateeq Ur and Ali, Mumtaz and Abdulla, Shahab and Farooque, Aitazaz A.},
  doi          = {10.1007/s40747-023-00971-2},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {4765-4782},
  shortjournal = {Complex Intell. Syst.},
  title        = {Designing pentapartitioned neutrosophic cubic set aggregation operator-based air pollution decision-making model},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SimDCL: Dropout-based simple graph contrastive learning for
recommendation. <em>CIS</em>, <em>9</em>(5), 4751–4763. (<a
href="https://doi.org/10.1007/s40747-023-00974-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation learning of users and items is the core of recommendation, and benefited from the development of graph neural network (GNN), graph collaborative filtering (GCF) for capturing higher order connectivity has been successful in the recommendation domain. Nevertheless, the matrix sparsity problem in collaborative filtering and the tendency of higher order embeddings to smooth in GNN limit further performance improvements. Contrastive learning (CL) was introduced into GCF and alleviated these problems to some extent. However, existing methods usually require graph perturbation to construct augmented views or design complex CL tasks, which limits the further development of CL-based methods in the recommendation. We propose a simple CL framework that does not require graph augmentation, but is based on dropout techniques to generate contrastive views to address the aforementioned problem. Specifically, we first added dropout operation to the GNN computation, and then fed the same batch of samples twice into the network for computation. Using the randomness of dropout, a pair of views with random noise was obtained, and maximizing the similarity of the view pairs is set as an auxiliary task to complement the recommendation. In addition, we made a simple modification to the computation of the GNN to alleviate the information loss due to embedding smoothing by means of cross-layer connected graph convolution computation. We named our proposed method as Simple Contrastive Learning Graph Neural Network based on dropout (SimDCL). Extensive experiments on five public datasets demonstrate the effectiveness of the proposed SimDCL, especially on the Amazon Books and Ta-Feng datasets, where our approach achieves 44% and 43% performance gains compared to baseline.},
  archive      = {J_CIS},
  author       = {Xu, YuHao and Wang, ZhenHai and Wang, ZhiRu and Guo, YunLong and Fan, Rong and Tian, HongYu and Wang, Xing},
  doi          = {10.1007/s40747-023-00974-z},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {4751-4763},
  shortjournal = {Complex Intell. Syst.},
  title        = {SimDCL: Dropout-based simple graph contrastive learning for recommendation},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RBUE: A ReLU-based uncertainty estimation method for
convolutional neural networks. <em>CIS</em>, <em>9</em>(5), 4735–4749.
(<a href="https://doi.org/10.1007/s40747-023-00973-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have successfully demonstrated their powerful predictive performance in a variety of tasks. However, it remains a challenge to estimate the uncertainty of these predictions simply and accurately. Deep Ensemble is widely considered the state-of-the-art method which can estimate the uncertainty accurately, but it is expensive to train and test. MC-Dropout is another popular method that is less costly but lacks the diversity of predictions resulting in less accurate uncertainty estimates. To combine the benefits of both, we introduce a ReLU-Based Uncertainty Estimation (RBUE) method. Instead of using the randomness of the Dropout module during the test phase (MC-Dropout) or using the randomness of the initial weights of CNNs (Deep Ensemble), RBUE uses the randomness of activation function to obtain diverse outputs in the testing phase to estimate uncertainty. Under the method, we propose strategy MC-DropReLU and develop strategy MC-RReLU. The uniform distribution of the activation function’s position in CNNs allows the randomness to be well transferred to the output results and gives a more diverse output, thus improving the accuracy of the uncertainty estimation. Moreover, our method is simple to implement and does not need to modify the existing model. We experimentally validate the RBUE on three widely used datasets, CIFAR10, CIFAR100, and TinyImageNet. The experiments demonstrate that our method has competitive performance but is more favorable in training time.},
  archive      = {J_CIS},
  author       = {Xia, Yufeng and Zhang, Jun and Gong, Zhiqiang and Jiang, Tingsong and Yao, Wen},
  doi          = {10.1007/s40747-023-00973-0},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {10},
  number       = {5},
  pages        = {4735-4749},
  shortjournal = {Complex Intell. Syst.},
  title        = {RBUE: A ReLU-based uncertainty estimation method for convolutional neural networks},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiple sparse detection-based evolutionary algorithm for
large-scale sparse multiobjective optimization problems. <em>CIS</em>,
<em>9</em>(4), 4369–4388. (<a
href="https://doi.org/10.1007/s40747-022-00963-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse multiobjective optimization problems are common in practical applications. Such problems are characterized by large-scale decision variables and sparse optimal solutions. General large-scale multiobjective optimization problems (LSMOPs) have been extensively studied for many years. They can be well solved by many excellent custom algorithms. However, when these algorithms are used to deal with sparse LSMOPs, they often encounter difficulties because the sparse nature of the problem is not considered. Therefore, aiming at sparse LSMOPs, an algorithm based on multiple sparse detection is proposed in this paper. The algorithm applies an adaptive sparse genetic operator that can generate sparse solutions by detecting the sparsity of individuals. To improve the deficiency of sparse detection caused by local detection, an enhanced sparse detection (ESD) strategy is proposed in this paper. The strategy uses binary coefficient vectors to integrate the masks of nondominated solutions. Essentially, the mask is globally and deeply optimized by coefficient vectors to enhance the sparsity of the solutions. In addition, the algorithm adopts an improved weighted optimization strategy to fully optimize the key nonzero variables to balance exploration and optimization. Finally, the proposed algorithm is named MOEA-ESD and is compared to the current state-of-the-art algorithm to verify its effectiveness.},
  archive      = {J_CIS},
  author       = {Ren, Jin and Qiu, Feiyue and Hu, Huizhen},
  doi          = {10.1007/s40747-022-00963-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {4369-4388},
  shortjournal = {Complex Intell. Syst.},
  title        = {Multiple sparse detection-based evolutionary algorithm for large-scale sparse multiobjective optimization problems},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CenterLoc3D: Monocular 3D vehicle localization network for
roadside surveillance cameras. <em>CIS</em>, <em>9</em>(4), 4349–4368.
(<a href="https://doi.org/10.1007/s40747-022-00962-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monocular 3D vehicle localization is an important task for vehicle behaviour analysis, traffic flow parameter estimation and autonomous driving in Intelligent Transportation System (ITS) and Cooperative Vehicle Infrastructure System (CVIS), which is usually achieved by monocular 3D vehicle detection. However, monocular cameras cannot obtain depth information directly due to the inherent imaging mechanism, resulting in more challenging monocular 3D tasks. Currently, most of the monocular 3D vehicle detection methods still rely on 2D detectors and additional geometric constraint modules to recover 3D vehicle information, which reduces the efficiency. At the same time, most of the research is based on datasets of onboard scenes, instead of roadside perspective, which is limited in large-scale 3D perception. Therefore, we focus on 3D vehicle detection without 2D detectors in roadside scenes. We propose a 3D vehicle localization network CenterLoc3D for roadside monocular cameras, which directly predicts centroid and eight vertexes in image space, and the dimension of 3D bounding boxes without 2D detectors. To improve the precision of 3D vehicle localization, we propose a multi-scale weighted-fusion module and a loss with spatial constraints embedded in CenterLoc3D. Firstly, the transformation matrix between 2D image space and 3D world space is solved by camera calibration. Secondly, vehicle type, centroid, eight vertexes, and the dimension of 3D vehicle bounding boxes are obtained by CenterLoc3D. Finally, centroid in 3D world space can be obtained by camera calibration and CenterLoc3D for 3D vehicle localization. To the best of our knowledge, this is the first application of 3D vehicle localization for roadside monocular cameras. Hence, we also propose a benchmark for this application including a dataset (SVLD-3D), an annotation tool (LabelImg-3D), and evaluation metrics. Through experimental validation, the proposed method achieves high accuracy with $$A{P_{3D}}$$ of 51.30%, average 3D localization precision of 98%, average 3D dimension precision of 85% and real-time performance with FPS of 41.18.},
  archive      = {J_CIS},
  author       = {Tang, Xinyao and Wang, Wei and Song, Huansheng and Zhao, Chunhui},
  doi          = {10.1007/s40747-022-00962-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {4349-4368},
  shortjournal = {Complex Intell. Syst.},
  title        = {CenterLoc3D: Monocular 3D vehicle localization network for roadside surveillance cameras},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NCT: Noise-control multi-object tracking. <em>CIS</em>,
<em>9</em>(4), 4331–4347. (<a
href="https://doi.org/10.1007/s40747-022-00946-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Object Tracking (MOT) is an important topic in computer vision. Recent MOT methods based on the anchor-free paradigm trade complicated hierarchical structures for tracking performance. However, existing anchor-free MOT methods ignore the noise in detection, data association, and trajectory reconnection stages, which results in serious problems, such as missing detection of small objects, insufficient motion information, and trajectory drifting. To solve these problems, this paper proposes Noise-Control Tracker (NCT), which focuses on the noise-control design of detection, association, and reconnection. First, a prior depth denoise method is introduced to suppress the fusion feature redundant noise, which can recover the gradient information of the heatmap fusion features. Then, the Smoothing Gain Kalman filter is designed, which combines the Gaussian function with the adaptive observation coefficient matrix to stabilize the mutation noise of Kalman gain. Finally, to address the drift noise issue, the gradient boosting reconnection context mechanism is designed, which realizes adaptive trajectory reconnection to effectively fill the gaps in trajectories. With the assistance of the plug-and-play noise-control method, the experimental results on MOTChallenge 16 &amp;17 datasets indicate that the NCT can achieve better performance than other state-of-the-art trackers.},
  archive      = {J_CIS},
  author       = {Zeng, Kai and You, Yujie and Shen, Tao and Wang, Qingwang and Tao, Zhimin and Wang, Zhifeng and Liu, Quanjun},
  doi          = {10.1007/s40747-022-00946-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {4331-4347},
  shortjournal = {Complex Intell. Syst.},
  title        = {NCT: Noise-control multi-object tracking},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DAACO: Adaptive dynamic quantity of ant ACO algorithm to
solve the traveling salesman problem. <em>CIS</em>, <em>9</em>(4),
4317–4330. (<a
href="https://doi.org/10.1007/s40747-022-00949-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traveling salesman problem (TSP) is an NP-hard problem. Thus far, a large number of researchers have proposed different ant colony optimization (ACO) algorithms to solve the TSP. These algorithms inevitably encounter problems such as long convergence time and the tendency to easily fall into local optima. On the basis of the ACO algorithm, this study proposes a dynamic adaptive ACO algorithm (DAACO). DAACO realizes the diversity of initialization of the ACO algorithm by dynamically determining the number of ants to be prevented from falling into local optimization. DAACO also adopts a hybrid local selection strategy to increase the quality of ant optimization and reduce the optimization time. Among the 20 instances of the TSPLIB dataset, the DAACO algorithm obtains 19 optimal values, and the solutions of 10 instances are better than those of other algorithms. The experimental results on the TSPLIB dataset show that the DAACO algorithm has obvious advantages in terms of convergence time, solution quality, and average value relative to existing state-of-the-art ACO algorithms.},
  archive      = {J_CIS},
  author       = {Liu, Huijun and Lee, Ao and Lee, Wenshi and Guo, Ping},
  doi          = {10.1007/s40747-022-00949-6},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {4317-4330},
  shortjournal = {Complex Intell. Syst.},
  title        = {DAACO: Adaptive dynamic quantity of ant ACO algorithm to solve the traveling salesman problem},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A bidirectional trajectory contrastive learning model for
driving intention prediction. <em>CIS</em>, <em>9</em>(4), 4301–4315.
(<a href="https://doi.org/10.1007/s40747-022-00945-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driving intention prediction with trajectory data of surrounding vehicles is critical to advanced driver assistance system for improving the accuracy of decision-making. Previous works mostly focused on trajectory representation based on supervised manners. However, learning generalized and high-quality representations from unlabeled data remains a very challenging task. In this paper, we propose a self-supervised bidirectional trajectory contrastive learning (BTCL) model that learns generalized trajectory representation to improve the performance of the driving intention prediction task. Different trajectory data augmentation strategies and a cross-view trajectory prediction task are constructed jointly as pretext task of contrastive learning. The pretext task can maximize the similarity among different augmentations of the same sample while minimizing similarity among augmentations of different samples. It can not only learn the high-quality representation of trajectory without labeled information but also improve the adversarial attacks on BTCL. Moreover, considering the vehicle trajectory forward and backward follows the same social norms and driving behavior constraints. A bidirectional trajectory contrastive learning module is built to gain more positive samples that further increasing the prediction accuracy in downstream tasks and transfer ability of the model. Experimental results demonstrate that BTCL is competitive with the state-of-the-art, especially for adversarial attack and transfer learning tasks, on real-world HighD and NGSIM datasets.},
  archive      = {J_CIS},
  author       = {Zhou, Yi and Wang, Huxiao and Ning, Nianwen and Wang, Zhangyun and Zhang, Yanyu and Liu, Fuqiang},
  doi          = {10.1007/s40747-022-00945-w},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {4301-4315},
  shortjournal = {Complex Intell. Syst.},
  title        = {A bidirectional trajectory contrastive learning model for driving intention prediction},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DM-DQN: Dueling munchausen deep q network for robot path
planning. <em>CIS</em>, <em>9</em>(4), 4287–4300. (<a
href="https://doi.org/10.1007/s40747-022-00948-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to achieve collision-free path planning in complex environment, Munchausen deep Q-learning network (M-DQN) is applied to mobile robot to learn the best decision. On the basis of Soft-DQN, M-DQN adds the scaled log-policy to the immediate reward. The method allows agent to do more exploration. However, the M-DQN algorithm has the problem of slow convergence. A new and improved M-DQN algorithm (DM-DQN) is proposed in the paper to address the problem. First, its network structure was improved on the basis of M-DQN by decomposing the network structure into a value function and an advantage function, thus decoupling action selection and action evaluation and speeding up its convergence, giving it better generalization performance and enabling it to learn the best decision faster. Second, to address the problem of the robot’s trajectory being too close to the edge of the obstacle, a method of using an artificial potential field to set a reward function is proposed to drive the robot’s trajectory away from the vicinity of the obstacle. The result of simulation experiment shows that the method learns more efficiently and converges faster than DQN, Dueling DQN and M-DQN in both static and dynamic environments, and is able to plan collision-free paths away from obstacles.},
  archive      = {J_CIS},
  author       = {Gu, Yuwan and Zhu, Zhitao and Lv, Jidong and Shi, Lin and Hou, Zhenjie and Xu, Shoukun},
  doi          = {10.1007/s40747-022-00948-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {4287-4300},
  shortjournal = {Complex Intell. Syst.},
  title        = {DM-DQN: Dueling munchausen deep q network for robot path planning},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multiscale convolution neural network for bearing fault
diagnosis based on frequency division denoising under complex noise
conditions. <em>CIS</em>, <em>9</em>(4), 4263–4285. (<a
href="https://doi.org/10.1007/s40747-022-00925-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The condition of bearings has a significant impact on the healthy operation of mechanical equipment, which leads to a tremendous attention on fault diagnosis algorithms. However, due to the complex working environment and severe noise interference, training a robust bearing fault diagnosis model is considered to be a difficult task. To address this problem, a multiscale frequency division denoising network (MFDDN) model is proposed, where the frequency division denoising modules are presented to extract the detail fault features, and multiscale convolution neural network is employed to learn and enrich the overall fault features through two-scale convolution channels communication. The stacking convolution pooling layers are adopted to deepen the large-scale convolution channel and learn abundant global features. To remove the noise in the small-scale convolution channel, the frequency division denoising layers are constructed based on wavelet analysis to acquire the features of noise, where the input feature map is separated into high frequency and low-frequency features, and a sub-network based on attention mechanism is established for adaptive denoising. The superior features of MFDDN are the fusion of important fault features at each scale and custom learning of fine-grained features for the adaptive denoising, which improves the network feature extraction capability and noise robustness. This paper compares the performance of MFDDN with several common bearing fault diagnosis models on two benchmark bearing fault datasets. Extensive experiments show the state-of-the-art performance including robustness, generalization, and accuracy compared to the other methods under complex noise environment.},
  archive      = {J_CIS},
  author       = {Wang, Youming and Cao, Gongqing},
  doi          = {10.1007/s40747-022-00925-0},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {4263-4285},
  shortjournal = {Complex Intell. Syst.},
  title        = {A multiscale convolution neural network for bearing fault diagnosis based on frequency division denoising under complex noise conditions},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid temporal convolutional network and prophet model
for power load forecasting. <em>CIS</em>, <em>9</em>(4), 4249–4261. (<a
href="https://doi.org/10.1007/s40747-022-00952-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and effective power system load forecasting is an important prerequisite for the safe and stable operation of the power grid and the normal production and operation of society. In recent years, convolutional neural networks (CNNs) have been widely used in time series prediction due to their parallel computing and other characteristics, but it is difficult for CNNs to capture the relationship of sequence context and meanwhile, it easily leads to information leakage. To avoid the drawbacks of CNNs, we adopt a temporal convolutional network (TCN), specially designed for time series. TCN combines causal convolution, dilated convolution, and residual connection, and fully considers the causal correlation between historical data and future data. Considering that the power load data has strong periodicity and is greatly influenced by seasons and holidays, we adopt the Prophet model to decompose the load data and fit the trend component, season component, and holiday component. We use TCN and Prophet to forecast the power load data respectively, and then use the least square method to fuse the two models, and make use of their respective advantages to improve the forecasting accuracy. Experiments show that the proposed TCN-Prophet model has a higher prediction accuracy than the classic ARIMA, RNN, LSTM, GRU, and some ensemble models, and can provide more effective decision-making references for power grid departments.},
  archive      = {J_CIS},
  author       = {Mo, Jinyuan and Wang, Rui and Cao, Mengda and Yang, Kang and Yang, Xu and Zhang, Tao},
  doi          = {10.1007/s40747-022-00952-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {4249-4261},
  shortjournal = {Complex Intell. Syst.},
  title        = {A hybrid temporal convolutional network and prophet model for power load forecasting},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A cross-domain fruit classification method based on
lightweight attention networks and unsupervised domain adaptation.
<em>CIS</em>, <em>9</em>(4), 4227–4247. (<a
href="https://doi.org/10.1007/s40747-022-00955-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image-based fruit classification offers many useful applications in industrial production and daily life, such as self-checkout in the supermarket, automatic fruit sorting and dietary guidance. However, fruit classification task will have different data distributions due to different application scenarios. One feasible solution to solve this problem is to use domain adaptation that adapts knowledge from the original training data (source domain) to the new testing data (target domain). In this paper, we propose a novel deep learning-based unsupervised domain adaptation method for cross-domain fruit classification. A hybrid attention module is proposed and added to MobileNet V3 to construct the HAM-MobileNet that can suppress the impact of complex backgrounds and extract more discriminative features. A hybrid loss function combining subdomain alignment and implicit distribution metrics is used to reduce domain discrepancy during model training and improve model classification performance. Two fruit classification datasets covering several domains are established to simulate common industrial and daily life application scenarios. We validate the proposed method on our constructed grape classification dataset and general fruit classification dataset. The experimental results show that the proposed method achieves an average accuracy of 95.0% and 93.2% on the two datasets, respectively. The classification model after domain adaptation can well overcome the domain discrepancy brought by different fruit classification scenarios. Meanwhile, the proposed datasets and method can serve as a benchmark for future cross-domain fruit classification research.},
  archive      = {J_CIS},
  author       = {Wang, Jin and Zhang, Cheng and Yan, Ting and Yang, Jingru and Lu, Xiaohui and Lu, Guodong and Huang, Bincheng},
  doi          = {10.1007/s40747-022-00955-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {4227-4247},
  shortjournal = {Complex Intell. Syst.},
  title        = {A cross-domain fruit classification method based on lightweight attention networks and unsupervised domain adaptation},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust neural dynamics with adaptive coefficient applied to
solve the dynamic matrix square root. <em>CIS</em>, <em>9</em>(4),
4213–4226. (<a
href="https://doi.org/10.1007/s40747-022-00954-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zeroing neural networks (ZNN) have shown their state-of-the-art performance on dynamic problems. However, ZNNs are vulnerable to perturbations, which causes reliability concerns in these models owing to the potentially severe consequences. Although it has been reported that some models possess enhanced robustness but cost worse convergence speed. In order to address these problems, a robust neural dynamic with an adaptive coefficient (RNDAC) model is proposed, aided by the novel adaptive activation function and robust evolution formula to boost convergence speed and preserve robustness accuracy. In order to validate and analyze the performance of the RNDAC model, it is applied to solve the dynamic matrix square root (DMSR) problem. Related experiment results show that the RNDAC model reliably solves the DMSR question perturbed by various noises. Using the RNDAC model, we are able to reduce the residual error from 10 $$^1$$ to 10 $$^{-4}$$ with noise perturbed and reached a satisfying and competitive convergence speed, which converges within 3 s.},
  archive      = {J_CIS},
  author       = {Jiang, Chengze and Wu, Chaomin and Xiao, Xiuchun and Lin, Cong},
  doi          = {10.1007/s40747-022-00954-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {4213-4226},
  shortjournal = {Complex Intell. Syst.},
  title        = {Robust neural dynamics with adaptive coefficient applied to solve the dynamic matrix square root},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Discrete matrix factorization cross-modal hashing with
multi-similarity consistency. <em>CIS</em>, <em>9</em>(4), 4195–4212.
(<a href="https://doi.org/10.1007/s40747-022-00950-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, matrix factorization-based hashing has gained wide attention because of its strong subspace learning ability and high search efficiency. However, some problems need to be further addressed. First, uniform hash codes can be generated by collective matrix factorization, but they often cause serious loss, degrading the quality of hash codes. Second, most of them preserve the absolute similarity simply in hash codes, failing to capture the inherent semantic affinity among training data. To overcome these obstacles, we propose a Discrete Multi-similarity Consistent Matrix Factorization Hashing (DMCMFH). Specifically, an individual subspace is first learned by matrix factorization and multi-similarity consistency for each modality. Then, the subspaces are aligned by a shared semantic space to generate homogenous hash codes. Finally, an iterative-based discrete optimization scheme is presented to reduce the quantization loss. We conduct quantitative experiments on three datasets, MSCOCO, Mirflickr25K and NUS-WIDE. Compared with supervised baseline methods, DMCMFH achieves increases of $$0.22\%$$ , $$3.00\%$$ and $$0.79\%$$ on the image-query-text tasks for three datasets respectively, and achieves increases of $$0.21\%$$ , $$1.62\%$$ and $$0.50\%$$ on the text-query-image tasks for three datasets respectively.},
  archive      = {J_CIS},
  author       = {Li, Yiru and Hu, Peiwen and Li, Ying and Peng, Shouyong and Zhang, Xiaofeng and Yue, Jun and Yao, Tao},
  doi          = {10.1007/s40747-022-00950-z},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {4195-4212},
  shortjournal = {Complex Intell. Syst.},
  title        = {Discrete matrix factorization cross-modal hashing with multi-similarity consistency},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Can financial stress be anticipated and explained?
Uncovering the hidden pattern using EEMD-LSTM, EEMD-prophet, and XAI
methodologies. <em>CIS</em>, <em>9</em>(4), 4169–4193. (<a
href="https://doi.org/10.1007/s40747-022-00947-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global financial stress is a critical variable that reflects the ongoing state of several key macroeconomic indicators and financial markets. Predictive analytics of financial stress, nevertheless, has seen very little focus in literature as of now. Futuristic movements of stress in markets can be anticipated if the same can be predicted with a satisfactory level of precision. The current research resorts to two granular hybrid predictive frameworks to discover the inherent pattern of financial stress across several critical variables and geography. The predictive structure utilizes the Ensemble Empirical Mode Decomposition (EEMD) for granular time series decomposition. The Long Short-Term Memory Network (LSTM) and Facebook’s Prophet algorithms are invoked on top of the decomposed components to scrupulously investigate the predictability of final stress variables regulated by the Office of Financial Research (OFR). A rigorous feature screening using the Boruta methodology has been utilized too. The findings of predictive exercises reveal that financial stress across assets and continents can be predicted accurately in short and long-run horizons even at the time of steep financial distress during the COVID-19 pandemic. The frameworks appear to be statistically significant at the expense of model interpretation. To resolve the issue, dedicated Explainable Artificial Intelligence (XAI) methods have been used to interpret the same. The immediate past information of financial stress indicators largely explains patterns in the long run, while short-run fluctuations can be tracked by closely monitoring several technical indicators.},
  archive      = {J_CIS},
  author       = {Ghosh, Indranil and Dragan, Pamucar},
  doi          = {10.1007/s40747-022-00947-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {4169-4193},
  shortjournal = {Complex Intell. Syst.},
  title        = {Can financial stress be anticipated and explained? uncovering the hidden pattern using EEMD-LSTM, EEMD-prophet, and XAI methodologies},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Resonance algorithm: An intuitive algorithm to find all
shortest paths between two nodes. <em>CIS</em>, <em>9</em>(4),
4159–4167. (<a
href="https://doi.org/10.1007/s40747-022-00942-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The shortest path problem (SPP) is a classic problem and appears in a wide range of applications. Although a variety of algorithms already exist, new advances are still being made, mainly tuned for particular scenarios to have better performances. As a result, they become more and more technically complex and sophisticated. In this paper, we developed an intuitive and nature-inspired algorithm to compute all possible shortest paths between two nodes in a graph: Resonance Algorithm (RA). It can handle any undirected, directed, or mixed graphs, irrespective of loops, unweighted or positively weighted edges, and can be implemented in a fully decentralized manner. Although the original motivation for RA is not the speed per se, in certain scenarios (when sophisticated matrix operations can be employed, and when the map is very large and all possible shortest paths are demanded), it out-competes Dijkstra’s algorithm, which suggests that in those scenarios, RA could also be practically useful.},
  archive      = {J_CIS},
  author       = {Liu, Yu and Lin, Qiguang and Hong, Binbin and Peng, Yunru and Hjerpe, Daniel and Liu, Xiaofeng},
  doi          = {10.1007/s40747-022-00942-z},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {4159-4167},
  shortjournal = {Complex Intell. Syst.},
  title        = {Resonance algorithm: An intuitive algorithm to find all shortest paths between two nodes},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analysis of hamming and hausdorff 3D distance measures for
complex pythagorean fuzzy sets and their applications in pattern
recognition and medical diagnosis. <em>CIS</em>, <em>9</em>(4),
4147–4158. (<a
href="https://doi.org/10.1007/s40747-022-00939-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Similarity measures are very effective and meaningful tool used for evaluating the closeness between any two attributes which are very important and valuable to manage awkward and complex information in real-life problems. Therefore, for better handing of fuzzy information in real life, Ullah et al. (Complex Intell Syst 6(1): 15–27, 2020) recently introduced the concept of complex Pythagorean fuzzy set (CPyFS) and also described valuable and dominant measures, called various types of distance measures (DisMs) based on CPyFSs. The theory of CPyFS is the essential modification of Pythagorean fuzzy set to handle awkward and complicated in real-life problems. Keeping the advantages of the CPyFS, in this paper, we first construct an example to illustrate that a DisM proposed by Ullah et al. does not satisfy the axiomatic definition of complex Pythagorean fuzzy DisM. Then, combining the 3D Hamming distance with the Hausdorff distance, we propose a new DisM for CPyFSs, which is proved to satisfy the axiomatic definition of complex Pythagorean fuzzy DisM. Moreover, similarly to some DisMs for intuitionistic fuzzy sets, we present some other new complex Pythagorean fuzzy DisMs. Finally, we apply our proposed DisMs to a building material recognition problem and a medical diagnosis problem to illustrate the effectiveness of our DisMs. Finally, we aim to compare the proposed work with some existing measures is to enhance the worth of the derived measures.},
  archive      = {J_CIS},
  author       = {Wu, Dong-Lun and Zhu, Zhiyi and Ullah, Kifayat and Liu, Lantian and Wu, Xinxing and Zhang, Xu},
  doi          = {10.1007/s40747-022-00939-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {4147-4158},
  shortjournal = {Complex Intell. Syst.},
  title        = {Analysis of hamming and hausdorff 3D distance measures for complex pythagorean fuzzy sets and their applications in pattern recognition and medical diagnosis},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid differential evolution algorithm for a
location-inventory problem in a closed-loop supply chain with product
recovery. <em>CIS</em>, <em>9</em>(4), 4123–4145. (<a
href="https://doi.org/10.1007/s40747-022-00930-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Product recovery is an important business because of its great economic, social, and environmental benefits in practice. In this paper, a location-inventory problem (LIP) in a closed-loop supply chain (CLSC) is investigated to optimize facility location and inventory control decisions by considering product recovery. The objective is to optimize facility location and inventory control decisions to minimize the total cost of business operations in a closed-loop supply chain system. We formulate this problem as a mixed-integer nonlinear programming model and design a modified hybrid differential evolution algorithm (MHDE) to solve it efficiently. Finally, numerical results are presented to validate the performance of the new algorithm. The results show that MHDE is more efficient and effective than Lingo and other algorithms for the research problem under study. Managerial insights are also derived for business managers to improve their supply chain performance.},
  archive      = {J_CIS},
  author       = {Guo, Hao and Liu, Gang and Zhang, Ying and Zhang, Chunnan and Xiong, Chuanhui and Li, Wenli},
  doi          = {10.1007/s40747-022-00930-3},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {4123-4145},
  shortjournal = {Complex Intell. Syst.},
  title        = {A hybrid differential evolution algorithm for a location-inventory problem in a closed-loop supply chain with product recovery},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-feature contrastive learning for unpaired
image-to-image translation. <em>CIS</em>, <em>9</em>(4), 4111–4122. (<a
href="https://doi.org/10.1007/s40747-022-00924-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unpaired image-to-image translation for the generation field has made much progress recently. However, these methods suffer from mode collapse because of the overfitting of the discriminator. To this end, we propose a straightforward method to construct a contrastive loss using the feature information of the discriminator output layer, which is named multi-feature contrastive learning (MCL). Our proposed method enhances the performance of the discriminator and solves the problem of model collapse by further leveraging contrastive learning. We perform extensive experiments on several open challenge datasets. Our method achieves state-of-the-art results compared with current methods. Finally, a series of ablation studies proved that our approach has better stability. In addition, our proposed method is also practical for single image translation tasks. Code is available at https://github.com/gouayao/MCL.},
  archive      = {J_CIS},
  author       = {Gou, Yao and Li, Min and Song, Yu and He, Yujie and Wang, Litao},
  doi          = {10.1007/s40747-022-00924-1},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {4111-4122},
  shortjournal = {Complex Intell. Syst.},
  title        = {Multi-feature contrastive learning for unpaired image-to-image translation},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven harris hawks constrained optimization for
computationally expensive constrained problems. <em>CIS</em>,
<em>9</em>(4), 4089–4110. (<a
href="https://doi.org/10.1007/s40747-022-00923-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the constrained optimization problem where function evaluation is time-consuming, this paper proposed a novel algorithm called data-driven Harris Hawks constrained optimization (DHHCO). In DHHCO, Kriging models are utilized to prospect potentially optimal areas by leveraging computationally expensive historical data during optimization. Three powerful strategies are, respectively, embedded into different phases of conventional Harris Hawks optimization (HHO) to generate diverse candidate sample data for exploiting around the existing sample data and exploring uncharted region. Moreover, a Kriging-based data-driven strategy composed of data-driven population construction and individual selection strategy is presented, which fully mines and utilizes the potential available information in the existing sample data. DHHCO inherits and develops HHO&#39;s offspring updating mechanism, and meanwhile exerts the prediction ability of Kriging, reduces the number of expensive function evaluations, and provides new ideas for data-driven constraint optimization. Comprehensive experiments have been conducted on 13 benchmark functions and a real-world expensive optimization problem. The experimental results suggest that the proposed DHHCO can achieve quite competitive performance compared with six representative algorithms and can find the near global optimum with 200 function evaluations for most examples. Moreover, DHHCO is applied to the structural optimization of the internal components of the real underwater vehicle, and the final satisfactory weight reduction effect is more than 18%.},
  archive      = {J_CIS},
  author       = {Fu, Chongbo and Dong, Huachao and Wang, Peng and Li, Yihong},
  doi          = {10.1007/s40747-022-00923-2},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {4089-4110},
  shortjournal = {Complex Intell. Syst.},
  title        = {Data-driven harris hawks constrained optimization for computationally expensive constrained problems},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Surrogated-assisted multimodal multi-objective optimization
for hybrid renewable energy system. <em>CIS</em>, <em>9</em>(4),
4075–4087. (<a
href="https://doi.org/10.1007/s40747-022-00943-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid renewable energy system (HRES) is an effective tool to improve the utilization of renewable energy so as to enhance the quality of energy supply. The optimization of HRES includes a simulation process during a long time span, which is time-consuming. So far, introducing a surrogate model to replace the objective evaluation is an effective way to solve such problems. However, existing methods focused few on the diversity of solutions in the decision space. Based on this motivation, we proposed a novel surrogated-assisted multi-objective evolutionary algorithm that focuses on solving multimodal and time-expensive problems, termed SaMMEA. Specifically, we use a Gaussian process model to replace the calculation of the objective values. In addition, a special environmental selection strategy is proposed to enhance the diversity of solutions in the decision space and a model management method is proposed to better train the surrogate model. The proposed algorithm is then compared to several state-of-the-art algorithms on HRES problems, which indicates that the proposed algorithm is competitive.},
  archive      = {J_CIS},
  author       = {Zhang, Tao and Li, Wenhua and Wang, Rui},
  doi          = {10.1007/s40747-022-00943-y},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {4075-4087},
  shortjournal = {Complex Intell. Syst.},
  title        = {Surrogated-assisted multimodal multi-objective optimization for hybrid renewable energy system},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LTF-NSI: A novel local transfer function based on
neighborhood similarity index for medical image enhancement.
<em>CIS</em>, <em>9</em>(4), 4061–4074. (<a
href="https://doi.org/10.1007/s40747-022-00941-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image is an essential tool used in quantitative and qualitative evaluation of different diseases. Medical imaging methods such as fluorescein angiography (FA), optical coherence tomography angiography (OCTA), computed tomography (CT), optical coherence tomography (OCT), and X-ray are used for diagnosis. These imaging modalities suffer from low contrast, which leads to deterioration in the image quality. Consequently, this causes limitation in the usage of medical images in clinical routine and hindered its potential by depriving clinicians from assessing useful information that are needed in disease monitoring, treatment, progression, and decision-making. To overcome this limitation, we propose a novel local transfer function for medical image enhancement algorithm using the pixel neighborhood constraint. The proposed algorithm uses block-wise intensity distribution to generate the regional similarity index. The regional similarity index transformed each centered pixel in the block, to generate a new similarity image. An intuitive optimization algorithm is utilized to optimize the proposed algorithm parameters. Experimentation results show that the proposed LTF-NSI performs better than the state-of-the-art methods and improves the interpretability and perception of the medical images, which can provide clinicians and computer vision program with good quantitative and qualitative information.},
  archive      = {J_CIS},
  author       = {Okuwobi, Idowu Paul and Ding, Zhixiang and Wan, Jifeng and Jiang, Jiajia and Ding, Shuxue},
  doi          = {10.1007/s40747-022-00941-0},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {4061-4074},
  shortjournal = {Complex Intell. Syst.},
  title        = {LTF-NSI: A novel local transfer function based on neighborhood similarity index for medical image enhancement},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Assessment of regional economic restorability under the
stress of COVID-19 using the new interval type-2 fuzzy ORESTE method.
<em>CIS</em>, <em>9</em>(4), 4025–4060. (<a
href="https://doi.org/10.1007/s40747-022-00928-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The economic implications from the COVID-19 crisis are not like anything people have ever experienced. As predictions indicated, it is not until the year 2025 may the global economy recover to the ideal situation as it was in 2020. Regions lacked of developing category is among the mostly affected regions, because the category includes weakly and averagely potential power. For supporting the decision of economic system recovery scientifically and accurately under the stress of COVID-19, one feasible solution is to assess the regional economic restorability by taking into account a variety of indicators, such as development foundation, industrial structure, labor forces, financial support and government&#39;s ability. This is a typical multi-criteria decision-making (MCDM) problem with quantitative and qualitative criteria/indicator. To solve this problem, in this paper, an investigation is conducted to obtain 14 indicators affecting regional economic restorability, which form an indicator system. The interval type-2 fuzzy set (IT2FS) is an effective tool to express experts’ subjective preference values (PVs) in the process of decision-making. First, some formulas are developed to convert quantitative PVs to IT2FSs. Second, an improved interval type-2 fuzzy ORESTE (IT2F-ORESTE) method based on distance and likelihood are developed to assess the regional economic restorability. Third, a case study is given to illustrate the method. Then, robust ranking results are acquired by performing a sensitivity analysis. Finally, some comparative analyses with other methods are conducted to demonstrate that the developed IT2F-ORESTE method can supporting the decision of economic system recovery scientifically and accurately.},
  archive      = {J_CIS},
  author       = {Zhang, Hui and Gao, Hui and Liu, Peide},
  doi          = {10.1007/s40747-022-00928-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {4025-4060},
  shortjournal = {Complex Intell. Syst.},
  title        = {Assessment of regional economic restorability under the stress of COVID-19 using the new interval type-2 fuzzy ORESTE method},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Study on non-iterative algorithms for center-of-sets
type-reduction of takagi–sugeno–kang type general type-2 fuzzy logic
systems. <em>CIS</em>, <em>9</em>(4), 4015–4023. (<a
href="https://doi.org/10.1007/s40747-022-00927-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper performs the center-of-sets (COS) type-reduction (TR) and de-fuzzification for Takagi–Sugeno–Kang (TSK) type general type-2 fuzzy logic systems (GT2 FLSs) on the basis of the $$\alpha$$ -planes expression of general type-2 fuzzy sets. Actually, comparing the popular Karnik–Mendel (KM) algorithms with other non-iterative algorithms is an important question in T2 society. Here the modules of fuzzy inference, COS TR, and de-fuzzification for TSK type GT2 FLSs are discussed by means of non-iterative Nagar–Bardini (NB) algorithms, Nie–Tan (NT) algorithms, and Begian–Melek–Mendel (BMM) algorithms. Simulation instances are constructed to illustrate the performances of three types of non-iterative algorithms compared with the KM algorithms. It is proved that, the proposed non-iterative algorithms can enhance the computational efficiencies significantly, which afford the potential application value for designers of GT2 FLSs.},
  archive      = {J_CIS},
  author       = {Chen, Yang},
  doi          = {10.1007/s40747-022-00927-y},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {4015-4023},
  shortjournal = {Complex Intell. Syst.},
  title        = {Study on non-iterative algorithms for center-of-sets type-reduction of Takagi–Sugeno–Kang type general type-2 fuzzy logic systems},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Modeling multiple latent information graph structures via
graph convolutional network for aspect-based sentiment analysis.
<em>CIS</em>, <em>9</em>(4), 4003–4014. (<a
href="https://doi.org/10.1007/s40747-022-00940-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) aims to determine the sentiment polarity of aspects in a sentence. Recently, graph convolution network (GCN) model combined with attention mechanism has been used for ABSA task over graph structures, achieving promising results. However, these methods of modeling over graph structure fail to consider multiple latent information in the text, i.e., syntax, semantics, context, and so on. In addition, the attention mechanism is vulnerable to noise in sentences. To tackle these problems, in this paper, we construct an efficient text graph and propose a matrix fusion-based graph convolution network (MFLGCN) for ABSA. First, the graph structure is constructed by combining statistics, semantics, and part of speech. Then, we use the sequence model combined with the multi-head self-attention mechanism to obtain the feature representation of the context. Subsequently, the text graph structure and the feature representation of context are fed into GCN to aggregate the information around aspect nodes. The attention matrix is obtained by combining sequence model, GCN and the attention mechanism. Besides, we design a filter layer to alleviate the noise problem in the sentence introduced by the attention mechanism. Finally, in order to make the context representation more effective, attention and filtering matrices are integrated into the model. Experimental results on four public datasets show that our model is more effective than the previous models, demonstrating that using our text graph and matrix fusion can significantly empower ABSA models.},
  archive      = {J_CIS},
  author       = {Wang, Jiajun and Li, Xiaoge and An, Xiaochun},
  doi          = {10.1007/s40747-022-00940-1},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {4003-4014},
  shortjournal = {Complex Intell. Syst.},
  title        = {Modeling multiple latent information graph structures via graph convolutional network for aspect-based sentiment analysis},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attention-guided video super-resolution with recurrent
multi-scale spatial–temporal transformer. <em>CIS</em>, <em>9</em>(4),
3989–4002. (<a
href="https://doi.org/10.1007/s40747-022-00944-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video super-resolution (VSR) aims to recover the high-resolution (HR) contents from the low-resolution (LR) observations relying on compositing the spatial–temporal information in the LR frames. It is crucial to propagate and aggregate spatial–temporal information. Recently, while transformers show impressive performance on high-level vision tasks, few attempts have been made on image restoration, especially on VSR. In addition, previous transformers simultaneously process spatial–temporal information, easily synthesizing confused textures and high computational cost limit its development. Towards this end, we construct a novel bidirectional recurrent VSR architecture. Our model disentangles the task of learning spatial–temporal information into two easier sub-tasks, each sub-task focuses on propagating and aggregating specific information with a multi-scale transformer-based design, which alleviates the difficulty of learning. Additionally, an attention-guided motion compensation module is applied to get rid of the influence of misalignment between frames. Experiments on three widely used benchmark datasets show that, relying on superior feature correlation learning, the proposed network can outperform previous state-of-the-art methods, especially for recovering the fine details.},
  archive      = {J_CIS},
  author       = {Sun, Wei and Kong, Xianguang and Zhang, Yanning},
  doi          = {10.1007/s40747-022-00944-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3989-4002},
  shortjournal = {Complex Intell. Syst.},
  title        = {Attention-guided video super-resolution with recurrent multi-scale spatial–temporal transformer},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HS-gen: A hypersphere-constrained generation mechanism to
improve synthetic minority oversampling for imbalanced classification.
<em>CIS</em>, <em>9</em>(4), 3971–3988. (<a
href="https://doi.org/10.1007/s40747-022-00938-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mitigating the impact of class-imbalance data on classifiers is a challenging task in machine learning. SMOTE is a well-known method to tackle this task by modifying class distribution and generating synthetic instances. However, most of the SMOTE-based methods focus on the phase of data selection, while few consider the phase of data generation. This paper proposes a hypersphere-constrained generation mechanism (HS-Gen) to improve synthetic minority oversampling. Unlike linear interpolation commonly used in SMOTE-based methods, HS-Gen generates a minority instance in a hypersphere rather than on a straight line. This mechanism expands the distribution range of minority instances with significant randomness and diversity. Furthermore, HS-Gen is attached with a noise prevention strategy that adaptively shrinks the hypersphere by determining whether new instances fall into the majority class region. HS-Gen can be regarded as an oversampling optimization mechanism and flexibly embedded into the SMOTE-based methods. We conduct comparative experiments by embedding HS-Gen into the original SMOTE, Borderline-SMOTE, ADASYN, k-means SMOTE, and RSMOTE. Experimental results show that the embedded versions can generate higher quality synthetic instances than the original ones. Moreover, on these oversampled datasets, the conventional classifiers (C4.5 and Adaboost) obtain significant performance improvement in terms of F1 measure and G-mean.},
  archive      = {J_CIS},
  author       = {He, Zuowei and Tao, Jiaqing and Leng, Qiangkui and Zhai, Junchang and Wang, Changzhong},
  doi          = {10.1007/s40747-022-00938-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3971-3988},
  shortjournal = {Complex Intell. Syst.},
  title        = {HS-gen: A hypersphere-constrained generation mechanism to improve synthetic minority oversampling for imbalanced classification},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid algorithm based on state-adaptive slime mold model
and fractional-order ant system for the travelling salesman problem.
<em>CIS</em>, <em>9</em>(4), 3951–3970. (<a
href="https://doi.org/10.1007/s40747-022-00932-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ant colony optimization (ACO) is one efficient approach for solving the travelling salesman problem (TSP). Here, we propose a hybrid algorithm based on state-adaptive slime mold model and fractional-order ant system (SSMFAS) to address the TSP. The state-adaptive slime mold (SM) model with two targeted auxiliary strategies emphasizes some critical connections and balances the exploration and exploitation ability of SSMFAS. The consideration of fractional-order calculus in the ant system (AS) takes full advantage of the neighboring information. The pheromone update rule of AS is modified to dynamically integrate the flux information of SM. To understand the search behavior of the proposed algorithm, some mathematical proofs of convergence analysis are given. The experimental results validate the efficiency of the hybridization and demonstrate that the proposed algorithm has the competitive ability of finding the better solutions on TSP instances compared with some state-of-the-art algorithms.},
  archive      = {J_CIS},
  author       = {Gong, Xiaoling and Rong, Ziheng and Wang, Jian and Zhang, Kai and Yang, Shengxiang},
  doi          = {10.1007/s40747-022-00932-1},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3951-3970},
  shortjournal = {Complex Intell. Syst.},
  title        = {A hybrid algorithm based on state-adaptive slime mold model and fractional-order ant system for the travelling salesman problem},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Does the one-size-fits-all setting meet the demand?
Assessment of setting EV–charging-capable parking spaces in public
parking lots based on agent simulation. <em>CIS</em>, <em>9</em>(4),
3937–3949. (<a
href="https://doi.org/10.1007/s40747-022-00845-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the rapid development of electric vehicles (EVs), the limited range and accessibility of charging infrastructure are still obstacles to the development of EVs. At present, the Chinese government has made great efforts to set up charging stations and the most popular construction mode of charging stations in China is to divide a certain proportion of parking spaces in the parking lot to build charge piles. The proportion for every parking lot is the same and recommended by the government, which is a one-size-fits-all construction strategy. Nevertheless, with the growth of EVs, some challenges arise such as how to improve the accessibility of charging facilities in hot parking lots. The current work addresses this challenge by correctly forecasting the charging demand of EVs based on simulation. In particular, in this paper, based on agent simulation technology, electric vehicle agent, fuel vehicle agent and parking lot agent are established to predict the charging demand and the Wulin business district of Hangzhou City is used as an example to predict the charging demand of nine public parking lots. Simulation results show that under the current number of EVs, this one-size-fits-all setting strategy can meet the demand with high accessibility. However, with the increasing of EVs, the spatial distribution of charging demand will be more uneven and a decline in system overall benefits will appear, considering both EVs charging and fuel vehicles parking. Given all this, an optimization method based on GA (Genetic Algorithm) is put forward and an optimized setting strategy is proposed.},
  archive      = {J_CIS},
  author       = {Mei, Zhenyu and Tang, Wei and Feng, Chi and Zhang, Lihui and Wang, Dianhai},
  doi          = {10.1007/s40747-022-00845-z},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3937-3949},
  shortjournal = {Complex Intell. Syst.},
  title        = {Does the one-size-fits-all setting meet the demand? assessment of setting EV–charging-capable parking spaces in public parking lots based on agent simulation},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Variable surrogate model-based particle swarm optimization
for high-dimensional expensive problems. <em>CIS</em>, <em>9</em>(4),
3887–3935. (<a
href="https://doi.org/10.1007/s40747-022-00910-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many industrial applications require time-consuming and resource-intensive evaluations of suitable solutions within very limited time frames. Therefore, many surrogate-assisted evaluation algorithms (SAEAs) have been widely used to optimize expensive problems. However, due to the curse of dimensionality and its implications, scaling SAEAs to high-dimensional expensive problems is still challenging. This paper proposes a variable surrogate model-based particle swarm optimization (called VSMPSO) to meet this challenge and extends it to solve 200-dimensional problems. Specifically, a single surrogate model constructed by simple random sampling is taken to explore different promising areas in different iterations. Moreover, a variable model management strategy is used to better utilize the current global model and accelerate the convergence rate of the optimizer. In addition, the strategy can be applied to any SAEA irrespective of the surrogate model used. To control the trade-off between optimization results and optimization time consumption of SAEAs, we consider fitness value and running time as a bi-objective problem. Applying the proposed approach to a benchmark test suite of dimensions ranging from 30 to 200 and comparisons with four state-of-the-art algorithms show that the proposed VSMPSO achieves high-quality solutions and computational efficiency for high-dimensional problems.},
  archive      = {J_CIS},
  author       = {Tian, Jie and Hou, Mingdong and Bian, Hongli and Li, Junqing},
  doi          = {10.1007/s40747-022-00910-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3887-3935},
  shortjournal = {Complex Intell. Syst.},
  title        = {Variable surrogate model-based particle swarm optimization for high-dimensional expensive problems},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Wind speed and global radiation forecasting based on
differential, deep and stochastic machine learning of patterns in
2-level historical meteo-quantity sets. <em>CIS</em>, <em>9</em>(4),
3871–3885. (<a
href="https://doi.org/10.1007/s40747-022-00879-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of wind speed and solar radiation can help operators of wind farms and Photo-Voltaic (PV) plants prepare efficient and practicable production plans to balance the supply with demand in the generation and consumption of Renewable Energy (RE). Reliable Artificial Intelligence (AI) forecast models can minimize the effect of wind and solar power fluctuations, eliminating their intermittent character in system dispatch planning and utilization. Intelligent wind and solar energy management is essential in load scheduling and decision-making processes to meet user requirements. The proposed 24-h prediction schemes involve the beginning detection and secondary similarity re-evaluation of optimal day-data sequences, which is a notable incremental improvement against state-of-the-art in the consequent application of statistical AI learning. 2-level altitude measurements allow the identification of data relationships between two surface layers (hill and lowland) and adequate interpretation of various meteorological situations, whose differentiate information is used by AI models to recognize upcoming changes in the mid-term day horizon. Observations at two professional meteorological stations comprise specific quantities, of which the most valuable are automatically selected as input for the day model. Differential learning is a novel designed unconventional neurocomputing approach that combines derivative components produced in selected network nodes in the weighted modular output. The complexity of the node-stepwise composed model corresponds to the patterns included in the training data. It allows for representation of high uncertain and nonlinear dynamic systems, dependent on local RE production, not substantially reducing the input vector dimensionality leading to model over simplifications as standard AI does. Available angular and frequency time data (e.g., wind direction, humidity, and irradiation cycles) are combined with the amplitudes to solve reduced Partial Differential Equations (PDEs), defined in network nodes, in the periodical complex form. This is a substantial improvement over the previous publication design. The comparative results show better efficiency and reliability of differential learning in representing the modular uncertainty and PDE dynamics of patterns on a day horizon, taking into account recent deep and stochastic learning. A free available C++ parametric software together with the processed meteo-data sets allow additional comparisons with the presented model results.},
  archive      = {J_CIS},
  author       = {Zjavka, Ladislav},
  doi          = {10.1007/s40747-022-00879-3},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3871-3885},
  shortjournal = {Complex Intell. Syst.},
  title        = {Wind speed and global radiation forecasting based on differential, deep and stochastic machine learning of patterns in 2-level historical meteo-quantity sets},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph neural networks and cross-protocol analysis for
detecting malicious IP addresses. <em>CIS</em>, <em>9</em>(4),
3857–3869. (<a
href="https://doi.org/10.1007/s40747-022-00838-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An internet protocol (IP) address is the foundation of the Internet, allowing connectivity between people, servers, Internet of Things, and services across the globe. Knowing what is connecting to what and where connections are initiated is crucial to accurately assess a company’s or individual’s security posture. IP reputation assessment can be quite complex because of the numerous services that may be hosted on that IP address. For example, an IP might be serving millions of websites from millions of different companies like web hosting companies often do, or it could be a large email system sending and receiving emails for millions of independent entities. The heterogeneous nature of an IP address typically makes it challenging to interpret the security risk. To make matters worse, adversaries understand this complexity and leverage the ambiguous nature of the IP reputation to exploit further unsuspecting Internet users or devices connected to the Internet. In addition, traditional techniques like dirty-listing cannot react quickly enough to changes in the security climate, nor can they scale large enough to detect new exploits that may be created and disappear in minutes. In this paper, we introduce the use of cross-protocol analysis and graph neural networks (GNNs) in semi-supervised learning to address the speed and scalability of assessing IP reputation. In the cross-protocol supervised approach, we combine features from the web, email, and domain name system (DNS) protocols to identify ones which are the most useful in discriminating suspicious and benign IPs. In our second experiment, we leverage the most discriminant features and incorporate them into the graph as nodes’ features. We use GNNs to pass messages from node to node, propagating the signal to the neighbors while also gaining the benefit of having the originating nodes being influenced by neighboring nodes. Thanks to the relational graph structure we can use only a small portion of labeled data and train the algorithm in a semi-supervised approach. Our dataset represents real-world data that is sparse and only contain a small percentage of IPs with verified clean or suspicious labels but are connected. The experimental results demonstrate that the system can achieve $$85.28\%$$ accuracy in detecting malicious IP addresses at scale with only $$5\%$$ of labeled data.},
  archive      = {J_CIS},
  author       = {Huang, Yonghong and Negrete, Joanna and Wagener, John and Fralick, Celeste and Rodriguez, Armando and Peterson, Eric and Wosotowsky, Adam},
  doi          = {10.1007/s40747-022-00838-y},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3857-3869},
  shortjournal = {Complex Intell. Syst.},
  title        = {Graph neural networks and cross-protocol analysis for detecting malicious IP addresses},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BugPre: An intelligent software version-to-version bug
prediction system using graph convolutional neural networks.
<em>CIS</em>, <em>9</em>(4), 3835–3855. (<a
href="https://doi.org/10.1007/s40747-022-00848-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since defects in software may cause product fault and financial loss, it is essential to conduct software defect prediction (SDP) to identify the potentially defective modules, especially in the early stage of the software development lifecycle. Recently, cross-version defect prediction (CVDP) began to draw increasing research interests, employing the labeled defect data of the prior version within the same project to predict defects in the current version. As software development is a dynamic process, the data distribution (such as defects) during version change may get changed. Recent studies utilize machine learning (ML) techniques to detect software defects. However, due to the close dependencies between the updated and unchanged code, prior ML-based methods fail to model the long and deep dependencies, causing a high false positive. Furthermore, traditional defect detection is performed on the entire project, and the detection efficiency is relatively low, especially on large-scale software projects. To this end, we propose BugPre, a CVDP approach to address these two issues. BugPre is a novel framework that only conducts efficient defect prediction on changed modules in the current version. BugPre utilizes variable propagation tree-based associated analysis method to obtain the changed modules in the current version. Besides, BugPre constructs graph leveraging code context dependences and uses a graph convolutional neural network to learn representative characteristics of code, thereby improving defect prediction capability when version changes occur. Through extensive experiments on open-source Apache projects, the experimental results indicate that our BugPre outperforms three state-of-the-art defect detection approaches, and the F1-score has increased by higher than 16%.},
  archive      = {J_CIS},
  author       = {Wang, Zixu and Tong, Weiyuan and Li, Peng and Ye, Guixin and Chen, Hao and Gong, Xiaoqing and Tang, Zhanyong},
  doi          = {10.1007/s40747-022-00848-w},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3835-3855},
  shortjournal = {Complex Intell. Syst.},
  title        = {BugPre: An intelligent software version-to-version bug prediction system using graph convolutional neural networks},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unexpected interest recommender system with graph neural
network. <em>CIS</em>, <em>9</em>(4), 3819–3833. (<a
href="https://doi.org/10.1007/s40747-022-00849-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional recommender systems often face the filter bubble problem when they focus on recommending familiar items to users. The over-specialized recommended contents will make users bored. To solve this problem, researchers have proposed models that focus on unexpectedness, but these models all suffer from incomplete learning of features. To address this problem, we propose an unexpected interest recommender system with graph neural network (UIRS-GNN). First, we preprocess the input data with a graph convolutional network. It enriches user and item feature vectors by aggregating neighborhood information. Second, we transform the GRU and propose the attention-based long short-term gated recurrent unit network to learn user preferences hidden in historical behavior sequences. Then, we input the preprocessed feature vectors of users and items into the unexpected interest model, and solve the problem of insufficient feature information learning by aggregating neighborhood information. Furthermore, our model also alleviates data sparsity due to our deep learning feature information. Finally, empirical evaluations with several competitive baseline models on three real-world datasets reveal the superior performance of UIRS-GNN.},
  archive      = {J_CIS},
  author       = {Xia, Hongbin and Huang, Kai and Liu, Yuan},
  doi          = {10.1007/s40747-022-00849-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3819-3833},
  shortjournal = {Complex Intell. Syst.},
  title        = {Unexpected interest recommender system with graph neural network},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantifying safety risks of deep neural networks.
<em>CIS</em>, <em>9</em>(4), 3801–3818. (<a
href="https://doi.org/10.1007/s40747-022-00790-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safety concerns on the deep neural networks (DNNs) have been raised when they are applied to critical sectors. In this paper, we define safety risks by requesting the alignment of network’s decision with human perception. To enable a general methodology for quantifying safety risks, we define a generic safety property and instantiate it to express various safety risks. For the quantification of risks, we take the maximum radius of safe norm balls, in which no safety risk exists. The computation of the maximum safe radius is reduced to the computation of their respective Lipschitz metrics—the quantities to be computed. In addition to the known adversarial example, reachability example, and invariant example, in this paper, we identify a new class of risk—uncertainty example—on which humans can tell easily, but the network is unsure. We develop an algorithm, inspired by derivative-free optimization techniques and accelerated by tensor-based parallelization on GPUs, to support an efficient computation of the metrics. We perform evaluations on several benchmark neural networks, including ACSC-Xu, MNIST, CIFAR-10, and ImageNet networks. The experiments show that our method can achieve competitive performance on safety quantification in terms of the tightness and the efficiency of computation. Importantly, as a generic approach, our method can work with a broad class of safety risks and without restrictions on the structure of neural networks.},
  archive      = {J_CIS},
  author       = {Xu, Peipei and Ruan, Wenjie and Huang, Xiaowei},
  doi          = {10.1007/s40747-022-00790-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3801-3818},
  shortjournal = {Complex Intell. Syst.},
  title        = {Quantifying safety risks of deep neural networks},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-layer stacking ensemble learners for low footprint
network intrusion detection. <em>CIS</em>, <em>9</em>(4), 3787–3799. (<a
href="https://doi.org/10.1007/s40747-022-00809-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning has become the standard solution to problems in many areas, such as image recognition, natural language processing, and spam detection. In the area of network intrusion detection, machine learning techniques have also been successfully used to detect anomalies in network traffic. However, there is less tolerance in the network intrusion detection domain in terms of errors, especially false positives. In this paper, we define strict acceptance criteria, and show that only very few ensemble learning classifiers are able to meet them in detecting low footprint network intrusions. We compare bagging, boosting, and stacking techniques, and show how methods such as multi-layer stacking can outperform other ensemble techniques and non-ensemble models in detecting such intrusions. We show how different variations on a stacking ensemble model can play a significant role on the classification performance. Malicious examples in our dataset are from the network intrusions that exfiltrate data from a target machine. The benign examples are captured by network taps in geographically different locations on a big corporate network. Among hundreds of ensemble models based on seven different base learners, only three multi-layer stacking models meet the strict acceptance criteria, and achieve an F1 score of 0.99, and a false-positive rate of 0.001. Furthermore, we show that our ensemble models outperform different deep neural network models in classifying low footprint network intrusions.},
  archive      = {J_CIS},
  author       = {Shafieian, Saeed and Zulkernine, Mohammad},
  doi          = {10.1007/s40747-022-00809-3},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3787-3799},
  shortjournal = {Complex Intell. Syst.},
  title        = {Multi-layer stacking ensemble learners for low footprint network intrusion detection},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic review of homomorphic encryption and its
contributions in healthcare industry. <em>CIS</em>, <em>9</em>(4),
3759–3786. (<a
href="https://doi.org/10.1007/s40747-022-00756-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing and cloud storage have contributed to a big shift in data processing and its use. Availability and accessibility of resources with the reduction of substantial work is one of the main reasons for the cloud revolution. With this cloud computing revolution, outsourcing applications are in great demand. The client uses the service by uploading their data to the cloud and finally gets the result by processing it. It benefits users greatly, but it also exposes sensitive data to third-party service providers. In the healthcare industry, patient health records are digital records of a patient’s medical history kept by hospitals or health care providers. Patient health records are stored in data centers for storage and processing. Before doing computations on data, traditional encryption techniques decrypt the data in their original form. As a result, sensitive medical information is lost. Homomorphic encryption can protect sensitive information by allowing data to be processed in an encrypted form such that only encrypted data is accessible to service providers. In this paper, an attempt is made to present a systematic review of homomorphic cryptosystems with its categorization and evolution over time. In addition, this paper also includes a review of homomorphic cryptosystem contributions in healthcare.},
  archive      = {J_CIS},
  author       = {Munjal, Kundan and Bhatia, Rekha},
  doi          = {10.1007/s40747-022-00756-z},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3759-3786},
  shortjournal = {Complex Intell. Syst.},
  title        = {A systematic review of homomorphic encryption and its contributions in healthcare industry},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Uncertainty as a swiss army knife: New adversarial attack
and defense ideas based on epistemic uncertainty. <em>CIS</em>,
<em>9</em>(4), 3739–3757. (<a
href="https://doi.org/10.1007/s40747-022-00701-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although state-of-the-art deep neural network models are known to be robust to random perturbations, it was verified that these architectures are indeed quite vulnerable to deliberately crafted perturbations, albeit being quasi-imperceptible. These vulnerabilities make it challenging to deploy deep neural network models in the areas where security is a critical concern. In recent years, many research studies have been conducted to develop new attack methods and come up with new defense techniques that enable more robust and reliable models. In this study, we use the quantified epistemic uncertainty obtained from the model’s final probability outputs, along with the model’s own loss function, to generate more effective adversarial samples. And we propose a novel defense approach against attacks like Deepfool which result in adversarial samples located near the model’s decision boundary. We have verified the effectiveness of our attack method on MNIST (Digit), MNIST (Fashion) and CIFAR-10 datasets. In our experiments, we showed that our proposed uncertainty-based reversal method achieved a worst case success rate of around 95% without compromising clean accuracy.},
  archive      = {J_CIS},
  author       = {Tuna, Omer Faruk and Catak, Ferhat Ozgur and Eskil, M. Taner},
  doi          = {10.1007/s40747-022-00701-0},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3739-3757},
  shortjournal = {Complex Intell. Syst.},
  title        = {Uncertainty as a swiss army knife: New adversarial attack and defense ideas based on epistemic uncertainty},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual-filtering (DF) schemes for learning systems to prevent
adversarial attacks. <em>CIS</em>, <em>9</em>(4), 3717–3738. (<a
href="https://doi.org/10.1007/s40747-022-00649-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defenses against adversarial attacks are essential to ensure the reliability of machine-learning models as their applications are expanding in different domains. Existing ML defense techniques have several limitations in practical use. We proposed a trustworthy framework that employs an adaptive strategy to inspect both inputs and decisions. In particular, data streams are examined by a series of diverse filters before sending to the learning system and then crossed checked its output through anomaly (outlier) detectors before making the final decision. Experimental results (using benchmark data-sets) demonstrated that our dual-filtering strategy could mitigate adaptive or advanced adversarial manipulations for wide-range of ML attacks with higher accuracy. Moreover, the output decision boundary inspection with a classification technique automatically affirms the reliability and increases the trustworthiness of any ML-based decision support system. Unlike other defense techniques, our dual-filtering strategy does not require adversarial sample generation and updating the decision boundary for detection, makes the ML defense robust to adaptive attacks.},
  archive      = {J_CIS},
  author       = {Dasgupta, Dipankar and Gupta, Kishor Datta},
  doi          = {10.1007/s40747-022-00649-1},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3717-3738},
  shortjournal = {Complex Intell. Syst.},
  title        = {Dual-filtering (DF) schemes for learning systems to prevent adversarial attacks},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid data-driven online solar energy disaggregation
system from the grid supply point. <em>CIS</em>, <em>9</em>(4),
3695–3716. (<a
href="https://doi.org/10.1007/s40747-022-00842-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of small-scale Photovoltaics (PV) systems (such as rooftop PVs) decreases the visibility of power systems, since the real demand load is masked. Most rooftop systems are behind the metre and cannot be measured by household smart meters. To overcome the challenges mentioned above, this paper proposes an online solar energy disaggregation system to decouple the solar energy generated by rooftop PV systems and the ground truth demand load from net measurements. A 1D Convolutional Neural Network (CNN) Bidirectional Long Short-Term Memory (BiLSTM) deep learning method is used as the core algorithm of the proposed system. The system takes a wide range of online information (Advanced Metering Infrastructure (AMI) data, meteorological data, satellite-driven irradiance, and temporal information) as inputs to evaluate PV generation, and the system also enables online and offline modes. The effectiveness of the proposed algorithm is evaluated by comparing it to baselines. The results show that the proposed method achieves good performance under different penetration rates and different feeder levels. Finally, a transfer learning process is introduced to verify that the proposed system has good robustness and can be applied to other feeders.},
  archive      = {J_CIS},
  author       = {Zhang, Xiao-Yu and Kuenzel, Stefanie and Guo, Peiqian and Yin, Lei and Watkins, Chris},
  doi          = {10.1007/s40747-022-00842-2},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3695-3716},
  shortjournal = {Complex Intell. Syst.},
  title        = {A hybrid data-driven online solar energy disaggregation system from the grid supply point},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integration and classification approach based on
probabilistic semantic association for big data. <em>CIS</em>,
<em>9</em>(4), 3681–3694. (<a
href="https://doi.org/10.1007/s40747-021-00548-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The process of integration through classification provides a unified representation of diverse data sources in Big data. The main challenges of big data analysis are due to the various granularities, irreconcilable data models, and multipart interdependencies between data content. Previously designed models were facing problems in integrating and analyzing big data due to highly complex and dynamic multi-source and heterogeneous information variation and also in processing and classifying the association among the attributes in a schema. In this paper, we propose an integration and classification approach through designing a Probabilistic Semantic Association (PSA) method to generate the feature pattern for the sources of big data. The PSA approach is trained to understand the data association and dependency pattern between the data class and incoming data to map the data objects accurately. It initially builds a data integration mechanism by transforming data into structured and learn to utilize the trained knowledge to classify the probabilistic association among the data and knowledge patterns. Later it builds a data analysis mechanism to analyze the mapped data through PSA to evaluate the integration efficiency. An experimental evaluation is performed over a real-time crime dataset generated from multiple locations having various events classes. The analysis of results confined that the utilization of knowledge patterns of accurate classification to enhance the integration of multiple source data is appropriate. The measure of precision, recall, fall-out rate, and F-measure approve the efficiency of the proposed PSA method. Even in comparison with the state-of-art classification method and with SC-LDA algorithm shows an improvisation in the prediction accuracy and enhance the data integration.},
  archive      = {J_CIS},
  author       = {VandanaKolisetty, Vishnu and Rajput, Dharmendra Singh},
  doi          = {10.1007/s40747-021-00548-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3681-3694},
  shortjournal = {Complex Intell. Syst.},
  title        = {Integration and classification approach based on probabilistic semantic association for big data},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A noise-based privacy preserving model for internet of
things. <em>CIS</em>, <em>9</em>(4), 3655–3679. (<a
href="https://doi.org/10.1007/s40747-021-00489-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the ever-increasing number of devices, the Internet of Things facilitates the connection between the devices in the hyper-connected world. As the number of interconnected devices increases, sensitive data disclosure becomes an important issue that needs to be addressed. In order to prevent the disclosure of sensitive data, effective and feasible privacy preservation strategies are necessary. A noise-based privacy-preserving model has been proposed in this article. The components of the noise-based privacy-preserving model include Multilevel Noise Treatment for data collection; user preferences-based data classifier to classify sensitive and non-sensitive data; Noise Removal and Fuzzification Mechanism for data access and user-customized privacy preservation mechanism. Experiments have been conducted to evaluate the performance and feasibility of the proposed model. The results have been compared with existing approaches. The experimental results show an improvement in the proposed noise-based privacy-preserving model in terms of computational overhead. The comparative analysis indicates that the proposed model without the fuzzifier has around 52–77% less computational overhead than the Data access control scheme and 46–70% less computational overhead compared to the Dynamic Privacy Protection model. The proposed model with the fuzzifier has around 48–73% less computational overhead compared to the Data access control scheme and 31–63% less computational overhead compared to the Dynamic Privacy Protection model. Furthermore, the privacy analysis has been done with the relevant approaches. The results indicate that the proposed model can customize privacy as per the users’ preferences and at the same time takes less execution time which reduces the overhead on the resource constraint IoT devices.},
  archive      = {J_CIS},
  author       = {Jain, Shelendra Kumar and Kesswani, Nishtha},
  doi          = {10.1007/s40747-021-00489-5},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3655-3679},
  shortjournal = {Complex Intell. Syst.},
  title        = {A noise-based privacy preserving model for internet of things},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IHWC: Intelligent hidden web crawler for harvesting data in
urban domains. <em>CIS</em>, <em>9</em>(4), 3635–3653. (<a
href="https://doi.org/10.1007/s40747-021-00471-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the massive size of the hidden web, searching, retrieving and mining rich and high-quality data can be a daunting task. Moreover, with the presence of forms, data cannot be accessed easily. Forms are dynamic, heterogeneous and spread over trillions of web pages. Significant efforts have addressed the problem of tapping into the hidden web to integrate and mine rich data. Effective techniques, as well as application in special cases, are required to be explored to achieve an effective harvest rate. One such special area is atmospheric science, where hidden web crawling is least implemented, and crawler is required to crawl through the huge web to narrow down the search to specific data. In this study, an intelligent hidden web crawler for harvesting data in urban domains (IHWC) is implemented to address the relative problems such as classification of domains, prevention of exhaustive searching, and prioritizing the URLs. The crawler also performs well in curating pollution-related data. The crawler targets the relevant web pages and discards the irrelevant by implementing rejection rules. To achieve more accurate results for a focused crawl, ICHW crawls the websites on priority for a given topic. The crawler has fulfilled the dual objective of developing an effective hidden web crawler that can focus on diverse domains and to check its integration in searching pollution data in smart cities. One of the objectives of smart cities is to reduce pollution. Resultant crawled data can be used for finding the reason for pollution. The crawler can help the user to search the level of pollution in a specific area. The harvest rate of the crawler is compared with pioneer existing work. With an increase in the size of a dataset, the presented crawler can add significant value to emission accuracy. Our results are demonstrating the accuracy and harvest rate of the proposed framework, and it efficiently collect hidden web interfaces from large-scale sites and achieve higher rates than other crawlers.},
  archive      = {J_CIS},
  author       = {Kaur, Sawroop and Singh, Aman and Geetha, G. and Cheng, Xiaochun},
  doi          = {10.1007/s40747-021-00471-1},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3635-3653},
  shortjournal = {Complex Intell. Syst.},
  title        = {IHWC: Intelligent hidden web crawler for harvesting data in urban domains},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An infrastructure-assisted job scheduling and task
coordination in volunteer computing-based VANET. <em>CIS</em>,
<em>9</em>(4), 3613–3633. (<a
href="https://doi.org/10.1007/s40747-021-00437-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicular networks as the key enablers in Intelligent Transportation Systems (ITS) and the Internet of Things (IoT) are key components of smart sustainable cities. Vehicles as a significant component of smart cities have emerging in-vehicle applications that can assist in good governance for sustainable smart cities. Most of these applications are delay sensitive and demand high computational capabilities that are provided by emerging technologies. Utilizing the distributed computational resources of vehicles with the help of volunteer computing is an efficient method to fulfill the high computational requirements of vehicles itself and the other components of smart cities. Vehicle as a resource is an emerging concept that must be considered to address the future challenges of sustainable smart cities. In this paper, an infrastructure-assisted job scheduling and task coordination mechanism in volunteer computing-based VANET called RSU-based VCBV is proposed, which enhances the architecture of VANET to utilize the surplus resources of vehicles for task execution. We propose job scheduling and task coordination algorithms for different volunteer models. Further, we design and implement an adaptive task replication method to seek fault tolerance by avoiding task failures due to locations of vehicles. We propose a task replication algorithm called location-based task replication algorithm. Extensive simulations validate the performance of our proposed volunteer models while comparing average task execution time and weight ratios with existing work.},
  archive      = {J_CIS},
  author       = {Waheed, Abdul and Shah, Munam Ali and Khan, Abid and Jeon, Gwanggil},
  doi          = {10.1007/s40747-021-00437-3},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3613-3633},
  shortjournal = {Complex Intell. Syst.},
  title        = {An infrastructure-assisted job scheduling and task coordination in volunteer computing-based VANET},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lane detection under artificial colored light in tunnels and
on highways: An IoT-based framework for smart city infrastructure.
<em>CIS</em>, <em>9</em>(4), 3601–3612. (<a
href="https://doi.org/10.1007/s40747-021-00381-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lane detection (LD) under different illumination conditions is a vital part of lane departure warning system and vehicle localization which are current trends in the future smart cities. Recently, vision-based methods are proposed to detect lane markers in different road situations including abnormal marker cases. However, an inclusive framework for driverless cars has not been introduced yet. In this work, a novel LD and tracking method is proposed for the autonomous vehicle in the IoT-based framework (IBF). The IBF consists of three modules which are vehicle board (VB), cloud module (CM), and the vehicle remote controller. The LD and tracking are carried out initially by the VB, and then, in case of any failure, the whole set of data is passed to CM to be processed and the results are sent to the VB to perform the appropriate action. If the CM detects a lane departure, then the autonomous vehicle is driven remotely and the VB would be restarted. In addition to the proposed framework, an illumination invariance method is presented to detect lane markers under different light conditions. The simulation results with real-life data demonstrate lane-keeping rates of 95.3% and 95.2% in tunnels and on highways, respectively. The approximate processing time of the proposed method is 31 ms/frame which fulfills the real-time requirements.},
  archive      = {J_CIS},
  author       = {Ghanem, Safwan and Kanungo, Priyadarshi and Panda, Ganapati and Satapathy, Suresh Chandra and Sharma, Rohit},
  doi          = {10.1007/s40747-021-00381-2},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3601-3612},
  shortjournal = {Complex Intell. Syst.},
  title        = {Lane detection under artificial colored light in tunnels and on highways: An IoT-based framework for smart city infrastructure},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An integrated fuzzy credit rating model using fuzzy-BWM and
new fuzzy-TOPSIS-sort-c. <em>CIS</em>, <em>9</em>(4), 3581–3600. (<a
href="https://doi.org/10.1007/s40747-022-00823-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial institutions use credit rating models to make lending, investing, and risk management decisions. Credit rating models have been developed using a variety of statistical and machine learning methods. These methods, however, are data-intensive and dependent on assumptions about data distribution. This research offers an integrated fuzzy credit rating model to address such issues. This study proposes an integrated fuzzy credit rating model to reduce such problems. The study applies the fuzzy best–worst method (fuzzy-BWM) to obtain the weight of criteria that affect creditworthiness and fuzzy technique for order of preference by similarity to ideal solution (fuzzy-TOPSIS)-Sort-C to evaluate the borrowers. The BWM was found consistent amongst existing multi-criteria decision-making (MCDM) methods, and consistency further improves when BWM is extended to a fuzzy version. The study applies TOPSIS-Sorting along with fuzzy theory to overcome human uncertainty while making a decision. TOPSIS-sorting has been found capable of handling rank reversal problems that persist in the TOPSIS method. The fuzzy-TOPSIS-Sort-C method is applied to evaluate borrowers based on the characteristic profile of the identified criteria. The proposed model&#39;s efficacy has been illustrated with a case study to rate fifty firms with real-life data. The proposed model results are compared with previous studies and commercially available ratings. The model results show better accuracy in terms of accuracy and true-positive rates to predict default. It can help financial institutions to find potential borrowers for granting credit.},
  archive      = {J_CIS},
  author       = {Roy, Pranith K. and Shaw, Krishnendu},
  doi          = {10.1007/s40747-022-00823-5},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3581-3600},
  shortjournal = {Complex Intell. Syst.},
  title        = {An integrated fuzzy credit rating model using fuzzy-BWM and new fuzzy-TOPSIS-sort-C},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combining weighted SMOTE with ensemble learning for the
class-imbalanced prediction of small business credit risk. <em>CIS</em>,
<em>9</em>(4), 3559–3579. (<a
href="https://doi.org/10.1007/s40747-021-00614-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In small business credit risk assessment, the default and nondefault classes are highly imbalanced. To overcome this problem, this study proposes an extended ensemble approach rooted in the weighted synthetic minority oversampling technique (WSMOTE), which is called WSMOTE-ensemble. The proposed ensemble classifier hybridizes WSMOTE and Bagging with sampling composite mixtures to guarantee the robustness and variability of the generated synthetic instances and, thus, minimize the small business class-skewed constraints linked to default and nondefault instances. The original small business dataset used in this study was taken from 3111 records from a Chinese commercial bank. By implementing a thorough experimental study of extensively skewed data-modeling scenarios, a multilevel experimental setting was established for a rare event domain. Based on the proper evaluation measures, this study proposes that the random forest classifier used in the WSMOTE-ensemble model provides a good trade-off between the performance on default class and that of nondefault class. The ensemble solution improved the accuracy of the minority class by 15.16% in comparison with its competitors. This study also shows that sampling methods outperform nonsampling algorithms. With these contributions, this study fills a noteworthy knowledge gap and adds several unique insights regarding the prediction of small business credit risk.},
  archive      = {J_CIS},
  author       = {Abedin, Mohammad Zoynul and Guotai, Chi and Hajek, Petr and Zhang, Tong},
  doi          = {10.1007/s40747-021-00614-4},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3559-3579},
  shortjournal = {Complex Intell. Syst.},
  title        = {Combining weighted SMOTE with ensemble learning for the class-imbalanced prediction of small business credit risk},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluation of regional industrial cluster innovation
capability based on particle swarm clustering algorithm and
multi-objective optimization. <em>CIS</em>, <em>9</em>(4), 3547–3558.
(<a href="https://doi.org/10.1007/s40747-021-00521-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the progress of the times and the development of science, industrial clusters have been regarded by all countries in the world as one of the important ways to enhance regional competitiveness, and become an inevitable trend of industrial development. The research on the innovation ability of industrial clusters can not only maintain sustainable development of industrial clusters and obtain sustained competitive advantages, but also provide reference for the government&#39;s policy formulation of industrial clusters. This paper aims to study the evaluation of regional industrial clusters&#39; innovation capability based on particle swarm clustering and multi-objective optimization. This paper uses the theory of industrial cluster innovation and takes regional industrial system as the empirical research object to establish a regional industrial system capability evaluation system, which is based on the selection of indicators, combined with analytic hierarchy process and factor analysis to evaluate industrial innovation capability. On this basis, the particle swarm clustering theory is used to verify the innovation ability and evaluation index system of industrial clusters, and provide a reference for the evaluation of the innovation ability of industrial clusters. This paper divides the regional cluster innovation capability into four aspects: innovation input capability, environment support capability, self-development capability and innovation output capability, and systematically analyzes the key elements and in the composition of innovation elements and their relationships. It then constructs the evaluation index system of regional cluster innovation capability. At the same time, this paper introduces clustering analysis algorithm and swarm intelligence algorithm into regional innovation evaluation, combines particle swarm optimization algorithm and K-means clustering algorithm, and optimizes particle swarm clustering algorithm by adjusting adaptive parameters and adding fitness variance. The experimental results of this paper show that from the results of the tested innovation potential of the three industrial clusters, industrial cluster F has the strongest innovation ability, with an evaluation coefficient of 0.851, followed by industrial cluster F, which has a value of 0.623. This result is consistent with the actual innovation status of the selected industry. From this point of view, the established particle swarm clustering model for evaluating the innovation capability of regional industrial clusters is reliable and can be used to evaluate the innovation capability of different industrial clusters.},
  archive      = {J_CIS},
  author       = {Yan, Yongcai and He, Mengxue and Song, Lifang},
  doi          = {10.1007/s40747-021-00521-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3547-3558},
  shortjournal = {Complex Intell. Syst.},
  title        = {Evaluation of regional industrial cluster innovation capability based on particle swarm clustering algorithm and multi-objective optimization},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent system for human activity recognition in IoT
environment. <em>CIS</em>, <em>9</em>(4), 3535–3546. (<a
href="https://doi.org/10.1007/s40747-021-00508-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the adoption of machine learning has grown steadily in different fields affecting the day-to-day decisions of individuals. This paper presents an intelligent system for recognizing human’s daily activities in a complex IoT environment. An enhanced model of capsule neural network called 1D-HARCapsNe is proposed. This proposed model consists of convolution layer, primary capsule layer, activity capsules flat layer and output layer. It is validated using WISDM dataset collected via smart devices and normalized using the random-SMOTE algorithm to handle the imbalanced behavior of the dataset. The experimental results indicate the potential and strengths of the proposed 1D-HARCapsNet that achieved enhanced performance with an accuracy of 98.67%, precision of 98.66%, recall of 98.67%, and F1-measure of 0.987 which shows major performance enhancement compared to the Conventional CapsNet (accuracy 90.11%, precision 91.88%, recall 89.94%, and F1-measure 0.93).},
  archive      = {J_CIS},
  author       = {Khaled, Hassan and Abu-Elnasr, Osama and Elmougy, Samir and Tolba, A. S.},
  doi          = {10.1007/s40747-021-00508-5},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3535-3546},
  shortjournal = {Complex Intell. Syst.},
  title        = {Intelligent system for human activity recognition in IoT environment},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design and analysis of an efficient machine learning based
hybrid recommendation system with enhanced density-based spatial
clustering for digital e-learning applications. <em>CIS</em>,
<em>9</em>(4), 3517–3533. (<a
href="https://doi.org/10.1007/s40747-021-00509-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A decision-making system is one of the most important tools in data mining. The data mining field has become a forum where it is necessary to utilize users&#39; interactions, decision-making processes and overall experience. Nowadays, e-learning is indeed a progressive method to provide online education in long-lasting terms, contrasting to the customary head-to-head process of educating with culture. Through e-learning, an ever-increasing number of learners have profited from different programs. Notwithstanding, the highly assorted variety of the students on the internet presents new difficulties to the conservative one-estimate fit-all learning systems, in which a solitary arrangement of learning assets is specified to the learners. The problems and limitations in well-known recommender systems are much variations in the expected absolute error, consuming more query processing time, and providing less accuracy in the final recommendation. The main objectives of this research are the design and analysis of a new transductive support vector machine-based hybrid personalized hybrid recommender for the machine learning public data sets. The learning experience has been achieved through the habits of the learners. This research designs some of the new strategies that are experimented with to improve the performance of a hybrid recommender. The modified one-source denoising approach is designed to preprocess the learner dataset. The modified anarchic society optimization strategy is designed to improve the performance measurements. The enhanced and generalized sequential pattern strategy is proposed to mine the sequential pattern of learners. The enhanced transductive support vector machine is developed to evaluate the extracted habits and interests. These new strategies analyze the confidential rate of learners and provide the best recommendation to the learners. The proposed generalized model is simulated on public datasets for machine learning such as movies, music, books, food, merchandise, healthcare, dating, scholarly paper, and open university learning recommendation. The experimental analysis concludes that the enhanced clustering strategy discovers clusters that are based on random size. The proposed recommendation strategies achieve better significant performance over the methods in terms of expected absolute error, accuracy, ranking score, recall, and precision measurements. The accuracy of the proposed datasets lies between 82 and 98%. The MAE metric lies between 5 and 19.2% for the simulated public datasets. The simulation results prove the proposed generalized recommender has a great strength to improve the quality and performance.},
  archive      = {J_CIS},
  author       = {Bhaskaran, S. and Marappan, Raja},
  doi          = {10.1007/s40747-021-00509-4},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3517-3533},
  shortjournal = {Complex Intell. Syst.},
  title        = {Design and analysis of an efficient machine learning based hybrid recommendation system with enhanced density-based spatial clustering for digital e-learning applications},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning framework for handling concept drift and class
imbalanced complex decision-making on streaming data. <em>CIS</em>,
<em>9</em>(4), 3499–3515. (<a
href="https://doi.org/10.1007/s40747-021-00456-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In present times, data science become popular to support and improve decision-making process. Due to the accessibility of a wide application perspective of data streaming, class imbalance and concept drifting become crucial learning problems. The advent of deep learning (DL) models finds useful for the classification of concept drift in data streaming applications. This paper presents an effective class imbalance with concept drift detection (CIDD) using Adadelta optimizer-based deep neural networks (ADODNN), named CIDD-ADODNN model for the classification of highly imbalanced streaming data. The presented model involves four processes namely preprocessing, class imbalance handling, concept drift detection, and classification. The proposed model uses adaptive synthetic (ADASYN) technique for handling class imbalance data, which utilizes a weighted distribution for diverse minority class examples based on the level of difficulty in learning. Next, a drift detection technique called adaptive sliding window (ADWIN) is employed to detect the existence of the concept drift. Besides, ADODNN model is utilized for the classification processes. For increasing the classifier performance of the DNN model, ADO-based hyperparameter tuning process takes place to determine the optimal parameters of the DNN model. The performance of the presented model is evaluated using three streaming datasets namely intrusion detection (NSL KDDCup) dataset, Spam dataset, and Chess dataset. A detailed comparative results analysis takes place and the simulation results verified the superior performance of the presented model by obtaining a maximum accuracy of 0.9592, 0.9320, and 0.7646 on the applied KDDCup, Spam, and Chess dataset, respectively.},
  archive      = {J_CIS},
  author       = {Priya, S. and Uthra, R. Annie},
  doi          = {10.1007/s40747-021-00456-0},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3499-3515},
  shortjournal = {Complex Intell. Syst.},
  title        = {Deep learning framework for handling concept drift and class imbalanced complex decision-making on streaming data},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature selection algorithm for usability engineering: A
nature inspired approach. <em>CIS</em>, <em>9</em>(4), 3487–3497. (<a
href="https://doi.org/10.1007/s40747-021-00384-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software usability is usually used in reference to the hierarchical software usability model by researchers and is an important aspect of user experience and software quality. Thus, evaluation of software usability is an essential parameter for managing and regulating a software. However, it has been difficult to establish a precise evaluation method for this problem. A large number of usability factors have been suggested by many researchers, each covering a set of different factors to increase the degree of user friendliness of a software. Therefore, the selection of the correct determining features is of paramount importance. This paper proposes an innovative metaheuristic algorithm for the selection of most important features in a hierarchical software model. A hierarchy-based usability model is an exhaustive interpretation of the factors, attributes, and its characteristics in a software at different levels. This paper proposes a modified version of grey wolf optimisation algorithm (GWO) termed as modified grey wolf optimization (MGWO) algorithm. The mechanism of this algorithm is based on the hunting mechanism of wolves in nature. The algorithm chooses a number of features which are then applied to software development life cycle models for finding out the best among them. The outcome of this application is also compared with the conventional grey wolf optimization algorithm (GWO), modified binary bat algorithm (MBBAT), modified whale optimization algorithm (MWOA), and modified moth flame optimization (MMFO). The results show that MGWO surpasses all the other relevant optimizers in terms of accuracy and produces a lesser number of attributes equal to 8 as compared to 9 in MMFO and 12 in MBBAT and 19 in MWOA.},
  archive      = {J_CIS},
  author       = {Jain, Rajat and Joseph, Tania and Saxena, Anvita and Gupta, Deepak and Khanna, Ashish and Sagar, Kalpna and Ahlawat, Anil K.},
  doi          = {10.1007/s40747-021-00384-z},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3487-3497},
  shortjournal = {Complex Intell. Syst.},
  title        = {Feature selection algorithm for usability engineering: A nature inspired approach},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-objective rain optimization algorithm with WELM model
for customer churn prediction in telecommunication sector. <em>CIS</em>,
<em>9</em>(4), 3473–3485. (<a
href="https://doi.org/10.1007/s40747-021-00353-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Customer retention is a major challenge in several business sectors and diverse companies identify the customer churn prediction (CCP) as an important process for retaining the customers. CCP in the telecommunication sector has become an essential need owing to a rise in the number of the telecommunication service providers. Recently, machine learning (ML) and deep learning (DL) models have begun to develop effective CCP model. This paper presents a new improved synthetic minority over-sampling technique (SMOTE) with optimal weighted extreme machine learning (OWELM) called the ISMOTE-OWELM model for CCP. The presented model comprises preprocessing, balancing the unbalanced dataset, and classification. The multi-objective rain optimization algorithm (MOROA) is used for two purposes: determining the optimal sampling rate of SMOTE and parameter tuning of WELM. Initially, the customer data involve data normalization and class labeling. Then, the ISMOTE is employed to handle the imbalanced dataset where the rain optimization algorithm (ROA) is applied to determine the optimal sampling rate. At last, the WELM model is applied to determine the class labels of the applied data. Extensive experimentation is carried out to ensure the ISMOTE-OWELM model against the CCP Telecommunication dataset. The simulation outcome portrayed that the ISMOTE-OWELM model is superior to other models with the accuracy of 0.94, 0.92, 0.909 on the applied dataset I, II, and III, respectively.},
  archive      = {J_CIS},
  author       = {Pustokhina, Irina V. and Pustokhin, Denis A. and Nguyen, Phong Thanh and Elhoseny, Mohamed and Shankar, K.},
  doi          = {10.1007/s40747-021-00353-6},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {8},
  number       = {4},
  pages        = {3473-3485},
  shortjournal = {Complex Intell. Syst.},
  title        = {Multi-objective rain optimization algorithm with WELM model for customer churn prediction in telecommunication sector},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Low-power AES s-box design using dual-basis tower field
extension method for cyber security applications. <em>CIS</em>,
<em>9</em>(3), 2959–2967. (<a
href="https://doi.org/10.1007/s40747-021-00556-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cryptography, one among several investigated areas is the implementation of AES S-boxes. In this paper, a substitution-box is designed which follows combined data path using dual-basis tower field extension with Golod–Shafarevich theorem fed in immune genetic algorithm for optimization purpose for each and every block. The role of enhanced immune genetic algorithm is as follows: at first, chaotic system generates S-boxes population, these S-boxes which perform excellently are then optimized by a sequence of operators such as extraction of anti-agent and immune selection. Few criteria of S-boxes such as differential uniformity, nonlinear degree, and strict avalanche effect are analyzed. The obtained results are analyzed with CMOS 35 nm and 15 nm technologies to measure the performance of the proposed designs and was observed that the proposed one outperforms in power and area. The optimized S-box can be effectively applied for securing information. The proposed Golod–Shafarevich feeder Immune Genetic Algorithm S-box (GSIGA-Sbox) is compared with two baseline methods such as Reversed Genetic Algorithm S-box (RGA-Sbox) and Discrete Space Chaotic S-box (DSC-Sbox). As a result the proposed GSIGA-Sbox achieves encryption speed of 61 MHZ, decryption speed of 55 MHZ with 24% of power consumption for 35 nm CMOS technology and 57 MHZ encryption speed, 51 MHZ decryption speed with 28% of power consumption for 15 nm CMOS technology.},
  archive      = {J_CIS},
  author       = {Nandan, V. and Rao, R. Gowri Shankar},
  doi          = {10.1007/s40747-021-00556-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2959-2967},
  shortjournal = {Complex Intell. Syst.},
  title        = {Low-power AES S-box design using dual-basis tower field extension method for cyber security applications},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RETRACTED ARTICLE: Optimized intelligent data management
framework for a cyber-physical system for computational applications.
<em>CIS</em>, <em>9</em>(3), 2957. (<a
href="https://doi.org/10.1007/s40747-021-00511-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CIS},
  author       = {Alsufyani, Abdulmajeed and Alotaibi, Youseef and Almagrabi, Alaa Omran and Alghamdi, Saleh Ahmed and Alsufyani, Nawal},
  doi          = {10.1007/s40747-021-00511-w},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2957},
  shortjournal = {Complex Intell. Syst.},
  title        = {RETRACTED ARTICLE: Optimized intelligent data management framework for a cyber-physical system for computational applications},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Code-based encryption techniques with distributed cluster
head and energy consumption routing protocol. <em>CIS</em>,
<em>9</em>(3), 2943–2955. (<a
href="https://doi.org/10.1007/s40747-021-00505-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fog computing and the Internet of Things (IoT) played a crucial role in storing data in the third-party server. Fog computing provides various resources to collect data by managing data security. However, intermediate attacks and data sharing create enormous security challenges like data privacy, confidentiality, authentication, and integrity issues. Various researchers introduce several cryptographic techniques; security is still significant while sharing data in the distributed environment. Therefore, in this paper, Code-Based Encryption with the Energy Consumption Routing Protocol (CBE-ECR) has been proposed for managing data security and data transmission protocols using keyed-hash message authentication. Initially, the data have been analyzed, and the distributed cluster head is selected, and the stochastically distributed energy clustering protocol is utilized for making the data transmission. Code-driven cryptography relies on the severity of code theory issues such as disorder demodulation and vibration required to learn equivalence. These crypto-systems are based on error codes to build a single-way function. The encryption technique minimizes intermediate attacks, and the data have protected all means of transmission. In addition to data security management, the introduced CBE-ECR reduces unauthorized access and manages the network lifetime successfully, leading to the effective data management of 96.17% and less energy consumption of 21.11% than other popular methods.The effectiveness of the system is compared to the traditional clustering techniques.},
  archive      = {J_CIS},
  author       = {Jalasri, M. and Lakshmanan, L.},
  doi          = {10.1007/s40747-021-00505-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2943-2955},
  shortjournal = {Complex Intell. Syst.},
  title        = {Code-based encryption techniques with distributed cluster head and energy consumption routing protocol},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A genre trust model for defending shilling attacks in
recommender systems. <em>CIS</em>, <em>9</em>(3), 2929–2942. (<a
href="https://doi.org/10.1007/s40747-021-00357-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shilling attacks have been a significant vulnerability of collaborative filtering (CF) recommender systems, and trust in CF recommender algorithms has been proven to be helpful for improving the accuracy of system recommendations. As a few studies have been devoted to trust in this area, we explore the benefits of using trust to resist shilling attacks. Rather than simply using user-generated trust values, we propose the genre trust degree, which differ in terms of the genres of items and take both trust value and user credibility into consideration. This paper introduces different types of shilling attack methods in an attempt to study the impact of users’ trust values and behavior features on defending against shilling attacks. Meanwhile, it improves the approach used to calculate user similarities to form a recommendation model based on genre trust degrees. The performance of the genre trust-based recommender system is evaluated on the Ciao dataset. Experimental results demonstrated the superior and comparable genre trust degrees recommended for defending against different types of shilling attacks.},
  archive      = {J_CIS},
  author       = {Yang, Li and Niu, Xinxin},
  doi          = {10.1007/s40747-021-00357-2},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2929-2942},
  shortjournal = {Complex Intell. Syst.},
  title        = {A genre trust model for defending shilling attacks in recommender systems},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Three factor authentication system with modified ECC based
secured data transfer: Untrusted cloud environment. <em>CIS</em>,
<em>9</em>(3), 2915–2928. (<a
href="https://doi.org/10.1007/s40747-021-00305-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing (CC) is a technology that delivers its service by means of the internet. In the modern scenario, cloud storage services have gained attention. The cloud environment confronts data breaches expansively in cloud storage, which might bring about the disclosure of personal in addition to corporate data. Thus, the requirement arises for the creation of a more foremost authentication system. Customary authentication schemes depend on techniques, like Password Authentications Protocol (PAP), Challenge Handshakes Authentication Protocols (CHAP), as well as One-Time Pads (OTP), which are often susceptible to malevolent attacks as well as security threats. To shun such issues, this paper proposed a Modified ECC centred secure data transfer and a ‘3’-factor authentication scheme in the untrusted cloud environment. The proposed work comprises ‘3’ steps: authentication, data compression, and safe data transfer. In the authentication phase, the SHA-512 algorithm along with CCP is utilized. After that, the user-uploaded data is compressed utilizing CHA on the server-side. Next, MECC encrypts the compressed data, and then, safely uploaded it to the cloud server (CS). In the investigational appraisal, the proposed work is contrasted with the prevailing methods. The outcomes proved that the proposed work renders better security than the prevailing methods.},
  archive      = {J_CIS},
  author       = {Vengala, Dilip Venkata Kumar and Kavitha, D. and Kumar, A. P. Siva},
  doi          = {10.1007/s40747-021-00305-0},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2915-2928},
  shortjournal = {Complex Intell. Syst.},
  title        = {Three factor authentication system with modified ECC based secured data transfer: Untrusted cloud environment},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluating feature combination strategies for hate-speech
detection in spanish using linguistic features and transformers.
<em>CIS</em>, <em>9</em>(3), 2893–2914. (<a
href="https://doi.org/10.1007/s40747-022-00693-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of social networks has allowed misogynistic, xenophobic, and homophobic people to spread their hate-speech to intimidate individuals or groups because of their gender, ethnicity or sexual orientation. The consequences of hate-speech are devastating, causing severe depression and even leading people to commit suicide. Hate-speech identification is challenging as the large amount of daily publications makes it impossible to review every comment by hand. Moreover, hate-speech is also spread by hoaxes that requires language and context understanding. With the aim of reducing the number of comments that should be reviewed by experts, or even for the development of autonomous systems, the automatic identification of hate-speech has gained academic relevance. However, the reliability of automatic approaches is still limited specifically in languages other than English, in which some of the state-of-the-art techniques have not been analyzed in detail. In this work, we examine which features are most effective in identifying hate-speech in Spanish and how these features can be combined to develop more accurate systems. In addition, we characterize the language present in each type of hate-speech by means of explainable linguistic features and compare our results with state-of-the-art approaches. Our research indicates that combining linguistic features and transformers by means of knowledge integration outperforms current solutions regarding hate-speech identification in Spanish.},
  archive      = {J_CIS},
  author       = {García-Díaz, José Antonio and Jiménez-Zafra, Salud María and García-Cumbreras, Miguel Angel and Valencia-García, Rafael},
  doi          = {10.1007/s40747-022-00693-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2893-2914},
  shortjournal = {Complex Intell. Syst.},
  title        = {Evaluating feature combination strategies for hate-speech detection in spanish using linguistic features and transformers},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combating the infodemic: COVID-19 induced fake news
recognition in social media networks. <em>CIS</em>, <em>9</em>(3),
2879–2891. (<a
href="https://doi.org/10.1007/s40747-022-00672-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 has caused havoc globally due to its transmission pace among the inhabitants and prolific rise in the number of people contracting the disease worldwide. As a result, the number of people seeking information about the epidemic via Internet media has increased. The impact of the hysteria that has prevailed makes people believe and share everything related to illness without questioning its truthfulness. As a result, it has amplified the misinformation spread on social media networks about the disease. Today, there is an immediate need to restrict disseminating false news, even more than ever before. This paper presents an early fusion-based method for combining key features extracted from context-based embeddings such as BERT, XLNet, and ELMo to enhance context and semantic information collection from social media posts and achieve higher accuracy for false news identification. From the observation, we found that the proposed early fusion-based method outperforms models that work on single embeddings. We also conducted detailed studies using several machine learning and deep learning models to classify misinformation on social media platforms relevant to COVID-19. To facilitate our work, we have utilized the dataset of “CONSTRAINT shared task 2021”. Our research has shown that language and ensemble models are well adapted to this role, with a 97% accuracy.},
  archive      = {J_CIS},
  author       = {Biradar, Shankar and Saumya, Sunil and Chauhan, Arun},
  doi          = {10.1007/s40747-022-00672-2},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2879-2891},
  shortjournal = {Complex Intell. Syst.},
  title        = {Combating the infodemic: COVID-19 induced fake news recognition in social media networks},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TVS: A trusted verification scheme for office documents
based on blockchain. <em>CIS</em>, <em>9</em>(3), 2865–2877. (<a
href="https://doi.org/10.1007/s40747-021-00617-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To realize the encryption of document information, authority authentication, and traceability of historical records, we propose a trusted verification scheme (TVS) for office documents to ensure security. Specifically, the scheme is realized by timestamps, smart contracts (or chaincode), and other blockchain technologies. It is based on the features of blockchain, such as security, credibility, immutability, and traceability of network behavior. And the TVS stores users and documents information through blockchain; it can monitor the state changes of office documents in real time by setting the trigger conditions of smart contracts. The experiment indicates that we have realized the real-time monitoring of data and the traceability of historical records. Moreover, we have achieved the purpose of document encryption and authority authentication, ensuring the authenticity and objectivity of data, avoiding the illegal tampering of malicious users to realize the trusted verification for documents.},
  archive      = {J_CIS},
  author       = {Zhai, Xue and Pang, Shanchen and Wang, Min and Qiao, Sibo and Lv, Zhihan},
  doi          = {10.1007/s40747-021-00617-1},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2865-2877},
  shortjournal = {Complex Intell. Syst.},
  title        = {TVS: A trusted verification scheme for office documents based on blockchain},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IFND: A benchmark dataset for fake news detection.
<em>CIS</em>, <em>9</em>(3), 2843–2863. (<a
href="https://doi.org/10.1007/s40747-021-00552-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spotting fake news is a critical problem nowadays. Social media are responsible for propagating fake news. Fake news propagated over digital platforms generates confusion as well as induce biased perspectives in people. Detection of misinformation over the digital platform is essential to mitigate its adverse impact. Many approaches have been implemented in recent years. Despite the productive work, fake news identification poses many challenges due to the lack of a comprehensive publicly available benchmark dataset. There is no large-scale dataset that consists of Indian news only. So, this paper presents IFND (Indian fake news dataset) dataset. The dataset consists of both text and images. The majority of the content in the dataset is about events from the year 2013 to the year 2021. Dataset content is scrapped using the Parsehub tool. To increase the size of the fake news in the dataset, an intelligent augmentation algorithm is used. An intelligent augmentation algorithm generates meaningful fake news statements. The latent Dirichlet allocation (LDA) technique is employed for topic modelling to assign the categories to news statements. Various machine learning and deep-learning classifiers are implemented on text and image modality to observe the proposed IFND dataset&#39;s performance. A multi-modal approach is also proposed, which considers both textual and visual features for fake news detection. The proposed IFND dataset achieved satisfactory results. This study affirms that the accessibility of such a huge dataset can actuate research in this laborious exploration issue and lead to better prediction models.},
  archive      = {J_CIS},
  author       = {Sharma, Dilip Kumar and Garg, Sonal},
  doi          = {10.1007/s40747-021-00552-1},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2843-2863},
  shortjournal = {Complex Intell. Syst.},
  title        = {IFND: A benchmark dataset for fake news detection},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hate speech operationalization: A preliminary examination of
hate speech indicators and their structure. <em>CIS</em>, <em>9</em>(3),
2827–2842. (<a
href="https://doi.org/10.1007/s40747-021-00561-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hate speech should be tackled and prosecuted based on how it is operationalized. However, the existing theoretical definitions of hate speech are not sufficiently fleshed out or easily operable. To overcome this inadequacy, and with the help of interdisciplinary experts, we propose an empirical definition of hate speech by providing a list of 10 hate speech indicators and the rationale behind them (the indicators refer to specific, observable, and measurable characteristics that offer a practical definition of hate speech). A preliminary exploratory examination of the structure of hate speech, with the focus on comments related to migrants (one of the most reported grounds of hate speech), revealed that two indicators in particular, denial of human rights and promoting violent behavior, occupy a central role in the network of indicators. Furthermore, we discuss the practical implications of the proposed hate speech indicators—especially (semi-)automatic detection using the latest natural language processing (NLP) and machine learning (ML) methods. Having a set of quantifiable indicators could benefit researchers, human right activists, educators, analysts, and regulators by providing them with a pragmatic approach to hate speech assessment and detection.},
  archive      = {J_CIS},
  author       = {Papcunová, Jana and Martončik, Marcel and Fedáková, Denisa and Kentoš, Michal and Bozogáňová, Miroslava and Srba, Ivan and Moro, Robert and Pikuliak, Matúš and Šimko, Marián and Adamkovič, Matúš},
  doi          = {10.1007/s40747-021-00561-0},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2827-2842},
  shortjournal = {Complex Intell. Syst.},
  title        = {Hate speech operationalization: A preliminary examination of hate speech indicators and their structure},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hatred and trolling detection transliteration framework
using hierarchical LSTM in code-mixed social media text. <em>CIS</em>,
<em>9</em>(3), 2813–2826. (<a
href="https://doi.org/10.1007/s40747-021-00487-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper describes the usage of self-learning Hierarchical LSTM technique for classifying hatred and trolling contents in social media code-mixed data. The Hierarchical LSTM-based learning is a novel learning architecture inspired from the neural learning models. The proposed HLSTM model is trained to identify the hatred and trolling words available in social media contents. The proposed HLSTM systems model is equipped with self-learning and predicting mechanism for annotating hatred words in transliteration domain. The Hindi–English data are ordered into Hindi, English, and hatred labels for classification. The mechanism of word embedding and character-embedding features are used here for word representation in the sentence to detect hatred words. The method developed based on HLSTM model helps in recognizing the hatred word context by mining the intention of the user for using that word in the sentence. Wide experiments suggests that the HLSTM-based classification model gives the accuracy of 97.49% when evaluated against the standard parameters like BLSTM, CRF, LR, SVM, Random Forest and Decision Tree models especially when there are some hatred and trolling words in the social media data.},
  archive      = {J_CIS},
  author       = {Shekhar, Shashi and Garg, Hitendra and Agrawal, Rohit and Shivani, Shivendra and Sharma, Bhisham},
  doi          = {10.1007/s40747-021-00487-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2813-2826},
  shortjournal = {Complex Intell. Syst.},
  title        = {Hatred and trolling detection transliteration framework using hierarchical LSTM in code-mixed social media text},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). POI recommendation method using LSTM-attention in LBSN
considering privacy protection. <em>CIS</em>, <em>9</em>(3), 2801–2812.
(<a href="https://doi.org/10.1007/s40747-021-00440-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problems of traditional point of interest (POI), such as sparse data, lack of negative feedback, and dynamic and periodic changes of user preferences, a POI recommendation method using deep learning in location-based social networks (LBSN) considering privacy protection is proposed. First, the idea of Embedding is used to quantify the user information, friend relationship, POI information, and so on, so as to obtain the internal relationship of the location. Then, based on the user&#39;s history and current POI check-in sequence set, the long- and short-term attention mechanism (LSA) is constructed, and the quantified information is used as the input of LSA to better capture the user&#39;s long-term and short-term preferences. Finally, the social network information and semantic information are fitted in different input layers, and the time and geographical location information of user&#39;s historical behavior are used to recommend the next POI for users. Gowalla and Brightkite datasets are used to demonstrate the proposed method. The results show that the performance of the proposed method is better than other comparison methods under different sparsity, location sequence length, and embedding length. When the number of iterations is 500, the recommended method tends to be stable, and the accuracy is 0.27. Moreover, the recommendation time of the proposed method is less than 130 ms, which is better than other comparative deep learning methods.},
  archive      = {J_CIS},
  author       = {Wang, Kun and Wang, Xiaofeng and Lu, Xuan},
  doi          = {10.1007/s40747-021-00440-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2801-2812},
  shortjournal = {Complex Intell. Syst.},
  title        = {POI recommendation method using LSTM-attention in LBSN considering privacy protection},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Social media intention mining for sustainable information
systems: Categories, taxonomy, datasets and challenges. <em>CIS</em>,
<em>9</em>(3), 2773–2799. (<a
href="https://doi.org/10.1007/s40747-021-00342-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intention mining is a promising research area of data mining that aims to determine end-users’ intentions from their past activities stored in the logs, which note users’ interaction with the system. Search engines are a major source to infer users’ past searching activities to predict their intention, facilitating the vendors and manufacturers to present their products to the user in a promising manner. This area has been consistently getting pertinence with an increasing trend for online purchasing. Noticeable research work has been accomplished in this area for the last two decades. There is no such systematic literature review available that provides a comprehensive review in intension mining domain to the best of our knowledge. This article presents a systematic literature review based on 109 high-quality research papers selected after rigorous screening. The analysis reveals that there exist eight prominent categories of intention. Furthermore, a taxonomy of the approaches and techniques used for intention mining have been discussed in this article. Similarly, six important types of data sets used for this purpose have also been discussed in this work. Lastly, future challenges and research gaps have also been presented for the researchers working in this domain.},
  archive      = {J_CIS},
  author       = {Rashid, Ayesha and Farooq, Muhammad Shoaib and Abid, Adnan and Umer, Tariq and Bashir, Ali Kashif and Zikria, Yousaf Bin},
  doi          = {10.1007/s40747-021-00342-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2773-2799},
  shortjournal = {Complex Intell. Syst.},
  title        = {Social media intention mining for sustainable information systems: Categories, taxonomy, datasets and challenges},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data hiding in encryption–compression domain. <em>CIS</em>,
<em>9</em>(3), 2759–2772. (<a
href="https://doi.org/10.1007/s40747-021-00309-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a robust and secure data hiding scheme to transmit grayscale image in encryption-then-compression domain. First, host image is transformed using lifting wavelet transform, Hessenberg decomposition and redundant singular value decomposition. Then, we use appropriate scaling factor to invisibly embed the singular value of watermark data into the lower frequency sub-band of the host image. We also use suitable encryption-then-compression scheme to improve the security of the image. Additionally, de-noising convolutional neural network is performed at extracted mark data to enhance the robustness of the scheme. Experimental results verify the effectiveness of our scheme, including embedding capacity, robustness, invisibility, and security. Further, it is established that our scheme has a better ability to recover concealed mark than conventional ones at low cost.},
  archive      = {J_CIS},
  author       = {Singh, O. P. and Singh, A. K.},
  doi          = {10.1007/s40747-021-00309-w},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2759-2772},
  shortjournal = {Complex Intell. Syst.},
  title        = {Data hiding in encryption–compression domain},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ST-v-net: Incorporating shape prior into convolutional
neural networks for proximal femur segmentation. <em>CIS</em>,
<em>9</em>(3), 2747–2758. (<a
href="https://doi.org/10.1007/s40747-021-00427-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We aim to develop a deep-learning-based method for automatic proximal femur segmentation in quantitative computed tomography (QCT) images. We proposed a spatial transformation V-Net (ST-V-Net), which contains a V-Net and a spatial transform network (STN) to extract the proximal femur from QCT images. The STN incorporates a shape prior into the segmentation network as a constraint and guidance for model training, which improves model performance and accelerates model convergence. Meanwhile, a multi-stage training strategy is adopted to fine-tune the weights of the ST-V-Net. We performed experiments using a QCT dataset which included 397 QCT subjects. During the experiments for the entire cohort and then for male and female subjects separately, 90% of the subjects were used in ten-fold stratified cross-validation for training and the rest of the subjects were used to evaluate the performance of models. In the entire cohort, the proposed model achieved a Dice similarity coefficient (DSC) of 0.9888, a sensitivity of 0.9966 and a specificity of 0.9988. Compared with V-Net, the Hausdorff distance was reduced from 9.144 to 5.917 mm, and the average surface distance was reduced from 0.012 to 0.009 mm using the proposed ST-V-Net. Quantitative evaluation demonstrated excellent performance of the proposed ST-V-Net for automatic proximal femur segmentation in QCT images. In addition, the proposed ST-V-Net sheds light on incorporating shape prior to segmentation to further improve the model performance.},
  archive      = {J_CIS},
  author       = {Zhao, Chen and Keyak, Joyce H. and Tang, Jinshan and Kaneko, Tadashi S. and Khosla, Sundeep and Amin, Shreyasee and Atkinson, Elizabeth J. and Zhao, Lan-Juan and Serou, Michael J. and Zhang, Chaoyang and Shen, Hui and Deng, Hong-Wen and Zhou, Weihua},
  doi          = {10.1007/s40747-021-00427-5},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2747-2758},
  shortjournal = {Complex Intell. Syst.},
  title        = {ST-V-net: Incorporating shape prior into convolutional neural networks for proximal femur segmentation},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review on deep learning approaches for low-dose computed
tomography restoration. <em>CIS</em>, <em>9</em>(3), 2713–2745. (<a
href="https://doi.org/10.1007/s40747-021-00405-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computed Tomography (CT) is a widely use medical image modality in clinical medicine, because it produces excellent visualizations of fine structural details of the human body. In clinical procedures, it is desirable to acquire CT scans by minimizing the X-ray flux to prevent patients from being exposed to high radiation. However, these Low-Dose CT (LDCT) scanning protocols compromise the signal-to-noise ratio of the CT images because of noise and artifacts over the image space. Thus, various restoration methods have been published over the past 3 decades to produce high-quality CT images from these LDCT images. More recently, as opposed to conventional LDCT restoration methods, Deep Learning (DL)-based LDCT restoration approaches have been rather common due to their characteristics of being data-driven, high-performance, and fast execution. Thus, this study aims to elaborate on the role of DL techniques in LDCT restoration and critically review the applications of DL-based approaches for LDCT restoration. To achieve this aim, different aspects of DL-based LDCT restoration applications were analyzed. These include DL architectures, performance gains, functional requirements, and the diversity of objective functions. The outcome of the study highlights the existing limitations and future directions for DL-based LDCT restoration. To the best of our knowledge, there have been no previous reviews, which specifically address this topic.},
  archive      = {J_CIS},
  author       = {Kulathilake, K. A. Saneera Hemantha and Abdullah, Nor Aniza and Sabri, Aznul Qalid Md and Lai, Khin Wee},
  doi          = {10.1007/s40747-021-00405-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2713-2745},
  shortjournal = {Complex Intell. Syst.},
  title        = {A review on deep learning approaches for low-dose computed tomography restoration},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Security for eHealth system: Data hiding in AMBTC compressed
images via gradient-based coding. <em>CIS</em>, <em>9</em>(3),
2699–2711. (<a
href="https://doi.org/10.1007/s40747-021-00391-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various eHealth applications based on the Internet of Things (IoT) contain a considerable number of medical images and visual electronic health records, which are transmitted through the Internet everyday. Information forensics thus becomes a critical issue. This paper presents a data hiding algorithm for absolute moment block truncation coding (AMBTC) images, wherein secret data, or the authentication code, can be embedded in images to enhance security. Moreover, in view of the importance of transmission efficiency in IoT, image compression is widely used in Internet-based applications. To cope with this challenge, we present a novel compression method named gradient-based (GB) compression, which is compatible with AMBTC compression. Therefore, after applying the block classification scheme, GB compression and data hiding can be performed jointly for blocks with strong gradient effects, and AMBTC compression and data hiding can be performed jointly for the remaining blocks. From the experimental results, we demonstrate that the proposed method outperforms other state-of-the-art methods.},
  archive      = {J_CIS},
  author       = {Chen, Yung-Yao and Hu, Yu-Chen and Kao, Hsiang-Yun and Lin, Yu-Hsiu},
  doi          = {10.1007/s40747-021-00391-0},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2699-2711},
  shortjournal = {Complex Intell. Syst.},
  title        = {Security for eHealth system: Data hiding in AMBTC compressed images via gradient-based coding},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). O-WCNN: An optimized integration of spatial and spectral
feature map for arrhythmia classification. <em>CIS</em>, <em>9</em>(3),
2685–2698. (<a
href="https://doi.org/10.1007/s40747-021-00371-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The regular monitoring and accurate diagnosis of arrhythmia are critically important, leading to a reduction in mortality rate due to cardiovascular diseases (CVD) such as heart stroke or cardiac arrest. This paper proposes a novel convolutional neural network (CNN) model for arrhythmia classification. The proposed model offers the following improvements compared with traditional CNN models. Firstly, the multi-channel model can concatenate spectral and spatial feature maps. Secondly, the structural unit is composed of a depthwise separable convolution layer followed by activation and batch normalization layers. The structural unit offers effective utilization of network parameters. Also, the optimization of hyperparameters is done using Hyperopt library, based on Sequential Model-Based Global Optimization algorithm (SMBO). These improvements make the network more efficient and accurate for arrhythmia classification. The proposed model is evaluated using tenfold cross-validation following both subject-oriented inter-patient and class-oriented intra-patient evaluation protocols. Our model achieved 99.48% and 99.46% accuracy in VEB (ventricular ectopic beat) and SVEB (supraventricular ectopic beat) class classification, respectively. The model is compared with state-of-the-art models and has shown significant performance improvement.},
  archive      = {J_CIS},
  author       = {Jangra, Manisha and Dhull, Sanjeev Kumar and Singh, Krishna Kant and Singh, Akansha and Cheng, Xiaochun},
  doi          = {10.1007/s40747-021-00371-4},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2685-2698},
  shortjournal = {Complex Intell. Syst.},
  title        = {O-WCNN: An optimized integration of spatial and spectral feature map for arrhythmia classification},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human gait analysis for osteoarthritis prediction: A
framework of deep learning and kernel extreme learning machine.
<em>CIS</em>, <em>9</em>(3), 2665–2683. (<a
href="https://doi.org/10.1007/s40747-020-00244-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human gait analysis is a novel topic in the field of computer vision with many famous applications like prediction of osteoarthritis and patient surveillance. In this application, the abnormal behavior like problems in walking style is detected of suspected patients. The suspected behavior means assessments in terms of knee joints and any other symptoms that directly affected patients’ walking style. Human gait analysis carries substantial importance in the medical domain, but the variability in patients’ clothes, viewing angle, and carrying conditions, may severely affect the performance of a system. Several deep learning techniques, specifically focusing on efficient feature selection, have been recently proposed for this purpose, unfortunately, their accuracy is rather constrained. To address this disparity, we propose an aggregation of robust deep learning features in Kernel Extreme Learning Machine. The proposed framework consists of a series of steps. First, two pre-trained Convolutional Neural Network models are retrained on public gait datasets using transfer learning, and features are extracted from the fully connected layers. Second, the most discriminant features are selected using a novel probabilistic approach named Euclidean Norm and Geometric Mean Maximization along with Conditional Entropy. Third, the aggregation of the robust features is performed using Canonical Correlation Analysis, and the aggregated features are subjected to various classifiers for final recognition. The evaluation of the proposed scheme is performed on a publicly available gait image dataset CASIA B. We demonstrate that the proposed feature aggregation methodology, once used with the Kernel Extreme Learning Machine, achieves accuracy beyond 96%, and outperforms the existing works and several other widely adopted classifiers.},
  archive      = {J_CIS},
  author       = {Khan, Muhammad Attique and Kadry, Seifedine and Parwekar, Pritee and Damaševičius, Robertas and Mehmood, Asif and Khan, Junaid Ali and Naqvi, Syed Rameez},
  doi          = {10.1007/s40747-020-00244-2},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2665-2683},
  shortjournal = {Complex Intell. Syst.},
  title        = {Human gait analysis for osteoarthritis prediction: A framework of deep learning and kernel extreme learning machine},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diabetic retinopathy detection and classification using
capsule networks. <em>CIS</em>, <em>9</em>(3), 2651–2664. (<a
href="https://doi.org/10.1007/s40747-021-00318-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, diabetic retinopathy is a prominent reason for blindness among the people who suffer from diabetes. Early and timely detection of this problem is critical for a good prognosis. An automated system for this purpose contains several phases like identification and classification of lesions in fundus images. Machine learning techniques based on manual extraction of features and automatic extraction of features with convolution neural network have been presented for diabetic retinopathy detection. The recent developments like capsule networks in deep learning and their significant success over traditional machine learning methods for a variety of applications inspired the researchers to apply them for diabetic retinopathy diagnosis. In this paper, a reformed capsule network is developed for the detection and classification of diabetic retinopathy. Using the convolution and primary capsule layer, the features are extracted from the fundus images and then using the class capsule layer and softmax layer the probability that the image belongs to a specific class is estimated. The efficiency of the proposed reformed network is validated concerning four performance measures by considering the Messidor dataset. The constructed capsule network attains an accuracy of 97.98%, 97.65%, 97.65%, and 98.64% on the healthy retina, stage 1, stage 2, and stage 3 fundus images.},
  archive      = {J_CIS},
  author       = {Kalyani, G. and Janakiramaiah, B. and Karuna, A. and Prasad, L. V. Narasimha},
  doi          = {10.1007/s40747-021-00318-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2651-2664},
  shortjournal = {Complex Intell. Syst.},
  title        = {Diabetic retinopathy detection and classification using capsule networks},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Secure-user sign-in authentication for IoT-based eHealth
systems. <em>CIS</em>, <em>9</em>(3), 2629–2649. (<a
href="https://doi.org/10.1007/s40747-020-00231-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sustainable Computing has advanced the technological evolution of the Internet and information-based communication technology. It is nowadays emerging in the form of the Cloud of Medical Things (CoMT) to develop smart healthcare systems. The academic community has lately made great strides for the development of security for the CoMT based application systems, such as e-healthcare systems, industrial automation systems, military surveillance systems, and so on. To the architecture of CoMT based Smart Environment, Chebyshev Chaotic-Map based single-user sign-in (S-USI) is found as a significant security-control mechanism. To ensure the fidelity, the S-USI assigns a unary-token to the legal users to access the various services, provided by a service provider over an IP-enabled distributed networks. Numerous authentication mechanisms have been presented for the cloud-based distributed networks. However, most of the schemes are still persuasible to security threats, such as user-anonymity, privileged-insider, mutual authentication, and replay type of attacks. This paper applies a sensor/sensor-tag based smart healthcare environment that uses S-USI to provide security and privacy. To strengthen the authentication process, a robust secure based S-USI mechanism and a well-formed coexistence protocol proof for pervasive services in the cloud are proposed. Using the formal security analysis, the prominence of the proposed strategies is proven to show the security efficiency of proposed S-USI. From the formal verification, the comparison results demonstrate that the proposed S-USI consumes less computation overhead; and thus it can be more suitable for the telecare medical information systems.},
  archive      = {J_CIS},
  author       = {Deebak, B. D. and Al-Turjman, Fadi},
  doi          = {10.1007/s40747-020-00231-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2629-2649},
  shortjournal = {Complex Intell. Syst.},
  title        = {Secure-user sign-in authentication for IoT-based eHealth systems},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent IoT-based large-scale inverse planning system
considering postmodulation factors. <em>CIS</em>, <em>9</em>(3),
2613–2627. (<a
href="https://doi.org/10.1007/s40747-020-00207-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The model and algorithm of intensity-modulated radiotherapy (IMRT) are updated increasingly quickly, but the hardware upgrade of primary hospitals often lags behind. The new generation of intelligent precise radiotherapy platforms provides users with intelligent medical consortium services using big data, artificial intelligence and industrial Internet of Things technology. This technology can ensure that under the real-time guidance of a professional medical consortium, primary hospitals can realize rapid large-scale reverse planning design and can more accurately consider many factors of postprocessing. Although large-scale healthcare systems, such as volumetric-modulated arc therapy and other accurate radiotherapy technologies, have developed rapidly, the development of step-and-shoot-mode IMRT technology is still very important for developing countries. For software, in addition to the conformity of the dose distribution, the modulation speed, convenience and stability of the later dose delivery should also be considered in inverse planning. Therefore, this paper analyzes the main problems in conventional IMRT inverse planning, including the smoothing of the fluence map, the selection of the gantry angle and the dose leakage of tongue–groove effects. To address these issues, a novel Intelligent IoT-based large-scale inverse planning strategy with the key factors of the postmodulation is developed, and a detailed flow chart is also provided. The scheme consists of two steps. The first step is to obtain a relatively optimal combination of gantry angles by considering the dose distribution requirements and constraints and the modulation requirements and constraints. The second step is to optimize the intensity map, to smooth the map based on prior knowledge according to the determined angles, and to obtain the final modulation scheme according to the relevant objectives and constraints of the map decomposition (leaf sequencing). In an experiment, we calculate and validate the clinical head and neck case. Because of the special gantry angle selection, the angle combination is optimized from the initial equivalent distribution to adapt to the target area and protect the nontarget area. The value of the objective function varies greatly after the optimization, especially in the target area, and the target value decreases by approximately 10%. On this basis, we smooth the fluence map by a partial differential equation with prior knowledge and a minimization of the total number of monitor units. It is also shown from the objective function value that the target value is essentially unchanged for the target area, while for the nontarget area, the value decreases by 16%, which is very impressive.},
  archive      = {J_CIS},
  author       = {Lan, Yihua and Li, Fang and Li, Zijun and Yue, Binglei and Zhang, Yin},
  doi          = {10.1007/s40747-020-00207-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2613-2627},
  shortjournal = {Complex Intell. Syst.},
  title        = {Intelligent IoT-based large-scale inverse planning system considering postmodulation factors},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Angle of attack prediction using recurrent neural networks
in flight conditions with faulty sensors in the case of f-16 fighter
jet. <em>CIS</em>, <em>9</em>(3), 2599–2611. (<a
href="https://doi.org/10.1007/s40747-021-00612-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The angle of attack (AOA) is one of the critical parameters in a fixed-wing aircraft because all aerodynamic forces are functions of the AOA. Most methods for estimation of the AOA do not provide information on the method’s performance in the presence of noise, faulty total velocity measurement, and faulty pitch rate measurement. This paper investigates data-driven modeling of the F-16 fighter jet and AOA prediction in flight conditions with faulty sensor measurements using recurrent neural networks (RNNs). The F-16 fighter jet is modeled in several architectures: simpleRNN (sRNN), long-short-term memory (LSTM), gated recurrent unit (GRU), and the combinations LSTM-GRU, sRNN-GRU, and sRNN-LSTM. The developed models are tested by their performance to predict the AOA of the F-16 fighter jet in flight conditions with faulty sensor measurements: faulty total velocity measurement, faulty pitch rate and total velocity measurement, and faulty AOA measurement. We show the model obtained using sRNN trained with the adaptive momentum estimation algorithm (Adam) produces more exact predictions during faulty total velocity measurement and faulty total velocity and pitch rate measurement but fails to perform well during faulty AOA measurement. The sRNN-GRU combinations with the GRU layer closer to the output layer performed better than all the other networks. When using this architecture, the correlation and mean squared error (MSE) between the true (real) value and the predicted value during faulty AOA measurement increased by 0.12 correlation value and the MSE decreased by 4.3 degrees if one uses only sRNN. In the sRNN-GRU combined architecture, moving the GRU closer to the output layer produced a model with better predicted values.},
  archive      = {J_CIS},
  author       = {Mersha, Bemnet Wondimagegnehu and Jansen, David N. and Ma, Hongbin},
  doi          = {10.1007/s40747-021-00612-6},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2599-2611},
  shortjournal = {Complex Intell. Syst.},
  title        = {Angle of attack prediction using recurrent neural networks in flight conditions with faulty sensors in the case of F-16 fighter jet},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). General type industrial temperature system control based on
fuzzy fractional-order PID controller. <em>CIS</em>, <em>9</em>(3),
2585–2597. (<a
href="https://doi.org/10.1007/s40747-021-00431-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fuzzy fractional-order PID control algorithm for a general type industrial temperature control system is proposed in this paper. In order to improve the production quality and controlled model accuracy, a fractional-order elementary system is used to describe the temperature control process. The gain coefficients of the proposed fractional-order PID controller is updated online based on a set of fractional-order fuzzy rules which are defined by Mittag–Leffler functions and follow fat-tailed distributions. Therefore, the proposed controller parameters could be auto-tuned according to model uncertainties, noise disturbance, random delay, and etc. Examples of the studied temperature control systems are shown to verify the effectiveness of the proposed controller. The superiority of fractional calculus is fully explored in the presented control methodology. The controlled temperature profile with the proposed algorithm could realize more satisfactory dynamic performance, better robustness respect to environment changes caused by internal and external disturbance.},
  archive      = {J_CIS},
  author       = {Liu, Lu and Xue, Dingyu and Zhang, Shuo},
  doi          = {10.1007/s40747-021-00431-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2585-2597},
  shortjournal = {Complex Intell. Syst.},
  title        = {General type industrial temperature system control based on fuzzy fractional-order PID controller},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Voice of urban park visitors: Exploring destination
attributes influencing behavioural intentions through online review
mining. <em>CIS</em>, <em>9</em>(3), 2571–2583. (<a
href="https://doi.org/10.1007/s40747-020-00223-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we will identify the destination attributes of a popular urban park and investigate their specific roles in forming visitors&#39; behavioural intentions using text mining approaches. The principles of natural language processing and psychometric procedure were combined to achieve the objectives of the research. Initially, park visitors’ online reviews were collected and analysed to identify possible latent dimensions for questionnaire design. Then, exploratory factor analysis (EFA) and confirmatory factor analysis (CFA) were used for crucial factor selection and verification. Lastly, a structural equation model (SEM) was constructed to investigate the impacts of these park attributes on the behavioural intention of visitors.},
  archive      = {J_CIS},
  author       = {Ma, Ke and Jiang, Beibei},
  doi          = {10.1007/s40747-020-00223-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2571-2583},
  shortjournal = {Complex Intell. Syst.},
  title        = {Voice of urban park visitors: Exploring destination attributes influencing behavioural intentions through online review mining},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CEEMDAN-IMFx-PCA-CICA: An improved single-channel blind
source separation in multimedia environment for motion artifact
reduction in ambulatory ECG. <em>CIS</em>, <em>9</em>(3), 2555–2569. (<a
href="https://doi.org/10.1007/s40747-020-00188-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-term monitoring of ECG via wearable monitoring systems has already been widely adopted to detect and prevent heart diseases. However, one of the main issues faced by wearable ECG monitoring systems is that motion artifacts significantly affect the systems&#39; stability and reliability. Therefore, motion artifact reduction is a very challenging task in filtering and processing physiological signals. Based on the existing algorithms and ECG prior knowledge, in this paper, we propose an algorithm, CEEMDAN-IMFx-PCA-CICA, for motion artifact reduction in ambulatory ECG signals using single-channel blind source separation technique. Our algorithm first utilizes CEEMDAN to decompose the mixed signals into IMFs (intrinsic mode function) containing different source signal features, thereby forming new multi-dimensional signals. Using the correlation between IMFx (IMF component with the most ECG features) and each IMF, and PCA are then applied to reduce the dimension of each IMF. Finally, the blind separation of the source ECG signals is achieved by using CICA with IMFx as the constraint reference component. The results of our experiments indicate that our algorithm outperformed CEEMDAN-CICA, CEEMDAN-PCA-CICA, and improved CEEMDAN-PCA-CICA. Besides, the number of iterations of the CICA is significantly reduced; the separated source signal is better; the obtained result is stable. Furthermore, the separated ECG signal has a higher correlation with the source ECG signal and a lower RRMSE, especially in the case of high noise-to-signal ratios.},
  archive      = {J_CIS},
  author       = {Xiong, Fan and Chen, Dongyi},
  doi          = {10.1007/s40747-020-00188-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2555-2569},
  shortjournal = {Complex Intell. Syst.},
  title        = {CEEMDAN-IMFx-PCA-CICA: An improved single-channel blind source separation in multimedia environment for motion artifact reduction in ambulatory ECG},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Big data-driven public transportation network: A simulation
approach. <em>CIS</em>, <em>9</em>(3), 2541–2553. (<a
href="https://doi.org/10.1007/s40747-021-00462-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the maturity of big data technology, analyzing residents’ travel habits and tracks has become an important research direction in the field of intelligent transportation study. In this paper, based on the subway and bus ride data, a subway-bus double-layer network model was established using complex network theory, taking the optimal traffic efficiency as the goal, the structure of intelligent bus network optimization method is proposed, and an empirical study is conducted on the Beijing bus network. In the empirical study, by adding or deleting bus station in the network, obtain an efficient network structure, the goal of optimal operation efficiency of the bus network was realized, and the theoretical and practical research on solving the problem of transportation line network planning with big data of traffic travel was enriched.},
  archive      = {J_CIS},
  author       = {Wang, Zhaohua and Li, Xuewei and Zhu, Xin and Li, Jing and Wang, Fan and Wang, Fei},
  doi          = {10.1007/s40747-021-00462-2},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2541-2553},
  shortjournal = {Complex Intell. Syst.},
  title        = {Big data-driven public transportation network: A simulation approach},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Charging station planning based on the accumulation prospect
theory and dynamic user equilibrium. <em>CIS</em>, <em>9</em>(3),
2521–2539. (<a
href="https://doi.org/10.1007/s40747-021-00414-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale use of electric vehicles will greatly increase the traffic pressure on urban road network. Therefore, planning of charging stations for electric vehicles considering charging demand and transportation network is particularly important for the coordinated development of electric vehicles and intelligent transportation. Under the condition of bounded rationality, this paper considers such factors as the travel utility perception difference between the users of fuel vehicles and electric vehicles, the time-varying of traffic flow, the location and service level of charging stations. On this basis, combining the cumulative prospect theory, dynamic traffic flow allocation and charging demands, a two-level programming model is established to solve the problem of charging station site selection. The upper layer is a system optimal model, the goal is to minimize the travel time of the network. The lower model describes the time-variability of departure time and the randomness of charging and travel behaviors, establishes the dynamic user equilibrium model and designs the heuristic algorithm. The validity of the model and algorithm is verified by a numerical example. Through the simulation experiment, the optimal location scheme of charging station under different electric vehicle proportion is obtained, and the driving characteristics of two types of vehicles are analyzed. Compared with the traditional model, it is found that the charging station planning considering bounded rationality can achieve higher road network traffic efficiency with fewer charging piles.},
  archive      = {J_CIS},
  author       = {Heting, Qiu and Shuihai, Dou and Huayan, Shang and Jun, Zhang},
  doi          = {10.1007/s40747-021-00414-w},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2521-2539},
  shortjournal = {Complex Intell. Syst.},
  title        = {Charging station planning based on the accumulation prospect theory and dynamic user equilibrium},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantity decisions of two-stage competitive location model
based on different location modes. <em>CIS</em>, <em>9</em>(3),
2509–2520. (<a
href="https://doi.org/10.1007/s40747-021-00385-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The facility location of a competing firm in a market has great importance in supply chain management. The two-stage competitive location model formulates the decision process of an entrant firm facing both location and price competition. In this paper, we incorporated the facility quantity as a decision variable into a two-stage competitive location model with the objective of maximized profit. Sequential location mode and simultaneous location mode were applied to simulate different location behavior. We developed an approximate branch and bound method to accelerate optimal location searching speed under the premise of accuracy. Greedy algorithm and approximate branch and bound method were used in two location modes. From algorithm evaluation, we found that the approximate branch and bound method is an ideal supplement of the traditional branch and bound method, especially for location problems with large-scale potential locations. Compare the results of the two modes, we found when a new firm is going to enter a market with both price and location competition, sequential location mode is an advantage strategy, since it can gain more profit than simultaneous location mode.},
  archive      = {J_CIS},
  author       = {Li, Yadong and Li, Xuemei},
  doi          = {10.1007/s40747-021-00385-y},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2509-2520},
  shortjournal = {Complex Intell. Syst.},
  title        = {Quantity decisions of two-stage competitive location model based on different location modes},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid ant colony algorithm based on multiple strategies
for the vehicle routing problem with time windows. <em>CIS</em>,
<em>9</em>(3), 2491–2508. (<a
href="https://doi.org/10.1007/s40747-021-00401-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a vehicle routing problem with time windows (TWVRP). In this problem, we consider a hard time constraint that the fleet can only serve customers within a specific time window. To solve this problem, a hybrid ant colony (HACO) algorithm is proposed based on ant colony algorithm and mutation operation. The HACO algorithm proposed has three innovations: the first is to update pheromones with a new method; the second is the introduction of adaptive parameters; and the third is to add the mutation operation. A famous Solomon instance is used to evaluate the performance of the proposed algorithm. Experimental results show that HACO algorithm is effective against solving the problem of vehicle routing with time windows. Besides, the proposed algorithm also has practical implications for vehicle routing problem and the results show that it is applicable and effective in practical problems.},
  archive      = {J_CIS},
  author       = {Wu, Hongguang and Gao, Yuelin and Wang, Wanting and Zhang, Ziyu},
  doi          = {10.1007/s40747-021-00401-1},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2491-2508},
  shortjournal = {Complex Intell. Syst.},
  title        = {A hybrid ant colony algorithm based on multiple strategies for the vehicle routing problem with time windows},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A branch-and-price algorithm for two-echelon electric
vehicle routing problem. <em>CIS</em>, <em>9</em>(3), 2475–2490. (<a
href="https://doi.org/10.1007/s40747-021-00403-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by express and e-commerce companies’ distribution practices, we study a two-echelon electric vehicle routing problem. In this problem, fuel-powered vehicles are used to transport goods from a depot to intermediate facilities (satellites) in the first echelon, whereas electric vehicles, which have limited driving ranges and need to be recharged at recharging stations, are used to transfer goods from the satellites to customers in the second echelon. We model the problem as an arc flow model and decompose the model into a master problem and pricing subproblem. We propose a branch-and-price algorithm to solve it. We use column generation to solve the restricted master problem to provide lower bounds. By enumerating all the subsets of the satellites, we generate feasible columns by solving the elementary shortest path problem with resource constraints in the first echelon. Then, we design a bidirectional labeling algorithm to generate feasible routes in the second echelon. Comparing the performance of our proposed algorithm with that of CPLEX in solving a set of small-sized instances, we demonstrate the former’s effectiveness. We further assess our algorithm in solving two sets of larger scale instances. We also examine the impacts of some model parameters on the solution.},
  archive      = {J_CIS},
  author       = {Wu, Zhiguo and Zhang, Juliang},
  doi          = {10.1007/s40747-021-00403-z},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2475-2490},
  shortjournal = {Complex Intell. Syst.},
  title        = {A branch-and-price algorithm for two-echelon electric vehicle routing problem},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge organization of node enterprises’ technological
innovation under supply chain environment. <em>CIS</em>, <em>9</em>(3),
2459–2473. (<a
href="https://doi.org/10.1007/s40747-021-00388-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An improved text classification method based on domain ontology is proposed in this paper to organize the mass information that records node enterprises’ innovation activities under the supply chain environment. This method can classify the documents of node enterprises under the supply chain without a training set. It achieves a precision of 80% for documents’ classification, which outperforms the baseline method. Besides, the paper constructs a domain ontology of enterprises’ technological innovation under the supply chain that effectively enhances the semantic relationship between words. Therefore, it can summarize and classify the textual information generated by node enterprises in product design, production, storage, logistics, and sales.},
  archive      = {J_CIS},
  author       = {Zhang, Qianqian and Liu, Shifeng and Tu, Qun},
  doi          = {10.1007/s40747-021-00388-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2459-2473},
  shortjournal = {Complex Intell. Syst.},
  title        = {Knowledge organization of node enterprises’ technological innovation under supply chain environment},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). O2O selection mode portrait and optimization for railway
service enterprises based on k-means. <em>CIS</em>, <em>9</em>(3),
2447–2458. (<a
href="https://doi.org/10.1007/s40747-021-00375-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Establishing a platform successfully is just the basis for railway service companies to meet the demands of online to offline (O2O) supply chain services. In this paper, the K-means algorithm is first used to construct the user segmentation model of railway service companies and the AISAS (Attention-Interest-Search-Action-Share) method is used to establish the evaluation O2O model. According to this result, we propose four modes to establish O2O supply chain service platform for railway enterprise, which are self-built and self-operated (SBSO, Mode1), commissioned construction and self-operated (CCSO, Mode2), self-built and commissioned operation (SBCO, Mode3), commissioned construction and commissioned operation (CCCO, Mode4). By comparing the advantages and disadvantages of the four modes, the results illustrate the optimal model is impacted by the nature of the platform&#39;s operating products and the operating capabilities of the partners. The railway service enterprise needs to transform the traditional multi-level management model into the flat model to adapt the O2O supply chain strategies.},
  archive      = {J_CIS},
  author       = {Sun, Changsuo and Ye, Long and Zhang, Na},
  doi          = {10.1007/s40747-021-00375-0},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2447-2458},
  shortjournal = {Complex Intell. Syst.},
  title        = {O2O selection mode portrait and optimization for railway service enterprises based on K-means},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal coordination and service level of the supply chain
in the sharing economy: The perspective of social responsibility.
<em>CIS</em>, <em>9</em>(3), 2429–2445. (<a
href="https://doi.org/10.1007/s40747-021-00361-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sharing economy has changed people’s lives. These changes have accelerated the pace of life and improved the quality of life, but have also had some negative effects. For example, in China, in the supply chain of the takeout delivery platform, the service deliverer often violates traffic rules to shorten the delivery time. This phenomenon has aroused widespread concern in society. From the perspective of sustainable operation of platform enterprises and reducing social risks, this issue is worthy of in-depth study. First, this study analyses the optimal decision-making about pricing and service efforts, then discusses the supply chain coordination mechanism under a revenue-sharing contract, and finds that the platform’s service level is related to the efforts of deliverers and the elasticity of demand/service. However, under a traditional revenue-sharing contract, the economic returns are not enough to motivate deliverers to avoid violations of traffic regulations; When the increase of cost caused by the improvement of service level is not fully covered by the revenue sharing from the platform, they have a strong incentive to break the rules even if the optimal coordination can be achieved in the supply chain. Second, this study reconstructs the revenue-sharing contract by adding social responsibility to the objective function of the platform enterprises and designs contingent rewards to regulate behaviours of service deliverers. The results indicate that when the contingent reward factor reaches a certain level, the optimal effort of the service deliverers is constrained within a reasonable range, which can to some extent reduce the occurrence of illegal behaviour. Our findings offer fresh insights on coordination of supply chain in the sharing economy, identify new direction for future research on CSR, and provide managers of platform enterprises with suggestions for regulating the behaviour of partners and balance the economic and social benefits.},
  archive      = {J_CIS},
  author       = {Guo, Jie and Guo, Yanli},
  doi          = {10.1007/s40747-021-00361-6},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2429-2445},
  shortjournal = {Complex Intell. Syst.},
  title        = {Optimal coordination and service level of the supply chain in the sharing economy: The perspective of social responsibility},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Subsidy strategy of sharing logistics platform.
<em>CIS</em>, <em>9</em>(3), 2413–2428. (<a
href="https://doi.org/10.1007/s40747-021-00331-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sharing logistics platform can effectively realize the sharing of idle logistics resources and maximize the utility of logistics resources utilization by publishing and matching the supply and demand information of logistics resource. For sharing logistics platform, subsidy strategy plays a significant role in winning market competition. Therefore, how to establish an effective subsidy scheme is a burning issue. By analyzing the problems in the transaction orders of drivers and consignor on the sharing logistics platform, this paper estimates the subsidy strategy on the following three aspects: (1) establish a dynamic model of freight supply and demand matching according to the freight cost and determine the impact of different subsidy policies on the platform usage; (2) evaluate the solution of different subsidy policies to the matching problem of vehicles and goods, and determine the optimal subsidy scheme based on the evaluation results; (3) establish the subsidy model based on platform maximum benefit and social welfare optimization and analyze a practical case of &quot;Huochebang&quot; (a Sharing logistics platform). The analysis results show that the model constructed in this paper can be well applied to the subsidy problem of sharing logistics platform and assist the platform to establish the most suitable subsidy policy to achieve the optimal economic benefits.},
  archive      = {J_CIS},
  author       = {Cai, Yingzhen and Bai, Lan and Jiang, Fan and Yin, Shi},
  doi          = {10.1007/s40747-021-00331-y},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2413-2428},
  shortjournal = {Complex Intell. Syst.},
  title        = {Subsidy strategy of sharing logistics platform},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Production decision-making system for manufacturing
enterprises constrained by carbon reduction policies. <em>CIS</em>,
<em>9</em>(3), 2393–2411. (<a
href="https://doi.org/10.1007/s40747-021-00329-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the optimal low carbon production decision system with considered the constraints of carbon emission reduction policy for manufacturing enterprises producing two kinds of products in the free market. Firstly, The research proved the optimal production combination exists and it is unique under the carbon emissions limits, and next, the research analyzed the low-carbon production decision-making system in three situations, which are carbon emission trade decision, green technology input decision, and joint decision. The research results showed that carbon emission permits trade can increase more flexibility to manufacturing enterprises and increase their profits as well. However, the carbon emissions limits set by the government would have an important impact on the production decision system of manufacturing enterprises. Carbon emission permits trade and green technology investment can optimize and improve the production decision system of manufacturing enterprises to a certain extent. Meanwhile, the government&#39;s scientific and reasonable formulation of initial carbon quotas would mobilize the enthusiasm and initiative of manufacturing enterprises to participate in carbon emission reduction. The government should also guide and encourage enterprises to invest in and develop low-carbon emission reduction technologies through tax relief, so as to improve carbon emission reduction technologies and its innovations to reduce carbon dioxide emissions.},
  archive      = {J_CIS},
  author       = {Changsong, Ma and Tiantong, Yuan and Lei, Zhong and Wei, Liu},
  doi          = {10.1007/s40747-021-00329-6},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2393-2411},
  shortjournal = {Complex Intell. Syst.},
  title        = {Production decision-making system for manufacturing enterprises constrained by carbon reduction policies},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Express delivery logistics with high-speed railway: A
perspective of payment scheme and forecast information sharing.
<em>CIS</em>, <em>9</em>(3), 2379–2391. (<a
href="https://doi.org/10.1007/s40747-021-00304-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the payment scheme and forecast information sharing issues in the express delivery logistics with the high-speed railway. The HSR carriers need to coordinate the transportation capacity between passenger and freight. It is widely recognized that the advance payment scheme (APS) using as deposit is a beneficial way for the HSR carriers to make decisions on the transportation capacity preserved for express delivery. However, the express service providers, who possess private forecast information of express delivery demand, may share inaccurate information with the HSR carriers to acquire sufficient preserved transportation capacity. This paper discusses what payment scheme is preferred by the HSR carrier, the express service provider through discussing the deposit decisions with or without forecast information sharing. We show that sharing demand forecast information can reduce the prereserved capacity and increase the profits of the HSR carrier. With the delayed payment scheme (DPS), the express service provider has no motivation to share the information; while with the APS, the HSR carrier can reasonably choose the deposit to encourage the express service provider to share the demand information. Our analysis also shows that the HSR carrier’s profits with the APS is restricted by the investment returns and the express service provider’s information sharing decisions. We also analyze the value range of the deposit, which is a proportion of the overall payment, that allows both the HSR carrier and the express service provider to prefer the APS, as well as to encourage the express service provider to share the demand information.},
  archive      = {J_CIS},
  author       = {Duan, Huawei and Ye, Yusen and Lei, Zheng and Wang, Mengting},
  doi          = {10.1007/s40747-021-00304-1},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2379-2391},
  shortjournal = {Complex Intell. Syst.},
  title        = {Express delivery logistics with high-speed railway: A perspective of payment scheme and forecast information sharing},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Private-label sustainable supplier selection using a fuzzy
entropy-VIKOR-based approach. <em>CIS</em>, <em>9</em>(3), 2361–2378.
(<a href="https://doi.org/10.1007/s40747-021-00317-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, private labels have been the focus of great development in retail due to their price advantage and consumer-oriented production. With growing customer awareness of safety and health, private-label sustainable supplier selection has become a strategic issue for many retailers. Although there are many studies on supplier selection issues and evaluation methods, studies on the sustainability and consumption sectors are rather limited. Therefore, a novel three-phase MCDM model for private-label supplier selection compliance with sustainability criteria is proposed. First, the Delphi method is used to construct a criteria system based on a detailed literature review. Then, an integrated weight algorithm is suggested, in which objective weights are based on attributes’ entropy measurements, and subjective weights are derived from decision-makers’ preferences. Eventually, during evaluation, a fuzzy set extended in VIKOR is exploited by considering the vagueness of decision makers’ expressions. The results from a case study then show that green packaging and labelling, relationship with manufacturing brand, order flexibility, and product traceability are the most important criteria in retail private-label supplier selection. The flexibility and reliability of the proposed model are also demonstrated in a practical case of supplier evaluation.},
  archive      = {J_CIS},
  author       = {Zhang, Jun and Li, Linze and Zhang, Jing and Chen, Liping and Chen, Guojiao},
  doi          = {10.1007/s40747-021-00317-w},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2361-2378},
  shortjournal = {Complex Intell. Syst.},
  title        = {Private-label sustainable supplier selection using a fuzzy entropy-VIKOR-based approach},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integration of manufacturing and pricing for downward
substitution products decision-making. <em>CIS</em>, <em>9</em>(3),
2351–2359. (<a
href="https://doi.org/10.1007/s40747-021-00320-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With a cap-and-trade policy and green technology as inputs, we built a manufacturing ordering and pricing joint decision-making model for two downward substitution products to identify the conditions for optimal order quantities and prices of products under the additive demand case. Considering the case of a single period model, the conditions required for optimal manufacturing quantities and pricing were discussed, and the construction of the model was analyzed; furthermore, a study of the tactical choices between green technology inputs and manufacturing decisions was conducted, and the conditions required for green technology manufacturing input were obtained.},
  archive      = {J_CIS},
  author       = {He, Hua},
  doi          = {10.1007/s40747-021-00320-1},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2351-2359},
  shortjournal = {Complex Intell. Syst.},
  title        = {Integration of manufacturing and pricing for downward substitution products decision-making},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A modified NK algorithm based on BP neural network and
DEMATEL for evolution path optimization of urban innovation ecosystem.
<em>CIS</em>, <em>9</em>(3), 2333–2349. (<a
href="https://doi.org/10.1007/s40747-021-00284-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the new era, the key measure to accelerate the construction of smart city, so as to promote the modernization of urban governance system and governance capacity, is to establish a good urban innovation ecosystem, and guide its continuous evolution to the direction of the highest efficiency and the best performance. Focusing on solving the practical problem of “how the urban innovation ecosystem evolves”, this paper develops a NK algorithm using BP neural network and DEMATEL method. First, through literature research, constructing the urban innovation ecosystem including five subsystems of innovation talents, innovation subjects, innovation resources, innovation environment and innovation network. Then, taking Beijing as an example, the weights and the number of epistatic relationships of each subsystem in its innovation ecosystem are calculated by BP neural network and DEMATEL method, and the NK model is modified; on this basis, the fitness values corresponding to different states of the system are calculated using MATLAB software, and the optimal evolution path of Beijing innovation ecosystem is determined through the comparison of 100,000 simulation results. The results show that the optimal evolution path of Beijing&#39;s innovation ecosystem is to create a favorable environment and culture for innovation first; then increase the input of innovation resources; and then promote the development of innovation network assets; on this basis, cultivate, attract and retain innovative talents; and finally strengthen the construction of innovation subjects.},
  archive      = {J_CIS},
  author       = {Liu, Ruijian and Tang, Fangcheng and Wang, Yuhan and Zheng, Shaofang},
  doi          = {10.1007/s40747-021-00284-2},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2333-2349},
  shortjournal = {Complex Intell. Syst.},
  title        = {A modified NK algorithm based on BP neural network and DEMATEL for evolution path optimization of urban innovation ecosystem},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). System dynamics mechanism of cross-regional collaborative
dispatch of emergency supplies based on multi-agent game. <em>CIS</em>,
<em>9</em>(3), 2321–2332. (<a
href="https://doi.org/10.1007/s40747-021-00303-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cross-regional coordinated dispatch of emergency supplies is a complex issue involving multiple topics, which covers multiple relationships and is affected by multiple variables. In the face of severe emergencies, relief supplies inside a specific area are far from meeting the explosive demand for emergency supplies. Besides, the supply of emergency materials and the disaster areas often have a spatial mismatch. Considering the attributes of externalities and public goods of emergency rescue, there are many obstacles for Local administration of emergency (LAE) and emergency logistics enterprises (ELE) spontaneously carrying out emergency supplies across regions. To solve this complexity problem, this research abstracts higher-level administration of emergency (HAE), LAE and ELE as the main stakeholders, with which a tripartite evolutionary game (ETG) model and a system dynamic (SD) model are constructed to analyze the dynamic mechanism of the complex system and to carry out the numerical simulation of the three-party game process. All the analyses and tests in this study have proved that the strong supervision of HAE has a decisive impact on the realization of cross-regional coordinated dispatch of emergency supplies, and the financial rewards and punishments imposed by HAE on other entities can accelerate or delay the achievement of the equilibrium strategy. However, when HAE chooses not to regulate, the cooperation willingness of LAE affects a lot that all the stakeholders will eventually reach equilibrium at (1,1,1) only if LAE chooses to actively carry out cross-regional coordinated dispatch of emergency supplies.},
  archive      = {J_CIS},
  author       = {Qiu, Ying and Shi, Meng and Zhao, Xinna and Jing, Yongping},
  doi          = {10.1007/s40747-021-00303-2},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2321-2332},
  shortjournal = {Complex Intell. Syst.},
  title        = {System dynamics mechanism of cross-regional collaborative dispatch of emergency supplies based on multi-agent game},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Product-harm crisis intelligent warning system design based
on fine-grained sentiment analysis of automobile complaints.
<em>CIS</em>, <em>9</em>(3), 2313–2320. (<a
href="https://doi.org/10.1007/s40747-021-00306-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the huge losses caused by product-harm crises and subsequent recalls in the automobile industry, companies must urgently design a product-harm crisis warning system. However, the designs of existing warning systems use the recurrent neural network algorithm, which suffers from gradient disappearance and gradient explosion issues. To compensate for these defects, this study uses a long and short-term memory algorithm to achieve a final prediction accuracy of 90%. This study contributes to the research and design of automatic crisis warning systems by considering sentiment and improving the accuracy of automobile product-harm crisis prediction.},
  archive      = {J_CIS},
  author       = {Hu, Haiju and Wei, Yonghui and Zhou, Yu},
  doi          = {10.1007/s40747-021-00306-z},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2313-2320},
  shortjournal = {Complex Intell. Syst.},
  title        = {Product-harm crisis intelligent warning system design based on fine-grained sentiment analysis of automobile complaints},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Regional logistics demand forecasting: A BP neural network
approach. <em>CIS</em>, <em>9</em>(3), 2297–2312. (<a
href="https://doi.org/10.1007/s40747-021-00297-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of e-commerce, the backlog of distribution orders, insufficient logistics capacity and other issues are becoming more and more serious. It is very significant for e-commerce platforms and logistics enterprises to clarify the demand of logistics. To meet this need, a forecasting indicator system of Guangdong logistics demand was constructed from the perspective of e-commerce. The GM (1, 1) model and Back Propagation (BP) neural network model were used to simulate and forecast the logistics demand of Guangdong province from 2000 to 2019. The results show that the Guangdong logistics demand forecasting indicator system has good applicability. Compared with the GM (1, 1) model, the BP neural network model has smaller prediction error and more stable prediction results. Based on the results of the study, it is the recommendation of the authors that e-commerce platforms and logistics enterprises should pay attention to the prediction of regional logistics demand, choose scientific forecasting methods, and encourage the implementation of new distribution modes.},
  archive      = {J_CIS},
  author       = {Huang, Lijuan and Xie, Guojie and Zhao, Wende and Gu, Yan and Huang, Yi},
  doi          = {10.1007/s40747-021-00297-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2297-2312},
  shortjournal = {Complex Intell. Syst.},
  title        = {Regional logistics demand forecasting: A BP neural network approach},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Forecasting emergency medicine reserve demand with a novel
decomposition-ensemble methodology. <em>CIS</em>, <em>9</em>(3),
2285–2295. (<a
href="https://doi.org/10.1007/s40747-021-00289-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction is a fundamental and leading work of the emergency medicine reserve management. Given that the emergency medicine reserve demand is affected by various factors during the public health events and thus the observed data are composed of different but hard-to-distinguish components, the traditional demand forecasting method is not competent for this case. To bridge this gap, this paper proposes the EMD-ELMAN-ARIMA (ELA) model which first utilizes Empirical Mode Decomposition (EMD) to decompose the original series into various components. The Elman neural network and ARIMA models are employed to forecast the identified components and the final forecast values are generated by integrating the individual component predictions. For the purpose of validation, an empirical study is carried out based on the influenza data of Beijing from 2014 to 2018. The results clearly show the superiority of the proposed ELA algorithm over its two rivals including the ARIMA and ELMAN models.},
  archive      = {J_CIS},
  author       = {Jiang-ning, Li and Xian-liang, Shi and An-qiang, Huang and Ze-fang, He and Yu-xuan, Kang and Dong, Li},
  doi          = {10.1007/s40747-021-00289-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2285-2295},
  shortjournal = {Complex Intell. Syst.},
  title        = {Forecasting emergency medicine reserve demand with a novel decomposition-ensemble methodology},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven optimization for last-mile delivery.
<em>CIS</em>, <em>9</em>(3), 2271–2284. (<a
href="https://doi.org/10.1007/s40747-021-00293-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers how an online food delivery platform can improve last-mile delivery services’ performance using multi-source data. The delivery time is one critical but uncertain factor for online platforms that also regarded as the main challenges in order assignment and routing service. To tackle this challenge, we propose a data-driven optimization approach that combines machine learning techniques with capacitated vehicle routing optimization. Machine learning methods can provide more accurate predictions and have received increasing attention in the operations research field. However, different from the traditional predict-then-optimize paradigm, we use a new smart predict-then-optimize framework, whose prediction objective is constructed by decision error instead of prediction error when implementing machine learning. Using this type of prediction, we can obtain a more accurate decision in the following optimization step. Efficient mini-batching gradient and heuristic algorithms are designed to solve the joint order assignment and routing problem of last-mile delivery service. Besides, this paper considers the mutual effect between routing decision and delivery time, and provides the corresponding solution algorithm. In addition, this paper conducts a computational study and finds that the proposed method’s performance has an approximate 5% improvement compared with other methods.},
  archive      = {J_CIS},
  author       = {Chu, Hongrui and Zhang, Wensi and Bai, Pengfei and Chen, Yahong},
  doi          = {10.1007/s40747-021-00293-1},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2271-2284},
  shortjournal = {Complex Intell. Syst.},
  title        = {Data-driven optimization for last-mile delivery},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluate the priority of product design factors in the
process of complex product innovation. <em>CIS</em>, <em>9</em>(3),
2257–2270. (<a
href="https://doi.org/10.1007/s40747-021-00298-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whether the design of product innovation can highly match the customer demand is the key to extend the product life cycle, and it is also the basis for enterprises to carry out continuous production and operation. The first step of product innovation is to identify the relationship between customer demands and design factors of product innovation. This paper focuses on the problems of market control, due to the wide range and deep level of knowledge from customer demands in the process of product innovation. To better meet the customer demands, combined with Entropy Theorem, Prospect Theory and Grey Correlation Method, this paper puts forward a method of importance of design factors of product innovation considering customer demands. First, the Entropy Theorem and Prospect Theory are introduced to calculate the importance of demand factors from the perspective of customers and experts. Second, the priority ranking of design factors of product innovation from the perspective of customer demand is calculated through Gray Correlation Method and Fuzzy TOPSIS. Finally, this method is availability and feasibility thought taking the continuous innovation of electric vehicle as an example.},
  archive      = {J_CIS},
  author       = {Yu, Yinyun and Li, Congdong},
  doi          = {10.1007/s40747-021-00298-w},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2257-2270},
  shortjournal = {Complex Intell. Syst.},
  title        = {Evaluate the priority of product design factors in the process of complex product innovation},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimization-driven distribution of relief materials in
emergency disasters. <em>CIS</em>, <em>9</em>(3), 2249–2256. (<a
href="https://doi.org/10.1007/s40747-021-00290-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distribution of relief materials is an important part of post-disaster emergency rescue. To meet the needs of the relief materials in the affected areas after a sudden disaster and ensure its smooth progress, an optimized dispatch model for multiple periods and multiple modes of transportation supported by the Internet of Things is established according to the characteristics of relief materials. Through the urgent production of relief materials, market procurement, and the use of inventory collection, the needs of the disaster area are met and the goal of minimizing system response time and total cost is achieved. The model is solved using CPLX software, and numerical simulation and results are analyzed using the example of the COVID-19 in Wuhan City, and the dispatching strategies are given under different disruption scenarios. The results show that the scheduling optimization method can meet the material demand of the disaster area with shorter time and lower cost compared with other methods, and can better cope with the supply interruptions that occur in post-disaster rescue.},
  archive      = {J_CIS},
  author       = {Yan, Yan and Di, Xinyue and Zhang, Yuanyuan},
  doi          = {10.1007/s40747-021-00290-4},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2249-2256},
  shortjournal = {Complex Intell. Syst.},
  title        = {Optimization-driven distribution of relief materials in emergency disasters},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving the location problem of front distribution center
for omni-channel retailing. <em>CIS</em>, <em>9</em>(3), 2237–2248. (<a
href="https://doi.org/10.1007/s40747-020-00260-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consumer demand and retailing models nowadays are being upgraded more frequently. More and more retailers are switching to the Omni-channel retailing model. Choosing a reasonable location for a front distribution center (FDC) helps control an enterprise&#39;s cost and improves its service level. This is especially true in the existence of fierce competition. In this paper, two important and contradictory objectives are proposed for the first time in the FDC location problem: minimizing the distribution costs from the facility and minimizing the fixed cost of the facility&#39;s location. For these objectives, a bi-objective programming model is established by considering the factors of a facility&#39;s capacity, demand and rent fluctuation. Meanwhile, the FDC location problem has been solved by compromising programming and elite set multi-objective simulated annealing algorithm respectively. Taking the FDC locations set of an e-commerce enterprise in a region of Beijing as an empirical sample, this paper uses the above algorithms to re-plan the FDC locations of the enterprise. This algorithm provides support for retail enterprises by helping find the best FDC location. Based on the empirical results, some comments and future research directions are also proposed.},
  archive      = {J_CIS},
  author       = {Huang, Jikai and Shi, Xianliang},
  doi          = {10.1007/s40747-020-00260-2},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2237-2248},
  shortjournal = {Complex Intell. Syst.},
  title        = {Solving the location problem of front distribution center for omni-channel retailing},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Applying catastrophe progression method to evaluate the
service quality of cold chain logistics. <em>CIS</em>, <em>9</em>(3),
2221–2235. (<a
href="https://doi.org/10.1007/s40747-020-00202-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logistics service quality (LSQ) is one of the key influential factors in the success of an ecommerce business. In view of the complexity of the topic, this paper proposes a novel model for fresh ecommerce cold chain LSQ evaluation based on the catastrophe progression method. In the proposed methodology, first an index system for evaluating the fresh ecommerce cold chain LSQ is established from the perspective of service recipients. Then, the comprehensive weight of each evaluation index is determined using a combination weighting approach based on maximizing deviations and fuzzy set theory. The priority weights and the ranking of the indices are determined using the catastrophe progression method. Finally, the model is applied in a case study of two representative enterprises. The study demonstrates the validity and practical applicability of the proposed model. Also, based on the evaluation results and findings, some improvement suggestions are made for improving the cold chain LSQ of similar kinds of fresh ecommerce companies.},
  archive      = {J_CIS},
  author       = {Zhang, Hao and Shi, Yuxin and Qiu, Bin},
  doi          = {10.1007/s40747-020-00202-y},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2221-2235},
  shortjournal = {Complex Intell. Syst.},
  title        = {Applying catastrophe progression method to evaluate the service quality of cold chain logistics},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid deep learning-based fruit classification using
attention model and convolution autoencoder. <em>CIS</em>,
<em>9</em>(3), 2209–2219. (<a
href="https://doi.org/10.1007/s40747-020-00192-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image recognition supports several applications, for instance, facial recognition, image classification, and achieving accurate fruit and vegetable classification is very important in fresh supply chain, factories, supermarkets, and other fields. In this paper, we develop a hybrid deep learning-based fruit image classification framework, named attention-based densely connected convolutional networks with convolution autoencoder (CAE-ADN), which uses a convolution autoencoder to pre-train the images and uses an attention-based DenseNet to extract the features of image. In the first part of the framework, an unsupervised method with a set of images is applied to pre-train the greedy layer-wised CAE. We use CAE structure to initialize a set of weights and bias of ADN. In the second part of the framework, the supervised ADN with the ground truth is implemented. The final part of the framework makes a prediction of the category of fruits. We use two fruit datasets to test the effectiveness of the model, experimental results show the effectiveness of the framework, and the framework can improve the efficiency of fruit sorting, which can reduce costs of fresh supply chain, factories, supermarkets, etc.},
  archive      = {J_CIS},
  author       = {Xue, Gang and Liu, Shifeng and Ma, Yicao},
  doi          = {10.1007/s40747-020-00192-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {6},
  number       = {3},
  pages        = {2209-2219},
  shortjournal = {Complex Intell. Syst.},
  title        = {A hybrid deep learning-based fruit classification using attention model and convolution autoencoder},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Context vector-based visual mapless navigation in indoor
using hierarchical semantic information and meta-learning. <em>CIS</em>,
<em>9</em>(2), 2031–2041. (<a
href="https://doi.org/10.1007/s40747-022-00902-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual mapless navigation (VMN), modeling a direct mapping between sensory inputs and agent actions, aims to navigate from a stochastic origin location to a prescribed goal in an unseen scene. A fundamental yet challenging issue in visual mapless navigation is generalizing to a new scene. Furthermore, it is of pivotal concern to design a method to make effective policy learning. To address these issues, we introduce a novel visual mapless navigation model, which integrates hierarchical semantic information represented by context vector with meta-learning to improve the generalization performance gap between known and unknown environments. Extensive experimental results on AI2-THOR benchmark dataset demonstrate that our model significantly outperforms the state-of-the-art model by $$15.79\%$$ for the SPL and by $$23.83\%$$ for the success rate. In addition, the exploration rate experiment shows that our model can effectively improve the invalid exploration behavior of the agent and accelerate the convergence speed of the model. Our implementation code and data can be viewed on https://github.com/zhiyu-tech/WHU-CVVMN .},
  archive      = {J_CIS},
  author       = {Li, Fei and Guo, Chi and Zhang, Huyin and Luo, Binhan},
  doi          = {10.1007/s40747-022-00902-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {2031-2041},
  shortjournal = {Complex Intell. Syst.},
  title        = {Context vector-based visual mapless navigation in indoor using hierarchical semantic information and meta-learning},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enriched entity representation of knowledge graph for text
generation. <em>CIS</em>, <em>9</em>(2), 2019–2030. (<a
href="https://doi.org/10.1007/s40747-022-00898-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text generation is a key tool in natural language applications. Generating texts which could express rich ideas through several sentences needs a structured representation of their content. Many works utilize graph-based methods for graph-to-text generation, like knowledge-graph-to-text generation. However, generating texts from knowledge graph still faces problems, such as repetitions and the entity information is not fully utilized in the generated text. In this paper, we focus on knowledge-graph-to-text generation, and develop a multi-level entity fusion representation (MEFR) model to address the above problems, aiming to generate high-quality text from knowledge graph. Our model introduces a fusion mechanism, which is capable of aggregating node representations from word level and phrase level to obtain rich entity representations of the knowledge graph. Then, Graph Transformer is adopted to encode the graph and outputs contextualized node representations. Besides, we develop a vanilla beam search-based comparison mechanism during decoding procedure, which further considers similarity to reduce repetitive information of the generated text. Experimental results show that the proposed MEFR model could effectively improve generation performance, and outperform other baselines on AGENDA and WebNLG datasets. The results also demonstrate the importance to further explore information contained in knowledge graph.},
  archive      = {J_CIS},
  author       = {Shi, Kaile and Cai, Xiaoyan and Yang, Libin and Zhao, Jintao},
  doi          = {10.1007/s40747-022-00898-0},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {2019-2030},
  shortjournal = {Complex Intell. Syst.},
  title        = {Enriched entity representation of knowledge graph for text generation},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-HFL: Semi-supervised federated learning for
heterogeneous devices. <em>CIS</em>, <em>9</em>(2), 1995–2017. (<a
href="https://doi.org/10.1007/s40747-022-00894-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the vanilla federated learning (FL) framework, the central server distributes a globally unified model to each client and uses labeled samples for training. However, in most cases, clients are equipped with different devices and are exposed to a variety of situations. There are great differences between clients in storage, computing, communication, and other resources, which makes unified deep models used in traditional FL cannot fit clients’ personalized resource conditions. Furthermore, a great deal of labeled data is needed in traditional FL, whereas data labeling requires a great investment of time and resources, which is hard to do for individual clients. As a result, clients only have a vast amount of unlabeled data, which goes against the federated learning needs. To address the aforementioned two issues, we propose Semi-HFL, a semi-supervised federated learning approach for heterogeneous devices, which divides a deep model into a series of small submodels by inserting early exit branches to meet the resource requirements of different devices. Furthermore, considering the availability of labeled data, Semi-HFL introduces semi-supervised techniques for training in the above heterogeneous learning process. Specifically, two training phases are included in the semi-supervised learning process, unsupervised learning on clients and supervised learning on the server, which makes full use of clients’ unlabeled data. Through image classification, text classification, next-word prediction, and multi-task FL experiments based on five kinds of datasets, it is verified that compared with the traditional homogeneous learning method, Semi-HFL not only achieves higher accuracies but also significantly reduces the global resource overhead.},
  archive      = {J_CIS},
  author       = {Zhong, Zhengyi and Wang, Ji and Bao, Weidong and Zhou, Jingxuan and Zhu, Xiaomin and Zhang, Xiongtao},
  doi          = {10.1007/s40747-022-00894-4},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1995-2017},
  shortjournal = {Complex Intell. Syst.},
  title        = {Semi-HFL: Semi-supervised federated learning for heterogeneous devices},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multilayer fisher extreme learning machine for
classification. <em>CIS</em>, <em>9</em>(2), 1975–1993. (<a
href="https://doi.org/10.1007/s40747-022-00867-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a special deep learning algorithm, the multilayer extreme learning machine (ML-ELM) has been extensively studied to solve practical problems in recent years. The ML-ELM is constructed from the extreme learning machine autoencoder (ELM-AE), and its generalization performance is affected by the representation learning of the ELM-AE. However, given label information, the unsupervised learning of the ELM-AE is difficult to build the discriminative feature space for classification tasks. To address this problem, a novel Fisher extreme learning machine autoencoder (FELM-AE) is proposed and is used as the component for the multilayer Fisher extreme leaning machine (ML-FELM). The FELM-AE introduces the Fisher criterion into the ELM-AE by adding the Fisher regularization term to the objective function, aiming to maximize the between-class distance and minimize the within-class distance of abstract feature. Different from the ELM-AE, the FELM-AE requires class labels to calculate the Fisher regularization loss, so that the learned abstract feature contains sufficient category information to complete classification tasks. The ML-FELM stacks the FELM-AE to extract feature and adopts the extreme leaning machine (ELM) to classify samples. Experiments on benchmark datasets show that the abstract feature extracted by the FELM-AE is more discriminative than the ELM-AE, and the classification results of the ML-FELM are more competitive and robust in comparison with the ELM, one-dimensional convolutional neural network (1D-CNN), ML-ELM, denoising multilayer extreme learning machine (D-ML-ELM), multilayer generalized extreme learning machine (ML-GELM), and hierarchical extreme learning machine with L21‑norm loss and regularization (H-LR21-ELM).},
  archive      = {J_CIS},
  author       = {Lai, Jie and Wang, Xiaodan and Xiang, Qian and Wang, Jian and Lei, Lei},
  doi          = {10.1007/s40747-022-00867-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1975-1993},
  shortjournal = {Complex Intell. Syst.},
  title        = {Multilayer fisher extreme learning machine for classification},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gaussian guided frame sequence encoder network for action
quality assessment. <em>CIS</em>, <em>9</em>(2), 1963–1974. (<a
href="https://doi.org/10.1007/s40747-022-00892-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Can a computer evaluate an athlete’s performance automatically? Many action quality assessment (AQA) methods have been proposed in recent years. Limited by the randomness of video sampling and the simple strategy of model training, the performance of the existing AQA methods can still be further improved. To achieve this goal, a Gaussian guided frame sequence encoder network is proposed in this paper. In the proposed method, the image feature of each video frame is extracted by Resnet model. And then, a frame sequence encoder network is applied to model temporal information and generate action quality feature. Finally, a fully connected network is designed to predict action quality score. To train the proposed method effectively, inspired by the final score calculation rule in Olympic game, Gaussian loss function is employed to compute the error between the predicted score and the label score. The proposed method is implemented on the AQA-7 and MTL–AQA datasets. The experimental results confirm that compared with the state-of-the-art methods, our proposed method achieves the better performance. And detailed ablation experiments are conducted to verify the effectiveness of each component in the module.},
  archive      = {J_CIS},
  author       = {Li, Ming-Zhe and Zhang, Hong-Bo and Dong, Li-Jia and Lei, Qing and Du, Ji-Xiang},
  doi          = {10.1007/s40747-022-00892-6},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1963-1974},
  shortjournal = {Complex Intell. Syst.},
  title        = {Gaussian guided frame sequence encoder network for action quality assessment},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid swarm intelligent algorithm for multi-UAV formation
reconfiguration. <em>CIS</em>, <em>9</em>(2), 1929–1962. (<a
href="https://doi.org/10.1007/s40747-022-00891-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Formation flight of unmanned aerial vehicles (UAVs) utilizes reconfiguration procedures to handle a variety of emergencies, such as collision avoidance, malfunctions, fuel savings, and member replacement. As UAVs have limited computing power and energy resources, it is necessary to optimize the control inputs to reduce the distance travelled by UAVs while reducing the computing costs during formation reconfiguration. In this paper, the problem of multi-UAV reconfiguration is decoupled into two stages: task assignment and control input optimization of UAVs. For a solution to the above problem, we propose an adaptive hybrid particle swarm optimization and differential evolution algorithm (AHPSODE) to optimize minimize the distance of the total movement and reduce the computing cost of formation reconfiguration. Based on the idea of receding horizon control (RHC) and the nonlinear model of multi-UAV formation reconfiguration, an RHC controller using AHPSODE is designed to optimize the control input of the UAV group to obtain the shortest movement distance, and this method can reduce the computation time. We use the CEC 2017 test suit to test the performance of our proposed AHPSODE algorithm, and simulate the AHPSODE-based RHC controller to manage formation reconfiguration. The results show that our proposed AHPSODE performed well in convergence and accuracy and the RHC controller is effective.},
  archive      = {J_CIS},
  author       = {Gao, Chenyang and Ma, Jianfeng and Li, Teng and Shen, Yulong},
  doi          = {10.1007/s40747-022-00891-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1929-1962},
  shortjournal = {Complex Intell. Syst.},
  title        = {Hybrid swarm intelligent algorithm for multi-UAV formation reconfiguration},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A robust performance evaluation approach for solution
preservation in multiobjective optimization. <em>CIS</em>,
<em>9</em>(2), 1913–1927. (<a
href="https://doi.org/10.1007/s40747-022-00889-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world optimization problems have complex features, such as bias, multimodel, etc. Existing evolutionary algorithms mainly utilize solutions’ current performance to decide their survivals, which are not comprehensive enough to describe the evolving trend, and may misguide the evolve decision. In this paper, a novel robust performance evaluation approach for evolutionary multiobjective optimization algorithm is proposed. Here, the robustness refers to the performance fluctuation degree among several generations, which can be expressed by interval values in respect to the decision and objective spaces. Based on the robust performance evaluation, solutions can be selected and preserved considering their historical performance, and thus, the exploration strength in convergence potential areas can be maintained. Meanwhile, to construct an evolutionary algorithm that embeds robustness evaluation, a robust elite managerial method and a learning-based updating strategy are also designed. Experiments on multiobjective benchmark problems and a real-world optimization in a robotic manipulation system have proved the superiority of the proposed approach.},
  archive      = {J_CIS},
  author       = {Pan, Anqi and Wang, Chuang and Shen, Bo and Wang, Lei},
  doi          = {10.1007/s40747-022-00889-1},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1913-1927},
  shortjournal = {Complex Intell. Syst.},
  title        = {A robust performance evaluation approach for solution preservation in multiobjective optimization},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic multi-objective sequence-wise recommendation
framework via deep reinforcement learning. <em>CIS</em>, <em>9</em>(2),
1891–1911. (<a
href="https://doi.org/10.1007/s40747-022-00871-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequence-wise recommendation, where recommend exercises to each student step by step, is one of the most exciting tasks in the field of intelligent tutoring systems (ITS). It is important to develop a personalized sequence-wise recommendation framework that immerses students in learning and helps them acquire as much necessary knowledge as possible, rather than merely focusing on providing non-mastered exercises, which is referred to optimize a single objective. However, due to the different knowledge levels of students and the large scale of exercise banks, it is difficult to generate a personalized exercise recommendation for each student. To fully exploit the multifaceted beneficial information collected from e-learning platforms, we design a dynamic multi-objective sequence-wise recommendation framework via deep reinforcement learning, i.e., DMoSwR-DRL, which automatically select the most suitable exercises for each student based on the well-designed domain-objective rewards. Within this framework, the interaction between students and exercises can be explicitly modeled by integrating the actor–critic network and the state representation component, which can greatly help the agent perform effective reinforcement learning. Specifically, we carefully design a state representation module with dynamic recurrent mechanism, which integrates concept information and exercise difficulty level, thus generating a continuous state representation of the student. Subsequently, a flexible reward function is designed to simultaneously optimize the four domain-specific objectives of difficulty, novelty, coverage, and diversity, providing the students with a trade-off sequence-wise recommendation. To set up the online evaluation, we test DMoSwR-DRL on a simulated environment which can model qualitative development of knowledge level and predicts their performance for a given exercise. Comprehensive experiments are conducted on four classical exercise-answer datasets, and the results show the effectiveness and advantages of DMoSwR-DRL in terms of recommendation quality.},
  archive      = {J_CIS},
  author       = {Zhang, Xiankun and Shang, Yuhu and Ren, Yimeng and Liang, Kun},
  doi          = {10.1007/s40747-022-00871-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1891-1911},
  shortjournal = {Complex Intell. Syst.},
  title        = {Dynamic multi-objective sequence-wise recommendation framework via deep reinforcement learning},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integrated scheduling of distributed production and
distribution in group manufacturing with uncertain travel time.
<em>CIS</em>, <em>9</em>(2), 1871–1889. (<a
href="https://doi.org/10.1007/s40747-022-00875-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel integrated distributed production and distribution scheduling problem in group manufacturing with uncertain travel time (IDPDSP-GM-UTT), in which products are firstly produced in several distributed hybrid flow shops and then delivered to several retailers in batches. The proposed model considers both geographical dispersion of multi-factories and variable travel time between factories and retailers caused by time-varying dynamics of road network, which describes the production environment more authentic. Additionally, a mathematical model is developed to find the optimal quantity of raw material, delivery plan, and punishment of earliness and tardiness with the objective of minimizing total costs. Then, an improved genetic algorithm with two-stage heuristic mutation scheduling strategy and tabu search for local optimization (GA-2HMS&amp;TS) is designed to solve the proposed model. To verify the performances of the proposed method, several experiments by adopting test experimental examples with different scales are performed. The computational results exhibit that the GA-2HMS&amp;TS not only significantly reduces the total cost of production and distribution, but also outperforms all of its rivals. In addition, the robustness of the proposed models is also analyzed with regard to the different road conditions.},
  archive      = {J_CIS},
  author       = {Guo, Jun and Liu, Wenjun and Peng, Zhao and Du, Baigang},
  doi          = {10.1007/s40747-022-00875-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1871-1889},
  shortjournal = {Complex Intell. Syst.},
  title        = {Integrated scheduling of distributed production and distribution in group manufacturing with uncertain travel time},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). T-spherical uncertain linguistic MARCOS method based on
generalized distance and heronian mean for multi-attribute group
decision-making with unknown weight information. <em>CIS</em>,
<em>9</em>(2), 1837–1869. (<a
href="https://doi.org/10.1007/s40747-022-00862-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The T-spherical uncertain linguistic (TSUL) sets (TSULSs) integrated by T-spherical fuzzy sets and uncertain linguistic variables are introduced in this article. This new concept is not only a generalized form but also can integrate decision-makers’ quantitative evaluation ideas and qualitative evaluation information. The TSULSs serve as a reliable and comprehensive tool for describing complex and uncertain decision information. This paper focuses on an extended MARCOS (Measurement of Alternatives and Ranking according to the Compromise Solution) method to handle the TSUL multi-attribute group decision-making problems where the weight information is completely unknown. First, we define, respectively, the operation rules and generalized distance measure of T-spherical uncertain linguistic numbers (TSULNs). Then, we develop two kinds of aggregation operators of TSULNs, one kind of operator with independent attributes is T-spherical uncertain linguistic weighted averaging and geometric (TSULWA and TSULWG) operators, and the other is T-spherical uncertain linguistic Heronian mean aggregation operators (TSULHM and TSULWHM) considering attributes interrelationship. Their related properties are discussed and a series of reduced forms are presented. Subsequently, a new TSUL-MARCOS-based multi-attribute group decision-making model combining the proposed aggregation operators and generalized distance is constructed. Finally, a real case of investment decision for a community group-buying platform is presented for illustration. We further test the rationality and superiorities of the proposed method through sensitivity analysis and comparative study.},
  archive      = {J_CIS},
  author       = {Wang, Haolun and Ullah, Kifayat},
  doi          = {10.1007/s40747-022-00862-y},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1837-1869},
  shortjournal = {Complex Intell. Syst.},
  title        = {T-spherical uncertain linguistic MARCOS method based on generalized distance and heronian mean for multi-attribute group decision-making with unknown weight information},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distribution matching and structure preservation for domain
adaptation. <em>CIS</em>, <em>9</em>(2), 1823–1835. (<a
href="https://doi.org/10.1007/s40747-022-00887-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain classification refers to completing the corresponding classification task in a target domain which lacks label information, by exploring useful knowledge in a related source domain but with different data distribution. Domain adaptation can deal with such cross-domain classification, by reducing divergence of domains and transferring the relevant knowledge from the source to the target. To mine the discriminant information of the source domain samples and the geometric structure information of domains, and thus improve domain adaptation performance, this paper proposes a novel method involving distribution matching and structure preservation for domain adaptation (DMSP). First, it aligns the subspaces of the source domain and target domain on the Grassmann manifold; and learns the non-distorted embedded feature representations of the two domains. Second, in this embedded feature space, the empirical structure risk minimization method with distribution adaptation regularization and intra-domain graph regularization is used to learn an adaptive classifier, further adapting the source and target domains. Finally, we perform extensive experiments on widely used cross-domain classification datasets to validate the superiority of DMSP. The average classification accuracy of DMSP on these datasets is the highest compared with several state-of-the-art domain adaptation methods.},
  archive      = {J_CIS},
  author       = {Li, Ping and Ni, Zhiwei and Zhu, Xuhui and Song, Juan},
  doi          = {10.1007/s40747-022-00887-3},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1823-1835},
  shortjournal = {Complex Intell. Syst.},
  title        = {Distribution matching and structure preservation for domain adaptation},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A collaborative neurodynamic optimization algorithm to
traveling salesman problem. <em>CIS</em>, <em>9</em>(2), 1809–1821. (<a
href="https://doi.org/10.1007/s40747-022-00884-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposed a collaborative neurodynamic optimization (CNO) method to solve traveling salesman problem (TSP). First, we construct a Hopfield neural network (HNN) with $$n \times n$$ neurons for the n cities. Second, to ensure the convergence of continuous HNN (CHNN), we reformulate TSP to satisfy the convergence condition of CHNN and solve TSP by CHNN. Finally, a population of CHNNs is used to search for local optimal solutions of TSP and the globally optimal solution is obtained using particle swarm optimization. Experimental results show the effectiveness of the CNO approach for solving TSP.},
  archive      = {J_CIS},
  author       = {Zhong, Jing and Feng, Yuelei and Tang, Shuyu and Xiong, Jiang and Dai, Xiangguang and Zhang, Nian},
  doi          = {10.1007/s40747-022-00884-6},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1809-1821},
  shortjournal = {Complex Intell. Syst.},
  title        = {A collaborative neurodynamic optimization algorithm to traveling salesman problem},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid spectral clustering simulated annealing algorithm
for the street patrol districting problem. <em>CIS</em>, <em>9</em>(2),
1791–1807. (<a
href="https://doi.org/10.1007/s40747-022-00880-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reasonable districting plays an important role in the patrolling process. In this paper, workload attributes are considered, and a mixed integer programming model is developed to solve the street patrol districting problem (SPDP). The improved spectral clustering algorithm named spectral clustering algorithm based on the road network (SCRn) and simulated annealing algorithm (SA) are combined. This results in a hybrid algorithm called SCRn-SA. The SCRn-SA algorithm is tested on small examples and real instances in Zhengzhou, China. The experimental results show that the proposed algorithm is effective for solving SPDP. It has better performance when compared to other advanced algorithms.},
  archive      = {J_CIS},
  author       = {Jiang, Yirui and Zhao, Shan and Li, Hongwei and Qin, Yulu and Yang, Xiaoyue},
  doi          = {10.1007/s40747-022-00880-w},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1791-1807},
  shortjournal = {Complex Intell. Syst.},
  title        = {A hybrid spectral clustering simulated annealing algorithm for the street patrol districting problem},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature selection based on self-information and entropy
measures for incomplete neighborhood decision systems. <em>CIS</em>,
<em>9</em>(2), 1773–1790. (<a
href="https://doi.org/10.1007/s40747-022-00882-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For incomplete datasets with mixed numerical and symbolic features, feature selection based on neighborhood multi-granulation rough sets (NMRS) is developing rapidly. However, its evaluation function only considers the information contained in the lower approximation of the neighborhood decision, which easily leads to the loss of some information. To solve this problem, we construct a novel NMRS-based uncertain measure for feature selection, named neighborhood multi-granulation self-information-based pessimistic neighborhood multi-granulation tolerance joint entropy (PTSIJE), which can be used to incomplete neighborhood decision systems. First, from the algebra view, four kinds of neighborhood multi-granulation self-information measures of decision variables are proposed by using the upper and lower approximations of NMRS. We discuss the related properties, and find the fourth measure-lenient neighborhood multi-granulation self-information measure (NMSI) has better classification performance. Then, inspired by the algebra and information views simultaneously, a feature selection method based on PTSIJE is proposed. Finally, the Fisher score method is used to delete uncorrelated features to reduce the computational complexity for high-dimensional gene datasets, and a heuristic feature selection algorithm is raised to improve classification performance for mixed and incomplete datasets. Experimental results on 11 datasets show that our method selects fewer features and has higher classification accuracy than related methods.},
  archive      = {J_CIS},
  author       = {Yuan, Meng and Xu, Jiucheng and Li, Tao and Sun, Yuanhao},
  doi          = {10.1007/s40747-022-00882-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1773-1790},
  shortjournal = {Complex Intell. Syst.},
  title        = {Feature selection based on self-information and entropy measures for incomplete neighborhood decision systems},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A consensus algorithm based on the worst consistency index
of hesitant fuzzy preference relations in group decision-making.
<em>CIS</em>, <em>9</em>(2), 1753–1771. (<a
href="https://doi.org/10.1007/s40747-022-00863-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper mainly solves the individual consistency and group consensus in the decision-making with hesitant fuzzy preference relations (HFPRs). The worst consistency index (WCI) is used to measure the individual consistency level. The envelop of an HFPR called envelop of HFPR (EHFRP) is proposed in the consensus reaching process (CRP). Two algorithms are proposed: one is to improve the WCI, in which only one pair of elements are revised in the consistency improving process each time, which aims to preserve the decision makers’ (DMs’) original information as much as possible. Another algorithm is proposed to improve the consensus in the CRP. To aggregate individual EHFPRs into one group HFPR, a new induced ordered weighted averaging (IOWA) operator is presented, called envelope HFPR-IOWA (EHFPR-IOWA), which allows the experts&#39; preference to be aggregated in such a way that the most consistent ones are given more weight. Finally, an illustrative example and comparisons with the existing methods are provided to show the effectiveness of the proposed method.},
  archive      = {J_CIS},
  author       = {Li, Qiujie and Liu, Gaofeng and Zhang, Tianming and Xu, Yejun},
  doi          = {10.1007/s40747-022-00863-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1753-1771},
  shortjournal = {Complex Intell. Syst.},
  title        = {A consensus algorithm based on the worst consistency index of hesitant fuzzy preference relations in group decision-making},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learned vectors’ formation using auto-correlation,
scaling, and derivations with CNN for complex and huge image retrieval.
<em>CIS</em>, <em>9</em>(2), 1729–1751. (<a
href="https://doi.org/10.1007/s40747-022-00866-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning for image retrieval has been used in this era, but image retrieval with the highest accuracy is the biggest challenge, which still lacks auto-correlation for feature extraction and description. In this paper, a novel deep learning technique for achieving highly accurate results for image retrieval is proposed, which implements a convolutional neural network with auto-correlation, gradient computation, scaling, filter, and localization coupled with state-of-the-art content-based image retrieval methods. For this purpose, novel image features are fused with signatures produced by the VGG-16. In the initial step, images from rectangular neighboring key points are auto-correlated. The image smoothing is achieved by computing intensities according to the local gradient. The result of Gaussian approximation with the lowest scale and suppression is adjusted by the by-box filter with the standard deviation adjusted to the lowest scale. The parameterized images are smoothed at different scales at various levels to achieve high accuracy. The principal component analysis has been used to reduce feature vectors and combine them with the VGG features. These features are integrated with the spatial color coordinates to represent color channels. This experimentation has been performed on Cifar-100, Cifar-10, Tropical fruits, 17 Flowers, Oxford, and Corel-1000 datasets. This study has achieved an extraordinary result for the Cifar-10 and Cifar-100 datasets. Similarly, the results of the study have shown efficient results for texture datasets of 17 Flowers and Tropical fruits. Moreover, when compared to state-of-the-art approaches, this research produced outstanding results for the Corel-1000 dataset.},
  archive      = {J_CIS},
  author       = {Naeem, Ahmad and Anees, Tayyaba and Ahmed, Khawaja Tehseen and Naqvi, Rizwan Ali and Ahmad, Shabir and Whangbo, Taegkeun},
  doi          = {10.1007/s40747-022-00866-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1729-1751},
  shortjournal = {Complex Intell. Syst.},
  title        = {Deep learned vectors’ formation using auto-correlation, scaling, and derivations with CNN for complex and huge image retrieval},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-objective evolutionary design of central pattern
generator network for biomimetic robotic fish. <em>CIS</em>,
<em>9</em>(2), 1707–1727. (<a
href="https://doi.org/10.1007/s40747-022-00883-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fish-inspired motion is an important research area with many applications in real-world tasks such as underwater vehicles or robotic fish control design. Owing to robust, smooth, and coordinated oscillatory signals generated by Central Pattern Generators (CPGs) for locomotion control of robots with multiple degrees of freedom, CPGs are the most versatile solution for robotic control systems, especially in robotic fish. However, tuning central pattern generator parameters is difficult for complex mechanical system designs. Besides, most current CPG-based methods only consider one aspect (e.g., speed), which widens the gap between theory and practice in robotic fish design. Also, it may affect the practical applicability of the designed motion model to a certain extent. This paper addresses this problem by constructing a multi-objective evolutionary design of a central pattern generator network to control the proposed biomimetic robotic fish. A new CPG model is proposed to help biomimetic robotic fish swim efficiently. In addition, an efficient multi-objective evolutionary algorithm proposed in our previous work is also applied to assist the biomimetic robotic fish in obtaining faster-swimming speed, good stability of the head, and higher propulsive efficiency simultaneously. Considering that the result of multi-objective optimization is a set of non-dominated solutions rather than a solution, a screening method based on fuzzy theory is adopted to assist decision-makers in selecting the most appropriate solution. Based on this, the control model of biomimetic robotic fish is constructed. The proposed control model is simulated and compared with seven well-known algorithms and a series of robotic fish designs. After that, the proposed control model is validated with extensive experiments on the actual biomimetic robotic fish. Simulations and experiments demonstrate the proposed control model’s effectiveness and good performance, especially when the control model has been applied to the real biomimetic robotic fish.},
  archive      = {J_CIS},
  author       = {Li, Wei Kun and Chen, Hao and Cui, Wei Cheng and Song, Chang Hui and Chen, Lin Ke},
  doi          = {10.1007/s40747-022-00883-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1707-1727},
  shortjournal = {Complex Intell. Syst.},
  title        = {Multi-objective evolutionary design of central pattern generator network for biomimetic robotic fish},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). (2,1)-fuzzy sets: Properties, weighted aggregated operators
and their applications to multi-criteria decision-making methods.
<em>CIS</em>, <em>9</em>(2), 1687–1705. (<a
href="https://doi.org/10.1007/s40747-022-00878-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Orthopair fuzzy sets are fuzzy sets in which every element is represented by a pair of values in the unit interval, one of which refers to membership and the other refers to non-membership. The different types of orthopair fuzzy sets given in the literature are distinguished according to the proposed constrain for membership and non-membership grades. The aim of writing this manuscript is to familiarize a new class of orthopair fuzzy sets called “(2,1)-Fuzzy sets” which are good enough to control some real-life situations. We compare (2,1)-Fuzzy sets with IFSs and some of their celebrated extensions. Then, we put forward the fundamental set of operations for (2,1)-Fuzzy sets and investigate main properties. Also, we define score and accuracy functions which we apply to rank (2,1)-Fuzzy sets. Moreover, we reformulate aggregation operators to be used with (2,1)-Fuzzy sets. Finally, we develop the successful technique “aggregation operators” to handle multi-criteria decision-making (MCDM) problems in the environment of (2,1)-Fuzzy sets. To show the effectiveness and usability of the proposed technique in MCDM problems, an illustrative example is provided.},
  archive      = {J_CIS},
  author       = {Al-shami, Tareq M.},
  doi          = {10.1007/s40747-022-00878-4},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1687-1705},
  shortjournal = {Complex Intell. Syst.},
  title        = {(2,1)-fuzzy sets: Properties, weighted aggregated operators and their applications to multi-criteria decision-making methods},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A global relative similarity for inferring interactions of
multi-agent systems. <em>CIS</em>, <em>9</em>(2), 1671–1686. (<a
href="https://doi.org/10.1007/s40747-022-00877-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactions and dynamics are critical mechanisms for multi-agent systems to achieve complex intelligence through the cooperation of simple agents. Yet, inferring interactions of the multi-agent system is still a common and open problem. A new method named K-similarity is designed to measure the global relative similarities for inferring the interactions among multiple agents in this paper. K-similarity is defined to be a synthetic measure of relative similarity on each observation snapshot where regular distances are nonlinearly mapped into a network. Therefore, K-similarity contains the global relative similarity information, and the interaction topology can be inferred from the similarity matrix. It has the potential to transform into distance strictly and detect multi-scale information with various K strategies. Therefore, K-similarity can be flexibly applied to various synchronized dynamical systems with fixed, switching, and time-varying topologies. In the experiments, K-similarity outperforms four benchmark methods in accuracy in most scenarios on both simulated and real datasets, and shows strong stability towards outliers. Furthermore, according to the property of K-similarity we develop a Gaussian Mixture Model (GMM)-based threshold to select probable interactions. Our method contributes to not only similarity measurement in multi-agent systems, but also other global similarity measurement problems.},
  archive      = {J_CIS},
  author       = {Gu, Kongjing and Duan, Xiaojun and Qi, Mingze and Yan, Liang},
  doi          = {10.1007/s40747-022-00877-5},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1671-1686},
  shortjournal = {Complex Intell. Syst.},
  title        = {A global relative similarity for inferring interactions of multi-agent systems},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Secure medical image sharing for smart healthcare system
based on cellular neural network. <em>CIS</em>, <em>9</em>(2),
1653–1670. (<a
href="https://doi.org/10.1007/s40747-022-00881-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The smart healthcare system (SHCS) facilitates the healthcare process with the widespread use of medical data through the internet of medical things (IoMT). Widespread use of medical data, especially medical images can also lead to privacy issues. Traditional encryption algorithms can address some problems; however, they cannot deter the redistribution of decrypted content. To prevent the decrypted content from being used illegally, the paper proposes a combination scheme of encryption and fingerprinting based on the game of life (GOL) and singular value decomposition (SVD) with the purpose of protecting medical images. First, medical images are performed with discrete wavelet transform (DWT). Second, the highest coefficients bit planes of the approximation component are selected to confuse with GOL. Third, the other bit planes and other detail components are chosen to embed fingerprints. Finally, all subbands are diffused with SVD computing. The proposed privacy protection scheme, as far as we know, is the first privacy protection scheme for the SHCS using GOL and SVD based on a chaotic cellular neural network (CNN). The proposed scheme can provide double-level privacy protection for the SHCS. The experimental results and discussion verify it is effective for the privacy protection of the SHCS.},
  archive      = {J_CIS},
  author       = {Ye, Conghuan and Chen, Cong},
  doi          = {10.1007/s40747-022-00881-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1653-1670},
  shortjournal = {Complex Intell. Syst.},
  title        = {Secure medical image sharing for smart healthcare system based on cellular neural network},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated bridge crack detection method based on lightweight
vision models. <em>CIS</em>, <em>9</em>(2), 1639–1652. (<a
href="https://doi.org/10.1007/s40747-022-00876-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based bridge crack detection methods have advantages over traditional methods. We proposed an automated bridge crack detection method using lightweight vision models. First, our study applied the You Only Look Once 4th version (YOLO v4) (Bochkovskiy et al. in Yolov4: Optimal speed and accuracy of object detection. arXiv:200410934, 2020) to bridge surface crack detection. Then, to achieve model acceleration, some lightweight networks were used to replace the feature extraction network in YOLO v4, which reduced the parameter numbers and the backbone layers. The lightweight design can reduce the computational overhead of the model, making it convenient to deploy on edge platforms with limited computational power. The experimental results showed that the lightweight network-based bridge crack detection model required significantly less storage space at the expense of a slight reduction in precision. Therefore, an improved YOLO v4 crack detection method was proposed to meet real-time running without sacrificing accuracy. The precision, recall, and F1 score of the proposed crack detection method are 93.96%, 90.12%, and 92%, respectively. And the model only required 23.4 MB of storage space, and its frames per second could reach 140.2 frames. Compared with existing bridge crack detection methods, the proposed method showed precision, speed, and model size advantages.},
  archive      = {J_CIS},
  author       = {Zhang, Jian and Qian, Songrong and Tan, Can},
  doi          = {10.1007/s40747-022-00876-6},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1639-1652},
  shortjournal = {Complex Intell. Syst.},
  title        = {Automated bridge crack detection method based on lightweight vision models},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evolutionary game analysis of three parties in logistics
platforms and freight transportation companies’ behavioral strategies
for horizontal collaboration considering vehicle capacity utilization.
<em>CIS</em>, <em>9</em>(2), 1617–1637. (<a
href="https://doi.org/10.1007/s40747-022-00873-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In China, logistics platforms are an effective way to solve vehicle capacity utilization using information sharing. However, most logistics platforms do not possess operational sustainability due to excessive profit-seeking. To address this problem, conflicts of interest among freight transportation participants are discussed using a stakeholder approach. A three-player evolutionary game model (TEGM) is developed to analyze the interactions among freight carriers, freight shippers, and logistics platforms. Then, the asymptotic equilibrium and evolutionary stability strategies of the three-player game are analyzed. The results indicate that a high-level positive network externality is the driving force behind the logistics platform’s “high-level service”. A fairness payment incentive guarantees a “sharing” strategy for freight carriers and shippers. When the high-level positive network externality is limited and lower than a threshold value, there is no stable equilibrium point in the TEGM. A government tax incentive cannot change the freight carriers’ and shippers’ strategy to participate in this horizontal collaboration system, except for the logistics platform’s probability of providing “high-level service”. However, the behavioral strategies of the freight transportation participants can be changed to achieve the sustainability of freight transportation by reducing the value-added tax rate through the logistics platform and increasing the high-level positive network externality of the logistics platform and other participants’ perceived fairness through a payment incentive. Finally, suggestions for regulating the behaviors of freight transportation participants and promoting the sustainability of freight transportation are discussed.},
  archive      = {J_CIS},
  author       = {Deng, Shuai and Zhou, Duohong and Wu, Guohua and Wang, Ling and You, Ge},
  doi          = {10.1007/s40747-022-00873-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1617-1637},
  shortjournal = {Complex Intell. Syst.},
  title        = {Evolutionary game analysis of three parties in logistics platforms and freight transportation companies’ behavioral strategies for horizontal collaboration considering vehicle capacity utilization},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive nonsingular fixed-time sliding mode control for
manipulator systems’ trajectory tracking. <em>CIS</em>, <em>9</em>(2),
1605–1616. (<a
href="https://doi.org/10.1007/s40747-022-00864-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an adaptive fixed-time controller is raised for the manipulator system with uncertain disturbances to boost the rate and precision of its trajectory tracking and solve the convergence time dependence on the system&#39;s initial conditions. First, a nonsingular fixed-time sliding mode (SM) surface and a reaching law based on an arctangent function are constructed to enhance the control scheme performance. Second, the upper bound is difficult to obtain because of the uncertainty of the disturbance. The disturbance upper bound is estimated by adaptive techniques, which do not require a priori knowledge about the upper bound and effectively inhibit the effect of disturbance on the system. Finally, the fixed-time convergence of the states is analyzed by rigorous theoretical proof, and the validity of the presented control scheme is demonstrated by simulation.},
  archive      = {J_CIS},
  author       = {Zhang, Xin and Shi, Ran and Zhu, Zijun and Quan, Ying},
  doi          = {10.1007/s40747-022-00864-w},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1605-1616},
  shortjournal = {Complex Intell. Syst.},
  title        = {Adaptive nonsingular fixed-time sliding mode control for manipulator systems’ trajectory tracking},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A study of sparse representation-based classification for
biometric verification based on both handcrafted and deep learning
features. <em>CIS</em>, <em>9</em>(2), 1583–1603. (<a
href="https://doi.org/10.1007/s40747-022-00868-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biometric verification is generally considered a one-to-one matching task. In contrast, in this paper, we argue that the one-to-many competitive matching via sparse representation-based classification (SRC) can bring enhanced verification security and accuracy. SRC-based verification introduces non-target subjects to construct dynamic dictionary together with the client claimed and encodes the submitted feature. Owing to the sparsity constraint, a client can only be accepted when it defeats almost all non-target classes and wins a convincing sparsity-based matching score. This will make the verification more secure than those using one-to-one matching. However, intense competition may also lead to extremely inferior genuine scores when data degeneration occurs. Motivated by the latent benefits and concerns, we study SRC-based verification using two sparsity-based matching measures, three biometric modalities (i.e., face, palmprint, and ear) and their multimodal combinations based on both handcrafted and deep learning features. We finally approach a comprehensive study of SRC-based verification, including its methodology, characteristics, merits, challenges and the directions to resolve. Extensive experimental results demonstrate the superiority of SRC-based verification, especially when using multimodal fusion and advanced deep learning features. The concerns about its efficiency in large-scale user applications can be readily solved using a simple dictionary shrinkage strategy based on cluster analysis and random selection of non-target subjects.},
  archive      = {J_CIS},
  author       = {Huang, Zengxi and Wang, Jie and Wang, Xiaoming and Song, Xiaoning and Chen, Mingjin},
  doi          = {10.1007/s40747-022-00868-6},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1583-1603},
  shortjournal = {Complex Intell. Syst.},
  title        = {A study of sparse representation-based classification for biometric verification based on both handcrafted and deep learning features},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybridizing slime mould algorithm with simulated annealing
algorithm: A hybridized statistical approach for numerical and
engineering design problems. <em>CIS</em>, <em>9</em>(2), 1525–1582. (<a
href="https://doi.org/10.1007/s40747-022-00852-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing slime mould algorithm clones the uniqueness of the phase of oscillation of slime mould conduct and exhibits slow convergence in local search space due to poor exploitation phase. This research work exhibits to discover the best solution for objective function by commingling slime mould algorithm and simulated annealing algorithm for better variation of parameters and named as hybridized slime mould algorithm–simulated annealing algorithm. The simulated annealing algorithm improves and accelerates the effectiveness of slime mould technique as well as assists to take off from the local optimum. To corroborate the worth and usefulness of the introduced strategy, nonconvex, nonlinear, and typical engineering design difficulties were analyzed for standard benchmarks and interdisciplinary engineering design concerns. The proposed technique version is used to evaluate six, five, five unimodal, multimodal and fixed-dimension benchmark functions, respectively, also including 11 kinds of interdisciplinary engineering design difficulties. The technique’s outcomes were compared to the results of other on-hand optimization methods, and the experimental results show that the suggested approach outperforms the other optimization techniques.},
  archive      = {J_CIS},
  author       = {Ch, Leela Kumari and Kamboj, Vikram Kumar and Bath, S. K.},
  doi          = {10.1007/s40747-022-00852-0},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1525-1582},
  shortjournal = {Complex Intell. Syst.},
  title        = {Hybridizing slime mould algorithm with simulated annealing algorithm: A hybridized statistical approach for numerical and engineering design problems},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Primary node election based on probabilistic linguistic term
set with confidence interval in the PBFT consensus mechanism for
blockchain. <em>CIS</em>, <em>9</em>(2), 1507–1524. (<a
href="https://doi.org/10.1007/s40747-022-00857-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a primary node election method based on probabilistic linguistic term set (PLTS) for the practical Byzantine fault tolerance (PBFT) consensus mechanism to effectively enhance the efficiency of reaching consensus. Specifically, a novel concept of the probabilistic linguistic term set with a confidence interval (PLTS-CI) is presented to express the uncertain complex voting information of nodes during primary node election. Then, a novel score function based on the exponential semantic value and confidence approximation value for the PLTS-CI, called Score-ESCA, is used to solve the problems of comparing different nodes with various voting attitudes. This method helps select the node with the highest score by utilizing complex decision attitudes, making it an accurate primary node election solution. Furthermore, the feasibility of our proposed method is proved by both theoretical analysis and experimental evaluations.},
  archive      = {J_CIS},
  author       = {Xie, Mingyue and Liu, Jun and Chen, Shuyu and Xu, Guangxia and Lin, Mingwei},
  doi          = {10.1007/s40747-022-00857-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1507-1524},
  shortjournal = {Complex Intell. Syst.},
  title        = {Primary node election based on probabilistic linguistic term set with confidence interval in the PBFT consensus mechanism for blockchain},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Object tracking in infrared images using a deep learning
model and a target-attention mechanism. <em>CIS</em>, <em>9</em>(2),
1495–1506. (<a
href="https://doi.org/10.1007/s40747-022-00872-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small object tracking in infrared images is widely utilized in various fields, such as video surveillance, infrared guidance, and unmanned aerial vehicle monitoring. The existing small target detection strategies in infrared images suffer from submerging the target in heavy cluttered infrared (IR) maritime images. To overcome this issue, we use the original image and the corresponding encoded image to apply our model. We use the local directional number patterns algorithm to encode the original image to represent more unique details. Our model is able to learn more informative and unique features from the original and encoded image for visual tracking. In this study, we explore the best convolutional filters to obtain the best possible visual tracking results by finding those inactive to the backgrounds while active in the target region. To this end, the attention mechanism for the feature extracting framework is investigated comprising a scale-sensitive feature generation component and a discriminative feature generation module based on the gradients of regression and scoring losses. Comprehensive experiments have demonstrated that our pipeline obtains competitive results compared to recently published papers.},
  archive      = {J_CIS},
  author       = {Parhizkar, Mahboub and Karamali, Gholamreza and Abedi Ravan, Bahram},
  doi          = {10.1007/s40747-022-00872-w},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1495-1506},
  shortjournal = {Complex Intell. Syst.},
  title        = {Object tracking in infrared images using a deep learning model and a target-attention mechanism},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nuclear cataract classification in anterior segment OCT
based on clinical global–local features. <em>CIS</em>, <em>9</em>(2),
1479–1493. (<a
href="https://doi.org/10.1007/s40747-022-00869-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nuclear cataract (NC) is a priority ocular disease of blindness and vision impairment globally. Early intervention and cataract surgery can improve the vision and life quality of NC patients. Anterior segment coherence tomography (AS-OCT) imaging is a non-invasive way to capture the NC opacity objectively and quantitatively. Recent clinical research has shown that there exists a strong opacity correlation relationship between NC severity levels and the mean density on AS-OCT images. In this paper, we present an effective NC classification framework on AS-OCT images, based on feature extraction and feature importance analysis. Motivated by previous clinical knowledge, our method extracts the clinical global–local features, and then applies Pearson’s correlation coefficient and recursive feature elimination methods to analyze the feature importance. Finally, an ensemble logistic regression is employed to distinguish NC, which considers different optimization methods’ characteristics. A dataset with 11,442 AS-OCT images is collected to evaluate the method. The results show that the proposed method achieves 86.96% accuracy and 88.70% macro-sensitivity, respectively. The performance comparison analysis also demonstrates that the global–local feature extraction method improves about 2% accuracy than the single region-based feature extraction method.},
  archive      = {J_CIS},
  author       = {Zhang, Xiaoqing and Xiao, Zunjie and Wu, Xiao and Chen, Yu and Higashita, Risa and Chen, Wan and Yuan, Jin and Liu, Jiang},
  doi          = {10.1007/s40747-022-00869-5},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1479-1493},
  shortjournal = {Complex Intell. Syst.},
  title        = {Nuclear cataract classification in anterior segment OCT based on clinical global–local features},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A constrained multi-objective optimization algorithm using
an efficient global diversity strategy. <em>CIS</em>, <em>9</em>(2),
1455–1478. (<a
href="https://doi.org/10.1007/s40747-022-00851-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When solving constrained multi-objective optimization problems (CMOPs), multiple conflicting objectives and multiple constraints need to be considered simultaneously, which are challenging to handle. Although some recent constrained multi-objective evolutionary algorithms (CMOEAs) have been developed to solve CMOPs and have worked well on most CMOPs. However, for CMOPs with small feasible regions and complex constraints, the performance of most algorithms needs to be further improved, especially when the feasible region is composed of multiple disjoint parts or the search space is narrow. To address this issue, an efficient global diversity CMOEA (EGDCMO) is proposed in this paper to solve CMOPs, where a certain number of infeasible solutions with well-distributed feature are maintained in the evolutionary process. To this end, a set of weight vectors are used to specify several subregions in the objective space, and infeasible solutions are selected from each subregion. Furthermore, a new fitness function is used in this proposed algorithm to evaluate infeasible solutions, which can balance the importance of constraints and objectives. In addition, the infeasible solutions are ranked higher than the feasible solutions to focus on the search in the undeveloped areas for better diversity. After the comparison tests on three benchmark cases and an actual engineering application, EGDCMO has more impressive performance compared with other constrained evolutionary multi-objective algorithms.},
  archive      = {J_CIS},
  author       = {Long, Wenyi and Dong, Huachao and Wang, Peng and Huang, Yan and Li, Jinglu and Yang, Xubo and Fu, Chongbo},
  doi          = {10.1007/s40747-022-00851-1},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1455-1478},
  shortjournal = {Complex Intell. Syst.},
  title        = {A constrained multi-objective optimization algorithm using an efficient global diversity strategy},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-scale progressive blind face deblurring. <em>CIS</em>,
<em>9</em>(2), 1439–1453. (<a
href="https://doi.org/10.1007/s40747-022-00865-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blind face deblurring aims to recover a sharper face from its unknown degraded version (i.e., different motion blur, noise). However, most previous works typically rely on degradation facial priors extracted from low-quality inputs, which generally leads to unlifelike deblurring results. In this paper, we propose a multi-scale progressive face-deblurring generative adversarial network (MPFD-GAN) that requires no facial priors to generate more realistic multi-scale deblurring results by one feed-forward process. Specifically, MPFD-GAN mainly includes two core modules: the feature retention module and the texture reconstruction module (TRM). The former can capture non-local similar features by full advantage of the different receptive fields, which facilitates the network to recover the complete structure. The latter adopts a supervisory attention mechanism that fully utilizes the recovered low-scale face to refine incoming features at every scale before propagating them further. Moreover, TRM extracts the high-frequency texture information from the recovered low-scale face by the Laplace operator, which guides subsequent steps to progressively recover faithful face texture details. Experimental results on the CelebA, UTKFace and CelebA-HQ datasets demonstrate the effectiveness of the proposed network, which achieves better accuracy and visual quality against state-of-the-art methods.},
  archive      = {J_CIS},
  author       = {Zhang, Hao and Shi, Canghong and Zhang, Xian and Wu, Linfeng and Li, Xiaojie and Peng, Jing and Wu, Xi and Lv, Jiancheng},
  doi          = {10.1007/s40747-022-00865-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1439-1453},
  shortjournal = {Complex Intell. Syst.},
  title        = {Multi-scale progressive blind face deblurring},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel dynamic reference point model for preference-based
evolutionary multiobjective optimization. <em>CIS</em>, <em>9</em>(2),
1415–1437. (<a
href="https://doi.org/10.1007/s40747-022-00860-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of preference-based evolutionary multiobjective optimization, optimization algorithms are required to search for the Pareto optimal solutions preferred by the decision maker (DM). The reference point is a type of techniques that effectively describe the preferences of DM. So far, the reference point is either static or interactive with the evolutionary process. However, the existing reference point techniques do not cover all application scenarios. A novel case, i.e., the reference point changes over time due to the environment change, has not been considered. This paper focuses on the multiobjective optimization problems with dynamic preferences of the DM. First, we propose a change model of the reference point to simulate the change of the preference by the DM over time. Then, a dynamic preference-based multiobjective evolutionary algorithm framework with a clonal selection algorithm (ĝa-NSCSA) and a genetic algorithm (ĝa-NSGA-II) is designed to solve such kind of optimization problems. In addition, in terms of practical applications, the experiments on the portfolio optimization problems with the dynamic reference point model are tested. Experimental results on the benchmark problems and the practical applications show that ĝa-NSCSA exhibits better performance among the compared optimization algorithms.},
  archive      = {J_CIS},
  author       = {Lin, Xin and Luo, Wenjian and Gu, Naijie and Zhang, Qingfu},
  doi          = {10.1007/s40747-022-00860-0},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1415-1437},
  shortjournal = {Complex Intell. Syst.},
  title        = {A novel dynamic reference point model for preference-based evolutionary multiobjective optimization},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Credit risk assessment mechanism of personal auto loan based
on PSO-XGBoost model. <em>CIS</em>, <em>9</em>(2), 1391–1414. (<a
href="https://doi.org/10.1007/s40747-022-00854-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As online P2P loans in automotive financing grows, there is a need to manage and control the credit risk of the personal auto loans. In this paper, the personal auto loans data sets on the Kaggle platform are used on a machine learning based credit risk assessment mechanism for personal auto loans. An integrated Smote-Tomek Link algorithm is proposed to convert the data set into a balanced data set. Then, an improved Filter-Wrapper feature selection method is presented to select credit risk assessment indexes for the loans. Combining Particle Swarm Optimization (PSO) with the eXtreme Gradient Boosting (XGBoost) model, a PSO-XGBoost model is formed to assess the credit risk of the loans. The PSO-XGBoost model is compared against the XGBoost, Random Forest, and Logistic Regression models on the standard performance evaluation indexes of accuracy, precision, ROC curve, and AUC value. The PSO-XGBoost model is found to be superior on classification performance and classification effect.},
  archive      = {J_CIS},
  author       = {Rao, Congjun and Liu, Ying and Goh, Mark},
  doi          = {10.1007/s40747-022-00854-y},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1391-1414},
  shortjournal = {Complex Intell. Syst.},
  title        = {Credit risk assessment mechanism of personal auto loan based on PSO-XGBoost model},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parallel temporal feature selection based on improved
attention mechanism for dynamic gesture recognition. <em>CIS</em>,
<em>9</em>(2), 1377–1390. (<a
href="https://doi.org/10.1007/s40747-022-00858-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic gesture recognition has become a new type of interaction to meet the needs of daily interaction. It is the most natural, easy to operate, and intuitive, so it has a wide range of applications. The accuracy of gesture recognition depends on the ability to accurately learn the short-term and long-term spatiotemporal features of gestures. Our work is different from improving the performance of a single type of network with convnets-based models and recurrent neural network-based models or serial stacking of two heterogeneous networks, we proposed a fusion architecture that can simultaneously learn short-term and long-term spatiotemporal features of gestures, which combined convnets-based models and recurrent neural network-based models in parallel. At each stage of feature learning, the short-term and long-term spatiotemporal features of gestures are captured simultaneously, and the contribution of two heterogeneous networks to the classification results in spatial and channel axes that can be learned automatically by using the attention mechanism. The sequence and pooling operation of the channel attention module and spatial attention module are compared through experiments. And the proportion of short-term and long-term features of gestures on channel and spatial axes in each stage of feature learning is quantitatively analyzed, and the final model is determined according to the experimental results. The module can be used for end-to-end learning and the proposed method was validated on the EgoGesture, SKIG, and IsoGD datasets and got very competitive performance.},
  archive      = {J_CIS},
  author       = {Chen, Gongzheng and Dong, Zhenghong and Wang, Jue and Xia, Lurui},
  doi          = {10.1007/s40747-022-00858-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1377-1390},
  shortjournal = {Complex Intell. Syst.},
  title        = {Parallel temporal feature selection based on improved attention mechanism for dynamic gesture recognition},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-task learning-based generative adversarial network
for red tide multivariate time series imputation. <em>CIS</em>,
<em>9</em>(2), 1363–1376. (<a
href="https://doi.org/10.1007/s40747-022-00856-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Red tide data are typical multivariate time series (MTS) and complete data help analyze red tide more conveniently. However, missing values due to artificial or accidental events hinder further analysis of red tide phenomenon. Generative adversarial network (GAN) is effective in capturing distribution of MTS while the imputation performance is far from satisfactory, especially in conditions of high missing rate. One of the remaining open challenges is that common GAN-based imputation methods usually lack the ability to excavate implicit correlations between different attributions and downstream tasks, from which advanced latent information about missing values can be mined to improve imputation performance. To deal with the problem, a novel multi-task learning-based generative adversarial imputation network (MTGAIN) is proposed by introducing the prediction task into GAN to unearth more detailed information about missing values to better model distribution of red tide MTS. Furthermore, the homoscedastic uncertainty of multiple tasks is exploited to balance the weights of losses between generation and prediction tasks. The experiments conducted on a real-world dataset demonstrate that MTGAIN outperforms existing methods in terms of imputation and post-imputation performances, especially in conditions of high missing rate.},
  archive      = {J_CIS},
  author       = {Xu, Longfei and Xu, Lingyu and Yu, Jie},
  doi          = {10.1007/s40747-022-00856-w},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1363-1376},
  shortjournal = {Complex Intell. Syst.},
  title        = {A multi-task learning-based generative adversarial network for red tide multivariate time series imputation},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiple spatial residual network for object detection.
<em>CIS</em>, <em>9</em>(2), 1347–1362. (<a
href="https://doi.org/10.1007/s40747-022-00859-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many residual network-based methods have been proposed to perform object detection. However, most of them may lead to overfitting or cannot perform well in small object detection and alleviate the problem of overfitting. We propose a multiple spatial residual network (MSRNet) for object detection. Particularly, our method is based on central point detection algorithm. Our proposed MSRNet employs a residual network as the backbone. The resulting features are processed by our proposed residual channel pooling module. We then construct a multi-scale feature transposed residual fusion structure consists of three overlapping stacked residual convolution modules and a transpose convolution function. Finally, we use the Center structure to process the high-resolution feature image for obtaining the final prediction detection result. Experimental results on PASCAL VOC dataset and COCO dataset confirm that the MSRNet has competitive accuracy compared with several other classical object detection algorithms, while providing a unified framework for training and reasoning. The MSRNet runs on GeForce RTX 2080Ti.},
  archive      = {J_CIS},
  author       = {Dong, Yongsheng and Jiang, Zhiqiang and Tao, Fazhan and Fu, Zhumu},
  doi          = {10.1007/s40747-022-00859-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1347-1362},
  shortjournal = {Complex Intell. Syst.},
  title        = {Multiple spatial residual network for object detection},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using dual evolutionary search to construct decision tree
based ensemble classifier. <em>CIS</em>, <em>9</em>(2), 1327–1345. (<a
href="https://doi.org/10.1007/s40747-022-00855-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A typical ensemble learning process typically uses a forward integration mechanism to construct the ensemble classifier with a large number of base classifiers. Based on this mechanism, it is difficult to adjust the diversity among base classifiers and optimize the structure inside ensemble since the generation process has a certain amount of randomness, which makes the performance of ensemble classifiers heavily dependent on the human design decisions. To address this issue, we proposed an automatic ensemble classifier construction method based on a dual-layer evolutionary search mechanism, which includes a tree coding-based base classifier population and a binary coding-based ensemble classifier population. Through a collaborative searching process between the two populations, the proposed method can be driven by training data to update the base classifier population and optimize the ensemble classifiers globally. To verify the effectiveness of the dual evolutionary ensemble learning method (DEEL), we tested it on 22 classification tasks from 4 data repositories. The results show that the proposed method can generate a diverse decision tree population on the training data while searching and constructing ensemble classifiers from them. Compared with 9 competitor algorithms, the proposed method achieved the best performance on 17 of 22 test tasks and improved the average accuracies by 0.97–7.65% over the second place. In particular, the generated ensemble classifiers show excellent structure, which involve small number and diverse decision trees. That increases the transparency of ensembles and helps to perform interpretability analysis on them.},
  archive      = {J_CIS},
  author       = {Chen, Hao and Zhang, Guoxin and Pan, Xiaoying and Jia, Rong},
  doi          = {10.1007/s40747-022-00855-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1327-1345},
  shortjournal = {Complex Intell. Syst.},
  title        = {Using dual evolutionary search to construct decision tree based ensemble classifier},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the similarity measures of n-cubic pythagorean fuzzy sets
using the overlapping ratio. <em>CIS</em>, <em>9</em>(2), 1317–1325. (<a
href="https://doi.org/10.1007/s40747-022-00850-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The similarity measures are essential concepts to discuss the closeness between sets. Fuzzy similarity measures and intuitionistic fuzzy similarity measures dealt with the incomplete and inconsistent data more efficiently. With time in decision-making theory, a complex frame of the environment that occurs cannot be specified entirely by these sets. A generalization like the Pythagorean fuzzy set can handle such a situation more efficiently. The applicability of this set attracted the researchers to generalize it into N-Pythagorean, interval-valued N-Pythagorean, and N-cubic Pythagorean sets. For this purpose, first, we define the overlapping ratios of N-interval valued Pythagorean and N-Pythagorean fuzzy sets. In addition, we define similarity measures in these sets. We applied this proposed measure for comparison analysis of plagiarism software.},
  archive      = {J_CIS},
  author       = {Shumrani, Mohammed A. Al and Gulistan, Muhammad},
  doi          = {10.1007/s40747-022-00850-2},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1317-1325},
  shortjournal = {Complex Intell. Syst.},
  title        = {On the similarity measures of N-cubic pythagorean fuzzy sets using the overlapping ratio},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Custom CornerNet: A drone-based improved deep learning
technique for large-scale multiclass pest localization and
classification. <em>CIS</em>, <em>9</em>(2), 1299–1316. (<a
href="https://doi.org/10.1007/s40747-022-00847-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Insect pests are among the most critical factors affecting crops and result in a severe reduction in food yield. At the same time, early and accurate identification of insect pests can assist farmers in taking timely preventative steps to reduce financial losses and improve food quality. However, the manual inspection process is a daunting and time-consuming task due to visual similarity between various insect species. Moreover, sometimes it is difficult to find an experienced professional for the consultation. To deal with the problems of manual inspection, we have presented an automated framework for the identification and categorization of insect pests using deep learning. We proposed a lightweight drone-based approach, namely a custom CornerNet approach with DenseNet-100 as a base network. The introduced framework comprises three phases. The region of interest is initially acquired by developing sample annotations later used for model training. A custom CornerNet is proposed in the next phase by employing the DenseNet-100 for deep keypoints computation. The one-stage detector CornerNet identifies and categorizes several insect pests in the final step. The DenseNet network improves the capacity of feature representation by connecting the feature maps from all of its preceding layers and assists the CornerNet model in detecting insect pests as paired vital points. We assessed the performance of the proposed model on the standard IP102 benchmark dataset for pest recognition which is challenging in terms of pest size, color, orientation, category, chrominance, and lighting variations. Both qualitative and quantitative experimental results showed the effectiveness of our approach for identifying target insects in the field with improved accuracy and recall rates.},
  archive      = {J_CIS},
  author       = {Albattah, Waleed and Masood, Momina and Javed, Ali and Nawaz, Marriam and Albahli, Saleh},
  doi          = {10.1007/s40747-022-00847-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1299-1316},
  shortjournal = {Complex Intell. Syst.},
  title        = {Custom CornerNet: A drone-based improved deep learning technique for large-scale multiclass pest localization and classification},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploiting lexical patterns for knowledge graph construction
from unstructured text in spanish. <em>CIS</em>, <em>9</em>(2),
1281–1297. (<a
href="https://doi.org/10.1007/s40747-022-00805-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) are useful data structures for the integration, retrieval, dissemination, and inference of information in various information domains. One of the main challenges in building KGs is the extraction of named entities (nodes) and their relations (edges), particularly when processing unstructured text as it has no semantic descriptions. Generating KGs from texts written in Spanish represents a research challenge as the existing structures, models, and strategies designed for other languages are not compatible in this scenario. This paper proposes a method to design and construct KGs from unstructured text in Spanish. We defined lexical patterns to extract named entities and (non) taxonomic, equivalence, and composition relations. Next, named entities are linked and enriched with DBpedia resources through a strategy based on SPARQL queries. Finally, OWL properties are defined from the predicate relations for creating resource description framework (RDF) triples. We evaluated the performance of the proposed method to determine the degree of elements extracted from the input text and to assess their quality through standard information retrieval measures. The evaluation revealed the feasibility of the proposed method to extract RDF triples from datasets in general and computer science domains. Competitive results were observed by comparing our method regarding an existing approach from the literature.},
  archive      = {J_CIS},
  author       = {Rios-Alvarado, Ana B. and Martinez-Rodriguez, Jose L. and Garcia-Perez, Andrea G. and Guerrero-Melendez, Tania Y. and Lopez-Arevalo, Ivan and Gonzalez-Compean, Jose Luis},
  doi          = {10.1007/s40747-022-00805-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1281-1297},
  shortjournal = {Complex Intell. Syst.},
  title        = {Exploiting lexical patterns for knowledge graph construction from unstructured text in spanish},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fast and efficient algorithm for DNA sequence similarity
identification. <em>CIS</em>, <em>9</em>(2), 1265–1280. (<a
href="https://doi.org/10.1007/s40747-022-00846-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {DNA sequence similarity analysis is necessary for enormous purposes including genome analysis, extracting biological information, finding the evolutionary relationship of species. There are two types of sequence analysis which are alignment-based (AB) and alignment-free (AF). AB is effective for small homologous sequences but becomes NP-hard problem for long sequences. However, AF algorithms can solve the major limitations of AB. But most of the existing AF methods show high time complexity and memory consumption, less precision, and less performance on benchmark datasets. To minimize these limitations, we develop an AF algorithm using a 2D $$k-mer$$ count matrix inspired by the CGR approach. Then we shrink the matrix by analyzing the neighbors and then measure similarities using the best combinations of pairwise distance (PD) and phylogenetic tree methods. We also dynamically choose the value of k for $$k-mer$$ . We develop an efficient system for finding the positions of $$k-mer$$ in the count matrix. We apply our system in six different datasets. We achieve the top rank for two benchmark datasets from AFproject, 100% accuracy for two datasets (16 S Ribosomal, 18 Eutherian), and achieve a milestone for time complexity and memory consumption in comparison to the existing study datasets (HEV, HIV-1). Therefore, the comparative results of the benchmark datasets and existing studies demonstrate that our method is highly effective, efficient, and accurate. Thus, our method can be used with the top level of authenticity for DNA sequence similarity measurement.},
  archive      = {J_CIS},
  author       = {Uddin, Machbah and Islam, Mohammad Khairul and Hassan, Md. Rakib and Jahan, Farah and Baek, Joong Hwan},
  doi          = {10.1007/s40747-022-00846-y},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1265-1280},
  shortjournal = {Complex Intell. Syst.},
  title        = {A fast and efficient algorithm for DNA sequence similarity identification},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Decentralized robust interaction control of modular robot
manipulators via harmonic drive compliance model-based human motion
intention identification. <em>CIS</em>, <em>9</em>(2), 1247–1263. (<a
href="https://doi.org/10.1007/s40747-022-00816-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a human motion intention estimation-based decentralized robust interaction control method of modular robot manipulators (MRMs) is proposed under the situation of physical human–robot interaction (pHRI). Different from traditional interaction control scheme that depends on the biological signal and centralized control method, the decentralized robust interaction control is implemented that using only position measurements of each joint module in this investigation. Based on the harmonic drive compliance model, a novel torque-sensorless human motion intention estimation method is developed, which utilizes only the information of local dynamic position measurements. On this basis, the decentralized robust interaction control scheme is presented to achieve high performance of position tracking and ensure the security of interaction to create the ’safety’ interaction environment. The uniformly ultimately bounded (UUB) of the tracking error is proved by the Lyapunov theory. Finally, pHRI experiments confirm the effectiveness and advancement of the proposed method.},
  archive      = {J_CIS},
  author       = {Dong, Bo and Wang, Yuexi and Chen, Jingchen and Zhang, Zhenguo and An, Tianjiao},
  doi          = {10.1007/s40747-022-00816-4},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1247-1263},
  shortjournal = {Complex Intell. Syst.},
  title        = {Decentralized robust interaction control of modular robot manipulators via harmonic drive compliance model-based human motion intention identification},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A special point-based transfer component analysis for
dynamic multi-objective optimization. <em>CIS</em>, <em>9</em>(2),
1229–1245. (<a
href="https://doi.org/10.1007/s40747-021-00631-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve dynamic multi-objective optimization problems better, the key is to adapt quickly to environmental changes and track the possible changing optimal solutions in time. In this paper, we propose a special point-based transfer component analysis for dynamic multi-objective optimization algorithm (SPTr-RM-MEDA). To be specific, when a change occurs, the neighbors of some special points are selected from the optimal set at previous time, and the transfer component analysis makes the use of minimizing the distance between the mapped previous optima and the mapped current optima. Accordingly, the purpose is to predict a part of next initial population from the neighborhoods of special points by transfer component analysis. To adapt to the change well, SPTr-RM-MEDA also reevaluates the previous optimal set. In addition, an adaptive diversity introduction strategy is adopted to maintain the population size. SPTr-RM-MEDA is performed on 12 test problems under 8 kinds of environmental changes, and experimental results show that it is superior to other five state-of-the-art algorithms on most of test problems.},
  archive      = {J_CIS},
  author       = {Liu, Ruochen and Li, Nanxi and Peng, Luyao and Wu, Kai},
  doi          = {10.1007/s40747-021-00631-3},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1229-1245},
  shortjournal = {Complex Intell. Syst.},
  title        = {A special point-based transfer component analysis for dynamic multi-objective optimization},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-objective multi-criteria evolutionary algorithm for
multi-objective multi-task optimization. <em>CIS</em>, <em>9</em>(2),
1211–1228. (<a
href="https://doi.org/10.1007/s40747-022-00650-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary multi-objective multi-task optimization is an emerging paradigm for solving multi-objective multi-task optimization problem (MO-MTOP) using evolutionary computation. However, most existing methods tend to directly treat the multiple multi-objective tasks as different problems and optimize them by different populations, which face the difficulty in designing good knowledge transferring strategy among the tasks/populations. Different from existing methods that suffer from the difficult knowledge transfer, this paper proposes to treat the MO-MTOP as a multi-objective multi-criteria optimization problem (MO-MCOP), so that the knowledge of all the tasks can be inherited in a same population to be fully utilized for solving the MO-MTOP more efficiently. To be specific, the fitness evaluation function of each task in the MO-MTOP is treated as an evaluation criterion in the corresponding MO-MCOP, and therefore, the MO-MCOP has multiple relevant evaluation criteria to help the individual selection and evolution in different evolutionary stages. Furthermore, a probability-based criterion selection strategy and an adaptive parameter learning method are also proposed to better select the fitness evaluation function as the criterion. By doing so, the algorithm can use suitable evaluation criteria from different tasks at different evolutionary stages to guide the individual selection and population evolution, so as to find out the Pareto optimal solutions of all tasks. By integrating the above, this paper develops a multi-objective multi-criteria evolutionary algorithm framework for solving MO-MTOP. To investigate the proposed algorithm, extensive experiments are conducted on widely used MO-MTOPs to compare with some state-of-the-art and well-performing algorithms, which have verified the great effectiveness and efficiency of the proposed algorithm. Therefore, treating MO-MTOP as MO-MCOP is a potential and promising direction for solving MO-MTOP.},
  archive      = {J_CIS},
  author       = {Du, Ke-Jing and Li, Jian-Yu and Wang, Hua and Zhang, Jun},
  doi          = {10.1007/s40747-022-00650-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1211-1228},
  shortjournal = {Complex Intell. Syst.},
  title        = {Multi-objective multi-criteria evolutionary algorithm for multi-objective multi-task optimization},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adjusting normalization bounds to improve hypervolume based
search for expensive multi-objective optimization. <em>CIS</em>,
<em>9</em>(2), 1193–1209. (<a
href="https://doi.org/10.1007/s40747-021-00590-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When solving expensive multi-objective optimization problems, surrogate models are often used to reduce the number of true evaluations. Based on predictions from the surrogate models, promising candidate solutions, also referred to as infill solutions, can be identified for evaluation to expedite the search towards the optimum. This infill process in turn involves optimization of certain criteria derived from the surrogate models. In this study, predicted hypervolume maximization is considered as the infill criterion for expensive multi/many-objective optimization. In particular, we examine the effect of normalization bounds on the performance of the algorithm building on our previous study on bi-objective optimization. We propose a more scalable approach based on “surrogate corner” search that shows improved performance where some of the conventional techniques face challenges. Numerical experiments on a range of benchmark problems with up to 5 objectives demonstrate the efficacy and reliability of the proposed approach.},
  archive      = {J_CIS},
  author       = {Wang, Bing and Singh, Hemant Kumar and Ray, Tapabrata},
  doi          = {10.1007/s40747-021-00590-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1193-1209},
  shortjournal = {Complex Intell. Syst.},
  title        = {Adjusting normalization bounds to improve hypervolume based search for expensive multi-objective optimization},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accelerating multi-objective neural architecture search by
random-weight evaluation. <em>CIS</em>, <em>9</em>(2), 1183–1192. (<a
href="https://doi.org/10.1007/s40747-021-00594-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the goal of automated design of high-performance deep convolutional neural networks (CNNs), neural architecture search (NAS) methodology is becoming increasingly important for both academia and industries. Due to the costly stochastic gradient descent training of CNNs for performance evaluation, most existing NAS methods are computationally expensive for real-world deployments. To address this issue, we first introduce a new performance estimation metric, named random-weight evaluation (RWE) to quantify the quality of CNNs in a cost-efficient manner. Instead of fully training the entire CNN, the RWE only trains its last layer and leaves the remainders with randomly initialized weights, which results in a single network evaluation in seconds. Second, a complexity metric is adopted for multi-objective NAS to balance the model size and performance. Overall, our proposed method obtains a set of efficient models with state-of-the-art performance in two real-world search spaces. Then the results obtained on the CIFAR-10 dataset are transferred to the ImageNet dataset to validate the practicality of the proposed algorithm. Moreover, ablation studies on NAS-Bench-301 datasets reveal the effectiveness of the proposed RWE in estimating the performance compared to existing methods.},
  archive      = {J_CIS},
  author       = {Hu, Shengran and Cheng, Ran and He, Cheng and Lu, Zhichao and Wang, Jing and Zhang, Miao},
  doi          = {10.1007/s40747-021-00594-5},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1183-1192},
  shortjournal = {Complex Intell. Syst.},
  title        = {Accelerating multi-objective neural architecture search by random-weight evaluation},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comparing interactive evolutionary multiobjective
optimization methods with an artificial decision maker. <em>CIS</em>,
<em>9</em>(2), 1165–1181. (<a
href="https://doi.org/10.1007/s40747-021-00586-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving multiobjective optimization problems with interactive methods enables a decision maker with domain expertise to direct the search for the most preferred trade-offs with preference information and learn about the problem. There are different interactive methods, and it is important to compare them and find the best-suited one for solving the problem in question. Comparisons with real decision makers are expensive, and artificial decision makers (ADMs) have been proposed to simulate humans in basic testing before involving real decision makers. Existing ADMs only consider one type of preference information. In this paper, we propose ADM-II, which is tailored to assess several interactive evolutionary methods and is able to handle different types of preference information. We consider two phases of interactive solution processes, i.e., learning and decision phases separately, so that the proposed ADM-II generates preference information in different ways in each of them to reflect the nature of the phases. We demonstrate how ADM-II can be applied with different methods and problems. We also propose an indicator to assess and compare the performance of interactive evolutionary methods.},
  archive      = {J_CIS},
  author       = {Afsar, Bekir and Ruiz, Ana B. and Miettinen, Kaisa},
  doi          = {10.1007/s40747-021-00586-5},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1165-1181},
  shortjournal = {Complex Intell. Syst.},
  title        = {Comparing interactive evolutionary multiobjective optimization methods with an artificial decision maker},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved NSGA-III using transfer learning and centroid
distance for dynamic multi-objective optimization. <em>CIS</em>,
<em>9</em>(2), 1143–1164. (<a
href="https://doi.org/10.1007/s40747-021-00570-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective problems in real world are often contradictory and even change over time. As we know, how to find the changing Pareto front quickly and accurately is challenging during the process of solving dynamic multi-objective optimization problems (DMOPs). In addition, most solutions obey different distributions in decision space and the performance of NSGA-III when dealing with DMOPs should be further improved. In this paper, centroid distance is proposed and combined into NSGA-III with transfer learning together for DMOPs, called TC_NSGAIII. Centroid distance-based strategy is regarded as a prediction method to prevent some inappropriate individuals through measuring the distance of the population centroid and reference points. After the distance strategy, transfer learning is used for generating an initial population using the past experience. To verify the effectiveness of our proposed algorithm, NSGAIII, Tr_NSGAIII (NSGA-III combining with transfer learning only), Ce_NSGAIII (NSGA-III combining with centroid distance only), and TC_NSGAIII are compared. Seven state-of-the-art algorithms have been used for comparison on CEC 2015 benchmarks. Besides, transfer learning and centroid distance are regarded as a dynamic strategy, which is incorporated into three static algorithms, and the performance improvement is measured. What’s more, twelve benchmark functions from CEC 2015 and eight sets of parameters in each function are used in our experiments. The experimental results show that the performance of algorithms can be greatly improved through the proposed approach.},
  archive      = {J_CIS},
  author       = {Zhang, Haijuan and Wang, Gai-Ge},
  doi          = {10.1007/s40747-021-00570-z},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1143-1164},
  shortjournal = {Complex Intell. Syst.},
  title        = {Improved NSGA-III using transfer learning and centroid distance for dynamic multi-objective optimization},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved SparseEA for sparse large-scale multi-objective
optimization problems. <em>CIS</em>, <em>9</em>(2), 1127–1142. (<a
href="https://doi.org/10.1007/s40747-021-00553-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse large-scale multi-objective optimization problems (LSMOPs) widely exist in real-world applications, which have the properties of involving a large number of decision variables and sparse Pareto optimal solutions, i.e., most decision variables of these solutions are zero. In recent years, sparse LSMOPs have attracted increasing attentions in the evolutionary computation community. However, all the recently tailored algorithms for sparse LSMOPs put the sparsity detection and maintenance in the first place, where the nonzero variables can hardly be optimized sufficiently within a limited budget of function evaluations. To address this issue, this paper proposes to enhance the connection between real variables and binary variables within the two-layer encoding scheme with the assistance of variable grouping techniques. In this way, more efforts can be devoted to the real part of nonzero variables, achieving the balance between sparsity maintenance and variable optimization. According to the experimental results on eight benchmark problems and three real-world applications, the proposed algorithm is superior over existing state-of-the-art evolutionary algorithms for sparse LSMOPs.},
  archive      = {J_CIS},
  author       = {Zhang, Yajie and Tian, Ye and Zhang, Xingyi},
  doi          = {10.1007/s40747-021-00553-0},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1127-1142},
  shortjournal = {Complex Intell. Syst.},
  title        = {Improved SparseEA for sparse large-scale multi-objective optimization problems},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The dilemma between eliminating dominance-resistant
solutions and preserving boundary solutions of extremely convex pareto
fronts. <em>CIS</em>, <em>9</em>(2), 1117–1126. (<a
href="https://doi.org/10.1007/s40747-021-00543-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been acknowledged that dominance-resistant solutions (DRSs) extensively exist in the feasible region of multi-objective optimization problems. Recent studies show that DRSs can cause serious performance degradation of many multi-objective evolutionary algorithms (MOEAs). Thereafter, various strategies (e.g., the $$\epsilon $$ -dominance and the modified objective calculation) to eliminate DRSs have been proposed. However, these strategies may in turn cause algorithm inefficiency in other aspects. We argue that these coping strategies prevent the algorithm from obtaining some boundary solutions of an extremely convex Pareto front (ECPF). That is, there is a dilemma between eliminating DRSs and preserving boundary solutions of the ECPF. To illustrate such a dilemma, we propose a new multi-objective optimization test problem with the ECPF as well as DRSs. Using this test problem, we investigate the performance of six representative MOEAs in terms of boundary solutions preservation and DRS elimination. The results reveal that it is quite challenging to distinguish between DRSs and boundary solutions of the ECPF.},
  archive      = {J_CIS},
  author       = {Wang, Zhenkun and Li, Qingyan and Yang, Qite and Ishibuchi, Hisao},
  doi          = {10.1007/s40747-021-00543-2},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1117-1126},
  shortjournal = {Complex Intell. Syst.},
  title        = {The dilemma between eliminating dominance-resistant solutions and preserving boundary solutions of extremely convex pareto fronts},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Guest editorial for special issue “emerging topics in
evolutionary multiobjective optimization.” <em>CIS</em>, <em>9</em>(2),
1115–1116. (<a
href="https://doi.org/10.1007/s40747-023-01047-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CIS},
  author       = {He, Cheng and Gong, Dunwei and Tan, Kay Chen},
  doi          = {10.1007/s40747-023-01047-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {4},
  number       = {2},
  pages        = {1115-1116},
  shortjournal = {Complex Intell. Syst.},
  title        = {Guest editorial for special issue “Emerging topics in evolutionary multiobjective optimization”},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Topology-based UAV path planning for multi-view stereo 3D
reconstruction of complex structures. <em>CIS</em>, <em>9</em>(1),
909–926. (<a href="https://doi.org/10.1007/s40747-022-00831-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new UAV path planning method for creating high-quality 3D reconstruction models of large and complex structures. The core of the new method is incorporating the topology information of the surveyed 3D structure to decompose the multi-view stereo path planning into a collection of overlapped view optimization problems that can be processed in parallel. Different from the existing state-of-the-arts that recursively select the vantage camera views, the new method iteratively resamples all nearby cameras (i.e., positions/orientations) together and achieves a substantial reduction in computation cost while improving reconstruction quality. The new approach also provides a higher-level automation function that facilitates field implementations by eliminating the need for redundant camera initialization as in existing studies. Validations are provided by measuring the variance between the reconstructions to the ground truth models. Results from three synthetic case studies and one real-world application are presented to demonstrate the improved performance. The new method is expected to be instrumental in expanding the adoption of UAV-based multi-view stereo 3D reconstruction of large and complex structures.},
  archive      = {J_CIS},
  author       = {Shang, Zhexiong and Shen, Zhigang},
  doi          = {10.1007/s40747-022-00831-5},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {909-926},
  shortjournal = {Complex Intell. Syst.},
  title        = {Topology-based UAV path planning for multi-view stereo 3D reconstruction of complex structures},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GRAN: Graph recurrent attention network for pedestrian
orientation classification. <em>CIS</em>, <em>9</em>(1), 891–908. (<a
href="https://doi.org/10.1007/s40747-022-00836-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In complex traffic scenes, accurate identification of pedestrian orientations can help drivers determine pedestrian trajectories and help reduce traffic accidents. However, there are still many challenges in pedestrian orientation recognition. First, due to the irregular appearance of pedestrians, it is difficult for general Convolutional Neural Networks (CNNs) to extract discriminative features. In addition, more features of body parts help to judge the orientation of pedestrians. For example, head, arms and legs. However, they are usually small and not conducive to feature extraction. Therefore, in this work, we use several discrete values to define the orientation of pedestrians, and propose a Gated Graph Neural Network (GGNN)-based Graph Recurrent Attention Network (GRAN) to classify the orientation of pedestrians. The contributions are as follows: (1) We construct a body parts graph consisting of head, arms and legs on the feature maps output by the CNN backbone. (2) Mining the dependencies between body parts on the graph via the proposed GRAN, and utilizing the encoder–decoder to propagate features among graph nodes. (3) In this process, we propose an adjacency matrix with attention edge weights to dynamically represent graph node relationships, and the edge weights are learned during network training. To evaluate the proposed method, we conduct experiments on three different benchmarks (PDC, PDRD, and Cityscapes) with 8, 3, and 4 orientations, respectively. Note that the orientation labels for PDRD and Cityscapes are annotated by our hand. The proposed method achieves 97%, 91% and 90% classification accuracy on the three data sets, respectively. The results are all higher than current state-of-the-art methods, which demonstrate the effectiveness of the proposed method.},
  archive      = {J_CIS},
  author       = {Li, Xiao and Ma, Shexiang and Shan, Liqing and Liu, Sheng and Chai, Song},
  doi          = {10.1007/s40747-022-00836-0},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {891-908},
  shortjournal = {Complex Intell. Syst.},
  title        = {GRAN: Graph recurrent attention network for pedestrian orientation classification},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed tracking control of structural balance for
complex dynamical networks based on the coupling targets of nodes and
links. <em>CIS</em>, <em>9</em>(1), 881–889. (<a
href="https://doi.org/10.1007/s40747-022-00840-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the complex dynamical networks (CDNs) with dynamic connections are regarded as an interconnected systems composed of intercoupling links’ subsystem (LS) and nodes’ subsystem (NS). Different from the previous researches on structural balance control of CDNs, the directed CDNs’ structural balance problem is solved. Considering the state of links cannot be measured accurately in practice, we can control the nodes’ state and enforce the weights of links to satisfy the conditions of structural balance via effective coupling. To achieve this aim, a coupling strategy between a predetermined matrix of the structural balance and a reference tracking target of NS is established by the correlative control method. Here, the controller in NS is used to track the reference tracking target, and indirectly let LS track the predetermined matrix and reach a structural balance by the effective coupling for directed and undirected networks. Finally, numerical simulations are presented to verify the theoretical results.},
  archive      = {J_CIS},
  author       = {Gao, Zilin and Li, Yongfu and Wang, Yinhe and Liu, Qingshan},
  doi          = {10.1007/s40747-022-00840-4},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {881-889},
  shortjournal = {Complex Intell. Syst.},
  title        = {Distributed tracking control of structural balance for complex dynamical networks based on the coupling targets of nodes and links},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-view 3D human pose reconstruction based on spatial
confidence point group for jump analysis in figure skating.
<em>CIS</em>, <em>9</em>(1), 865–879. (<a
href="https://doi.org/10.1007/s40747-022-00837-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Competitive figure skaters perform successful jumps with critical parameters, which are valuable for jump analysis in athlete training. Driven by recent computer vision applications, recovering 3D pose of figure skater to obtain the meaningful variables has become increasingly important. However, conventional works have suffered from getting 3D information based on the corresponding 2D information directly or leaving the specificity of sports out of consideration. Issues such as self-occlusion, abnormal pose, limitation of venue and so on will result in poor results. Motivated by these problems, this paper proposes a multi-task architecture based on a calibrated multi-camera system to facilitate jointly 3D jump pose of figure skater. The proposed methods consist of three key components: Likelihood distribution and temporal smoothness- based discrete probability points selection filter out the most valuable 2D information; Multi-perspective and combinations unification-based large-scale venue 3D reconstruction is proposed to deal with the multi-camera; multi-constraint-based human skeleton estimation decides the final 3D coordinate from the candidates. This work is proved can be applied to 3D animated display and motion capture of the figure skating competition. The success rate of the independent joint is: 93.38% of 70 mm error range, 92.57% of 50 mm error range and 91.55% of 30 mm error range.},
  archive      = {J_CIS},
  author       = {Tian, Limao and Cheng, Xina and Honda, Masaaki and Ikenaga, Takeshi},
  doi          = {10.1007/s40747-022-00837-z},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {865-879},
  shortjournal = {Complex Intell. Syst.},
  title        = {Multi-view 3D human pose reconstruction based on spatial confidence point group for jump analysis in figure skating},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-granularity scenarios understanding network for
trajectory prediction. <em>CIS</em>, <em>9</em>(1), 851–864. (<a
href="https://doi.org/10.1007/s40747-022-00834-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding agents’ motion behaviors under complex scenes is crucial for intelligent autonomous moving systems (like delivery robots and self-driving cars). It is challenging duo to the inherent uncertain of future trajectories and the large variation in the scene layout. However, most recent approaches ignored or underutilized the scenario information. In this work, a Multi-Granularity Scenarios Understanding framework, MGSU, is proposed to explore the scene layout from different granularity. MGSU can be divided into three modules: (1) A coarse-grained fusion module uses the cross-attention to fuse the observed trajectory with the semantic information of the scene. (2) The inverse reinforcement learning module generates optimal path strategy through grid-based policy sampling and outputs multiple scene paths. (3) The fine-grained fusion module integrates the observed trajectory with the scene paths to generate multiple future trajectories. To fully explore the scene information and improve the efficiency, we present a novel scene-fusion Transformer, whose encoder is used to extract scene features and the decoder is used to fuse scene and trajectory features to generate future trajectories. Compared with the current state-of-the-art methods, our method decreases the ADE errors by 4.3% and 3.3% by gradually integrating different granularity of scene information on SDD and NuScenes, respectively. The visualized trajectories demonstrate that our method can accurately predict future trajectories after fusing scene information.},
  archive      = {J_CIS},
  author       = {Yang, Biao and Yang, Jicheng and Ni, Rongrong and Yang, Changchun and Liu, Xiaofeng},
  doi          = {10.1007/s40747-022-00834-2},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {851-864},
  shortjournal = {Complex Intell. Syst.},
  title        = {Multi-granularity scenarios understanding network for trajectory prediction},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved NSGA-II for energy-efficient distributed no-wait
flow-shop with sequence-dependent setup time. <em>CIS</em>,
<em>9</em>(1), 825–849. (<a
href="https://doi.org/10.1007/s40747-022-00830-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a multi-objective energy-efficient scheduling problem of the distributed permutation flowshop with sequence-dependent setup time and no-wait constraints (EEDNWFSP), which have important practical applications. Two objectives minimization of both makespan and total energy consumption (TEC) are considered simultaneously. To address this problem, a new mixed-integer linear programming (MILP) model is formulated. Considering the issues faced in solving large-scale instances, an improved non-dominated sorting genetic algorithm (INSGA-II) is further proposed that uses two variants of the Nawaz-Enscore-Ham heuristic (NEH) to generate high-quality initial population. Moreover, two problem-specific speed adjustment heuristics are presented, which can enhance the qualities of the obtained non-dominated solutions. In addition, four local and two global search operators are designed to improve the exploration and exploitation abilities of the proposed algorithm. The effectiveness of the proposed algorithm was verified using extensive computational tests and comparisons. The experimental results show that the proposed INSGA-II is more effective compared to other efficient multi-objective algorithms.},
  archive      = {J_CIS},
  author       = {Zeng, Qing-qing and Li, Jun-qing and Li, Rong-hao and Huang, Ti-hao and Han, Yu-yan and Sang, Hong-yan},
  doi          = {10.1007/s40747-022-00830-6},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {825-849},
  shortjournal = {Complex Intell. Syst.},
  title        = {Improved NSGA-II for energy-efficient distributed no-wait flow-shop with sequence-dependent setup time},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A human learning optimization algorithm with competitive and
cooperative learning. <em>CIS</em>, <em>9</em>(1), 797–823. (<a
href="https://doi.org/10.1007/s40747-022-00808-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human learning optimization (HLO) is a simple yet powerful metaheuristic developed based on a simplified human learning model. Competition and cooperation, as two basic modes of social cognition, can motivate individuals to learn more efficiently and improve their efficiency in solving problems by stimulating their competitive instincts and increasing interaction with each other. Inspired by this fact, this paper presents a novel human learning optimization algorithm with competitive and cooperative learning (HLOCC), in which a competitive and cooperative learning operator (CCLO) is developed to mimic competition and cooperation in social interaction for enhancing learning efficiency. The HLOCC can efficiently maintain the diversity of the algorithm as well as achieve the optimal values, demonstrating that the proposed CCLO can effectively improve algorithm performance. HLOCC has been compared with other heuristic algorithms on CEC2017 functions. In the second study, the uncapacitated facility location problems (UFLPs) which are one of the pure binary optimization problems are solved with HLOCC. The experimental results show that the developed HLOCC is superior to previous HLO variants and other metaheuristics with its improved exploitation and exploration abilities.},
  archive      = {J_CIS},
  author       = {Du, JiaoJie and Wang, Ling and Fei, Minrui and Menhas, Muhammad Ilyas},
  doi          = {10.1007/s40747-022-00808-4},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {797-823},
  shortjournal = {Complex Intell. Syst.},
  title        = {A human learning optimization algorithm with competitive and cooperative learning},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An enhanced whale optimization algorithm with improved
dynamic opposite learning and adaptive inertia weight strategy.
<em>CIS</em>, <em>9</em>(1), 767–795. (<a
href="https://doi.org/10.1007/s40747-022-00827-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whale Optimization Algorithm (WOA), as a newly proposed swarm-based algorithm, has gradually become a popular approach for optimization problems in various engineering fields. However, WOA suffers from the poor balance of exploration and exploitation, and premature convergence. In this paper, a new enhanced WOA (EWOA), which adopts an improved dynamic opposite learning (IDOL) and an adaptive encircling prey stage, is proposed to overcome the problems. IDOL plays an important role in the initialization part and the algorithm iterative process of EWOA. By evaluating the optimal solution in the current population, IDOL can adaptively switch exploitation/exploration modes constructed by the DOL strategy and a modified search strategy, respectively. On the other hand, for the encircling prey stage of EWOA in the latter part of the iteration, an adaptive inertia weight strategy is introduced into this stage to adaptively adjust the prey’s position to avoid falling into local optima. Numerical experiments, with unimodal, multimodal, hybrid and composition benchmarks, and three typical engineering problems are utilized to evaluate the performance of EWOA. The proposed EWOA also evaluates against canonical WOA, three sub-variants of EWOA, three other common algorithms, three advanced algorithms and four advanced variants of WOA. Results indicate that according to Wilcoxon rank sum test and Friedman test, EWOA has balanced exploration and exploitation ability in coping with global optimization, and it has obvious advantages when compared with other state-of-the-art algorithms.},
  archive      = {J_CIS},
  author       = {Cao, Di and Xu, Yunlang and Yang, Zhile and Dong, He and Li, Xiaoping},
  doi          = {10.1007/s40747-022-00827-1},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {767-795},
  shortjournal = {Complex Intell. Syst.},
  title        = {An enhanced whale optimization algorithm with improved dynamic opposite learning and adaptive inertia weight strategy},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deterministic and nature-inspired algorithm for the fuzzy
multi-objective path optimization problem. <em>CIS</em>, <em>9</em>(1),
753–765. (<a href="https://doi.org/10.1007/s40747-022-00825-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increasing evaluation indexes have been involved in the network modeling, and some parameters cannot be described precisely. Fuzzy set theory becomes a promising mathematical method to characterize such uncertain parameters. This study investigates the fuzzy multi-objective path optimization problem (FMOPOP), in which each arc has multiple crisp and fuzzy weights simultaneously. Fuzzy weights are characterized by triangular fuzzy numbers or trapezoidal fuzzy numbers. We adopt two fuzzy number ranking methods based on their fuzzy graded mean values and distances from the fuzzy minimum number. Motivated by the ripple spreading patterns on the natural water surface, we propose a novel ripple-spreading algorithm (RSA) to solve the FMOPOP. Theoretical analyses prove that the RSA can find all Pareto optimal paths from the source node to all other nodes within a single run. Numerical examples and comparative experiments demonstrate the efficiency and robustness of the newly proposed RSA. Moreover, in the first numerical example, the processes of the RSA are illustrated using metaphor-based language and ripple spreading phenomena to be more comprehensible. To the best of our knowledge, the RSA is the first algorithm for the FMOPOP that can adopt various fuzzy numbers and ranking methods while maintaining optimality.},
  archive      = {J_CIS},
  author       = {Ma, Yi-Ming and Hu, Xiao-Bing and Zhou, Hang},
  doi          = {10.1007/s40747-022-00825-3},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {753-765},
  shortjournal = {Complex Intell. Syst.},
  title        = {A deterministic and nature-inspired algorithm for the fuzzy multi-objective path optimization problem},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Social network analysis and consensus reaching
process-driven group decision making method with distributed linguistic
information. <em>CIS</em>, <em>9</em>(1), 733–751. (<a
href="https://doi.org/10.1007/s40747-022-00817-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In group decision making with social network analysis (SNA), determining the weights of experts and constructing the consensus-reaching process (CRP) are hot topics. With respect to the generation of weights of experts, this paper firstly develops a distributed linguistic trust propagation operator and a path order weighted averaging (POWA) operator to explore the trust propagation and aggregation between indirectly connected experts, and the weights of experts can be derived by using relative node in-degree centrality in a complete distributed linguistic trust relationship matrix. Then, three levels of consensus are proposed, in which the most inconsistent evaluation information in distributed linguistic trust decision-making matrices can be pinpointed. Subsequently, the distance between experts’ evaluation information and collective evaluation information is designed to be applied as the adjustment cost in CRP. Finally, a novel feedback mechanism supported by the minimum adjustment cost is activated until the group consensus degree reaches the predefined threshold. The novelties of this paper are as follows: (1) the proposed POWA considers the trust value as well as the propagation efficiency of trust path when aggregating the trust relationship in SNA; (2) the consensus reaching mechanism can gradually improve the value of group consensus degree by continuously adjusting the most inconsistent evaluation information.},
  archive      = {J_CIS},
  author       = {Jin, Feifei and Yang, Yu and Liu, Jinpei and Zhu, Jiaming},
  doi          = {10.1007/s40747-022-00817-3},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {733-751},
  shortjournal = {Complex Intell. Syst.},
  title        = {Social network analysis and consensus reaching process-driven group decision making method with distributed linguistic information},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The fuzzy weighted influence nonlinear gauge system method
extended with d numbers and MICMAC. <em>CIS</em>, <em>9</em>(1),
719–731. (<a href="https://doi.org/10.1007/s40747-022-00832-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Weighted Influence Nonlinear Measurement System (WINGS) method originates from DEMATEL, which has the advantage of analyzing the interweaved determinants and the causal relationships within them. The innovation is mainly reflected in considering both the strength of the influencing factors themselves and the relationship of their mutual influence. To address the problems of ambiguity in assessing information and uncertainty in the judgment of expert group, this paper proposes fuzzy WINGS improved by D numbers (fuzzy D-WINGS). Combining D numbers with Triangular fuzzy numbers can overcome the limitation of mutually exclusive and collectively extensive set. The WINGS method is used to reveal the interdependent causal relationships by recognizing the orientation and strength of the factors. Utilizing the MICMAC method to draw matrix analysis diagrams can further reveal the relationship among them. Finally, a practical case study is conducted to prove the practicability of this fuzzy D-WINGS–MICMAC method.},
  archive      = {J_CIS},
  author       = {Wang, Muwen and Tian, Yuan and Zhang, Kecheng},
  doi          = {10.1007/s40747-022-00832-4},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {719-731},
  shortjournal = {Complex Intell. Syst.},
  title        = {The fuzzy weighted influence nonlinear gauge system method extended with d numbers and MICMAC},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving arithmetic word problems by synergizing
syntax-semantics extractor for explicit relations and neural network
miner for implicit relations. <em>CIS</em>, <em>9</em>(1), 697–717. (<a
href="https://doi.org/10.1007/s40747-022-00828-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a relation-centric algorithm for solving arithmetic word problems (AWPs) by synergizing a syntax-semantics extractor for extracting explicit relations, and a neural network miner for mining implicit relations. This is the first algorithm that has a specific component to acquire implicit knowledge items for solving AWPs. This paper proposes a three-phase scheme to decompose the challenging task of designing an algorithm for solving AWPs into three smaller tasks. The first phase proposes a state-action paradigm; the second phase instantiates the paradigm into a relation-centric approach; and the third phase implements a relation-centric algorithm for solving AWPs. There are two main steps in the proposed algorithm: problem understanding and symbolic solver. By adopting the relation-centric approach, problem understanding becomes a task of relation acquisition. For conducting the task of relation acquisition, a relaxed syntax-semantics method first extracts a group of explicit relation candidates. In parallel, a neural network miner acquires implicit relation candidates. The miner computes the vectors encoded by BERT to determine which implicit relations should be added. Thus, problem understanding can acquire both explicit relations and implicit relations, which addresses the challenge of building a problem understanding method that can acquire all the knowledge items to find the solution. In the subsequent step of symbolic solver, a fusion procedure forms a distilled set of relations from all the candidates by discarding unnecessary relations. Experimentation on nine benchmark datasets validates the superiority of the proposed algorithm that outperforms the state-of-the-art algorithms.},
  archive      = {J_CIS},
  author       = {Yu, Xinguo and Lyu, Xiaopan and Peng, Rao and Shen, Jun},
  doi          = {10.1007/s40747-022-00828-0},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {697-717},
  shortjournal = {Complex Intell. Syst.},
  title        = {Solving arithmetic word problems by synergizing syntax-semantics extractor for explicit relations and neural network miner for implicit relations},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A faster dynamic convergency approach for self-organizing
maps. <em>CIS</em>, <em>9</em>(1), 677–696. (<a
href="https://doi.org/10.1007/s40747-022-00826-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel variable learning rate to address two main challenges of the conventional Self-Organizing Maps (SOM) termed VLRSOM: high accuracy with fast convergence and low topological error. We empirically showed that the proposed method exhibits faster convergence behavior. It is also more robust in topology preservation as it maintains an optimal topology until the end of the maximum iterations. Since the learning rate adaption and the misadjustment parameter depends on the calculated error, the VLRSOM will avoid the undesired results by exploiting the error response during the weight updation. Then the learning rate is updated adaptively after the random initialization at the beginning of the training process. Experimental results show that it eliminates the tradeoff between the rate of convergence and accuracy and maintains the data&#39;s topological relationship. Extensive experiments were conducted on different types of datasets to evaluate the performance of the proposed method. First, we experimented with synthetic data and handwritten digits. For each data set, two experiments with a different number of iterations (200 and 500) were performed to test the stability of the network. The proposed method was further evaluated using four benchmark data sets. These datasets include Balance, Wisconsin Breast, Dermatology, and Ionosphere. In addition, a comprehensive comparative analysis was performed between the proposed method and three other SOM techniques: conventional SOM, parameter-less self-organizing map (PLSOM2), and RA-SOM in terms of accuracy, quantization error (QE), and topology error (TE). The results indicated the proposed approach produced superior results to the other three methods.},
  archive      = {J_CIS},
  author       = {Jamil, Akhtar and Hameed, Alaa Ali and Orman, Zeynep},
  doi          = {10.1007/s40747-022-00826-2},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {677-696},
  shortjournal = {Complex Intell. Syst.},
  title        = {A faster dynamic convergency approach for self-organizing maps},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An environment-driven hybrid evolutionary algorithm for
dynamic multi-objective optimization problems. <em>CIS</em>,
<em>9</em>(1), 659–675. (<a
href="https://doi.org/10.1007/s40747-022-00824-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In dynamic multi-objective optimization problems, the environmental parameters may change over time, which makes the Pareto fronts shifting. To address the issue, a common idea is to track the moving Pareto front once an environmental change occurs. However, it might be hard to obtain the Pareto optimal solutions if the environment changes rapidly. Moreover, it may be costly to implement a new solution. By contrast, robust Pareto optimization over time provides a novel framework to find the robust solutions whose performance is acceptable for more than one environment, which not only saves the computational costs for tracking solutions, but also minimizes the cost for switching solutions. However, neither of the above two approaches can balance between the quality of the obtained non-dominated solutions and the computation cost. To address this issue, environment-driven hybrid dynamic multi-objective evolutionary optimization method is proposed, aiming to fully use strengths of TMO and RPOOT under various characteristics of environmental changes. Two indexes, i.e., the frequency and intensity of environmental changes, are first defined. Then, a criterion is presented based on the characteristics of dynamic environments and the switching cost of solutions, to select an appropriate optimization method in a given environment. The experimental results on a set of dynamic benchmark functions indicate that the proposed hybrid dynamic multi-objective evolutionary optimization method can choose the most rational method that meets the requirements of decision makers, and balance the convergence and robustness of the obtained non-dominated solutions.},
  archive      = {J_CIS},
  author       = {Chen, Meirong and Guo, Yinan and Jin, Yaochu and Yang, Shengxiang and Gong, Dunwei and Yu, Zekuan},
  doi          = {10.1007/s40747-022-00824-4},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {659-675},
  shortjournal = {Complex Intell. Syst.},
  title        = {An environment-driven hybrid evolutionary algorithm for dynamic multi-objective optimization problems},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MTHSA-DHEI: Multitasking harmony search algorithm for
detecting high-order SNP epistatic interactions. <em>CIS</em>,
<em>9</em>(1), 637–658. (<a
href="https://doi.org/10.1007/s40747-022-00813-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genome-wide association studies have succeeded in identifying genetic variants associated with complex diseases, but the findings have not been well interpreted biologically. Although it is widely accepted that epistatic interactions of high-order single nucleotide polymorphisms (SNPs) [(1) Single nucleotide polymorphisms (SNP) are mainly deoxyribonucleic acid (DNA) sequence polymorphisms caused by variants at a single nucleotide at the genome level. They are the most common type of heritable variation in humans.] are important causes of complex diseases, the combinatorial explosion of millions of SNPs and multiple tests impose a large computational burden. Moreover, it is extremely challenging to correctly distinguish high-order SNP epistatic interactions from other high-order SNP combinations due to small sample sizes. In this study, a multitasking harmony search algorithm (MTHSA-DHEI) is proposed for detecting high-order epistatic interactions [(2) In classical genetics, if genes X1 and X2 are mutated and each mutation by itself produces a unique disease status (phenotype) but the mutations together cause the same disease status as the gene X1 mutation, gene X1 is epistatic and gene X2 is hypostatic, and gene X1 has an epistatic effect (main effect) on disease status. In this work, a high-order epistatic interaction occurs when two or more SNP loci have a joint influence on disease status.], with the goal of simultaneously detecting multiple types of high-order (k1-order, k2-order, …, kn-order) SNP epistatic interactions. Unified coding is adopted for multiple tasks, and four complementary association evaluation functions are employed to improve the capability of discriminating the high-order SNP epistatic interactions. We compare the proposed MTHSA-DHEI method with four excellent methods for detecting high-order SNP interactions for 8 high-order epistatic interaction models with no marginal effect (EINMEs) and 12 epistatic interaction models with marginal effects (EIMEs) (*) and implement the MTHSA-DHEI algorithm with a real dataset: age-related macular degeneration (AMD). The experimental results indicate that MTHSA-DHEI has power and an F1-score exceeding 90% for all EIMEs and five EINMEs and reduces the computational time by more than 90%. It can efficiently perform multiple high-order detection tasks for high-order epistatic interactions and improve the discrimination ability for diverse epistasis models.},
  archive      = {J_CIS},
  author       = {Tuo, Shouheng and Li, Chao and Liu, Fan and Li, Aimin and He, Lang and Geem, Zong Woo and Shang, JunLiang and Liu, Haiyan and Zhu, YanLing and Feng, ZengYu and Chen, TianRui},
  doi          = {10.1007/s40747-022-00813-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {637-658},
  shortjournal = {Complex Intell. Syst.},
  title        = {MTHSA-DHEI: Multitasking harmony search algorithm for detecting high-order SNP epistatic interactions},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ACO-based traffic routing method with automated negotiation
for connected vehicles. <em>CIS</em>, <em>9</em>(1), 625–636. (<a
href="https://doi.org/10.1007/s40747-022-00833-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most traffic control systems are centralized, where all the collected data can be analyzed to make a decision. However, there are problems with computational complexity and, more seriously, real-time decision-making. This paper proposes a decentralized traffic routing system based on a new pheromone model of ant colony optimization algorithm and an automated negotiation technique in a connected vehicle environment. In particular, connected vehicles utilize a new pheromone model, namely the inverted pheromone model, which generates a repulsive force between vehicles and gives negative feedback to the congested roads. They also perform a collective learning-based negotiation process for distributing traffic flows throughout the road networks, reducing traffic congestion. Via extensive simulations based on the Simulation of Urban Mobility, the proposed system shows that it can significantly reduce travel time and fuel consumption compared to existing systems.},
  archive      = {J_CIS},
  author       = {Nguyen, Tri-Hai and Jung, Jason J.},
  doi          = {10.1007/s40747-022-00833-3},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {625-636},
  shortjournal = {Complex Intell. Syst.},
  title        = {ACO-based traffic routing method with automated negotiation for connected vehicles},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel image cryptosystem using gray code, quantum walks,
and henon map for cloud applications. <em>CIS</em>, <em>9</em>(1),
609–624. (<a href="https://doi.org/10.1007/s40747-022-00829-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing plays a vital task in our daily lives, in which an enormous amount of data is stored daily on cloud storage. The highest priority for cloud data storage is guaranteeing the security of confidential data. The security of confidential data can be realised through utilising one of the cryptographic mechanisms including encryption and data hiding. With the rapid development for the realization of quantum computers, modern cryptosystems may be cracked including cloud systems. Accordingly, it is a crucial task for achieving confidentiality of data stored on cloud storage before the availability of quantum computers. Therefore, this study aims to utilise one of the quantum computational models, as a quantum-inspired system, to layout a new data confidentiality technique that can be applied in digital devices to have the capability for resisting the potential attacks from quantum and digital computers. In this paper, a new image security algorithm for real-time cloud applications using Gray code, quantum walks (QW), and Henon map is proposed. In the proposed image cryptosystem, the generated key streams from QW and Henon map is related to the plain image with high sensitivity of slight bit changes on the plain image. The outcomes based on deep analysis proves that the presented algorithm is efficient with high security for real-time application.},
  archive      = {J_CIS},
  author       = {Abd-El-Atty, Bassem and ElAffendi, Mohammed and El-Latif, Ahmed A. Abd},
  doi          = {10.1007/s40747-022-00829-z},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {609-624},
  shortjournal = {Complex Intell. Syst.},
  title        = {A novel image cryptosystem using gray code, quantum walks, and henon map for cloud applications},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A privacy-preserving student status monitoring system.
<em>CIS</em>, <em>9</em>(1), 597–608. (<a
href="https://doi.org/10.1007/s40747-022-00796-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Timely feedback of students’ listening status is crucial for teaching work. However, it is often difficult for teachers to pay attention to all students at the same time. By leveraging surveillance cameras in the classroom, we are able to assist the teaching work. However, the existing methods either lack the protection of students’ privacy, or they have to reduce the accuracy of success, because they are concerned about the leakage of students’ privacy. We propose federated semi-supervised class assistance system to evaluate the listening status of students in the classroom. Rather than training the semi-supervised model in a centralized manner, we train a semi-supervised model in a federated manner among various monitors while preserving students’ privacy. We also formulate a new loss function according to the difference between the pre-trained initial model and the expected model to restrict the training process of the unlabeled data. By applying the pseudo-label assignment method on the unlabeled data, the class monitors are able to recognize the student class behavior. In addition, simulation and real-world experimental results demonstrate that the performance of the proposed system outperforms that of the baseline models.},
  archive      = {J_CIS},
  author       = {Wu, Haopeng and Lu, Zhiying and Zhang, Jianfeng},
  doi          = {10.1007/s40747-022-00796-5},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {597-608},
  shortjournal = {Complex Intell. Syst.},
  title        = {A privacy-preserving student status monitoring system},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A classification tree and decomposition based
multi-objective evolutionary algorithm with adaptive operator selection.
<em>CIS</em>, <em>9</em>(1), 579–596. (<a
href="https://doi.org/10.1007/s40747-022-00812-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive operator selection (AOS) is used to dynamically select the appropriate genic operator for offspring reproduction, which aims to improve the performance of evolutionary algorithms (EAs) by producing high-quality offspring during the evolutionary process. This paper proposes a novel classification tree based adaptive operator selection strategy for multi-objective evolutionary algorithm based on decomposition (MOEA/D-CTAOS). In our proposal, the classification tree is trained by the recorded data set which contains the information on the historical offspring. Before the reproduction at each generation, the classifier is used to predict each possible result obtained by different operators, and only one operator with the best result is selected to generate offspring next. Meanwhile, a novel differential evolution based on search inertia (SiDE) is designed to steer the evolutionary process in a more efficient way. The experimental results demonstrate that proposed MOEA/D-CTAOS outperforms other MOEA/D variants on UF and LZ benchmarks in terms of IGD and HV value. Further investigation also confirms the advantage of direction-guided search strategy in SiDE.},
  archive      = {J_CIS},
  author       = {Geng, Huantong and Xu, Ke and Zhang, Yanqi and Zhou, Zhengli},
  doi          = {10.1007/s40747-022-00812-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {579-596},
  shortjournal = {Complex Intell. Syst.},
  title        = {A classification tree and decomposition based multi-objective evolutionary algorithm with adaptive operator selection},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Coevolutionary opinion dynamics with sparse interactions in
open-ended societies. <em>CIS</em>, <em>9</em>(1), 565–577. (<a
href="https://doi.org/10.1007/s40747-022-00810-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Opinion dynamics is a crucial topic in complex social systems. However, existing models rarely study limited information accessibility, sparse interactions, and the coevolution of opinion and an open-ended structure. In this paper, we propose the Sparse COevolutionary Open-Ended (SCOOE) model. We address the sparse interaction limitation through extrinsic collective interaction and intrinsic observation based on incomplete neighborhood information. We also consider the coevolution of opinion and open-ended structure by studying structure-opinion co-dynamics when dissidents are leaving and when newcomers with novel opinions are joining. From an opinion dynamics perspective, we find that the proposed mechanisms effectively form lean and fast decision strategies to reduce conflicts under uncertainty. The model is robust in boosting and enhancing a global consensus with only small odds of extreme results. The structure evolves toward a small-world network. We find that an emergent dialectic relationship exists between community segregation and community cohesion viewed from a structural dynamics perspective. We also study the influence of agent heterogeneity under different cognitive ability distributions.},
  archive      = {J_CIS},
  author       = {Bao, Honglin and Neal, Zachary P and Banzhaf, Wolfgang},
  doi          = {10.1007/s40747-022-00810-w},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {565-577},
  shortjournal = {Complex Intell. Syst.},
  title        = {Coevolutionary opinion dynamics with sparse interactions in open-ended societies},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Aspect term extraction via information-augmented neural
network. <em>CIS</em>, <em>9</em>(1), 537–563. (<a
href="https://doi.org/10.1007/s40747-022-00818-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect term extraction (ATE) aims at identifying the aspect terms that are expressed in a sentence. Recently, Seq2Seq learning has been employed in ATE and significantly improved performance. However, it suffers from some weaknesses, such as lacking the ability to encode the more informative information and integrate information of surrounding words in the encoder. The static word embeddings employed in ATE fall short of modeling the dynamic meaning of words. To alleviate the problems mentioned above, this paper proposes the information-augmented neural network (IANN) which is a novel Seq2Seq learning framework. In IANN, a specialized neural network is developed as the key module of the encoder, named multiple convolution with recurrence network (MCRN), to encode the more informative information and integrate information of surrounding words in the encoder. The contextualized embedding layer is designed to capture the dynamic word sense. Besides, the novel AO ({Aspect, Outside}) tags are proposed as the less challenging tagging scheme. A lot of experiments have been performed on three widely used datasets. These experiments demonstrate that the proposed IANN acquires state-of-the-art results and validate that the proposed IANN is a powerful method for the ATE task.},
  archive      = {J_CIS},
  author       = {Liu, Ning and Shen, Bo},
  doi          = {10.1007/s40747-022-00818-2},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {537-563},
  shortjournal = {Complex Intell. Syst.},
  title        = {Aspect term extraction via information-augmented neural network},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Some t-conorm-based distance measures and knowledge measures
for pythagorean fuzzy sets with their application in decision-making.
<em>CIS</em>, <em>9</em>(1), 515–535. (<a
href="https://doi.org/10.1007/s40747-022-00804-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Pythagorean fuzzy sets are more robust than fuzzy sets and intuitionistic fuzzy sets in dealing with the problems involving uncertainty. To compare two Pythagorean fuzzy sets, distance measures play a crucial role. In this paper, we have proposed some novel distance measures for Pythagorean fuzzy sets using t-conorms. We have also discussed their various desirable properties. With the help of suggested distance measures, we have introduced some new knowledge measures for Pythagorean fuzzy sets. Through numerical comparison and linguistic hedges, we have established the effectiveness of the suggested distance measures and knowledge measures, respectively, over the existing measures in the Pythagorean fuzzy setting. At last, we have demonstrated the application of the suggested measures in pattern analysis and multi-attribute decision-making.},
  archive      = {J_CIS},
  author       = {Ganie, Abdul Haseeb},
  doi          = {10.1007/s40747-022-00804-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {515-535},
  shortjournal = {Complex Intell. Syst.},
  title        = {Some t-conorm-based distance measures and knowledge measures for pythagorean fuzzy sets with their application in decision-making},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid fuzzy AHP–TOPSIS approach to prioritizing solutions
for inverse reinforcement learning. <em>CIS</em>, <em>9</em>(1),
493–513. (<a href="https://doi.org/10.1007/s40747-022-00807-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) techniques nurture building up solutions for sequential decision-making problems under uncertainty and ambiguity. RL has agents with a reward function that interacts with a dynamic environment to find out an optimal policy. There are problems associated with RL like the reward function should be specified in advance, design difficulties and unable to handle large complex problems, etc. This led to the development of inverse reinforcement learning (IRL). IRL also suffers from many problems in real life like robust reward functions, ill-posed problems, etc., and different solutions have been proposed to solve these problems like maximum entropy, support for multiple rewards and non-linear reward functions, etc. There are majorly eight problems associated with IRL and eight solutions have been proposed to solve IRL problems. This paper has proposed a hybrid fuzzy AHP–TOPSIS approach to prioritize the solutions while implementing IRL. Fuzzy Analytical Hierarchical Process (FAHP) is used to get the weights of identified problems. The relative accuracy and root-mean-squared error using FAHP are 97.74 and 0.0349, respectively. Fuzzy Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) uses these FAHP weights to prioritize the solutions. The most significant problem in IRL implementation is of ‘lack of robust reward functions’ weighting 0.180, whereas the most significant solution in IRL implementation is ‘Supports optimal policy and rewards functions along with stochastic transition models’ having closeness of coefficient (CofC) value of 0.967156846.},
  archive      = {J_CIS},
  author       = {Kukreja, Vinay},
  doi          = {10.1007/s40747-022-00807-5},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {493-513},
  shortjournal = {Complex Intell. Syst.},
  title        = {Hybrid fuzzy AHP–TOPSIS approach to prioritizing solutions for inverse reinforcement learning},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An integrated distribution scheduling and route planning of
food cold chain with demand surge. <em>CIS</em>, <em>9</em>(1), 475–491.
(<a href="https://doi.org/10.1007/s40747-022-00811-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of e-commerce, customers could order online to ensure timeliness. Therefore, e-commerce enterprises need to pick and distribute customers’ orders. These two operations are interdependent. Order picking needs to consider the vehicle route planning. At the same time, the vehicle route planning is also based on the batching of orders. Considering the demand surge scenario of food cold chain, with the shortest time and lowest cost to complete all distribution tasks as the objective, this paper aims at the integrated optimization of distribution scheduling and route planning, and establishes a mixed integer programming mathematical model. Finally, we design a three-stage heuristic algorithm to solve this problem, and use the actual data to carry out numerical experiments to verify the reliability and effectiveness of the mathematical model and heuristic algorithm.},
  archive      = {J_CIS},
  author       = {Chen, Youhua and Lan, Hongjie and Wang, Chuan and Jia, Xiaoqiong},
  doi          = {10.1007/s40747-022-00811-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {475-491},
  shortjournal = {Complex Intell. Syst.},
  title        = {An integrated distribution scheduling and route planning of food cold chain with demand surge},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sentence part-enhanced BERT with respect to downstream
tasks. <em>CIS</em>, <em>9</em>(1), 463–474. (<a
href="https://doi.org/10.1007/s40747-022-00819-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bidirectional encoder representations from transformers (BERT) have achieved great success in many natural language processing tasks. However, BERT generally takes the embedding of the first token to represent sentence meaning in the tasks such as sentiment analysis and textual similarity, which does not properly treat different sentence parts. Different sentence parts have different levels of importance for different downstream tasks. For example, main parts (subject, predicate, and object) play crucial roles in textual similarity calculation, while secondary parts (adverbial and complement) are more important than the main parts in sentiment analysis. To this end, we propose a sentence part-enhanced BERT (SpeBERT) model that uses sentence parts with respect to downstream tasks to enhance sentence representations. Specifically, we encode sentence parts based on dependency parsing and downstream tasks, and extract embeddings through a pooling operation. Furthermore, we design several fusion strategies to incorporate different embeddings. We evaluate the proposed SpeBERT model on two downstream tasks, sentiment classification, and semantic textual similarity, with six benchmark datasets. The experimental results show that our model achieves better performance than competitor models.},
  archive      = {J_CIS},
  author       = {Liu, Chaoming and Zhu, Wenhao and Zhang, Xiaoyu and Zhai, Qiuhong},
  doi          = {10.1007/s40747-022-00819-1},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {463-474},
  shortjournal = {Complex Intell. Syst.},
  title        = {Sentence part-enhanced BERT with respect to downstream tasks},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-objective particle swarm optimization with density
and distribution-based competitive mechanism for sensor ontology
meta-matching. <em>CIS</em>, <em>9</em>(1), 435–462. (<a
href="https://doi.org/10.1007/s40747-022-00814-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensor ontology is a standard conceptual model that describes information of sensor device, which includes the concepts of various sensor modules and the relationships between them. The problem of heterogeneity between sensor ontologies is introduced because different sensor ontology engineers have different ways of describing sensor devices and different structures for the construction of sensor ontologies. Addressing the heterogeneity of sensor ontologies contributes to facilitate the semantic fusion of two sensor ontologies, enabling the sharing and reuse of sensor information. To solve the above problem, an ontology meta-matching method is proposed by this paper to find out the correspondence between entities in distinct sensor ontologies. How to measure the degree of similarity between entities with a set of suitable similarity measures and how to better integrate multiple measures to determine the equivalent entities are the challenges of the ontology meta-matching problem. In this paper, two approximate measurement methods of the quality for ontology matching results are designed, and a multi-objective optimization model for the ontology meta-matching problem is constructed based on these methods. Eventually, a multi-objective particle swarm optimization (MOPSO) algorithm is propounded to dispose of the problem and optimize the quality of ontology meta-matching results, which is named density and distribution-based competitive mechanism multi-objective particle swarm algorithm (D $$^{2}$$ CMOPSO). The sophistication of the D $$^{2}$$ CMOPSO based sensor ontology meta-matching method is verified through experiments. Comparing with other matching systems and advanced systems of Ontology Alignment Evaluation Initiative (OAEI), the proposed method can improve the quality of matching results more effectively.},
  archive      = {J_CIS},
  author       = {Geng, Aifeng and Lv, Qing},
  doi          = {10.1007/s40747-022-00814-6},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {435-462},
  shortjournal = {Complex Intell. Syst.},
  title        = {A multi-objective particle swarm optimization with density and distribution-based competitive mechanism for sensor ontology meta-matching},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A coin selection strategy based on the greedy and genetic
algorithm. <em>CIS</em>, <em>9</em>(1), 421–434. (<a
href="https://doi.org/10.1007/s40747-022-00799-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coin selection method refers to the process undergone when selecting a set of unspent transaction outputs (UTXOs) from a cryptocurrency wallet or account to use as inputs in each transaction. The most applied coin selection method that UTXO-based cryptocurrencies currently employ is an algorithm that decides on a certain set of UTXOs that matches the target amount and limits the transaction fee. However this approach trades off favourable maintenance overhead of the entire network for low transaction fees, as many low-value UTXOs known as “dust” is produced. Over time, this will impact the scalability and management of the cryptocurrency network as the global set of UTXOs become larger. Therefore, there is an urgency to find a higher-performing coin selection method suitable for UTXO-based cryptocurrencies. This paper proposes a method based on the greedy and genetic algorithm for effectively choosing sets of UTXOs in Bitcoin. The main objective of this coin selection strategy is to get as close as possible to the target while also maintaining and possibly reducing the number of UTXO inputs.},
  archive      = {J_CIS},
  author       = {Wei, Xuelin and Wu, Chang and Yu, Haoran and Liu, Siyan and Yuan, Yihong},
  doi          = {10.1007/s40747-022-00799-2},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {421-434},
  shortjournal = {Complex Intell. Syst.},
  title        = {A coin selection strategy based on the greedy and genetic algorithm},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Histone-net: A multi-paradigm computational framework for
histone occupancy and modification prediction. <em>CIS</em>,
<em>9</em>(1), 399–419. (<a
href="https://doi.org/10.1007/s40747-022-00802-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep exploration of histone occupancy and covalent post-translational modifications (e.g., acetylation, methylation) is essential to decode gene expression regulation, chromosome packaging, DNA damage, and transcriptional activation. Existing computational approaches are unable to precisely predict histone occupancy and modifications mainly due to the use of sub-optimal statistical representation of histone sequences. For the establishment of an improved histone occupancy and modification landscape for multiple histone markers, the paper in hand presents an end-to-end computational multi-paradigm framework “Histone-Net”. To learn local and global residue context aware sequence representation, Histone-Net generates unsupervised higher order residue embeddings (DNA2Vec) and presents a different application of language modelling, where it encapsulates histone occupancy and modification information while generating higher order residue embeddings (SuperDNA2Vec) in a supervised manner. We perform an intrinsic and extrinsic evaluation of both presented distributed representation learning schemes. A comprehensive empirical evaluation of Histone-Net over ten benchmark histone markers data sets for three different histone sequence analysis tasks indicates that SuperDNA2Vec sequence representation and softmax classifier-based approach outperforms state-of-the-art approach by an average accuracy of 7%. To eliminate the overhead of training separate binary classifiers for all ten histone markers, Histone-Net is evaluated in multi-label classification paradigm, where it produces decent performance for simultaneous prediction of histone occupancy, acetylation, and methylation.},
  archive      = {J_CIS},
  author       = {Asim, Muhammad Nabeel and Ibrahim, Muhammad Ali and Malik, Muhammad Imran and Razzak, Imran and Dengel, Andreas and Ahmed, Sheraz},
  doi          = {10.1007/s40747-022-00802-w},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {399-419},
  shortjournal = {Complex Intell. Syst.},
  title        = {Histone-net: A multi-paradigm computational framework for histone occupancy and modification prediction},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A baseline-reactive scheduling method for carrier-based
aircraft maintenance tasks. <em>CIS</em>, <em>9</em>(1), 367–397. (<a
href="https://doi.org/10.1007/s40747-022-00784-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carrier-based aircraft maintenance tasks are conducted in time-critical, resource-constrained, and uncertain environments. Optimizing the scheduling allocation scheme of maintenance personnel and equipment, reasonably responding to uncertainty disturbances, and maintaining a high fleet availability are vital to the combat and training missions of carrier-based aircraft. The maintenance task scheduling problem for carrier-based aircraft is investigated in this study. First, a mathematical model for comprehensive carrier-based aircraft maintenance task scheduling that considers constraints such as maintenance personnel, equipment/shop, space, and parallel capacity is developed. Second, to generate the baseline scheduling scheme, an improved non-dominated sorting genetic algorithm II (I_NSGA-II) with local neighborhood search is proposed for the model optimization solution; I_NSGA-II uses the serial scheduling generation scheme mechanism to generate the time sequence scheduling scheme for maintenance personnel and equipment/workshop of different fleet sizes. Third, to cope with dynamic uncertainty disturbances, two reactive scheduling methods, i.e., complete rescheduling and partial rescheduling, are proposed to perform reactive scheduling corrections to the baseline schedule. Case simulation shows that the established mathematical model is reasonable and practical, and that the proposed I_NSGA-II is superior to the current mainstream algorithms. In addition, the decision maker can select between the two reactive scheduling methods flexibly based on the different forms and scales of disturbance.},
  archive      = {J_CIS},
  author       = {Zhang, Yong and Li, Changjiu and Su, Xichao and Cui, Rongwei and Wan, Bing},
  doi          = {10.1007/s40747-022-00784-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {367-397},
  shortjournal = {Complex Intell. Syst.},
  title        = {A baseline-reactive scheduling method for carrier-based aircraft maintenance tasks},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A focused crawler based on semantic disambiguation vector
space model. <em>CIS</em>, <em>9</em>(1), 345–366. (<a
href="https://doi.org/10.1007/s40747-022-00707-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The focused crawler grabs continuously web pages related to the given topic according to priorities of unvisited hyperlinks. In many previous studies, the focused crawlers predict priorities of unvisited hyperlinks based on the text similarity models. However, the representation terms of the web page ignore the phenomenon of polysemy, and the topic similarity of the text cannot combine the cosine similarity and the semantic similarity effectively. To address these problems, this paper proposes a focused crawler based on semantic disambiguation vector space model (SDVSM). The SDVSM method combines the semantic disambiguation graph (SDG) and the semantic vector space model (SVSM). The SDG is used to remove the ambiguation terms irrelevant to the given topic from representation terms of retrieved web pages. The SVSM is used to calculate the topic similarity of the text by constructing text and topic semantic vectors based on TF × IDF weights of terms and semantic similarities between terms. The experiment results indicate that the SDVSM method can improve the performance of the focused crawler by comparing different evaluation indicators for four focused crawlers. In conclusion, the proposed method can make the focused crawler grab the higher quality and more quantity web pages related to the given topic from the Internet.},
  archive      = {J_CIS},
  author       = {Liu, Wenjun and He, Yu and Wu, Jing and Du, Yajun and Liu, Xing and Xi, Tiejun and Gan, Zurui and Jiang, Pengjun and Huang, Xiaoping},
  doi          = {10.1007/s40747-022-00707-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {345-366},
  shortjournal = {Complex Intell. Syst.},
  title        = {A focused crawler based on semantic disambiguation vector space model},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An MPA-based optimized grey bernoulli model for china’s
petroleum consumption forecasting. <em>CIS</em>, <em>9</em>(1), 329–343.
(<a href="https://doi.org/10.1007/s40747-022-00803-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The remarkable prediction of petroleum consumption is of significance for energy scheduling and economic development. Considering the uncertainty and volatility of petroleum system, this paper presents a nonlinear grey Bernoulli model with combined fractional accumulated generation operator to forecast China’s petroleum consumption and terminal consumption. The newly designed model introduces a combined fractional accumulated generation operator by incorporating the traditional fractional accumulation and conformable fractional accumulation; compared to the old accumulation, the newly optimized accumulation can enhance flexible ability to excavate the development patterns of time-series. In addition, to further improve the prediction performance of the new model, marine predation algorithm is applied to determine the optimal emerging coefficients such as fractional accumulation order. Furthermore, the proposed model is verified by a numerical example of coal consumption; and this newly established model is applied to predict China’s petroleum consumption and terminal consumption. Our tests suggest that the designed ONGBM(1,1,k,c) model outperforms the other benchmark models. Finally, we predict China’s petroleum consumption in the following years with the aid of the optimized model. According to the forecasts of this paper, some suggestions are provided for policy-makers in the relevant sectors.},
  archive      = {J_CIS},
  author       = {Wu, Wen-Ze and Hu, Zhiming and Qi, Qin and Zhang, Tao},
  doi          = {10.1007/s40747-022-00803-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {329-343},
  shortjournal = {Complex Intell. Syst.},
  title        = {An MPA-based optimized grey bernoulli model for china’s petroleum consumption forecasting},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multimodal medical image fusion with convolution sparse
representation and mutual information correlation in NSST domain.
<em>CIS</em>, <em>9</em>(1), 317–328. (<a
href="https://doi.org/10.1007/s40747-022-00792-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal medical image is an effective method to solve a series of clinical problems, such as clinical diagnosis and postoperative treatment. In this study, a medical image fusion method based on convolutional sparse representation (CSR) and mutual information correlation is proposed. In this method, the source image is decomposed into one high-frequency and one low-frequency sub-band by non-subsampled shearlet transform. For the high-frequency sub-band, CSR is used for high-frequency coefficient fusion. For the low-frequency sub-band, different fusion strategies are used for different regions by mutual information correlation analysis. Analysis of two kinds of medical image fusion problems, namely, CT–MRI and MRI–SPECT, reveals that the performance of this method is robust in terms of five common objective metrics. Compared with the other six advanced medical image fusion methods, the experimental results show that the proposed method achieves better results in subjective vision and objective evaluation metrics.},
  archive      = {J_CIS},
  author       = {Guo, Peng and Xie, Guoqi and Li, Renfa and Hu, Hui},
  doi          = {10.1007/s40747-022-00792-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {317-328},
  shortjournal = {Complex Intell. Syst.},
  title        = {Multimodal medical image fusion with convolution sparse representation and mutual information correlation in NSST domain},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SPCS: A spatial pyramid convolutional shuffle module for
YOLO to detect occluded object. <em>CIS</em>, <em>9</em>(1), 301–315.
(<a href="https://doi.org/10.1007/s40747-022-00786-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In crowded scenes, one of the most important issues is that heavily overlapped objects are hardly distinguished from each other since most of their pixels are shared and the visible pixels of the occluded objects, which are used to represent their features, are limited. In this paper, a spatial pyramid convolutional shuffle (SPCS) module is proposed to extract refined information from the limited visible pixels of the occluded objects and generate distinguishable representations for the heavily overlapped objects. We adopt four convolutional kernels with different sizes and dilation rates at each location in the pyramid features and adjacently recombine their fused outputs spatially using a pixel shuffle module. In this way, four distinguishable instance predictions corresponding different convolutional kernels can be produced for each location in the pyramid feature. In addition, multiple convolutional operations with different kernel sizes and dilation rates at the same location can generate refined information for the corresponding regions, which is helpful to extract features for the occluded objects from their limited visible pixels. Extensive experimental results demonstrate that SPCS module can effectively boost the performance in crowded human detection. YOLO detector with SPCS module achieves 94.11% AP, 41.75% MR, 97.75% Recall on CrowdHuman, 93.04% AP, and 98.45% Recall on WiderPerson, which are the best compared with previous state-of-the-art models.},
  archive      = {J_CIS},
  author       = {Li, Xiang and He, Miao and Liu, Yan and Luo, Haibo and Ju, Moran},
  doi          = {10.1007/s40747-022-00786-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {301-315},
  shortjournal = {Complex Intell. Syst.},
  title        = {SPCS: A spatial pyramid convolutional shuffle module for YOLO to detect occluded object},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A robust target tracking algorithm based on spatial
regularization and adaptive updating model. <em>CIS</em>, <em>9</em>(1),
285–299. (<a href="https://doi.org/10.1007/s40747-022-00800-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The correlation filtering-based target tracking method has impressive tracking performance and computational efficiency. Nevertheless, a few issues limit the accuracy of the correlation filter-based tracking methods including the object deformation, boundary effects, scale variations, and the target occlusion. This article proposes a robust target tracking algorithm to solve these issues. First, a feature fusion method is used to enhance feature response discrimination between the target and others. Second, a spatial weight function is introduced to penalize the magnitude of filter coefficients and an ADMM algorithm is employed to reduce the iteration of filter coefficients when tracking. Third, an adaptive scale filter is designed to make the algorithm adaptable to the scale variations. Finally, the correlation peak average difference ratio is applied to realize the adaptive updating and improve the stability. The experiment’s result demonstrates the proposed algorithm improved tracking results compared to the state-of-the-art correlation filtering-based target tracking method.},
  archive      = {J_CIS},
  author       = {Chen, Kansong and Guo, Xiang and Xu, Lijun and Zhou, Tian and Li, Ran},
  doi          = {10.1007/s40747-022-00800-y},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {285-299},
  shortjournal = {Complex Intell. Syst.},
  title        = {A robust target tracking algorithm based on spatial regularization and adaptive updating model},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A distributed gradient algorithm based on randomized
block-coordinate and projection-free over networks. <em>CIS</em>,
<em>9</em>(1), 267–283. (<a
href="https://doi.org/10.1007/s40747-022-00785-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computational bottleneck in distributed optimization methods, which is based on projected gradient descent, is due to the computation of a full gradient vector and projection step. This is a particular problem for large datasets. To reduce the computational complexity of existing methods, we combine the randomized block-coordinate descent and the Frank–Wolfe techniques, and then propose a distributed randomized block-coordinate projection-free algorithm over networks, where each agent randomly chooses a subset of the coordinates of its gradient vector and the projection step is eschewed in favor of a much simpler linear optimization step. Moreover, the convergence performance of the proposed algorithm is also theoretically analyzed. Specifically, we rigorously prove that the proposed algorithm can converge to optimal point at rate of $${\mathcal {O}}(1/t)$$ under convexity and $${\mathcal {O}}(1/t^2)$$ under strong convexity, respectively. Here, t is the number of iterations. Furthermore, the proposed algorithm can converge to a stationary point, where the “Frank-Wolfe” gap is equal to zero, at a rate $${\mathcal {O}}(1/\sqrt{t})$$ under non-convexity. To evaluate the computational benefit of the proposed algorithm, we use the proposed algorithm to solve the multiclass classification problems by simulation experiments on two datasets, i.e., aloi and news20. The results shows that the proposed algorithm is faster than the existing distributed optimization algorithms due to its lower computation per iteration. Furthermore, the results also show that well-connected graphs or smaller graphs leads to faster convergence rate, which can confirm the theoretical results.},
  archive      = {J_CIS},
  author       = {Zhu, Junlong and Wang, Xin and Zhang, Mingchuan and Liu, Muhua and Wu, Qingtao},
  doi          = {10.1007/s40747-022-00785-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {267-283},
  shortjournal = {Complex Intell. Syst.},
  title        = {A distributed gradient algorithm based on randomized block-coordinate and projection-free over networks},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An agent-based modeling framework for the design of a
dynamic closed-loop supply chain network. <em>CIS</em>, <em>9</em>(1),
247–265. (<a href="https://doi.org/10.1007/s40747-022-00780-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The supply chain is a dynamic and uncertain system consisting of material, information, and fund flows between different organizations, from the acquisition of the raw materials to the delivery of the finished products to the end customers. Closed-loop supply chains do not end with the delivery of the finished products to the end customers, the process continues until economic value is obtained from the returned products or they are disposed properly in landfills. Incorporating reverse flows in supply chains increases the uncertainty and complexity, as well as complicating the management of supply chains that are already composed of different actors and have a dynamic structure. Since agent-based modeling and simulation is a more efficient method of handling the dynamic and complex nature of supply chains than the traditional analytical methods, in this study agent-based modeling methodology has been used to model a generic closed-loop supply chain network design problem with the aims of integrating customer behavior into the network, coping with the dynamism, and obtaining a more realistic structure by eliminating the required assumptions for solving the model with analytical methods. The actors in the CLSC network have been defined as agents with goals, properties and behaviors. In the proposed model dynamic customer arrivals, the changing aspects of customers&#39; purchasing preferences for new and refurbished products and the time, quantity and quality uncertainties of returns have been handled via the proposed agent-based architecture. To observe the behavior of the supply chain in several conditions various scenarios have been developed according to different parameter settings for the supplier capacities, the rate of customers being affected by advertising, the market incentive threshold values, and the environmental awareness of customers. From the scenarios, it has been concluded that the system should be fed in the right amounts for the new and refurbished products to increase the effectiveness of factors such as advertising, incentives, and environmental awareness for achieving the desired sales amounts and cost targets.},
  archive      = {J_CIS},
  author       = {Bozdoğan, Ayşegül and Görkemli Aykut, Latife and Demirel, Neslihan},
  doi          = {10.1007/s40747-022-00780-z},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {247-265},
  shortjournal = {Complex Intell. Syst.},
  title        = {An agent-based modeling framework for the design of a dynamic closed-loop supply chain network},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved PSPNet-based water shoreline detection in complex
inland river scenarios. <em>CIS</em>, <em>9</em>(1), 233–245. (<a
href="https://doi.org/10.1007/s40747-022-00793-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The water shoreline is essential for unmanned surface vessels (USVs) to navigate autonomously. Many existing traditional water shoreline detections approaches not only fail to overcome the effects of water reflections, image inversions, and other factors but are also unsuitable for water shoreline detection in a variety of weather conditions and in complex inland river scenarios. Therefore, we propose a water shoreline detection approach based on an enhanced Pyramid Scene Parsing Network (PSPNet). We introduce a migration learning approach to the PSPNet feature backbone extraction network Resnet50 to improve training efficiency and add a Convolutional Block Attention Module (CBAM) attention mechanism module to improve the robustness of training. In addition, the pyramid pooling module adds the branch of the atrous convolution module. Finally, the waterfront segmentation map is processed by the Canny edge detection method, which detects the water shorelines. For the network&#39;s training and validation, we use the USVInland dataset, the world&#39;s first urban inland driverless dataset. The experimental results show that the segmentation accuracy MIou of this paper is 96.87% and Accuracy is 98.41, which are higher than some mainstream algorithms. It is capable of detecting water shorelines accurately in a variety of interior river situations.},
  archive      = {J_CIS},
  author       = {Yin, Yuheng and Guo, Yangang and Deng, Liwei and Chai, Borong},
  doi          = {10.1007/s40747-022-00793-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {233-245},
  shortjournal = {Complex Intell. Syst.},
  title        = {Improved PSPNet-based water shoreline detection in complex inland river scenarios},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Architecture entropy sampling-based evolutionary neural
architecture search and its application in osteoporosis diagnosis.
<em>CIS</em>, <em>9</em>(1), 213–231. (<a
href="https://doi.org/10.1007/s40747-022-00794-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, neural architecture search (NAS) has achieved unprecedented development because of its ability to automatically achieve high-performance neural networks in various tasks. Among these, the evolutionary neural architecture search (ENAS) has impressed the researchers due to the excellent heuristic exploration capability. However, the evolutionary algorithm-based NAS are prone to the loss of population diversity in the search process, causing that the structure of the surviving individuals is exceedingly similar, which will lead to premature convergence and fail to explore the search space comprehensively and effectively. To address this issue, we propose a novel indicator, named architecture entropy, which is used to measure the architecture diversity of population. Based on this indicator, an effective sampling strategy is proposed to select the candidate individuals with the potential to maintain the population diversity for environmental selection. In addition, an unified encoding scheme of topological structure and computing operation is designed to efficiently express the search space, and the corresponding population update strategies are suggested to promote the convergence. The experimental results on several image classification benchmark datasets CIFAR-10 and CIFAR-100 demonstrate the superiority of our proposed method over the state-of-the-art comparison ones. To further validate the effectiveness of our method in real applications, our proposed NAS method is applied in the identification of lumbar spine X-ray images for osteoporosis diagnosis, and can achieve a better performance than the commonly used methods. Our source codes are available at https://github.com/LabyrinthineLeo/AEMONAS.},
  archive      = {J_CIS},
  author       = {Chu, Jianjun and Yu, Xiaoshan and Yang, Shangshang and Qiu, Jianfeng and Wang, Qijun},
  doi          = {10.1007/s40747-022-00794-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {213-231},
  shortjournal = {Complex Intell. Syst.},
  title        = {Architecture entropy sampling-based evolutionary neural architecture search and its application in osteoporosis diagnosis},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel density deviation multi-peaks automatic clustering
algorithm. <em>CIS</em>, <em>9</em>(1), 177–211. (<a
href="https://doi.org/10.1007/s40747-022-00798-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The density peaks clustering (DPC) algorithm is a classical and widely used clustering method. However, the DPC algorithm requires manual selection of cluster centers, a single way of density calculation, and cannot effectively handle low-density points. To address the above issues, we propose a novel density deviation multi-peaks automatic clustering method (AmDPC) in this paper. Firstly, we propose a new local-density and use the deviation to measure the relationship between data points and the cut-off distance ( $$d_c$$ ). Secondly, we divide the density deviation into multiple density levels equally and extract the points with higher distances in each density level. Finally, for the multi-peak points with higher distances at low-density levels, we merge them according to the size difference of the density deviation. We finally achieve the overall automatic clustering by processing the low-density points. To verify the performance of the method, we test the synthetic dataset, the real-world dataset, and the Olivetti Face dataset, respectively. The simulation experimental results indicate that the AmDPC method can handle low-density points more effectively and has certain effectiveness and robustness.},
  archive      = {J_CIS},
  author       = {Zhou, Wei and Wang, Limin and Han, Xuming and Parmar, Milan and Li, Mingyang},
  doi          = {10.1007/s40747-022-00798-3},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {177-211},
  shortjournal = {Complex Intell. Syst.},
  title        = {A novel density deviation multi-peaks automatic clustering algorithm},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards a resource efficient and privacy-preserving
framework for campus-wide video analytics-based applications.
<em>CIS</em>, <em>9</em>(1), 161–176. (<a
href="https://doi.org/10.1007/s40747-022-00783-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video surveillance and analytics solutions based on Artificial Intelligence (AI) are increasingly being deployed across industries, including academia. There are a number of use-cases for campus-wide video analytics applications. Detecting events of interest in real-time and generating alerts is a core requirement for such applications, making them both network and compute intensive. Thus, the underlying framework needs to be resource optimized in terms of latency, compute and storage requirements for a multitude of video applications. Increasingly privacy concerns have been voiced against the pervasive deployment of video analytics-based applications. Thus, protecting the privacy of students and staff in a campus setting shall be a major design consideration for such systems going forward. This paper presents a resource optimized and privacy preserving framework for campus-wide video analytics applications. Several use-cases are presented and early results from the deployment of the proposed framework establish its feasibility and effectiveness.},
  archive      = {J_CIS},
  author       = {Gupta, Ankur and Prabhat, Purnendu},
  doi          = {10.1007/s40747-022-00783-w},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {161-176},
  shortjournal = {Complex Intell. Syst.},
  title        = {Towards a resource efficient and privacy-preserving framework for campus-wide video analytics-based applications},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual graph characteristics of water distribution
networks—how optimal are design solutions? <em>CIS</em>, <em>9</em>(1),
147–160. (<a href="https://doi.org/10.1007/s40747-022-00797-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban water infrastructures are an essential part of urban areas. For their construction and maintenance, major investments are required to ensure an efficient and reliable function. Vital parts of the urban water infrastructures are water distribution networks (WDNs), which transport water from the production (sources) to the spatially distributed consumers (sinks). To minimize the costs and at the same time maximize the resilience of such a system, multi-objective optimization procedures (e.g., meta-heuristic searches) are performed. Assessing the hydraulic behavior of WDNs in such an optimization procedure is no trivial task and is computationally demanding. Further, deciding how close to optimal design solutions the current solutions are, is difficult to assess and often results in an unnecessary extent of experiment. To tackle these challenges, an answer to the questions is sought: when is an optimization stage achieved from which no further improvements can be expected, and how can that be assessed? It was found that graph characteristics based on complex network theory (number of dual graph elements) converge towards a certain threshold with increasing number of generations. Furthermore, a novel method based on network topology and the demand distribution in WDNs, specifically based on changes in ‘demand edge betweenness centrality’, for identifying that threshold is developed and successfully tested. With the proposed novel approach, it is feasible, prior to the optimization, to determine characteristics that optimal design solutions should fulfill, and thereafter, test them during the optimization process. Therewith, numerous simulation runs of meta-heuristic search engines can be avoided.},
  archive      = {J_CIS},
  author       = {Sitzenfrei, Robert and Hajibabaei, Mohsen and Hesarkazzazi, Sina and Diao, Kegong},
  doi          = {10.1007/s40747-022-00797-4},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {147-160},
  shortjournal = {Complex Intell. Syst.},
  title        = {Dual graph characteristics of water distribution networks—how optimal are design solutions?},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vibration prediction and analysis of strip rolling mill
based on XGBoost and bayesian optimization. <em>CIS</em>, <em>9</em>(1),
133–145. (<a href="https://doi.org/10.1007/s40747-022-00795-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stable operation of strip rolling mill is the key factor to ensure the stability of product quality. The design capability of existing domestic imported and self-developed strip rolling mills cannot be fully developed, and the frequent occurrence of mill vibration and operation instability problems seriously restrict the equipment capacity and the production of high-end strip products. The vibration prediction analysis method for hot strip mill based on eXtreme gradient boosting (XGBoost) and Bayesian optimization (BO) is proposed. First, an XGBoost prediction model is developed based on a self-built data set to construct a complex functional relationship between process parameters and rolling mill vibration. Second, the important hyperparameters and parameters of XGBoost are optimized using Bayesian optimization algorithm to improve the prediction accuracy, computational efficiency, and stability of the model. Third, a comprehensive comparison is made between the prediction model in this paper and other well-known machine learning benchmark models. Finally, the prediction results of the model are interpreted using the SHapley Additive exPlanations (SHAP) method. The proposed model outperforms existing models in terms of prediction accuracy, computational speed and stability. At the same time, the degree of influence of each feature on rolling mill vibration is also obtained.},
  archive      = {J_CIS},
  author       = {Zhang, Yang and Lin, Ranmeng and Zhang, Huan and Peng, Yan},
  doi          = {10.1007/s40747-022-00795-6},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {133-145},
  shortjournal = {Complex Intell. Syst.},
  title        = {Vibration prediction and analysis of strip rolling mill based on XGBoost and bayesian optimization},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent depression detection with asynchronous federated
optimization. <em>CIS</em>, <em>9</em>(1), 115–131. (<a
href="https://doi.org/10.1007/s40747-022-00729-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growth of population and the various intensive life pressures everyday deepen the competitions among people. Tens of millions of people each year suffer from depression and only a fraction receives adequate treatment. The development of social networks such as Facebook, Twitter, Weibo, and QQ provides more convenient communication and provides a new emotional vent window. People communicate with their friends, sharing their opinions, and shooting videos to reflect their feelings. It provides an opportunity to detect depression in social networks. Although depression detection using social networks has reflected the established connectivity across users, fewer researchers consider the data security and privacy-preserving schemes. Therefore, we advocate the federated learning technique as an efficient and scalable method, where it enables the handling of a massive number of edge devices in parallel. In this study, we conduct the depression analysis on the basis of an online microblog called Weibo. A novel algorithm termed as CNN Asynchronous Federated optimization (CAFed) is proposed based on federated learning to improve the communication cost and convergence rate. It is shown that our proposed method can effectively protect users&#39; privacy under the premise of ensuring the accuracy of prediction. The proposed method converges faster than the Federated Averaging (FedAvg) for non-convex problems. Federated learning techniques can identify quality solutions of mental health problems among Weibo users.},
  archive      = {J_CIS},
  author       = {Li, Jinli and Jiang, Ming and Qin, Yunbai and Zhang, Ran and Ling, Sai Ho},
  doi          = {10.1007/s40747-022-00729-2},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {115-131},
  shortjournal = {Complex Intell. Syst.},
  title        = {Intelligent depression detection with asynchronous federated optimization},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). System dynamics model: Developing model for supplier
selection with a focus on CSR criteria. <em>CIS</em>, <em>9</em>(1),
99–114. (<a href="https://doi.org/10.1007/s40747-022-00788-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complexity and significance of decision-making in selecting suppliers highlight the need for a systematic and transparent approach. The more organizations rely on suppliers, the more harmful the direct and indirect consequences of poor decision-making are. This study attempted to identify factors affecting supplier selection and develop a system dynamics model for supplier selection by taking into account social corporate responsibility (CSR) practices. This model aims to increase CSR practices when selecting suppliers and thus help supply chain members gain competitive power and satisfy customer demands optimally. The system dynamics model for supplier selection was developed by considering profitability, productivity, social transparency, and customer satisfaction. To this end, first, the indicators affecting supplier selection were identified. Then, a cause–effect model was extracted by surveying subject-matter experts. Finally, the system dynamics model was developed. The final output of the third stage was a dynamic model of a supplier selection system that considers CSR practices. The results showed that profitability increases only by implementing the policy of reducing the average distance between suppliers and increasing the number of suppliers. This issue causes lower costs, reduced delivery time due to reduced average distance between suppliers, and increased suppliers, resulting in increased customer satisfaction and increased demand.},
  archive      = {J_CIS},
  author       = {Liu, Peide and Hendalianpour, Ayad and Hafshejani, Mitra Forouzandeh and Yaghoobi, Farideh and Feylizadeh, Mohammdreza},
  doi          = {10.1007/s40747-022-00788-5},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {99-114},
  shortjournal = {Complex Intell. Syst.},
  title        = {System dynamics model: Developing model for supplier selection with a focus on CSR criteria},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RST-net: A spatio-temporal residual network based on
region-reConStruction algorithm for shared bike prediction.
<em>CIS</em>, <em>9</em>(1), 81–97. (<a
href="https://doi.org/10.1007/s40747-022-00781-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a new form of public transportation, shared bikes have greatly facilitated people’s travel in recent years. However, in the actual operation process, the uneven distribution of bicycles at each shared bicycle station has limited the travel experience. In this paper, we propose a deep spatio-temporal residual network model based on Region-reConStruction algorithm to predict the usage of shared bikes in the bike-sharing system. We first propose an Region-reConStruction algorithm (RCS) to partition the shared bicycle sites within a city into separate areas based on their geographic location information as well as bikes’ migration trends between stations. We then combine the RCS algorithm with a deep spatio-temporal residual network to model the key factors affecting the usage of shared bicycles. RCS makes good use of the migration trend of shared bikes during user usage, thus greatly improving the accuracy of prediction. Experiments performed on New York’s bike-sharing system show that our model’s prediction accuracy is significantly better than that of previous models.},
  archive      = {J_CIS},
  author       = {Tan, Yanyan and Wang, Bin and Yan, Zeyuan and Liu, Haoran and Zhang, Huaxiang},
  doi          = {10.1007/s40747-022-00781-y},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {81-97},
  shortjournal = {Complex Intell. Syst.},
  title        = {RST-net: A spatio-temporal residual network based on region-reConStruction algorithm for shared bike prediction},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Imperceptible black-box waveform-level adversarial attack
towards automatic speaker recognition. <em>CIS</em>, <em>9</em>(1),
65–79. (<a href="https://doi.org/10.1007/s40747-022-00782-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic speaker recognition is an important biometric authentication approach with emerging applications. However, recent research has shown its vulnerability on adversarial attacks. In this paper, we propose a new type of adversarial examples by generating imperceptible adversarial samples for targeted attacks on black-box systems of automatic speaker recognition. Waveform samples are created directly by solving an optimization problem with waveform inputs and outputs, which is more realistic in real-life scenario. Inspired by auditory masking, a regularization term adapting to the energy of speech waveform is proposed for generating imperceptible adversarial perturbations. The optimization problems are subsequently solved by differential evolution algorithm in a black-box manner which does not require any knowledge on the inner configuration of the recognition systems. Experiments conducted on commonly used data sets, LibriSpeech and VoxCeleb, show that the proposed methods have successfully performed targeted attacks on state-of-the-art speaker recognition systems while being imperceptible to human listeners. Given the high SNR and PESQ scores of the yielded adversarial samples, the proposed methods deteriorate less on the quality of the original signals than several recently proposed methods, which justifies the imperceptibility of adversarial samples.},
  archive      = {J_CIS},
  author       = {Zhang, Xingyu and Zhang, Xiongwei and Sun, Meng and Zou, Xia and Chen, Kejiang and Yu, Nenghai},
  doi          = {10.1007/s40747-022-00782-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {65-79},
  shortjournal = {Complex Intell. Syst.},
  title        = {Imperceptible black-box waveform-level adversarial attack towards automatic speaker recognition},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interval-valued pythagorean fuzzy multi-criteria
decision-making method based on the set pair analysis theory and choquet
integral. <em>CIS</em>, <em>9</em>(1), 51–63. (<a
href="https://doi.org/10.1007/s40747-022-00778-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel fuzzy multi-criteria decision-making method based on an improved score function of connection numbers and Choquet integral under interval-valued Pythagorean fuzzy environment. To do so, we first introduce a method to convert interval-valued Pythagorean fuzzy numbers into connection numbers based on the set pair analysis theory. Then an improved score function of connection numbers is proposed to make the ranking order of connection numbers more in line with reality in multi-criteria decision-making process. In addition, some properties of the proposed score function of connection numbers and some examples have been given to illustrate the advantages of conversion method proposed in the paper. Then, considering interactions among different criteria, we propose a fuzzy multi-criteria decision-making approach based on set pair analysis and Choquet integral under interval-valued Pythagorean fuzzy environment. Finally, a case of online learning satisfaction survey and a brief comparative analysis with other existing approaches are studied to show that the proposed method is simple,convenient and easy to implement. Comparing with previous studies, the method in this paper, from a new perspective, effectively deals with multi-criteria decision-making problems that the alternatives cannot be reasonably ranked in the decision-making process under interval-valued Pythagorean fuzzy environment.},
  archive      = {J_CIS},
  author       = {Li, Feng and Xie, Jialiang and Lin, Mingwei},
  doi          = {10.1007/s40747-022-00778-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {51-63},
  shortjournal = {Complex Intell. Syst.},
  title        = {Interval-valued pythagorean fuzzy multi-criteria decision-making method based on the set pair analysis theory and choquet integral},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel feature relearning method for automatic sleep
staging based on single-channel EEG. <em>CIS</em>, <em>9</em>(1), 41–50.
(<a href="https://doi.org/10.1007/s40747-022-00779-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Correctly identifying sleep stages is essential for assessing sleep quality and treating sleep disorders. However, the current sleep staging methods have the following problems: (1) Manual or semi-automatic extraction of features requires professional knowledge, which is time-consuming and laborious. (2) Due to the similarity of stage features, it is necessary to strengthen the learning of features. (3) Acquisition of a variety of data has high requirements on equipment. Therefore, this paper proposes a novel feature relearning method for automatic sleep staging based on single-channel electroencephalography (EEG) to solve these three problems. Specifically, we design a bottom–up and top–down network and use the attention mechanism to learn EEG information fully. The cascading step with an imbalanced strategy is used to further improve the overall classification performance and realize automatic sleep classification. The experimental results on the public dataset Sleep-EDF show that the proposed method is advanced. The results show that the proposed method outperforms the state-of-the-art methods. The code and supplementary materials are available at GitHub: https://github.com/raintyj/A-novel-feature-relearning-method .},
  archive      = {J_CIS},
  author       = {Tao, Yujie and Yang, Yun and Yang, Po and Nan, Fengtao and Zhang, Yan and Rao, Yulong and Du, Fei},
  doi          = {10.1007/s40747-022-00779-6},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {41-50},
  shortjournal = {Complex Intell. Syst.},
  title        = {A novel feature relearning method for automatic sleep staging based on single-channel EEG},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AttenSy-SNER: Software knowledge entity extraction with
syntactic features and semantic augmentation information. <em>CIS</em>,
<em>9</em>(1), 25–39. (<a
href="https://doi.org/10.1007/s40747-022-00742-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software knowledge community contains a large scale of software knowledge entity information, complex structure and rich semantic correlations. It is significant to recognize and extract software knowledge entity from software knowledge community, as it has great impact on entity-centric tasks such as software knowledge graph construction, software document generation and expert recommendation. Since the texts of the software knowledge community are unstructured by user-generated texts, it is difficult to apply the traditional entity extraction method in the domain of the software knowledge community due to the problems of entity variation, entity sparsity, entity ambiguity, out-of-vocabulary (OOV) words and the lack of annotated data sets. This paper proposes a novel software knowledge entity extraction model, named AttenSy-SNER, which integrates syntactic features and semantic augmentation information, to extract fine-grained software knowledge entities from unstructured user-generated content. The input representation layer utilizes Bidirectional Encoder Representations from Transformers (BERT) model to extract the feature representation of the input sequence. The contextual coding layer leverages the Bidirectional Long Short-Term Memory (BiLSTM) network and Graph Convolutional Network (GCN) for contextual information and syntactic dependency information, and a semantic augmentation strategy based on attention mechanism is introduced to enrich the semantic feature representation of sequences as well. The tag decoding layer leverages Conditional Random Fields (CRF) to solve the dependency between the output tags and obtain the global optimal label sequence. The results of model comparison experiments show that the proposed model has better performance than the benchmark model in software engineering domain.},
  archive      = {J_CIS},
  author       = {Tang, Mingjing and Li, Tong and Gao, Wei and Xia, Yu},
  doi          = {10.1007/s40747-022-00742-5},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {25-39},
  shortjournal = {Complex Intell. Syst.},
  title        = {AttenSy-SNER: Software knowledge entity extraction with syntactic features and semantic augmentation information},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Developing sequentially trained robust punjabi speech
recognition system under matched and mismatched conditions.
<em>CIS</em>, <em>9</em>(1), 1–23. (<a
href="https://doi.org/10.1007/s40747-022-00651-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Development of a native language robust ASR framework is very challenging as well as an active area of research. Although an urge for investigation of effective front-end as well as back-end approaches are required for tackling environment differences, large training complexity and inter-speaker variability in achieving success of a recognition system. In this paper, four front-end approaches: mel-frequency cepstral coefficients (MFCC), Gammatone frequency cepstral coefficients (GFCC), relative spectral-perceptual linear prediction (RASTA-PLP) and power-normalized cepstral coefficients (PNCC) have been investigated to generate unique and robust feature vectors at different SNR values. Furthermore, to handle the large training data complexity, parameter optimization has been performed with sequence-discriminative training techniques: maximum mutual information (MMI), minimum phone error (MPE), boosted-MMI (bMMI), and state-level minimum Bayes risk (sMBR). It has been demonstrated by selection of an optimal value of parameters using lattice generation, and adjustments of learning rates. In proposed framework, four different systems have been tested by analyzing various feature extraction approaches (with or without speaker normalization through Vocal Tract Length Normalization (VTLN) approach in test set) and classification strategy on with or without artificial extension of train dataset. To compare each system performance, true matched (adult train and test—S1, child train and test—S2) and mismatched (adult train and child test—S3, adult + child train and child test—S4) systems on large adult and very small Punjabi clean speech corpus have been demonstrated. Consequently, gender-based in-domain data augmented is used to moderate acoustic and phonetic variations throughout adult and children’s speech under mismatched conditions. The experiment result shows that an effective framework developed on PNCC + VTLN front-end approach using TDNN-sMBR-based model through parameter optimization technique yields a relative improvement (RI) of 40.18%, 47.51%, and 49.87% in matched, mismatched and gender-based in-domain augmented system under typical clean and noisy conditions, respectively.},
  archive      = {J_CIS},
  author       = {Bawa, Puneet and Kadyan, Virender and Tripathy, Abinash and Singh, Thipendra P.},
  doi          = {10.1007/s40747-022-00651-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {2},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Complex Intell. Syst.},
  title        = {Developing sequentially trained robust punjabi speech recognition system under matched and mismatched conditions},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
