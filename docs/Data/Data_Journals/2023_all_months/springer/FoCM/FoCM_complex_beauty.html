<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>FoCM_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="focm---42">FoCM - 42</h2>
<ul>
<li><details>
<summary>
(2023b). Potentially singular behavior of the 3D navier–stokes
equations. <em>FoCM</em>, <em>23</em>(6), 2251–2299. (<a
href="https://doi.org/10.1007/s10208-022-09578-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whether the 3D incompressible Navier–Stokes equations can develop a finite time singularity from smooth initial data is one of the most challenging problems in nonlinear PDEs. In this paper, we present some new numerical evidence that the incompressible axisymmetric Navier–Stokes equations with smooth initial data of finite energy seem to develop potentially singular behavior at the origin. This potentially singular behavior is induced by a potential finite time singularity of the 3D Euler equations that we reported in a companion paper published in the same issue, see also Hou (Potential singularity of the 3D Euler equations in the interior domain. arXiv:2107.05870 [math.AP], 2021). We present numerical evidence that the 3D Navier–Stokes equations develop nearly self-similar singular scaling properties with maximum vorticity increased by a factor of $$10^7$$ . We have applied several blow-up criteria to study the potentially singular behavior of the Navier–Stokes equations. The Beale–Kato–Majda blow-up criterion and the blow-up criteria based on the growth of enstrophy and negative pressure seem to imply that the Navier–Stokes equations using our initial data develop a potential finite time singularity. We have also examined the Ladyzhenskaya–Prodi–Serrin regularity criteria (Kiselev and Ladyzhenskaya in Izv Akad Nauk SSSR Ser Mat 21(5):655–690, 1957; Prodi in Ann Math Pura Appl 4(48):173–182, 1959; Serrin in Arch Ration Mech Anal 9:187–191, 1962) that are based on the growth rate of $$L_t^q L_x^p$$ norm of the velocity with $$3/p + 2/q \le 1$$ . Our numerical results for the cases of $$(p,q) = (4,8),\; (6,4),\; (9,3)$$ and $$(p,q)=(\infty ,2)$$ provide strong evidence for the potentially singular behavior of the Navier–Stokes equations. The critical case of $$(p,q)=(3,\infty )$$ is more difficult to verify numerically due to the extremely slow growth rate in the $$L^3$$ norm of the velocity field and the significant contribution from the far field where we have a relatively coarse grid. Our numerical study shows that while the global $$L^3$$ norm of the velocity grows very slowly, the localized version of the $$L^3$$ norm of the velocity experiences rapid dynamic growth relative to the localized $$L^3$$ norm of the initial velocity. This provides further evidence for the potentially singular behavior of the Navier–Stokes equations.},
  archive      = {J_FoCM},
  author       = {Hou, Thomas Y.},
  doi          = {10.1007/s10208-022-09578-4},
  journal      = {Foundations of Computational Mathematics},
  number       = {6},
  pages        = {2251-2299},
  shortjournal = {Found. Comput. Math.},
  title        = {Potentially singular behavior of the 3D Navier–Stokes equations},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Potential singularity of the 3D euler equations in the
interior domain. <em>FoCM</em>, <em>23</em>(6), 2203–2249. (<a
href="https://doi.org/10.1007/s10208-022-09585-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whether the 3D incompressible Euler equations can develop a finite time singularity from smooth initial data is one of the most challenging problems in nonlinear PDEs. In this paper, we present some new numerical evidence that the 3D axisymmetric incompressible Euler equations with smooth initial data of finite energy develop a potential finite time singularity at the origin. This potential singularity is different from the blow-up scenario revealed by Luo and Hou (111:12968–12973, 2014) and (12:1722–1776, 2014), which occurs on the boundary. Our initial condition has a simple form and shares several attractive features of a more sophisticated initial condition constructed by Hou and Huang in ( arXiv:2102.06663 , 2021) and (435:133257, 2022). One important difference between these two blow-up scenarios is that the solution for our initial data has a one-scale structure instead of a two-scale structure reported in Hou and Huang ( arXiv:2102.06663 , 2021) and (435:133257, 2022). More importantly, the solution seems to develop nearly self-similar scaling properties that are compatible with those of the 3D Navier–Stokes equations. We will present numerical evidence that the 3D Euler equations seem to develop a potential finite time singularity. Moreover, the nearly self-similar profile seems to be very stable to the small perturbation of the initial data.},
  archive      = {J_FoCM},
  author       = {Hou, Thomas Y.},
  doi          = {10.1007/s10208-022-09585-5},
  journal      = {Foundations of Computational Mathematics},
  number       = {6},
  pages        = {2203-2249},
  shortjournal = {Found. Comput. Math.},
  title        = {Potential singularity of the 3D euler equations in the interior domain},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Families of polytopes with rational linear precision in
higher dimensions. <em>FoCM</em>, <em>23</em>(6), 2151–2202. (<a
href="https://doi.org/10.1007/s10208-022-09583-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we introduce a new family of lattice polytopes with rational linear precision. For this purpose, we define a new class of discrete statistical models that we call multinomial staged tree models. We prove that these models have rational maximum likelihood estimators (MLE) and give a criterion for these models to be log-linear. Our main result is then obtained by applying Garcia-Puente and Sottile’s theorem that establishes a correspondence between polytopes with rational linear precision and log-linear models with rational MLE. Throughout this article, we also study the interplay between the primitive collections of the normal fan of a polytope with rational linear precision and the shape of the Horn matrix of its corresponding statistical model. Finally, we investigate lattice polytopes arising from toric multinomial staged tree models, in terms of the combinatorics of their tree representations.},
  archive      = {J_FoCM},
  author       = {Davies, Isobel and Duarte, Eliana and Portakal, Irem and Sorea, Miruna-Ştefana},
  doi          = {10.1007/s10208-022-09583-7},
  journal      = {Foundations of Computational Mathematics},
  number       = {6},
  pages        = {2151-2202},
  shortjournal = {Found. Comput. Math.},
  title        = {Families of polytopes with rational linear precision in higher dimensions},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sampling rates for <span
class="math display"><em>ℓ</em><sup>1</sup></span> -synthesis.
<em>FoCM</em>, <em>23</em>(6), 2089–2150. (<a
href="https://doi.org/10.1007/s10208-022-09580-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work investigates the problem of signal recovery from undersampled noisy sub-Gaussian measurements under the assumption of a synthesis-based sparsity model. Solving the $$\ell ^1$$ -synthesis basis pursuit allows for a simultaneous estimation of a coefficient representation as well as the sought-for signal. However, due to linear dependencies within redundant dictionary atoms, it might be impossible to identify a specific representation vector, although the actual signal is still successfully recovered. The present manuscript studies both estimation problems from a non-uniform, signal-dependent perspective. By utilizing recent results on the convex geometry of linear inverse problems, the sampling rates describing the phase transitions of each formulation are identified. In both cases, they are given by the conic Gaussian mean width of an $$\ell ^1$$ -descent cone that is linearly transformed by the dictionary. In general, this expression does not allow for a simple calculation by following the polarity-based approach commonly found in the literature. Hence, two upper bounds involving the sparsity structure of coefficient representations are provided: The first one is based on a local condition number and the second one on a geometric analysis that makes use of the thinness of high-dimensional polyhedral cones with not too many generators. It is furthermore revealed that both recovery problems can differ dramatically with respect to robustness to measurement noise—a fact that seems to have gone unnoticed in most of the related literature. All insights are carefully validated through numerical simulations.},
  archive      = {J_FoCM},
  author       = {März, Maximilian and Boyer, Claire and Kahn, Jonas and Weiss, Pierre},
  doi          = {10.1007/s10208-022-09580-w},
  journal      = {Foundations of Computational Mathematics},
  number       = {6},
  pages        = {2089-2150},
  shortjournal = {Found. Comput. Math.},
  title        = {Sampling rates for $$\ell ^1$$ -synthesis},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bad and good news for strassen’s laser method: Border rank
of <span class="math display">Perm<sub>3</sub></span> and strict
submultiplicativity. <em>FoCM</em>, <em>23</em>(6), 2049–2087. (<a
href="https://doi.org/10.1007/s10208-022-09579-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We determine the border ranks of tensors that could potentially advance the known upper bound for the exponent $$\omega $$ of matrix multiplication. The Kronecker square of the small $$q=2$$ Coppersmith–Winograd tensor equals the $$3\times 3$$ permanent, and could potentially be used to show $$\omega =2$$ . We prove the negative result for complexity theory that its border rank is 16, resolving a longstanding problem. Regarding its $$q=4$$ skew cousin in $${\mathbb {C}}^5{\mathord { \otimes } }{\mathbb {C}}^5{\mathord { \otimes } }{\mathbb {C}}^5$$ , which could potentially be used to prove $$\le 2.11$$ , we show the border rank of its Kronecker square is at most 42, a remarkable sub-multiplicativity result, as the square of its border rank is 64. We also determine moduli spaces VSP for the small Coppersmith–Winograd tensors.},
  archive      = {J_FoCM},
  author       = {Conner, Austin and Huang, Hang and Landsberg, J. M.},
  doi          = {10.1007/s10208-022-09579-3},
  journal      = {Foundations of Computational Mathematics},
  number       = {6},
  pages        = {2049-2087},
  shortjournal = {Found. Comput. Math.},
  title        = {Bad and good news for strassen’s laser method: Border rank of $$\mathrm{Perm}_3$$ and strict submultiplicativity},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pseudospectral shattering, the sign function, and
diagonalization in nearly matrix multiplication time. <em>FoCM</em>,
<em>23</em>(6), 1959–2047. (<a
href="https://doi.org/10.1007/s10208-022-09577-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We exhibit a randomized algorithm which, given a square matrix $$A\in \mathbb {C}^{n\times n}$$ with $$\Vert A\Vert \le 1$$ and $$\delta &gt;0$$ , computes with high probability an invertible V and diagonal D such that $$ \Vert A-VDV^{-1}\Vert \le \delta $$ using $$O(T_\mathsf {MM}(n)\log ^2(n/\delta ))$$ arithmetic operations, in finite arithmetic with $$O(\log ^4(n/\delta )\log n)$$ bits of precision. The computed similarity V additionally satisfies $$\Vert V\Vert \Vert V^{-1}\Vert \le O(n^{2.5}/\delta )$$ . Here $$T_\mathsf {MM}(n)$$ is the number of arithmetic operations required to multiply two $$n\times n$$ complex matrices numerically stably, known to satisfy $$T_\mathsf {MM}(n)=O(n^{\omega +\eta })$$ for every $$\eta &gt;0$$ where $$\omega $$ is the exponent of matrix multiplication (Demmel et al. in Numer Math 108(1):59–91, 2007). The algorithm is a variant of the spectral bisection algorithm in numerical linear algebra (Beavers Jr. and Denman in Numer Math 21(1-2):143–169, 1974) with a crucial Gaussian perturbation preprocessing step. Our result significantly improves the previously best-known provable running times of $$O(n^{10}/\delta ^2)$$ arithmetic operations for diagonalization of general matrices (Armentano et al. in J Eur Math Soc 20(6):1375–1437, 2018) and (with regard to the dependence on n) $$O(n^3)$$ arithmetic operations for Hermitian matrices (Dekker and Traub in Linear Algebra Appl 4:137–154, 1971). It is the first algorithm to achieve nearly matrix multiplication time for diagonalization in any model of computation (real arithmetic, rational arithmetic, or finite arithmetic), thereby matching the complexity of other dense linear algebra operations such as inversion and QR factorization up to polylogarithmic factors. The proof rests on two new ingredients. (1) We show that adding a small complex Gaussian perturbation to any matrix splits its pseudospectrum into n small well-separated components. In particular, this implies that the eigenvalues of the perturbed matrix have a large minimum gap, a property of independent interest in random matrix theory. (2) We give a rigorous analysis of Roberts’ Newton iteration method (Roberts in Int J Control 32(4):677–687, 1980) for computing the sign function of a matrix in finite arithmetic, itself an open problem in numerical analysis since at least 1986.},
  archive      = {J_FoCM},
  author       = {Banks, Jess and Garza-Vargas, Jorge and Kulkarni, Archit and Srivastava, Nikhil},
  doi          = {10.1007/s10208-022-09577-5},
  journal      = {Foundations of Computational Mathematics},
  number       = {6},
  pages        = {1959-2047},
  shortjournal = {Found. Comput. Math.},
  title        = {Pseudospectral shattering, the sign function, and diagonalization in nearly matrix multiplication time},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Kähler geometry of framed quiver moduli and machine
learning. <em>FoCM</em>, <em>23</em>(5), 1899–1957. (<a
href="https://doi.org/10.1007/s10208-022-09587-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop an algebro-geometric formulation for neural networks in machine learning using the moduli space of framed quiver representations. We find natural Hermitian metrics on the universal bundles over the moduli whose expressions are independent of dimension vector, and show that their Ricci curvatures give a Kähler metric on the moduli. Moreover, we use toric moment maps to construct activation functions and prove the universal approximation theorem for the softmax function (also known as Boltzmann distribution) using toric geometry of the complex projective space.},
  archive      = {J_FoCM},
  author       = {Jeffreys, George and Lau, Siu-Cheong},
  doi          = {10.1007/s10208-022-09587-3},
  journal      = {Foundations of Computational Mathematics},
  number       = {5},
  pages        = {1899-1957},
  shortjournal = {Found. Comput. Math.},
  title        = {Kähler geometry of framed quiver moduli and machine learning},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sparse multi-reference alignment: Phase retrieval, uniform
uncertainty principles and the beltway problem. <em>FoCM</em>,
<em>23</em>(5), 1851–1898. (<a
href="https://doi.org/10.1007/s10208-022-09584-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by cutting-edge applications like cryo-electron microscopy (cryo-EM), the Multi-Reference Alignment (MRA) model entails the learning of an unknown signal from repeated measurements of its images under the latent action of a group of isometries and additive noise of magnitude $$\sigma $$ . Despite significant interest, a clear picture for understanding rates of estimation in this model has emerged only recently, particularly in the high-noise regime $$\sigma \gg 1$$ that is highly relevant in applications. Recent investigations have revealed a remarkable asymptotic sample complexity of order $$\sigma ^6$$ for certain signals whose Fourier transforms have full support, in stark contrast to the traditional $$\sigma ^2$$ that arise in regular models. Often prohibitively large in practice, these results have prompted the investigation of variations around the MRA model where better sample complexity may be achieved. In this paper, we show that sparse signals exhibit an intermediate $$\sigma ^4$$ sample complexity even in the classical MRA model. Further, we characterize the dependence of the estimation rate on the support size s as $$O_p(1)$$ and $$O_p(s^{3.5})$$ in the dilute and moderate regimes of sparsity respectively. Our techniques have implications for the problem of crystallographic phase retrieval, indicating a certain local uniqueness for the recovery of sparse signals from their power spectrum. Our results explore and exploit connections of the MRA estimation problem with two classical topics in applied mathematics: the beltway problem from combinatorial optimization, and uniform uncertainty principles from harmonic analysis. Our techniques include a certain enhanced form of the probabilistic method, which might be of general interest in its own right.},
  archive      = {J_FoCM},
  author       = {Ghosh, Subhroshekhar and Rigollet, Philippe},
  doi          = {10.1007/s10208-022-09584-6},
  journal      = {Foundations of Computational Mathematics},
  number       = {5},
  pages        = {1851-1898},
  shortjournal = {Found. Comput. Math.},
  title        = {Sparse multi-reference alignment: Phase retrieval, uniform uncertainty principles and the beltway problem},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rational homotopy type and computability. <em>FoCM</em>,
<em>23</em>(5), 1817–1849. (<a
href="https://doi.org/10.1007/s10208-022-09582-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a simplicial pair (X, A), a simplicial complex Y, and a map $$f:A \rightarrow Y$$ , does f have an extension to X? We show that for a fixed Y, this question is algorithmically decidable for all X, A, and f if Y has the rational homotopy type of an H-space. As a corollary, many questions related to bundle structures over a finite complex are likely decidable. Conversely, for all other Y, the question is at least as hard as certain special cases of Hilbert’s tenth problem which are known or suspected to be undecidable.},
  archive      = {J_FoCM},
  author       = {Manin, Fedor},
  doi          = {10.1007/s10208-022-09582-8},
  journal      = {Foundations of Computational Mathematics},
  number       = {5},
  pages        = {1817-1849},
  shortjournal = {Found. Comput. Math.},
  title        = {Rational homotopy type and computability},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Causal structure learning: A combinatorial perspective.
<em>FoCM</em>, <em>23</em>(5), 1781–1815. (<a
href="https://doi.org/10.1007/s10208-022-09581-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this review, we discuss approaches for learning causal structure from data, also called causal discovery. In particular, we focus on approaches for learning directed acyclic graphs and various generalizations which allow for some variables to be unobserved in the available data. We devote special attention to two fundamental combinatorial aspects of causal structure learning. First, we discuss the structure of the search space over causal graphs. Second, we discuss the structure of equivalence classes over causal graphs, i.e., sets of graphs which represent what can be learned from observational data alone, and how these equivalence classes can be refined by adding interventional data.},
  archive      = {J_FoCM},
  author       = {Squires, Chandler and Uhler, Caroline},
  doi          = {10.1007/s10208-022-09581-9},
  journal      = {Foundations of Computational Mathematics},
  number       = {5},
  pages        = {1781-1815},
  shortjournal = {Found. Comput. Math.},
  title        = {Causal structure learning: A combinatorial perspective},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Conormal spaces and whitney stratifications. <em>FoCM</em>,
<em>23</em>(5), 1745–1780. (<a
href="https://doi.org/10.1007/s10208-022-09574-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe a new algorithm for computing Whitney stratifications of complex projective varieties. The main ingredients are (a) an algebraic criterion, due to Lê and Teissier, which reformulates Whitney regularity in terms of conormal spaces and maps, and (b) a new interpretation of this conormal criterion via ideal saturations, which can be practically implemented on a computer. We show that this algorithm improves upon the existing state of the art by several orders of magnitude, even for relatively small input varieties. En route, we introduce related algorithms for efficiently stratifying affine varieties, flags on a given variety, and algebraic maps.},
  archive      = {J_FoCM},
  author       = {Helmer, Martin and Nanda, Vidit},
  doi          = {10.1007/s10208-022-09574-8},
  journal      = {Foundations of Computational Mathematics},
  number       = {5},
  pages        = {1745-1780},
  shortjournal = {Found. Comput. Math.},
  title        = {Conormal spaces and whitney stratifications},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detection thresholds in very sparse matrix completion.
<em>FoCM</em>, <em>23</em>(5), 1619–1743. (<a
href="https://doi.org/10.1007/s10208-022-09568-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the matrix completion problem: an underlying $$m \times n$$ matrix P is low rank, with incoherent singular vectors, and a random $$m \times n$$ matrix A is equal to P on a (uniformly) random subset of entries of size dn. All other entries of A are equal to zero. The goal is to retrieve information on P from the observation of A. Let $$A_1$$ be the random matrix where each entry of A is multiplied by an independent $${0,1}$$ -Bernoulli random variable with parameter 1/2. This paper is about when, how and why the non-Hermitian eigen-spectra of the matrices $$A_1 (A - A_1)^*$$ and $$(A-A_1)^*A_1$$ captures more of the relevant information about the principal component structure of A than the eigen-spectra of $$A A^*$$ and $$A^* A$$ . We show that the eigenvalues of the asymmetric matrices $$A_{1} (A - A_{1})^{*}$$ and $$(A-A_{1})^{*} A_{1}$$ with modulus greater than a detection threshold are asymptotically equal to the eigenvalues of $$PP^*$$ and $$P^*P$$ and that the associated eigenvectors are aligned as well. The central surprise is that by intentionally inducing asymmetry and additional randomness via the $$A_1$$ matrix, we can extract more information than if we had worked with the singular value decomposition (SVD) of A. The associated detection threshold is asymptotically exact and is non-universal since it explicitly depends on the element-wise distribution of the underlying matrix P. We show that reliable, statistically optimal but not perfect matrix recovery, via a universal data-driven algorithm, is possible above this detection threshold using the information extracted from the asymmetric eigen-decompositions. Averaging the left and right eigenvectors provably improves estimation accuracy but not the detection threshold. Our results encompass the very sparse regime where d is of order 1 where matrix completion via the SVD of A fails or produces unreliable recovery. We define another variant of this asymmetric principal component analysis procedure that bypasses the randomization step and has a detection threshold that is smaller by a constant factor but with a computational cost that is larger by a polynomial factor of the number of observed entries. Both detection thresholds allow to go beyond the barrier due to the well-known information theoretical limit $$d \asymp \log n$$ for exact matrix completion found in the literature.},
  archive      = {J_FoCM},
  author       = {Bordenave, Charles and Coste, Simon and Nadakuditi, Raj Rao},
  doi          = {10.1007/s10208-022-09568-6},
  journal      = {Foundations of Computational Mathematics},
  number       = {5},
  pages        = {1619-1743},
  shortjournal = {Found. Comput. Math.},
  title        = {Detection thresholds in very sparse matrix completion},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Spectral graph matching and regularized quadratic
relaxations II. <em>FoCM</em>, <em>23</em>(5), 1567–1617. (<a
href="https://doi.org/10.1007/s10208-022-09575-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze a new spectral graph matching algorithm, GRAph Matching by Pairwise eigen-Alignments (GRAMPA), for recovering the latent vertex correspondence between two unlabeled, edge-correlated weighted graphs. Extending the exact recovery guarantees established in a companion paper for Gaussian weights, in this work, we prove the universality of these guarantees for a general correlated Wigner model. In particular, for two Erdős-Rényi graphs with edge correlation coefficient $$1-\sigma ^2$$ and average degree at least $${\text {polylog}}(n)$$ , we show that GRAMPA exactly recovers the latent vertex correspondence with high probability when $$\sigma \lesssim 1/{\text {polylog}}(n)$$ . Moreover, we establish a similar guarantee for a variant of GRAMPA, corresponding to a tighter quadratic programming relaxation of the quadratic assignment problem. Our analysis exploits a resolvent representation of the GRAMPA similarity matrix and local laws for the resolvents of sparse Wigner matrices.},
  archive      = {J_FoCM},
  author       = {Fan, Zhou and Mao, Cheng and Wu, Yihong and Xu, Jiaming},
  doi          = {10.1007/s10208-022-09575-7},
  journal      = {Foundations of Computational Mathematics},
  number       = {5},
  pages        = {1567-1617},
  shortjournal = {Found. Comput. Math.},
  title        = {Spectral graph matching and regularized quadratic relaxations II},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Spectral graph matching and regularized quadratic
relaxations i algorithm and gaussian analysis. <em>FoCM</em>,
<em>23</em>(5), 1511–1565. (<a
href="https://doi.org/10.1007/s10208-022-09570-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph matching aims at finding the vertex correspondence between two unlabeled graphs that maximizes the total edge weight correlation. This amounts to solving a computationally intractable quadratic assignment problem. In this paper, we propose a new spectral method, graph matching by pairwise eigen-alignments (GRAMPA). Departing from prior spectral approaches that only compare top eigenvectors, or eigenvectors of the same order, GRAMPA first constructs a similarity matrix as a weighted sum of outer products between all pairs of eigenvectors of the two graphs, with weights given by a Cauchy kernel applied to the separation of the corresponding eigenvalues, then outputs a matching by a simple rounding procedure. The similarity matrix can also be interpreted as the solution to a regularized quadratic programming relaxation of the quadratic assignment problem. For the Gaussian Wigner model in which two complete graphs on n vertices have Gaussian edge weights with correlation coefficient $$1-\sigma ^2$$ , we show that GRAMPA exactly recovers the correct vertex correspondence with high probability when $$\sigma = O(\frac{1}{\log n})$$ . This matches the state of the art of polynomial-time algorithms and significantly improves over existing spectral methods which require $$\sigma $$ to be polynomially small in n. The superiority of GRAMPA is also demonstrated on a variety of synthetic and real datasets, in terms of both statistical accuracy and computational efficiency. Universality results, including similar guarantees for dense and sparse Erdős–Rényi graphs, are deferred to a companion paper.},
  archive      = {J_FoCM},
  author       = {Fan, Zhou and Mao, Cheng and Wu, Yihong and Xu, Jiaming},
  doi          = {10.1007/s10208-022-09570-y},
  journal      = {Foundations of Computational Mathematics},
  number       = {5},
  pages        = {1511-1565},
  shortjournal = {Found. Comput. Math.},
  title        = {Spectral graph matching and regularized quadratic relaxations i algorithm and gaussian analysis},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An accelerated first-order method for non-convex
optimization on manifolds. <em>FoCM</em>, <em>23</em>(4), 1433–1509. (<a
href="https://doi.org/10.1007/s10208-022-09573-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe the first gradient methods on Riemannian manifolds to achieve accelerated rates in the non-convex case. Under Lipschitz assumptions on the Riemannian gradient and Hessian of the cost function, these methods find approximate first-order critical points faster than regular gradient descent. A randomized version also finds approximate second-order critical points. Both the algorithms and their analyses build extensively on existing work in the Euclidean case. The basic operation consists in running the Euclidean accelerated gradient descent method (appropriately safe-guarded against non-convexity) in the current tangent space, then moving back to the manifold and repeating. This requires lifting the cost function from the manifold to the tangent space, which can be done for example through the Riemannian exponential map. For this approach to succeed, the lifted cost function (called the pullback) must retain certain Lipschitz properties. As a contribution of independent interest, we prove precise claims to that effect, with explicit constants. Those claims are affected by the Riemannian curvature of the manifold, which in turn affects the worst-case complexity bounds for our optimization algorithms.},
  archive      = {J_FoCM},
  author       = {Criscitiello, Christopher and Boumal, Nicolas},
  doi          = {10.1007/s10208-022-09573-9},
  journal      = {Foundations of Computational Mathematics},
  number       = {4},
  pages        = {1433-1509},
  shortjournal = {Found. Comput. Math.},
  title        = {An accelerated first-order method for non-convex optimization on manifolds},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On numerical approximations of fractional and nonlocal mean
field games. <em>FoCM</em>, <em>23</em>(4), 1381–1431. (<a
href="https://doi.org/10.1007/s10208-022-09572-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We construct numerical approximations for Mean Field Games with fractional or nonlocal diffusions. The schemes are based on semi-Lagrangian approximations of the underlying control problems/games along with dual approximations of the distributions of agents. The methods are monotone, stable, and consistent, and we prove convergence along subsequences for (i) degenerate equations in one space dimension and (ii) nondegenerate equations in arbitrary dimensions. We also give results on full convergence and convergence to classical solutions. Numerical tests are implemented for a range of different nonlocal diffusions and support our analytical findings.},
  archive      = {J_FoCM},
  author       = {Chowdhury, Indranil and Ersland, Olav and Jakobsen, Espen R.},
  doi          = {10.1007/s10208-022-09572-w},
  journal      = {Foundations of Computational Mathematics},
  number       = {4},
  pages        = {1381-1431},
  shortjournal = {Found. Comput. Math.},
  title        = {On numerical approximations of fractional and nonlocal mean field games},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction maps: A seed of geometric integrators.
<em>FoCM</em>, <em>23</em>(4), 1335–1380. (<a
href="https://doi.org/10.1007/s10208-022-09571-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classical notion of retraction map used to approximate geodesics is extended and rigorously defined to become a powerful tool to construct geometric integrators and it is called discretization map. Using the geometry of the tangent and cotangent bundles, we are able to tangently and cotangent lift such a map so that these lifts inherit the same properties as the original one and they continue to be discretization maps. In particular, the cotangent lift of a discretization map is a natural symplectomorphism, what plays a key role for constructing geometric integrators and symplectic methods. As a result, a wide range of (higher-order) numerical methods are recovered and canonically constructed by using different discretization maps, as well as some operations with Lagrangian submanifolds.},
  archive      = {J_FoCM},
  author       = {Barbero-Liñán, María and de Diego, David Martín},
  doi          = {10.1007/s10208-022-09571-x},
  journal      = {Foundations of Computational Mathematics},
  number       = {4},
  pages        = {1335-1380},
  shortjournal = {Found. Comput. Math.},
  title        = {Retraction maps: A seed of geometric integrators},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The moving-frame method for the iterated-integrals
signature: Orthogonal invariants. <em>FoCM</em>, <em>23</em>(4),
1273–1333. (<a
href="https://doi.org/10.1007/s10208-022-09569-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geometric, robust-to-noise features of curves in Euclidean space are of great interest for various applications such as machine learning and image analysis. We apply Fels–Olver’s moving-frame method (for geometric features) paired with the log-signature transform (for robust features) to construct a set of integral invariants under rigid motions for curves in $${\mathbb {R}}^d$$ from the iterated-integrals signature. In particular, we show that one can algorithmically construct a set of invariants that characterize the equivalence class of the truncated iterated-integrals signature under orthogonal transformations, which yields a characterization of a curve in $${\mathbb {R}}^d$$ under rigid motions (and tree-like extensions) and an explicit method to compare curves up to these transformations.},
  archive      = {J_FoCM},
  author       = {Diehl, Joscha and Preiß, Rosa and Ruddy, Michael and Tapia, Nikolas},
  doi          = {10.1007/s10208-022-09569-5},
  journal      = {Foundations of Computational Mathematics},
  number       = {4},
  pages        = {1273-1333},
  shortjournal = {Found. Comput. Math.},
  title        = {The moving-frame method for the iterated-integrals signature: Orthogonal invariants},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Approximating continuous functions on persistence diagrams
using template functions. <em>FoCM</em>, <em>23</em>(4), 1215–1272. (<a
href="https://doi.org/10.1007/s10208-022-09567-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The persistence diagram is an increasingly useful tool from Topological Data Analysis, but its use alongside typical machine learning techniques requires mathematical finesse. The most success to date has come from methods that map persistence diagrams into vector spaces, in a way which maximizes the structure preserved. This process is commonly referred to as featurization. In this paper, we describe a mathematical framework for featurization called template functions, and we show that it addresses the problem of approximating continuous functions on compact subsets of the space of persistence diagrams. Specifically, we begin by characterizing relative compactness with respect to the bottleneck distance, and then provide explicit theoretical methods for constructing compact-open dense subsets of continuous functions on persistence diagrams. These dense subsets—obtained via template functions—are leveraged for supervised learning tasks with persistence diagrams. Specifically, we test the method for classification and regression algorithms on several examples including shape data and dynamical systems.},
  archive      = {J_FoCM},
  author       = {Perea, Jose A. and Munch, Elizabeth and Khasawneh, Firas A.},
  doi          = {10.1007/s10208-022-09567-7},
  journal      = {Foundations of Computational Mathematics},
  number       = {4},
  pages        = {1215-1272},
  shortjournal = {Found. Comput. Math.},
  title        = {Approximating continuous functions on persistence diagrams using template functions},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distinguishing secant from cactus varieties. <em>FoCM</em>,
<em>23</em>(4), 1167–1214. (<a
href="https://doi.org/10.1007/s10208-022-09566-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cactus varieties are a generalization of secant varieties. They are defined using linear spans of arbitrary finite schemes of bounded length, while secant varieties use only isolated reduced points. In particular, any secant variety is always contained in the respective cactus variety, and, except in a few initial cases, the inclusion is strict. It is known that lots of natural criteria that test membership in secant varieties are actually only tests for membership in cactus varieties. In this article, we propose the first techniques to distinguish actual secant variety from the cactus variety in the case of the Veronese variety. We focus on two initial cases, $$\kappa _{14}(\nu _d({\mathbb {P}}^n))$$ and $$\kappa _{8,3}(\nu _d({\mathbb {P}}^n))$$ , the simplest that exhibit the difference between cactus and secant varieties. We show that for $$d\ge 5$$ , the component of the cactus variety $$\kappa _{14}(\nu _d({\mathbb {P}}^6))$$ other than the secant variety $$\sigma _{14}(\nu _d({\mathbb {P}}^6))$$ consists of degree d polynomials divisible by a $$(d-3)$$ rd power of a linear form. We generalize this description to an arbitrary number of variables. We present an algorithm for deciding whether a point in the cactus variety $$\kappa _{14}(\nu _d({\mathbb {P}}^n))$$ belongs to the secant variety $$\sigma _{14}(\nu _d({\mathbb {P}}^n))$$ for $$d\ge 6,$$ $$n \ge 6$$ . We obtain similar results for the Grassmann cactus variety $$\kappa _{8,3}(\nu _d({\mathbb {P}}^n))$$ . Our intermediate results give also a partial answer to analogous problems for other cactus varieties and Grassmann cactus varieties to any Veronese variety.},
  archive      = {J_FoCM},
  author       = {Gałązka, Maciej and Mańdziuk, Tomasz and Rupniewski, Filip},
  doi          = {10.1007/s10208-022-09566-8},
  journal      = {Foundations of Computational Mathematics},
  number       = {4},
  pages        = {1167-1214},
  shortjournal = {Found. Comput. Math.},
  title        = {Distinguishing secant from cactus varieties},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Principal components along quiver representations.
<em>FoCM</em>, <em>23</em>(4), 1129–1165. (<a
href="https://doi.org/10.1007/s10208-022-09563-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quiver representations arise naturally in many areas across mathematics. Here we describe an algorithm for calculating the vector space of sections, or compatible assignments of vectors to vertices, of any finite-dimensional representation of a finite quiver. Consequently, we are able to define and compute principal components with respect to quiver representations. These principal components are solutions to constrained optimisation problems defined over the space of sections and are eigenvectors of an associated matrix pencil.},
  archive      = {J_FoCM},
  author       = {Seigal, Anna and Harrington, Heather A. and Nanda, Vidit},
  doi          = {10.1007/s10208-022-09563-x},
  journal      = {Foundations of Computational Mathematics},
  number       = {4},
  pages        = {1129-1165},
  shortjournal = {Found. Comput. Math.},
  title        = {Principal components along quiver representations},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exponential ReLU neural network approximation rates for
point and edge singularities. <em>FoCM</em>, <em>23</em>(3), 1043–1127.
(<a href="https://doi.org/10.1007/s10208-022-09565-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In certain polytopal domains $$\varOmega $$ , in space dimension $$d=2,3$$ , we prove exponential expressivity with stable ReLU Neural Networks (ReLU NNs) in $$H^1(\varOmega )$$ for weighted analytic function classes. These classes comprise in particular solution sets of source and eigenvalue problems for elliptic PDEs with analytic data. Functions in these classes are locally analytic on open subdomains $$D\subset \varOmega $$ , but may exhibit isolated point singularities in the interior of $$\varOmega $$ or corner and edge singularities at the boundary $$\partial \varOmega $$ . The exponential approximation rates are shown to hold in space dimension $$d = 2$$ on Lipschitz polygons with straight sides, and in space dimension $$d=3$$ on Fichera-type polyhedral domains with plane faces. The constructive proofs indicate that NN depth and size increase poly-logarithmically with respect to the target NN approximation accuracy $$\varepsilon &gt;0$$ in $$H^1(\varOmega )$$ . The results cover solution sets of linear, second-order elliptic PDEs with analytic data and certain nonlinear elliptic eigenvalue problems with analytic nonlinearities and singular, weighted analytic potentials as arise in electron structure models. Here, the functions correspond to electron densities that exhibit isolated point singularities at the nuclei.},
  archive      = {J_FoCM},
  author       = {Marcati, Carlo and Opschoor, Joost A. A. and Petersen, Philipp C. and Schwab, Christoph},
  doi          = {10.1007/s10208-022-09565-9},
  journal      = {Foundations of Computational Mathematics},
  number       = {3},
  pages        = {1043-1127},
  shortjournal = {Found. Comput. Math.},
  title        = {Exponential ReLU neural network approximation rates for point and edge singularities},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Free component analysis: Theory, algorithms and
applications. <em>FoCM</em>, <em>23</em>(3), 973–1042. (<a
href="https://doi.org/10.1007/s10208-022-09564-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe a method for unmixing mixtures of freely independent random variables in a manner analogous to the independent component analysis (ICA)-based method for unmixing independent random variables from their additive mixtures. Random matrices play the role of free random variables in this context so the method we develop, which we call free component analysis (FCA), unmixes matrices from additive mixtures of matrices. Thus, while the mixing model is standard, the novelty and difference in unmixing performance comes from the introduction of a new statistical criteria, derived from free probability theory, that quantify freeness analogous to how kurtosis and entropy quantify independence. We describe the theory, the various algorithms, and compare FCA to vanilla ICA which does not account for spatial or temporal structure. We highlight why the statistical criteria make FCA also vanilla despite its matricial underpinnings and show that FCA performs comparably to, and sometimes better than, (vanilla) ICA in every application, such as image and speech unmixing, where ICA has been known to succeed. Our computational experiments suggest that not-so-random matrices, such as images and short-time Fourier transform matrix of waveforms are (closer to being) freer “in the wild” than we might have theoretically expected.},
  archive      = {J_FoCM},
  author       = {Nadakuditi, Raj Rao and Wu, Hao},
  doi          = {10.1007/s10208-022-09564-w},
  journal      = {Foundations of Computational Mathematics},
  number       = {3},
  pages        = {973-1042},
  shortjournal = {Found. Comput. Math.},
  title        = {Free component analysis: Theory, algorithms and applications},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A unified approach to uniform signal recovery from nonlinear
observations. <em>FoCM</em>, <em>23</em>(3), 899–972. (<a
href="https://doi.org/10.1007/s10208-022-09562-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in quantized compressed sensing and high-dimensional estimation have shown that signal recovery is even feasible under strong nonlinear distortions in the observation process. An important characteristic of associated guarantees is uniformity, i.e., recovery succeeds for an entire class of structured signals with a fixed measurement ensemble. However, despite significant results in various special cases, a general understanding of uniform recovery from nonlinear observations is still missing. This paper develops a unified approach to this problem under the assumption of i.i.d. sub-Gaussian measurement vectors. Our main result shows that a simple least-squares estimator with any convex constraint can serve as a universal recovery strategy, which is outlier robust and does not require explicit knowledge of the underlying nonlinearity. Based on empirical process theory, a key technical novelty is an approximative increment condition that can be implemented for all common types of nonlinear models. This flexibility allows us to apply our approach to a variety of problems in nonlinear compressed sensing and high-dimensional statistics, leading to several new and improved guarantees. Each of these applications is accompanied by a conceptually simple and systematic proof, which does not rely on any deeper properties of the observation model. On the other hand, known local stability properties can be incorporated into our framework in a plug-and-play manner, thereby implying near-optimal error bounds.},
  archive      = {J_FoCM},
  author       = {Genzel, Martin and Stollenwerk, Alexander},
  doi          = {10.1007/s10208-022-09562-y},
  journal      = {Foundations of Computational Mathematics},
  number       = {3},
  pages        = {899-972},
  shortjournal = {Found. Comput. Math.},
  title        = {A unified approach to uniform signal recovery from nonlinear observations},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A generalized conditional gradient method for dynamic
inverse problems with optimal transport regularization. <em>FoCM</em>,
<em>23</em>(3), 833–898. (<a
href="https://doi.org/10.1007/s10208-022-09561-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a dynamic generalized conditional gradient method (DGCG) for dynamic inverse problems with optimal transport regularization. We consider the framework introduced in Bredies and Fanzon (ESAIM: M2AN 54:2351–2382, 2020), where the objective functional is comprised of a fidelity term, penalizing the pointwise in time discrepancy between the observation and the unknown in time-varying Hilbert spaces, and a regularizer keeping track of the dynamics, given by the Benamou–Brenier energy constrained via the homogeneous continuity equation. Employing the characterization of the extremal points of the Benamou–Brenier energy (Bredies et al. in Bull Lond Math Soc 53(5):1436–1452, 2021), we define the atoms of the problem as measures concentrated on absolutely continuous curves in the domain. We propose a dynamic generalization of a conditional gradient method that consists of iteratively adding suitably chosen atoms to the current sparse iterate, and subsequently optimizing the coefficients in the resulting linear combination. We prove that the method converges with a sublinear rate to a minimizer of the objective functional. Additionally, we propose heuristic strategies and acceleration steps that allow to implement the algorithm efficiently. Finally, we provide numerical examples that demonstrate the effectiveness of our algorithm and model in reconstructing heavily undersampled dynamic data, together with the presence of noise.},
  archive      = {J_FoCM},
  author       = {Bredies, Kristian and Carioni, Marcello and Fanzon, Silvio and Romero, Francisco},
  doi          = {10.1007/s10208-022-09561-z},
  journal      = {Foundations of Computational Mathematics},
  number       = {3},
  pages        = {833-898},
  shortjournal = {Found. Comput. Math.},
  title        = {A generalized conditional gradient method for dynamic inverse problems with optimal transport regularization},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continuity of formal power series products in nonlinear
control theory. <em>FoCM</em>, <em>23</em>(3), 803–832. (<a
href="https://doi.org/10.1007/s10208-022-09560-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Formal power series products appear in nonlinear control theory when systems modeled by Chen–Fliess series are interconnected to form new systems. In fields like adaptive control and learning systems, the coefficients of these formal power series are estimated sequentially with real-time data. The main goal is to prove the continuity and analyticity of such products with respect to several natural (locally convex) topologies on spaces of locally convergent formal power series in order to establish foundational properties behind these technologies. In addition, it is shown that a transformation group central to describing the output feedback connection is in fact an analytic Lie group in this setting with certain regularity properties.},
  archive      = {J_FoCM},
  author       = {Gray, W. Steven and Palmstrøm, Mathias and Schmeding, Alexander},
  doi          = {10.1007/s10208-022-09560-0},
  journal      = {Foundations of Computational Mathematics},
  number       = {3},
  pages        = {803-832},
  shortjournal = {Found. Comput. Math.},
  title        = {Continuity of formal power series products in nonlinear control theory},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The canny–emiris conjecture for the sparse resultant.
<em>FoCM</em>, <em>23</em>(3), 741–801. (<a
href="https://doi.org/10.1007/s10208-021-09547-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a product formula for the initial parts of the sparse resultant associated with an arbitrary family of supports, generalizing a previous result by Sturmfels. This allows to compute the homogeneities and degrees of this sparse resultant, and its evaluation at systems of Laurent polynomials with smaller supports. We obtain an analogous product formula for some of the initial parts of the principal minors of the Sylvester-type square matrix associated with a mixed subdivision of a polytope. Applying these results, we prove that under suitable hypothesis, the sparse resultant can be computed as the quotient of the determinant of such a square matrix by one of its principal minors. This generalizes the classical Macaulay formula for the homogeneous resultant and confirms a conjecture of Canny and Emiris.},
  archive      = {J_FoCM},
  author       = {D’Andrea, Carlos and Jeronimo, Gabriela and Sombra, Martín},
  doi          = {10.1007/s10208-021-09547-3},
  journal      = {Foundations of Computational Mathematics},
  number       = {3},
  pages        = {741-801},
  shortjournal = {Found. Comput. Math.},
  title        = {The Canny–Emiris conjecture for the sparse resultant},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning elliptic partial differential equations with
randomized linear algebra. <em>FoCM</em>, <em>23</em>(2), 709–739. (<a
href="https://doi.org/10.1007/s10208-022-09556-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given input–output pairs of an elliptic partial differential equation (PDE) in three dimensions, we derive the first theoretically rigorous scheme for learning the associated Green’s function G. By exploiting the hierarchical low-rank structure of G, we show that one can construct an approximant to G that converges almost surely and achieves a relative error of $$\mathcal {O}(\varGamma _\epsilon ^{-1/2}\log ^3(1/\epsilon )\epsilon )$$ using at most $$\mathcal {O}(\epsilon ^{-6}\log ^4(1/\epsilon ))$$ input–output training pairs with high probability, for any $$0&lt;\epsilon &lt;1$$ . The quantity $$0&lt;\varGamma _\epsilon \le 1$$ characterizes the quality of the training dataset. Along the way, we extend the randomized singular value decomposition algorithm for learning matrices to Hilbert–Schmidt operators and characterize the quality of covariance kernels for PDE learning.},
  archive      = {J_FoCM},
  author       = {Boullé, Nicolas and Townsend, Alex},
  doi          = {10.1007/s10208-022-09556-w},
  journal      = {Foundations of Computational Mathematics},
  number       = {2},
  pages        = {709-739},
  shortjournal = {Found. Comput. Math.},
  title        = {Learning elliptic partial differential equations with randomized linear algebra},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Affine-invariant ensemble transform methods for logistic
regression. <em>FoCM</em>, <em>23</em>(2), 675–708. (<a
href="https://doi.org/10.1007/s10208-022-09550-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the application of ensemble transform approaches to Bayesian inference of logistic regression problems. Our approach relies on appropriate extensions of the popular ensemble Kalman filter and the feedback particle filter to the cross entropy loss function and is based on a well-established homotopy approach to Bayesian inference. The arising finite particle evolution equations as well as their mean-field limits are affine-invariant. Furthermore, the proposed methods can be implemented in a gradient-free manner in case of nonlinear logistic regression and the data can be randomly subsampled similar to mini-batching of stochastic gradient descent. We also propose a closely related SDE-based sampling method which again is affine-invariant and can easily be made gradient-free. Numerical examples demonstrate the appropriateness of the proposed methodologies.},
  archive      = {J_FoCM},
  author       = {Pidstrigach, Jakiw and Reich, Sebastian},
  doi          = {10.1007/s10208-022-09550-2},
  journal      = {Foundations of Computational Mathematics},
  number       = {2},
  pages        = {675-708},
  shortjournal = {Found. Comput. Math.},
  title        = {Affine-invariant ensemble transform methods for logistic regression},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Halting time is predictable for large models: A universality
property and average-case analysis. <em>FoCM</em>, <em>23</em>(2),
597–673. (<a href="https://doi.org/10.1007/s10208-022-09554-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Average-case analysis computes the complexity of an algorithm averaged over all possible inputs. Compared to worst-case analysis, it is more representative of the typical behavior of an algorithm, but remains largely unexplored in optimization. One difficulty is that the analysis can depend on the probability distribution of the inputs to the model. However, we show that this is not the case for a class of large-scale problems trained with first-order methods including random least squares and one-hidden layer neural networks with random weights. In fact, the halting time exhibits a universality property: it is independent of the probability distribution. With this barrier for average-case analysis removed, we provide the first explicit average-case convergence rates showing a tighter complexity not captured by traditional worst-case analysis. Finally, numerical simulations suggest this universality property holds for a more general class of algorithms and problems.},
  archive      = {J_FoCM},
  author       = {Paquette, Courtney and van Merriënboer, Bart and Paquette, Elliot and Pedregosa, Fabian},
  doi          = {10.1007/s10208-022-09554-y},
  journal      = {Foundations of Computational Mathematics},
  number       = {2},
  pages        = {597-673},
  shortjournal = {Found. Comput. Math.},
  title        = {Halting time is predictable for large models: A universality property and average-case analysis},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finite element systems for vector bundles: Elasticity and
curvature. <em>FoCM</em>, <em>23</em>(2), 545–596. (<a
href="https://doi.org/10.1007/s10208-022-09555-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a theory of finite element systems, for the purpose of discretizing sections of vector bundles, in particular those arising in the theory of elasticity. In the presence of curvature, we prove a discrete Bianchi identity. In the flat case, we prove a de Rham theorem on cohomology groups. We check that some known mixed finite elements for the stress–displacement formulation of elasticity fit our framework. We also define, in dimension two, the first conforming finite element spaces of metrics with good linearized curvature, corresponding to strain tensors with Saint-Venant compatibility conditions. Cochains with coefficients in rigid motions are given a key role in relating continuous and discrete elasticity complexes.},
  archive      = {J_FoCM},
  author       = {Christiansen, Snorre H. and Hu, Kaibo},
  doi          = {10.1007/s10208-022-09555-x},
  journal      = {Foundations of Computational Mathematics},
  number       = {2},
  pages        = {545-596},
  shortjournal = {Found. Comput. Math.},
  title        = {Finite element systems for vector bundles: Elasticity and curvature},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explicit computation of a galois representation attached to
an eigenform over <span class="math display">SL<sub>3</sub></span> from
the <span class="math display">$${{\text
{H}}}_{\acute{\mathrm{e}}\mathrm{t}}^2$$</span> of a surface.
<em>FoCM</em>, <em>23</em>(2), 519–543. (<a
href="https://doi.org/10.1007/s10208-021-09505-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe a method to compute mod $$\ell $$ Galois representations contained in the $${{\text {H}}}_{\acute{\mathrm{e}}\mathrm{t}}^2$$ of surfaces. We apply this method to the case of a representation with values in $${\text {GL}}_3(\mathbb {F}_9)$$ attached to an eigenform over a congruence subgroup of $${\text {SL}}_3$$ . We obtain, in particular, a polynomial with Galois group isomorphic to the simple group $${\text {PSU}}_3(\mathbb {F}_9)$$ and ramified at 2 and 3 only.},
  archive      = {J_FoCM},
  author       = {Mascot, Nicolas},
  doi          = {10.1007/s10208-021-09505-z},
  journal      = {Foundations of Computational Mathematics},
  number       = {2},
  pages        = {519-543},
  shortjournal = {Found. Comput. Math.},
  title        = {Explicit computation of a galois representation attached to an eigenform over $${\text {SL}}_3$$ from the $${{\text {H}}}_{\acute{\mathrm{e}}\mathrm{t}}^2$$ of a surface},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A common variable minimax theorem for graphs. <em>FoCM</em>,
<em>23</em>(2), 493–517. (<a
href="https://doi.org/10.1007/s10208-022-09558-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let $${\mathcal {G}} = {G_1 = (V, E_1), \ldots , G_m = (V, E_m)}$$ be a collection of m graphs defined on a common set of vertices V but with different edge sets $$E_1, \ldots , E_m$$ . Informally, a function $$f :V \rightarrow {\mathbb {R}}$$ is smooth with respect to $$G_k = (V,E_k)$$ if $$f(u) \sim f(v)$$ whenever $$(u, v) \in E_k$$ . We study the problem of understanding whether there exists a nonconstant function that is smooth with respect to all graphs in $${\mathcal {G}}$$ , simultaneously, and how to find it if it exists.},
  archive      = {J_FoCM},
  author       = {Coifman, Ronald R. and Marshall, Nicholas F. and Steinerberger, Stefan},
  doi          = {10.1007/s10208-022-09558-8},
  journal      = {Foundations of Computational Mathematics},
  number       = {2},
  pages        = {493-517},
  shortjournal = {Found. Comput. Math.},
  title        = {A common variable minimax theorem for graphs},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The average condition number of most tensor rank
decomposition problems is infinite. <em>FoCM</em>, <em>23</em>(2),
433–491. (<a href="https://doi.org/10.1007/s10208-022-09551-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The tensor rank decomposition, or canonical polyadic decomposition, is the decomposition of a tensor into a sum of rank-1 tensors. The condition number of the tensor rank decomposition measures the sensitivity of the rank-1 summands with respect to structured perturbations. Those are perturbations preserving the rank of the tensor that is decomposed. On the other hand, the angular condition number measures the perturbations of the rank-1 summands up to scaling. We show for random rank-2 tensors that the expected value of the condition number is infinite for a wide range of choices of the density. Under a mild additional assumption, we show that the same is true for most higher ranks $$r\ge 3$$ as well. In fact, as the dimensions of the tensor tend to infinity, asymptotically all ranks are covered by our analysis. On the contrary, we show that rank-2 tensors have finite expected angular condition number. Based on numerical experiments, we conjecture that this could also be true for higher ranks. Our results underline the high computational complexity of computing tensor rank decompositions. We discuss consequences of our results for algorithm design and for testing algorithms computing tensor rank decompositions.},
  archive      = {J_FoCM},
  author       = {Beltrán, Carlos and Breiding, Paul and Vannieuwenhoven, Nick},
  doi          = {10.1007/s10208-022-09551-1},
  journal      = {Foundations of Computational Mathematics},
  number       = {2},
  pages        = {433-491},
  shortjournal = {Found. Comput. Math.},
  title        = {The average condition number of most tensor rank decomposition problems is infinite},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continuum limit of lipschitz learning on graphs.
<em>FoCM</em>, <em>23</em>(2), 393–431. (<a
href="https://doi.org/10.1007/s10208-022-09557-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tackling semi-supervised learning problems with graph-based methods has become a trend in recent years since graphs can represent all kinds of data and provide a suitable framework for studying continuum limits, for example, of differential operators. A popular strategy here is p-Laplacian learning, which poses a smoothness condition on the sought inference function on the set of unlabeled data. For $$p&lt;\infty $$ continuum limits of this approach were studied using tools from $$\varGamma $$ -convergence. For the case $$p=\infty $$ , which is referred to as Lipschitz learning, continuum limits of the related infinity Laplacian equation were studied using the concept of viscosity solutions. In this work, we prove continuum limits of Lipschitz learning using $$\varGamma $$ -convergence. In particular, we define a sequence of functionals which approximate the largest local Lipschitz constant of a graph function and prove $$\varGamma $$ -convergence in the $$L^{\infty }$$ -topology to the supremum norm of the gradient as the graph becomes denser. Furthermore, we show compactness of the functionals which implies convergence of minimizers. In our analysis we allow a varying set of labeled data which converges to a general closed set in the Hausdorff distance. We apply our results to nonlinear ground states, i.e., minimizers with constrained $$L^p$$ -norm, and, as a by-product, prove convergence of graph distance functions to geodesic distance functions.},
  archive      = {J_FoCM},
  author       = {Roith, Tim and Bungert, Leon},
  doi          = {10.1007/s10208-022-09557-9},
  journal      = {Foundations of Computational Mathematics},
  number       = {2},
  pages        = {393-431},
  shortjournal = {Found. Comput. Math.},
  title        = {Continuum limit of lipschitz learning on graphs},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Phase transitions in rate distortion theory and deep
learning. <em>FoCM</em>, <em>23</em>(1), 329–392. (<a
href="https://doi.org/10.1007/s10208-021-09546-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rate distortion theory is concerned with optimally encoding signals from a given signal class $$\mathcal {S}$$ using a budget of R bits, as $$R \rightarrow \infty $$ . We say that $$\mathcal {S}$$ can be compressed at rate s if we can achieve an error of at most $$\mathcal {O}(R^{-s})$$ for encoding the given signal class; the supremal compression rate is denoted by $$s^*(\mathcal {S})$$ . Given a fixed coding scheme, there usually are some elements of $$\mathcal {S}$$ that are compressed at a higher rate than $$s^*(\mathcal {S})$$ by the given coding scheme; in this paper, we study the size of this set of signals. We show that for certain “nice” signal classes $$\mathcal {S}$$ , a phase transition occurs: We construct a probability measure $$\mathbb {P}$$ on $$\mathcal {S}$$ such that for every coding scheme $$\mathcal {C}$$ and any $$s &gt; s^*(\mathcal {S})$$ , the set of signals encoded with error $$\mathcal {O}(R^{-s})$$ by $$\mathcal {C}$$ forms a $$\mathbb {P}$$ -null-set. In particular, our results apply to all unit balls in Besov and Sobolev spaces that embed compactly into $$L^2 (\varOmega )$$ for a bounded Lipschitz domain $$\varOmega $$ . As an application, we show that several existing sharpness results concerning function approximation using deep neural networks are in fact generically sharp. In addition, we provide quantitative and non-asymptotic bounds on the probability that a random $$f\in \mathcal {S}$$ can be encoded to within accuracy $$\varepsilon $$ using R bits. This result is subsequently applied to the problem of approximately representing $$f\in \mathcal {S}$$ to within accuracy $$\varepsilon $$ by a (quantized) neural network with at most W nonzero weights. We show that for any $$s &gt; s^*(\mathcal {S})$$ there are constants c, C such that, no matter what kind of “learning” procedure is used to produce such a network, the probability of success is bounded from above by $$\min \big {1, 2^{C\cdot W \lceil \log _2 (1+W) \rceil ^2 - c\cdot \varepsilon ^{-1/s}} \big }$$ .},
  archive      = {J_FoCM},
  author       = {Grohs, Philipp and Klotz, Andreas and Voigtlaender, Felix},
  doi          = {10.1007/s10208-021-09546-4},
  journal      = {Foundations of Computational Mathematics},
  number       = {1},
  pages        = {329-392},
  shortjournal = {Found. Comput. Math.},
  title        = {Phase transitions in rate distortion theory and deep learning},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The geometry of off-the-grid compressed sensing.
<em>FoCM</em>, <em>23</em>(1), 241–327. (<a
href="https://doi.org/10.1007/s10208-021-09545-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compressed sensing (CS) ensures the recovery of sparse vectors from a number of randomized measurements proportional to their sparsity. The initial theory considers discretized domains, and the randomness makes the physical positions of the grid nodes irrelevant. Most imaging devices, however, operate over some continuous physical domain, and it makes sense to consider Dirac masses with arbitrary positions. In this article, we consider such a continuous setup and analyze the performance of the BLASSO algorithm, which is the continuous extension of the celebrated LASSO $$\ell ^1$$ regularization method. This approach is appealing from a numerical perspective because it avoids to discretize the domain of interest. Previous works considered translation-invariant measurements, such as randomized Fourier coefficients, in which it makes clear that the discrete theory should be extended by imposing a minimum distance separation constraint (often called “Rayleigh limit”) between the Diracs. These prior works, however, rule out many domains and sensing operators of interest, which are not translation invariant. This includes, for instance, Laplace measurements over the positive reals and Gaussian mixture models over the mean-covariance space. Our theoretical advances crucially rely on the introduction of a canonical metric associated with the measurement operator, which is the so-called Fisher geodesic distance. In the case of Fourier measurements, one recovers the Euclidean metric, but this metric can cope with arbitrary (possibly non-translation invariant) domains. Furthermore, it is naturally invariant under joint reparameterization of both the sensing operator and the Dirac locations. Our second and main contribution shows that if the Fisher distance between spikes is larger than a Rayleigh separation constant, then the BLASSO recovers in a stable way a stream of Diracs, provided that the number of measurements is proportional (up to log factors) to the number of Diracs. We measure the stability using an optimal transport distance constructed on top of the Fisher geodesic distance. Our result is (up to log factor) sharp and does not require any randomness assumption on the amplitudes of the underlying measure. Our proof technique relies on an infinite-dimensional extension of the so-called golfing scheme which operates over the space of measures and is of general interest.},
  archive      = {J_FoCM},
  author       = {Poon, Clarice and Keriven, Nicolas and Peyré, Gabriel},
  doi          = {10.1007/s10208-021-09545-5},
  journal      = {Foundations of Computational Mathematics},
  number       = {1},
  pages        = {241-327},
  shortjournal = {Found. Comput. Math.},
  title        = {The geometry of off-the-grid compressed sensing},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analysis of tensor approximation schemes for continuous
functions. <em>FoCM</em>, <em>23</em>(1), 219–240. (<a
href="https://doi.org/10.1007/s10208-021-09544-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we analyze tensor approximation schemes for continuous functions. We assume that the function to be approximated lies in an isotropic Sobolev space and discuss the cost when approximating this function in the continuous analogue of the Tucker tensor format or of the tensor train format. We especially show that the cost of both approximations are dimension-robust when the Sobolev space under consideration provides appropriate dimension weights.},
  archive      = {J_FoCM},
  author       = {Griebel, Michael and Harbrecht, Helmut},
  doi          = {10.1007/s10208-021-09544-6},
  journal      = {Foundations of Computational Mathematics},
  number       = {1},
  pages        = {219-240},
  shortjournal = {Found. Comput. Math.},
  title        = {Analysis of tensor approximation schemes for continuous functions},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analysis and convergence of hermite subdivision schemes.
<em>FoCM</em>, <em>23</em>(1), 165–218. (<a
href="https://doi.org/10.1007/s10208-021-09543-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hermite interpolation property is desired in applied and computational mathematics. Hermite and vector subdivision schemes are of interest in CAGD for generating subdivision curves and in computational mathematics for building Hermite wavelets to numerically solve partial differential equations. In contrast to well-studied scalar subdivision schemes, Hermite and vector subdivision schemes employ matrix-valued masks and vector input data, which make their analysis much more complicated and difficult than their scalar counterparts. Under the spectral condition or the spectral chain, analysis of Hermite subdivision schemes through factorization of matrix-valued masks has been extensively studied in the literature and sufficient conditions have been given for the convergence of Hermite subdivision schemes through the contractivity of their derived subdivision schemes. We contribute to the study of Hermite subdivision schemes from a different perspective by investigating vector subdivision operators acting on vector polynomials and by establishing connections among Hermite subdivision schemes, vector cascade algorithms, and refinable vector functions. This approach allows us to characterize and construct all masks for Hermite subdivision schemes, to explain the spectral condition and spectral chain in the literature, to characterize convergence and smoothness of Hermite subdivision schemes using vector cascade algorithms, and to provide simple factorizations of Hermite masks through the normal form of matrix-valued masks such that the Hermite subdivision scheme is convergent if and only if its derived subdivision scheme is contractive. We also constructively prove that there always exist arbitrarily smooth convergent Hermite subdivision schemes, whose basis vector functions are splines and have linearly independent shifts. Several examples of Hermite subdivision schemes with short support and high smoothness are presented to illustrate the results in this paper.},
  archive      = {J_FoCM},
  author       = {Han, Bin},
  doi          = {10.1007/s10208-021-09543-7},
  journal      = {Foundations of Computational Mathematics},
  number       = {1},
  pages        = {165-218},
  shortjournal = {Found. Comput. Math.},
  title        = {Analysis and convergence of hermite subdivision schemes},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An arbitrary-order discrete de rham complex on polyhedral
meshes: Exactness, poincaré inequalities, and consistency.
<em>FoCM</em>, <em>23</em>(1), 85–164. (<a
href="https://doi.org/10.1007/s10208-021-09542-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a novel arbitrary-order discrete de Rham (DDR) complex on general polyhedral meshes based on the decomposition of polynomial spaces into ranges of vector calculus operators and complements linked to the spaces in the Koszul complex. The DDR complex is fully discrete, meaning that both the spaces and discrete calculus operators are replaced by discrete counterparts, and satisfies suitable exactness properties depending on the topology of the domain. In conjunction with bespoke discrete counterparts of $$\text {L}^2$$ -products, it can be used to design schemes for partial differential equations that benefit from the exactness of the sequence but, unlike classical (e.g., Raviart–Thomas–Nédélec) finite elements, are nonconforming. We prove a complete panel of results for the analysis of such schemes: exactness properties, uniform Poincaré inequalities, as well as primal and adjoint consistency. We also show how this DDR complex enables the design of a numerical scheme for a magnetostatics problem, and use the aforementioned results to prove stability and optimal error estimates for this scheme.},
  archive      = {J_FoCM},
  author       = {Di Pietro, Daniele A. and Droniou, Jérôme},
  doi          = {10.1007/s10208-021-09542-8},
  journal      = {Foundations of Computational Mathematics},
  number       = {1},
  pages        = {85-164},
  shortjournal = {Found. Comput. Math.},
  title        = {An arbitrary-order discrete de rham complex on polyhedral meshes: Exactness, poincaré inequalities, and consistency},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Drift estimation of multiscale diffusions based on filtered
data. <em>FoCM</em>, <em>23</em>(1), 33–84. (<a
href="https://doi.org/10.1007/s10208-021-09541-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of drift estimation for two-scale continuous time series. We set ourselves in the framework of overdamped Langevin equations, for which a single-scale surrogate homogenized equation exists. In this setting, estimating the drift coefficient of the homogenized equation requires pre-processing of the data, often in the form of subsampling; this is because the two-scale equation and the homogenized single-scale equation are incompatible at small scales, generating mutually singular measures on the path space. We avoid subsampling and work instead with filtered data, found by application of an appropriate kernel function, and compute maximum likelihood estimators based on the filtered process. We show that the estimators we propose are asymptotically unbiased and demonstrate numerically the advantages of our method with respect to subsampling. Finally, we show how our filtered data methodology can be combined with Bayesian techniques and provide a full uncertainty quantification of the inference procedure.},
  archive      = {J_FoCM},
  author       = {Abdulle, Assyr and Garegnani, Giacomo and Pavliotis, Grigorios A. and Stuart, Andrew M. and Zanoni, Andrea},
  doi          = {10.1007/s10208-021-09541-9},
  journal      = {Foundations of Computational Mathematics},
  number       = {1},
  pages        = {33-84},
  shortjournal = {Found. Comput. Math.},
  title        = {Drift estimation of multiscale diffusions based on filtered data},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Orthogonal polynomials on planar cubic curves.
<em>FoCM</em>, <em>23</em>(1), 1–31. (<a
href="https://doi.org/10.1007/s10208-021-09540-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Orthogonal polynomials in two variables on cubic curves are considered. For an integral with respect to an appropriate weight function defined on a cubic curve, an explicit basis of orthogonal polynomials is constructed in terms of two families of orthogonal polynomials in one variable. We show that these orthogonal polynomials can be used to approximate functions with cubic and square root singularities, and demonstrate their usage for solving differential equations with singular solutions.},
  archive      = {J_FoCM},
  author       = {Fasondini, Marco and Olver, Sheehan and Xu, Yuan},
  doi          = {10.1007/s10208-021-09540-w},
  journal      = {Foundations of Computational Mathematics},
  number       = {1},
  pages        = {1-31},
  shortjournal = {Found. Comput. Math.},
  title        = {Orthogonal polynomials on planar cubic curves},
  volume       = {23},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
