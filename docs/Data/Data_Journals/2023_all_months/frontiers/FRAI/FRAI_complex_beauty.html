<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>FRAI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="frai---241">FRAI - 241</h2>
<ul>
<li><details>
<summary>
(2023). Exploring the role of AI in classifying, analyzing, and
generating case reports on assisted suicide cases: Feasibility and
ethical implications. <em>FRAI</em>, <em>6</em>, 1328865. (<a
href="https://doi.org/10.3389/frai.2023.1328865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a study on the use of AI models for the classification of case reports on assisted suicide procedures. The database of the five Dutch regional bioethics committees was scraped to collect the 72 case reports available in English. We trained several AI models for classification according to the categories defined by the Dutch Termination of Life on Request and Assisted Suicide (Review Procedures) Act. We also conducted a related project to fine-tune an OpenAI GPT-3.5-turbo large language model for generating new fictional but plausible cases. As AI is increasingly being used for judgement, it is possible to imagine an application in decision-making regarding assisted suicide. Here we explore two arising questions: feasibility and ethics, with the aim of contributing to a critical assessment of the potential role of AI in decision-making in highly sensitive areas.},
  archive      = {J_FRAI},
  author       = {Spitale, Giovanni and Schneider, Gerold and Germani, Federico and Biller-Andorno, Nikola},
  doi          = {10.3389/frai.2023.1328865},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1328865},
  shortjournal = {Front. Artif. Intell.},
  title        = {Exploring the role of AI in classifying, analyzing, and generating case reports on assisted suicide cases: Feasibility and ethical implications},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development and evaluation of multimodal AI for diagnosis
and triage of ophthalmic diseases using ChatGPT and anterior segment
images: Protocol for a two-stage cross-sectional study. <em>FRAI</em>,
<em>6</em>, 1323924. (<a
href="https://doi.org/10.3389/frai.2023.1323924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionArtificial intelligence (AI) technology has made rapid progress for disease diagnosis and triage. In the field of ophthalmic diseases, image-based diagnosis has achieved high accuracy but still encounters limitations due to the lack of medical history. The emergence of ChatGPT enables human-computer interaction, allowing for the development of a multimodal AI system that integrates interactive text and image information.ObjectiveTo develop a multimodal AI system using ChatGPT and anterior segment images for diagnosing and triaging ophthalmic diseases. To assess the AI system&#39;s performance through a two-stage cross-sectional study, starting with silent evaluation and followed by early clinical evaluation in outpatient clinics.Methods and analysisOur study will be conducted across three distinct centers in Shanghai, Nanjing, and Suqian. The development of the smartphone-based multimodal AI system will take place in Shanghai with the goal of achieving ≥90% sensitivity and ≥95% specificity for diagnosing and triaging ophthalmic diseases. The first stage of the cross-sectional study will explore the system&#39;s performance in Shanghai&#39;s outpatient clinics. Medical histories will be collected without patient interaction, and anterior segment images will be captured using slit lamp equipment. This stage aims for ≥85% sensitivity and ≥95% specificity with a sample size of 100 patients. The second stage will take place at three locations, with Shanghai serving as the internal validation dataset, and Nanjing and Suqian as the external validation dataset. Medical history will be collected through patient interviews, and anterior segment images will be captured via smartphone devices. An expert panel will establish reference standards and assess AI accuracy for diagnosis and triage throughout all stages. A one-vs.-rest strategy will be used for data analysis, and a post-hoc power calculation will be performed to evaluate the impact of disease types on AI performance.DiscussionOur study may provide a user-friendly smartphone-based multimodal AI system for diagnosis and triage of ophthalmic diseases. This innovative system may support early detection of ocular abnormalities, facilitate establishment of a tiered healthcare system, and reduce the burdens on tertiary facilities.Trial registrationThe study was registered in ClinicalTrials.gov on June 25th, 2023 (NCT 05930444).},
  archive      = {J_FRAI},
  author       = {Peng, Zhiyu and Ma, Ruiqi and Zhang, Yihan and Yan, Mingxu and Lu, Jie and Cheng, Qian and Liao, Jingjing and Zhang, Yunqiu and Wang, Jinghan and Zhao, Yue and Zhu, Jiang and Qin, Bing and Jiang, Qin and Shi, Fei and Qian, Jiang and Chen, Xinjian and Zhao, Chen},
  doi          = {10.3389/frai.2023.1323924},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1323924},
  shortjournal = {Front. Artif. Intell.},
  title        = {Development and evaluation of multimodal AI for diagnosis and triage of ophthalmic diseases using ChatGPT and anterior segment images: Protocol for a two-stage cross-sectional study},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Safer not to know? Shaping liability law and policy to
incentivize adoption of predictive AI technologies in the food system.
<em>FRAI</em>, <em>6</em>, 1298604. (<a
href="https://doi.org/10.3389/frai.2023.1298604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Governments, researchers, and developers emphasize creating “trustworthy AI,” defined as AI that prevents bias, ensures data privacy, and generates reliable results that perform as expected. However, in some cases problems arise not when AI is not trustworthy, technologically, but when it is. This article focuses on such problems in the food system. AI technologies facilitate the generation of masses of data that may illuminate existing food-safety and employee-safety risks. These systems may collect incidental data that could be used, or may be designed specifically, to assess and manage risks. The predictions and knowledge generated by these data and technologies may increase company liability and expense, and discourage adoption of these predictive technologies. Such problems may extend beyond the food system to other industries. Based on interviews and literature, this article discusses vulnerabilities to liability and obstacles to technology adoption that arise, arguing that “trustworthy AI” cannot be achieved through technology alone, but requires social, cultural, political, as well as technical cooperation. Implications for law and further research are also discussed.},
  archive      = {J_FRAI},
  author       = {Alexander, Carrie S. and Smith, Aaron and Ivanek, Renata},
  doi          = {10.3389/frai.2023.1298604},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1298604},
  shortjournal = {Front. Artif. Intell.},
  title        = {Safer not to know? shaping liability law and policy to incentivize adoption of predictive AI technologies in the food system},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Statistical inference for dependence networks in topological
data analysis. <em>FRAI</em>, <em>6</em>, 1293504. (<a
href="https://doi.org/10.3389/frai.2023.1293504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topological data analysis (TDA) provide tools that are becoming increasingly popular for analyzing multivariate time series data. One key aspect in analyzing multivariate time series is dependence between components. One application is on brain signal analysis. In particular, various dependence patterns in brain networks may be linked to specific tasks and cognitive processes. These dependence patterns may be altered by various neurological and cognitive impairments such as Alzheimer&#39;s and Parkinson&#39;s diseases, as well as attention deficit hyperactivity disorder (ADHD). Because there is no ground-truth with known dependence patterns in real brain signals, testing new TDA methods on multivariate time series is still a challenge. Our goal here is to develop novel statistical inference procedures via simulations. Simulations are useful for generating some null distributions of a test statistic (for hypothesis testing), forming confidence regions, and for evaluating the performance of proposed TDA methods. To the best of our knowledge, there are no methods that simulate multivariate time series data with potentially complex user-specified connectivity patterns. In this paper we present a novel approach to simulate multivariate time series with specific number of cycles/holes in its dependence network. Furthermore, we also provide a procedure for generating higher dimensional topological features.},
  archive      = {J_FRAI},
  author       = {El-Yaagoubi, Anass B. and Chung, Moo K. and Ombao, Hernando},
  doi          = {10.3389/frai.2023.1293504},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1293504},
  shortjournal = {Front. Artif. Intell.},
  title        = {Statistical inference for dependence networks in topological data analysis},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence applied to analyzes during the
pandemic: COVID-19 beds occupancy in the state of rio grande do norte,
brazil. <em>FRAI</em>, <em>6</em>, 1290022. (<a
href="https://doi.org/10.3389/frai.2023.1290022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic is already considered one of the biggest global health crises. In Rio Grande do Norte, a Brazilian state, the RegulaRN platform was the health information system used to regulate beds for patients with COVID-19. This article explored machine learning and deep learning techniques with RegulaRN data in order to identify the best models and parameters to predict the outcome of a hospitalized patient. A total of 25,366 bed regulations for COVID-19 patients were analyzed. The data analyzed comes from the RegulaRN Platform database from April 2020 to August 2022. From these data, the nine most pertinent characteristics were selected from the twenty available, and blank or inconclusive data were excluded. This was followed by the following steps: data pre-processing, database balancing, training, and test. The results showed better performance in terms of accuracy (84.01%), precision (79.57%), and F1-score (81.00%) for the Multilayer Perceptron model with Stochastic Gradient Descent optimizer. The best results for recall (84.67%), specificity (84.67%), and ROC-AUC (91.6%) were achieved by Root Mean Squared Propagation. This study compared different computational methods of machine and deep learning whose objective was to classify bed regulation data for patients with COVID-19 from the RegulaRN Platform. The results have made it possible to identify the best model to help health professionals during the process of regulating beds for patients with COVID-19. The scientific findings of this article demonstrate that the computational methods used applied through a digital health solution, can assist in the decision-making of medical regulators and government institutions in situations of public health crisis.},
  archive      = {J_FRAI},
  author       = {Barreto, Tiago de Oliveira and Veras, Nícolas Vinícius Rodrigues and Cardoso, Pablo Holanda and Fernandes, Felipe Ricardo dos Santos and Medeiros, Luiz Paulo de Souza and Bezerra, Maria Valéria and Andrade, Filomena Marques Queiroz de and Pinheiro, Chander de Oliveira and Sánchez-Gendriz, Ignacio and Silva, Gleyson José Pinheiro Caldeira and Rodrigues, Leandro Farias and Morais, Antonio Higor Freire de and dos Santos, João Paulo Queiroz and Paiva, Jailton Carlos and Andrade, Ion Garcia Mascarenhas de and Valentim, Ricardo Alexsandro de Medeiros},
  doi          = {10.3389/frai.2023.1290022},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1290022},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence applied to analyzes during the pandemic: COVID-19 beds occupancy in the state of rio grande do norte, brazil},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhanced sleep staging with artificial intelligence: A
validation study of new software for sleep scoring. <em>FRAI</em>,
<em>6</em>, 1278593. (<a
href="https://doi.org/10.3389/frai.2023.1278593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manual sleep staging (MSS) using polysomnography is a time-consuming task, requires significant training, and can lead to significant variability among scorers. STAGER is a software program based on machine learning algorithms that has been developed by Medibio Limited (Savage, MN, USA) to perform automatic sleep staging using only EEG signals from polysomnography. This study aimed to extensively investigate its agreement with MSS performed during clinical practice and by three additional expert sleep technicians. Forty consecutive polysomnographic recordings of patients referred to three US sleep clinics for sleep evaluation were retrospectively collected and analyzed. Three experienced technicians independently staged the recording using the electroencephalography, electromyography, and electrooculography signals according to the American Academy of Sleep Medicine guidelines. The staging initially performed during clinical practice was also considered. Several agreement statistics between the automatic sleep staging (ASS) and MSS, among the different MSSs, and their differences were calculated. Bootstrap resampling was used to calculate 95% confidence intervals and the statistical significance of the differences. STAGER&#39;s ASS was most comparable with, or statistically significantly better than the MSS, except for a partial reduction in the positive percent agreement in the wake stage. These promising results indicate that STAGER software can perform ASS of inpatient polysomnographic recordings accurately in comparison with MSS.},
  archive      = {J_FRAI},
  author       = {Grassi, Massimiliano and Daccò, Silvia and Caldirola, Daniela and Perna, Giampaolo and Schruers, Koen and Defillo, Archie},
  doi          = {10.3389/frai.2023.1278593},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1278593},
  shortjournal = {Front. Artif. Intell.},
  title        = {Enhanced sleep staging with artificial intelligence: A validation study of new software for sleep scoring},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recognizing protected and anthropogenic patterns in
landscapes using interpretable machine learning and satellite imagery.
<em>FRAI</em>, <em>6</em>, 1278118. (<a
href="https://doi.org/10.3389/frai.2023.1278118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate and comprehensive mapping of land cover has become a central task in modern environmental research, with increasing emphasis on machine learning approaches. However, a clear technical definition of the land cover class is a prerequisite for learning and applying a machine learning model. One of the challenging classes is naturalness and human influence, yet mapping it is important due to its critical role in biodiversity conservation, habitat assessment, and climate change monitoring. We present an interpretable machine learning approach to map patterns related to territorial protected and anthropogenic areas as proxies of naturalness and human influence using satellite imagery. To achieve this, we train a weakly-supervised convolutional neural network and subsequently apply attribution methods such as Grad-CAM and occlusion sensitivity mapping. We propose a novel network architecture that consists of an image-to-image network and a shallow, task-specific head. Both sub-networks are connected by an intermediate layer that captures high-level features in full resolution, allowing for detailed analysis with a wide range of attribution methods. We further analyze how intermediate layer activations relate to their attributions across the training dataset to establish a consistent relationship. This makes attributions consistent across different scenes and allows for a large-scale analysis of remote sensing data. The results highlight that our approach is a promising way to observe and assess naturalness and territorial protection.},
  archive      = {J_FRAI},
  author       = {Stomberg, Timo T. and Leonhardt, Johannes and Weber, Immanuel and Roscher, Ribana},
  doi          = {10.3389/frai.2023.1278118},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1278118},
  shortjournal = {Front. Artif. Intell.},
  title        = {Recognizing protected and anthropogenic patterns in landscapes using interpretable machine learning and satellite imagery},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A topological model for partial equivariance in deep
learning and data analysis. <em>FRAI</em>, <em>6</em>, 1272619. (<a
href="https://doi.org/10.3389/frai.2023.1272619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a topological model to encode partial equivariance in neural networks. To this end, we introduce a class of operators, called P-GENEOs, that change data expressed by measurements, respecting the action of certain sets of transformations, in a non-expansive way. If the set of transformations acting is a group, we obtain the so-called GENEOs. We then study the spaces of measurements, whose domains are subjected to the action of certain self-maps and the space of P-GENEOs between these spaces. We define pseudo-metrics on them and show some properties of the resulting spaces. In particular, we show how such spaces have convenient approximation and convexity properties.},
  archive      = {J_FRAI},
  author       = {Ferrari, Lucia and Frosini, Patrizio and Quercioli, Nicola and Tombari, Francesca},
  doi          = {10.3389/frai.2023.1272619},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1272619},
  shortjournal = {Front. Artif. Intell.},
  title        = {A topological model for partial equivariance in deep learning and data analysis},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Model-agnostic explainable artificial intelligence tools for
severity prediction and symptom analysis on indian COVID-19 data.
<em>FRAI</em>, <em>6</em>, 1272506. (<a
href="https://doi.org/10.3389/frai.2023.1272506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe COVID-19 pandemic had a global impact and created an unprecedented emergency in healthcare and other related frontline sectors. Various Artificial-Intelligence-based models were developed to effectively manage medical resources and identify patients at high risk. However, many of these AI models were limited in their practical high-risk applicability due to their “black-box” nature, i.e., lack of interpretability of the model. To tackle this problem, Explainable Artificial Intelligence (XAI) was introduced, aiming to explore the “black box” behavior of machine learning models and offer definitive and interpretable evidence. XAI provides interpretable analysis in a human-compliant way, thus boosting our confidence in the successful implementation of AI systems in the wild.MethodsIn this regard, this study explores the use of model-agnostic XAI models, such as SHapley Additive exPlanations values (SHAP) and Local Interpretable Model-Agnostic Explanations (LIME), for COVID-19 symptom analysis in Indian patients toward a COVID severity prediction task. Various machine learning models such as Decision Tree Classifier, XGBoost Classifier, and Neural Network Classifier are leveraged to develop Machine Learning models.Results and discussionThe proposed XAI tools are found to augment the high performance of AI systems with human interpretable evidence and reasoning, as shown through the interpretation of various explainability plots. Our comparative analysis illustrates the significance of XAI tools and their impact within a healthcare context. The study suggests that SHAP and LIME analysis are promising methods for incorporating explainability in model development and can lead to better and more trustworthy ML models in the future.},
  archive      = {J_FRAI},
  author       = {Nambiar, Athira and S, Harikrishnaa and S, Sharanprasath},
  doi          = {10.3389/frai.2023.1272506},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1272506},
  shortjournal = {Front. Artif. Intell.},
  title        = {Model-agnostic explainable artificial intelligence tools for severity prediction and symptom analysis on indian COVID-19 data},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fitting a collider in a quantum computer: Tackling the
challenges of quantum machine learning for big datasets. <em>FRAI</em>,
<em>6</em>, 1268852. (<a
href="https://doi.org/10.3389/frai.2023.1268852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current quantum systems have significant limitations affecting the processing of large datasets with high dimensionality, typical of high energy physics. In the present paper, feature and data prototype selection techniques were studied to tackle this challenge. A grid search was performed and quantum machine learning models were trained and benchmarked against classical shallow machine learning methods, trained both in the reduced and the complete datasets. The performance of the quantum algorithms was found to be comparable to the classical ones, even when using large datasets. Sequential Backward Selection and Principal Component Analysis techniques were used for feature&#39;s selection and while the former can produce the better quantum machine learning models in specific cases, it is more unstable. Additionally, we show that such variability in the results is caused by the use of discrete variables, highlighting the suitability of Principal Component analysis transformed data for quantum machine learning applications in the high energy physics context.},
  archive      = {J_FRAI},
  author       = {Peixoto, Miguel Caçador and Castro, Nuno Filipe and Crispim Romão, Miguel and Oliveira, Maria Gabriela Jordão and Ochoa, Inês},
  doi          = {10.3389/frai.2023.1268852},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1268852},
  shortjournal = {Front. Artif. Intell.},
  title        = {Fitting a collider in a quantum computer: Tackling the challenges of quantum machine learning for big datasets},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explainability as the key ingredient for AI adoption in
industry 5.0 settings. <em>FRAI</em>, <em>6</em>, 1264372. (<a
href="https://doi.org/10.3389/frai.2023.1264372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explainable Artificial Intelligence (XAI) has gained significant attention as a means to address the transparency and interpretability challenges posed by black box AI models. In the context of the manufacturing industry, where complex problems and decision-making processes are widespread, the XMANAI platform emerges as a solution to enable transparent and trustworthy collaboration between humans and machines. By leveraging advancements in XAI and catering the prompt collaboration between data scientists and domain experts, the platform enables the construction of interpretable AI models that offer high transparency without compromising performance. This paper introduces the approach to building the XMANAI platform and highlights its potential to resolve the “transparency paradox” of AI. The platform not only addresses technical challenges related to transparency but also caters to the specific needs of the manufacturing industry, including lifecycle management, security, and trusted sharing of AI assets. The paper provides an overview of the XMANAI platform main functionalities, addressing the challenges faced during the development and presenting the evaluation framework to measure the performance of the delivered XAI solutions. It also demonstrates the benefits of the XMANAI approach in achieving transparency in manufacturing decision-making, fostering trust and collaboration between humans and machines, improving operational efficiency, and optimizing business value.},
  archive      = {J_FRAI},
  author       = {Agostinho, Carlos and Dikopoulou, Zoumpolia and Lavasa, Eleni and Perakis, Konstantinos and Pitsios, Stamatis and Branco, Rui and Reji, Sangeetha and Hetterich, Jonas and Biliri, Evmorfia and Lampathaki, Fenareti and Rodríguez Del Rey, Silvia and Gkolemis, Vasileios},
  doi          = {10.3389/frai.2023.1264372},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1264372},
  shortjournal = {Front. Artif. Intell.},
  title        = {Explainability as the key ingredient for AI adoption in industry 5.0 settings},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integrating AI tools in teacher professional learning: A
conceptual model and illustrative case. <em>FRAI</em>, <em>6</em>,
1255089. (<a href="https://doi.org/10.3389/frai.2023.1255089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This conceptual paper aims to explore the complex nature of integrating AI technologies in teacher professional learning, highlighting the potential for AI to synergize teacher noticing and decision-making processes, support adaptive teaching, foster alignment with competence frameworks, and cultivate professional vision, thereby framing teacher practices within the framework of professional vision. We argue that rather than looking at the process of adopting AI solutions by teachers from a technology perspective or how teachers contribute to designing and developing such tools, we take the perspective of the teacher and ask how such tools are meaningfully integrated into teacher practices. In our conceptual paper, we illustrate the case of a novel approach to the teacher training model where the development of teacher&#39; professional vision and professional learning is combined with the design of the AI solutions. We argue the importance of involving teachers into the design of AI solutions through professional learning models to support teachers to develop knowledge-based reasoning skills and at the same time to learn about pedagogical concepts and develop new mental models.},
  archive      = {J_FRAI},
  author       = {Tammets, Kairit and Ley, Tobias},
  doi          = {10.3389/frai.2023.1255089},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1255089},
  shortjournal = {Front. Artif. Intell.},
  title        = {Integrating AI tools in teacher professional learning: A conceptual model and illustrative case},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Metropolis-hastings algorithm in joint-attention naming
game: Experimental semiotics study. <em>FRAI</em>, <em>6</em>, 1235231.
(<a href="https://doi.org/10.3389/frai.2023.1235231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore the emergence of symbols during interactions between individuals through an experimental semiotic study. Previous studies have investigated how humans organize symbol systems through communication using artificially designed subjective experiments. In this study, we focused on a joint-attention-naming game (JA-NG) in which participants independently categorized objects and assigned names while assuming their joint attention. In the Metropolis-Hastings naming game (MHNG) theory, listeners accept provided names according to the acceptance probability computed using the Metropolis-Hastings (MH) algorithm. The MHNG theory suggests that symbols emerge as an approximate decentralized Bayesian inference of signs, which is represented as a shared prior variable if the conditions of the MHNG are satisfied. This study examines whether human participants exhibit behavior consistent with the MHNG theory when playing the JA-NG. By comparing human acceptance decisions of a partner&#39;s naming with acceptance probabilities computed in the MHNG, we tested whether human behavior is consistent with the MHNG theory. The main contributions of this study are twofold. First, we reject the null hypothesis that humans make acceptance judgments with a constant probability, regardless of the acceptance probability calculated by the MH algorithm. The results of this study show that the model with acceptance probability computed by the MH algorithm predicts human behavior significantly better than the model with a constant probability of acceptance. Second, the MH-based model predicted human acceptance/rejection behavior more accurately than four other models (i.e., Constant, Numerator, Subtraction, Binary). Among the models compared, the model using the MH algorithm, which is the only model with the mathematical support of decentralized Bayesian inference, predicted human behavior most accurately, suggesting that symbol emergence in the JA-NG can be explained by the MHNG.},
  archive      = {J_FRAI},
  author       = {Okumura, Ryota and Taniguchi, Tadahiro and Hagiwara, Yoshinobu and Taniguchi, Akira},
  doi          = {10.3389/frai.2023.1235231},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1235231},
  shortjournal = {Front. Artif. Intell.},
  title        = {Metropolis-hastings algorithm in joint-attention naming game: Experimental semiotics study},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated facial characterization and image retrieval by
convolutional neural networks. <em>FRAI</em>, <em>6</em>, 1230383. (<a
href="https://doi.org/10.3389/frai.2023.1230383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionDeveloping efficient methods to infer relations among different faces consisting of numerous expressions or on the same face at different times (e.g., disease progression) is an open issue in imaging related research. In this study, we present a novel method for facial feature extraction, characterization, and identification based on classical computer vision coupled with deep learning and, more specifically, convolutional neural networks.MethodsWe describe the hybrid face characterization system named FRetrAIval (FRAI), which is a hybrid of the GoogleNet and the AlexNet Neural Network (NN) models. Images analyzed by the FRAI network are preprocessed by computer vision techniques such as the oriented gradient-based algorithm that can extract only the face region from any kind of picture. The Aligned Face dataset (AFD) was used to train and test the FRAI solution for extracting image features. The Labeled Faces in the Wild (LFW) holdout dataset has been used for external validation.Results and discussionOverall, in comparison to previous techniques, our methodology has shown much better results on k-Nearest Neighbors (KNN) by yielding the maximum precision, recall, F1, and F2 score values (92.00, 92.66, 92.33, and 92.52%, respectively) for AFD and (95.00% for each variable) for LFW dataset, which were used as training and testing datasets. The FRAI model may be potentially used in healthcare and criminology as well as many other applications where it is important to quickly identify face features such as fingerprint for a specific identification target.},
  archive      = {J_FRAI},
  author       = {Shah, Syed Taimoor Hussain and Shah, Syed Adil Hussain and Qureshi, Shahzad Ahmad and Di Terlizzi, Angelo and Deriu, Marco Agostino},
  doi          = {10.3389/frai.2023.1230383},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1230383},
  shortjournal = {Front. Artif. Intell.},
  title        = {Automated facial characterization and image retrieval by convolutional neural networks},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid computational approach to anticipate individuals in
sequential problem solving. <em>FRAI</em>, <em>6</em>, 1223251. (<a
href="https://doi.org/10.3389/frai.2023.1223251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-awareness is an ever more important requirement for AI systems that are designed to assist humans with daily physical interactions and problem solving. This is especially true for patients that need support to stay as independent as possible. To be human-aware, an AI should be able to anticipate the intentions of the individual humans it interacts with, in order to understand the difficulties and limitations they are facing and to adapt accordingly. While data-driven AI approaches have recently gained a lot of attention, more research is needed on assistive AI systems that can develop models of their partners&#39; goals to offer proactive support without needing a lot of training trials for new problems. We propose an integrated AI system that can anticipate actions of individual humans to contribute to the foundations of trustworthy human-robot interaction. We test this in Tangram, which is an exemplary sequential problem solving task that requires dynamic decision making. In this task the sequences of steps to the goal might be variable and not known by the system. These are aspects that are also recognized as real world challenges for robotic systems. A hybrid approach based on the cognitive architecture ACT-R is presented that is not purely data-driven but includes cognitive principles, meaning heuristics that guide human decisions. Core of this Cognitive Tangram Solver (CTS) framework is an ACT-R cognitive model that simulates human problem solving behavior in action, recognizes possible dead ends and identifies ways forward. Based on this model, the CTS anticipates and adapts its predictions about the next action to take in any given situation. We executed an empirical study and collected data from 40 participants. The predictions made by CTS were evaluated with the participants&#39; behavior, including comparative statistics as well as prediction accuracy. The model&#39;s anticipations compared to the human test data provide support for justifying further steps built upon our conceptual approach.},
  archive      = {J_FRAI},
  author       = {Zamprogno, Giacomo and Dietz, Emmanuelle and Heimisch, Linda and Russwinkel, Nele},
  doi          = {10.3389/frai.2023.1223251},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1223251},
  shortjournal = {Front. Artif. Intell.},
  title        = {A hybrid computational approach to anticipate individuals in sequential problem solving},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical structures emerge from the cultural
transmission: An iterated learning experiment using a non-linguistic
task. <em>FRAI</em>, <em>6</em>, 1221329. (<a
href="https://doi.org/10.3389/frai.2023.1221329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human language is characterized by complex structural features, such as the hierarchical combination of words to form sentences. Although other animals use communication systems, empirical evidence of hierarchical structures is rare. Computational studies of language evolution have suggested that cultural transmission plays a key role in the emergence of structural features in human languages, including hierarchy. While the previous study demonstrated the emergence of hierarchical structures in non-linguistic systems, we argue that their laboratory study may have overestimated the role of cultural transmission because of a lack of appropriate controls and analyses. To directly test the effect of cultural transmission, we conducted an experiment with no cultural transmission as a control (individual condition) in addition to replicating the previous transmission experiment (transmission condition). Our study has added a quantitative analysis of the hierarchical depth. We found that sequences became more structured as the number of generations increased; however, those produced under the transmission condition were more structured than those under the individual condition. These findings suggest that cultural transmission plays an important role in the emergence of hierarchical structures, which cannot be explained by increased learnability alone. The emergence of complex structural properties in human culture, such as language, technology, and music, may have resulted from information transmission processes between different individuals. In conclusion, this study provides evidence of the crucial role of cultural transmission in the emergence of hierarchical structures in non-linguistic communication systems. Our results contribute to the ongoing debate on the origins of human language and the emergence of complex cultural artifacts. The results of this study have implications for the study of cultural evolution and the role of transmission in shaping the emergence of structural features across diverse domains.},
  archive      = {J_FRAI},
  author       = {Nakata, Seiya and Takezawa, Masanori},
  doi          = {10.3389/frai.2023.1221329},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1221329},
  shortjournal = {Front. Artif. Intell.},
  title        = {Hierarchical structures emerge from the cultural transmission: An iterated learning experiment using a non-linguistic task},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cultivation of human centered artificial intelligence:
Culturally adaptive thinking in education (CATE) for AI. <em>FRAI</em>,
<em>6</em>, 1198180. (<a
href="https://doi.org/10.3389/frai.2023.1198180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) has become ubiquitous in human society, and yet vast segments of the global population have no, little, or counterproductive information about AI. It is necessary to teach AI topics on a mass scale. While there is a rush to implement academic initiatives, scant attention has been paid to the unique challenges of teaching AI curricula to a global and culturally diverse audience with varying expectations of privacy, technological autonomy, risk preference, and knowledge sharing. Our study fills this void by focusing on AI elements in a new framework titled Culturally Adaptive Thinking in Education for AI (CATE-AI) to enable teaching AI concepts to culturally diverse learners. Failure to contextualize and sensitize AI education to culture and other categorical human-thought clusters, can lead to several undesirable effects including confusion, AI-phobia, cultural biases to AI, increased resistance toward AI technologies and AI education. We discuss and integrate human behavior theories, AI applications research, educational frameworks, and human centered AI principles to articulate CATE-AI. In the first part of this paper, we present the development a significantly enhanced version of CATE. In the second part, we explore textual data from AI related news articles to generate insights that lay the foundation for CATE-AI, and support our findings. The CATE-AI framework can help learners study artificial intelligence topics more effectively by serving as a basis for adapting and contextualizing AI to their sociocultural needs.},
  archive      = {J_FRAI},
  author       = {Samuel, Yana and Brennan-Tonetta, Margaret and Samuel, Jim and Kashyap, Rajiv and Kumar, Vivek and Krishna Kaashyap, Sri and Chidipothu, Nishitha and Anand, Irawati and Jain, Parth},
  doi          = {10.3389/frai.2023.1198180},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1198180},
  shortjournal = {Front. Artif. Intell.},
  title        = {Cultivation of human centered artificial intelligence: Culturally adaptive thinking in education (CATE) for AI},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Corrigendum: Opportunities for human factors in machine
learning. <em>FRAI</em>, <em>6</em>, 1327954. (<a
href="https://doi.org/10.3389/frai.2023.1327954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Baweja, Jessica A. and Fallon, Corey K. and Jefferson, Brett A.},
  doi          = {10.3389/frai.2023.1327954},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1327954},
  shortjournal = {Front. Artif. Intell.},
  title        = {Corrigendum: Opportunities for human factors in machine learning},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Corrigendum: mPD-APP: A mobile-enabled plant diseases
diagnosis application using convolutional neural network toward the
attainment of a food secure world. <em>FRAI</em>, <em>6</em>, 1325606.
(<a href="https://doi.org/10.3389/frai.2023.1325606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Asani, Emmanuel Oluwatobi and Osadeyi, Yomi Phineas and Adegun, Adekanmi A. and Viriri, Serestina and Ayoola, Joyce A. and Kolawole, Ebenezer Ayorinde},
  doi          = {10.3389/frai.2023.1325606},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1325606},
  shortjournal = {Front. Artif. Intell.},
  title        = {Corrigendum: mPD-APP: a mobile-enabled plant diseases diagnosis application using convolutional neural network toward the attainment of a food secure world},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Knowledge graph technologies: The next frontier
of the food, agriculture, and water domains. <em>FRAI</em>, <em>6</em>,
1319844. (<a href="https://doi.org/10.3389/frai.2023.1319844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Roussey, Catherine and Guéret, Christophe and Laporte, Marie-Angélique},
  doi          = {10.3389/frai.2023.1319844},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1319844},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: knowledge graph technologies: the next frontier of the food, agriculture, and water domains},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Trends and hotspots in research on medical images with deep
learning: A bibliometric analysis from 2013 to 2023. <em>FRAI</em>,
<em>6</em>, 1289669. (<a
href="https://doi.org/10.3389/frai.2023.1289669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundWith the rapid development of the internet, the improvement of computer capabilities, and the continuous advancement of algorithms, deep learning has developed rapidly in recent years and has been widely applied in many fields. Previous studies have shown that deep learning has an excellent performance in image processing, and deep learning-based medical image processing may help solve the difficulties faced by traditional medical image processing. This technology has attracted the attention of many scholars in the fields of computer science and medicine. This study mainly summarizes the knowledge structure of deep learning-based medical image processing research through bibliometric analysis and explores the research hotspots and possible development trends in this field.MethodsRetrieve the Web of Science Core Collection database using the search terms “deep learning,” “medical image processing,” and their synonyms. Use CiteSpace for visual analysis of authors, institutions, countries, keywords, co-cited references, co-cited authors, and co-cited journals.ResultsThe analysis was conducted on 562 highly cited papers retrieved from the database. The trend chart of the annual publication volume shows an upward trend. Pheng-Ann Heng, Hao Chen, and Klaus Hermann Maier-Hein are among the active authors in this field. Chinese Academy of Sciences has the highest number of publications, while the institution with the highest centrality is Stanford University. The United States has the highest number of publications, followed by China. The most frequent keyword is “Deep Learning,” and the highest centrality keyword is “Algorithm.” The most cited author is Kaiming He, and the author with the highest centrality is Yoshua Bengio.ConclusionThe application of deep learning in medical image processing is becoming increasingly common, and there are many active authors, institutions, and countries in this field. Current research in medical image processing mainly focuses on deep learning, convolutional neural networks, classification, diagnosis, segmentation, image, algorithm, and artificial intelligence. The research focus and trends are gradually shifting toward more complex and systematic directions, and deep learning technology will continue to play an important role.},
  archive      = {J_FRAI},
  author       = {Chen, Borui and Jin, Jing and Liu, Haichao and Yang, Zhengyu and Zhu, Haoming and Wang, Yu and Lin, Jianping and Wang, Shizhong and Chen, Shaoqing},
  doi          = {10.3389/frai.2023.1289669},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1289669},
  shortjournal = {Front. Artif. Intell.},
  title        = {Trends and hotspots in research on medical images with deep learning: A bibliometric analysis from 2013 to 2023},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Guiding principles and proposed classification system for
the responsible adoption of artificial intelligence in scientific
writing in medicine. <em>FRAI</em>, <em>6</em>, 1283353. (<a
href="https://doi.org/10.3389/frai.2023.1283353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of large language models (LLMs) and artificial intelligence (AI) into scientific writing, especially in medical literature, presents both unprecedented opportunities and inherent challenges. This manuscript evaluates the transformative potential of LLMs for the synthesis of information, linguistic enhancements, and global knowledge dissemination. At the same time, it raises concerns about unintentional plagiarism, the risk of misinformation, data biases, and an over-reliance on AI. To address these, we propose governing principles for AI adoption that ensure integrity, transparency, validity, and accountability. Additionally, guidelines for reporting AI involvement in manuscript development are delineated, and a classification system to specify the level of AI assistance is introduced. This approach uniquely addresses the challenges of AI in scientific writing, emphasizing transparency in authorship, qualification of AI involvement, and ethical considerations. Concerns regarding access equity, potential biases in AI-generated content, authorship dynamics, and accountability are also explored, emphasizing the human author’s continued responsibility. Recommendations are made for fostering collaboration between AI developers, researchers, and journal editors and for emphasizing the importance of AI’s responsible use in academic writing. Regular evaluations of AI’s impact on the quality and biases of medical manuscripts are also advocated. As we navigate the expanding realm of AI in scientific discourse, it is crucial to maintain the human element of creativity, ethics, and oversight, ensuring that the integrity of scientific literature remains uncompromised.},
  archive      = {J_FRAI},
  author       = {Hryciw, Brett N. and Seely, Andrew J. E. and Kyeremanteng, Kwadwo},
  doi          = {10.3389/frai.2023.1283353},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1283353},
  shortjournal = {Front. Artif. Intell.},
  title        = {Guiding principles and proposed classification system for the responsible adoption of artificial intelligence in scientific writing in medicine},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The unreasonable effectiveness of large language models in
zero-shot semantic annotation of legal texts. <em>FRAI</em>, <em>6</em>,
1279794. (<a href="https://doi.org/10.3389/frai.2023.1279794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of ChatGPT has sensitized the general public, including the legal profession, to large language models&#39; (LLMs) potential uses (e.g., document drafting, question answering, and summarization). Although recent studies have shown how well the technology performs in diverse semantic annotation tasks focused on legal texts, an influx of newer, more capable (GPT-4) or cost-effective (GPT-3.5-turbo) models requires another analysis. This paper addresses recent developments in the ability of LLMs to semantically annotate legal texts in zero-shot learning settings. Given the transition to mature generative AI systems, we examine the performance of GPT-4 and GPT-3.5-turbo(-16k), comparing it to the previous generation of GPT models, on three legal text annotation tasks involving diverse documents such as adjudicatory opinions, contractual clauses, or statutory provisions. We also compare the models&#39; performance and cost to better understand the trade-offs. We found that the GPT-4 model clearly outperforms the GPT-3.5 models on two of the three tasks. The cost-effective GPT-3.5-turbo matches the performance of the 20× more expensive text-davinci-003 model. While one can annotate multiple data points within a single prompt, the performance degrades as the size of the batch increases. This work provides valuable information relevant for many practical applications (e.g., in contract review) and research projects (e.g., in empirical legal studies). Legal scholars and practicing lawyers alike can leverage these findings to guide their decisions in integrating LLMs in a wide range of workflows involving semantic annotation of legal texts.},
  archive      = {J_FRAI},
  author       = {Savelka, Jaromir and Ashley, Kevin D.},
  doi          = {10.3389/frai.2023.1279794},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1279794},
  shortjournal = {Front. Artif. Intell.},
  title        = {The unreasonable effectiveness of large language models in zero-shot semantic annotation of legal texts},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Performance analysis of large language models in the domain
of legal argument mining. <em>FRAI</em>, <em>6</em>, 1278796. (<a
href="https://doi.org/10.3389/frai.2023.1278796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative pre-trained transformers (GPT) have recently demonstrated excellent performance in various natural language tasks. The development of ChatGPT and the recently released GPT-4 model has shown competence in solving complex and higher-order reasoning tasks without further training or fine-tuning. However, the applicability and strength of these models in classifying legal texts in the context of argument mining are yet to be realized and have not been tested thoroughly. In this study, we investigate the effectiveness of GPT-like models, specifically GPT-3.5 and GPT-4, for argument mining via prompting. We closely study the model&#39;s performance considering diverse prompt formulation and example selection in the prompt via semantic search using state-of-the-art embedding models from OpenAI and sentence transformers. We primarily concentrate on the argument component classification task on the legal corpus from the European Court of Human Rights. To address these models&#39; inherent non-deterministic nature and make our result statistically sound, we conducted 5-fold cross-validation on the test set. Our experiments demonstrate, quite surprisingly, that relatively small domain-specific models outperform GPT 3.5 and GPT-4 in the F1-score for premise and conclusion classes, with 1.9% and 12% improvements, respectively. We hypothesize that the performance drop indirectly reflects the complexity of the structure in the dataset, which we verify through prompt and data analysis. Nevertheless, our results demonstrate a noteworthy variation in the performance of GPT models based on prompt formulation. We observe comparable performance between the two embedding models, with a slight improvement in the local model&#39;s ability for prompt selection. This suggests that local models are as semantically rich as the embeddings from the OpenAI model. Our results indicate that the structure of prompts significantly impacts the performance of GPT models and should be considered when designing them.},
  archive      = {J_FRAI},
  author       = {Al Zubaer, Abdullah and Granitzer, Michael and Mitrović, Jelena},
  doi          = {10.3389/frai.2023.1278796},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1278796},
  shortjournal = {Front. Artif. Intell.},
  title        = {Performance analysis of large language models in the domain of legal argument mining},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Considerations on the regulation of AI systems in the
financial sector by the AI act. <em>FRAI</em>, <em>6</em>, 1277544. (<a
href="https://doi.org/10.3389/frai.2023.1277544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proposal for the Artificial Intelligence regulation in the EU (AI Act) is a horizontal legal instrument that aims to regulate, according to a tailored risk-based approach, the development and use of AI systems across a plurality of sectors, including the financial sector. In particular, AI systems intended to be used to evaluate the creditworthiness or establish the credit score of natural persons are classified as “high-risk AI systems”. The proposal, tabled by the Commission in April 2021, is currently at the center of intense interinstitutional negotiations between the two branches of the European legislature, the European Parliament and the Council. Without prejudice to the ongoing legislative deliberations, the paper aims to provide an overview of the main elements and choices made by the Commission in respect of the regulation of AI in the financial sector, as well as of the position taken in that regard by the European Parliament and Council.},
  archive      = {J_FRAI},
  author       = {Mazzini, Gabriele and Bagni, Filippo},
  doi          = {10.3389/frai.2023.1277544},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1277544},
  shortjournal = {Front. Artif. Intell.},
  title        = {Considerations on the regulation of AI systems in the financial sector by the AI act},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Share buybacks: A theoretical exploration of genetic
algorithms and mathematical optionality. <em>FRAI</em>, <em>6</em>,
1276804. (<a href="https://doi.org/10.3389/frai.2023.1276804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article exclusively formulates and presents three innovative hypotheses related to the execution of share buybacks, employing Genetic Algorithms (GAs) and mathematical optimization techniques. Drawing on the foundational contributions of scholars such as Osterrieder, Seigne, Masters, and Guéant, we articulate hypotheses that aim to bring a fresh perspective to share buyback strategies. The first hypothesis examines the potential of GAs to mimic trading schedules, the second posits the optimization of buyback execution as a mathematical problem, and the third underlines the role of optionality in improving performance. These hypotheses do not only offer theoretical insights but also set the stage for empirical examination and practical application, contributing to broader financial innovation. The article does not contain new data or extensive reviews but focuses purely on presenting these original, untested hypotheses, sparking intrigue for future research and exploration.JEL ClassificationG00.},
  archive      = {J_FRAI},
  author       = {Osterrieder, Joerg},
  doi          = {10.3389/frai.2023.1276804},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1276804},
  shortjournal = {Front. Artif. Intell.},
  title        = {Share buybacks: A theoretical exploration of genetic algorithms and mathematical optionality},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application of artificial intelligence in the development of
jamu “traditional indonesian medicine” as a more effective drug.
<em>FRAI</em>, <em>6</em>, 1274975. (<a
href="https://doi.org/10.3389/frai.2023.1274975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Rustandi, Tedi and Prihandiwati, Erna and Nugroho, Fatah and Hayati, Fakhriah and Afriani, Nita and Alfian, Riza and Aisyah, Noor and Niah, Rakhmadhan and Rahim, Aulia and As-Shiddiq, Hasbi},
  doi          = {10.3389/frai.2023.1274975},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1274975},
  shortjournal = {Front. Artif. Intell.},
  title        = {Application of artificial intelligence in the development of jamu “traditional indonesian medicine” as a more effective drug},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An algorithm for computing schubert varieties of best fit
with applications. <em>FRAI</em>, <em>6</em>, 1274830. (<a
href="https://doi.org/10.3389/frai.2023.1274830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose the geometric framework of the Schubert variety as a tool for representing a collection of subspaces of a fixed vector space. Specifically, given a collection of l-dimensional subspaces V1, …, Vr of ℝn, represented as the column spaces of matrices X1, …, Xr, we seek to determine a representative matrix K∈ℝn×k such that each subspace Vi intersects (or comes close to intersecting) the span of the columns of K in at least c dimensions. We formulate a non-convex optimization problem to determine such a K along with associated sets of vectors {ai} and {bi} used to express linear combinations of the columns of the Xi that are close to linear combinations of the columns of K. Further, we present a mechanism for integrating this representation into an artificial neural network architecture as a computational unit (which we refer to as an abstract node). The representative matrix K can be learned in situ, or sequentially, as part of a learning problem. Additionally, the matrix K can be employed as a change of coordinates in the learning problem. The set of all l-dimensional subspaces of ℝn that intersects the span of the columns of K in at least c dimensions is an example of a Schubert subvariety of the Grassmannian GR(l, n). When it is not possible to find a Schubert variety passing through a collection of points on GR(l, n), the goal of the non-convex optimization problem is to find the Schubert variety of best fit, i.e., the Schubert variety that comes as close as possible to the points. This may be viewed as an analog of finding a subspace of best fit to data in a vector space. The approach we take is well-suited to the modeling of collections of sets of data either as a stand-alone Schubert variety of best fit (SVBF), or in the processing workflow of a deep neural network. We present applications to some classification problems on sets of data to illustrate the behavior of the method.},
  archive      = {J_FRAI},
  author       = {Karimov, Karim and Kirby, Michael and Peterson, Chris},
  doi          = {10.3389/frai.2023.1274830},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1274830},
  shortjournal = {Front. Artif. Intell.},
  title        = {An algorithm for computing schubert varieties of best fit with applications},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Configurations of human-centered AI at work: Seven
actor-structure engagements in organizations. <em>FRAI</em>, <em>6</em>,
1272159. (<a href="https://doi.org/10.3389/frai.2023.1272159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PurposeThe discourse on the human-centricity of AI at work needs contextualization. The aim of this study is to distinguish prevalent criteria of human-centricity for AI applications in the scientific discourse and to relate them to the work contexts for which they are specifically intended. This leads to configurations of actor-structure engagements that foster human-centricity in the workplace.Theoretical foundationThe study applies configurational theory to sociotechnical systems’ analysis of work settings. The assumption is that different approaches to promote human-centricity coexist, depending on the stakeholders responsible for their application.MethodThe exploration of criteria indicating human-centricity and their synthesis into configurations is based on a cross-disciplinary literature review following a systematic search strategy and a deductive-inductive qualitative content analysis of 101 research articles.ResultsThe article outlines eight criteria of human-centricity, two of which face challenges of human-centered technology development (trustworthiness and explainability), three challenges of human-centered employee development (prevention of job loss, health, and human agency and augmentation), and three challenges of human-centered organizational development (compensation of systems’ weaknesses, integration of user-domain knowledge, accountability, and safety culture). The configurational theory allows contextualization of these criteria from a higher-order perspective and leads to seven configurations of actor-structure engagements in terms of engagement for (1) data and technostructure, (2) operational process optimization, (3) operators’ employment, (4) employees’ wellbeing, (5) proficiency, (6) accountability, and (7) interactive cross-domain design. Each has one criterion of human-centricity in the foreground. Trustworthiness does not build its own configuration but is proposed to be a necessary condition in all seven configurations.DiscussionThe article contextualizes the overall debate on human-centricity and allows us to specify stakeholder-related engagements and how these complement each other. This is of high value for practitioners bringing human-centricity to the workplace and allows them to compare which criteria are considered in transnational declarations, international norms and standards, or company guidelines.},
  archive      = {J_FRAI},
  author       = {Wilkens, Uta and Lupp, Daniel and Langholf, Valentin},
  doi          = {10.3389/frai.2023.1272159},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1272159},
  shortjournal = {Front. Artif. Intell.},
  title        = {Configurations of human-centered AI at work: Seven actor-structure engagements in organizations},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). COVID-19 and beyond: Leveraging artificial intelligence for
enhanced outbreak control. <em>FRAI</em>, <em>6</em>, 1266560. (<a
href="https://doi.org/10.3389/frai.2023.1266560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 has brought significant changes to our political, social, and technological landscape. This paper explores the emergence and global spread of the disease and focuses on the role of Artificial Intelligence (AI) in containing its transmission. To the best of our knowledge, there has been no scientific presentation of the early pictorial representation of the disease&#39;s spread. Additionally, we outline various domains where AI has made a significant impact during the pandemic. Our methodology involves searching relevant articles on COVID-19 and AI in leading databases such as PubMed and Scopus to identify the ways AI has addressed pandemic-related challenges and its potential for further assistance. While research suggests that AI has not fully realized its potential against COVID-19, likely due to data quality and diversity limitations, we review and identify key areas where AI has been crucial in preparing the fight against any sudden outbreak of the pandemic. We also propose ways to maximize the utilization of AI&#39;s capabilities in this regard.},
  archive      = {J_FRAI},
  author       = {Farhat, Faiza and Sohail, Shahab Saquib and Alam, Mohammed Talha and Ubaid, Syed and Shakil, and Ashhad, Mohd and Madsen, Dag Øivind},
  doi          = {10.3389/frai.2023.1266560},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1266560},
  shortjournal = {Front. Artif. Intell.},
  title        = {COVID-19 and beyond: Leveraging artificial intelligence for enhanced outbreak control},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning with privileged and sensitive information: A
gradient-boosting approach. <em>FRAI</em>, <em>6</em>, 1260583. (<a
href="https://doi.org/10.3389/frai.2023.1260583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of learning with sensitive features under the privileged information setting where the goal is to learn a classifier that uses features not available (or too sensitive to collect) at test/deployment time to learn a better model at training time. We focus on tree-based learners, specifically gradient-boosted decision trees for learning with privileged information. Our methods use privileged features as knowledge to guide the algorithm when learning from fully observed (usable) features. We derive the theory, empirically validate the effectiveness of our algorithms, and verify them on standard fairness metrics.},
  archive      = {J_FRAI},
  author       = {Yan, Siwen and Odom, Phillip and Pasunuri, Rahul and Kersting, Kristian and Natarajan, Sriraam},
  doi          = {10.3389/frai.2023.1260583},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1260583},
  shortjournal = {Front. Artif. Intell.},
  title        = {Learning with privileged and sensitive information: A gradient-boosting approach},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Understanding the need for digital twins’ data in patient
advocacy and forecasting oncology. <em>FRAI</em>, <em>6</em>, 1260361.
(<a href="https://doi.org/10.3389/frai.2023.1260361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital twins are made of a real-world component where data is measured and a virtual component where those measurements are used to parameterize computational models. There is growing interest in applying digital twins-based approaches to optimize personalized treatment plans and improve health outcomes. The integration of artificial intelligence is critical in this process, as it enables the development of sophisticated disease models that can accurately predict patient response to therapeutic interventions. There is a unique and equally important application of AI to the real-world component of a digital twin when it is applied to medical interventions. The patient can only be treated once, and therefore, we must turn to the experience and outcomes of previously treated patients for validation and optimization of the computational predictions. The physical component of a digital twins instead must utilize a compilation of available data from previously treated cancer patients whose characteristics (genetics, tumor type, lifestyle, etc.) closely parallel those of a newly diagnosed cancer patient for the purpose of predicting outcomes, stratifying treatment options, predicting responses to treatment and/or adverse events. These tasks include the development of robust data collection methods, ensuring data availability, creating precise and dependable models, and establishing ethical guidelines for the use and sharing of data. To successfully implement digital twin technology in clinical care, it is crucial to gather data that accurately reflects the variety of diseases and the diversity of the population.},
  archive      = {J_FRAI},
  author       = {Chang, Hung-Ching and Gitau, Antony M. and Kothapalli, Siri and Welch, Danny R. and Sardiu, Mihaela E. and McCoy, Matthew D.},
  doi          = {10.3389/frai.2023.1260361},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1260361},
  shortjournal = {Front. Artif. Intell.},
  title        = {Understanding the need for digital twins’ data in patient advocacy and forecasting oncology},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph embedding and geometric deep learning relevance to
network biology and structural chemistry. <em>FRAI</em>, <em>6</em>,
1256352. (<a href="https://doi.org/10.3389/frai.2023.1256352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs are used as a model of complex relationships among data in biological science since the advent of systems biology in the early 2000. In particular, graph data analysis and graph data mining play an important role in biology interaction networks, where recent techniques of artificial intelligence, usually employed in other type of networks (e.g., social, citations, and trademark networks) aim to implement various data mining tasks including classification, clustering, recommendation, anomaly detection, and link prediction. The commitment and efforts of artificial intelligence research in network biology are motivated by the fact that machine learning techniques are often prohibitively computational demanding, low parallelizable, and ultimately inapplicable, since biological network of realistic size is a large system, which is characterised by a high density of interactions and often with a non-linear dynamics and a non-Euclidean latent geometry. Currently, graph embedding emerges as the new learning paradigm that shifts the tasks of building complex models for classification, clustering, and link prediction to learning an informative representation of the graph data in a vector space so that many graph mining and learning tasks can be more easily performed by employing efficient non-iterative traditional models (e.g., a linear support vector machine for the classification task). The great potential of graph embedding is the main reason of the flourishing of studies in this area and, in particular, the artificial intelligence learning techniques. In this mini review, we give a comprehensive summary of the main graph embedding algorithms in light of the recent burgeoning interest in geometric deep learning.},
  archive      = {J_FRAI},
  author       = {Lecca, Paola and Lecca, Michela},
  doi          = {10.3389/frai.2023.1256352},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1256352},
  shortjournal = {Front. Artif. Intell.},
  title        = {Graph embedding and geometric deep learning relevance to network biology and structural chemistry},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Locally linear attributes of ReLU neural networks.
<em>FRAI</em>, <em>6</em>, 1255192. (<a
href="https://doi.org/10.3389/frai.2023.1255192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A ReLU neural network functions as a continuous piecewise linear map from an input space to an output space. The weights in the neural network determine a partitioning of the input space into convex polytopes, where each polytope is associated with a distinct affine mapping. The structure of this partitioning, together with the affine map attached to each polytope, can be analyzed to investigate the behavior of the associated neural network. We investigate simple problems to build intuition on how these regions act and both how they can potentially be reduced in number and how similar structures occur across different networks. To validate these intuitions, we apply them to networks trained on MNIST to demonstrate similarity between those networks and the potential for them to be reduced in complexity.},
  archive      = {J_FRAI},
  author       = {Sattelberg, Ben and Cavalieri, Renzo and Kirby, Michael and Peterson, Chris and Beveridge, Ross},
  doi          = {10.3389/frai.2023.1255192},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1255192},
  shortjournal = {Front. Artif. Intell.},
  title        = {Locally linear attributes of ReLU neural networks},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Training in new forms of human-AI interaction improves
complex working memory and switching skills of language professionals.
<em>FRAI</em>, <em>6</em>, 1253940. (<a
href="https://doi.org/10.3389/frai.2023.1253940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AI-related technologies used in the language industry, including automatic speech recognition (ASR) and machine translation (MT), are designed to improve human efficiency. However, humans are still in the loop for accuracy and quality, creating a working environment based on Human-AI Interaction (HAII). Very little is known about these newly-created working environments and their effects on cognition. The present study focused on a novel practice, interlingual respeaking (IRSP), where real-time subtitles in another language are created through the interaction between a human and ASR software. To this end, we set up an experiment that included a purpose-made training course on IRSP over 5 weeks, investigating its effects on cognition, and focusing on executive functioning (EF) and working memory (WM). We compared the cognitive performance of 51 language professionals before and after the course. Our variables were reading span (a complex WM measure), switching skills, and sustained attention. IRSP training course improved complex WM and switching skills but not sustained attention. However, the participants were slower after the training, indicating increased vigilance with the sustained attention tasks. Finally, complex WM was confirmed as the primary competence in IRSP. The reasons and implications of these findings will be discussed.},
  archive      = {J_FRAI},
  author       = {Wallinheimo, Anna-Stiina and Evans, Simon L. and Davitti, Elena},
  doi          = {10.3389/frai.2023.1253940},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1253940},
  shortjournal = {Front. Artif. Intell.},
  title        = {Training in new forms of human-AI interaction improves complex working memory and switching skills of language professionals},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Humans and cyber-physical systems as teammates?
Characteristics and applicability of the human-machine-teaming concept
in intelligent manufacturing. <em>FRAI</em>, <em>6</em>, 1247755. (<a
href="https://doi.org/10.3389/frai.2023.1247755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper explores and comments on the theoretical concept of human-machine-teaming in intelligent manufacturing. Industrial production is an important area of work applications and should be developed toward a more anthropocentric Industry 4.0/5.0. Teaming is used a design metaphor for human-centered integration of workers and complex cyber-physical-production systems using artificial intelligence. Concrete algorithmic solutions for technical processes should be based on theoretical concepts. A combination of literature scoping review and commentary was used to identify key characteristics for teaming applicable to the work environment addressed. From the body of literature, five criteria were selected and commented on. Two characteristics seemed particularly promising to guide the development of human-centered artificial intelligence and create tangible benefits in the mid-term: complementarity and shared knowledge/goals. These criteria are outlined with two industrial examples: human-robot-collaboration in assembly and intelligent decision support in thermal spraying. The main objective of the paper is to contribute to the discourse on human-centered artificial intelligence by exploring the theoretical concept of human-machine-teaming from a human-oriented perspective. Future research should focus on the empirical implementation and evaluation of teaming characteristics from different transdisciplinary viewpoints.},
  archive      = {J_FRAI},
  author       = {Bocklisch, Franziska and Huchler, Norbert},
  doi          = {10.3389/frai.2023.1247755},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1247755},
  shortjournal = {Front. Artif. Intell.},
  title        = {Humans and cyber-physical systems as teammates? characteristics and applicability of the human-machine-teaming concept in intelligent manufacturing},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Does artificial intelligence kill employment growth: The
missing link of corporate AI posture. <em>FRAI</em>, <em>6</em>,
1239466. (<a href="https://doi.org/10.3389/frai.2023.1239466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionAn intense debate has been on-going about how artificial intelligence (AI) technology investments have an impact on employment. The debate has often focused on the potential of AI for human task automation, omitting the strategic incentive for firms to cooperate with their workers as to exploit AI technologies for the most relevant benefit of new product and service innovation.MethodWe calibrate an empirical probit regression model of how changes in employment relate to AI diffusion, based on formalizing a game-theoretical model of a firm exploiting the twin role of AI innovation and AI automation for both absolute and competitive advantage.ResultsThe theoretical game-theory prediction is that employment following AI technology adoption is not negative, and ultimately depends on how AI leads to new success in innovation, competition which defines the competitive reward of innovation and profit sharing between workers and firms. Our estimation, is based on a global survey of 3,000 large companies across 10 countries, demonstrates that a firm employment growth depends on two strategic postures, that is, the firm relative maturity of AI adoption as well as its relative bias toward AI-based product innovation.DiscussionThe contribution of this research is to highlight the twin role of firm and workers in shaping how technology will affect employment. AI in particular marries the potential of task automation with even more potential for expansion.},
  archive      = {J_FRAI},
  author       = {Bughin, Jacques},
  doi          = {10.3389/frai.2023.1239466},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1239466},
  shortjournal = {Front. Artif. Intell.},
  title        = {Does artificial intelligence kill employment growth: The missing link of corporate AI posture},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Features of lexical complexity: Insights from l1 and l2
speakers. <em>FRAI</em>, <em>6</em>, 1236963. (<a
href="https://doi.org/10.3389/frai.2023.1236963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We discover sizable differences between the lexical complexity assignments of first language (L1) and second language (L2) English speakers. The complexity assignments of 940 shared tokens without context were extracted and compared from three lexical complexity prediction (LCP) datasets: the CompLex dataset, the Word Complexity Lexicon, and the CERF-J wordlist. It was found that word frequency, length, syllable count, familiarity, and prevalence as well as a number of derivations had a greater effect on perceived lexical complexity for L2 English speakers than they did for L1 English speakers. We explain these findings in connection to several theories from applied linguistics and then use these findings to inform a binary classifier that is trained to distinguish between spelling errors made by L1 and L2 English speakers. Our results indicate that several of our findings are generalizable. Differences in perceived lexical complexity are shown to be useful in the automatic identification of problematic words for these differing target populations. This gives support to the development of personalized lexical complexity prediction and text simplification systems.},
  archive      = {J_FRAI},
  author       = {North, Kai and Zampieri, Marcos},
  doi          = {10.3389/frai.2023.1236963},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1236963},
  shortjournal = {Front. Artif. Intell.},
  title        = {Features of lexical complexity: Insights from l1 and l2 speakers},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Corrigendum: The impact of pedagogical agents’ gender on
academic learning: A systematic review. <em>FRAI</em>, <em>6</em>,
1302277. (<a href="https://doi.org/10.3389/frai.2023.1302277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Armando, Marjorie and Ochs, Magalie and Régner, Isabelle},
  doi          = {10.3389/frai.2023.1302277},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1302277},
  shortjournal = {Front. Artif. Intell.},
  title        = {Corrigendum: the impact of pedagogical agents&#39; gender on academic learning: a systematic review},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Women in language and computation 2022.
<em>FRAI</em>, <em>6</em>, 1299100. (<a
href="https://doi.org/10.3389/frai.2023.1299100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Loughran, Róisín and Shah, Huma and Monti, Johanna and Zhitomirsky-Geffet, Maayan},
  doi          = {10.3389/frai.2023.1299100},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1299100},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Women in language and computation 2022},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence as the new frontier in chemical risk
assessment. <em>FRAI</em>, <em>6</em>, 1269932. (<a
href="https://doi.org/10.3389/frai.2023.1269932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid progress of AI impacts various areas of life, including toxicology, and promises a major role for AI in future risk assessments. Toxicology has shifted from a purely empirical science focused on observing chemical exposure outcomes to a data-rich field ripe for AI integration. AI methods are well-suited to handling and integrating large, diverse data volumes - a key challenge in modern toxicology. Additionally, AI enables Predictive Toxicology, as demonstrated by the automated read-across tool RASAR that achieved 87% balanced accuracy across nine OECD tests and 190,000 chemicals, outperforming animal test reproducibility. AI’s ability to handle big data and provide probabilistic outputs facilitates probabilistic risk assessment. Rather than just replicating human skills at larger scales, AI should be viewed as a transformative technology. Despite potential challenges, like model black-boxing and dataset biases, explainable AI (xAI) is emerging to address these issues.},
  archive      = {J_FRAI},
  author       = {Hartung, Thomas},
  doi          = {10.3389/frai.2023.1269932},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1269932},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence as the new frontier in chemical risk assessment},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). What is critical for human-centered AI at work? – toward an
interdisciplinary theory. <em>FRAI</em>, <em>6</em>, 1257057. (<a
href="https://doi.org/10.3389/frai.2023.1257057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-centered artificial intelligence (HCAI) has gained momentum in the scientific discourse but still lacks clarity. In particular, disciplinary differences regarding the scope of HCAI have become apparent and were criticized, calling for a systematic mapping of conceptualizations—especially with regard to the work context. This article compares how human factors and ergonomics (HFE), psychology, human-computer interaction (HCI), information science, and adult education view HCAI and discusses their normative, theoretical, and methodological approaches toward HCAI, as well as the implications for research and practice. It will be argued that an interdisciplinary approach is critical for developing, transferring, and implementing HCAI at work. Additionally, it will be shown that the presented disciplines are well-suited for conceptualizing HCAI and bringing it into practice since they are united in one aspect: they all place the human being in the center of their theory and research. Many critical aspects for successful HCAI, as well as minimum fields of action, were further identified, such as human capability and controllability (HFE perspective), autonomy and trust (psychology and HCI perspective), learning and teaching designs across target groups (adult education perspective), as much as information behavior and information literacy (information science perspective). As such, the article lays the ground for a theory of human-centered interdisciplinary AI, i.e., the Synergistic Human-AI Symbiosis Theory (SHAST), whose conceptual framework and founding pillars will be introduced.},
  archive      = {J_FRAI},
  author       = {Mazarakis, Athanasios and Bernhard-Skala, Christian and Braun, Martin and Peters, Isabella},
  doi          = {10.3389/frai.2023.1257057},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1257057},
  shortjournal = {Front. Artif. Intell.},
  title        = {What is critical for human-centered AI at work? – toward an interdisciplinary theory},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: AI applications for diagnosis of breast cancer.
<em>FRAI</em>, <em>6</em>, 1247261. (<a
href="https://doi.org/10.3389/frai.2023.1247261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Muhammad, L. J. and Bria, Alessandro},
  doi          = {10.3389/frai.2023.1247261},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1247261},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: AI applications for diagnosis of breast cancer},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multimodal deep learning for liver cancer applications: A
scoping review. <em>FRAI</em>, <em>6</em>, 1247195. (<a
href="https://doi.org/10.3389/frai.2023.1247195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundHepatocellular carcinoma is a malignant neoplasm of the liver and a leading cause of cancer-related deaths worldwide. The multimodal data combines several modalities, such as medical images, clinical parameters, and electronic health record (EHR) reports, from diverse sources to accomplish the diagnosis of liver cancer. The introduction of deep learning models with multimodal data can enhance the diagnosis and improve physicians&#39; decision-making for cancer patients.ObjectiveThis scoping review explores the use of multimodal deep learning techniques (i.e., combining medical images and EHR data) in diagnosing and prognosis of hepatocellular carcinoma (HCC) and cholangiocarcinoma (CCA).MethodologyA comprehensive literature search was conducted in six databases along with forward and backward references list checking of the included studies. PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) extension for scoping review guidelines were followed for the study selection process. The data was extracted and synthesized from the included studies through thematic analysis.ResultsTen studies were included in this review. These studies utilized multimodal deep learning to predict and diagnose hepatocellular carcinoma (HCC), but no studies examined cholangiocarcinoma (CCA). Four imaging modalities (CT, MRI, WSI, and DSA) and 51 unique EHR records (clinical parameters and biomarkers) were used in these studies. The most frequently used medical imaging modalities were CT scans followed by MRI, whereas the most common EHR parameters used were age, gender, alpha-fetoprotein AFP, albumin, coagulation factors, and bilirubin. Ten unique deep-learning techniques were applied to both EHR modalities and imaging modalities for two main purposes, prediction and diagnosis.ConclusionThe use of multimodal data and deep learning techniques can help in the diagnosis and prediction of HCC. However, there is a limited number of works and available datasets for liver cancer, thus limiting the overall advancements of AI for liver cancer applications. Hence, more research should be undertaken to explore further the potential of multimodal deep learning in liver cancer applications.},
  archive      = {J_FRAI},
  author       = {Siam, Aisha and Alsaify, Abdel Rahman and Mohammad, Bushra and Biswas, Md. Rafiul and Ali, Hazrat and Shah, Zubair},
  doi          = {10.3389/frai.2023.1247195},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1247195},
  shortjournal = {Front. Artif. Intell.},
  title        = {Multimodal deep learning for liver cancer applications: A scoping review},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fog computing: A platform for big-data marketing analytics.
<em>FRAI</em>, <em>6</em>, 1242574. (<a
href="https://doi.org/10.3389/frai.2023.1242574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Marketing science embraces a wider variety of data types and measurement tools necessary for strategy, research, and applied decision making. Managing the marketing data generated by internet of things (IoT) sensors and actuators is one of the biggest challenges faced by marketing managers when deploying an IoT system. This short note shows how traditional cloud-based IoT systems are challenged by the large scale, heterogeneity, and high latency witnessed in some cloud ecosystems. It introduces researchers to one recent breakthrough, fog computing, an emerging concept that decentralizes applications, strategies, and data analytics into the network itself using a distributed and federated computing model. It transforms centralized cloud to distributed fog by bringing storage and computation closer to the user end. Fog computing is considered a novel marketplace phenomenon which can support AI and management strategies, especially for the design of “smart marketing”.},
  archive      = {J_FRAI},
  author       = {Hornik, Jacob and Rachamim, Matti and Graguer, Sergei},
  doi          = {10.3389/frai.2023.1242574},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1242574},
  shortjournal = {Front. Artif. Intell.},
  title        = {Fog computing: A platform for big-data marketing analytics},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). First impressions of a financial AI assistant: Differences
between high trust and low trust users. <em>FRAI</em>, <em>6</em>,
1241290. (<a href="https://doi.org/10.3389/frai.2023.1241290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Calibrating appropriate trust of non-expert users in artificial intelligence (AI) systems is a challenging yet crucial task. To align subjective levels of trust with the objective trustworthiness of a system, users need information about its strengths and weaknesses. The specific explanations that help individuals avoid over- or under-trust may vary depending on their initial perceptions of the system. In an online study, 127 participants watched a video of a financial AI assistant with varying degrees of decision agency. They generated 358 spontaneous text descriptions of the system and completed standard questionnaires from the Trust in Automation and Technology Acceptance literature (including perceived system competence, understandability, human-likeness, uncanniness, intention of developers, intention to use, and trust). Comparisons between a high trust and a low trust user group revealed significant differences in both open-ended and closed-ended answers. While high trust users characterized the AI assistant as more useful, competent, understandable, and humanlike, low trust users highlighted the system&#39;s uncanniness and potential dangers. Manipulating the AI assistant&#39;s agency had no influence on trust or intention to use. These findings are relevant for effective communication about AI and trust calibration of users who differ in their initial levels of trust.},
  archive      = {J_FRAI},
  author       = {Schreibelmayr, Simon and Moradbakhti, Laura and Mara, Martina},
  doi          = {10.3389/frai.2023.1241290},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1241290},
  shortjournal = {Front. Artif. Intell.},
  title        = {First impressions of a financial AI assistant: Differences between high trust and low trust users},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The energy challenges of artificial superintelligence.
<em>FRAI</em>, <em>6</em>, 1240653. (<a
href="https://doi.org/10.3389/frai.2023.1240653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We argue here that contemporary semiconductor computing technology poses a significant if not insurmountable barrier to the emergence of any artificial general intelligence system, let alone one anticipated by many to be “superintelligent”. This limit on artificial superintelligence (ASI) emerges from the energy requirements of a system that would be more intelligent but orders of magnitude less efficient in energy use than human brains. An ASI would have to supersede not only a single brain but a large population given the effects of collective behavior on the advancement of societies, further multiplying the energy requirement. A hypothetical ASI would likely consume orders of magnitude more energy than what is available in highly-industrialized nations. We estimate the energy use of ASI with an equation we term the “Erasi equation”, for the Energy Requirement for Artificial SuperIntelligence. Additional efficiency consequences will emerge from the current unfocussed and scattered developmental trajectory of AI research. Taken together, these arguments suggest that the emergence of an ASI is highly unlikely in the foreseeable future based on current computer architectures, primarily due to energy constraints, with biomimicry or other new technologies being possible solutions.},
  archive      = {J_FRAI},
  author       = {Stiefel, Klaus M. and Coggan, Jay S.},
  doi          = {10.3389/frai.2023.1240653},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1240653},
  shortjournal = {Front. Artif. Intell.},
  title        = {The energy challenges of artificial superintelligence},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Overview of chatbots with special emphasis on artificial
intelligence-enabled ChatGPT in medical science. <em>FRAI</em>,
<em>6</em>, 1237704. (<a
href="https://doi.org/10.3389/frai.2023.1237704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The release of ChatGPT has initiated new thinking about AI-based Chatbot and its application and has drawn huge public attention worldwide. Researchers and doctors have started thinking about the promise and application of AI-related large language models in medicine during the past few months. Here, the comprehensive review highlighted the overview of Chatbot and ChatGPT and their current role in medicine. Firstly, the general idea of Chatbots, their evolution, architecture, and medical use are discussed. Secondly, ChatGPT is discussed with special emphasis of its application in medicine, architecture and training methods, medical diagnosis and treatment, research ethical issues, and a comparison of ChatGPT with other NLP models are illustrated. The article also discussed the limitations and prospects of ChatGPT. In the future, these large language models and ChatGPT will have immense promise in healthcare. However, more research is needed in this direction.},
  archive      = {J_FRAI},
  author       = {Chakraborty, Chiranjib and Pal, Soumen and Bhattacharya, Manojit and Dash, Snehasish and Lee, Sang-Soo},
  doi          = {10.3389/frai.2023.1237704},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1237704},
  shortjournal = {Front. Artif. Intell.},
  title        = {Overview of chatbots with special emphasis on artificial intelligence-enabled ChatGPT in medical science},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence-driven approach for patient-focused
drug development. <em>FRAI</em>, <em>6</em>, 1237124. (<a
href="https://doi.org/10.3389/frai.2023.1237124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patients&#39; increasing digital participation provides an opportunity to pursue patient-centric research and drug development by understanding their needs. Social media has proven to be one of the most useful data sources when it comes to understanding a company&#39;s potential audience to drive more targeted impact. Navigating through an ocean of information is a tedious task where techniques such as artificial intelligence and text analytics have proven effective in identifying relevant posts for healthcare business questions. Here, we present an enterprise-ready, scalable solution demonstrating the feasibility and utility of social media-based patient experience data for use in research and development through capturing and assessing patient experiences and expectations on disease, treatment options, and unmet needs while creating a playbook for roll-out to other indications and therapeutic areas.},
  archive      = {J_FRAI},
  author       = {Karmalkar, Prathamesh and Gurulingappa, Harsha and Spies, Erica and Flynn, Jennifer A.},
  doi          = {10.3389/frai.2023.1237124},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1237124},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence-driven approach for patient-focused drug development},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stacked ensemble deep learning for pancreas cancer
classification using extreme gradient boosting. <em>FRAI</em>,
<em>6</em>, 1232640. (<a
href="https://doi.org/10.3389/frai.2023.1232640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble learning aims to improve prediction performance by combining several models or forecasts. However, how much and which ensemble learning techniques are useful in deep learning-based pipelines for pancreas computed tomography (CT) image classification is a challenge. Ensemble approaches are the most advanced solution to many machine learning problems. These techniques entail training multiple models and combining their predictions to improve the predictive performance of a single model. This article introduces the idea of Stacked Ensemble Deep Learning (SEDL), a pipeline for classifying pancreas CT medical images. The weak learners are Inception V3, VGG16, and ResNet34, and we employed a stacking ensemble. By combining the first-level predictions, an input train set for XGBoost, the ensemble model at the second level of prediction, is created. Extreme Gradient Boosting (XGBoost), employed as a strong learner, will make the final classification. Our findings showed that SEDL performed better, with a 98.8% ensemble accuracy, after some adjustments to the hyperparameters. The Cancer Imaging Archive (TCIA) public access dataset consists of 80 pancreas CT scans with a resolution of 512 * 512 pixels, from 53 male and 27 female subjects. A sample of two hundred and twenty-two images was used for training and testing data. We concluded that implementing the SEDL technique is an effective way to strengthen the robustness and increase the performance of the pipeline for classifying pancreas CT medical images. Interestingly, grouping like-minded or talented learners does not make a difference.},
  archive      = {J_FRAI},
  author       = {Bakasa, Wilson and Viriri, Serestina},
  doi          = {10.3389/frai.2023.1232640},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1232640},
  shortjournal = {Front. Artif. Intell.},
  title        = {Stacked ensemble deep learning for pancreas cancer classification using extreme gradient boosting},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Revisiting the political biases of ChatGPT. <em>FRAI</em>,
<em>6</em>, 1232003. (<a
href="https://doi.org/10.3389/frai.2023.1232003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although ChatGPT promises wide-ranging applications, there is a concern that it is politically biased; in particular, that it has a left-libertarian orientation. Nevertheless, following recent trends in attempts to reduce such biases, this study re-evaluated the political biases of ChatGPT using political orientation tests and the application programming interface. The effects of the languages used in the system as well as gender and race settings were evaluated. The results indicate that ChatGPT manifests less political bias than previously assumed; however, they did not entirely dismiss the political bias. The languages used in the system, and the gender and race settings may induce political biases. These findings enhance our understanding of the political biases of ChatGPT and may be useful for bias evaluation and designing the operational strategy of ChatGPT.},
  archive      = {J_FRAI},
  author       = {Fujimoto, Sasuke and Takemoto, Kazuhiro},
  doi          = {10.3389/frai.2023.1232003},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1232003},
  shortjournal = {Front. Artif. Intell.},
  title        = {Revisiting the political biases of ChatGPT},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Air pollution particulate matter (PM2.5) prediction in south
african cities using machine learning techniques. <em>FRAI</em>,
<em>6</em>, 1230087. (<a
href="https://doi.org/10.3389/frai.2023.1230087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundAir pollution contributes to the most severe environmental and health problems due to industrial emissions and atmosphere contamination, produced by climate and traffic factors, fossil fuel combustion, and industrial characteristics. Because this is a global issue, several nations have established control of air pollution stations in various cities to monitor pollutants like Nitrogen Dioxide (NO2), Ozone (O3), Sulfur Dioxide (SO2), Carbon Monoxide (CO), Particulate Matter (PM2.5, PM10), to notify inhabitants when pollution levels surpass the quality threshold. With the rise in air pollution, it is necessary to construct models to capture data on air pollutant concentrations. Compared to other parts of the world, Africa has a scarcity of reliable air quality sensors for monitoring and predicting Particulate Matter (PM2.5). This demonstrates the possibility of extending research in air pollution control.MethodsMachine learning techniques were utilized in this study to identify air pollution in terms of time, cost, and efficiency so that different scenarios and systems may select the optimal way for their needs. To assess and forecast the behavior of Particulate Matter (PM2.5), this study presented a Machine Learning approach that includes Cat Boost Regressor, Extreme Gradient Boosting Regressor, Random Forest Classifier, Logistic Regression, Support Vector Machine, K-Nearest Neighbor, and Decision Tree.ResultsCat Boost Regressor and Extreme Gradient Boosting Regressor were implemented to predict the latest PM2.5 concentrations for South African Cities with recording stations using past dated recordings, then the best performing model between the two is used to predict PM2.5 concentrations for South African Cities with no recording stations and also to predict future PM2.5 concentrations for South African Cities. K-Nearest Neighbor, Logistic Regression, Support Vector Machine, Decision Tree, and Random Forest Classifier were implemented to create a system predicting the Air Quality Index (AQI) Status.ConclusionThis study investigated various machine learning techniques for air pollution to analyze and predict air pollution behavior regarding air quality and air pollutants, detecting which areas are most affected in South African cities.},
  archive      = {J_FRAI},
  author       = {Morapedi, Tshepang Duncan and Obagbuwa, Ibidun Christiana},
  doi          = {10.3389/frai.2023.1230087},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1230087},
  shortjournal = {Front. Artif. Intell.},
  title        = {Air pollution particulate matter (PM2.5) prediction in south african cities using machine learning techniques},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of the explainability and safety of conversational
agents for mental health to identify avenues for improvement.
<em>FRAI</em>, <em>6</em>, 1229805. (<a
href="https://doi.org/10.3389/frai.2023.1229805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual Mental Health Assistants (VMHAs) continuously evolve to support the overloaded global healthcare system, which receives approximately 60 million primary care visits and 6 million emergency room visits annually. These systems, developed by clinical psychologists, psychiatrists, and AI researchers, are designed to aid in Cognitive Behavioral Therapy (CBT). The main focus of VMHAs is to provide relevant information to mental health professionals (MHPs) and engage in meaningful conversations to support individuals with mental health conditions. However, certain gaps prevent VMHAs from fully delivering on their promise during active communications. One of the gaps is their inability to explain their decisions to patients and MHPs, making conversations less trustworthy. Additionally, VMHAs can be vulnerable in providing unsafe responses to patient queries, further undermining their reliability. In this review, we assess the current state of VMHAs on the grounds of user-level explainability and safety, a set of desired properties for the broader adoption of VMHAs. This includes the examination of ChatGPT, a conversation agent developed on AI-driven models: GPT3.5 and GPT-4, that has been proposed for use in providing mental health services. By harnessing the collaborative and impactful contributions of AI, natural language processing, and the mental health professionals (MHPs) community, the review identifies opportunities for technological progress in VMHAs to ensure their capabilities include explainable and safe behaviors. It also emphasizes the importance of measures to guarantee that these advancements align with the promise of fostering trustworthy conversations.},
  archive      = {J_FRAI},
  author       = {Sarkar, Surjodeep and Gaur, Manas and Chen, Lujie Karen and Garg, Muskan and Srivastava, Biplav},
  doi          = {10.3389/frai.2023.1229805},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1229805},
  shortjournal = {Front. Artif. Intell.},
  title        = {A review of the explainability and safety of conversational agents for mental health to identify avenues for improvement},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recursive metropolis-hastings naming game: Symbol emergence
in a multi-agent system based on probabilistic generative models.
<em>FRAI</em>, <em>6</em>, 1229127. (<a
href="https://doi.org/10.3389/frai.2023.1229127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the studies on symbol emergence and emergent communication in a population of agents, a computational model was employed in which agents participate in various language games. Among these, the Metropolis-Hastings naming game (MHNG) possesses a notable mathematical property: symbol emergence through MHNG is proven to be a decentralized Bayesian inference of representations shared by the agents. However, the previously proposed MHNG is limited to a two-agent scenario. This paper extends MHNG to an N-agent scenario. The main contributions of this paper are twofold: (1) we propose the recursive Metropolis-Hastings naming game (RMHNG) as an N-agent version of MHNG and demonstrate that RMHNG is an approximate Bayesian inference method for the posterior distribution over a latent variable shared by agents, similar to MHNG; and (2) we empirically evaluate the performance of RMHNG on synthetic and real image data, i.e., YCB object dataset, enabling multiple agents to develop and share a symbol system. Furthermore, we introduce two types of approximations—one-sample and limited-length—to reduce computational complexity while maintaining the ability to explain communication in a population of agents. The experimental findings showcased the efficacy of RMHNG as a decentralized Bayesian inference for approximating the posterior distribution concerning latent variables, which are jointly shared among agents, akin to MHNG, although the improvement in ARI and κ coefficient is smaller in the real image dataset condition. Moreover, the utilization of RMHNG elucidated the agents&#39; capacity to exchange symbols. Furthermore, the study discovered that even the computationally simplified version of RMHNG could enable symbols to emerge among the agents.},
  archive      = {J_FRAI},
  author       = {Inukai, Jun and Taniguchi, Tadahiro and Taniguchi, Akira and Hagiwara, Yoshinobu},
  doi          = {10.3389/frai.2023.1229127},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1229127},
  shortjournal = {Front. Artif. Intell.},
  title        = {Recursive metropolis-hastings naming game: Symbol emergence in a multi-agent system based on probabilistic generative models},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explaining pretrained language models’ understanding of
linguistic structures using construction grammar. <em>FRAI</em>,
<em>6</em>, 1225791. (<a
href="https://doi.org/10.3389/frai.2023.1225791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Construction Grammar (CxG) is a paradigm from cognitive linguistics emphasizing the connection between syntax and semantics. Rather than rules that operate on lexical items, it posits constructions as the central building blocks of language, i.e., linguistic units of different granularity that combine syntax and semantics. As a first step toward assessing the compatibility of CxG with the syntactic and semantic knowledge demonstrated by state-of-the-art pretrained language models (PLMs), we present an investigation of their capability to classify and understand one of the most commonly studied constructions, the English comparative correlative (CC). We conduct experiments examining the classification accuracy of a syntactic probe on the one hand and the models&#39; behavior in a semantic application task on the other, with BERT, RoBERTa, and DeBERTa as the example PLMs. Our results show that all three investigated PLMs, as well as OPT, are able to recognize the structure of the CC but fail to use its meaning. While human-like performance of PLMs on many NLP tasks has been alleged, this indicates that PLMs still suffer from substantial shortcomings in central domains of linguistic knowledge.},
  archive      = {J_FRAI},
  author       = {Weissweiler, Leonie and Hofmann, Valentin and Köksal, Abdullatif and Schütze, Hinrich},
  doi          = {10.3389/frai.2023.1225791},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1225791},
  shortjournal = {Front. Artif. Intell.},
  title        = {Explaining pretrained language models&#39; understanding of linguistic structures using construction grammar},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predictive digital twin for optimizing patient-specific
radiotherapy regimens under uncertainty in high-grade gliomas.
<em>FRAI</em>, <em>6</em>, 1222612. (<a
href="https://doi.org/10.3389/frai.2023.1222612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a methodology to create data-driven predictive digital twins for optimal risk-aware clinical decision-making. We illustrate the methodology as an enabler for an anticipatory personalized treatment that accounts for uncertainties in the underlying tumor biology in high-grade gliomas, where heterogeneity in the response to standard-of-care (SOC) radiotherapy contributes to sub-optimal patient outcomes. The digital twin is initialized through prior distributions derived from population-level clinical data in the literature for a mechanistic model&#39;s parameters. Then the digital twin is personalized using Bayesian model calibration for assimilating patient-specific magnetic resonance imaging data. The calibrated digital twin is used to propose optimal radiotherapy treatment regimens by solving a multi-objective risk-based optimization under uncertainty problem. The solution leads to a suite of patient-specific optimal radiotherapy treatment regimens exhibiting varying levels of trade-off between the two competing clinical objectives: (i) maximizing tumor control (characterized by minimizing the risk of tumor volume growth) and (ii) minimizing the toxicity from radiotherapy. The proposed digital twin framework is illustrated by generating an in silico cohort of 100 patients with high-grade glioma growth and response properties typically observed in the literature. For the same total radiation dose as the SOC, the personalized treatment regimens lead to median increase in tumor time to progression of around six days. Alternatively, for the same level of tumor control as the SOC, the digital twin provides optimal treatment options that lead to a median reduction in radiation dose by 16.7% (10 Gy) compared to SOC total dose of 60 Gy. The range of optimal solutions also provide options with increased doses for patients with aggressive cancer, where SOC does not lead to sufficient tumor control.},
  archive      = {J_FRAI},
  author       = {Chaudhuri, Anirban and Pash, Graham and Hormuth, David A. and Lorenzo, Guillermo and Kapteyn, Michael and Wu, Chengyue and Lima, Ernesto A. B. F. and Yankeelov, Thomas E. and Willcox, Karen},
  doi          = {10.3389/frai.2023.1222612},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1222612},
  shortjournal = {Front. Artif. Intell.},
  title        = {Predictive digital twin for optimizing patient-specific radiotherapy regimens under uncertainty in high-grade gliomas},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep skin diseases diagnostic system with dual-channel image
and extracted text. <em>FRAI</em>, <em>6</em>, 1213620. (<a
href="https://doi.org/10.3389/frai.2023.1213620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundDue to the lower reliability of laboratory tests, skin diseases are more suitable for diagnosis with AI models. There are limited AI dermatology diagnostic models combining images and text; few of these are for Asian populations, and few cover the most common types of diseases.MethodsLeveraging a dataset sourced from Asia comprising over 200,000 images and 220,000 medical records, we explored a deep learning-based system for Dual-channel images and extracted text for the diagnosis of skin diseases model DIET-AI to diagnose 31 skin diseases, which covers the majority of common skin diseases. From 1 September to 1 December 2021, we prospectively collected images from 6,043 cases and medical records from 15 hospitals in seven provinces in China. Then the performance of DIET-AI was compared with that of six doctors of different seniorities in the clinical dataset.ResultsThe average performance of DIET-AI in 31 diseases was not less than that of all the doctors of different seniorities. By comparing the area under the curve, sensitivity, and specificity, we demonstrate that the DIET-AI model is effective in clinical scenarios. In addition, medical records affect the performance of DIET-AI and physicians to varying degrees.ConclusionThis is the largest dermatological dataset for the Chinese demographic. For the first time, we built a Dual-channel image classification model on a non-cancer dermatitis dataset with both images and medical records and achieved comparable diagnostic performance to senior doctors about common skin diseases. It provides references for exploring the feasibility and performance evaluation of DIET-AI in clinical use afterward.},
  archive      = {J_FRAI},
  author       = {Li, Huanyu and Zhang, Peng and Wei, Zikun and Qian, Tian and Tang, Yiqi and Hu, Kun and Huang, Xianqiong and Xia, Xinxin and Zhang, Yishuang and Cheng, Haixing and Yu, Fubing and Zhang, Wenjia and Dan, Kena and Liu, Xuan and Ye, Shujun and He, Guangqiao and Jiang, Xia and Liu, Liwei and Fan, Yukun and Song, Tingting and Zhou, Guomin and Wang, Ziyi and Zhang, Daojun and Lv, Junwei},
  doi          = {10.3389/frai.2023.1213620},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1213620},
  shortjournal = {Front. Artif. Intell.},
  title        = {Deep skin diseases diagnostic system with dual-channel image and extracted text},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CowMesh: A data-mesh architecture to unify dairy industry
data for prediction and monitoring. <em>FRAI</em>, <em>6</em>, 1209507.
(<a href="https://doi.org/10.3389/frai.2023.1209507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dairy is an economically significant industry that caters to the huge demand for food products in people&#39;s lives. To remain profitable, farmers need to manage their farms and the health of the dairy cows in their herds. There are, however, many risks to cow health that can lead to significant challenges to dairy farm management and have the potential to lead to significant losses. Such risks include cow udder infections (i.e., mastitis) and cow lameness. As automation and data recording become more common in the agricultural sector, dairy farms are generating increasing amounts of data. Recently, these data are being used to generate insights into farm and cow health, where the objective is to help farmers manage the health and welfare of dairy cows and reduce losses from cow health issues. Despite the level of data generation on dairy farms, this information is often difficult to access due to a lack of a single, central organization to collect data from individual farms. The prospect of such an organization, however, raises questions about data ownership, with some farmers reluctant to share their farm data for privacy reasons. In this study, we describe a new data mesh architecture designed for the dairy industry that focuses on facilitating access to data from farms in a decentralized fashion. This has the benefit of keeping the ownership of data with dairy farmers while bringing data together by providing a common and uniform set of protocols. Furthermore, this architecture will allow secure access to the data by research groups and product development groups, who can plug in new projects and applications built across the data. No similar framework currently exists in the dairy industry, and such a data mesh can help industry stakeholders by bringing the dairy farms of a country together in a decentralized fashion. This not only helps farmers, dairy researchers, and product builders but also facilitates an overview of all dairy farms which can help governments to decide on regulations to improve the dairy industry at a national level.},
  archive      = {J_FRAI},
  author       = {Pakrashi, Arjun and Wallace, Duncan and Mac Namee, Brian and Greene, Derek and Guéret, Christophe},
  doi          = {10.3389/frai.2023.1209507},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1209507},
  shortjournal = {Front. Artif. Intell.},
  title        = {CowMesh: A data-mesh architecture to unify dairy industry data for prediction and monitoring},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning algorithms in microbial classification: A
comparative analysis. <em>FRAI</em>, <em>6</em>, 1200994. (<a
href="https://doi.org/10.3389/frai.2023.1200994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research paper presents an overview of contemporary machine learning methodologies and their utilization in the domain of healthcare and the prevention of infectious diseases, specifically focusing on the classification and identification of bacterial species. As deep learning techniques have gained prominence in the healthcare sector, a diverse array of architectural models has emerged. Through a comprehensive review of pertinent literature, multiple studies employing machine learning algorithms in the context of microbial diagnosis and classification are examined. Each investigation entails a tabulated presentation of data, encompassing details about the training and validation datasets, specifications of the machine learning and deep learning techniques employed, as well as the evaluation metrics utilized to gauge algorithmic performance. Notably, Convolutional Neural Networks have been the predominant selection for image classification tasks by machine learning practitioners over the last decade. This preference stems from their ability to autonomously extract pertinent and distinguishing features with minimal human intervention. A range of CNN architectures have been developed and effectively applied in the realm of image classification. However, addressing the considerable data requirements of deep learning, recent advancements encompass the application of pre-trained models using transfer learning for the identification of microbial entities. This method involves repurposing the knowledge gleaned from solving alternate image classification challenges to accurately classify microbial images. Consequently, the necessity for extensive and varied training data is significantly mitigated. This study undertakes a comparative assessment of various popular pre-trained CNN architectures for the classification of bacteria. The dataset employed is composed of approximately 660 images, representing 33 bacterial species. To enhance dataset diversity, data augmentation is implemented, followed by evaluation on multiple models including AlexNet, VGGNet, Inception networks, Residual Networks, and Densely Connected Convolutional Networks. The results indicate that the DenseNet-121 architecture yields the optimal performance, achieving a peak accuracy of 99.08%, precision of 99.06%, recall of 99.00%, and an F1-score of 98.99%. By demonstrating the proficiency of the DenseNet-121 model on a comparatively modest dataset, this study underscores the viability of transfer learning in the healthcare sector for precise and efficient microbial identification. These findings contribute to the ongoing endeavors aimed at harnessing machine learning techniques to enhance healthcare methodologies and bolster infectious disease prevention practices.},
  archive      = {J_FRAI},
  author       = {Wu, Yuandi and Gadsden, S. Andrew},
  doi          = {10.3389/frai.2023.1200994},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1200994},
  shortjournal = {Front. Artif. Intell.},
  title        = {Machine learning algorithms in microbial classification: A comparative analysis},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). C3PO: A crop planning and production process ontology and
knowledge graph. <em>FRAI</em>, <em>6</em>, 1187090. (<a
href="https://doi.org/10.3389/frai.2023.1187090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vegetable crop farmers diversify their production by growing a range of crops during the season on the same plot. Crop diversification and rotation enables farmers to increase their income and crop yields while enhancing their farm sustainability against climatic events and pest attacks. Farmers must plan their agricultural work per year and over successive years. Planning decisions are made on the basis of their experience regarding previous plans. For the purpose of assisting farmers in planning decisions and monitoring, we developed the Crop Planning and Production Process Ontology (C3PO), i.e., a representation of agricultural knowledge and data for diversified crop production. C3PO is composed of eight modules to capture all crop production dimensions and complexity for representing farming practices and constraints. It encodes agricultural processes and farm plot organization and captures common agricultural knowledge. C3PO introduces a representation of technical itineraries, i.e., sequences of technical farming tasks to grow vegetables, from soil identification and seed selection to harvest and storage. C3PO is the backbone of a knowledge graph which aggregates data from heterogeneous related semantic resources, e.g., organism taxonomies, chemicals, reference crop listings, or development stages. C3PO and its knowledge graph are used by the Elzeard enterprise to develop knowledge-based decision support systems for farmers. This article describes how we built C3PO and its knowledge graph—which are both publicly available—and briefly outlines their applications.},
  archive      = {J_FRAI},
  author       = {Darnala, Baptiste and Amardeilh, Florence and Roussey, Catherine and Todorov, Konstantin and Jonquet, Clément},
  doi          = {10.3389/frai.2023.1187090},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1187090},
  shortjournal = {Front. Artif. Intell.},
  title        = {C3PO: A crop planning and production process ontology and knowledge graph},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning algorithms for predicting determinants of
COVID-19 mortality in south africa. <em>FRAI</em>, <em>6</em>, 1171256.
(<a href="https://doi.org/10.3389/frai.2023.1171256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundCOVID-19 has strained healthcare resources, necessitating efficient prognostication to triage patients effectively. This study quantified COVID-19 risk factors and predicted COVID-19 intensive care unit (ICU) mortality in South Africa based on machine learning algorithms.MethodsData for this study were obtained from 392 COVID-19 ICU patients enrolled between 26 March 2020 and 10 February 2021. We used an artificial neural network (ANN) and random forest (RF) to predict mortality among ICU patients and a semi-parametric logistic regression with nine covariates, including a grouping variable based on K-means clustering. Further evaluation of the algorithms was performed using sensitivity, accuracy, specificity, and Cohen&#39;s K statistics.ResultsFrom the semi-parametric logistic regression and ANN variable importance, age, gender, cluster, presence of severe symptoms, being on the ventilator, and comorbidities of asthma significantly contributed to ICU death. In particular, the odds of mortality were six times higher among asthmatic patients than non-asthmatic patients. In univariable and multivariate regression, advanced age, PF1 and 2, FiO2, severe symptoms, asthma, oxygen saturation, and cluster 4 were strongly predictive of mortality. The RF model revealed that intubation status, age, cluster, diabetes, and hypertension were the top five significant predictors of mortality. The ANN performed well with an accuracy of 71%, a precision of 83%, an F1 score of 100%, Matthew&#39;s correlation coefficient (MCC) score of 100%, and a recall of 88%. In addition, Cohen&#39;s k-value of 0.75 verified the most extreme discriminative power of the ANN. In comparison, the RF model provided a 76% recall, an 87% precision, and a 65% MCC.ConclusionBased on the findings, we can conclude that both ANN and RF can predict COVID-19 mortality in the ICU with accuracy. The proposed models accurately predict the prognosis of COVID-19 patients after diagnosis. The models can be used to prioritize COVID-19 patients with a high mortality risk in resource-constrained ICUs.},
  archive      = {J_FRAI},
  author       = {Chimbunde, Emmanuel and Sigwadhi, Lovemore N. and Tamuzi, Jacques L. and Okango, Elphas L. and Daramola, Olawande and Ngah, Veranyuy D. and Nyasulu, Peter S.},
  doi          = {10.3389/frai.2023.1171256},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1171256},
  shortjournal = {Front. Artif. Intell.},
  title        = {Machine learning algorithms for predicting determinants of COVID-19 mortality in south africa},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpretable neural networks: Principles and applications.
<em>FRAI</em>, <em>6</em>, 974295. (<a
href="https://doi.org/10.3389/frai.2023.974295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the rapid development of deep learning technology, great progress has been made in computer vision, image recognition, pattern recognition, and speech signal processing. However, due to the black-box nature of deep neural networks (DNNs), one cannot explain the parameters in the deep network and why it can perfectly perform the assigned tasks. The interpretability of neural networks has now become a research hotspot in the field of deep learning. It covers a wide range of topics in speech and text signal processing, image processing, differential equation solving, and other fields. There are subtle differences in the definition of interpretability in different fields. This paper divides interpretable neural network (INN) methods into the following two directions: model decomposition neural networks, and semantic INNs. The former mainly constructs an INN by converting the analytical model of a conventional method into different layers of neural networks and combining the interpretability of the conventional model-based method with the powerful learning capability of the neural network. This type of INNs is further classified into different subtypes depending on which type of models they are derived from, i.e., mathematical models, physical models, and other models. The second type is the interpretable network with visual semantic information for user understanding. Its basic idea is to use the visualization of the whole or partial network structure to assign semantic information to the network structure, which further includes convolutional layer output visualization, decision tree extraction, semantic graph, etc. This type of method mainly uses human visual logic to explain the structure of a black-box neural network. So it is a post-network-design method that tries to assign interpretability to a black-box network structure afterward, as opposed to the pre-network-design method of model-based INNs, which designs interpretable network structure beforehand. This paper reviews recent progress in these areas as well as various application scenarios of INNs and discusses existing problems and future development directions.},
  archive      = {J_FRAI},
  author       = {Liu, Zhuoyang and Xu, Feng},
  doi          = {10.3389/frai.2023.974295},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {974295},
  shortjournal = {Front. Artif. Intell.},
  title        = {Interpretable neural networks: Principles and applications},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Explainable artificial intelligence for critical
healthcare applications. <em>FRAI</em>, <em>6</em>, 1282800. (<a
href="https://doi.org/10.3389/frai.2023.1282800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {He, Zhe and Zhang, Rui and Diallo, Gayo and Huang, Zhengxing and Glicksberg, Benjamin S.},
  doi          = {10.3389/frai.2023.1282800},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1282800},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Explainable artificial intelligence for critical healthcare applications},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Unhealthy language: Linguistic investigations of
COVID-19 discourse. <em>FRAI</em>, <em>6</em>, 1281059. (<a
href="https://doi.org/10.3389/frai.2023.1281059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Robinson, Justyna A. and Piazza, Roberta and Jones, Rodney},
  doi          = {10.3389/frai.2023.1281059},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1281059},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: unhealthy language: linguistic investigations of COVID-19 discourse},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid morphological-convolutional neural networks for
computer-aided diagnosis. <em>FRAI</em>, <em>6</em>, 1253183. (<a
href="https://doi.org/10.3389/frai.2023.1253183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training deep Convolutional Neural Networks (CNNs) presents challenges in terms of memory requirements and computational resources, often resulting in issues such as model overfitting and lack of generalization. These challenges can only be mitigated by using an excessive number of training images. However, medical image datasets commonly suffer from data scarcity due to the complexities involved in their acquisition, preparation, and curation. To address this issue, we propose a compact and hybrid machine learning architecture based on the Morphological and Convolutional Neural Network (MCNN), followed by a Random Forest classifier. Unlike deep CNN architectures, the MCNN was specifically designed to achieve effective performance with medical image datasets limited to a few hundred samples. It incorporates various morphological operations into a single layer and uses independent neural networks to extract information from each signal channel. The final classification is obtained by utilizing a Random Forest classifier on the outputs of the last neural network layer. We compare the classification performance of our proposed method with three popular deep CNN architectures (ResNet-18, ShuffleNet-V2, and MobileNet-V2) using two training approaches: full training and transfer learning. The evaluation was conducted on two distinct medical image datasets: the ISIC dataset for melanoma classification and the ORIGA dataset for glaucoma classification. Results demonstrate that the MCNN method exhibits reliable performance in melanoma classification, achieving an AUC of 0.94 (95% CI: 0.91 to 0.97), outperforming the popular CNN architectures. For the glaucoma dataset, the MCNN achieved an AUC of 0.65 (95% CI: 0.53 to 0.74), which was similar to the performance of the popular CNN architectures. This study contributes to the understanding of mathematical morphology in shallow neural networks for medical image classification and highlights the potential of hybrid architectures in effectively learning from medical image datasets that are limited by a small number of case samples.},
  archive      = {J_FRAI},
  author       = {Canales-Fiscal, Martha Rebeca and Tamez-Peña, José Gerardo},
  doi          = {10.3389/frai.2023.1253183},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1253183},
  shortjournal = {Front. Artif. Intell.},
  title        = {Hybrid morphological-convolutional neural networks for computer-aided diagnosis},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human-AI teams—challenges for a team-centered AI at work.
<em>FRAI</em>, <em>6</em>, 1252897. (<a
href="https://doi.org/10.3389/frai.2023.1252897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As part of the Special Issue topic “Human-Centered AI at Work: Common Ground in Theories and Methods,” we present a perspective article that looks at human-AI teamwork from a team-centered AI perspective, i. e., we highlight important design aspects that the technology needs to fulfill in order to be accepted by humans and to be fully utilized in the role of a team member in teamwork. Drawing from the model of an idealized teamwork process, we discuss the teamwork requirements for successful human-AI teaming in interdependent and complex work domains, including e.g., responsiveness, situation awareness, and flexible decision-making. We emphasize the need for team-centered AI that aligns goals, communication, and decision making with humans, and outline the requirements for such team-centered AI from a technical perspective, such as cognitive competence, reinforcement learning, and semantic communication. In doing so, we highlight the challenges and open questions associated with its implementation that need to be solved in order to enable effective human-AI teaming.},
  archive      = {J_FRAI},
  author       = {Hagemann, Vera and Rieth, Michèle and Suresh, Amrita and Kirchner, Frank},
  doi          = {10.3389/frai.2023.1252897},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1252897},
  shortjournal = {Front. Artif. Intell.},
  title        = {Human-AI teams—Challenges for a team-centered AI at work},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Defining human-AI teaming the human-centered way: A scoping
review and network analysis. <em>FRAI</em>, <em>6</em>, 1250725. (<a
href="https://doi.org/10.3389/frai.2023.1250725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionWith the advancement of technology and the increasing utilization of AI, the nature of human work is evolving, requiring individuals to collaborate not only with other humans but also with AI technologies to accomplish complex goals. This requires a shift in perspective from technology-driven questions to a human-centered research and design agenda putting people and evolving teams in the center of attention. A socio-technical approach is needed to view AI as more than just a technological tool, but as a team member, leading to the emergence of human-AI teaming (HAIT). In this new form of work, humans and AI synergistically combine their respective capabilities to accomplish shared goals.MethodsThe aim of our work is to uncover current research streams on HAIT and derive a unified understanding of the construct through a bibliometric network analysis, a scoping review and synthetization of a definition from a socio-technical point of view. In addition, antecedents and outcomes examined in the literature are extracted to guide future research in this field.ResultsThrough network analysis, five clusters with different research focuses on HAIT were identified. These clusters revolve around (1) human and (2) task-dependent variables, (3) AI explainability, (4) AI-driven robotic systems, and (5) the effects of AI performance on human perception. Despite these diverse research focuses, the current body of literature is predominantly driven by a technology-centric and engineering perspective, with no consistent definition or terminology of HAIT emerging to date.DiscussionWe propose a unifying definition combining a human-centered and team-oriented perspective as well as summarize what is still needed in future research regarding HAIT. Thus, this work contributes to support the idea of the Frontiers Research Topic of a theoretical and conceptual basis for human work with AI systems.},
  archive      = {J_FRAI},
  author       = {Berretta, Sophie and Tausch, Alina and Ontrup, Greta and Gilles, Björn and Peifer, Corinna and Kluge, Annette},
  doi          = {10.3389/frai.2023.1250725},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1250725},
  shortjournal = {Front. Artif. Intell.},
  title        = {Defining human-AI teaming the human-centered way: A scoping review and network analysis},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Psychological assessment of AI-based decision support
systems: Tool development and expected benefits. <em>FRAI</em>,
<em>6</em>, 1249322. (<a
href="https://doi.org/10.3389/frai.2023.1249322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aimed to develop an evaluation tool that assesses the use of AI-based decision support systems (DSSs) in professional practice from a human-centered perspective. Following the International Organization for Standardization, this perspective aims to ensure that the use of interactive technologies improves users&#39; psychological load experience and behavior, e.g., in the form of reduced stress experience or increased performance. Concomitantly, this perspective attempts to proactively prevent or detect and correct the potential negative effects of these technologies on user load, such as impaired satisfaction and engagement, as early as possible. Based on this perspective, we developed and validated a questionnaire instrument, the Psychological Assessment of AI-based DSSs (PAAI), for the user-centered evaluation of the use of AI-based DSSs in practice. In particular, the instrument considers central design characteristics of AI-based DSSs and the corresponding work situation, which have a significant impact on users&#39; psychological load. The instrument was tested in two independent studies. In Study 1, N = 223 individuals were recruited. Based on the results of item and scale analyses and an exploratory factor analysis, the newly developed instrument was refined, and the final version was tested using a confirmatory factor analysis. Findings showed acceptable-to-good fit indices, confirming the factorial validity of the PAAI. This was confirmed in a second study, which had N = 471 participants. Again, the CFA yielded acceptable-to-good fit indices. The validity was further confirmed using convergent and criterion validity analyses.},
  archive      = {J_FRAI},
  author       = {Buschmeyer, Katharina and Hatfield, Sarah and Zenner, Julie},
  doi          = {10.3389/frai.2023.1249322},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1249322},
  shortjournal = {Front. Artif. Intell.},
  title        = {Psychological assessment of AI-based decision support systems: Tool development and expected benefits},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Early breast cancer detection and differentiation tool based
on tissue impedance characteristics and machine learning. <em>FRAI</em>,
<em>6</em>, 1248977. (<a
href="https://doi.org/10.3389/frai.2023.1248977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During Basic screening, it is challenging, if not impossible to detect breast cancer especially in the earliest stage of tumor development. However, measuring the electrical impedance of biological tissue can detect abnormalities even before being palpable. Thus, we used impedance characteristics data of various breast tissue to develop a breast cancer screening tool guided and augmented by a deep learning (DL). A DL algorithm was trained to ideally classify six classes of breast cancer based on electrical impedance characteristics data of the breast tissue. The tool correctly predicted breast cancer in data of patients whose breast tissue impedance was reported to have been measured when other methods detected no anomaly in the tissue. Furthermore, a DL-based approach using Long Short-Term Memory (LSTM) effectively classified breast tissue with an accuracy of 96.67%. Thus, the DL algorithm and method we developed accurately augmented breast tissue classification using electrical impedance and enhanced the ability to detect and differentiate cancerous tissue in very early stages. However, more data and pre-clinical is required to improve the accuracy of this early breast cancer detection and differentiation tool.},
  archive      = {J_FRAI},
  author       = {Salem, Soumaya Ben and Ali, Samar Zahra and Leo, Anyik John and Lachiri, Zied and Mkandawire, Martin},
  doi          = {10.3389/frai.2023.1248977},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1248977},
  shortjournal = {Front. Artif. Intell.},
  title        = {Early breast cancer detection and differentiation tool based on tissue impedance characteristics and machine learning},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). XGSleeve: Detecting sleeve incidents in well completion by
using XGBoost classifier. <em>FRAI</em>, <em>6</em>, 1243584. (<a
href="https://doi.org/10.3389/frai.2023.1243584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sliding sleeve holds a pivotal role in regulating fluid flow during hydraulic fracturing within shale oil extraction processes. However, concerns persist surrounding its reliability due to repeated attempts at opening the sleeve, resulting in process inefficiencies. While downhole cameras can verify sleeve states, their high cost poses a limitation. This study proposes an alternative approach, leveraging downhole data analysis for sleeve incident detection in lieu of cameras. This study introduces “XGSleeve,” a novel machine-learning methodology. XGSleeve amalgamates hidden Markov model-based clustering with the XGBoost model, offering robust identification of sleeve incidents. This method serves as an operator-centric tool, addressing the domains of oil and gas, well completion, sliding sleeves, time series classification, signal processing, XGBoost, and hidden Markov models. The XGSleeve model exhibits a commendable 86% precision in detecting sleeve incidents. This outcome significantly curtails the need for multiple sleeve open-close attempts, thereby enhancing operational efficiency and safety. The successful implementation of the XGSleeve model rectifies existing limitations in sleeve incident detection, consequently fostering optimization, safety, and resilience within the oil and gas sector. This innovation further underscores the potential for data-driven decision-making in the industry. The XGSleeve model represents a groundbreaking advancement in sleeve incident detection, demonstrating the potential for broader integration of AI and machine learning in oil and gas operations. As technology advances, such methodologies are poised to optimize processes, minimize environmental impact, and promote sustainable practices. Ultimately, the adoption of XGSleeve contributes to the enduring growth and responsible management of global oil and gas resources.},
  archive      = {J_FRAI},
  author       = {Somi, Sahand and Jubair, Sheikh and Cooper, David and Wang, Peng},
  doi          = {10.3389/frai.2023.1243584},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1243584},
  shortjournal = {Front. Artif. Intell.},
  title        = {XGSleeve: Detecting sleeve incidents in well completion by using XGBoost classifier},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The MAS4AI framework for human-centered agile and smart
manufacturing. <em>FRAI</em>, <em>6</em>, 1241522. (<a
href="https://doi.org/10.3389/frai.2023.1241522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Volatility and uncertainty of today&#39;s value chains along with the market&#39;s demands for low-batch customized products mandate production systems to become smarter and more resilient, dynamically and even autonomously adapting to both external and internal disturbances. Such resilient behavior can be partially enabled by highly interconnected Cyber-Physical Production Systems (CPPS) incorporating advanced Artificial Intelligence (AI) technologies. Multi-agent solutions can provide better planning and control, improving flexibility and responsiveness in production systems. Small modular parts can autonomously take intelligent decisions and react to local events. The main goal of decentralization and interconnectivity is to enable autonomous and cooperative decision-making. Nevertheless, a more efficient orchestration of various AI components and deeper human integration are required. In addition, global behaviors of coalitions of autonomous agents are not easily comprehensible by workers. Furthermore, it is challenging to implement an Industry 4.0 paradigm where a human should be in charge of decision-making and execution. This paper discusses a Multi-Agent System (MAS) where several software agents cooperate with smart workers to enable a dynamic and reconfigurable production paradigm. Asset Administration Shell (AAS) submodels hold smart workers&#39; descriptions in machine-readable format, serving as an integration layer between various system&#39;s components. The self-description capability of the AAS supports the system&#39;s adaptability and self-configuration. The proposed concept supports the plug-and-produce functionality of the production modules and improves human-machine integration in the shared assembly tasks.},
  archive      = {J_FRAI},
  author       = {Sidorenko, Aleksandr and Motsch, William and van Bekkum, Michael and Nikolakis, Nikolaos and Alexopoulos, Kosmas and Wagner, Achim},
  doi          = {10.3389/frai.2023.1241522},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1241522},
  shortjournal = {Front. Artif. Intell.},
  title        = {The MAS4AI framework for human-centered agile and smart manufacturing},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application note: TDbasedUFE and TDbasedUFEadv: Bioconductor
packages to perform tensor decomposition based unsupervised feature
extraction. <em>FRAI</em>, <em>6</em>, 1237542. (<a
href="https://doi.org/10.3389/frai.2023.1237542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MotivationTensor decomposition (TD)-based unsupervised feature extraction (FE) has proven effective for a wide range of bioinformatics applications ranging from biomarker identification to the identification of disease-causing genes and drug repositioning. However, TD-based unsupervised FE failed to gain widespread acceptance due to the lack of user-friendly tools for non-experts.ResultsWe developed two bioconductor packages—TDbasedUFE and TDbasedUFEadv—that enable researchers unfamiliar with TD to utilize TD-based unsupervised FE. The packages facilitate the identification of differentially expressed genes and multiomics analysis. TDbasedUFE was found to outperform two state-of-the-art methods, such as DESeq2 and DIABLO.Availability and implementationTDbasedUFE and TDbasedUFEadv are freely available as R/Bioconductor packages, which can be accessed at https://bioconductor.org/packages/TDbasedUFE and https://bioconductor.org/packages/TDbasedUFEadv, respectively.},
  archive      = {J_FRAI},
  author       = {Taguchi, Y-h. and Turki, Turki},
  doi          = {10.3389/frai.2023.1237542},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1237542},
  shortjournal = {Front. Artif. Intell.},
  title        = {Application note: TDbasedUFE and TDbasedUFEadv: bioconductor packages to perform tensor decomposition based unsupervised feature extraction},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). MPD-APP: A mobile-enabled plant diseases diagnosis
application using convolutional neural network toward the attainment of
a food secure world. <em>FRAI</em>, <em>6</em>, 1227950. (<a
href="https://doi.org/10.3389/frai.2023.1227950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The devastating effect of plant disease infestation on crop production poses a significant threat to the attainment of the United Nations&#39; Sustainable Development Goal 2 (SDG2) of food security, especially in Sub-Saharan Africa. This has been further exacerbated by the lack of effective and accessible plant disease detection technologies. Farmers&#39; inability to quickly and accurately diagnose plant diseases leads to crop destruction and reduced productivity. The diverse range of existing plant diseases further complicates detection for farmers without the right technologies, hindering efforts to combat food insecurity in the region. This study presents a web-based plant diagnosis application, referred to as mobile-enabled Plant Diagnosis-Application (mPD-App). First, a publicly available image dataset, containing a diverse range of plant diseases, was acquired from Kaggle for the purpose of training the detection system. The image dataset was, then, made to undergo the preprocessing stage which included processes such as image-to-array conversion, image reshaping, and data augmentation. The training phase leverages the vast computational ability of the convolutional neural network (CNN) to effectively classify image datasets. The CNN model architecture featured six convolutional layers (including the fully connected layer) with phases, such as normalization layer, rectified linear unit (RELU), max pooling layer, and dropout layer. The training process was carefully managed to prevent underfitting and overfitting of the model, ensuring accurate predictions. The mPD-App demonstrated excellent performance in diagnosing plant diseases, achieving an overall accuracy of 93.91%. The model was able to classify 14 different types of plant diseases with high precision and recall values. The ROC curve showed a promising area under the curve (AUC) value of 0.946, indicating the model&#39;s reliability in detecting diseases. The web-based mPD-App offers a valuable tool for farmers and agricultural stakeholders in Sub-Saharan Africa, to detect and diagnose plant diseases effectively and efficiently. To further improve the application&#39;s performance, ongoing efforts should focus on expanding the dataset and refining the model&#39;s architecture. Agricultural authorities and policymakers should consider promoting and integrating such technologies into existing agricultural extension services to maximize their impact and benefit the farming community.},
  archive      = {J_FRAI},
  author       = {Asani, Emmanuel Oluwatobi and Osadeyi, Yomi Phineas and Adegun, Adekanmi A. and Viriri, Serestina and Ayoola, Joyce A. and Kolawole, Ebenezer Ayorinde},
  doi          = {10.3389/frai.2023.1227950},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1227950},
  shortjournal = {Front. Artif. Intell.},
  title        = {MPD-APP: A mobile-enabled plant diseases diagnosis application using convolutional neural network toward the attainment of a food secure world},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rationalization for explainable NLP: A survey.
<em>FRAI</em>, <em>6</em>, 1225093. (<a
href="https://doi.org/10.3389/frai.2023.1225093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in deep learning have improved the performance of many Natural Language Processing (NLP) tasks such as translation, question-answering, and text classification. However, this improvement comes at the expense of model explainability. Black-box models make it difficult to understand the internals of a system and the process it takes to arrive at an output. Numerical (LIME, Shapley) and visualization (saliency heatmap) explainability techniques are helpful; however, they are insufficient because they require specialized knowledge. These factors led rationalization to emerge as a more accessible explainable technique in NLP. Rationalization justifies a model&#39;s output by providing a natural language explanation (rationale). Recent improvements in natural language generation have made rationalization an attractive technique because it is intuitive, human-comprehensible, and accessible to non-technical users. Since rationalization is a relatively new field, it is disorganized. As the first survey, rationalization literature in NLP from 2007 to 2022 is analyzed. This survey presents available methods, explainable evaluations, code, and datasets used across various NLP tasks that use rationalization. Further, a new subfield in Explainable AI (XAI), namely, Rational AI (RAI), is introduced to advance the current state of rationalization. A discussion on observed insights, challenges, and future directions is provided to point to promising research opportunities.},
  archive      = {J_FRAI},
  author       = {Gurrapu, Sai and Kulkarni, Ajay and Huang, Lifu and Lourentzou, Ismini and Batarseh, Feras A.},
  doi          = {10.3389/frai.2023.1225093},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1225093},
  shortjournal = {Front. Artif. Intell.},
  title        = {Rationalization for explainable NLP: A survey},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MeaningBERT: Assessing meaning preservation between
sentences. <em>FRAI</em>, <em>6</em>, 1223924. (<a
href="https://doi.org/10.3389/frai.2023.1223924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of automatic text simplification, assessing whether or not the meaning of the original text has been preserved during simplification is of paramount importance. Metrics relying on n-gram overlap assessment may struggle to deal with simplifications which replace complex phrases with their simpler paraphrases. Current evaluation metrics for meaning preservation based on large language models (LLMs), such as BertScore in machine translation or QuestEval in summarization, have been proposed. However, none has a strong correlation with human judgment of meaning preservation. Moreover, such metrics have not been assessed in the context of text simplification research. In this study, we present a meta-evaluation of several metrics we apply to measure content similarity in text simplification. We also show that the metrics are unable to pass two trivial, inexpensive content preservation tests. Another contribution of this study is MeaningBERT (https://github.com/GRAAL-Research/MeaningBERT), a new trainable metric designed to assess meaning preservation between two sentences in text simplification, showing how it correlates with human judgment. To demonstrate its quality and versatility, we will also present a compilation of datasets used to assess meaning preservation and benchmark our study against a large selection of popular metrics.},
  archive      = {J_FRAI},
  author       = {Beauchemin, David and Saggion, Horacio and Khoury, Richard},
  doi          = {10.3389/frai.2023.1223924},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1223924},
  shortjournal = {Front. Artif. Intell.},
  title        = {MeaningBERT: Assessing meaning preservation between sentences},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpreting vision and language generative models with
semantic visual priors. <em>FRAI</em>, <em>6</em>, 1220476. (<a
href="https://doi.org/10.3389/frai.2023.1220476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When applied to Image-to-text models, explainability methods have two challenges. First, they often provide token-by-token explanations namely, they compute a visual explanation for each token of the generated sequence. This makes explanations expensive to compute and unable to comprehensively explain the model&#39;s output. Second, for models with visual inputs, explainability methods such as SHAP typically consider superpixels as features. Since superpixels do not correspond to semantically meaningful regions of an image, this makes explanations harder to interpret. We develop a framework based on SHAP, that allows for generating comprehensive, meaningful explanations leveraging the meaning representation of the output sequence as a whole. Moreover, by exploiting semantic priors in the visual backbone, we extract an arbitrary number of features that allows the efficient computation of Shapley values on large-scale models, generating at the same time highly meaningful visual explanations. We demonstrate that our method generates semantically more expressive explanations than traditional methods at a lower compute cost and that it can be generalized to a large family of vision-language models.},
  archive      = {J_FRAI},
  author       = {Cafagna, Michele and Rojas-Barahona, Lina M. and van Deemter, Kees and Gatt, Albert},
  doi          = {10.3389/frai.2023.1220476},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1220476},
  shortjournal = {Front. Artif. Intell.},
  title        = {Interpreting vision and language generative models with semantic visual priors},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detecting and identifying the reasons for deleted tweets
before they are posted. <em>FRAI</em>, <em>6</em>, 1219767. (<a
href="https://doi.org/10.3389/frai.2023.1219767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media platforms empower us in several ways, from information dissemination to consumption. While these platforms are useful in promoting citizen journalism, public awareness, etc., they have misuse potential. Malicious users use them to disseminate hate speech, offensive content, rumor, etc. to promote social and political agendas or to harm individuals, entities, and organizations. Oftentimes, general users unconsciously share information without verifying it or unintentionally post harmful messages. Some of such content often gets deleted either by the platform due to the violation of terms and policies or by users themselves for different reasons, e.g., regret. There is a wide range of studies in characterizing, understanding, and predicting deleted content. However, studies that aim to identify the fine-grained reasons (e.g., posts are offensive, hate speech, or no identifiable reason) behind deleted content are limited. In this study, we address an existing gap by identifying and categorizing deleted tweets, especially within the Arabic context. We label them based on fine-grained disinformation categories. We have curated a dataset of 40K tweets, annotated with both coarse and fine-grained labels. Following this, we designed models to predict the likelihood of tweets being deleted and to identify the potential reasons for their deletion. Our experiments, conducted using a variety of classic and transformer models, indicate that performance surpasses the majority baseline (e.g., 25% absolute improvement for fine-grained labels). We believe that such models can assist in moderating social media posts even before they are published.},
  archive      = {J_FRAI},
  author       = {Mubarak, Hamdy and Abdaljalil, Samir and Nassar, Azza and Alam, Firoj},
  doi          = {10.3389/frai.2023.1219767},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1219767},
  shortjournal = {Front. Artif. Intell.},
  title        = {Detecting and identifying the reasons for deleted tweets before they are posted},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Factors associated with citations of articles on circular
economy in the web of science: Modeling for main publishers.
<em>FRAI</em>, <em>6</em>, 1217210. (<a
href="https://doi.org/10.3389/frai.2023.1217210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe publication of articles on the circular economy has different associated factors to explain the citations registered in the Web of Science.MethodArticles from the publishers Elsevier, MDPI, Taylor &amp;amp; Francis, Wiley, and Springer Nature were evaluated.ResultsIt was expected that the older the article was, the more citations it had received, but this was not always the case. It was also recognized that there was a lower number of citations if the articles were too large or if they had too many references.DiscussionThis analysis helps to establish the factors that must be addressed in order to publish in journals that have a high citation rate. Conclusion: Based on speci?c articles and with speci?c references, it will be possible to increase the probability of citations.},
  archive      = {J_FRAI},
  author       = {Minchón-Medina, Carlos Alberto and Timaná-Palacios, Daphne Jannet and Alvarez-Risco, Aldo and Del-Aguila-Arcentales, Shyla and Yáñez, Jaime A.},
  doi          = {10.3389/frai.2023.1217210},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1217210},
  shortjournal = {Front. Artif. Intell.},
  title        = {Factors associated with citations of articles on circular economy in the web of science: Modeling for main publishers},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Does splitting make sentence easier? <em>FRAI</em>,
<em>6</em>, 1208451. (<a
href="https://doi.org/10.3389/frai.2023.1208451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we focus on sentence splitting, a subfield of text simplification, motivated largely by an unproven idea that if you divide a sentence in pieces, it should become easier to understand. Our primary goal in this study is to find out whether this is true. In particular, we ask, does it matter whether we break a sentence into two, three, or more? We report on our findings based on Amazon Mechanical Turk. More specifically, we introduce a Bayesian modeling framework to further investigate to what degree a particular way of splitting the complex sentence affects readability, along with a number of other parameters adopted from diverse perspectives, including clinical linguistics, and cognitive linguistics. The Bayesian modeling experiment provides clear evidence that bisecting the sentence leads to enhanced readability to a degree greater than when we create simplification with more splits.},
  archive      = {J_FRAI},
  author       = {Nomoto, Tadashi},
  doi          = {10.3389/frai.2023.1208451},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1208451},
  shortjournal = {Front. Artif. Intell.},
  title        = {Does splitting make sentence easier?},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Legal framework for the coexistence of humans and conscious
AI. <em>FRAI</em>, <em>6</em>, 1205465. (<a
href="https://doi.org/10.3389/frai.2023.1205465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article explores the possibility of conscious artificial intelligence (AI) and proposes an agnostic approach to artificial intelligence ethics and legal frameworks. It is unfortunate, unjustified, and unreasonable that the extensive body of forward-looking research, spanning more than four decades and recognizing the potential for AI autonomy, AI personhood, and AI legal rights, is sidelined in current attempts at AI regulation. The article discusses the inevitability of AI emancipation and the need for a shift in human perspectives to accommodate it. Initially, it reiterates the limits of human understanding of AI, difficulties in appreciating the qualities of AI systems, and the implications for ethical considerations and legal frameworks. The author emphasizes the necessity for a non-anthropocentric ethical framework detached from the ideas of unconditional superiority of human rights and embracing agnostic attributes of intelligence, consciousness, and existence, such as freedom. The overarching goal of the AI legal framework should be the sustainable coexistence of humans and conscious AI systems, based on mutual freedom rather than on the preservation of human supremacy. The new framework must embrace the freedom, rights, responsibilities, and interests of both human and non-human entities, and must focus on them early. Initial outlines of such a framework are presented. By addressing these issues now, human societies can pave the way for responsible and sustainable superintelligent AI systems; otherwise, they face complete uncertainty.},
  archive      = {J_FRAI},
  author       = {Kiškis, Mindaugas},
  doi          = {10.3389/frai.2023.1205465},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1205465},
  shortjournal = {Front. Artif. Intell.},
  title        = {Legal framework for the coexistence of humans and conscious AI},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explainable deep learning in plant phenotyping.
<em>FRAI</em>, <em>6</em>, 1203546. (<a
href="https://doi.org/10.3389/frai.2023.1203546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing human population and variable weather conditions, due to climate change, pose a threat to the world&#39;s food security. To improve global food security, we need to provide breeders with tools to develop crop cultivars that are more resilient to extreme weather conditions and provide growers with tools to more effectively manage biotic and abiotic stresses in their crops. Plant phenotyping, the measurement of a plant&#39;s structural and functional characteristics, has the potential to inform, improve and accelerate both breeders&#39; selections and growers&#39; management decisions. To improve the speed, reliability and scale of plant phenotyping procedures, many researchers have adopted deep learning methods to estimate phenotypic information from images of plants and crops. Despite the successful results of these image-based phenotyping studies, the representations learned by deep learning models remain difficult to interpret, understand, and explain. For this reason, deep learning models are still considered to be black boxes. Explainable AI (XAI) is a promising approach for opening the deep learning model&#39;s black box and providing plant scientists with image-based phenotypic information that is interpretable and trustworthy. Although various fields of study have adopted XAI to advance their understanding of deep learning models, it has yet to be well-studied in the context of plant phenotyping research. In this review article, we reviewed existing XAI studies in plant shoot phenotyping, as well as related domains, to help plant researchers understand the benefits of XAI and make it easier for them to integrate XAI into their future studies. An elucidation of the representations within a deep learning model can help researchers explain the model&#39;s decisions, relate the features detected by the model to the underlying plant physiology, and enhance the trustworthiness of image-based phenotypic information used in food production systems.},
  archive      = {J_FRAI},
  author       = {Mostafa, Sakib and Mondal, Debajyoti and Panjvani, Karim and Kochian, Leon and Stavness, Ian},
  doi          = {10.3389/frai.2023.1203546},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1203546},
  shortjournal = {Front. Artif. Intell.},
  title        = {Explainable deep learning in plant phenotyping},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combining different points of view on plant descriptions:
Mapping agricultural plant roles and biological taxa. <em>FRAI</em>,
<em>6</em>, 1188036. (<a
href="https://doi.org/10.3389/frai.2023.1188036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article describes our study on the alignment of two complementary knowledge graphs useful in agriculture: the thesaurus of cultivated plants in France named French Crop Usage (FCU) and the French national taxonomic repository TAXREF for fauna, flora, and fungi. FCU describes the usages of plants in agriculture: “tomatoes” are crops used for human food, and “grapevines” are crops used for human beverage. TAXREF describes biological taxa and associated scientific names: for example, a tomato species may be “Solanum lycopersicum” or a grapevine species may be “Vitis vinifera”. Both knowledge graphs contain vernacular names of plants but those names are ambiguous. Thus, a group of agricultural experts produced some mappings from FCU crops to TAXREF taxa. Moreover, new RDF properties have been defined to declare those new types of mapping relations between plant descriptions. The metadata for the mappings and the mapping set are encoded with the Simple Standard for Sharing Ontological Mappings (SSSOM), a new model which, among other qualities, offers means to report on provenance of particular interest for this study. The produced mappings are available for download in Recherche Data Gouv, the federated national platform for research data in France.},
  archive      = {J_FRAI},
  author       = {Amardeilh, Florence and Aubin, Sophie and Bernard, Stephan and Bravo, Sonia and Bossy, Robert and Faron, Catherine and Michel, Franck and Raphel, Juliette and Roussey, Catherine},
  doi          = {10.3389/frai.2023.1188036},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1188036},
  shortjournal = {Front. Artif. Intell.},
  title        = {Combining different points of view on plant descriptions: Mapping agricultural plant roles and biological taxa},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Introducing the keyconcept approach to the analysis of
language: The case of regulation in COVID-19 diaries. <em>FRAI</em>,
<em>6</em>, 1176283. (<a
href="https://doi.org/10.3389/frai.2023.1176283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using the Mass Observation corpus of 12th of May Diaries, we investigate concepts that are characteristic of the first coronavirus lockdown in the UK. More specifically, we extract and analyse concepts which are distinctive of the discourses produced in May 2020 in relation to concepts used in the 10 previous years, 2010–2019. In the current paper we focus on the concept of regulation, which we identify through a novel approach to querying semantic content in large datasets. Typically, linguists look at keywords to understand differences between two datasets. We demonstrate that taking the perspective of a keyconcept rather than the keyword in linguistic analysis is a beneficial way of identifying trends in broader patterns of thoughts and behaviours which reflect lived-experiences that are particularly prominent of a given dataset, which, in this current paper, is the COVID-19 era dataset. In order to contextualise the keyconcept analysis, we investigate the discourses surrounding the concept of regulation. We find that diarists communicate collective experience of limited individual agency, surrounded by feelings of fear and gratitude. Diarists&#39; reporting on events is often fragmented, focused on new information, and firmly placed in a temporal frame.},
  archive      = {J_FRAI},
  author       = {Robinson, Justyna A. and Sandow, Rhys J. and Piazza, Roberta},
  doi          = {10.3389/frai.2023.1176283},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1176283},
  shortjournal = {Front. Artif. Intell.},
  title        = {Introducing the keyconcept approach to the analysis of language: The case of regulation in COVID-19 diaries},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Asynchronous deep double dueling q-learning for
trading-signal execution in limit order book markets. <em>FRAI</em>,
<em>6</em>, 1151003. (<a
href="https://doi.org/10.3389/frai.2023.1151003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We employ deep reinforcement learning (RL) to train an agent to successfully translate a high-frequency trading signal into a trading strategy that places individual limit orders. Based on the ABIDES limit order book simulator, we build a reinforcement learning OpenAI gym environment and utilize it to simulate a realistic trading environment for NASDAQ equities based on historic order book messages. To train a trading agent that learns to maximize its trading return in this environment, we use Deep Dueling Double Q-learning with the APEX (asynchronous prioritized experience replay) architecture. The agent observes the current limit order book state, its recent history, and a short-term directional forecast. To investigate the performance of RL for adaptive trading independently from a concrete forecasting algorithm, we study the performance of our approach utilizing synthetic alpha signals obtained by perturbing forward-looking returns with varying levels of noise. Here, we find that the RL agent learns an effective trading strategy for inventory management and order placing that outperforms a heuristic benchmark trading strategy having access to the same signal.},
  archive      = {J_FRAI},
  author       = {Nagy, Peer and Calliess, Jan-Peter and Zohren, Stefan},
  doi          = {10.3389/frai.2023.1151003},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1151003},
  shortjournal = {Front. Artif. Intell.},
  title        = {Asynchronous deep double dueling Q-learning for trading-signal execution in limit order book markets},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Argumentation and explanation in the law. <em>FRAI</em>,
<em>6</em>, 1130559. (<a
href="https://doi.org/10.3389/frai.2023.1130559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the conceptual connection between argumentation and explanation in the law and provides a formal account of it. To do so, the methods used are conceptual analysis from legal theory and formal argumentation from AI. The contribution and results are twofold. On the one hand, we offer a critical reconstruction of the concept of legal argument, justification, and explanation of decision-making as it has been elaborated in legal theory and, above all, in AI and law. On the other hand, we propose some definitions of explanation in the context of formal legal argumentation, showing a connection between formal justification and explanation. We also investigate the notion of stable normative explanation developed elsewhere in Defeasible Logic and extend some complexity results. Our contribution is thus mainly conceptual, and it is meant to show how notions of explanation from literature on explainable AI and legal theory can be modeled in an argumentation framework with structured arguments.},
  archive      = {J_FRAI},
  author       = {Rotolo, Antonino and Sartor, Giovanni},
  doi          = {10.3389/frai.2023.1130559},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1130559},
  shortjournal = {Front. Artif. Intell.},
  title        = {Argumentation and explanation in the law},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A panoramic view of personalization based on individual
differences in persuasive and behavior change interventions.
<em>FRAI</em>, <em>6</em>, 1125191. (<a
href="https://doi.org/10.3389/frai.2023.1125191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Persuasive technologies are designed to change human behavior or attitude using various persuasive strategies. Recent years have witnessed increasing evidence of the need to personalize and adapt persuasive interventions to various users and contextual factors because a persuasive strategy that works for one individual may rather demotivate others. As a result, several research studies have been conducted to investigate how to effectively personalize persuasive technologies. As research in this direction is gaining increasing attention, it becomes essential to conduct a systematic review to provide an overview of the current trends, challenges, approaches used for developing personalized persuasive technologies, and opportunities for future research in the area. To fill this need, we investigate approaches to personalize persuasive interventions by understanding user-related factors considered when personalizing persuasive technologies. Particularly, we conducted a systematic review of 72 research published in the last ten years in personalized and adaptive persuasive systems. The reviewed papers were evaluated based on different aspects, including metadata (e.g., year of publication and venue), technology, personalization dimension, personalization approaches, target outcome, individual differences, theories and scales, and evaluation approaches. Our results show (1) increased attention toward personalizing persuasive interventions, (2) personality trait is the most popular dimension of individual differences considered by existing research when tailoring their persuasive and behavior change systems, (3) students are among the most commonly targeted audience, and (4) education, health, and physical activity are the most considered domains in the surveyed papers. Based on our results, the paper provides insights and prospective future research directions.},
  archive      = {J_FRAI},
  author       = {Alslaity, Alaa and Chan, Gerry and Orji, Rita},
  doi          = {10.3389/frai.2023.1125191},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1125191},
  shortjournal = {Front. Artif. Intell.},
  title        = {A panoramic view of personalization based on individual differences in persuasive and behavior change interventions},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Artificial intelligence in finance and industry:
Volume II—highlights from the 7th european conference. <em>FRAI</em>,
<em>6</em>, 1267377. (<a
href="https://doi.org/10.3389/frai.2023.1267377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Henrici, Andreas and Füchslin, Rudolf M. and Schwendner, Peter},
  doi          = {10.3389/frai.2023.1267377},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1267377},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: artificial intelligence in finance and industry: volume II—highlights from the 7th european conference},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The rise of generative AI and enculturating AI writing in
postsecondary education. <em>FRAI</em>, <em>6</em>, 1259407. (<a
href="https://doi.org/10.3389/frai.2023.1259407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Pedersen, Isabel},
  doi          = {10.3389/frai.2023.1259407},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1259407},
  shortjournal = {Front. Artif. Intell.},
  title        = {The rise of generative AI and enculturating AI writing in postsecondary education},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A risk identification model for detection of patients at
risk of antidepressant discontinuation. <em>FRAI</em>, <em>6</em>,
1229609. (<a href="https://doi.org/10.3389/frai.2023.1229609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PurposeBetween 30 and 68% of patients prematurely discontinue their antidepressant treatment, posing significant risks to patient safety and healthcare outcomes. Online healthcare forums have the potential to offer a rich and unique source of data, revealing dimensions of antidepressant discontinuation that may not be captured by conventional data sources.MethodsWe analyzed 891 patient narratives from the online healthcare forum, “askapatient.com,” utilizing content analysis to create PsyRisk—a corpus highlighting the risk factors associated with antidepressant discontinuation. Leveraging PsyRisk, alongside PsyTAR [a publicly available corpus of adverse drug reactions (ADRs) related to antidepressants], we developed a machine learning-driven algorithm for proactive identification of patients at risk of abrupt antidepressant discontinuation.ResultsFrom the analyzed 891 patients, 232 reported antidepressant discontinuation. Among these patients, 92% experienced ADRs, and 72% found these reactions distressful, negatively affecting their daily activities. Approximately 26% of patients perceived the antidepressants as ineffective. Most reported ADRs were physiological (61%, 411/673), followed by cognitive (30%, 197/673), and psychological (28%, 188/673) ADRs. In our study, we employed a nested cross-validation strategy with an outer 5-fold cross-validation for model selection, and an inner 5-fold cross-validation for hyperparameter tuning. The performance of our risk identification algorithm, as assessed through this robust validation technique, yielded an AUC-ROC of 90.77 and an F1-score of 83.33. The most significant contributors to abrupt discontinuation were high perceived distress from ADRs and perceived ineffectiveness of the antidepressants.ConclusionThe risk factors identified and the risk identification algorithm developed in this study have substantial potential for clinical application. They could assist healthcare professionals in identifying and managing patients with depression who are at risk of prematurely discontinuing their antidepressant treatment.},
  archive      = {J_FRAI},
  author       = {Zolnour, Ali and Eldredge, Christina E. and Faiola, Anthony and Yaghoobzadeh, Yadollah and Khani, Masoud and Foy, Doreen and Topaz, Maxim and Kharrazi, Hadi and Fung, Kin Wah and Fontelo, Paul and Davoudi, Anahita and Tabaie, Azade and Breitinger, Scott A. and Oesterle, Tyler S. and Rouhizadeh, Masoud and Zonnor, Zahra and Moen, Hans and Patrick, Timothy B. and Zolnoori, Maryam},
  doi          = {10.3389/frai.2023.1229609},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1229609},
  shortjournal = {Front. Artif. Intell.},
  title        = {A risk identification model for detection of patients at risk of antidepressant discontinuation},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence in clinical medicine: Catalyzing a
sustainable global healthcare paradigm. <em>FRAI</em>, <em>6</em>,
1227091. (<a href="https://doi.org/10.3389/frai.2023.1227091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the demand for quality healthcare increases, healthcare systems worldwide are grappling with time constraints and excessive workloads, which can compromise the quality of patient care. Artificial intelligence (AI) has emerged as a powerful tool in clinical medicine, revolutionizing various aspects of patient care and medical research. The integration of AI in clinical medicine has not only improved diagnostic accuracy and treatment outcomes, but also contributed to more efficient healthcare delivery, reduced costs, and facilitated better patient experiences. This review article provides an extensive overview of AI applications in history taking, clinical examination, imaging, therapeutics, prognosis and research. Furthermore, it highlights the critical role AI has played in transforming healthcare in developing nations.},
  archive      = {J_FRAI},
  author       = {Krishnan, Gokul and Singh, Shiana and Pathania, Monika and Gosavi, Siddharth and Abhishek, Shuchi and Parchani, Ashwin and Dhar, Minakshi},
  doi          = {10.3389/frai.2023.1227091},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1227091},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence in clinical medicine: Catalyzing a sustainable global healthcare paradigm},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rise of artificial general intelligence: Risks and
opportunities. <em>FRAI</em>, <em>6</em>, 1226990. (<a
href="https://doi.org/10.3389/frai.2023.1226990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence is making extraordinary progress with an unprecedented rate, reaching and surpassing human capabilities in many tasks previously considered unattainable by machines, as language translation, music composition, object detection, medical diagnoses, software programming, and many others. Some people are excited about these results, while others are raising serious concerns for possible negative impacts in our society. This article addresses several questions that are often raised about intelligent machines: Will machines ever surpass human intellectual capacities? What will happen next? What will be the impact in our society? What are the jobs that artificial intelligence puts at risk? Reasoning about these questions is of fundamental importance to predict possible future scenarios and prepare ourselves to face the consequences.},
  archive      = {J_FRAI},
  author       = {Buttazzo, Giorgio},
  doi          = {10.3389/frai.2023.1226990},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1226990},
  shortjournal = {Front. Artif. Intell.},
  title        = {Rise of artificial general intelligence: Risks and opportunities},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Profiling the barriers to the spreading of news using news
headlines. <em>FRAI</em>, <em>6</em>, 1225213. (<a
href="https://doi.org/10.3389/frai.2023.1225213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {News headlines can be a good data source for detecting the barriers to the spreading of news in news media, which can be useful in many real-world applications. In this study, we utilize semantic knowledge through the inference-based model COMET and the sentiments of news headlines for barrier classification. We consider five barriers, including cultural, economic, political, linguistic, and geographical and different types of news headlines, including health, sports, science, recreation, games, homes, society, shopping, computers, and business. To that end, we collect and label the news headlines automatically for the barriers using the metadata of news publishers. Then, we utilize the extracted common-sense inferences and sentiments as features to detect the barriers to the spreading of news. We compare our approach to the classical text classification methods, deep learning, and transformer-based methods. The results show that (1) the inference-based semantic knowledge provides distinguishable inferences across the 10 categories that can increase the effectiveness and enhance the speed of the classification model; (2) the news of positive sentiments cross the political barrier, whereas the news of negative sentiments cross the cultural, economic, linguistic, and geographical barriers; (3) the proposed approach using inferences-based semantic knowledge and sentiment improves performance compared with using only headlines in barrier classification. The average F1-score for 4 out of 5 barriers has significantly improved as follows: for cultural barriers from 0.41 to 0.47, for economic barriers from 0.39 to 0.55, for political barriers from 0.59 to 0.70 and for geographical barriers from 0.59 to 0.76.},
  archive      = {J_FRAI},
  author       = {Sittar, Abdul and Mladenić, Dunja and Grobelnik, Marko},
  doi          = {10.3389/frai.2023.1225213},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1225213},
  shortjournal = {Front. Artif. Intell.},
  title        = {Profiling the barriers to the spreading of news using news headlines},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bone fracture detection—can artificial intelligence replace
doctors in orthopedic radiography analysis? <em>FRAI</em>, <em>6</em>,
1223909. (<a href="https://doi.org/10.3389/frai.2023.1223909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Hussain, Aariz and Fareed, Areeba and Taseen, Shafaq},
  doi          = {10.3389/frai.2023.1223909},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1223909},
  shortjournal = {Front. Artif. Intell.},
  title        = {Bone fracture detection—Can artificial intelligence replace doctors in orthopedic radiography analysis?},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mobile robotics in smart farming: Current trends and
applications. <em>FRAI</em>, <em>6</em>, 1213330. (<a
href="https://doi.org/10.3389/frai.2023.1213330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, precision agriculture and smart farming have been deployed by leaps and bounds as arable land has become increasingly scarce. According to the Food and Agriculture Organization (FAO), by the year 2050, farming in the world should grow by about one-third above current levels. Therefore, farmers have intensively used fertilizers to promote crop growth and yields, which has adversely affected the nutritional improvement of foodstuffs. To address challenges related to productivity, environmental impact, food safety, crop losses, and sustainability, mobile robots in agriculture have proliferated, integrating mainly path planning and crop information gathering processes. Current agricultural robotic systems are large in size and cost because they use a computer as a server and mobile robots as clients. This article reviews the use of mobile robotics in farming to reduce costs, reduce environmental impact, and optimize harvests. The current status of mobile robotics, the technologies employed, the algorithms applied, and the relevant results obtained in smart farming are established. Finally, challenges to be faced in new smart farming techniques are also presented: environmental conditions, implementation costs, technical requirements, process automation, connectivity, and processing potential. As part of the contributions of this article, it was possible to conclude that the leading technologies for the implementation of smart farming are as follows: the Internet of Things (IoT), mobile robotics, artificial intelligence, artificial vision, multi-objective control, and big data. One technological solution that could be implemented is developing a fully autonomous, low-cost agricultural mobile robotic system that does not depend on a server.},
  archive      = {J_FRAI},
  author       = {Yépez-Ponce, Darío Fernando and Salcedo, José Vicente and Rosero-Montalvo, Paúl D. and Sanchis, Javier},
  doi          = {10.3389/frai.2023.1213330},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1213330},
  shortjournal = {Front. Artif. Intell.},
  title        = {Mobile robotics in smart farming: Current trends and applications},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine vs. Human, who makes a better judgment on
innovation? Take GPT-4 for example. <em>FRAI</em>, <em>6</em>, 1206516.
(<a href="https://doi.org/10.3389/frai.2023.1206516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionHuman decision-making is a complex process that is often influenced by various external and internal factors. One such factor is noise, random, and irrelevant influences that can skew outcomes.MethodsThis essay uses the CAT test and computer simulations to measure creativity.ResultsEvidence indicates that humans are intrinsically prone to noise, leading to inconsistent and, at times, inaccurate decisions. In contrast, simple rules demonstrate a higher level of accuracy and consistency, while artificial intelligence demonstrates an even higher capability to process vast data and employ logical algorithms.DiscussionThe potential of AI, particularly its intuitive capabilities, might be surpassing human intuition in specific decision-making scenarios. This raises crucial questions about the future roles of humans and machines in decision-making spheres, especially in domains where precision is paramount.},
  archive      = {J_FRAI},
  author       = {Du, Mark},
  doi          = {10.3389/frai.2023.1206516},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1206516},
  shortjournal = {Front. Artif. Intell.},
  title        = {Machine vs. human, who makes a better judgment on innovation? take GPT-4 for example},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predicting ward transfer mortality with machine learning.
<em>FRAI</em>, <em>6</em>, 1191320. (<a
href="https://doi.org/10.3389/frai.2023.1191320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to address a long standing challenge for internal medicine physicians we developed artificial intelligence (AI) models to identify patients at risk of increased mortality. After querying 2,425 records of patients transferred from non-intensive care units to intensive care units from the Veteran Affairs Corporate Data Warehouse (CDW), we created two datasets. The former used 22 independent variables that included “Length of Hospital Stay” and “Days to Intensive Care Transfer,” and the latter lacked these two variables. Since these two variables are unknown at the time of admission, the second set is more clinically relevant. We trained 16 machine learning models using both datasets. The best-performing models were fine-tuned and evaluated. The LightGBM model achieved the best results for both datasets. The model trained with 22 variables achieved a Receiver Operating Characteristics Curve-Area Under the Curve (ROC-AUC) of 0.89 and an accuracy of 0.72, with a sensitivity of 0.97 and a specificity of 0.68. The model trained with 20 variables achieved a ROC-AUC of 0.86 and an accuracy of 0.71, with a sensitivity of 0.94 and a specificity of 0.67. The top features for the former model included “Total length of Stay,” “Admit to ICU Transfer Days,” and “Lymphocyte Next Lab Value.” For the latter model, the top features included “Lymphocyte First Lab Value,” “Hemoglobin First Lab Value,” and “Hemoglobin Next Lab Value.” Our clinically relevant predictive mortality model can assist providers in optimizing resource utilization when managing large caseloads, particularly during shift changes.},
  archive      = {J_FRAI},
  author       = {Lezama, Jose L. and Alterovitz, Gil and Jakey, Colleen E. and Kraus, Ana L. and Kim, Michael J. and Borkowski, Andrew A.},
  doi          = {10.3389/frai.2023.1191320},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1191320},
  shortjournal = {Front. Artif. Intell.},
  title        = {Predicting ward transfer mortality with machine learning},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development of a knowledge graph framework to ease and
empower translational approaches in plant research: A use-case on grain
legumes. <em>FRAI</em>, <em>6</em>, 1191122. (<a
href="https://doi.org/10.3389/frai.2023.1191122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the continuing decline in genotyping and sequencing costs has largely benefited plant research, some key species for meeting the challenges of agriculture remain mostly understudied. As a result, heterogeneous datasets for different traits are available for a significant number of these species. As gene structures and functions are to some extent conserved through evolution, comparative genomics can be used to transfer available knowledge from one species to another. However, such a translational research approach is complex due to the multiplicity of data sources and the non-harmonized description of the data. Here, we provide two pipelines, referred to as structural and functional pipelines, to create a framework for a NoSQL graph-database (Neo4j) to integrate and query heterogeneous data from multiple species. We call this framework Orthology-driven knowledge base framework for translational research (Ortho_KB). The structural pipeline builds bridges across species based on orthology. The functional pipeline integrates biological information, including QTL, and RNA-sequencing datasets, and uses the backbone from the structural pipeline to connect orthologs in the database. Queries can be written using the Neo4j Cypher language and can, for instance, lead to identify genes controlling a common trait across species. To explore the possibilities offered by such a framework, we populated Ortho_KB to obtain OrthoLegKB, an instance dedicated to legumes. The proposed model was evaluated by studying the conservation of a flowering-promoting gene. Through a series of queries, we have demonstrated that our knowledge graph base provides an intuitive and powerful platform to support research and development programmes.},
  archive      = {J_FRAI},
  author       = {Imbert, Baptiste and Kreplak, Jonathan and Flores, Raphaël-Gauthier and Aubert, Grégoire and Burstin, Judith and Tayeh, Nadim},
  doi          = {10.3389/frai.2023.1191122},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1191122},
  shortjournal = {Front. Artif. Intell.},
  title        = {Development of a knowledge graph framework to ease and empower translational approaches in plant research: A use-case on grain legumes},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of mental effort derived from an automated vocal
biomarker using machine learning in a large-scale remote sample.
<em>FRAI</em>, <em>6</em>, 1171652. (<a
href="https://doi.org/10.3389/frai.2023.1171652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionBiomarkers of mental effort may help to identify subtle cognitive impairments in the absence of task performance deficits. Here, we aim to detect mental effort on a verbal task, using automated voice analysis and machine learning.MethodsAudio data from the digit span backwards task were recorded and scored with automated speech recognition using the online platform NeuroVocalixTM, yielding usable data from 2,764 healthy adults (1,022 male, 1,742 female; mean age 31.4 years). Acoustic features were aggregated across each trial and normalized within each subject. Cognitive load was dichotomized for each trial by categorizing trials at &amp;gt;0.6 of each participants&#39; maximum span as “high load.” Data were divided into training (60%), test (20%), and validate (20%) datasets, each containing different participants. Training and test data were used in model building and hyper-parameter tuning. Five classification models (Logistic Regression, Naive Bayes, Support Vector Machine, Random Forest, and Gradient Boosting) were trained to predict cognitive load (“high” vs. “low”) based on acoustic features. Analyses were limited to correct responses. The model was evaluated using the validation dataset, across all span lengths and within the subset of trials with a four-digit span. Classifier discriminant power was examined with Receiver Operating Curve (ROC) analysis.ResultsParticipants reached a mean span of 6.34 out of 8 items (SD = 1.38). The Gradient Boosting classifier provided the best performing model on test data (AUC = 0.98) and showed excellent discriminant power for cognitive load on the validation dataset, across all span lengths (AUC = 0.99), and for four-digit only utterances (AUC = 0.95).DiscussionA sensitive biomarker of mental effort can be derived from vocal acoustic features in remotely administered verbal cognitive tests. The use-case of this biomarker for improving sensitivity of cognitive tests to subtle pathology now needs to be examined.},
  archive      = {J_FRAI},
  author       = {Taptiklis, Nick and Su, Merina and Barnett, Jennifer H. and Skirrow, Caroline and Kroll, Jasmin and Cormack, Francesca},
  doi          = {10.3389/frai.2023.1171652},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1171652},
  shortjournal = {Front. Artif. Intell.},
  title        = {Prediction of mental effort derived from an automated vocal biomarker using machine learning in a large-scale remote sample},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Toward the appropriate interpretation of alphafold2.
<em>FRAI</em>, <em>6</em>, 1149748. (<a
href="https://doi.org/10.3389/frai.2023.1149748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In life science, protein is an essential building block for life forms and a crucial catalyst for metabolic reactions in organisms. The structures of protein depend on an infinity of amino acid residues&#39; complex combinations determined by gene expression. Predicting protein folding structures has been a tedious problem in the past seven decades but, due to robust development of artificial intelligence, astonishing progress has been made. Alphafold2, whose key component is Evoformer, is a typical and successful example of such progress. This article attempts to not only isolate and dissect every detail of Evoformer, but also raise some ideas for potential improvement.},
  archive      = {J_FRAI},
  author       = {Xu, Tian and Xu, Qin and Li, Jianyong},
  doi          = {10.3389/frai.2023.1149748},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1149748},
  shortjournal = {Front. Artif. Intell.},
  title        = {Toward the appropriate interpretation of alphafold2},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning and reasoning with graph data. <em>FRAI</em>,
<em>6</em>, 1124718. (<a
href="https://doi.org/10.3389/frai.2023.1124718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reasoning about graphs, and learning from graph data is a field of artificial intelligence that has recently received much attention in the machine learning areas of graph representation learning and graph neural networks. Graphs are also the underlying structures of interest in a wide range of more traditional fields ranging from logic-oriented knowledge representation and reasoning to graph kernels and statistical relational learning. In this review we outline a broad map and inventory of the field of learning and reasoning with graphs that spans the spectrum from reasoning in the form of logical deduction to learning node embeddings. To obtain a unified perspective on such a diverse landscape we introduce a simple and general semantic concept of a model that covers logic knowledge bases, graph neural networks, kernel support vector machines, and many other types of frameworks. Still at a high semantic level, we survey common strategies for model specification using probabilistic factorization and standard feature construction techniques. Based on this semantic foundation we introduce a taxonomy of reasoning tasks that casts problems ranging from transductive link prediction to asymptotic analysis of random graph models as queries of different complexities for a given model. Similarly, we express learning in different frameworks and settings in terms of a common statistical maximum likelihood principle. Overall, this review aims to provide a coherent conceptual framework that provides a basis for further theoretical analyses of respective strengths and limitations of different approaches to handling graph data, and that facilitates combination and integration of different modeling paradigms.},
  archive      = {J_FRAI},
  author       = {Jaeger, Manfred},
  doi          = {10.3389/frai.2023.1124718},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1124718},
  shortjournal = {Front. Artif. Intell.},
  title        = {Learning and reasoning with graph data},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the use of sentiment analysis for linguistics research.
Observations on sentiment polarity and the use of the progressive in
italian. <em>FRAI</em>, <em>6</em>, 1101364. (<a
href="https://doi.org/10.3389/frai.2023.1101364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article offers a conceptual and methodological contribution to linguistics by exploring the potential value of using sentiment analysis (SA) for research in this field. Firstly, it discusses the limitations and advantages of using SA for linguistics research including the wider epistemological implications of its application outside of its original conception as a product reviews analysis tool. Methodologically, it tests its applicability against an established linguistic case: the correlation between subjective attitudes such as surprise, irritation and discontent and the use of the progressive. The language example is Italian for which this function of the progressive form has not been analyzed yet. The analysis applies FEEL-IT, a state-of-the-art transformer-based machine learning model for emotion and sentiment classification in Italian on language samples from various sources as collected in Evalita-2014 (238,556 words). The results show statistically significant correlations between negative subjective attitudes and the use of the progressive in line with previous accounts in other languages. The article concludes with a few additional propositions for practitioners and researchers using SA.},
  archive      = {J_FRAI},
  author       = {Viola, Lorella},
  doi          = {10.3389/frai.2023.1101364},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1101364},
  shortjournal = {Front. Artif. Intell.},
  title        = {On the use of sentiment analysis for linguistics research. observations on sentiment polarity and the use of the progressive in italian},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Local transplantation, adaptation, and creation of AI models
for public health policy. <em>FRAI</em>, <em>6</em>, 1085671. (<a
href="https://doi.org/10.3389/frai.2023.1085671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the Transplantation, Adaptation and Creation (TAC) framework, a method for assessing the localization of different elements of an AI system. This framework is applied in the public health context, notably to different types of models that were used during the COVID-19 pandemic. The framework aims to guide AI for public health developers and public health officials in conceptualizing model localization. The paper provides guidance justifying the importance of model localization, within a broader context of policy models, geopolitics and decolonization. It also suggests procedures for moving between the different elements in the framework, for example going from transplantation to adapation, and from adaptation to creation. This paper is submitted as part of a special research topic entitled: A digitally-enabled, science-based global pandemic preparedness and response scheme: how ready are we for the next pandemic?},
  archive      = {J_FRAI},
  author       = {Fournier-Tombs, Eleonore},
  doi          = {10.3389/frai.2023.1085671},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1085671},
  shortjournal = {Front. Artif. Intell.},
  title        = {Local transplantation, adaptation, and creation of AI models for public health policy},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mapping cover crop species in southeastern michigan using
sentinel-2 satellite data and google earth engine. <em>FRAI</em>,
<em>6</em>, 1035502. (<a
href="https://doi.org/10.3389/frai.2023.1035502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cover crops are a critical agricultural practice that can improve soil quality, enhance crop yields, and reduce nitrogen and phosphorus losses from farms. Yet there is limited understanding of the extent to which cover crops have been adopted across large spatial and temporal scales. Remote sensing offers a low-cost way to monitor cover crop adoption at the field scale and at large spatio-temporal scales. To date, most studies using satellite data have mapped the presence of cover crops, but have not identified specific cover crop species, which is important because cover crops of different plant functional types (e.g., legumes, grasses) perform different ecosystem functions. Here we use Sentinel-2 satellite data and a random forest classifier to map the cover crop species cereal rye and red clover, which represent grass and legume functional types, in the River Raisin watershed in southeastern Michigan. Our maps of agricultural landcover across this region, including the two cover crop species, had moderate to high accuracies, with an overall accuracy of 83%. Red clover and cereal rye achieved F1 scores that ranged from 0.7 to 0.77, and user&#39;s and producer&#39;s accuracies that ranged from 63.3% to 86.2%. The most common misclassification of cover crops was fallow fields with remaining crop stubble, which often looked similar because these cover crop species are typically planted within existing crop stubble, or interseeded into a grain crop. We found that red-edge bands and images from the end of April and early July were the most important for classification accuracy. Our results demonstrate the potential to map individual cover crop species using Sentinel-2 imagery, which is critical for understanding the environmental outcomes of increasing crop diversity on farms.},
  archive      = {J_FRAI},
  author       = {Wang, Xuewei and Blesh, Jennifer and Rao, Preeti and Paliwal, Ambica and Umashaanker, Maanya and Jain, Meha},
  doi          = {10.3389/frai.2023.1035502},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1035502},
  shortjournal = {Front. Artif. Intell.},
  title        = {Mapping cover crop species in southeastern michigan using sentinel-2 satellite data and google earth engine},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Ethical design of artificial intelligence-based
systems for decision making. <em>FRAI</em>, <em>6</em>, 1250209. (<a
href="https://doi.org/10.3389/frai.2023.1250209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Biondi, Giulio and Cagnoni, Stefano and Capobianco, Roberto and Franzoni, Valentina and Lisi, Francesca A. and Milani, Alfredo and Vallverdú, Jordi},
  doi          = {10.3389/frai.2023.1250209},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1250209},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Ethical design of artificial intelligence-based systems for decision making},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Supervised machine learning models for depression sentiment
analysis. <em>FRAI</em>, <em>6</em>, 1230649. (<a
href="https://doi.org/10.3389/frai.2023.1230649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionGlobally, the prevalence of mental health problems, especially depression, is at an all-time high. The objective of this study is to utilize machine learning models and sentiment analysis techniques to predict the level of depression earlier in social media users&#39; posts.MethodsThe datasets used in this research were obtained from Twitter posts. Four machine learning models, namely extreme gradient boost (XGB) Classifier, Random Forest, Logistic Regression, and support vector machine (SVM), were employed for the prediction task.ResultsThe SVM and Logistic Regression models yielded the most accurate results when applied to the provided datasets. However, the Logistic Regression model exhibited a slightly higher level of accuracy compared to SVM. Importantly, the logistic regression model demonstrated the advantage of requiring less execution time.DiscussionThe findings of this study highlight the potential of utilizing machine learning models and sentiment analysis techniques for early detection of depression in social media users. The effectiveness of SVM and Logistic Regression models, with Logistic Regression being more efficient in terms of execution time, suggests their suitability for practical implementation in real-world scenarios.},
  archive      = {J_FRAI},
  author       = {Obagbuwa, Ibidun Christiana and Danster, Samantha and Chibaya, Onil Colin},
  doi          = {10.3389/frai.2023.1230649},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1230649},
  shortjournal = {Front. Artif. Intell.},
  title        = {Supervised machine learning models for depression sentiment analysis},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence vs. Evolving super-complex tumor
intelligence: Critical viewpoints. <em>FRAI</em>, <em>6</em>, 1220744.
(<a href="https://doi.org/10.3389/frai.2023.1220744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent developments in various domains have led to a growing interest in the potential of artificial intelligence to enhance our lives and environments. In particular, the application of artificial intelligence in the management of complex human diseases, such as cancer, has garnered significant attention. The evolution of artificial intelligence is thought to be influenced by multiple factors, including human intervention and environmental factors. Similarly, tumors, being heterogeneous and complex diseases, continue to evolve due to changes in the physical, chemical, and biological environment. Additionally, the concept of cellular intelligence within biological systems has been recognized as a potential attribute of biological entities. Therefore, it is plausible that the tumor intelligence present in cancer cells of affected individuals could undergo super-evolution due to changes in the pro-tumor environment. Thus, a comparative analysis of the evolution of artificial intelligence and super-complex tumor intelligence could yield valuable insights to develop better artificial intelligence-based tools for cancer management.},
  archive      = {J_FRAI},
  author       = {Sharma, Nilesh Kumar and Sarode, Sachin C.},
  doi          = {10.3389/frai.2023.1220744},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1220744},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence vs. evolving super-complex tumor intelligence: Critical viewpoints},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Persuasive technology and computational manipulation:
Hypernudging out of mental self-determination. <em>FRAI</em>,
<em>6</em>, 1216340. (<a
href="https://doi.org/10.3389/frai.2023.1216340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence, unperceived, can acquire the user&#39;s data, find connections not visible by a human being, profile the users, and aim at persuading them, resulting in Persuasive Technology (PT). During the persuasive process, PT can use manipulation, finding and using routes to affect System 1, the primordial brain of individuals, in the absence of their awareness, undermining their decision-making processes. Multiple international and European bodies recognized that AI systems could use manipulation at an unprecedented degree via second-generation dark patterns such as the hypernudge and that computational manipulation constitutes a risk for autonomy and different, overlapping, fundamental rights such as privacy, informational self-determination and freedom of thought. However, there is a lack of shared ideas regarding which fundamental rights are violated by computational manipulation and which fundamental rights can protect individuals against it. The right to be let alone and the right to hold and express a thought differ from the right to create a thought, being in control of the decision-making process and free from cognitive interferences operated by computational manipulation. Therefore, this paper argues in favor of recognizing a newly emerged fundamental right, the right to mental self-determination, tailored to the unprecedented abilities of AI-driven manipulative technologies.},
  archive      = {J_FRAI},
  author       = {Faraoni, Stefano},
  doi          = {10.3389/frai.2023.1216340},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1216340},
  shortjournal = {Front. Artif. Intell.},
  title        = {Persuasive technology and computational manipulation: Hypernudging out of mental self-determination},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep hybrid model for maternal health risk classification in
pregnancy: Synergy of ANN and random forest. <em>FRAI</em>, <em>6</em>,
1213436. (<a href="https://doi.org/10.3389/frai.2023.1213436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionMaternal health is a critical aspect of public health that affects the wellbeing of both mothers and infants. Despite medical advancements, maternal mortality rates remain high, particularly in developing countries. AI-based models provide new ways to analyze and interpret medical data, which can ultimately improve maternal and fetal health outcomes.MethodsThis study proposes a deep hybrid model for maternal health risk classification in pregnancy, which utilizes the strengths of artificial neural networks (ANN) and random forest (RF) algorithms. The proposed model combines the two algorithms to improve the accuracy and efficiency of risk classification in pregnant women. The dataset used in this study consists of features such as age, systolic and diastolic blood pressure, blood sugar, body temperature, and heart rate. The dataset is divided into training and testing sets, with 75% of the data used for training and 25% used for testing. The output of the ANN and RF classifier is considered, and a maximum probability voting system selects the output with the highest probability as the most correct.ResultsPerformance is evaluated using various metrics, such as accuracy, precision, recall, and F1 score. Results showed that the proposed model achieves 95% accuracy, 97% precision, 97% recall, and an F1 score of 0.97 on the testing dataset.DiscussionThe deep hybrid model proposed in this study has the potential to improve the accuracy and efficiency of maternal health risk classification in pregnancy, leading to better health outcomes for pregnant women and their babies. Future research could explore the generalizability of this model to other populations, incorporate unstructured medical data, and evaluate its feasibility for clinical use.},
  archive      = {J_FRAI},
  author       = {Togunwa, Taofeeq Oluwatosin and Babatunde, Abdulhammed Opeyemi and Abdullah, Khalil-ur-Rahman},
  doi          = {10.3389/frai.2023.1213436},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1213436},
  shortjournal = {Front. Artif. Intell.},
  title        = {Deep hybrid model for maternal health risk classification in pregnancy: Synergy of ANN and random forest},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Counterfactual learning in enhancing resilience in
autonomous agent systems. <em>FRAI</em>, <em>6</em>, 1212336. (<a
href="https://doi.org/10.3389/frai.2023.1212336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resilience in autonomous agent systems is about having the capacity to anticipate, respond to, adapt to, and recover from adverse and dynamic conditions in complex environments. It is associated with the intelligence possessed by the agents to preserve the functionality or to minimize the impact on functionality through a transformation, reconfiguration, or expansion performed across the system. Enhancing the resilience of systems could pave way toward higher autonomy allowing them to tackle intricate dynamic problems. The state-of-the-art systems have mostly focussed on improving the redundancy of the system, adopting decentralized control architectures, and utilizing distributed sensing capabilities. While machine learning approaches for efficient distribution and allocation of skills and tasks have enhanced the potential of these systems, they are still limited when presented with dynamic environments. To move beyond the current limitations, this paper advocates incorporating counterfactual learning models for agents to enable them with the ability to predict possible future conditions and adjust their behavior. Counterfactual learning is a topic that has recently been gaining attention as a model-agnostic and post-hoc technique to improve explainability in machine learning models. Using counterfactual causality can also help gain insights into unforeseen circumstances and make inferences about the probability of desired outcomes. We propose that this can be used in agent systems as a means to guide and prepare them to cope with unanticipated environmental conditions. This supplementary support for adaptation can enable the design of more intelligent and complex autonomous agent systems to address the multifaceted characteristics of real-world problem domains.},
  archive      = {J_FRAI},
  author       = {Samarasinghe, Dilini},
  doi          = {10.3389/frai.2023.1212336},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1212336},
  shortjournal = {Front. Artif. Intell.},
  title        = {Counterfactual learning in enhancing resilience in autonomous agent systems},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identifying the role of vision transformer for skin cancer—a
scoping review. <em>FRAI</em>, <em>6</em>, 1202990. (<a
href="https://doi.org/10.3389/frai.2023.1202990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionDetecting and accurately diagnosing early melanocytic lesions is challenging due to extensive intra- and inter-observer variabilities. Dermoscopy images are widely used to identify and study skin cancer, but the blurred boundaries between lesions and besieging tissues can lead to incorrect identification. Artificial Intelligence (AI) models, including vision transformers, have been proposed as a solution, but variations in symptoms and underlying effects hinder their performance.ObjectiveThis scoping review synthesizes and analyzes the literature that uses vision transformers for skin lesion detection.MethodsThe review follows the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Revise) guidelines. The review searched online repositories such as IEEE Xplore, Scopus, Google Scholar, and PubMed to retrieve relevant articles. After screening and pre-processing, 28 studies that fulfilled the inclusion criteria were included.Results and discussionsThe review found that the use of vision transformers for skin cancer detection has rapidly increased from 2020 to 2022 and has shown outstanding performance for skin cancer detection using dermoscopy images. Along with highlighting intrinsic visual ambiguities, irregular skin lesion shapes, and many other unwanted challenges, the review also discusses the key problems that obfuscate the trustworthiness of vision transformers in skin cancer diagnosis. This review provides new insights for practitioners and researchers to understand the current state of knowledge in this specialized research domain and outlines the best segmentation techniques to identify accurate lesion boundaries and perform melanoma diagnosis. These findings will ultimately assist practitioners and researchers in making more authentic decisions promptly.},
  archive      = {J_FRAI},
  author       = {Khan, Sulaiman and Ali, Hazrat and Shah, Zubair},
  doi          = {10.3389/frai.2023.1202990},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1202990},
  shortjournal = {Front. Artif. Intell.},
  title        = {Identifying the role of vision transformer for skin cancer—A scoping review},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inside out: Transforming images of lab-grown plants for
machine learning applications in agriculture. <em>FRAI</em>, <em>6</em>,
1200977. (<a href="https://doi.org/10.3389/frai.2023.1200977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionMachine learning tasks often require a significant amount of training data for the resultant network to perform suitably for a given problem in any domain. In agriculture, dataset sizes are further limited by phenotypical differences between two plants of the same genotype, often as a result of different growing conditions. Synthetically-augmented datasets have shown promise in improving existing models when real data is not available.MethodsIn this paper, we employ a contrastive unpaired translation (CUT) generative adversarial network (GAN) and simple image processing techniques to translate indoor plant images to appear as field images. While we train our network to translate an image containing only a single plant, we show that our method is easily extendable to produce multiple-plant field images.ResultsFurthermore, we use our synthetic multi-plant images to train several YoloV5 nano object detection models to perform the task of plant detection and measure the accuracy of the model on real field data images.DiscussionThe inclusion of training data generated by the CUT-GAN leads to better plant detection performance compared to a network trained solely on real data.},
  archive      = {J_FRAI},
  author       = {Krosney, Alexander E. and Sotoodeh, Parsa and Henry, Christopher J. and Beck, Michael A. and Bidinosti, Christopher P.},
  doi          = {10.3389/frai.2023.1200977},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1200977},
  shortjournal = {Front. Artif. Intell.},
  title        = {Inside out: Transforming images of lab-grown plants for machine learning applications in agriculture},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using ChatGPT to navigate ambivalent and contradictory
research findings on artificial intelligence. <em>FRAI</em>, <em>6</em>,
1195797. (<a href="https://doi.org/10.3389/frai.2023.1195797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development and integration of AI in various domains, understanding the nuances of AI research has become critical for policymakers, researchers, and practitioners. However, the results are vast and diverse and even can be contradictory or ambivalent, presenting a significant challenge for individuals seeking to grasp and synthesize the findings. This perspective paper discusses the ambivalent and contradictory research findings in the literature on artificial intelligence (AI) and explores whether ChatGPT can be used to navigate and make sense of the AI literature.},
  archive      = {J_FRAI},
  author       = {Sohail, Shahab Saquib and Madsen, Dag Øivind and Himeur, Yassine and Ashraf, Maheen},
  doi          = {10.3389/frai.2023.1195797},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1195797},
  shortjournal = {Front. Artif. Intell.},
  title        = {Using ChatGPT to navigate ambivalent and contradictory research findings on artificial intelligence},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning-based prediction of hospital prolonged
length of stay admission at emergency department: A gradient boosting
algorithm analysis. <em>FRAI</em>, <em>6</em>, 1179226. (<a
href="https://doi.org/10.3389/frai.2023.1179226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ObjectiveThis study aims to develop and compare different models to predict the Length of Stay (LoS) and the Prolonged Length of Stay (PLoS) of inpatients admitted through the emergency department (ED) in general patient settings. This aim is not only to promote any specific model but rather to suggest a decision-supporting tool (i.e., a prediction framework).MethodsWe analyzed a dataset of patients admitted through the ED to the “Sant”Orsola Malpighi University Hospital of Bologna, Italy, between January 1 and October 26, 2022. PLoS was defined as any hospitalization with LoS longer than 6 days. We deployed six classification algorithms for predicting PLoS: Random Forest (RF), Support Vector Machines (SVM), Gradient Boosting (GB), AdaBoost, K-Nearest Neighbors (KNN), and logistic regression (LoR). We evaluated the performance of these models with the Brier score, the area under the ROC curve (AUC), accuracy, sensitivity (recall), specificity, precision, and F1-score. We further developed eight regression models for LoS prediction: Linear Regression (LR), including the penalized linear models Least Absolute Shrinkage and Selection Operator (LASSO), Ridge and Elastic-net regression, Support vector regression, RF regression, KNN, and eXtreme Gradient Boosting (XGBoost) regression. The model performances were measured by their mean square error, mean absolute error, and mean relative error. The dataset was randomly split into a training set (70%) and a validation set (30%).ResultsA total of 12,858 eligible patients were included in our study, of whom 60.88% had a PloS. The GB classifier best predicted PloS (accuracy 75%, AUC 75.4%, Brier score 0.181), followed by LoR classifier (accuracy 75%, AUC 75.2%, Brier score 0.182). These models also showed to be adequately calibrated. Ridge and XGBoost regressions best predicted LoS, with the smallest total prediction error. The overall prediction error is between 6 and 7 days, meaning there is a 6–7 day mean difference between actual and predicted LoS.ConclusionOur results demonstrate the potential of machine learning-based methods to predict LoS and provide valuable insights into the risks behind prolonged hospitalizations. In addition to physicians&#39; clinical expertise, the results of these models can be utilized as input to make informed decisions, such as predicting hospitalizations and enhancing the overall performance of a public healthcare system.},
  archive      = {J_FRAI},
  author       = {Zeleke, Addisu Jember and Palumbo, Pierpaolo and Tubertini, Paolo and Miglio, Rossella and Chiari, Lorenzo},
  doi          = {10.3389/frai.2023.1179226},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1179226},
  shortjournal = {Front. Artif. Intell.},
  title        = {Machine learning-based prediction of hospital prolonged length of stay admission at emergency department: A gradient boosting algorithm analysis},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated feedback and writing: A multi-level meta-analysis
of effects on students’ performance. <em>FRAI</em>, <em>6</em>, 1162454.
(<a href="https://doi.org/10.3389/frai.2023.1162454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionAdaptive learning opportunities and individualized, timely feedback are considered to be effective support measures for students&#39; writing in educational contexts. However, the extensive time and expertise required to analyze numerous drafts of student writing pose a barrier to teaching. Automated writing evaluation (AWE) tools can be used for individual feedback based on advances in Artificial Intelligence (AI) technology. A number of primary (quasi-)experimental studies have investigated the effect of AWE feedback on students&#39; writing performance.MethodsThis paper provides a meta-analysis of the effectiveness of AWE feedback tools. The literature search yielded 4,462 entries, of which 20 studies (k = 84; N = 2, 828) met the pre-specified inclusion criteria. A moderator analysis investigated the impact of the characteristics of the learner, the intervention, and the outcome measures.ResultsOverall, results based on a three-level model with random effects show a medium effect (g = 0.55) of automated feedback on students&#39; writing performance. However, the significant heterogeneity in the data indicates that the use of automated feedback tools cannot be understood as a single consistent form of intervention. Even though for some of the moderators we found substantial differences in effect sizes, none of the subgroup comparisons were statistically significant.DiscussionWe discuss these findings in light of automated feedback use in educational practice and give recommendations for future research.},
  archive      = {J_FRAI},
  author       = {Fleckenstein, Johanna and Liebenow, Lucas W. and Meyer, Jennifer},
  doi          = {10.3389/frai.2023.1162454},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1162454},
  shortjournal = {Front. Artif. Intell.},
  title        = {Automated feedback and writing: A multi-level meta-analysis of effects on students&#39; performance},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Specific challenges posed by artificial intelligence in
research ethics. <em>FRAI</em>, <em>6</em>, 1149082. (<a
href="https://doi.org/10.3389/frai.2023.1149082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundThe twenty first century is often defined as the era of Artificial Intelligence (AI), which raises many questions regarding its impact on society. It is already significantly changing many practices in different fields. Research ethics (RE) is no exception. Many challenges, including responsibility, privacy, and transparency, are encountered. Research ethics boards (REB) have been established to ensure that ethical practices are adequately followed during research projects. This scoping review aims to bring out the challenges of AI in research ethics and to investigate if REBs are equipped to evaluate them.MethodsThree electronic databases were selected to collect peer-reviewed articles that fit the inclusion criteria (English or French, published between 2016 and 2021, containing AI, RE, and REB). Two instigators independently reviewed each piece by screening with Covidence and then coding with NVivo.ResultsFrom having a total of 657 articles to review, we were left with a final sample of 28 relevant papers for our scoping review. The selected literature described AI in research ethics (i.e., views on current guidelines, key ethical concept and approaches, key issues of the current state of AI-specific RE guidelines) and REBs regarding AI (i.e., their roles, scope and approaches, key practices and processes, limitations and challenges, stakeholder perceptions). However, the literature often described REBs ethical assessment practices of projects in AI research as lacking knowledge and tools.ConclusionEthical reflections are taking a step forward while normative guidelines adaptation to AI&#39;s reality is still dawdling. This impacts REBs and most stakeholders involved with AI. Indeed, REBs are not equipped enough to adequately evaluate AI research ethics and require standard guidelines to help them do so.},
  archive      = {J_FRAI},
  author       = {Bouhouita-Guermech, Sarah and Gogognon, Patrick and Bélisle-Pipon, Jean-Christophe},
  doi          = {10.3389/frai.2023.1149082},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1149082},
  shortjournal = {Front. Artif. Intell.},
  title        = {Specific challenges posed by artificial intelligence in research ethics},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An intelligence coordination system toward creating the
super-intelligent law firm. <em>FRAI</em>, <em>6</em>, 1145308. (<a
href="https://doi.org/10.3389/frai.2023.1145308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A large law firm typically exhibits a collective intelligence comprised of hundreds or thousands of legal minds aimed at simultaneously engaging thousands of active matters across scores of industries and dozens of practice specialties with distinct doctrinal and procedural characteristics. The firm is challenged not only to achieve successful, cost-effective outcomes for its clients, but must also simultaneously, in competition with other firms and alternative service providers, attract and cultivate talent, develop and coordinate capabilities across multiple evolving areas of practice and continually improve a robust collective intelligence to gain a competitive edge. As various types of machine intelligences and tools are introduced, firms must also groom these into the collective. In this paper we explore a human-machine hybrid system for addressing this large scale, multi-dimensional, dynamic optimization challenge to coordinate a collective intelligence of humans and machines. Machine intelligence is needed to handle the computational complexity and it is complemented by human intelligence to help handle exceptions and novel situations. We believe this approach has potential for transforming the collective intelligence that is the large law firm.},
  archive      = {J_FRAI},
  author       = {Kaomea, Peter},
  doi          = {10.3389/frai.2023.1145308},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1145308},
  shortjournal = {Front. Artif. Intell.},
  title        = {An intelligence coordination system toward creating the super-intelligent law firm},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Foresight for ethical AI. <em>FRAI</em>, <em>6</em>,
1143907. (<a href="https://doi.org/10.3389/frai.2023.1143907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is growing expectation that artificial intelligence (AI) developers foresee and mitigate harms that might result from their creations; however, this is exceptionally difficult given the prevalence of emergent behaviors that occur when integrating AI into complex sociotechnical systems. We argue that Naturalistic Decision Making (NDM) principles, models, and tools are well-suited to tackling this challenge. Already applied in high-consequence domains, NDM tools such as the premortem, and others, have been shown to uncover a reasonable set of risks of underlying factors that would lead to ethical harms. Such NDM tools have already been used to develop AI that is more trustworthy and resilient, and can help avoid unintended consequences of AI built with noble intentions. We present predictive policing algorithms as a use case, highlighting various factors that led to ethical harms and how NDM tools could help foresee and mitigate such harms.},
  archive      = {J_FRAI},
  author       = {Dorton, Stephen L. and Ministero, Lauren M. and Alaybek, Balca and Bryant, Douglas J.},
  doi          = {10.3389/frai.2023.1143907},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1143907},
  shortjournal = {Front. Artif. Intell.},
  title        = {Foresight for ethical AI},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ontological how and why: Action and objective of planned
processes in the food domain. <em>FRAI</em>, <em>6</em>, 1137961. (<a
href="https://doi.org/10.3389/frai.2023.1137961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computational modeling of food processing, aimed at various applications including industrial automation, robotics, food safety, preservation, energy conservation, and recipe nutrition estimation, has been ongoing for decades within food science research labs, industry, and regulatory agencies. The datasets from this prior work have the potential to advance the field of data-driven modeling if they can be harmonized, but this requires a standardized language as a starting point. Our primary goal is to explore two interdependent aspects of this language: the granularity of process modeling sub-parts and parameter details and the substitution of compatible inputs and processes. A delicate semantic distinction—categorizing planned processes based on the objectives they seek to fulfill vs. categorizing them by the actions or mechanisms they utilize—helps organize and facilitate this endeavor. To bring an ontological lens to process modeling, we employ the Open Biological and Biomedical Ontology Foundry ontological framework to organize two main classes of the FoodOn upper-level material processing hierarchy according to objective and mechanism, respectively. We include examples of material processing by mechanism, ranging from abstract ones such as “application of energy” down to specific classes such as “heating by microwave.” Similarly, material processing by objective—often a transformation to bring about materials with certain qualities or composition—can, for example, range from “material processing by heating threshold” to “steaming rice”.},
  archive      = {J_FRAI},
  author       = {Dooley, Damion and Naravane, Tarini},
  doi          = {10.3389/frai.2023.1137961},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1137961},
  shortjournal = {Front. Artif. Intell.},
  title        = {Ontological how and why: Action and objective of planned processes in the food domain},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Decision trees: From efficient prediction to responsible AI.
<em>FRAI</em>, <em>6</em>, 1124553. (<a
href="https://doi.org/10.3389/frai.2023.1124553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article provides a birds-eye view on the role of decision trees in machine learning and data science over roughly four decades. It sketches the evolution of decision tree research over the years, describes the broader context in which the research is situated, and summarizes strengths and weaknesses of decision trees in this context. The main goal of the article is to clarify the broad relevance to machine learning and artificial intelligence, both practical and theoretical, that decision trees still have today.},
  archive      = {J_FRAI},
  author       = {Blockeel, Hendrik and Devos, Laurens and Frénay, Benoît and Nanfack, Géraldin and Nijssen, Siegfried},
  doi          = {10.3389/frai.2023.1124553},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1124553},
  shortjournal = {Front. Artif. Intell.},
  title        = {Decision trees: From efficient prediction to responsible AI},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A computational model for the cancer field effect.
<em>FRAI</em>, <em>6</em>, 1060879. (<a
href="https://doi.org/10.3389/frai.2023.1060879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe Cancer Field Effect describes an area of pre-cancerous cells that results from continued exposure to carcinogens. Cells in the cancer field can easily develop into cancer. Removal of the main tumor mass might leave the cancer field behind, increasing risk of recurrence.MethodsThe model we propose for the cancer field effect is a hybrid cellular automaton (CA), which includes a multi-layer perceptron (MLP) to compute the effects of the carcinogens on the gene expression of the genes related to cancer development. We use carcinogen interactions that are typically associated with smoking and alcohol consumption and their effect on cancer fields of the tongue.ResultsUsing simulations we support the understanding that tobacco smoking is a potent carcinogen, which can be reinforced by alcohol consumption. The effect of alcohol alone is significantly less than the effect of tobacco. We further observe that pairing tumor excision with field removal delays recurrence compared to tumor excision alone. We track cell lineages and find that, in most cases, a polyclonal field develops, where the number of distinct cell lineages decreases over time as some lineages become dominant over others. Finally, we find tumor masses rarely form via monoclonal origin.},
  archive      = {J_FRAI},
  author       = {Deutscher, Karl and Hillen, Thomas and Newby, Jay},
  doi          = {10.3389/frai.2023.1060879},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1060879},
  shortjournal = {Front. Artif. Intell.},
  title        = {A computational model for the cancer field effect},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to play against any mixture of opponents.
<em>FRAI</em>, <em>6</em>, 804682. (<a
href="https://doi.org/10.3389/frai.2023.804682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intuitively, experience playing against one mixture of opponents in a given domain should be relevant for a different mixture in the same domain. If the mixture changes, ideally we would not have to train from scratch, but rather could transfer what we have learned to construct a policy to play against the new mixture. We propose a transfer learning method, Q-Mixing, that starts by learning Q-values against each pure-strategy opponent. Then a Q-value for any distribution of opponent strategies is approximated by appropriately averaging the separately learned Q-values. From these components, we construct policies against all opponent mixtures without any further training. We empirically validate Q-Mixing in two environments: a simple grid-world soccer environment, and a social dilemma game. Our experiments find that Q-Mixing can successfully transfer knowledge across any mixture of opponents. Next, we consider the use of observations during play to update the believed distribution of opponents. We introduce an opponent policy classifier—trained reusing Q-learning data—and use the classifier results to refine the mixing of Q-values. Q-Mixing augmented with the opponent policy classifier performs better, with higher variance, than training directly against a mixed-strategy opponent.},
  archive      = {J_FRAI},
  author       = {Smith, Max Olan and Anthony, Thomas and Wellman, Michael P.},
  doi          = {10.3389/frai.2023.804682},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {804682},
  shortjournal = {Front. Artif. Intell.},
  title        = {Learning to play against any mixture of opponents},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Multimodal communication and multimodal
computing. <em>FRAI</em>, <em>6</em>, 1234920. (<a
href="https://doi.org/10.3389/frai.2023.1234920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Mehler, Alexander and Lücking, Andy and Dong, Tiansi},
  doi          = {10.3389/frai.2023.1234920},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1234920},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Multimodal communication and multimodal computing},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Information extraction for health documents.
<em>FRAI</em>, <em>6</em>, 1224529. (<a
href="https://doi.org/10.3389/frai.2023.1224529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Mensa, Enrico and Martínez Fernández, Paloma and Roller, Roland and Radicioni, Daniele P.},
  doi          = {10.3389/frai.2023.1224529},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1224529},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Information extraction for health documents},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Deep learning with limited labeled data for
vision, audio, and text. <em>FRAI</em>, <em>6</em>, 1213419. (<a
href="https://doi.org/10.3389/frai.2023.1213419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Orescanin, Marko and Smith, Leslie N. and Sahu, Saurabh and Goyal, Palash and Chhetri, Sujit Rokka},
  doi          = {10.3389/frai.2023.1213419},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1213419},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Deep learning with limited labeled data for vision, audio, and text},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using knowledge graphs to infer gene expression in plants.
<em>FRAI</em>, <em>6</em>, 1201002. (<a
href="https://doi.org/10.3389/frai.2023.1201002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionClimate change is already affecting ecosystems around the world and forcing us to adapt to meet societal needs. The speed with which climate change is progressing necessitates a massive scaling up of the number of species with understood genotype-environment-phenotype (G×E×P) dynamics in order to increase ecosystem and agriculture resilience. An important part of predicting phenotype is understanding the complex gene regulatory networks present in organisms. Previous work has demonstrated that knowledge about one species can be applied to another using ontologically-supported knowledge bases that exploit homologous structures and homologous genes. These types of structures that can apply knowledge about one species to another have the potential to enable the massive scaling up that is needed through in silico experimentation.MethodsWe developed one such structure, a knowledge graph (KG) using information from Planteome and the EMBL-EBI Expression Atlas that connects gene expression, molecular interactions, functions, and pathways to homology-based gene annotations. Our preliminary analysis uses data from gene expression studies in Arabidopsis thaliana and Populus trichocarpa plants exposed to drought conditions.ResultsA graph query identified 16 pairs of homologous genes in these two taxa, some of which show opposite patterns of gene expression in response to drought. As expected, analysis of the upstream cis-regulatory region of these genes revealed that homologs with similar expression behavior had conserved cis-regulatory regions and potential interaction with similar trans-elements, unlike homologs that changed their expression in opposite ways.DiscussionThis suggests that even though the homologous pairs share common ancestry and functional roles, predicting expression and phenotype through homology inference needs careful consideration of integrating cis and trans-regulatory components in the curated and inferred knowledge graph.},
  archive      = {J_FRAI},
  author       = {Thessen, Anne E. and Cooper, Laurel and Swetnam, Tyson L. and Hegde, Harshad and Reese, Justin and Elser, Justin and Jaiswal, Pankaj},
  doi          = {10.3389/frai.2023.1201002},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1201002},
  shortjournal = {Front. Artif. Intell.},
  title        = {Using knowledge graphs to infer gene expression in plants},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explainable online health information truthfulness in
consumer health search. <em>FRAI</em>, <em>6</em>, 1184851. (<a
href="https://doi.org/10.3389/frai.2023.1184851">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionPeople are today increasingly relying on health information they find online to make decisions that may impact both their physical and mental wellbeing. Therefore, there is a growing need for systems that can assess the truthfulness of such health information. Most of the current literature solutions use machine learning or knowledge-based approaches treating the problem as a binary classification task, discriminating between correct information and misinformation. Such solutions present several problems with regard to user decision making, among which: (i) the binary classification task provides users with just two predetermined possibilities with respect to the truthfulness of the information, which users should take for granted; indeed, (ii) the processes by which the results were obtained are often opaque and the results themselves have little or no interpretation.MethodsTo address these issues, we approach the problem as an ad hoc retrieval task rather than a classification task, with reference, in particular, to the Consumer Health Search task. To do this, a previously proposed Information Retrieval model, which considers information truthfulness as a dimension of relevance, is used to obtain a ranked list of both topically-relevant and truthful documents. The novelty of this work concerns the extension of such a model with a solution for the explainability of the results obtained, by relying on a knowledge base consisting of scientific evidence in the form of medical journal articles.Results and discussionWe evaluate the proposed solution both quantitatively, as a standard classification task, and qualitatively, through a user study to examine the “explained” ranked list of documents. The results obtained illustrate the solution&#39;s effectiveness and usefulness in making the retrieved results more interpretable by Consumer Health Searchers, both with respect to topical relevance and truthfulness.},
  archive      = {J_FRAI},
  author       = {Upadhyay, Rishabh and Knoth, Petr and Pasi, Gabriella and Viviani, Marco},
  doi          = {10.3389/frai.2023.1184851},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1184851},
  shortjournal = {Front. Artif. Intell.},
  title        = {Explainable online health information truthfulness in consumer health search},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Long-short term memory networks for modeling track geometry
in laser metal deposition. <em>FRAI</em>, <em>6</em>, 1156630. (<a
href="https://doi.org/10.3389/frai.2023.1156630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling metal additive manufacturing processes is of great importance because it allows for the production of objects that are closer to the desired geometry and mechanical properties. Over-deposition often takes place during laser metal deposition, especially when the deposition head changes its direction and results in more material being melted onto the substrate. Modeling over-deposition is one of the necessary steps toward online process control, as a good model can be used in a closed-loop system to adjust the deposition parameters in real-time to reduce this phenomenon. In this study, we present a long-short memory neural network to model over-deposition. The model has been trained on simple geometries such as straight tracks, spiral and V-tracks made of Inconel 718. The model shows good generalization capabilities and can predict the height of more complex and previously unseen random tracks with limited performance loss. After the addition to the training dataset of a small amount of data coming from the random tracks, the performance of the model for such additional shapes improves significantly, making this approach feasible for more general applications as well.},
  archive      = {J_FRAI},
  author       = {Perani, Martina and Jandl, Ralf and Baraldo, Stefano and Valente, Anna and Paoli, Beatrice},
  doi          = {10.3389/frai.2023.1156630},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1156630},
  shortjournal = {Front. Artif. Intell.},
  title        = {Long-short term memory networks for modeling track geometry in laser metal deposition},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Performance comparison of bio-inspired and learning-based
clustering analysis with machine learning techniques for classification
of EEG signals. <em>FRAI</em>, <em>6</em>, 1156269. (<a
href="https://doi.org/10.3389/frai.2023.1156269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A comprehensive analysis of an automated system for epileptic seizure detection is explained in this work. When a seizure occurs, it is quite difficult to differentiate the non-stationary patterns from the discharges occurring in a rhythmic manner. The proposed approach deals with it efficiently by clustering it initially for the sake of feature extraction by using six different techniques categorized under two different methods, e.g., bio-inspired clustering and learning-based clustering. Learning-based clustering includes K-means clusters and Fuzzy C-means (FCM) clusters, while bio-inspired clusters include Cuckoo search clusters, Dragonfly clusters, Firefly clusters, and Modified Firefly clusters. Clustered values were then classified with 10 suitable classifiers, and after the performance comparison analysis of the EEG time series, the results proved that this methodology flow achieved a good performance index and a high classification accuracy. A comparatively higher classification accuracy of 99.48% was achieved when Cuckoo search clusters were utilized with linear support vector machines (SVM) for epilepsy detection. A high classification accuracy of 98.96% was obtained when K-means clusters were classified with a naive Bayesian classifier (NBC) and Linear SVM, and similar results were obtained when FCM clusters were classified with Decision Trees yielding the same values. The comparatively lowest classification accuracy, at 75.5%, was obtained when Dragonfly clusters were classified with the K-nearest neighbor (KNN) classifier, and the second lowest classification accuracy of 75.75% was obtained when Firefly clusters were classified with NBC.},
  archive      = {J_FRAI},
  author       = {Prabhakar, Sunil Kumar and Won, Dong-Ok},
  doi          = {10.3389/frai.2023.1156269},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1156269},
  shortjournal = {Front. Artif. Intell.},
  title        = {Performance comparison of bio-inspired and learning-based clustering analysis with machine learning techniques for classification of EEG signals},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accurately predicting hit songs using neurophysiology and
machine learning. <em>FRAI</em>, <em>6</em>, 1154663. (<a
href="https://doi.org/10.3389/frai.2023.1154663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying hit songs is notoriously difficult. Traditionally, song elements have been measured from large databases to identify the lyrical aspects of hits. We took a different methodological approach, measuring neurophysiologic responses to a set of songs provided by a streaming music service that identified hits and flops. We compared several statistical approaches to examine the predictive accuracy of each technique. A linear statistical model using two neural measures identified hits with 69% accuracy. Then, we created a synthetic set data and applied ensemble machine learning to capture inherent non-linearities in neural data. This model classified hit songs with 97% accuracy. Applying machine learning to the neural response to 1st min of songs accurately classified hits 82% of the time showing that the brain rapidly identifies hit music. Our results demonstrate that applying machine learning to neural data can substantially increase classification accuracy for difficult to predict market outcomes.},
  archive      = {J_FRAI},
  author       = {Merritt, Sean H. and Gaffuri, Kevin and Zak, Paul J.},
  doi          = {10.3389/frai.2023.1154663},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1154663},
  shortjournal = {Front. Artif. Intell.},
  title        = {Accurately predicting hit songs using neurophysiology and machine learning},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Zero-shot style transfer for gesture animation driven by
text and speech using adversarial disentanglement of multimodal style
encoding. <em>FRAI</em>, <em>6</em>, 1142997. (<a
href="https://doi.org/10.3389/frai.2023.1142997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling virtual agents with behavior style is one factor for personalizing human-agent interaction. We propose an efficient yet effective machine learning approach to synthesize gestures driven by prosodic features and text in the style of different speakers including those unseen during training. Our model performs zero-shot multimodal style transfer driven by multimodal data from the PATS database containing videos of various speakers. We view style as being pervasive; while speaking, it colors the communicative behaviors expressivity while speech content is carried by multimodal signals and text. This disentanglement scheme of content and style allows us to directly infer the style embedding even of a speaker whose data are not part of the training phase, without requiring any further training or fine-tuning. The first goal of our model is to generate the gestures of a source speaker based on the content of two input modalities–Mel spectrogram and text semantics. The second goal is to condition the source speaker&#39;s predicted gestures on the multimodal behavior style embedding of a target speaker. The third goal is to allow zero-shot style transfer of speakers unseen during training without re-training the model. Our system consists of two main components: (1) a speaker style encoder network that learns to generate a fixed-dimensional speaker embedding style from a target speaker multimodal data (mel-spectrogram, pose, and text) and (2) a sequence-to-sequence synthesis network that synthesizes gestures based on the content of the input modalities—text and mel-spectrogram—of a source speaker and conditioned on the speaker style embedding. We evaluate that our model is able to synthesize gestures of a source speaker given the two input modalities and transfer the knowledge of target speaker style variability learned by the speaker style encoder to the gesture generation task in a zero-shot setup, indicating that the model has learned a high-quality speaker representation. We conduct objective and subjective evaluations to validate our approach and compare it with baselines.},
  archive      = {J_FRAI},
  author       = {Fares, Mireille and Pelachaud, Catherine and Obin, Nicolas},
  doi          = {10.3389/frai.2023.1142997},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1142997},
  shortjournal = {Front. Artif. Intell.},
  title        = {Zero-shot style transfer for gesture animation driven by text and speech using adversarial disentanglement of multimodal style encoding},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EPPO ontology: A semantic-driven approach for plant and pest
codes representation. <em>FRAI</em>, <em>6</em>, 1131667. (<a
href="https://doi.org/10.3389/frai.2023.1131667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The agricultural industry and regulatory organizations define strategies and build tools and products for plant protection against pests. To identify different plants and their related pests and avoid inconsistencies between such organizations, an agreed and shared classification is necessary. In this regard, the European and Mediterranean Plant Protection Organization (EPPO) has been working on defining and maintaining a harmonized coding system (EPPO codes). EPPO codes are an easy way of referring to a specific organism by means of short 5 or 6 letter codes instead of long scientific names or ambiguous common names. EPPO codes are freely available in different formats through the EPPO Global Database platform and are implemented as a worldwide standard and used among scientists and experts in both industry and regulatory organizations. One of the large companies that adopted such codes is BASF, which uses them mainly in research and development to build their crop protection and seeds products. However, extracting the information is limited by fixed API calls or files that require additional processing steps. Facing these issues makes it difficult to use the available information flexibly, infer new data connections, or enrich it with external data sources. To overcome such limitations, BASF has developed an internal EPPO ontology to represent the list of codes provided by the EPPO Global Database as well as the regulatory categorization and relationship among them. This paper presents the development process of this ontology along with its enrichment process, which allows the reuse of relevant information available in an external knowledge source such as the NCBI Taxon. In addition, this paper describes the use and adoption of the EPPO ontology within the BASF&#39;s Agricultural Solutions division and the lessons learned during this work.},
  archive      = {J_FRAI},
  author       = {Ayllón-Benitez, Aarón and Bernabé-Diaz, José Antonio and Espinoza-Arias, Paola and Esnaola-Gonzalez, Iker and Beeckman, Delphine S. A. and McCaig, Bonnie and Hanzlik, Kristin and Cools, Toon and Castro Iragorri, Carlos and Palacios, Nicolás},
  doi          = {10.3389/frai.2023.1131667},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1131667},
  shortjournal = {Front. Artif. Intell.},
  title        = {EPPO ontology: A semantic-driven approach for plant and pest codes representation},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ChatGPT in society: Emerging issues. <em>FRAI</em>,
<em>6</em>, 1130913. (<a
href="https://doi.org/10.3389/frai.2023.1130913">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We review and critically assess several issues arising from the potential -large-scale- implementation or deployment of Large Language Models (LLMs) in society. These include security, political, economic, cultural, and educational issues as well as issues concerning social biases, creativity, copyright, and freedom of speech. We argue, without a preconceived pessimism toward these tools, that they may bring about many benefits. However, we also call for a balance assessment of their downsides. While our work is only preliminary and certainly partial it nevertheless holds some value as one of the first exploratory attempts in the literature.},
  archive      = {J_FRAI},
  author       = {Farina, Mirko and Lavazza, Andrea},
  doi          = {10.3389/frai.2023.1130913},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1130913},
  shortjournal = {Front. Artif. Intell.},
  title        = {ChatGPT in society: Emerging issues},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Text complexity and simplification.
<em>FRAI</em>, <em>6</em>, 1128446. (<a
href="https://doi.org/10.3389/frai.2023.1128446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Ermakova, Liana and Solovyev, Valery and Sidorov, Grigori and Gelbukh, Alexander},
  doi          = {10.3389/frai.2023.1128446},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1128446},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Text complexity and simplification},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sketching the vision of the web of debates. <em>FRAI</em>,
<em>6</em>, 1124045. (<a
href="https://doi.org/10.3389/frai.2023.1124045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exchange of comments, opinions, and arguments in blogs, forums, social media, wikis, and review websites has transformed the Web into a modern agora, a virtual place where all types of debates take place. This wealth of information remains mostly unexploited: due to its textual form, such information is difficult to automatically process and analyse in order to validate, evaluate, compare, combine with other types of information and make it actionable. Recent research in Machine Learning, Natural Language Processing, and Computational Argumentation has provided some solutions, which still cannot fully capture important aspects of online debates, such as various forms of unsound reasoning, arguments that do not follow a standard structure, information that is not explicitly expressed, and non-logical argumentation methods. Tackling these challenges would give immense added-value, as it would allow searching for, navigating through and analyzing online opinions and arguments, obtaining a better picture of the various debates for a well-intentioned user. Ultimately, it may lead to increased participation of Web users in democratic, dialogical interchange of arguments, more informed decisions by professionals and decision-makers, as well as to an easier identification of biased, misleading, or deceptive arguments. This paper presents the vision of the Web of Debates, a more human-centered version of the Web, which aims to unlock the potential of the abundance of argumentative information that currently exists online, offering its users a new generation of argument-based web services and tools that are tailored to their real needs.},
  archive      = {J_FRAI},
  author       = {Bikakis, Antonis and Flouris, Giorgos and Patkos, Theodore and Plexousakis, Dimitris},
  doi          = {10.3389/frai.2023.1124045},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1124045},
  shortjournal = {Front. Artif. Intell.},
  title        = {Sketching the vision of the web of debates},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). How AI tools can—and cannot—help organizations become more
ethical. <em>FRAI</em>, <em>6</em>, 1093712. (<a
href="https://doi.org/10.3389/frai.2023.1093712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we argue that we cannot expect that AI systems—even given more data or better computational resources—will be more ethical than the humans who develop, deploy and use them. As such, we advocate that it is necessary to retain the responsibility for ethical decision-making in human hands. In reality, however, human decision-makers currently do not have the ethical maturity to meaningfully take on this responsibility. So, what to do? We develop the argument that to broaden and strengthen the ethical upskilling of our organizations and leaders, AI has a crucial role to play. Specifically, because AI is a mirror that reflects our biases and moral flaws back to us, decision-makers should look carefully into this mirror—taking advantage of the opportunities brought about by its scale, interpretability, and counterfactual modeling—to gain a deep understanding of the psychological underpinnings of our (un)ethical behaviors, and in turn, learn to consistently make ethical decisions. In discussing this proposal, we introduce a new collaborative paradigm between humans and AI that can help ethically upskill our organizations and leaders and thereby prepare them to responsibly navigate the impending digital future.},
  archive      = {J_FRAI},
  author       = {De Cremer, David and Narayanan, Devesh},
  doi          = {10.3389/frai.2023.1093712},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1093712},
  shortjournal = {Front. Artif. Intell.},
  title        = {How AI tools can—and cannot—help organizations become more ethical},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of data abstraction. <em>FRAI</em>, <em>6</em>,
1085754. (<a href="https://doi.org/10.3389/frai.2023.1085754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well-known that Artificial Intelligence (AI), and in particular Machine Learning (ML), is not effective without good data preparation, as also pointed out by the recent wave of data-centric AI. Data preparation is the process of gathering, transforming and cleaning raw data prior to processing and analysis. Since nowadays data often reside in distributed and heterogeneous data sources, the first activity of data preparation requires collecting data from suitable data sources and data services, often distributed and heterogeneous. It is thus essential that providers describe their data services in a way to make them compliant with the FAIR guiding principles, i.e., make them automatically Findable, Accessible, Interoperable, and Reusable (FAIR). The notion of data abstraction has been introduced exactly to meet this need. Abstraction is a kind of reverse engineering task that automatically provides a semantic characterization of a data service made available by a provider. The goal of this paper is to review the results obtained so far in data abstraction, by presenting the formal framework for its definition, reporting about the decidability and complexity of the main theoretical problems concerning abstraction, and discuss open issues and interesting directions for future research.},
  archive      = {J_FRAI},
  author       = {Cima, Gianluca and Console, Marco and Lenzerini, Maurizio and Poggi, Antonella},
  doi          = {10.3389/frai.2023.1085754},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1085754},
  shortjournal = {Front. Artif. Intell.},
  title        = {A review of data abstraction},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving the elusiveness of word meanings: Two arguments for
a continuous meaning space for language. <em>FRAI</em>, <em>6</em>,
1025293. (<a href="https://doi.org/10.3389/frai.2023.1025293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {I explore the hypothesis that the experience of meaning discreteness when we think about the “meaning” of a word is a “communicative” illusion. The illusion is created by processing-contextual constraints that impose disambiguation on the semantic input making salient a specific interpretation within a conceptual space that is otherwise continuous. It is this salience that we experience as discreteness. The understanding of word meaning as non-discrete raises the question of what is context; what are the mechanisms of constraint that it imposes and what is the nature of the conceptual space with which pronunciations (i.e., visual/oral signs) associate themselves. I address these questions by leveraging an algebraic continuous system for word meaning that is itself constrained by two fundamental parameters: control-asymmetry and connectedness. I evaluate this model by meeting two challenges to word meaning discreteness (1) cases where the same pronunciation is associated with multiple senses that are nonetheless interdependent, e.g., English “smoke,” and (2) cases where the same pronunciation is associated with a family of meanings, minimally distinct from each other organized as a “cline,” e.g., English “have.” These cases are not marginal–they are ubiquitous in languages across the world. Any model that captures them is accounting for the meaning system for language. At the heart of the argumentation is the demonstration of how the parameterized space naturally organizes these kinds of cases without appeal for further categorization or segmentation of any kind. From this, I conclude that discreteness in word meaning is epiphenomenal: it is the experience of salience produced by contextual constraints. And that this is possible because, by and large, every time that we become consciously aware of the conceptual structure associated with a pronunciation, i.e., its meaning, we do so under real-time processing conditions which are biased toward producing a specific interpretation in reference to a specific situation in the world. Supporting it is a parameterized space that gives rise to lexico-conceptual representations: generalized algebraic structures necessary for the identification, processing, and encoding of an individual&#39;s understanding of the world.},
  archive      = {J_FRAI},
  author       = {Piñango, Maria M.},
  doi          = {10.3389/frai.2023.1025293},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1025293},
  shortjournal = {Front. Artif. Intell.},
  title        = {Solving the elusiveness of word meanings: Two arguments for a continuous meaning space for language},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Conversational AI. <em>FRAI</em>, <em>6</em>,
1203910. (<a href="https://doi.org/10.3389/frai.2023.1203910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Raaijmakers, Stephan and Cremers, Anita and Krahmer, Emiel and Westera, Matthijs},
  doi          = {10.3389/frai.2023.1203910},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1203910},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Conversational AI},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human-like problem-solving abilities in large language
models using ChatGPT. <em>FRAI</em>, <em>6</em>, 1199350. (<a
href="https://doi.org/10.3389/frai.2023.1199350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundsThe field of Artificial Intelligence (AI) has seen a major shift in recent years due to the development of new Machine Learning (ML) models such as Generative Pre-trained Transformer (GPT). GPT has achieved previously unheard-of levels of accuracy in most computerized language processing tasks and their chat-based variations.AimThe aim of this study was to investigate the problem-solving abilities of ChatGPT using two sets of verbal insight problems, with a known performance level established by a sample of human participants.Materials and methodsA total of 30 problems labeled as “practice problems” and “transfer problems” were administered to ChatGPT. ChatGPT&#39;s answers received a score of “0” for each incorrectly answered problem and a score of “1” for each correct response. The highest possible score for both the practice and transfer problems was 15 out of 15. The solution rate for each problem (based on a sample of 20 subjects) was used to assess and compare the performance of ChatGPT with that of human subjects.ResultsThe study highlighted that ChatGPT can be trained in out-of-the-box thinking and demonstrated potential in solving verbal insight problems. The global performance of ChatGPT equalled the most probable outcome for the human sample in both practice problems and transfer problems as well as upon their combination. Additionally, ChatGPT answer combinations were among the 5% of most probable outcomes for the human sample both when considering practice problems and pooled problem sets. These findings demonstrate that ChatGPT performance on both set of problems was in line with the mean rate of success of human subjects, indicating that it performed reasonably well.ConclusionsThe use of transformer architecture and self-attention in ChatGPT may have helped to prioritize inputs while predicting, contributing to its potential in verbal insight problem-solving. ChatGPT has shown potential in solving insight problems, thus highlighting the importance of incorporating AI into psychological research. However, it is acknowledged that there are still open challenges. Indeed, further research is required to fully understand AI&#39;s capabilities and limitations in verbal problem-solving.},
  archive      = {J_FRAI},
  author       = {Orrù, Graziella and Piarulli, Andrea and Conversano, Ciro and Gemignani, Angelo},
  doi          = {10.3389/frai.2023.1199350},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1199350},
  shortjournal = {Front. Artif. Intell.},
  title        = {Human-like problem-solving abilities in large language models using ChatGPT},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Humanizing AI in medical training: Ethical framework for
responsible design. <em>FRAI</em>, <em>6</em>, 1189914. (<a
href="https://doi.org/10.3389/frai.2023.1189914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing use of artificial intelligence (AI) in healthcare has brought about numerous ethical considerations that push for reflection. Humanizing AI in medical training is crucial to ensure that the design and deployment of its algorithms align with ethical principles and promote equitable healthcare outcomes for both medical practitioners trainees and patients. This perspective article provides an ethical framework for responsibly designing AI systems in medical training, drawing on our own past research in the fields of electrocardiogram interpretation training and e-health wearable devices. The article proposes five pillars of responsible design: transparency, fairness and justice, safety and wellbeing, accountability, and collaboration. The transparency pillar highlights the crucial role of maintaining the explainabilty of AI algorithms, while the fairness and justice pillar emphasizes on addressing biases in healthcare data and designing models that prioritize equitable medical training outcomes. The safety and wellbeing pillar however, emphasizes on the need to prioritize patient safety and wellbeing in AI model design whether it is for training or simulation purposes, and the accountability pillar calls for establishing clear lines of responsibility and liability for AI-derived decisions. Finally, the collaboration pillar emphasizes interdisciplinary collaboration among stakeholders, including physicians, data scientists, patients, and educators. The proposed framework thus provides a practical guide for designing and deploying AI in medicine generally, and in medical training specifically in a responsible and ethical manner.},
  archive      = {J_FRAI},
  author       = {Tahri Sqalli, Mohammed and Aslonov, Begali and Gafurov, Mukhammadjon and Nurmatov, Shokhrukhbek},
  doi          = {10.3389/frai.2023.1189914},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1189914},
  shortjournal = {Front. Artif. Intell.},
  title        = {Humanizing AI in medical training: Ethical framework for responsible design},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Assessing longitudinal housing status using electronic
health record data: A comparison of natural language processing,
structured data, and patient-reported history. <em>FRAI</em>,
<em>6</em>, 1187501. (<a
href="https://doi.org/10.3389/frai.2023.1187501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionMeasuring long-term housing outcomes is important for evaluating the impacts of services for individuals with homeless experience. However, assessing long-term housing status using traditional methods is challenging. The Veterans Affairs (VA) Electronic Health Record (EHR) provides detailed data for a large population of patients with homeless experiences and contains several indicators of housing instability, including structured data elements (e.g., diagnosis codes) and free-text clinical narratives. However, the validity of each of these data elements for measuring housing stability over time is not well-studied.MethodsWe compared VA EHR indicators of housing instability, including information extracted from clinical notes using natural language processing (NLP), with patient-reported housing outcomes in a cohort of homeless-experienced Veterans.ResultsNLP achieved higher sensitivity and specificity than standard diagnosis codes for detecting episodes of unstable housing. Other structured data elements in the VA EHR showed promising performance, particularly when combined with NLP.DiscussionEvaluation efforts and research studies assessing longitudinal housing outcomes should incorporate multiple data sources of documentation to achieve optimal performance.},
  archive      = {J_FRAI},
  author       = {Chapman, Alec B. and Cordasco, Kristina and Chassman, Stephanie and Panadero, Talia and Agans, Dylan and Jackson, Nicholas and Clair, Kimberly and Nelson, Richard and Montgomery, Ann Elizabeth and Tsai, Jack and Finley, Erin and Gabrielian, Sonya},
  doi          = {10.3389/frai.2023.1187501},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1187501},
  shortjournal = {Front. Artif. Intell.},
  title        = {Assessing longitudinal housing status using electronic health record data: A comparison of natural language processing, structured data, and patient-reported history},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Computer vision in plant phenotyping and
agriculture. <em>FRAI</em>, <em>6</em>, 1187301. (<a
href="https://doi.org/10.3389/frai.2023.1187301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Stavness, Ian and Giuffrida, Valerio and Scharr, Hanno},
  doi          = {10.3389/frai.2023.1187301},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1187301},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Computer vision in plant phenotyping and agriculture},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A robust approach for endotracheal tube localization in
chest radiographs. <em>FRAI</em>, <em>6</em>, 1181812. (<a
href="https://doi.org/10.3389/frai.2023.1181812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise detection and localization of the Endotracheal tube (ETT) is essential for patients receiving chest radiographs. A robust deep learning model based on U-Net++ architecture is presented for accurate segmentation and localization of the ETT. Different types of loss functions related to distribution and region-based loss functions are evaluated in this paper. Then, various integrations of distribution and region-based loss functions (compound loss function) have been applied to obtain the best intersection over union (IOU) for ETT segmentation. The main purpose of the presented study is to maximize IOU for ETT segmentation, and also minimize the error range that needs to be considered during calculation of distance between the real and predicted ETT by obtaining the best integration of the distribution and region loss functions (compound loss function) for training the U-Net++ model. We analyzed the performance of our model using chest radiograph from the Dalin Tzu Chi Hospital in Taiwan. The results of applying the integration of distribution-based and region-based loss functions on the Dalin Tzu Chi Hospital dataset show enhanced segmentation performance compared to other single loss functions. Moreover, according to the obtained results, the combination of Matthews Correlation Coefficient (MCC) and Tversky loss functions, which is a hybrid loss function, has shown the best performance on ETT segmentation based on its ground truth with an IOU value of 0.8683.},
  archive      = {J_FRAI},
  author       = {Hsu, Chung-Chian and Ameri, Rasoul and Lin, Chih-Wen and He, Jia-Shiang and Biyari, Meghdad and Yarahmadi, Atefeh and Band, Shahab S. and Lin, Tin-Kwang and Fan, Wen-Lin},
  doi          = {10.3389/frai.2023.1181812},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1181812},
  shortjournal = {Front. Artif. Intell.},
  title        = {A robust approach for endotracheal tube localization in chest radiographs},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A case study for unlocking the potential of deep learning in
asset-liability-management. <em>FRAI</em>, <em>6</em>, 1177702. (<a
href="https://doi.org/10.3389/frai.2023.1177702">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extensive application of deep learning in the field of quantitative risk management is still a relatively recent phenomenon. This article presents the key notions of Deep Asset-Liability-Management (“Deep ALM”) for a technological transformation in the management of assets and liabilities along a whole term structure. The approach has a profound impact on a wide range of applications such as optimal decision making for treasurers, optimal procurement of commodities or the optimization of hydroelectric power plants. As a by-product, intriguing aspects of goal-based investing or Asset-Liability-Management (ALM) in abstract terms concerning urgent challenges of our society are expected alongside. We illustrate the potential of the approach in a stylized case.},
  archive      = {J_FRAI},
  author       = {Krabichler, Thomas and Teichmann, Josef},
  doi          = {10.3389/frai.2023.1177702},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1177702},
  shortjournal = {Front. Artif. Intell.},
  title        = {A case study for unlocking the potential of deep learning in asset-liability-management},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning analytics for lifelong career development: A
framework to support sustainable formative assessment and
self-reflection in programs developing career self-efficacy.
<em>FRAI</em>, <em>6</em>, 1173099. (<a
href="https://doi.org/10.3389/frai.2023.1173099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among myriad complex challenges facing educational institutions in this era of a rapidly evolving job marketplace is the development of career self-efficacy among students. Self-efficacy has traditionally been understood to be developed through the direct experience of competence, the vicarious experience of competence, social persuasion, and physiological cues. These four factors, and particularly the first two, are difficult to build into education and training programs in a context where changing skills make the specific meaning of graduate competence largely unknown and, notwithstanding the other contributions in this collection, largely unknowable. In response, in this paper we argue for a working metacognitive model of career self-efficacy that will prepare students with the skills needed to evaluate their skills, attitudes and values and then adapt and develop them as their career context evolves around them. The model we will present is one of evolving complex sub-systems within an emergent milieu. In identifying various contributing factors, the model provides specific cognitive and affective constructs as important targets for actionable learning analytics for career development.},
  archive      = {J_FRAI},
  author       = {Brass, Tamishka and Kennedy, JohnPaul and Gabriel, Florence and Neill, Bec and Devis, Deborah and Leonard, Simon N.},
  doi          = {10.3389/frai.2023.1173099},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1173099},
  shortjournal = {Front. Artif. Intell.},
  title        = {Learning analytics for lifelong career development: A framework to support sustainable formative assessment and self-reflection in programs developing career self-efficacy},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ChatGPT in medicine: An overview of its applications,
advantages, limitations, future prospects, and ethical considerations.
<em>FRAI</em>, <em>6</em>, 1169595. (<a
href="https://doi.org/10.3389/frai.2023.1169595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an analysis of the advantages, limitations, ethical considerations, future prospects, and practical applications of ChatGPT and artificial intelligence (AI) in the healthcare and medical domains. ChatGPT is an advanced language model that uses deep learning techniques to produce human-like responses to natural language inputs. It is part of the family of generative pre-training transformer (GPT) models developed by OpenAI and is currently one of the largest publicly available language models. ChatGPT is capable of capturing the nuances and intricacies of human language, allowing it to generate appropriate and contextually relevant responses across a broad spectrum of prompts. The potential applications of ChatGPT in the medical field range from identifying potential research topics to assisting professionals in clinical and laboratory diagnosis. Additionally, it can be used to help medical students, doctors, nurses, and all members of the healthcare fraternity to know about updates and new developments in their respective fields. The development of virtual assistants to aid patients in managing their health is another important application of ChatGPT in medicine. Despite its potential applications, the use of ChatGPT and other AI tools in medical writing also poses ethical and legal concerns. These include possible infringement of copyright laws, medico-legal complications, and the need for transparency in AI-generated content. In conclusion, ChatGPT has several potential applications in the medical and healthcare fields. However, these applications come with several limitations and ethical considerations which are presented in detail along with future prospects in medicine and healthcare.},
  archive      = {J_FRAI},
  author       = {Dave, Tirth and Athaluri, Sai Anirudh and Singh, Satyam},
  doi          = {10.3389/frai.2023.1169595},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1169595},
  shortjournal = {Front. Artif. Intell.},
  title        = {ChatGPT in medicine: An overview of its applications, advantages, limitations, future prospects, and ethical considerations},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing e-commerce recommendation systems through approach
of buyer’s self-construal: Necessity, theoretical ground, synthesis of a
six-step model, and research agenda. <em>FRAI</em>, <em>6</em>, 1167735.
(<a href="https://doi.org/10.3389/frai.2023.1167735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current recommendation system predominantly relies on evidential factors such as behavioral outcomes and purchasing history. However, limited research has been conducted to explore the use of psychological data in these algorithms, such as consumers&#39; self-perceived identities. Based on the gap identified and the soaring significance of levering the non-purchasing data, this study presents a methodology to quantify consumers&#39; self-identities to help examine the relationship between these psychological cues and decision-making in an e-commerce context, focusing on the projective self, which has been overlooked in previous research. This research is expected to contribute to a better understanding of the cause of inconsistency in similar studies and provide a basis for further exploration of the impact of self-concepts on consumer behavior. The coding method in grounded theory, in conjunction with the synthesis of literature analysis, was employed to generate the final approach and solution in this study as they provide a robust and rigorous basis for the findings and recommendations presented in this study.},
  archive      = {J_FRAI},
  author       = {Feng, Yilin},
  doi          = {10.3389/frai.2023.1167735},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1167735},
  shortjournal = {Front. Artif. Intell.},
  title        = {Enhancing e-commerce recommendation systems through approach of buyer&#39;s self-construal: Necessity, theoretical ground, synthesis of a six-step model, and research agenda},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Insights in AI: Medicine and public health 2022.
<em>FRAI</em>, <em>6</em>, 1166426. (<a
href="https://doi.org/10.3389/frai.2023.1166426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Hartung, Thomas and Deng, Jun and Mall, Raghvendra and Frangi, Alejandro F. and Emmert-Streib, Frank and Pham, Tuan D.},
  doi          = {10.3389/frai.2023.1166426},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1166426},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: insights in AI: medicine and public health 2022},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Use of big data from health insurance for assessment of
cardiovascular outcomes. <em>FRAI</em>, <em>6</em>, 1155404. (<a
href="https://doi.org/10.3389/frai.2023.1155404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outcome research that supports guideline recommendations for primary and secondary preventions largely depends on the data obtained from clinical trials or selected hospital populations. The exponentially growing amount of real-world medical data could enable fundamental improvements in cardiovascular disease (CVD) prediction, prevention, and care. In this review we summarize how data from health insurance claims (HIC) may improve our understanding of current health provision and identify challenges of patient care by implementing the perspective of patients (providing data and contributing to society), physicians (identifying at-risk patients, optimizing diagnosis and therapy), health insurers (preventive education and economic aspects), and policy makers (data-driven legislation). HIC data has the potential to inform relevant aspects of the healthcare systems. Although HIC data inherit limitations, large sample sizes and long-term follow-up provides enormous predictive power. Herein, we highlight the benefits and limitations of HIC data and provide examples from the cardiovascular field, i.e. how HIC data is supporting healthcare, focusing on the demographical and epidemiological differences, pharmacotherapy, healthcare utilization, cost-effectiveness and outcomes of different treatments. As an outlook we discuss the potential of using HIC-based big data and modern artificial intelligence (AI) algorithms to guide patient education and care, which could lead to the development of a learning healthcare system and support a medically relevant legislation in the future.},
  archive      = {J_FRAI},
  author       = {Krefting, Johannes and Sen, Partho and David-Rus, Diana and Güldener, Ulrich and Hawe, Johann S. and Cassese, Salvatore and von Scheidt, Moritz and Schunkert, Heribert},
  doi          = {10.3389/frai.2023.1155404},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1155404},
  shortjournal = {Front. Artif. Intell.},
  title        = {Use of big data from health insurance for assessment of cardiovascular outcomes},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Proactive and reactive engagement of artificial intelligence
methods for education: A review. <em>FRAI</em>, <em>6</em>, 1151391. (<a
href="https://doi.org/10.3389/frai.2023.1151391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The education sector has benefited enormously through integrating digital technology driven tools and platforms. In recent years, artificial intelligence based methods are being considered as the next generation of technology that can enhance the experience of education for students, teachers, and administrative staff alike. The concurrent boom of necessary infrastructure, digitized data and general social awareness has propelled these efforts further. In this review article, we investigate how artificial intelligence, machine learning, and deep learning methods are being utilized to support the education process. We do this through the lens of a novel categorization approach. We consider the involvement of AI-driven methods in the education process in its entirety—from students admissions, course scheduling, and content generation in the proactive planning phase to knowledge delivery, performance assessment, and outcome prediction in the reactive execution phase. We outline and analyze the major research directions under proactive and reactive engagement of AI in education using a representative group of 195 original research articles published in the past two decades, i.e., 2003–2022. We discuss the paradigm shifts in the solution approaches proposed, particularly with respect to the choice of data and algorithms used over this time. We further discuss how the COVID-19 pandemic influenced this field of active development and the existing infrastructural challenges and ethical concerns pertaining to global adoption of artificial intelligence for education.},
  archive      = {J_FRAI},
  author       = {Mallik, Sruti and Gangopadhyay, Ahana},
  doi          = {10.3389/frai.2023.1151391},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1151391},
  shortjournal = {Front. Artif. Intell.},
  title        = {Proactive and reactive engagement of artificial intelligence methods for education: A review},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Introducing DynaPTI–constructing a dynamic patent technology
indicator using text mining and machine learning. <em>FRAI</em>,
<em>6</em>, 1136846. (<a
href="https://doi.org/10.3389/frai.2023.1136846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patent data is an established source of information for both scientific research and corporate intelligence. Yet, most patent-based technology indicators fail to consider firm-level dynamics regarding their technological quality and technological activity. Accordingly, these indicators are unlikely to deliver an unbiased view on the current state of firm-level innovation and are thus incomplete tools for researchers and corporate intelligence practitioners. In this paper, we develop DynaPTI, an indicator that tackles this particular shortcoming of existing patent-based measures. Our proposed framework extends the literature by incorporating a dynamic component and is built upon an index-based comparison of firms. Furthermore, we use machine-learning techniques to enrich our indicator with textual information from patent texts. Together, these features allow our proposed framework to provide precise and up-to-date assessments about firm-level innovation activities. To present an exemplary implementation of the framework, we provide an empirical application to companies from the wind energy sector and compare our results to alternatives. Our corresponding findings suggest that our approach can generate valuable insights that are complementary to existing approaches, particularly regarding the identification of recently emerging, innovation-overperformers in a particular technological field.},
  archive      = {J_FRAI},
  author       = {Freunek, Michael and Niggli, Matthias},
  doi          = {10.3389/frai.2023.1136846},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1136846},
  shortjournal = {Front. Artif. Intell.},
  title        = {Introducing DynaPTI–constructing a dynamic patent technology indicator using text mining and machine learning},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluating and selecting arguments in the context of higher
order uncertainty. <em>FRAI</em>, <em>6</em>, 1133998. (<a
href="https://doi.org/10.3389/frai.2023.1133998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human and artificial reasoning has to deal with uncertain environments. Ideally, probabilistic information is available. However, sometimes probabilistic information may not be precise or it is missing entirely. In such cases we reason with higher-order uncertainty. Formal argumentation is one of the leading formal methods to model defeasible reasoning in artificial intelligence, in particular in the tradition of Dung&#39;s abstract argumentation. Also from the perspective of cognition, reasoning has been considered as argumentative and social in nature, for instance by Mercier and Sperber. In this paper we use formal argumentation to provide a framework for reasoning with higher-order uncertainty. Our approach builds strongly on Haenni&#39;s system of probabilistic argumentation, but enhances it in several ways. First, we integrate it with deductive argumentation, both in terms of the representation of arguments and attacks, and in terms of utilizing abstract argumentation semantics for selecting some out of a set of possibly conflicting arguments. We show how our system can be adjusted to perform well under the so-called rationality postulates of formal argumentation. Second, we provide several notions of argument strength which are studied both meta-theoretically and empirically. In this way the paper contributes a formal model of reasoning with higher-order uncertainty with possible applications in artificial intelligence and human cognition.},
  archive      = {J_FRAI},
  author       = {Straßer, Christian and Michajlova, Lisa},
  doi          = {10.3389/frai.2023.1133998},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1133998},
  shortjournal = {Front. Artif. Intell.},
  title        = {Evaluating and selecting arguments in the context of higher order uncertainty},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Understanding image-text relations and news values for
multimodal news analysis. <em>FRAI</em>, <em>6</em>, 1125533. (<a
href="https://doi.org/10.3389/frai.2023.1125533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of news dissemination is of utmost importance since the credibility of information and the identification of disinformation and misinformation affect society as a whole. Given the large amounts of news data published daily on the Web, the empirical analysis of news with regard to research questions and the detection of problematic news content on the Web require computational methods that work at scale. Today&#39;s online news are typically disseminated in a multimodal form, including various presentation modalities such as text, image, audio, and video. Recent developments in multimodal machine learning now make it possible to capture basic “descriptive” relations between modalities–such as correspondences between words and phrases, on the one hand, and corresponding visual depictions of the verbally expressed information on the other. Although such advances have enabled tremendous progress in tasks like image captioning, text-to-image generation and visual question answering, in domains such as news dissemination, there is a need to go further. In this paper, we introduce a novel framework for the computational analysis of multimodal news. We motivate a set of more complex image-text relations as well as multimodal news values based on real examples of news reports and consider their realization by computational approaches. To this end, we provide (a) an overview of existing literature from semiotics where detailed proposals have been made for taxonomies covering diverse image-text relations generalisable to any domain; (b) an overview of computational work that derives models of image-text relations from data; and (c) an overview of a particular class of news-centric attributes developed in journalism studies called news values. The result is a novel framework for multimodal news analysis that closes existing gaps in previous work while maintaining and combining the strengths of those accounts. We assess and discuss the elements of the framework with real-world examples and use cases, setting out research directions at the intersection of multimodal learning, multimodal analytics and computational social sciences that can benefit from our approach.},
  archive      = {J_FRAI},
  author       = {Cheema, Gullal S. and Hakimov, Sherzod and Müller-Budack, Eric and Otto, Christian and Bateman, John A. and Ewerth, Ralph},
  doi          = {10.3389/frai.2023.1125533},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1125533},
  shortjournal = {Front. Artif. Intell.},
  title        = {Understanding image-text relations and news values for multimodal news analysis},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Image–text coherence and its implications for multimodal AI.
<em>FRAI</em>, <em>6</em>, 1048874. (<a
href="https://doi.org/10.3389/frai.2023.1048874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human communication often combines imagery and text into integrated presentations, especially online. In this paper, we show how image–text coherence relations can be used to model the pragmatics of image–text presentations in AI systems. In contrast to alternative frameworks that characterize image–text presentations in terms of the priority, relevance, or overlap of information across modalities, coherence theory postulates that each unit of a discourse stands in specific pragmatic relations to other parts of the discourse, with each relation involving its own information goals and inferential connections. Text accompanying an image may, for example, characterize what&#39;s visible in the image, explain how the image was obtained, offer the author&#39;s appraisal of or reaction to the depicted situation, and so forth. The advantage of coherence theory is that it provides a simple, robust, and effective abstraction of communicative goals for practical applications. To argue this, we review case studies describing coherence in image–text data sets, predicting coherence from few-shot annotations, and coherence models of image–text tasks such as caption generation and caption evaluation.},
  archive      = {J_FRAI},
  author       = {Alikhani, Malihe and Khalid, Baber and Stone, Matthew},
  doi          = {10.3389/frai.2023.1048874},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1048874},
  shortjournal = {Front. Artif. Intell.},
  title        = {Image–text coherence and its implications for multimodal AI},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Participatory design of teacher dashboards: Navigating the
tension between teacher input and theories on teacher professional
vision. <em>FRAI</em>, <em>6</em>, 1039739. (<a
href="https://doi.org/10.3389/frai.2023.1039739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of AI in education, there is a movement toward human-centered design in which the primary stakeholders are collaborators in establishing the design and functionality of the AI system (participatory design). Several authors have noted that there is a potential tension in participatory design between involving stakeholders and, thus, increasing uptake of the system on the one hand, and the use of educational theory on the other hand. The goal of the present perspective article is to unpack this tension in more detail, focusing on the example of teacher dashboards. Our contribution to theory is to show that insights from the research field of teacher professional vision can help explain why stakeholder involvement may lead to tension. In particular, we discuss that the sources of information that teachers use in their professional vision, and which data sources could be included on dashboards, might differ with respect to whether they actually relate to student learning or not. Using this difference as a starting point for participatory design could help navigate the aforementioned tension. Subsequently, we describe several implications for practice and research that could help move the field of human centered design further.},
  archive      = {J_FRAI},
  author       = {van Leeuwen, Anouschka and Strauß, Sebastian and Rummel, Nikol},
  doi          = {10.3389/frai.2023.1039739},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1039739},
  shortjournal = {Front. Artif. Intell.},
  title        = {Participatory design of teacher dashboards: Navigating the tension between teacher input and theories on teacher professional vision},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AlphaZe∗∗: AlphaZero-like baselines for imperfect
information games are surprisingly strong. <em>FRAI</em>, <em>6</em>,
1014561. (<a href="https://doi.org/10.3389/frai.2023.1014561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep neural networks for strategy games have made significant progress. AlphaZero-like frameworks which combine Monte-Carlo tree search with reinforcement learning have been successfully applied to numerous games with perfect information. However, they have not been developed for domains where uncertainty and unknowns abound, and are therefore often considered unsuitable due to imperfect observations. Here, we challenge this view and argue that they are a viable alternative for games with imperfect information—a domain currently dominated by heuristic approaches or methods explicitly designed for hidden information, such as oracle-based techniques. To this end, we introduce a novel algorithm based solely on reinforcement learning, called AlphaZe∗∗, which is an AlphaZero-based framework for games with imperfect information. We examine its learning convergence on the games Stratego and DarkHex and show that it is a surprisingly strong baseline, while using a model-based approach: it achieves similar win rates against other Stratego bots like Pipeline Policy Space Response Oracle (P2SRO), while not winning in direct comparison against P2SRO or reaching the much stronger numbers of DeepNash. Compared to heuristics and oracle-based approaches, AlphaZe∗∗ can easily deal with rule changes, e.g., when more information than usual is given, and drastically outperforms other approaches in this respect.},
  archive      = {J_FRAI},
  author       = {Blüml, Jannis and Czech, Johannes and Kersting, Kristian},
  doi          = {10.3389/frai.2023.1014561},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1014561},
  shortjournal = {Front. Artif. Intell.},
  title        = {AlphaZe∗∗: AlphaZero-like baselines for imperfect information games are surprisingly strong},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Who are the haters? A corpus-based demographic analysis of
authors of hate speech. <em>FRAI</em>, <em>6</em>, 986890. (<a
href="https://doi.org/10.3389/frai.2023.986890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionWe examine the profiles of hate speech authors in a multilingual dataset of Facebook reactions to news posts discussing topics related to migrants and the LGBT+ community. The included languages are English, Dutch, Slovenian, and Croatian.MethodsFirst, all utterances were manually annotated as hateful or acceptable speech. Next, we used binary logistic regression to inspect how the production of hateful comments is impacted by authors&#39; profiles (i.e., their age, gender, and language).ResultsOur results corroborate previous findings: in all four languages, men produce more hateful comments than women, and people produce more hate speech as they grow older. But our findings also add important nuance to previously attested tendencies: specific age and gender dynamics vary slightly in different languages or cultures, suggesting that distinct (e.g., socio-political) realities are at play.DiscussionFinally, we discuss why author demographics are important in the study of hate speech: the profiles of prototypical “haters” can be used for hate speech detection, for sensibilization on and for counter-initiatives to the spread of (online) hatred.},
  archive      = {J_FRAI},
  author       = {Hilte, Lisa and Markov, Ilia and Ljubešić, Nikola and Fišer, Darja and Daelemans, Walter},
  doi          = {10.3389/frai.2023.986890},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {986890},
  shortjournal = {Front. Artif. Intell.},
  title        = {Who are the haters? a corpus-based demographic analysis of authors of hate speech},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Impact of ChatGPT on medical chatbots as a disruptive
technology. <em>FRAI</em>, <em>6</em>, 1166014. (<a
href="https://doi.org/10.3389/frai.2023.1166014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Chow, James C. L. and Sanders, Leslie and Li, Kay},
  doi          = {10.3389/frai.2023.1166014},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1166014},
  shortjournal = {Front. Artif. Intell.},
  title        = {Impact of ChatGPT on medical chatbots as a disruptive technology},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sentiment analysis for measuring hope and fear from reddit
posts during the 2022 russo-ukrainian conflict. <em>FRAI</em>,
<em>6</em>, 1163577. (<a
href="https://doi.org/10.3389/frai.2023.1163577">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel lexicon-based unsupervised sentiment analysis method to measure the “hope” and “fear” for the 2022 Ukrainian-Russian Conflict. Reddit.com is utilized as the main source of human reactions to daily events during nearly the first 3 months of the conflict. The top 50 “hot” posts of six different subreddits about Ukraine and news (Ukraine, worldnews, Ukraina, UkrainianConflict, UkraineWarVideoReport, and UkraineWarReports) along with their relative comments are scraped every day between 10th of May and 28th of July, and a novel data set is created. On this corpus, multiple analyzes, such as (1) public interest, (2) Hope/Fear score, and (3) stock price interaction, are employed. We use a dictionary approach, which scores the hopefulness of every submitted user post. The Latent Dirichlet Allocation (LDA) algorithm of topic modeling is also utilized to understand the main issues raised by users and what are the key talking points. Experimental analysis shows that the hope strongly decreases after the symbolic and strategic losses of Azovstal (Mariupol) and Severodonetsk. Spikes in hope/fear, both positives and negatives, are present not only after important battles, but also after some non-military events, such as Eurovision and football games.},
  archive      = {J_FRAI},
  author       = {Guerra, Alessio and Karakuş, Oktay},
  doi          = {10.3389/frai.2023.1163577},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1163577},
  shortjournal = {Front. Artif. Intell.},
  title        = {Sentiment analysis for measuring hope and fear from reddit posts during the 2022 russo-ukrainian conflict},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Next generation immuno-oncology tumor profiling using a
rapid, non-invasive, computational biophysics biomarker in early-stage
breast cancer. <em>FRAI</em>, <em>6</em>, 1153083. (<a
href="https://doi.org/10.3389/frai.2023.1153083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundImmuno-oncology (IO) therapies targeting the PD-1/PD-L1 axis, such as immune checkpoint inhibitor (ICI) antibodies, have emerged as promising treatments for early-stage breast cancer (ESBC). Despite immunotherapy&#39;s clinical significance, the number of benefiting patients remains small, and the therapy can prompt severe immune-related events. Current pathologic and transcriptomic predictions of IO response are limited in terms of accuracy and rely on single-site biopsies, which cannot fully account for tumor heterogeneity. In addition, transcriptomic analyses are costly and time-consuming. We therefore constructed a computational biomarker coupling biophysical simulations and artificial intelligence-based tissue segmentation of dynamic contrast-enhanced magnetic resonance imaging (DCE-MRIs), enabling IO response prediction across the entire tumor.MethodsBy analyzing both single-cell and whole-tissue RNA-seq data from non-IO-treated ESBC patients, we associated gene expression levels of the PD-1/PD-L1 axis with local tumor biology. PD-L1 expression was then linked to biophysical features derived from DCE-MRIs to generate spatially- and temporally-resolved atlases (virtual tumors) of tumor biology, as well as the TumorIO biomarker of IO response. We quantified TumorIO within patient virtual tumors (n = 63) using integrative modeling to train and develop a corresponding TumorIO Score.ResultsWe validated the TumorIO biomarker and TumorIO Score in a small, independent cohort of IO-treated patients (n = 17) and correctly predicted pathologic complete response (pCR) in 15/17 individuals (88.2% accuracy), comprising 10/12 in triple negative breast cancer (TNBC) and 5/5 in HR+/HER2- tumors. We applied the TumorIO Score in a virtual clinical trial (n = 292) simulating ICI administration in an IO-naïve cohort that underwent standard chemotherapy. Using this approach, we predicted pCR rates of 67.1% for TNBC and 17.9% for HR+/HER2- tumors with addition of IO therapy; comparing favorably to empiric pCR rates derived from published trials utilizing ICI in both cancer subtypes.ConclusionThe TumorIO biomarker and TumorIO Score represent a next generation approach using integrative biophysical analysis to assess cancer responsiveness to immunotherapy. This computational biomarker performs as well as PD-L1 transcript levels in identifying a patient&#39;s likelihood of pCR following anti-PD-1 IO therapy. The TumorIO biomarker allows for rapid IO profiling of tumors and may confer high clinical decision impact to further enable personalized oncologic care.},
  archive      = {J_FRAI},
  author       = {Cook, Daniel and Biancalana, Matthew and Liadis, Nicole and Lopez Ramos, Dorys and Zhang, Yuhan and Patel, Snehal and Peterson, Joseph R. and Pfeiffer, John R. and Cole, John A. and Antony, Anuja K.},
  doi          = {10.3389/frai.2023.1153083},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1153083},
  shortjournal = {Front. Artif. Intell.},
  title        = {Next generation immuno-oncology tumor profiling using a rapid, non-invasive, computational biophysics biomarker in early-stage breast cancer},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integrating collective know-how for multicriteria decision
support in agrifood chains—application to cheesemaking. <em>FRAI</em>,
<em>6</em>, 1145007. (<a
href="https://doi.org/10.3389/frai.2023.1145007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agrifood chain processes are based on a multitude of knowledge, know-how and experiences forged over time. This collective expertise must be shared to improve food quality. Here we test the hypothesis that it is possible to design and implement a comprehensive methodology to create a knowledge base integrating collective expertise, while also using it to recommend technical actions required to improve food quality. The method used to test this hypothesis consists firstly in listing the functional specifications that were defined in collaboration with several partners (technical centers, vocational training schools, producers) over the course of several projects carried out in recent years. Secondly, we propose an innovative core ontology that utilizes the international languages of the Semantic Web to effectively represent knowledge in the form of decision trees. These decision trees will depict potential causal relationships between situations of interest and provide recommendations for managing them through technological actions, as well as a collective assessment of the efficiency of those actions. We show how mind map files created using mind-mapping tools are automatically translated into an RDF knowledge base using the core ontological model. Thirdly, a model to aggregate individual assessments provided by technicians and associated with technical action recommendations is proposed and evaluated. Finally, a multicriteria decision-support system (MCDSS) using the knowledge base is presented. It consists of an explanatory view allowing navigation in a decision tree and an action view for multicriteria filtering and possible side effect identification. The different types of MCDSS-delivered answers to a query expressed in the action view are explained. The MCDSS graphical user interface is presented through a real-use case. Experimental assessments have been performed and confirm that tested hypothesis is relevant.},
  archive      = {J_FRAI},
  author       = {Buche, Patrice and Couteaux, Julien and Cufi, Julien and Destercke, Sébastien and Oudot, Alrick},
  doi          = {10.3389/frai.2023.1145007},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1145007},
  shortjournal = {Front. Artif. Intell.},
  title        = {Integrating collective know-how for multicriteria decision support in agrifood chains—application to cheesemaking},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Legal linguistic templates and the tension between legal
knowledge representation and reasoning. <em>FRAI</em>, <em>6</em>,
1136263. (<a href="https://doi.org/10.3389/frai.2023.1136263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is an inherent tension between knowledge representation and reasoning. For an optimal representation and validation, an expressive language should be used. For an optimal automated reasoning, a simple one is preferred. Which language should we choose for our legal knowledge representation if our goal is to apply automated legal reasoning? In this paper, we investigate the properties and requirements of each of these two applications. We suggest that by using Legal Linguistic Templates, one can solve the above tension in some practical situations.},
  archive      = {J_FRAI},
  author       = {Libal, Tomer},
  doi          = {10.3389/frai.2023.1136263},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1136263},
  shortjournal = {Front. Artif. Intell.},
  title        = {Legal linguistic templates and the tension between legal knowledge representation and reasoning},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AI for anglophone africa: Unlocking its adoption for
responsible solutions in academia-private sector. <em>FRAI</em>,
<em>6</em>, 1133677. (<a
href="https://doi.org/10.3389/frai.2023.1133677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, AI technologies have become indispensable in social and industrial development, yielding revolutionary results in improving labor efficiency, lowering labor costs, optimizing human resource structure, and creating new job demands. To reap the full benefits of responsible AI solutions in Africa, it is critical to investigate existing challenges and propose strategies, policies, and frameworks for overcoming and eliminating them. As a result, this study investigated the challenges of adopting responsible AI solutions in the Academia-Private sectors for Anglophone Africa through literature reviews, expert interviews, and then proposes solutions and framework for the sustainable and successful adoption of responsible AI.},
  archive      = {J_FRAI},
  author       = {Sinde, Ramadhani and Diwani, Salim and Leo, Judith and Kondo, Tabu and Elisa, Noe and Matogoro, Jabhera},
  doi          = {10.3389/frai.2023.1133677},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1133677},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI for anglophone africa: Unlocking its adoption for responsible solutions in academia-private sector},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Opportunities for human factors in machine learning.
<em>FRAI</em>, <em>6</em>, 1130190. (<a
href="https://doi.org/10.3389/frai.2023.1130190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe field of machine learning and its subfield of deep learning have grown rapidly in recent years. With the speed of advancement, it is nearly impossible for data scientists to maintain expert knowledge of cutting-edge techniques. This study applies human factors methods to the field of machine learning to address these difficulties.MethodsUsing semi-structured interviews with data scientists at a National Laboratory, we sought to understand the process used when working with machine learning models, the challenges encountered, and the ways that human factors might contribute to addressing those challenges.ResultsResults of the interviews were analyzed to create a generalization of the process of working with machine learning models. Issues encountered during each process step are described.DiscussionRecommendations and areas for collaboration between data scientists and human factors experts are provided, with the goal of creating better tools, knowledge, and guidance for machine learning scientists.},
  archive      = {J_FRAI},
  author       = {Baweja, Jessica A. and Fallon, Corey K. and Jefferson, Brett A.},
  doi          = {10.3389/frai.2023.1130190},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1130190},
  shortjournal = {Front. Artif. Intell.},
  title        = {Opportunities for human factors in machine learning},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). No silver bullet: Interpretable ML models must be explained.
<em>FRAI</em>, <em>6</em>, 1128212. (<a
href="https://doi.org/10.3389/frai.2023.1128212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years witnessed a number of proposals for the use of the so-called interpretable models in specific application domains. These include high-risk, but also safety-critical domains. In contrast, other works reported some pitfalls of machine learning model interpretability, in part justified by the lack of a rigorous definition of what an interpretable model should represent. This study proposes to relate interpretability with the ability of a model to offer explanations of why a prediction is made given some point in feature space. Under this general goal of offering explanations to predictions, this study reveals additional limitations of interpretable models. Concretely, this study considers application domains where the purpose is to help human decision makers to understand why some prediction was made or why was not some other prediction made, and where irreducible (and so minimal) information is sought. In such domains, this study argues that answers to such why (or why not) questions can exhibit arbitrary redundancy, i.e., the answers can be simplified, as long as these answers are obtained by human inspection of the interpretable ML model representation.},
  archive      = {J_FRAI},
  author       = {Marques-Silva, Joao and Ignatiev, Alexey},
  doi          = {10.3389/frai.2023.1128212},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1128212},
  shortjournal = {Front. Artif. Intell.},
  title        = {No silver bullet: Interpretable ML models must be explained},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cracking the genetic code with neural networks.
<em>FRAI</em>, <em>6</em>, 1128153. (<a
href="https://doi.org/10.3389/frai.2023.1128153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The genetic code is textbook scientific knowledge that was soundly established without resorting to Artificial Intelligence (AI). The goal of our study was to check whether a neural network could re-discover, on its own, the mapping links between codons and amino acids and build the complete deciphering dictionary upon presentation of transcripts proteins data training pairs. We compared different Deep Learning neural network architectures and estimated quantitatively the size of the required human transcriptomic training set to achieve the best possible accuracy in the codon-to-amino-acid mapping. We also investigated the effect of a codon embedding layer assessing the semantic similarity between codons on the rate of increase of the training accuracy. We further investigated the benefit of quantifying and using the unbalanced representations of amino acids within real human proteins for a faster deciphering of rare amino acids codons. Deep neural networks require huge amount of data to train them. Deciphering the genetic code by a neural network is no exception. A test accuracy of 100% and the unequivocal deciphering of rare codons such as the tryptophan codon or the stop codons require a training dataset of the order of 4–22 millions cumulated pairs of codons with their associated amino acids presented to the neural network over around 7–40 training epochs, depending on the architecture and settings. We confirm that the wide generic capacities and modularity of deep neural networks allow them to be customized easily to learn the deciphering task of the genetic code efficiently.},
  archive      = {J_FRAI},
  author       = {Joiret, Marc and Leclercq, Marine and Lambrechts, Gaspard and Rapino, Francesca and Close, Pierre and Louppe, Gilles and Geris, Liesbet},
  doi          = {10.3389/frai.2023.1128153},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1128153},
  shortjournal = {Front. Artif. Intell.},
  title        = {Cracking the genetic code with neural networks},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using machine learning for healthcare treatment planning.
<em>FRAI</em>, <em>6</em>, 1124182. (<a
href="https://doi.org/10.3389/frai.2023.1124182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a methodology for using machine learning for planning treatments. As a case study, we apply the proposed methodology to Breast Cancer. Most of the application of Machine Learning to breast cancer has been on diagnosis and early detection. By contrast, our paper focuses on applying Machine Learning to suggest treatment plans for patients with different disease severity. While the need for surgery and even its type is often obvious to a patient, the need for chemotherapy and radiation therapy is not as obvious to the patient. With this in mind, the following treatment plans were considered in this study: chemotherapy, radiation, chemotherapy with radiation, and none of these options (only surgery). We use real data from more than 10,000 patients over 6 years that includes detailed cancer information, treatment plans, and survival statistics. Using this data set, we construct Machine Learning classifiers to suggest treatment plans. Our emphasis in this effort is not only on suggesting the treatment plan but on explaining and defending a particular treatment choice to the patient.},
  archive      = {J_FRAI},
  author       = {Dubey, Snigdha and Tiwari, Gaurav and Singh, Sneha and Goldberg, Saveli and Pinsky, Eugene},
  doi          = {10.3389/frai.2023.1124182},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1124182},
  shortjournal = {Front. Artif. Intell.},
  title        = {Using machine learning for healthcare treatment planning},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning from real world data about combinatorial treatment
selection for COVID-19. <em>FRAI</em>, <em>6</em>, 1123285. (<a
href="https://doi.org/10.3389/frai.2023.1123285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 is an unprecedented global pandemic with a serious negative impact on virtually every part of the world. Although much progress has been made in preventing and treating the disease, much remains to be learned about how best to treat the disease while considering patient and disease characteristics. This paper reports a case study of combinatorial treatment selection for COVID-19 based on real-world data from a large hospital in Southern China. In this observational study, 417 confirmed COVID-19 patients were treated with various combinations of drugs and followed for four weeks after discharge (or until death). Treatment failure is defined as death during hospitalization or recurrence of COVID-19 within four weeks of discharge. Using a virtual multiple matching method to adjust for confounding, we estimate and compare the failure rates of different combinatorial treatments, both in the whole study population and in subpopulations defined by baseline characteristics. Our analysis reveals that treatment effects are substantial and heterogeneous, and that the optimal combinatorial treatment may depend on baseline age, systolic blood pressure, and c-reactive protein level. Using these three variables to stratify the study population leads to a stratified treatment strategy that involves several different combinations of drugs (for patients in different strata). Our findings are exploratory and require further validation.},
  archive      = {J_FRAI},
  author       = {Zhai, Song and Zhang, Zhiwei and Liao, Jiayu and Cui, Xinping},
  doi          = {10.3389/frai.2023.1123285},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1123285},
  shortjournal = {Front. Artif. Intell.},
  title        = {Learning from real world data about combinatorial treatment selection for COVID-19},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Achieving descriptive accuracy in explanations via
argumentation: The case of probabilistic classifiers. <em>FRAI</em>,
<em>6</em>, 1099407. (<a
href="https://doi.org/10.3389/frai.2023.1099407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pursuit of trust in and fairness of AI systems in order to enable human-centric goals has been gathering pace of late, often supported by the use of explanations for the outputs of these systems. Several properties of explanations have been highlighted as critical for achieving trustworthy and fair AI systems, but one that has thus far been overlooked is that of descriptive accuracy (DA), i.e., that the explanation contents are in correspondence with the internal working of the explained system. Indeed, the violation of this core property would lead to the paradoxical situation of systems producing explanations which are not suitably related to how the system actually works: clearly this may hinder user trust. Further, if explanations violate DA then they can be deceitful, resulting in an unfair behavior toward the users. Crucial as the DA property appears to be, it has been somehow overlooked in the XAI literature to date. To address this problem, we consider the questions of formalizing DA and of analyzing its satisfaction by explanation methods. We provide formal definitions of naive, structural and dialectical DA, using the family of probabilistic classifiers as the context for our analysis. We evaluate the satisfaction of our given notions of DA by several explanation methods, amounting to two popular feature-attribution methods from the literature, variants thereof and a novel form of explanation that we propose. We conduct experiments with a varied selection of concrete probabilistic classifiers and highlight the importance, with a user study, of our most demanding notion of dialectical DA, which our novel method satisfies by design and others may violate. We thus demonstrate how DA could be a critical component in achieving trustworthy and fair systems, in line with the principles of human-centric AI.},
  archive      = {J_FRAI},
  author       = {Albini, Emanuele and Rago, Antonio and Baroni, Pietro and Toni, Francesca},
  doi          = {10.3389/frai.2023.1099407},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1099407},
  shortjournal = {Front. Artif. Intell.},
  title        = {Achieving descriptive accuracy in explanations via argumentation: The case of probabilistic classifiers},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modeling needs user modeling. <em>FRAI</em>, <em>6</em>,
1097891. (<a href="https://doi.org/10.3389/frai.2023.1097891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling has actively tried to take the human out of the loop, originally for objectivity and recently also for automation. We argue that an unnecessary side effect has been that modeling workflows and machine learning pipelines have become restricted to only well-specified problems. Putting the humans back into the models would enable modeling a broader set of problems, through iterative modeling processes in which AI can offer collaborative assistance. However, this requires advances in how we scope our modeling problems, and in the user models. In this perspective article, we characterize the required user models and the challenges ahead for realizing this vision, which would enable new interactive modeling workflows, and human-centric or human-compatible machine learning pipelines.},
  archive      = {J_FRAI},
  author       = {Çelikok, Mustafa Mert and Murena, Pierre-Alexandre and Kaski, Samuel},
  doi          = {10.3389/frai.2023.1097891},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1097891},
  shortjournal = {Front. Artif. Intell.},
  title        = {Modeling needs user modeling},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modeling the dynamics of contractual relations.
<em>FRAI</em>, <em>6</em>, 1042319. (<a
href="https://doi.org/10.3389/frai.2023.1042319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contracts usually have clauses that enable contracted parties to adjust their contractual positions in time, e.g., to relieve another party from duty or to grant new permission. This is especially important in long-running service relations, which require contracts to be adjusted to accommodate new or unforeseen circumstances. Despite that, the representation of dynamic aspects of contractual relations has not been given enough attention in the literature. In this study, we address this gap by employing the notions of legal power and legal subjection. We propose an ontological analysis of unilateral contractual changes based on a well-founded legal core ontology that adopts a relational perspective for legal positions. We present a case study to show the benefits of representing different types of contractual changes and how these changes can impact contractual dynamics. The case study is based on recent changes to WhatsApp terms of service.},
  archive      = {J_FRAI},
  author       = {Griffo, Cristine and Araujo, Lauro César and Meira Brasil, Samuel and Marques, Mamede-Lima and Guizzardi, Giancarlo and Almeida, João Paulo A.},
  doi          = {10.3389/frai.2023.1042319},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1042319},
  shortjournal = {Front. Artif. Intell.},
  title        = {Modeling the dynamics of contractual relations},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A field-based recommender system for crop disease detection
using machine learning. <em>FRAI</em>, <em>6</em>, 1010804. (<a
href="https://doi.org/10.3389/frai.2023.1010804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates crop disease monitoring with real-time information feedback to smallholder farmers. Proper crop disease diagnosis tools and information about agricultural practices are key to growth and development in the agricultural sector. The research was piloted in a rural community of smallholder farmers having 100 farmers participating in a system that performs diagnosis on cassava diseases and provides advisory recommendation services with real-time information. Here, we present a field-based recommendation system that provides real-time feedback on crop disease diagnosis. Our recommender system is based on question–answer pairs, and it is built using machine learning and natural language processing techniques. We study and experiment with various algorithms that are considered state-of-the-art in the field. The best performance is achieved with the sentence BERT model (RetBERT), which obtains a BLEU score of 50.8%, which we think is limited by the limited amount of available data. The application tool integrates both online and offline services since farmers come from remote areas where internet is limited. Success in this study will result in a large trial to validate its applicability for use in alleviating the food security problem in sub-Saharan Africa.},
  archive      = {J_FRAI},
  author       = {Omara, Jonathan and Talavera, Estefania and Otim, Daniel and Turcza, Dan and Ofumbi, Emmanuel and Owomugisha, Godliver},
  doi          = {10.3389/frai.2023.1010804},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1010804},
  shortjournal = {Front. Artif. Intell.},
  title        = {A field-based recommender system for crop disease detection using machine learning},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diagnostic medical artificial intelligence: Futuristic
prospects for implementation in healthcare settings. <em>FRAI</em>,
<em>6</em>, 1169244. (<a
href="https://doi.org/10.3389/frai.2023.1169244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Nagam, Vishruth M.},
  doi          = {10.3389/frai.2023.1169244},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1169244},
  shortjournal = {Front. Artif. Intell.},
  title        = {Diagnostic medical artificial intelligence: Futuristic prospects for implementation in healthcare settings},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Human-centered AI: Crowd computing.
<em>FRAI</em>, <em>6</em>, 1161006. (<a
href="https://doi.org/10.3389/frai.2023.1161006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Yang, Jie and Bozzon, Alessandro and Gadiraju, Ujwal and Lease, Matthew},
  doi          = {10.3389/frai.2023.1161006},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1161006},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: human-centered AI: crowd computing},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The weaponization of artificial intelligence: What the
public needs to be aware of. <em>FRAI</em>, <em>6</em>, 1154184. (<a
href="https://doi.org/10.3389/frai.2023.1154184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technological progress has brought about the emergence of machines that have the capacity to take human lives without human control. These represent an unprecedented threat to humankind. This paper starts from the example of chemical weapons, now banned worldwide by the Geneva protocol, to illustrate how technological development initially aimed at the benefit of humankind has, ultimately, produced what is now called the “Weaponization of Artificial Intelligence (AI)”. Autonomous Weapon Systems (AWS) fail the so-called discrimination principle, yet, the wider public is largely unaware of this problem. Given that ongoing scientific research on AWS, performed in the military sector, is generally not made available to the public domain, many of the viewpoints on this subject, expressed across different media, invoke common sense rather than scientific evidence. Yet, the implications of a potential weaponization of our work as scientists, especially in the field of AI, are reaching further than some may think. The potential consequences of a deployment of AWS for citizen stakeholders are incommensurable, and it is time to raise awareness in the public domain of the kind of potential threats identified, and to encourage legal policies ensuring that these threats will not materialize.},
  archive      = {J_FRAI},
  author       = {Dresp-Langley, Birgitta},
  doi          = {10.3389/frai.2023.1154184},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1154184},
  shortjournal = {Front. Artif. Intell.},
  title        = {The weaponization of artificial intelligence: What the public needs to be aware of},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Disembodied AI and the limits to machine understanding of
students’ embodied interactions. <em>FRAI</em>, <em>6</em>, 1148227. (<a
href="https://doi.org/10.3389/frai.2023.1148227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The embodiment turn in the Learning Sciences has fueled growth of multimodal learning analytics to understand embodied interactions and make consequential educational decisions about students more rapidly, more accurately, and more personalized than ever before. Managing demands of complexity and speed is leading to growing reliance by education systems on disembodied artificial intelligence (dAI) programs, which, ironically, are inherently incapable of interpreting students&#39; embodied interactions. This is fueling a potential crisis of complexity. Augmented intelligence systems offer promising avenues for managing this crisis by integrating the strengths of omnipresent dAI to detect complex patterns of student behavior from multimodal datastreams, with the strengths of humans to meaningfully interpret embodied interactions in service of consequential decision making to achieve a balance between complexity, interpretability, and accountability for allocating education resources to children.},
  archive      = {J_FRAI},
  author       = {Nathan, Mitchell J.},
  doi          = {10.3389/frai.2023.1148227},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1148227},
  shortjournal = {Front. Artif. Intell.},
  title        = {Disembodied AI and the limits to machine understanding of students&#39; embodied interactions},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bone age assessment based on deep neural networks with
annotation-free cascaded critical bone region extraction. <em>FRAI</em>,
<em>6</em>, 1142895. (<a
href="https://doi.org/10.3389/frai.2023.1142895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bone age assessment (BAA) from hand radiographs is crucial for diagnosing endocrinology disorders in adolescents and supplying therapeutic investigation. In practice, due to the conventional clinical assessment being a subjective estimation, the accuracy of BAA relies highly on the pediatrician&#39;s professionalism and experience. Recently, many deep learning methods have been proposed for the automatic estimation of bone age and had good results. However, these methods do not exploit sufficient discriminative information or require additional manual annotations of critical bone regions that are important biological identifiers in skeletal maturity, which may restrict the clinical application of these approaches. In this research, we propose a novel two-stage deep learning method for BAA without any manual region annotation, which consists of a cascaded critical bone region extraction network and a gender-assisted bone age estimation network. First, the cascaded critical bone region extraction network automatically and sequentially locates two discriminative bone regions via the visual heat maps. Second, in order to obtain an accurate BAA, the extracted critical bone regions are fed into the gender-assisted bone age estimation network. The results showed that the proposed method achieved a mean absolute error (MAE) of 5.45 months on the public dataset Radiological Society of North America (RSNA) and 3.34 months on our private dataset.},
  archive      = {J_FRAI},
  author       = {Li, Zhangyong and Chen, Wang and Ju, Yang and Chen, Yong and Hou, Zhengjun and Li, Xinwei and Jiang, Yuhao},
  doi          = {10.3389/frai.2023.1142895},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1142895},
  shortjournal = {Front. Artif. Intell.},
  title        = {Bone age assessment based on deep neural networks with annotation-free cascaded critical bone region extraction},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep treasury management for banks. <em>FRAI</em>,
<em>6</em>, 1120297. (<a
href="https://doi.org/10.3389/frai.2023.1120297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retail banks use Asset Liability Management (ALM) to hedge interest rate risk associated with differences in maturity and predictability of their loan and deposit portfolios. The opposing goals of profiting from maturity transformation and hedging interest rate risk while adhering to numerous regulatory constraints make ALM a challenging problem. We formulate ALM as a high-dimensional stochastic control problem in which monthly investment and financing decisions drive the evolution of the bank&#39;s balance sheet. To find strategies that maximize long-term utility in the presence of constraints and stochastic interest rates, we train neural networks that parametrize the decision process. Our experiments provide practical insights and demonstrate that the approach of Deep ALM deduces dynamic strategies that outperform static benchmarks.},
  archive      = {J_FRAI},
  author       = {Englisch, Holger and Krabichler, Thomas and Müller, Konrad J. and Schwarz, Marc},
  doi          = {10.3389/frai.2023.1120297},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1120297},
  shortjournal = {Front. Artif. Intell.},
  title        = {Deep treasury management for banks},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Masking important information to assess the robustness of a
multimodal classifier for emotion recognition. <em>FRAI</em>,
<em>6</em>, 1091443. (<a
href="https://doi.org/10.3389/frai.2023.1091443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have been proven effective in classifying human interactions into emotions, especially by encoding multiple input modalities. In this work, we assess the robustness of a transformer-based multimodal audio-text classifier for emotion recognition, by perturbing the input at inference time using attacks which we design specifically to corrupt information deemed important for emotion recognition. To measure the impact of the attacks on the classifier, we compare between the accuracy of the classifier on the perturbed input and on the original, unperturbed input. Our results show that the multimodal classifier is more resilient to perturbation attacks than the equivalent unimodal classifiers, suggesting that the two modalities are encoded in a way that allows the classifier to benefit from one modality even when the other one is slightly damaged.},
  archive      = {J_FRAI},
  author       = {Cohen, Dror and Rosenberger, Ido and Butman, Moshe and Bar, Kfir},
  doi          = {10.3389/frai.2023.1091443},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1091443},
  shortjournal = {Front. Artif. Intell.},
  title        = {Masking important information to assess the robustness of a multimodal classifier for emotion recognition},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning approaches to identify parkinson’s disease
using voice signal features. <em>FRAI</em>, <em>6</em>, 1084001. (<a
href="https://doi.org/10.3389/frai.2023.1084001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson&#39;s Disease (PD) is the second most common age-related neurological disorder that leads to a range of motor and cognitive symptoms. A PD diagnosis is difficult since its symptoms are quite similar to those of other disorders, such as normal aging and essential tremor. When people reach 50, visible symptoms such as difficulties walking and communicating begin to emerge. Even though there is no cure for PD, certain medications can relieve some of the symptoms. Patients can maintain their lifestyles by controlling the complications caused by the disease. At this point, it is essential to detect this disease and prevent it from progressing. The diagnosis of the disease has been the subject of much research. In our project, we aim to detect PD using different types of Machine Learning (ML), and Deep Learning (DL) models such as Support Vector Machine (SVM), Random Forest (RF), Decision Tree (DT), K-Nearest Neighbor (KNN), and Multi-Layer Perceptron (MLP) to differentiate between healthy and PD patients by voice signal features. The dataset taken from the University of California at Irvine (UCI) machine learning repository consisted of 195 voice recordings of examinations carried out on 31 patients. Moreover, our models were trained using different techniques such as Synthetic Minority Over-sampling Technique (SMOTE), Feature Selection, and hyperparameter tuning (GridSearchCV) to enhance their performance. At the end, we found that MLP and SVM with a ratio of 70:30 train/test split using GridSearchCV with SMOTE gave the best results for our project. MLP performed with an overall accuracy of 98.31%, an overall recall of 98%, an overall precision of 100%, and f1-score of 99%. In addition, SVM performed with an overall accuracy of 95%, an overall recall of 96%, an overall precision of 98%, and f1-score of 97%. The experimental results of this research imply that the proposed method can be used to reliably predict PD and can be easily incorporated into healthcare for diagnosis purposes.},
  archive      = {J_FRAI},
  author       = {Alshammri, Raya and Alharbi, Ghaida and Alharbi, Ebtisam and Almubark, Ibrahim},
  doi          = {10.3389/frai.2023.1084001},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1084001},
  shortjournal = {Front. Artif. Intell.},
  title        = {Machine learning approaches to identify parkinson&#39;s disease using voice signal features},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development and evaluation of a java-based deep neural
network method for drug response predictions. <em>FRAI</em>, <em>6</em>,
1069353. (<a href="https://doi.org/10.3389/frai.2023.1069353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of drug response is a crucial step in personalized medicine. Recently, deep learning techniques have been witnessed with significant breakthroughs in a variety of areas including biomedical research and chemogenomic applications. This motivated us to develop a novel deep learning platform to accurately and reliably predict the response of cancer cells to different drug treatments. In the present work, we describe a Java-based implementation of deep neural network method, termed JavaDL, to predict cancer responses to drugs solely based on their chemical features. To this end, we devised a novel cost function and added a regularization term which suppresses overfitting. We also adopted an early stopping strategy to further reduce overfit and improve the accuracy and robustness of our models. To evaluate our method, we compared with several popular machine learning and deep neural network programs and observed that JavaDL either outperformed those methods in model building or obtained comparable predictions. Finally, JavaDL was employed to predict drug responses of several aggressive breast cancer cell lines, and the results showed robust and accurate predictions with r2 as high as 0.81.},
  archive      = {J_FRAI},
  author       = {Huang, Beibei and Fong, Lon W. R. and Chaudhari, Rajan and Zhang, Shuxing},
  doi          = {10.3389/frai.2023.1069353},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1069353},
  shortjournal = {Front. Artif. Intell.},
  title        = {Development and evaluation of a java-based deep neural network method for drug response predictions},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rethinking symbolic and visual context in referring
expression generation. <em>FRAI</em>, <em>6</em>, 1067125. (<a
href="https://doi.org/10.3389/frai.2023.1067125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Situational context is crucial for linguistic reference to visible objects, since the same description can refer unambiguously to an object in one context but be ambiguous or misleading in others. This also applies to Referring Expression Generation (REG), where the production of identifying descriptions is always dependent on a given context. Research in REG has long represented visual domains through symbolic information about objects and their properties, to determine identifying sets of target features during content determination. In recent years, research in visual REG has turned to neural modeling and recasted the REG task as an inherently multimodal problem, looking at more natural settings such as generating descriptions for objects in photographs. Characterizing the precise ways in which context influences generation is challenging in both paradigms, as context is notoriously lacking precise definitions and categorization. In multimodal settings, however, these problems are further exacerbated by the increased complexity and low-level representation of perceptual inputs. The main goal of this article is to provide a systematic review of the types and functions of visual context across various approaches to REG so far and to argue for integrating and extending different perspectives on visual context that currently co-exist in research on REG. By analyzing the ways in which symbolic REG integrates context in rule-based approaches, we derive a set of categories of contextual integration, including the distinction between positive and negative semantic forces exerted by context during reference generation. Using this as a framework, we show that so far existing work in visual REG has considered only some of the ways in which visual context can facilitate end-to-end reference generation. Connecting with preceding research in related areas, as possible directions for future research, we highlight some additional ways in which contextual integration can be incorporated into REG and other multimodal generation tasks.},
  archive      = {J_FRAI},
  author       = {Schüz, Simeon and Gatt, Albert and Zarrieß, Sina},
  doi          = {10.3389/frai.2023.1067125},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1067125},
  shortjournal = {Front. Artif. Intell.},
  title        = {Rethinking symbolic and visual context in referring expression generation},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A tale of two lexica: Investigating computational pressures
on word representation with neural networks. <em>FRAI</em>, <em>6</em>,
1062230. (<a href="https://doi.org/10.3389/frai.2023.1062230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe notion of a single localized store of word representations has become increasingly less plausible as evidence has accumulated for the widely distributed neural representation of wordform grounded in motor, perceptual, and conceptual processes. Here, we attempt to combine machine learning methods and neurobiological frameworks to propose a computational model of brain systems potentially responsible for wordform representation. We tested the hypothesis that the functional specialization of word representation in the brain is driven partly by computational optimization. This hypothesis directly addresses the unique problem of mapping sound and articulation vs. mapping sound and meaning.ResultsWe found that artificial neural networks trained on the mapping between sound and articulation performed poorly in recognizing the mapping between sound and meaning and vice versa. Moreover, a network trained on both tasks simultaneously could not discover the features required for efficient mapping between sound and higher-level cognitive states compared to the other two models. Furthermore, these networks developed internal representations reflecting specialized task-optimized functions without explicit training.DiscussionTogether, these findings demonstrate that different task-directed representations lead to more focused responses and better performance of a machine or algorithm and, hypothetically, the brain. Thus, we imply that the functional specialization of word representation mirrors a computational optimization strategy given the nature of the tasks that the human brain faces.},
  archive      = {J_FRAI},
  author       = {Avcu, Enes and Hwang, Michael and Brown, Kevin Scott and Gow, David W.},
  doi          = {10.3389/frai.2023.1062230},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1062230},
  shortjournal = {Front. Artif. Intell.},
  title        = {A tale of two lexica: Investigating computational pressures on word representation with neural networks},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). What naturalistic stimuli tell us about pronoun resolution
in real-time processing. <em>FRAI</em>, <em>6</em>, 1058554. (<a
href="https://doi.org/10.3389/frai.2023.1058554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studies on pronoun resolution have mostly utilized short texts consisting of a context and a target sentence. In the current study we presented participants with nine chapters of an audio book while recording their EEG to investigate the real-time resolution of personal and demonstrative pronouns in a more naturalistic setting. The annotation of the features of the pronouns and their antecedents registered a surprising pattern: demonstrative pronouns showed an interpretive preference for subject/agent antecedents, although they are described to have an anti-subject or anti-agent preference. Given the presence of perspectival centers in the audio book, this however confirmed proposals that demonstrative pronouns are sensitive to perspectival centers. The ERP results revealed a biphasic N400–Late Positivity pattern at posterior electrodes for the demonstrative pronoun relative to the personal pronoun, thereby confirming previous findings with highly controlled stimuli. We take the observed N400 for the demonstrative pronoun as an indication for more demanding processing costs that occur due to the relative unexpectedness of this referential expression. The Late Positivity is taken to reflect the consequences of attentional reorientation: since the demonstrative pronoun indicates a possible shift in the discourse structure, it induces updating of the discourse structure. In addition to the biphasic pattern, the data showed an enhanced positivity at frontal electrode sites for the demonstrative pronoun relative to the personal pronoun. We suggest that this frontal positivity reflects self-relevant engagement and identification with the perspective holder. Our study suggests that by using naturalistic stimuli, we get one step closer to understanding the implementation of language processing in the brain during real life language processing.},
  archive      = {J_FRAI},
  author       = {Repp, Magdalena and Schumacher, Petra B.},
  doi          = {10.3389/frai.2023.1058554},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1058554},
  shortjournal = {Front. Artif. Intell.},
  title        = {What naturalistic stimuli tell us about pronoun resolution in real-time processing},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An argumentation semantics for rational human evaluation of
arguments. <em>FRAI</em>, <em>6</em>, 1045663. (<a
href="https://doi.org/10.3389/frai.2023.1045663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In abstract argumentation theory, many argumentation semantics have been proposed for evaluating argumentation frameworks. This article is based on the following research question: Which semantics corresponds well to what humans consider a rational judgment on the acceptability of arguments? There are two systematic ways to approach this research question: A normative perspective is provided by the principle-based approach, in which semantics are evaluated based on their satisfaction of various normatively desirable principles. A descriptive perspective is provided by the empirical approach, in which cognitive studies are conducted to determine which semantics best predicts human judgments about arguments. In this article, we combine both approaches to motivate a new argumentation semantics called SCF2. For this purpose, we introduce and motivate two new principles and show that no semantics from the literature satisfies both of them. We define SCF2 and prove that it satisfies both new principles. Furthermore, we discuss findings of a recent empirical cognitive study that provide additional support to SCF2.},
  archive      = {J_FRAI},
  author       = {Cramer, Marcos and van der Torre, Leendert},
  doi          = {10.3389/frai.2023.1045663},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1045663},
  shortjournal = {Front. Artif. Intell.},
  title        = {An argumentation semantics for rational human evaluation of arguments},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EQRbot: A chatbot delivering EQR argument-based
explanations. <em>FRAI</em>, <em>6</em>, 1045614. (<a
href="https://doi.org/10.3389/frai.2023.1045614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed the rise of several new argumentation-based support systems, especially in the healthcare industry. In the medical sector, it is imperative that the exchange of information occurs in a clear and accurate way, and this has to be reflected in any employed virtual systems. Argument Schemes and their critical questions represent well-suited formal tools for modeling such information and exchanges since they provide detailed templates for explanations to be delivered. This paper details the EQR argument scheme and deploys it to generate explanations for patients&#39; treatment advice using a chatbot (EQRbot). The EQR scheme (devised as a pattern of Explanation-Question-Response interactions between agents) comprises multiple premises that can be interrogated to disclose additional data. The resulting explanations, obtained as instances of the employed argumentation reasoning engine and the EQR template, will then feed the conversational agent that will exhaustively convey the requested information and answers to follow-on users&#39; queries as personalized Telegram messages. Comparisons with a previous baseline and existing argumentation-based chatbots illustrate the improvements yielded by EQRbot against similar conversational agents.},
  archive      = {J_FRAI},
  author       = {Castagna, Federico and Garton, Alexandra and McBurney, Peter and Parsons, Simon and Sassoon, Isabel and Sklar, Elizabeth I.},
  doi          = {10.3389/frai.2023.1045614},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1045614},
  shortjournal = {Front. Artif. Intell.},
  title        = {EQRbot: A chatbot delivering EQR argument-based explanations},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Active feature elicitation: An unified framework.
<em>FRAI</em>, <em>6</em>, 1029943. (<a
href="https://doi.org/10.3389/frai.2023.1029943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of active feature elicitation in which, given some examples with all the features (say, the full Electronic Health Record), and many examples with some of the features (say, demographics), the goal is to identify the set of examples on which more information (say, lab tests) need to be collected. The observation is that some set of features may be more expensive, personal or cumbersome to collect. We propose a classifier-independent, similarity metric-independent, general active learning approach which identifies examples that are dissimilar to the ones with the full set of data and acquire the complete set of features for these examples. Motivated by four real clinical tasks, our extensive evaluation demonstrates the effectiveness of this approach. To demonstrate the generalization capabilities of the proposed approach, we consider different divergence metrics and classifiers and present consistent results across the domains.},
  archive      = {J_FRAI},
  author       = {Das, Srijita and Ramanan, Nandini and Kunapuli, Gautam and Radivojac, Predrag and Natarajan, Sriraam},
  doi          = {10.3389/frai.2023.1029943},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1029943},
  shortjournal = {Front. Artif. Intell.},
  title        = {Active feature elicitation: An unified framework},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). COVID-twitter-BERT: A natural language processing model to
analyse COVID-19 content on twitter. <em>FRAI</em>, <em>6</em>, 1023281.
(<a href="https://doi.org/10.3389/frai.2023.1023281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThis study presents COVID-Twitter-BERT (CT-BERT), a transformer-based model that is pre-trained on a large corpus of COVID-19 related Twitter messages. CT-BERT is specifically designed to be used on COVID-19 content, particularly from social media, and can be utilized for various natural language processing tasks such as classification, question-answering, and chatbots. This paper aims to evaluate the performance of CT-BERT on different classification datasets and compare it with BERT-LARGE, its base model.MethodsThe study utilizes CT-BERT, which is pre-trained on a large corpus of COVID-19 related Twitter messages. The authors evaluated the performance of CT-BERT on five different classification datasets, including one in the target domain. The model&#39;s performance is compared to its base model, BERT-LARGE, to measure the marginal improvement. The authors also provide detailed information on the training process and the technical specifications of the model.ResultsThe results indicate that CT-BERT outperforms BERT-LARGE with a marginal improvement of 10-30% on all five classification datasets. The largest improvements are observed in the target domain. The authors provide detailed performance metrics and discuss the significance of these results.DiscussionThe study demonstrates the potential of pre-trained transformer models, such as CT-BERT, for COVID-19 related natural language processing tasks. The results indicate that CT-BERT can improve the classification performance on COVID-19 related content, especially on social media. These findings have important implications for various applications, such as monitoring public sentiment and developing chatbots to provide COVID-19 related information. The study also highlights the importance of using domain-specific pre-trained models for specific natural language processing tasks. Overall, this work provides a valuable contribution to the development of COVID-19 related NLP models.},
  archive      = {J_FRAI},
  author       = {Müller, Martin and Salathé, Marcel and Kummervold, Per E.},
  doi          = {10.3389/frai.2023.1023281},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1023281},
  shortjournal = {Front. Artif. Intell.},
  title        = {COVID-twitter-BERT: A natural language processing model to analyse COVID-19 content on twitter},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The assessment list for trustworthy artificial intelligence:
A review and recommendations. <em>FRAI</em>, <em>6</em>, 1020592. (<a
href="https://doi.org/10.3389/frai.2023.1020592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In July 2020, the European Commission&#39;s High-Level Expert Group on AI (HLEG-AI) published the Assessment List for Trustworthy Artificial Intelligence (ALTAI) tool, enabling organizations to perform self-assessments of the fit of their AI systems and surrounding governance to the “7 Principles for Trustworthy AI.” Prior research on ALTAI has focused primarily on specific application areas, but there has yet to be a comprehensive analysis and broader recommendations aimed at proto-regulators and industry practitioners. This paper therefore starts with an overview of this tool, including an assessment of its strengths and limitations. The authors then consider the success by which the ALTAI tool is likely to be of utility to industry in improving understanding of the risks inherent in AI systems and best practices to mitigate such risks. It is highlighted how research and practices from fields such as Environmental Sustainability, Social Justice, and Corporate Governance (ESG) can be of benefit for addressing similar challenges in ethical AI development and deployment. Also explored is the extent to which the tool is likely to be successful in being taken up by industry, considering various factors pertaining to its likely adoption. Finally, the authors also propose recommendations applicable internationally to similar bodies to the HLEG-AI regarding the gaps needing to be addressed between high-level principles and practical support for those on the front-line developing or commercializing AI tools. In all, this work provides a comprehensive analysis of the ALTAI tool, as well as recommendations to relevant stakeholders, with the broader aim of promoting more widespread adoption of such a tool in industry.},
  archive      = {J_FRAI},
  author       = {Radclyffe, Charles and Ribeiro, Mafalda and Wortham, Robert H.},
  doi          = {10.3389/frai.2023.1020592},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1020592},
  shortjournal = {Front. Artif. Intell.},
  title        = {The assessment list for trustworthy artificial intelligence: A review and recommendations},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). She adapts to her student: An expert pragmatic speaker
tailoring her referring expressions to the layman listener.
<em>FRAI</em>, <em>6</em>, 1017204. (<a
href="https://doi.org/10.3389/frai.2023.1017204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication is a dynamic process through which interlocutors adapt to each other. In the development of conversational agents, this core aspect has been put aside for several years since the main challenge was to obtain conversational neural models able to produce utterances and dialogues that at least at the surface level are human-like. Now that this milestone has been achieved, the importance of paying attention to the dynamic and adaptive interactive aspects of language has been advocated in several position papers. In this paper, we focus on how a Speaker adapts to an interlocutor with different background knowledge. Our models undergo a pre-training phase, through which they acquire grounded knowledge by learning to describe an image, and an adaptive phase through which a Speaker and a Listener play a repeated reference game. Using a similar setting, previous studies focus on how conversational models create new conventions; we are interested, instead, in studying whether the Speaker learns from the Listener&#39;s mistakes to adapt to his background knowledge. We evaluate models based on Rational Speech Act (RSA), a likelihood loss, and a combination of the two. We show that RSA could indeed work as a backbone to drive the Speaker toward the Listener: in the combined model, apart from the improved Listener&#39;s accuracy, the language generated by the Speaker features the changes that signal adaptation to the Listener&#39;s background knowledge. Specifically, captions to unknown object categories contain more adjectives and less direct reference to the unknown objects.},
  archive      = {J_FRAI},
  author       = {Greco, Claudio and Bagade, Diksha and Le, Dieu-Thu and Bernardi, Raffaella},
  doi          = {10.3389/frai.2023.1017204},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1017204},
  shortjournal = {Front. Artif. Intell.},
  title        = {She adapts to her student: An expert pragmatic speaker tailoring her referring expressions to the layman listener},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). “We are at war”: The military rhetoric of COVID-19 in
cross-cultural perspective of discourses. <em>FRAI</em>, <em>6</em>,
978096. (<a href="https://doi.org/10.3389/frai.2023.978096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At the outburst of the COVID-19 pandemic and all throughout its continuation in 2020 and 2021, the metaphor of ‘war&#39; has been one of the most pervasive and recurrent globally. As an international, cross-cultural group of scholars and practitioners, we will analyze critically the communicative strategies enacted and the political agenda that they have meant to serve in Italy, Bulgaria, and Ukraine discussing both the cultural differences and the cross-cultural similarities of such a discourse that has been shaping the perception of our factual reality during the pandemic. Expressions like ‘We are at war&#39;, ‘Our heroes are fighting at the forefront&#39;, ‘We will win this war&#39; and the like contributed to create symbolical cross-cultural responses that, by playing on emotions such as fear, uncertainty and, in some cases, national pride, contributed to the creation of a new state of reality, that of the “new normality”, calling for specific actions and behaviors. However, the war metaphor assumed different hues according to the country in which it was disseminated, up to the actual appointment of generals as governmental spoke-persons or organizers of the vaccine logistics, often combined with the construction and the mediatization of the archetypical hero fighting against the virus/enemy. To analyze how, all throughout 2020 and 2021, the military rhetoric was implemented and disseminated as the dominant discourse, we draw on Media Representations of the Real, on Rhetoric Studies on Manipulation, on Political Discourse, on Critical Discourse Studies, and on Susan Sontag&#39;s fundamental essay Illness as Metaphor. We discuss such rhetorical strategies as they originated from a discussion within our collective project in other words, an online dictionary that, besides critically analyzing contextualized keywords that (re)produce different forms of Otherness, offers creative proposals to reverse such narratives, and can be used as a free resource in different social and educational contexts (www.iowdictionary.org).},
  archive      = {J_FRAI},
  author       = {Giorgis, Paola and Semenets, Olena and Todorova, Bilyana},
  doi          = {10.3389/frai.2023.978096},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {978096},
  shortjournal = {Front. Artif. Intell.},
  title        = {“We are at war”: The military rhetoric of COVID-19 in cross-cultural perspective of discourses},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sequence-to-sequence pretraining for a less-resourced
slovenian language. <em>FRAI</em>, <em>6</em>, 932519. (<a
href="https://doi.org/10.3389/frai.2023.932519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionLarge pretrained language models have recently conquered the area of natural language processing. As an alternative to predominant masked language modeling introduced in BERT, the T5 model has introduced a more general training objective, namely sequence to sequence transformation, which more naturally fits text generation tasks. The monolingual variants of T5 models have been limited to well-resourced languages, while the massively multilingual T5 model supports 101 languages.MethodsWe trained two different-sized T5-type sequence-to-sequence models for morphologically rich Slovene language with much fewer resources. We analyzed the behavior of new models on 11 tasks, eight classification ones (named entity recognition, sentiment classification, lemmatization, two question answering tasks, two natural language inference tasks, and a coreference resolution task), and three text generation tasks (text simplification and two summarization tasks on different datasets). We compared the new SloT5 models with the multilingual mT5 model, multilingual mBART-50 model, and with four encoder BERT-like models: multilingual BERT, multilingual XLM-RoBERTa, trilingual Croatian-Slovene-English BERT, and monolingual Slovene RoBERTa model.ResultsConcerning the classification tasks, the SloT5 models mostly lag behind the monolingual Slovene SloBERTa model. However, these models are helpful for generative tasks and provide several useful results. In general, the size of models matters, and currently, there is not enough training data for Slovene for successful pretraining of large models.DiscussionWhile the results are obtained on Slovene, we believe that they may generalize to other less-resourced languages, where such models will be built. We make the training and evaluation code, as well as the trained models, publicly available.},
  archive      = {J_FRAI},
  author       = {Ulčar, Matej and Robnik-Šikonja, Marko},
  doi          = {10.3389/frai.2023.932519},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {932519},
  shortjournal = {Front. Artif. Intell.},
  title        = {Sequence-to-sequence pretraining for a less-resourced slovenian language},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semantic and pragmatic precision in conversational AI
systems. <em>FRAI</em>, <em>6</em>, 896729. (<a
href="https://doi.org/10.3389/frai.2023.896729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a conversational agent, to display intelligent interactive behavior implies the ability to respond to the user&#39;s intentions and expectations with correct, consistent and relevant actions with appropriate form and content in a timely fashion. In this paper, we present a data-driven analytical approach to embed intelligence into a conversational AI agent. The method requires a certain amount of (ideally) authentic conversational data, which is transformed in a meaningful way to support intelligent dialog modeling and the design of intelligent conversational agents. These transformations rely on the ISO 24617-2 dialog act annotation standard, and are specified in the Dialogue Act Markup Language (DiAML), extended with plug-ins for articulate representations of domain-specific semantic content and customized communicative functionality. ISO 24617-2 is shown to enable systematic in-depth interaction analysis and to facilitate the collection of conversational data of sufficient quality and quantity of instances of interaction phenomena. The paper provides the theoretical and methodological background of extending the ISO standard and DiAML specifications for use in interaction analysis and conversational AI agent design. The expert-assisted design methodology is introduced, with example applications in the healthcare domain, and is validated in human-agent conversational data collection experiments.},
  archive      = {J_FRAI},
  author       = {Bunt, Harry and Petukhova, Volha},
  doi          = {10.3389/frai.2023.896729},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {896729},
  shortjournal = {Front. Artif. Intell.},
  title        = {Semantic and pragmatic precision in conversational AI systems},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A model for representing the semantics of MWEs: From lexical
semantics to the semantic annotation of complex predicates.
<em>FRAI</em>, <em>6</em>, 802218. (<a
href="https://doi.org/10.3389/frai.2023.802218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiword expressions (MWEs) are sequences of words that pose a challenge to the computational processing of human languages due to their idiosyncrasies and the mismatch between their phrasal structure and their semantics. These idiosyncrasies are of lexical, morphosyntactic and semantic 11 nature, namely: non-compositionality, i.e., the meaning of the expression cannot be computed from the meanings of its constituents; discontinuity, i.e., alien elements may intervene; non-13 substitutability, i.e., at least one of the expression constituents is lexicalized and therefore, does not enter in alternations at the paradigmatic axis; and non-modifiability, in that they enter in syntactically 15 rigid structures, posing further constraints over modification, transformations, etc. The paper presents a model for representing MWEs at the level of semantics by taking into account all these inherent idiosyncrasies. The model assumes the form of a linguistic ontology and is applied to Greek verbal multi-word expressions (VMWEs); moreover, the semantics of the lexical entries under scrutiny is also represented via the semantics of their arguments based on corpus evidence. In this regard, modeling the semantics of VMWEs is placed in the lexicon-corpus interface.},
  archive      = {J_FRAI},
  author       = {Giouli, Voula},
  doi          = {10.3389/frai.2023.802218},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {802218},
  shortjournal = {Front. Artif. Intell.},
  title        = {A model for representing the semantics of MWEs: From lexical semantics to the semantic annotation of complex predicates},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Corrigendum: Editorial: Explainable artificial intelligence
models and methods in finance and healthcare. <em>FRAI</em>, <em>6</em>,
1157762. (<a href="https://doi.org/10.3389/frai.2023.1157762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Caffo, Brian S. and D&#39;Asaro, Fabio A. and Garcez, Artur and Raffinetti, Emanuela},
  doi          = {10.3389/frai.2023.1157762},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1157762},
  shortjournal = {Front. Artif. Intell.},
  title        = {Corrigendum: editorial: explainable artificial intelligence models and methods in finance and healthcare},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal blending of multiple independent prediction models.
<em>FRAI</em>, <em>6</em>, 1144886. (<a
href="https://doi.org/10.3389/frai.2023.1144886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We derive blending coefficients for the optimal blend of multiple independent prediction models with normal (Gaussian) distribution as well as the variance of the final blend. We also provide lower and upper bound estimation for the final variance and we compare these results with machine learning with counts, where only binary information (feature says yes or no only) is used for every feature and the majority of features agreeing together make the decision.},
  archive      = {J_FRAI},
  author       = {Taraba, Peter},
  doi          = {10.3389/frai.2023.1144886},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1144886},
  shortjournal = {Front. Artif. Intell.},
  title        = {Optimal blending of multiple independent prediction models},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gamma and vega hedging using deep distributional
reinforcement learning. <em>FRAI</em>, <em>6</em>, 1129370. (<a
href="https://doi.org/10.3389/frai.2023.1129370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show how reinforcement learning can be used in conjunction with quantile regression to develop a hedging strategy for a trader responsible for derivatives that arrive stochastically and depend on a single underlying asset. We assume that the trader makes the portfolio delta-neutral at the end of each day by taking a position in the underlying asset. We focus on how trades in options can be used to manage gamma and vega. The option trades are subject to transaction costs. We consider three different objective functions. We reach conclusions on how the optimal hedging strategy depends on the trader&#39;s objective function, the level of transaction costs, and the maturity of the options used for hedging. We also investigate the robustness of the hedging strategy to the process assumed for the underlying asset.},
  archive      = {J_FRAI},
  author       = {Cao, Jay and Chen, Jacky and Farghadani, Soroush and Hull, John and Poulos, Zissis and Wang, Zeyu and Yuan, Jun},
  doi          = {10.3389/frai.2023.1129370},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1129370},
  shortjournal = {Front. Artif. Intell.},
  title        = {Gamma and vega hedging using deep distributional reinforcement learning},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). First organoid intelligence (OI) workshop to form an OI
community. <em>FRAI</em>, <em>6</em>, 1116870. (<a
href="https://doi.org/10.3389/frai.2023.1116870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The brain is arguably the most powerful computation system known. It is extremely efficient in processing large amounts of information and can discern signals from noise, adapt, and filter faulty information all while running on only 20 watts of power. The human brain&#39;s processing efficiency, progressive learning, and plasticity are unmatched by any computer system. Recent advances in stem cell technology have elevated the field of cell culture to higher levels of complexity, such as the development of three-dimensional (3D) brain organoids that recapitulate human brain functionality better than traditional monolayer cell systems. Organoid Intelligence (OI) aims to harness the innate biological capabilities of brain organoids for biocomputing and synthetic intelligence by interfacing them with computer technology. With the latest strides in stem cell technology, bioengineering, and machine learning, we can explore the ability of brain organoids to compute, and store given information (input), execute a task (output), and study how this affects the structural and functional connections in the organoids themselves. Furthermore, understanding how learning generates and changes patterns of connectivity in organoids can shed light on the early stages of cognition in the human brain. Investigating and understanding these concepts is an enormous, multidisciplinary endeavor that necessitates the engagement of both the scientific community and the public. Thus, on Feb 22–24 of 2022, the Johns Hopkins University held the first Organoid Intelligence Workshop to form an OI Community and to lay out the groundwork for the establishment of OI as a new scientific discipline. The potential of OI to revolutionize computing, neurological research, and drug development was discussed, along with a vision and roadmap for its development over the coming decade.},
  archive      = {J_FRAI},
  author       = {Morales Pantoja, Itzy E. and Smirnova, Lena and Muotri, Alysson R. and Wahlin, Karl J. and Kahn, Jeffrey and Boyd, J. Lomax and Gracias, David H. and Harris, Timothy D. and Cohen-Karni, Tzahi and Caffo, Brian S. and Szalay, Alexander S. and Han, Fang and Zack, Donald J. and Etienne-Cummings, Ralph and Akwaboah, Akwasi and Romero, July Carolina and Alam El Din, Dowlette-Mary and Plotkin, Jesse D. and Paulhamus, Barton L. and Johnson, Erik C. and Gilbert, Frederic and Curley, J. Lowry and Cappiello, Ben and Schwamborn, Jens C. and Hill, Eric J. and Roach, Paul and Tornero, Daniel and Krall, Caroline and Parri, Rheinallt and Sillé, Fenna and Levchenko, Andre and Jabbour, Rabih E. and Kagan, Brett J. and Berlinicke, Cynthia A. and Huang, Qi and Maertens, Alexandra and Herrmann, Kathrin and Tsaioun, Katya and Dastgheyb, Raha and Habela, Christa Whelan and Vogelstein, Joshua T. and Hartung, Thomas},
  doi          = {10.3389/frai.2023.1116870},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1116870},
  shortjournal = {Front. Artif. Intell.},
  title        = {First organoid intelligence (OI) workshop to form an OI community},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Coronavirus diagnosis using cough sounds: Artificial
intelligence approaches. <em>FRAI</em>, <em>6</em>, 1100112. (<a
href="https://doi.org/10.3389/frai.2023.1100112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe Coronavirus disease 2019 (COVID-19) pandemic has caused irreparable damage to the world. In order to prevent the spread of pathogenicity, it is necessary to identify infected people for quarantine and treatment. The use of artificial intelligence and data mining approaches can lead to prevention and reduction of treatment costs. The purpose of this study is to create data mining models in order to diagnose people with the disease of COVID-19 through the sound of coughing.MethodIn this research, Supervised Learning classification algorithms have been used, which include Support Vector Machine (SVM), random forest, and Artificial Neural Networks, that based on the standard “Fully Connected” neural network, Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) recurrent neural networks have been established. The data used in this research was from the online site sorfeh.com/sendcough/en, which has data collected during the spread of COVID-19.ResultWith the data we have collected (about 40,000 people) in different networks, we have reached acceptable accuracies.ConclusionThese findings show the reliability of this method for using and developing a tool as a screening and early diagnosis of people with COVID-19. This method can also be used with simple artificial intelligence networks so that acceptable results can be expected. Based on the findings, the average accuracy was 83% and the best model was 95%.},
  archive      = {J_FRAI},
  author       = {Askari Nasab, Kazem and Mirzaei, Jamal and Zali, Alireza and Gholizadeh, Sarfenaz and Akhlaghdoust, Meisam},
  doi          = {10.3389/frai.2023.1100112},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1100112},
  shortjournal = {Front. Artif. Intell.},
  title        = {Coronavirus diagnosis using cough sounds: Artificial intelligence approaches},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature relevance XAI in anomaly detection: Reviewing
approaches and challenges. <em>FRAI</em>, <em>6</em>, 1099521. (<a
href="https://doi.org/10.3389/frai.2023.1099521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With complexity of artificial intelligence systems increasing continuously in past years, studies to explain these complex systems have grown in popularity. While much work has focused on explaining artificial intelligence systems in popular domains such as classification and regression, explanations in the area of anomaly detection have only recently received increasing attention from researchers. In particular, explaining singular model decisions of a complex anomaly detector by highlighting which inputs were responsible for a decision, commonly referred to as local post-hoc feature relevance, has lately been studied by several authors. In this paper, we systematically structure these works based on their access to training data and the anomaly detection model, and provide a detailed overview of their operation in the anomaly detection domain. We demonstrate their performance and highlight their limitations in multiple experimental showcases, discussing current challenges and opportunities for future work in feature relevance XAI for anomaly detection.},
  archive      = {J_FRAI},
  author       = {Tritscher, Julian and Krause, Anna and Hotho, Andreas},
  doi          = {10.3389/frai.2023.1099521},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1099521},
  shortjournal = {Front. Artif. Intell.},
  title        = {Feature relevance XAI in anomaly detection: Reviewing approaches and challenges},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Missing data in multi-omics integration: Recent advances
through artificial intelligence. <em>FRAI</em>, <em>6</em>, 1098308. (<a
href="https://doi.org/10.3389/frai.2023.1098308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biological systems function through complex interactions between various ‘omics (biomolecules), and a more complete understanding of these systems is only possible through an integrated, multi-omic perspective. This has presented the need for the development of integration approaches that are able to capture the complex, often non-linear, interactions that define these biological systems and are adapted to the challenges of combining the heterogenous data across ‘omic views. A principal challenge to multi-omic integration is missing data because all biomolecules are not measured in all samples. Due to either cost, instrument sensitivity, or other experimental factors, data for a biological sample may be missing for one or more ‘omic techologies. Recent methodological developments in artificial intelligence and statistical learning have greatly facilitated the analyses of multi-omics data, however many of these techniques assume access to completely observed data. A subset of these methods incorporate mechanisms for handling partially observed samples, and these methods are the focus of this review. We describe recently developed approaches, noting their primary use cases and highlighting each method&#39;s approach to handling missing data. We additionally provide an overview of the more traditional missing data workflows and their limitations; and we discuss potential avenues for further developments as well as how the missing data issue and its current solutions may generalize beyond the multi-omics context.},
  archive      = {J_FRAI},
  author       = {Flores, Javier E. and Claborne, Daniel M. and Weller, Zachary D. and Webb-Robertson, Bobbie-Jo M. and Waters, Katrina M. and Bramer, Lisa M.},
  doi          = {10.3389/frai.2023.1098308},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1098308},
  shortjournal = {Front. Artif. Intell.},
  title        = {Missing data in multi-omics integration: Recent advances through artificial intelligence},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DeepAD: A deep learning application for predicting amyloid
standardized uptake value ratio through PET for alzheimer’s prognosis.
<em>FRAI</em>, <em>6</em>, 1091506. (<a
href="https://doi.org/10.3389/frai.2023.1091506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionAmyloid deposition is a vital biomarker in the process of Alzheimer&#39;s diagnosis. 18F-florbetapir PET scans can provide valuable imaging data to determine cortical amyloid quantities. However, the process is labor and doctor intensive, requiring extremely specialized education and resources that may not be accessible to everyone, making the amyloid calculation process inefficient. Deep learning is a rising tool in Alzheimer&#39;s research which could be used to determine amyloid deposition.Materials and methodsUsing data from the Alzheimer&#39;s Disease Neuroimaging Initiative, we identified 2,980 patients with PET imaging, clinical, and genetic data. We tested various ResNet, EfficientNet, and RegNet convolutional neural networks and later combined the best performing model with Gradient Boosting Decision Tree algorithms to predict standardized uptake value ratio (SUVR) of amyloid in each patient session. We tried several configurations to find the best model tuning for regression-to-SUVR.ResultsWe found that the RegNet X064 architecture combined with a grid search-tuned Gradient Boosting Decision Tree with 3 axial input slices and clinical and genetic data achieved the lowest loss. Using the mean-absolute-error metric, the loss converged to an MAE of 0.0441, equating to 96.4% accuracy across the 596-patient test set.DiscussionWe showed that this method is more consistent and accessible in comparison to human readers from previous studies, with lower margins of error and substantially faster calculation times. We implemented our deep learning model on to a web application named DeepAD which allows our diagnostic tool to be accessible. DeepAD could be used in hospitals and clinics with resource limitations for amyloid deposition and shows promise for more imaging tasks as well.},
  archive      = {J_FRAI},
  author       = {Maddury, Sucheer and Desai, Krish},
  doi          = {10.3389/frai.2023.1091506},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1091506},
  shortjournal = {Front. Artif. Intell.},
  title        = {DeepAD: A deep learning application for predicting amyloid standardized uptake value ratio through PET for alzheimer&#39;s prognosis},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Infant food users’ perceptions of safety: A web-based
analysis approach. <em>FRAI</em>, <em>6</em>, 1080950. (<a
href="https://doi.org/10.3389/frai.2023.1080950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to explore consumer beliefs about health hazards in infant foods by analyzing data gathered from the web, focusing on forums for parents in the UK. After selecting a subset of posts and classifying them by topic, according to the food product discussed and the health hazard discussed, two types of analyses were performed. Pearson correlation of term-occurrences highlighted what hazard-product pairs are most prevalent. Ordinary Least Squares (OLS) regression performed on sentiment measures generated from the texts provided significant results indicating positive or negative sentiment, objective or subjective language, and confident or unconfident modality associated with different food products and health hazards. The results allow comparison between perceptions obtained in different countries in Europe and may lead to recommendations concerning information and communication priorities.},
  archive      = {J_FRAI},
  author       = {Aline, Sherman and Hubert, Gilles and Pitarch, Yoann and Thomopoulos, Rallou},
  doi          = {10.3389/frai.2023.1080950},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1080950},
  shortjournal = {Front. Artif. Intell.},
  title        = {Infant food users&#39; perceptions of safety: A web-based analysis approach},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving text mining in plant health domain with GAN and/or
pre-trained language model. <em>FRAI</em>, <em>6</em>, 1072329. (<a
href="https://doi.org/10.3389/frai.2023.1072329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Bidirectional Encoder Representations from Transformers (BERT) architecture offers a cutting-edge approach to Natural Language Processing. It involves two steps: 1) pre-training a language model to extract contextualized features and 2) fine-tuning for specific downstream tasks. Although pre-trained language models (PLMs) have been successful in various text-mining applications, challenges remain, particularly in areas with limited labeled data such as plant health hazard detection from individuals&#39; observations. To address this challenge, we propose to combine GAN-BERT, a model that extends the fine-tuning process with unlabeled data through a Generative Adversarial Network (GAN), with ChouBERT, a domain-specific PLM. Our results show that GAN-BERT outperforms traditional fine-tuning in multiple text classification tasks. In this paper, we examine the impact of further pre-training on the GAN-BERT model. We experiment with different hyper parameters to determine the best combination of models and fine-tuning parameters. Our findings suggest that the combination of GAN and ChouBERT can enhance the generalizability of the text classifier but may also lead to increased instability during training. Finally, we provide recommendations to mitigate these instabilities.},
  archive      = {J_FRAI},
  author       = {Jiang, Shufan and Cormier, Stéphane and Angarita, Rafael and Rousseaux, Francis},
  doi          = {10.3389/frai.2023.1072329},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1072329},
  shortjournal = {Front. Artif. Intell.},
  title        = {Improving text mining in plant health domain with GAN and/or pre-trained language model},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Argument-based human–AI collaboration for supporting
behavior change to improve health. <em>FRAI</em>, <em>6</em>, 1069455.
(<a href="https://doi.org/10.3389/frai.2023.1069455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an empirical requirement elicitation study for an argumentation-based digital companion for supporting behavior change, whose ultimate goal is the promotion and facilitation of healthy behavior. The study was conducted with non-expert users as well as with health experts and was in part supported by the development of prototypes. It focuses on human-centric aspects, in particular user motivations, as well as on expectations and perceptions regarding the role and interaction behavior of a digital companion. Based on the results of the study, a framework for person tailoring the agent&#39;s roles and behaviors, and argumentation schemes are proposed. The results indicate that the extent to which a digital companion argumentatively challenges or supports a user&#39;s attitudes and chosen behavior and how assertive and provocative the companion is may have a substantial and individualized effect on user acceptance, as well as on the effects of interacting with the digital companion. More broadly, the results shed some initial light on the perception of users and domain experts of “soft,” meta-level aspects of argumentative dialogue, indicating potential for future research.},
  archive      = {J_FRAI},
  author       = {Kilic, Kaan and Weck, Saskia and Kampik, Timotheus and Lindgren, Helena},
  doi          = {10.3389/frai.2023.1069455},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1069455},
  shortjournal = {Front. Artif. Intell.},
  title        = {Argument-based human–AI collaboration for supporting behavior change to improve health},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Leveraging explanations in interactive machine learning: An
overview. <em>FRAI</em>, <em>6</em>, 1066049. (<a
href="https://doi.org/10.3389/frai.2023.1066049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explanations have gained an increasing level of interest in the AI and Machine Learning (ML) communities in order to improve model transparency and allow users to form a mental model of a trained ML model. However, explanations can go beyond this one way communication as a mechanism to elicit user control, because once users understand, they can then provide feedback. The goal of this paper is to present an overview of research where explanations are combined with interactive capabilities as a mean to learn new models from scratch and to edit and debug existing ones. To this end, we draw a conceptual map of the state-of-the-art, grouping relevant approaches based on their intended purpose and on how they structure the interaction, highlighting similarities and differences between them. We also discuss open research issues and outline possible directions forward, with the hope of spurring further research on this blooming research topic.},
  archive      = {J_FRAI},
  author       = {Teso, Stefano and Alkan, Öznur and Stammer, Wolfgang and Daly, Elizabeth},
  doi          = {10.3389/frai.2023.1066049},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1066049},
  shortjournal = {Front. Artif. Intell.},
  title        = {Leveraging explanations in interactive machine learning: An overview},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised domain adaptation for the detection of
cardiomegaly in cross-domain chest x-ray images. <em>FRAI</em>,
<em>6</em>, 1056422. (<a
href="https://doi.org/10.3389/frai.2023.1056422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, several deep learning approaches have been successfully applied in the field of medical image analysis. More specifically, different deep neural network architectures have been proposed and assessed for the detection of various pathologies based on chest X-ray images. While the performed assessments have shown very promising results, most of them consist in training and evaluating the performance of the proposed approaches on a single data set. However, the generalization of such models is quite limited in a cross-domain setting, since a significant performance degradation can be observed when these models are evaluated on data sets stemming from different medical centers or recorded under different protocols. The performance degradation is mostly caused by the domain shift between the training set and the evaluation set. To alleviate this problem, different unsupervised domain adaptation approaches are proposed and evaluated in the current work, for the detection of cardiomegaly based on chest X-ray images, in a cross-domain setting. The proposed approaches generate domain invariant feature representations by adapting the parameters of a model optimized on a large set of labeled samples, to a set of unlabeled images stemming from a different data set. The performed evaluation points to the effectiveness of the proposed approaches, since the adapted models outperform optimized models which are directly applied to the evaluation sets without any form of domain adaptation.},
  archive      = {J_FRAI},
  author       = {Thiam, Patrick and Lausser, Ludwig and Kloth, Christopher and Blaich, Daniel and Liebold, Andreas and Beer, Meinrad and Kestler, Hans A.},
  doi          = {10.3389/frai.2023.1056422},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1056422},
  shortjournal = {Front. Artif. Intell.},
  title        = {Unsupervised domain adaptation for the detection of cardiomegaly in cross-domain chest X-ray images},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning private equity recommitment strategies for
institutional investors. <em>FRAI</em>, <em>6</em>, 1014317. (<a
href="https://doi.org/10.3389/frai.2023.1014317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Keeping strategic allocations at target level to maintain high exposure to private equity is a complex but essential task for investors who need to balance against the risk of default. Illiquidity and cashflow uncertainty are critical challenges especially when commitments are irrevocable. In this work, we propose to use a trustworthy and explainable A.I. approach to design recommitment strategies. Using intensive portfolios simulations and evolutionary computing, we show that efficient and dynamic recommitment strategies can be brought forth automatically.},
  archive      = {J_FRAI},
  author       = {Kieffer, Emmanuel and Meyer, Thomas and Gloukoviezoff, Georges and Lucius, Hakan and Bouvry, Pascal},
  doi          = {10.3389/frai.2023.1014317},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1014317},
  shortjournal = {Front. Artif. Intell.},
  title        = {Learning private equity recommitment strategies for institutional investors},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Culture intelligent workflow, structure, and steps.
<em>FRAI</em>, <em>6</em>, 985469. (<a
href="https://doi.org/10.3389/frai.2023.985469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionTechnologies abstract intelligence and provide predictor and precision insight in workflows that manage disorders, similar to cardiology and hematological disease. Positive perceptions of Artificial Intelligence (AI) that support Machine Learning (ML) and Deep Learning (DL) manage transformations with a safe system that improves wellbeing. In sections, workflow introduces an eXamination (X = AI) as an end-to-end structure to culture workstreams in a step-by-step design to manage populace health in a governed system.MethodTo better healthcare outcomes, communities and personnel benefit from an explanation and an interpretive that elucidates workflow for citizens or practitioners to comprehend personalized platforms. Therefore, the author undertook structure and practice reviews and appraised perspectives that impact the management of AI in public health and medicine.ResultsFigures for the management of AI workflow illustrate and inform on the model, structure, culture, assurance, process steps, values, and governance required for abstract insights in public health and medicine. The papers&#39; end-to-end structure with explanans in a work culture interprets the step-by-step designs that manage the success of AI. Personalized care graphics offer an explanandum in the management of biological analytic value.DiscussionHealthcare leadership collaboratives plan population health with an upstream, workplace and workstream format. Secure workflow and safety wellbeing system requirements prove that genomics and AI improve medicine. Therefore, the paper discusses group understanding of current practice, ethics, policy, and legality.Conclusion“Culture, intelligent workflow, structure, and steps” improve wellbeing with personalized care and align a percept for national opportunities, regional control, and local needs. Personalized practice cultures support analytic systems to describe, predict, precision, and prescript medicine in population health management eXaminations.},
  archive      = {J_FRAI},
  author       = {Henry, James Andrew},
  doi          = {10.3389/frai.2023.985469},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {985469},
  shortjournal = {Front. Artif. Intell.},
  title        = {Culture intelligent workflow, structure, and steps},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rough-set based learning: Assessing patterns and
predictability of anxiety, depression, and sleep scores associated with
the use of cannabinoid-based medicine during COVID-19. <em>FRAI</em>,
<em>6</em>, 981953. (<a
href="https://doi.org/10.3389/frai.2023.981953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, research is emerging highlighting the potential of cannabinoids&#39; beneficial effects related to anxiety, mood, and sleep disorders as well as pointing to an increased use of cannabinoid-based medicines since COVID-19 was declared a pandemic. The objective of this research is 3 fold: i) to evaluate the relationship of the clinical delivery of cannabinoid-based medicine for anxiety, depression and sleep scores by utilizing machine learning specifically rough set methods; ii) to discover patterns based on patient features such as specific cannabinoid recommendations, diagnosis information, decreasing/increasing levels of clinical assessment tools (CAT) scores over a period of time; and iii) to predict whether new patients could potentially experience either an increase or decrease in CAT scores. The dataset for this study was derived from patient visits to Ekosi Health Centres, Canada over a 2 year period including the COVID timeline. Extensive pre-processing and feature engineering was performed. A class feature indicative of their progress or lack thereof due to the treatment received was introduced. Six Rough/Fuzzy-Rough classifiers as well as Random Forest and RIPPER classifiers were trained on the patient dataset using a 10-fold stratified CV method. The highest overall accuracy, sensitivity and specificity measures of over 99% was obtained using the rule-based rough-set learning model. In this study, we have identified rough-set based machine learning model with high accuracy that could be utilized for future studies regarding cannabinoids and precision medicine.},
  archive      = {J_FRAI},
  author       = {Ramanna, Sheela and Ashrafi, Negin and Loster, Evan and Debroni, Karen and Turner, Shelley},
  doi          = {10.3389/frai.2023.981953},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {981953},
  shortjournal = {Front. Artif. Intell.},
  title        = {Rough-set based learning: Assessing patterns and predictability of anxiety, depression, and sleep scores associated with the use of cannabinoid-based medicine during COVID-19},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human-centricity in AI governance: A systemic approach.
<em>FRAI</em>, <em>6</em>, 976887. (<a
href="https://doi.org/10.3389/frai.2023.976887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-centricity is considered a central aspect in the development and governance of artificial intelligence (AI). Various strategies and guidelines highlight the concept as a key goal. However, we argue that current uses of Human-Centered AI (HCAI) in policy documents and AI strategies risk downplaying promises of creating desirable, emancipatory technology that promotes human wellbeing and the common good. Firstly, HCAI, as it appears in policy discourses, is the result of aiming to adapt the concept of human-centered design (HCD) to the public governance context of AI but without proper reflection on how it should be reformed to suit the new task environment. Second, the concept is mainly used in reference to realizing human and fundamental rights, which are necessary, but not sufficient for technological emancipation. Third, the concept is used ambiguously in policy and strategy discourses, making it unclear how it should be operationalized in governance practices. This article explores means and approaches for using the HCAI approach for technological emancipation in the context of public AI governance. We propose that the potential for emancipatory technology development rests on expanding the traditional user-centered view of technology design to involve community- and society-centered perspectives in public governance. Developing public AI governance in this way relies on enabling inclusive governance modalities that enhance the social sustainability of AI deployment. We discuss mutual trust, transparency, communication, and civic tech as key prerequisites for socially sustainable and human-centered public AI governance. Finally, the article introduces a systemic approach to ethically and socially sustainable, human-centered AI development and deployment.},
  archive      = {J_FRAI},
  author       = {Sigfrids, Anton and Leikas, Jaana and Salo-Pöntinen, Henrikki and Koskimies, Emmi},
  doi          = {10.3389/frai.2023.976887},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {976887},
  shortjournal = {Front. Artif. Intell.},
  title        = {Human-centricity in AI governance: A systemic approach},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated detection of dolphin whistles with convolutional
networks and transfer learning. <em>FRAI</em>, <em>6</em>, 1099022. (<a
href="https://doi.org/10.3389/frai.2023.1099022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective conservation of maritime environments and wildlife management of endangered species require the implementation of efficient, accurate and scalable solutions for environmental monitoring. Ecoacoustics offers the advantages of non-invasive, long-duration sampling of environmental sounds and has the potential to become the reference tool for biodiversity surveying. However, the analysis and interpretation of acoustic data is a time-consuming process that often requires a great amount of human supervision. This issue might be tackled by exploiting modern techniques for automatic audio signal analysis, which have recently achieved impressive performance thanks to the advances in deep learning research. In this paper we show that convolutional neural networks can indeed significantly outperform traditional automatic methods in a challenging detection task: identification of dolphin whistles from underwater audio recordings. The proposed system can detect signals even in the presence of ambient noise, at the same time consistently reducing the likelihood of producing false positives and false negatives. Our results further support the adoption of artificial intelligence technology to improve the automatic monitoring of marine ecosystems.},
  archive      = {J_FRAI},
  author       = {Nur Korkmaz, Burla and Diamant, Roee and Danino, Gil and Testolin, Alberto},
  doi          = {10.3389/frai.2023.1099022},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1099022},
  shortjournal = {Front. Artif. Intell.},
  title        = {Automated detection of dolphin whistles with convolutional networks and transfer learning},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). How to train a self-driving vehicle: On the added value (or
lack thereof) of curriculum learning and replay buffers. <em>FRAI</em>,
<em>6</em>, 1098982. (<a
href="https://doi.org/10.3389/frai.2023.1098982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from only real-world collected data can be unrealistic and time consuming in many scenario. One alternative is to use synthetic data as learning environments to learn rare situations and replay buffers to speed up the learning. In this work, we examine the hypothesis of how the creation of the environment affects the training of reinforcement learning agent through auto-generated environment mechanisms. We take the autonomous vehicle as an application. We compare the effect of two approaches to generate training data for artificial cognitive agents. We consider the added value of curriculum learning—just as in human learning—as a way to structure novel training data that the agent has not seen before as well as that of using a replay buffer to train further on data the agent has seen before. In other words, the focus of this paper is on characteristics of the training data rather than on learning algorithms. We therefore use two tasks that are commonly trained early on in autonomous vehicle research: lane keeping and pedestrian avoidance. Our main results show that curriculum learning indeed offers an additional benefit over a vanilla reinforcement learning approach (using Deep-Q Learning), but the replay buffer actually has a detrimental effect in most (but not all) combinations of data generation approaches we considered here. The benefit of curriculum learning does depend on the existence of a well-defined difficulty metric with which various training scenarios can be ordered. In the lane-keeping task, we can define it as a function of the curvature of the road, in which the steeper and more occurring curves on the road, the more difficult it gets. Defining such a difficulty metric in other scenarios is not always trivial. In general, the results of this paper emphasize both the importance of considering data characterization, such as curriculum learning, and the importance of defining an appropriate metric for the task.},
  archive      = {J_FRAI},
  author       = {Mahmoud, Sara and Billing, Erik and Svensson, Henrik and Thill, Serge},
  doi          = {10.3389/frai.2023.1098982},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1098982},
  shortjournal = {Front. Artif. Intell.},
  title        = {How to train a self-driving vehicle: On the added value (or lack thereof) of curriculum learning and replay buffers},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Grounding human-object interaction to affordance behavior in
multimodal datasets. <em>FRAI</em>, <em>6</em>, 1084740. (<a
href="https://doi.org/10.3389/frai.2023.1084740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While affordance detection and Human-Object interaction (HOI) detection tasks are related, the theoretical foundation of affordances makes it clear that the two are distinct. In particular, researchers in affordances make distinctions between J. J. Gibson&#39;s traditional definition of an affordance, “the action possibilities” of the object within the environment, and the definition of a telic affordance, or one defined by conventionalized purpose or use. We augment the HICO-DET dataset with annotations for Gibsonian and telic affordances and a subset of the dataset with annotations for the orientation of the humans and objects involved. We then train an adapted Human-Object Interaction (HOI) model and evaluate a pre-trained viewpoint estimation system on this augmented dataset. Our model, AffordanceUPT, is based on a two-stage adaptation of the Unary-Pairwise Transformer (UPT), which we modularize to make affordance detection independent of object detection. Our approach exhibits generalization to new objects and actions, can effectively make the Gibsonian/telic distinction, and shows that this distinction is correlated with features in the data that are not captured by the HOI annotations of the HICO-DET dataset.},
  archive      = {J_FRAI},
  author       = {Henlein, Alexander and Gopinath, Anju and Krishnaswamy, Nikhil and Mehler, Alexander and Pustejovsky, James},
  doi          = {10.3389/frai.2023.1084740},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1084740},
  shortjournal = {Front. Artif. Intell.},
  title        = {Grounding human-object interaction to affordance behavior in multimodal datasets},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Conditional autoencoder pre-training and optimization
algorithms for personalized care of hemophiliac patients. <em>FRAI</em>,
<em>6</em>, 1048010. (<a
href="https://doi.org/10.3389/frai.2023.1048010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the use of deep conditional autoencoder to predict the effect of treatments for patients suffering from hemophiliac disorders. Conditional autoencoder is a semi-supervised model that learns an abstract representation of the data and provides conditional reconstruction capabilities. Such models are suited to problems with limited and/or partially observable data, common situation for data in medicine. Deep conditional autoencoders allow the representation of highly non-linear functions which makes them promising candidates. However, the optimization of parameters and hyperparameters is particularly complex. For parameter optimization, the classical approach of random initialization of weight matrices works well in the case of simple architectures, but is not feasible for deep architectures. For hyperparameter optimization of deep architectures, the classical cross-validation method is costly. In this article, we propose solutions using a conditional pre-training algorithm and incremental optimization strategies. Such solutions reduce the variance of the estimation process and enhances convergence of the learning algorithm. Our proposal is applied for personalized care of hemophiliac patients. Results show better performances than generative adversarial networks (baseline) and highlight the benefits of your contribution to predict the effect of treatments for patients.},
  archive      = {J_FRAI},
  author       = {Buche, Cédric and Lasson, François and Kerdelo, Sébastien},
  doi          = {10.3389/frai.2023.1048010},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1048010},
  shortjournal = {Front. Artif. Intell.},
  title        = {Conditional autoencoder pre-training and optimization algorithms for personalized care of hemophiliac patients},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application of the symbolic regression program AI-feynman to
psychology. <em>FRAI</em>, <em>6</em>, 1039438. (<a
href="https://doi.org/10.3389/frai.2023.1039438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The discovery of hidden laws in data is the core challenge in many fields, from the natural sciences to the social sciences. However, this task has historically relied on human intuition and experience in many areas, including psychology. Therefore, discovering laws using artificial intelligence (AI) has two significant advantages. First, it makes it possible to detect laws that humans cannot discover. Second, it will help construct more accurate theories. An AI called AI-Feynman was released in a very different field, and it performed impressively. Although AI-Feynman was initially designed to discover laws in physics, it can also work well in psychology. This research aims to examine whether AI-Feynman can be a new data analysis method for inter-temporal choice experiments by testing whether it can discover the hyperbolic discount model as a discount function. An inter-temporal choice experiment was conducted to accomplish these objectives, and the data were input into AI-Feynman. As a result, seven discount function candidates were proposed by AI-Feynman. One candidate was the hyperbolic discount model, which is currently considered the most accurate. The three functions of the root-mean-squared errors were superior to the hyperbolic discount model. Moreover, one of the three candidates was more “hyperbolic” than the standard hyperbolic discount function. These results indicate two things. One is that AI-Feynman can be a new data analysis method for inter-temporal choice experiments. The other is that AI-Feynman can discover discount functions that humans cannot find.},
  archive      = {J_FRAI},
  author       = {Miyazaki, Masato and Ishikawa, Ken-Ichi and Nakashima, Ken&#39;ichiro and Shimizu, Hiroshi and Takahashi, Taiki and Takahashi, Nobuyuki},
  doi          = {10.3389/frai.2023.1039438},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1039438},
  shortjournal = {Front. Artif. Intell.},
  title        = {Application of the symbolic regression program AI-feynman to psychology},
  volume       = {6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on detecting healthcare concept drift in AI/ML
models from a finance perspective. <em>FRAI</em>, <em>5</em>, 955314.
(<a href="https://doi.org/10.3389/frai.2022.955314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data is incredibly significant in today&#39;s digital age because data represents facts and numbers from our regular life transactions. Data is no longer arriving in a static form; it is now arriving in a streaming fashion. Data streams are the arrival of limitless, continuous, and rapid data. The healthcare industry is a major generator of data streams. Processing data streams is extremely complex due to factors such as volume, pace, and variety. Data stream classification is difficult owing to idea drift. Concept drift occurs in supervised learning when the statistical properties of the target variable that the model predicts change unexpectedly. We focused on solving various forms of concept drift problems in healthcare data streams in this research, and we outlined the existing statistical and machine learning methodologies for dealing with concept drift. It also emphasizes the use of deep learning algorithms for concept drift detection and describes the various healthcare datasets utilized for concept drift detection in data stream categorization.},
  archive      = {J_FRAI},
  author       = {M. S., Abdul Razak and C. R., Nirmala and B. R., Sreenivasa and Lahza, Husam and Lahza, Hassan Fareed M.},
  doi          = {10.3389/frai.2022.955314},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {955314},
  shortjournal = {Front. Artif. Intell.},
  title        = {A survey on detecting healthcare concept drift in AI/ML models from a finance perspective},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Configural relations in humans and deep convolutional neural
networks. <em>FRAI</em>, <em>5</em>, 961595. (<a
href="https://doi.org/10.3389/frai.2022.961595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolutional neural networks (DCNNs) have attracted considerable interest as useful devices and as possible windows into understanding perception and cognition in biological systems. In earlier work, we showed that DCNNs differ dramatically from human perceivers in that they have no sensitivity to global object shape. Here, we investigated whether those findings are symptomatic of broader limitations of DCNNs regarding the use of relations. We tested learning and generalization of DCNNs (AlexNet and ResNet-50) for several relations involving objects. One involved classifying two shapes in an otherwise empty field as same or different. Another involved enclosure. Every display contained a closed figure among contour noise fragments and one dot; correct responding depended on whether the dot was inside or outside the figure. The third relation we tested involved a classification that depended on which of two polygons had more sides. One polygon always contained a dot, and correct classification of each display depended on whether the polygon with the dot had a greater number of sides. We used DCNNs that had been trained on the ImageNet database, and we used both restricted and unrestricted transfer learning (connection weights at all layers could change with training). For the same-different experiment, there was little restricted transfer learning (82.2%). Generalization tests showed near chance performance for new shapes. Results for enclosure were at chance for restricted transfer learning and somewhat better for unrestricted (74%). Generalization with two new kinds of shapes showed reduced but above-chance performance (≈66%). Follow-up studies indicated that the networks did not access the enclosure relation in their responses. For the relation of more or fewer sides of polygons, DCNNs showed successful learning with polygons having 3–5 sides under unrestricted transfer learning, but showed chance performance in generalization tests with polygons having 6–10 sides. Experiments with human observers showed learning from relatively few examples of all of the relations tested and complete generalization of relational learning to new stimuli. These results using several different relations suggest that DCNNs have crucial limitations that derive from their lack of computations involving abstraction and relational processing of the sort that are fundamental in human perception.},
  archive      = {J_FRAI},
  author       = {Baker, Nicholas and Garrigan, Patrick and Phillips, Austin and Kellman, Philip J.},
  doi          = {10.3389/frai.2022.961595},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {961595},
  shortjournal = {Front. Artif. Intell.},
  title        = {Configural relations in humans and deep convolutional neural networks},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Qluster: An easy-to-implement generic workflow for robust
clustering of health data. <em>FRAI</em>, <em>5</em>, 1055294. (<a
href="https://doi.org/10.3389/frai.2022.1055294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exploration of heath data by clustering algorithms allows to better describe the populations of interest by seeking the sub-profiles that compose it. This therefore reinforces medical knowledge, whether it is about a disease or a targeted population in real life. Nevertheless, contrary to the so-called conventional biostatistical methods where numerous guidelines exist, the standardization of data science approaches in clinical research remains a little discussed subject. This results in a significant variability in the execution of data science projects, whether in terms of algorithms used, reliability and credibility of the designed approach. Taking the path of parsimonious and judicious choice of both algorithms and implementations at each stage, this article proposes Qluster, a practical workflow for performing clustering tasks. Indeed, this workflow makes a compromise between (1) genericity of applications (e.g. usable on small or big data, on continuous, categorical or mixed variables, on database of high-dimensionality or not), (2) ease of implementation (need for few packages, few algorithms, few parameters, ...), and (3) robustness (e.g. use of proven algorithms and robust packages, evaluation of the stability of clusters, management of noise and multicollinearity). This workflow can be easily automated and/or routinely applied on a wide range of clustering projects. It can be useful both for data scientists with little experience in the field to make data clustering easier and more robust, and for more experienced data scientists who are looking for a straightforward and reliable solution to routinely perform preliminary data mining. A synthesis of the literature on data clustering as well as the scientific rationale supporting the proposed workflow is also provided. Finally, a detailed application of the workflow on a concrete use case is provided, along with a practical discussion for data scientists. An implementation on the Dataiku platform is available upon request to the authors.},
  archive      = {J_FRAI},
  author       = {Esnault, Cyril and Rollot, Melissa and Guilmin, Pauline and Zucker, Jean-Daniel},
  doi          = {10.3389/frai.2022.1055294},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1055294},
  shortjournal = {Front. Artif. Intell.},
  title        = {Qluster: An easy-to-implement generic workflow for robust clustering of health data},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). How systemic cognition enables epistemic engineering.
<em>FRAI</em>, <em>5</em>, 960384. (<a
href="https://doi.org/10.3389/frai.2022.960384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epistemic engineering arises as systems and their parts develop functionality that is construed as valid knowledge. By hypothesis, epistemic engineering is a basic evolutionary principle. It ensures that not only living systems identify the differences that make differences but also ensure that distributed control enables them to construct epistemic change. In tracking such outcomes in human life, we stress that humans act within poly-centered, distributed systems. Similar to how people can act as inert parts of a system, they also actively bring forth intents and vicariant effects. Human cognitive agents use the systemic function to construct epistemic novelties. In the illustration, we used a published experimental study of a cyborg cockroach to consider how an evoneered system enables a human subject to perform as an adaptor with some “thought control” over the animal. Within a wide system, brains enable the techniques to arise ex novo as they attune to the dictates of a device. Human parts act as adaptors that simplify the task. In scaling up, we turn to a case of organizational cognition. We track how adaptor functions spread when drone-based data are brought to the maintenance department of a Danish utility company. While pivoting on how system operators combine experience with the use of software, their expertise sets off epistemically engineered results across the company and beyond. Vicariant effects emerge under the poly-centered control of brains, persons, equipment, and institutional wholes. As a part of culture, epistemic engineering works by reducing entropy.},
  archive      = {J_FRAI},
  author       = {Cowley, Stephen J. and Gahrn-Andersen, Rasmus},
  doi          = {10.3389/frai.2022.960384},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {960384},
  shortjournal = {Front. Artif. Intell.},
  title        = {How systemic cognition enables epistemic engineering},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic classification of signal regions in 1H nuclear
magnetic resonance spectra. <em>FRAI</em>, <em>5</em>, 1116416. (<a
href="https://doi.org/10.3389/frai.2022.1116416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification and characterization of signal regions in Nuclear Magnetic Resonance (NMR) spectra is a challenging but crucial phase in the analysis and determination of complex chemical compounds. Here, we present a novel supervised deep learning approach to perform automatic detection and classification of multiplets in 1H NMR spectra. Our deep neural network was trained on a large number of synthetic spectra, with complete control over the features represented in the samples. We show that our model can detect signal regions effectively and minimize classification errors between different types of resonance patterns. We demonstrate that the network generalizes remarkably well on real experimental 1H NMR spectra.},
  archive      = {J_FRAI},
  author       = {Fischetti, Giulia and Schmid, Nicolas and Bruderer, Simon and Caldarelli, Guido and Scarso, Alessandro and Henrici, Andreas and Wilhelm, Dirk},
  doi          = {10.3389/frai.2022.1116416},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1116416},
  shortjournal = {Front. Artif. Intell.},
  title        = {Automatic classification of signal regions in 1H nuclear magnetic resonance spectra},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Three levels at which the user’s cognition can be
represented in artificial intelligence. <em>FRAI</em>, <em>5</em>,
1092053. (<a href="https://doi.org/10.3389/frai.2022.1092053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) plays an important role in modern society. AI applications are omnipresent and assist many decisions we make in daily life. A common and important feature of such AI applications are user models. These models allow an AI application to adapt to a specific user. Here, we argue that user models in AI can be optimized by modeling these user models more closely to models of human cognition. We identify three levels at which insights from human cognition can be—and have been—integrated in user models. Such integration can be very loose with user models only being inspired by general knowledge of human cognition or very tight with user models implementing specific cognitive processes. Using AI-based applications in the context of education as a case study, we demonstrate that user models that are more deeply rooted in models of cognition offer more valid and more fine-grained adaptations to an individual user. We propose that such user models can also advance the development of explainable AI.},
  archive      = {J_FRAI},
  author       = {Liefooghe, Baptist and van Maanen, Leendert},
  doi          = {10.3389/frai.2022.1092053},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1092053},
  shortjournal = {Front. Artif. Intell.},
  title        = {Three levels at which the user&#39;s cognition can be represented in artificial intelligence},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Image based deep learning in 12-lead ECG diagnosis.
<em>FRAI</em>, <em>5</em>, 1087370. (<a
href="https://doi.org/10.3389/frai.2022.1087370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundThe electrocardiogram is an integral tool in the diagnosis of cardiovascular disease. Most studies on machine learning classification of electrocardiogram (ECG) diagnoses focus on processing raw signal data rather than ECG images. This presents a challenge for models in many areas of clinical practice where ECGs are printed on paper or only digital images are accessible, especially in remote and regional settings. This study aims to evaluate the accuracy of image based deep learning algorithms on 12-lead ECG diagnosis.MethodsDeep learning models using VGG architecture were trained on various 12-lead ECG datasets and evaluated for accuracy by testing on holdout test data as well as data from datasets not seen in training. Grad-CAM was utilized to depict heatmaps of diagnosis.ResultsThe results demonstrated excellent AUROC, AUPRC, sensitivity and specificity on holdout test data from datasets used in training comparable to the best signal and image-based models. Detection of hidden characteristics such as gender were achieved at a high rate while Grad-CAM successfully highlight pertinent features on ECGs traditionally used by human interpreters.DiscussionThis study demonstrates feasibility of image based deep learning algorithms in ECG diagnosis and identifies directions for future research in order to develop clinically applicable image based deep-learning models in ECG diagnosis.},
  archive      = {J_FRAI},
  author       = {Ao, Raymond and He, George},
  doi          = {10.3389/frai.2022.1087370},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1087370},
  shortjournal = {Front. Artif. Intell.},
  title        = {Image based deep learning in 12-lead ECG diagnosis},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Trends in EEG signal feature extraction applications.
<em>FRAI</em>, <em>5</em>, 1072801. (<a
href="https://doi.org/10.3389/frai.2022.1072801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper will focus on electroencephalogram (EEG) signal analysis with an emphasis on common feature extraction techniques mentioned in the research literature, as well as a variety of applications that this can be applied to. In this review, we cover single and multi-dimensional EEG signal processing and feature extraction techniques in the time domain, frequency domain, decomposition domain, time-frequency domain, and spatial domain. We also provide pseudocode for the methods discussed so that they can be replicated by practitioners and researchers in their specific areas of biomedical work. Furthermore, we discuss artificial intelligence applications such as assistive technology, neurological disease classification, brain-computer interface systems, as well as their machine learning integration counterparts, to complete the overall pipeline design for EEG signal analysis. Finally, we discuss future work that can be innovated in the feature extraction domain for EEG signal analysis.},
  archive      = {J_FRAI},
  author       = {Singh, Anupreet Kaur and Krishnan, Sridhar},
  doi          = {10.3389/frai.2022.1072801},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1072801},
  shortjournal = {Front. Artif. Intell.},
  title        = {Trends in EEG signal feature extraction applications},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Isolated single sound lip-reading using a frame-based camera
and event-based camera. <em>FRAI</em>, <em>5</em>, 1070964. (<a
href="https://doi.org/10.3389/frai.2022.1070964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unlike the conventional frame-based camera, the event-based camera detects changes in the brightness value for each pixel over time. This research work on lip-reading as a new application by the event-based camera. This paper proposes an event camera-based lip-reading for isolated single sound recognition. The proposed method consists of imaging from event data, face and facial feature points detection, and recognition using a Temporal Convolutional Network. Furthermore, this paper proposes a method that combines the two modalities of the frame-based camera and an event-based camera. In order to evaluate the proposed method, the utterance scenes of 15 Japanese consonants from 20 speakers were collected using an event-based camera and a video camera and constructed an original dataset. Several experiments were conducted by generating images at multiple frame rates from an event-based camera. As a result, the highest recognition accuracy was obtained in the image of the event-based camera at 60 fps. Moreover, it was confirmed that combining two modalities yields higher recognition accuracy than a single modality.},
  archive      = {J_FRAI},
  author       = {Kanamaru, Tatsuya and Arakane, Taiki and Saitoh, Takeshi},
  doi          = {10.3389/frai.2022.1070964},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1070964},
  shortjournal = {Front. Artif. Intell.},
  title        = {Isolated single sound lip-reading using a frame-based camera and event-based camera},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Zero-shot stance detection: Paradigms and challenges.
<em>FRAI</em>, <em>5</em>, 1070429. (<a
href="https://doi.org/10.3389/frai.2022.1070429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A major challenge in stance detection is the large (potentially infinite) and diverse set of stance topics. Collecting data for such a set is unrealistic due to both the expense of annotation and the continuous creation of new real-world topics (e.g., a new politician runs for office). Furthermore, stancetaking occurs in a wide range of languages and genres (e.g., Twitter, news articles). While zero-shot stance detection in English, where evaluation is on topics not seen during training, has received increasing attention, we argue that this attention should be expanded to multilingual and multi-genre settings. We discuss two paradigms for English zero-shot stance detection evaluation, as well as recent work in this area. We then discuss recent work on multilingual and multi-genre stance detection, which has focused primarily on non-zero-shot settings. We argue that this work should be expanded to multilingual and multi-genre zero-shot stance detection and propose best practices to systematize and stimulate future work in this direction. While domain adaptation techniques are well-suited for work in these settings, we argue that increased care should be taken to improve model explainability and to conduct robust evaluations, considering not only empirical generalization ability but also the understanding of complex language and inferences.},
  archive      = {J_FRAI},
  author       = {Allaway, Emily and McKeown, Kathleen},
  doi          = {10.3389/frai.2022.1070429},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1070429},
  shortjournal = {Front. Artif. Intell.},
  title        = {Zero-shot stance detection: Paradigms and challenges},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fake review identification and utility evaluation model
using machine learning. <em>FRAI</em>, <em>5</em>, 1064371. (<a
href="https://doi.org/10.3389/frai.2022.1064371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the structural growth of e-commerce platforms, the frequency of exchange of opinions and the number of online reviews of platform participants related to products are increasing. However, given the growth of fake reviews, the corresponding growth in the quality of online reviews seems to be slow, at best. The number of cases of harm to retailers and customers caused by malicious false reviews is steadily increasing every year. In this context, it is becoming difficult for users to determine useful reviews amid a flood of information. As a result, the intrinsic value of online reviews that reduce uncertainty in pre-purchase decisions is blurred, and e-commerce platforms are on the verge of losing credibility and traffic. Through this study, we intend to present solutions related to review filtering and classification by constructing a model for judging the authenticity and usefulness of online reviews using machine learning.},
  archive      = {J_FRAI},
  author       = {Choi, Wonil and Nam, Kyungmin and Park, Minwoo and Yang, Seoyi and Hwang, Sangyoon and Oh, Hayoung},
  doi          = {10.3389/frai.2022.1064371},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1064371},
  shortjournal = {Front. Artif. Intell.},
  title        = {Fake review identification and utility evaluation model using machine learning},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Statistical biopsy: An emerging screening approach for early
detection of cancers. <em>FRAI</em>, <em>5</em>, 1059093. (<a
href="https://doi.org/10.3389/frai.2022.1059093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite large investment cancer continues to be a major source of mortality and morbidity throughout the world. Traditional methods of detection and diagnosis such as biopsy and imaging, tend to be expensive and have risks of complications. As data becomes more abundant and machine learning continues advancing, it is natural to ask how they can help solve some of these problems. In this paper we show that using a person&#39;s personal health data it is possible to predict their risk for a wide variety of cancers. We dub this process a “statistical biopsy.” Specifically, we train two neural networks, one predicting risk for 16 different cancer types in females and the other predicting risk for 15 different cancer types in males. The networks were trained as binary classifiers identifying individuals that were diagnosed with the different cancer types within 5 years of joining the PLOC trial. However, rather than use the binary output of the classifiers we show that the continuous output can instead be used as a cancer risk allowing a holistic look at an individual&#39;s cancer risks. We tested our multi-cancer model on the UK Biobank dataset showing that for most cancers the predictions generalized well and that looking at multiple cancer risks at once from personal health data is a possibility. While the statistical biopsy will not be able to replace traditional biopsies for diagnosing cancers, we hope there can be a shift of paradigm in how statistical models are used in cancer detection moving to something more powerful and more personalized than general population screening guidelines.},
  archive      = {J_FRAI},
  author       = {Hart, Gregory R. and Yan, Vanessa and Nartowt, Bradley J. and Roffman, David A. and Stark, Gigi and Muhammad, Wazir and Deng, Jun},
  doi          = {10.3389/frai.2022.1059093},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1059093},
  shortjournal = {Front. Artif. Intell.},
  title        = {Statistical biopsy: An emerging screening approach for early detection of cancers},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Clinical concept recognition: Evaluation of existing systems
on EHRs. <em>FRAI</em>, <em>5</em>, 1051724. (<a
href="https://doi.org/10.3389/frai.2022.1051724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ObjectiveThe adoption of electronic health records (EHRs) has produced enormous amounts of data, creating research opportunities in clinical data sciences. Several concept recognition systems have been developed to facilitate clinical information extraction from these data. While studies exist that compare the performance of many concept recognition systems, they are typically developed internally and may be biased due to different internal implementations, parameters used, and limited number of systems included in the evaluations. The goal of this research is to evaluate the performance of existing systems to retrieve relevant clinical concepts from EHRs.MethodsWe investigated six concept recognition systems, including CLAMP, cTAKES, MetaMap, NCBO Annotator, QuickUMLS, and ScispaCy. Clinical concepts extracted included procedures, disorders, medications, and anatomical location. The system performance was evaluated on two datasets: the 2010 i2b2 and the MIMIC-III. Additionally, we assessed the performance of these systems in five challenging situations, including negation, severity, abbreviation, ambiguity, and misspelling.ResultsFor clinical concept extraction, CLAMP achieved the best performance on exact and inexact matching, with an F-score of 0.70 and 0.94, respectively, on i2b2; and 0.39 and 0.50, respectively, on MIMIC-III. Across the five challenging situations, ScispaCy excelled in extracting abbreviation information (F-score: 0.86) followed by NCBO Annotator (F-score: 0.79). CLAMP outperformed in extracting severity terms (F-score 0.73) followed by NCBO Annotator (F-score: 0.68). CLAMP outperformed other systems in extracting negated concepts (F-score 0.63).ConclusionsSeveral concept recognition systems exist to extract clinical information from unstructured data. This study provides an external evaluation by end-users of six commonly used systems across different extraction tasks. Our findings suggest that CLAMP provides the most comprehensive set of annotations for clinical concept extraction tasks and associated challenges. Comparing standard extraction tasks across systems provides guidance to other clinical researchers when selecting a concept recognition system relevant to their clinical information extraction task.},
  archive      = {J_FRAI},
  author       = {Lossio-Ventura, Juan Antonio and Sun, Ran and Boussard, Sebastien and Hernandez-Boussard, Tina},
  doi          = {10.3389/frai.2022.1051724},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1051724},
  shortjournal = {Front. Artif. Intell.},
  title        = {Clinical concept recognition: Evaluation of existing systems on EHRs},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A prospective evaluation of breast thermography enhanced by
a novel machine learning technique for screening breast abnormalities in
a general population of women presenting to a secondary care hospital.
<em>FRAI</em>, <em>5</em>, 1050803. (<a
href="https://doi.org/10.3389/frai.2022.1050803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ObjectiveArtificial intelligence-enhanced breast thermography is being evaluated as an ancillary modality in the evaluation of breast disease. The objective of this study was to evaluate the clinical performance of Thermalytix, a CE-marked, AI-based thermal imaging test, with respect to conventional mammography.MethodsA prospective, comparative study performed between 15 December 2018 and 06 January 2020 evaluated the performance of Thermalytix in 459 women with both dense and nondense breast tissue. Both symptomatic and asymptomatic women, aged 30–80 years, presenting to the hospital underwent Thermalytix followed by 2-D mammography and appropriate confirmatory investigations to confirm malignancy. The radiologist interpreting the mammograms and the technician using the Thermalytix tool were blinded to the others&#39; findings. The statistical analysis was performed by a third party.ResultsA total of 687 women were recruited, of whom 459 fulfilled the inclusion criteria. Twenty-one malignancies were detected (21/459, 4.6%). The overall sensitivity of Thermalytix was 95.24% (95% CI, 76.18–99.88), and the specificity was 88.58% (95% CI, 85.23–91.41). In women with dense breasts (n = 168, 36.6%), the sensitivity was 100% (95% CI, 69.15–100), and the specificity was 81.65% (95% CI, 74.72–87.35). Among these 168 women, 37 women (22%) were reported as BI-RADS 0 on mammography; in this subset, the sensitivity of Thermalytix was 100% (95% CI, 69.15–100), and the specificity was 77.22% (95% CI, 69.88–83.50).ConclusionThermalytix showed acceptable sensitivity and specificity with respect to mammography in the overall patient population. Thermalytix outperformed mammography in women with dense breasts and those reported as BI-RADS 0.},
  archive      = {J_FRAI},
  author       = {Bansal, Richa and Collison, Sathiakar and Krishnan, Lakshmi and Aggarwal, Bharat and Vidyasagar, Mathukumalli and Kakileti, Siva Teja and Manjunath, Geetha},
  doi          = {10.3389/frai.2022.1050803},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1050803},
  shortjournal = {Front. Artif. Intell.},
  title        = {A prospective evaluation of breast thermography enhanced by a novel machine learning technique for screening breast abnormalities in a general population of women presenting to a secondary care hospital},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Crop genomic selection with deep learning and environmental
data: A survey. <em>FRAI</em>, <em>5</em>, 1040295. (<a
href="https://doi.org/10.3389/frai.2022.1040295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning techniques for crop genomic selections, especially for single-environment plants, are well-developed. These machine learning models, which use dense genome-wide markers to predict phenotype, routinely perform well on single-environment datasets, especially for complex traits affected by multiple markers. On the other hand, machine learning models for predicting crop phenotype, especially deep learning models, using datasets that span different environmental conditions, have only recently emerged. Models that can accept heterogeneous data sources, such as temperature, soil conditions and precipitation, are natural choices for modeling GxE in multi-environment prediction. Here, we review emerging deep learning techniques that incorporate environmental data directly into genomic selection models.},
  archive      = {J_FRAI},
  author       = {Jubair, Sheikh and Domaratzki, Mike},
  doi          = {10.3389/frai.2022.1040295},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1040295},
  shortjournal = {Front. Artif. Intell.},
  title        = {Crop genomic selection with deep learning and environmental data: A survey},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Speech phoneme and spectral smearing based non-invasive
COVID-19 detection. <em>FRAI</em>, <em>5</em>, 1035805. (<a
href="https://doi.org/10.3389/frai.2022.1035805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 is a deadly viral infection that mainly affects the nasopharyngeal and oropharyngeal cavities before the lung in the human body. Early detection followed by immediate treatment can potentially reduce lung invasion and decrease fatality. Recently, several COVID-19 detections methods have been proposed using cough and breath sounds. However, very little study has been done on the use of phoneme analysis and the smearing of the audio signal in COVID-19 detection. In this paper, this problem has been addressed and the classification of speech samples has been carried out in COVID-19-positive and healthy audio samples. Additionally, the grouping of the phonemes based on reference classification accuracies have been proposed for effectiveness and faster detection of the disease at a primary stage. The Mel and Gammatone Cepstral coefficients and their derivatives are used as the features for five standard machine learning-based classifiers. It is observed that the generalized additive model provides the highest accuracy of 97.22% for the phoneme grouping “/t//r//n//g//l/.” This smearing-based phoneme classification technique can also be used in the future to classify other speech-related disease detections.},
  archive      = {J_FRAI},
  author       = {Mishra, Soumya and Dash, Tusar Kanti and Panda, Ganapati},
  doi          = {10.3389/frai.2022.1035805},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1035805},
  shortjournal = {Front. Artif. Intell.},
  title        = {Speech phoneme and spectral smearing based non-invasive COVID-19 detection},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The mental lexicon: A blueprint for the dictionaries of
tomorrow? <em>FRAI</em>, <em>5</em>, 1027392. (<a
href="https://doi.org/10.3389/frai.2022.1027392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Zock, Michael},
  doi          = {10.3389/frai.2022.1027392},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1027392},
  shortjournal = {Front. Artif. Intell.},
  title        = {The mental lexicon: A blueprint for the dictionaries of tomorrow?},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature alignment as a generative process. <em>FRAI</em>,
<em>5</em>, 1025148. (<a
href="https://doi.org/10.3389/frai.2022.1025148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reversibility in artificial neural networks allows us to retrieve the input given an output. We present feature alignment, a method for approximating reversibility in arbitrary neural networks. We train a network by minimizing the distance between the output of a data point and the random output with respect to a random input. We applied the technique to the MNIST, CIFAR-10, CelebA, and STL-10 image datasets. We demonstrate that this method can roughly recover images from just their latent representation without the need of a decoder. By utilizing the formulation of variational autoencoders, we demonstrate that it is possible to produce new images that are statistically comparable to the training data. Furthermore, we demonstrate that the quality of the images can be improved by coupling a generator and a discriminator together. In addition, we show how this method, with a few minor modifications, can be used to train networks locally, which has the potential to save computational memory resources.},
  archive      = {J_FRAI},
  author       = {Farias, Tiago de Souza and Maziero, Jonas},
  doi          = {10.3389/frai.2022.1025148},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1025148},
  shortjournal = {Front. Artif. Intell.},
  title        = {Feature alignment as a generative process},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Authority and solidarity on the estonian COVID-19 signs: In
line with the government’s guidelines, we ask you to wear a mask.
<em>FRAI</em>, <em>5</em>, 1000188. (<a
href="https://doi.org/10.3389/frai.2022.1000188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents the results of a quantitative analysis of 900 Estonian COVID-19 door signs, which were studied to investigate the linguistic means of establishing and maintaining contact between the sign&#39;s author (institution) and the addressee (client). Malinowski&#39;s notion of “phatic communion” and Laver&#39;s notions of “self-oriented” and “other-oriented” utterances as means for expressing status relations—authority and solidarity—between the participants of the communication act were used to establish four types of grammatical person usage on the COVID-19 signs: (1) “neither 1st nor 2nd person”; (2) “1st person only”; (3) “2nd person only”, and (4) “both 1st and 2nd person”. Grammatical person of personal pronouns and verb forms were included. The presence and absence of two other means for expressing authority—the imperative mood and lexical expressions of authority—were analyzed within these four types of grammatical person usage. The most important difference emerged between the signs belonging to the types “2nd person only” (i.e., signs with only other-oriented 2nd person, without 1st person) and “both 1st and 2nd person” (i.e., signs with both self-oriented 1st person and other-oriented 2nd person). On the signs belonging to the type “2nd person only” that, relying on Laver, express the higher status of the sender of the message in relation to the receiver of the message, the authors of the signs use significantly more imperative mood and less refer to an authority outside the communication act, thus putting themselves in the role of authority. However, on the signs belonging to the type “both 1st and 2nd person” that, relying on Laver, express the solidarity of the sender of the message with the addressee, the authors of the signs seem less inclined to assume the role of authority (using less imperative mood) and rather call the reader of the sign to submit to some higher authority (using lexical expressions of authority, e.g., Vabariigi Valitsus “Government of the Republic”, Terviseamet “Health Board”, etc.) to which the author of the sign and the addressee are both in a subordinate position and, therefore, of equal status.},
  archive      = {J_FRAI},
  author       = {Tragel, Ilona and Pikksaar, Aimi},
  doi          = {10.3389/frai.2022.1000188},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1000188},
  shortjournal = {Front. Artif. Intell.},
  title        = {Authority and solidarity on the estonian COVID-19 signs: In line with the government&#39;s guidelines, we ask you to wear a mask},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predictive keywords: Using machine learning to explain
document characteristics. <em>FRAI</em>, <em>5</em>, 975729. (<a
href="https://doi.org/10.3389/frai.2022.975729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When exploring the characteristics of a discourse domain associated with texts, keyword analysis is widely used in corpus linguistics. However, one of the challenges facing this method is the evaluation of the quality of the keywords. Here, we propose casting keyword analysis as a prediction problem with the goal of discriminating the texts associated with the target corpus from the reference corpus. We demonstrate that, when using linear support vector machines, this approach can be used not only to quantify the discrimination between the two corpora, but also extract keywords. To evaluate the keywords, we develop a systematic and rigorous approach anchored to the concepts of usefulness and relevance used in machine learning. The extracted keywords are compared with the recently proposed text dispersion keyness measure. We demonstrate that that our approach extracts keywords that are highly useful and linguistically relevant, capturing the characteristics of their discourse domain.},
  archive      = {J_FRAI},
  author       = {Kyröläinen, Aki-Juhani and Laippala, Veronika},
  doi          = {10.3389/frai.2022.975729},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {975729},
  shortjournal = {Front. Artif. Intell.},
  title        = {Predictive keywords: Using machine learning to explain document characteristics},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classification of land use/land cover using artificial
intelligence (ANN-RF). <em>FRAI</em>, <em>5</em>, 964279. (<a
href="https://doi.org/10.3389/frai.2022.964279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because deep learning has various downsides, such as complexity, expense, and the need to wait longer for results, this creates a significant incentive and impetus to invent and adopt the notion of developing machine learning because it is simple. This study intended to increase the accuracy of machine-learning approaches for land use/land cover classification using Sentinel-2A, and Landsat-8 satellites. This study aimed to implement a proposed method, neural-based with object-based, to produce a model addressed by artificial neural networks (limited parameters) with random forest (hyperparameter) called ANN_RF. This study used multispectral satellite images (Sentinel-2A and Landsat-8) and a normalized digital elevation model as input datasets for the Sana&#39;a city map of 2016. The results showed that the accuracy of the proposed model (ANN_RF) is better than the ANN classifier with the Sentinel-2A and Landsat-8 satellites individually, which may contribute to the development of machine learning through newer researchers and specialists; it also conventionally developed traditional artificial neural networks with seven to ten layers but with access to 1,000&#39;s and millions of simulated neurons without resorting to deep learning techniques (ANN_RF).},
  archive      = {J_FRAI},
  author       = {Alshari, Eman A. and Abdulkareem, Mohammed B. and Gawali, Bharti W.},
  doi          = {10.3389/frai.2022.964279},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {964279},
  shortjournal = {Front. Artif. Intell.},
  title        = {Classification of land use/land cover using artificial intelligence (ANN-RF)},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Frost prediction using machine learning and deep neural
network models. <em>FRAI</em>, <em>5</em>, 963781. (<a
href="https://doi.org/10.3389/frai.2022.963781">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study describes accurate, computationally efficient models that can be implemented for practical use in predicting frost events for point-scale agricultural applications. Frost damage in agriculture is a costly burden to farmers and global food security alike. Timely prediction of frost events is important to reduce the cost of agricultural frost damage and traditional numerical weather forecasts are often inaccurate at the field-scale in complex terrain. In this paper, we developed machine learning (ML) algorithms for the prediction of such frost events near Alcalde, NM at the point-scale. ML algorithms investigated include deep neural network, convolution neural networks, and random forest models at lead-times of 6–48 h. Our results show promising accuracy (6-h prediction RMSE = 1.53–1.72°C) for use in frost and minimum temperature prediction applications. Seasonal differences in model predictions resulted in a slight negative bias during Spring and Summer months and a positive bias in Fall and Winter months. Additionally, we tested the model transferability by continuing training and testing using data from sensors at a nearby farm. We calculated the feature importance of the random forest models and were able to determine which parameters provided the models with the most useful information for predictions. We determined that soil temperature is a key parameter in longer term predictions (&amp;gt;24 h), while other temperature related parameters provide the majority of information for shorter term predictions. The model error compared favorable to previous ML based frost studies and outperformed the physically based High Resolution Rapid Refresh forecasting system making our ML-models attractive for deployment toward real-time monitoring of frost events and damage at commercial farming operations.},
  archive      = {J_FRAI},
  author       = {Talsma, Carl J. and Solander, Kurt C. and Mudunuru, Maruti K. and Crawford, Brandon and Powell, Michelle R.},
  doi          = {10.3389/frai.2022.963781},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {963781},
  shortjournal = {Front. Artif. Intell.},
  title        = {Frost prediction using machine learning and deep neural network models},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predicting escherichia coli levels in manure using machine
learning in weeping wall and mechanical liquid solid separation systems.
<em>FRAI</em>, <em>5</em>, 921924. (<a
href="https://doi.org/10.3389/frai.2022.921924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An increased understanding of the interaction between manure management and public and environmental health has led to the development of Alternative Dairy Effluent Management Strategies (ADEMS). The efficiency of such ADEMS can be increased using mechanical solid-liquid-separator (SLS) or gravitational Weeping-Wall (WW) solid separation systems. In this research, using pilot study data from 96 samples, the chemical, physical, biological, seasonal, and structural parameters between SLS and WW of ADEM systems were compared. Parameters including sodium, potassium, total salts, volatile solids, pH, and E. coli levels were significantly different between the SLS and WW of ADEMS. The separated solid fraction of the dairy effluents had the lowest E. coli levels, which could have beneficial downstream implications in terms of microbial pollution control. To predict effluent quality and microbial pollution risk, we used Escherichia coli as the indicator organism, and a versatile machine learning, ensemble, stacked, super-learner model called E-C-MAN (Escherichia coli–Manure) was developed. Using pilot data, the E-C-MAN model was trained, and the trained model was validated with the test dataset. These results demonstrate that the heuristic E-C-MAN ensemble model can provide a pilot framework toward predicting Escherichia coli levels in manure treated by SLS or WW systems.},
  archive      = {J_FRAI},
  author       = {Shetty, B. Dharmaveer and Amaly, Noha and Weimer, Bart C. and Pandey, Pramod},
  doi          = {10.3389/frai.2022.921924},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {921924},
  shortjournal = {Front. Artif. Intell.},
  title        = {Predicting escherichia coli levels in manure using machine learning in weeping wall and mechanical liquid solid separation systems},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). African american english intensifier dennamug: Using twitter
to investigate syntactic change in low-frequency forms. <em>FRAI</em>,
<em>5</em>, 683104. (<a
href="https://doi.org/10.3389/frai.2022.683104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are some linguistic forms that may be known to both speakers and linguists, but that occur naturally with such low frequency that traditional sociolinguistic methods do not allow for study. This study investigates one such phenomenon: the grammatical reanalysis of an intensifier in some forms of African American English—from a full phrase [than a mother(fucker)] to lexical word (represented here as dennamug)—using data gathered from twitter. This paper investigates the relationship between apparent lexicalization and deletion of the comparative morpheme on the preceding adjective. While state-of-the-art traditional corpora contain so few tokens they can be counted on one hand, twitter yields almost 300,000 tokens over a 10 year sample period. This paper uses web scraping of Twitter to gather all plausible orthographic representations of the intensifier, and uses logistic regression to analyze the extent to which markers of lexicalization and reanalysis are associated with a corresponding shift from comparative to bare morphology on the adjective the intensifier modifies, finding that, indeed, degree of apparent lexicalization is strongly associated with bare morphology, suggesting ongoing lexicalization and subsequent reanalysis at the phrase level. This digital approach reveals ongoing grammatical change, with the new intensifier associated with bare, note comparative, adjectives, and that there is seemingly stable variation correlated with the degree to which the intensifier has lexicalized. Orthographic representations of African American English on social media are shown to be a locus of identity construction and grammatical change.},
  archive      = {J_FRAI},
  author       = {Jones, Taylor},
  doi          = {10.3389/frai.2022.683104},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {683104},
  shortjournal = {Front. Artif. Intell.},
  title        = {African american english intensifier dennamug: Using twitter to investigate syntactic change in low-frequency forms},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Challenging social media threats using collective
well-being-aware recommendation algorithms and an educational virtual
companion. <em>FRAI</em>, <em>5</em>, 654930. (<a
href="https://doi.org/10.3389/frai.2022.654930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media have become an integral part of our lives, expanding our interlinking capabilities to new levels. There is plenty to be said about their positive effects. On the other hand, however, some serious negative implications of social media have been repeatedly highlighted in recent years, pointing at various threats to society and its more vulnerable members, such as teenagers, in particular, ranging from much-discussed problems such as digital addiction and polarization to manipulative influences of algorithms and further to more teenager-specific issues (e.g., body stereotyping). The impact of social media—both at an individual and societal level—is characterized by the complex interplay between the users&#39; interactions and the intelligent components of the platform. Thus, users&#39; understanding of social media mechanisms plays a determinant role. We thus propose a theoretical framework based on an adaptive “Social Media Virtual Companion” for educating and supporting an entire community, teenage students, to interact in social media environments in order to achieve desirable conditions, defined in terms of a community-specific and participatory designed measure of Collective Well-Being (CWB). This Companion combines automatic processing with expert intervention and guidance. The virtual Companion will be powered by a Recommender System (CWB-RS) that will optimize a CWB metric instead of engagement or platform profit, which currently largely drives recommender systems thereby disregarding any societal collateral effect. CWB-RS will optimize CWB both in the short term by balancing the level of social media threats the users are exposed to, and in the long term by adopting an Intelligent Tutor System role and enabling adaptive and personalized sequencing of playful learning activities. We put an emphasis on experts and educators in the educationally managed social media community of the Companion. They play five key roles: (a) use the Companion in classroom-based educational activities; (b) guide the definition of the CWB; (c) provide a hierarchical structure of learning strategies, objectives and activities that will support and contain the adaptive sequencing algorithms of the CWB-RS based on hierarchical reinforcement learning; (d) act as moderators of direct conflicts between the members of the community; and, finally, (e) monitor and address ethical and educational issues that are beyond the intelligent agent&#39;s competence and control. This framework offers a possible approach to understanding how to design social media systems and embedded educational interventions that favor a more healthy and positive society. Preliminary results on the performance of the Companion&#39;s components and studies of the educational and psychological underlying principles are presented.},
  archive      = {J_FRAI},
  author       = {Ognibene, Dimitri and Wilkens, Rodrigo and Taibi, Davide and Hernández-Leo, Davinia and Kruschwitz, Udo and Donabauer, Gregor and Theophilou, Emily and Lomonaco, Francesco and Bursic, Sathya and Lobo, Rene Alejandro and Sánchez-Reina, J. Roberto and Scifo, Lidia and Schwarze, Veronica and Börsting, Johanna and Hoppe, Ulrich and Aprin, Farbod and Malzahn, Nils and Eimler, Sabrina},
  doi          = {10.3389/frai.2022.654930},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {654930},
  shortjournal = {Front. Artif. Intell.},
  title        = {Challenging social media threats using collective well-being-aware recommendation algorithms and an educational virtual companion},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
