<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>FROBT_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="frobt---242">FROBT - 242</h2>
<ul>
<li><details>
<summary>
(2023). System integration of magnetic medical microrobots: From
design to control. <em>FROBT</em>, <em>10</em>, 1330960. (<a
href="https://doi.org/10.3389/frobt.2023.1330960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic microrobots are ideal for medical applications owing to their deep tissue penetration, precise control, and flexible movement. After decades of development, various magnetic microrobots have been used to achieve medical functions such as targeted delivery, cell manipulation, and minimally invasive surgery. This review introduces the research status and latest progress in the design and control systems of magnetic medical microrobots from a system integration perspective and summarizes the advantages and limitations of the research to provide a reference for developers. Finally, the future development direction of magnetic medical microrobot design and control systems are discussed.},
  archive      = {J_FROBT},
  author       = {Zhou, Junjian and Li, Mengyue and Li, Na and Zhou, Yuting and Wang, Jingyi and Jiao, Niandong},
  doi          = {10.3389/frobt.2023.1330960},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1330960},
  shortjournal = {Front. Robot. AI},
  title        = {System integration of magnetic medical microrobots: From design to control},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application and challenges of a metaverse in medicine.
<em>FROBT</em>, <em>10</em>, 1291199. (<a
href="https://doi.org/10.3389/frobt.2023.1291199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaverse has been confirmed as a relatively amorphous concept of innovation, which refers to technological advancement. Metaverse, i.e., a coalition between reality world and virtual world, has created significant significance and convenience in education, communication, economy, etc. The COVID-19 outbreak has stimulated the growth of metaverse applications in medicine. The above-mentioned technology has broad applications while comprising online remote medical treatment, online conferences, medical education, preparation of surgical plans, etc. Moreover, technical, security, and financial challenges should be tackled down by the future widespread use of metaverse. Metaverse is limitlessly promising, and it will exert a certain effect on future scientific and technological advancements in the medical industry. The review article primarily aims to summarize the application of the metaverse in medicine and their challenge in the future of medicine.},
  archive      = {J_FROBT},
  author       = {Wang, Yingshu and Li, Congcong and Qu, Lai and Cai, Hongfei and Ge, Yingying},
  doi          = {10.3389/frobt.2023.1291199},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1291199},
  shortjournal = {Front. Robot. AI},
  title        = {Application and challenges of a metaverse in medicine},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ergonomic dual four-bar linkage knee exoskeleton for stair
ascent assistance. <em>FROBT</em>, <em>10</em>, 1285520. (<a
href="https://doi.org/10.3389/frobt.2023.1285520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Robotic exoskeletons are emerging technologies that have demonstrated their effectiveness in assisting with Activities of Daily Living. However, kinematic disparities between human and robotic joints can result in misalignment between humans and exoskeletons, leading to discomfort and potential user injuries.Methods: In this paper, we present an ergonomic knee exoskeleton based on a dual four-bar linkage mechanism powered by hydraulic artificial muscles for stair ascent assistance. The device comprises two asymmetric four-bar linkage mechanisms on the medial and lateral sides to accommodate the internal rotation of the knee and address the kinematic discrepancies between these sides. A genetic algorithm was employed to optimize the parameters of the four-bar linkage mechanism to minimize misalignment between human and exoskeleton knee joints. The proposed device was evaluated through two experiments. The first experiment measured the reduction in undesired load due to misalignment, while the second experiment evaluated the device’s effectiveness in assisting stair ascent in a healthy subject.Results: The experimental results indicate that the proposed device has a significantly reduced undesired load compared to the traditional revolute joint, decreasing from 14.15 N and 18.32 N to 1.88 N and 1.07 N on the medial and lateral sides, respectively. Moreover, a substantial reduction in muscle activities during stair ascent was observed, with a 55.94% reduction in surface electromyography signal.Discussion: The reduced undesired load of the proposed dual four-bar linkage mechanism highlights the importance of the adopted asymmetrical design for reduced misalignment and increased comfort. Moreover, the proposed device was effective at reducing the effort required during stair ascent.},
  archive      = {J_FROBT},
  author       = {Kittisares, Sarin and Ide, Tohru and Nabae, Hiroyuki and Suzumori, Koichi},
  doi          = {10.3389/frobt.2023.1285520},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1285520},
  shortjournal = {Front. Robot. AI},
  title        = {Ergonomic dual four-bar linkage knee exoskeleton for stair ascent assistance},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning-based intelligent trajectory planning for auto
navigation of magnetic robots. <em>FROBT</em>, <em>10</em>, 1281362. (<a
href="https://doi.org/10.3389/frobt.2023.1281362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Electromagnetically controlled small-scale robots show great potential in precise diagnosis, targeted delivery, and minimally invasive surgery. The automatic navigation of such robots could reduce human intervention, as well as the risk and difficulty of surgery. However, it is challenging to build a precise kinematics model for automatic robotic control because the controlling process is affected by various delays and complex environments.Method: Here, we propose a learning-based intelligent trajectory planning strategy for automatic navigation of magnetic robots without kinematics modeling. The Long Short-Term Memory (LSTM) neural network is employed to establish a global mapping relationship between the current sequence in the electromagnetic actuation system and the trajectory coordinates.Result: We manually control the robot to move on a curved path 50 times to form the training database to train the LSTM network. The trained LSTM network is validated to output the current sequence for automatically controlling the magnetic robot to move on the same curved path and the tortuous and branched new paths in simulated vascular tracks.Discussion: The proposed trajectory planning strategy is expected to impact the clinical applications of robots.},
  archive      = {J_FROBT},
  author       = {Kou, Yuanshi and Liu, Xurui and Ma, Xiaotian and Xiang, Yuanzhuo and Zang, Jianfeng},
  doi          = {10.3389/frobt.2023.1281362},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1281362},
  shortjournal = {Front. Robot. AI},
  title        = {Learning-based intelligent trajectory planning for auto navigation of magnetic robots},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Decomposing user-defined tasks in a reinforcement learning
setup using TextWorld. <em>FROBT</em>, <em>10</em>, 1280578. (<a
href="https://doi.org/10.3389/frobt.2023.1280578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current paper proposes a hierarchical reinforcement learning (HRL) method to decompose a complex task into simpler sub-tasks and leverage those to improve the training of an autonomous agent in a simulated environment. For practical reasons (i.e., illustrating purposes, easy implementation, user-friendly interface, and useful functionalities), we employ two Python frameworks called TextWorld and MiniGrid. MiniGrid functions as a 2D simulated representation of the real environment, while TextWorld functions as a high-level abstraction of this simulated environment. Training on this abstraction disentangles manipulation from navigation actions and allows us to design a dense reward function instead of a sparse reward function for the lower-level environment, which, as we show, improves the performance of training. Formal methods are utilized throughout the paper to establish that our algorithm is not prevented from deriving solutions.},
  archive      = {J_FROBT},
  author       = {Petsanis, Thanos and Keroglou, Christoforos and Ch. Kapoutsis, Athanasios and Kosmatopoulos, Elias B. and Sirakoulis, Georgios Ch.},
  doi          = {10.3389/frobt.2023.1280578},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1280578},
  shortjournal = {Front. Robot. AI},
  title        = {Decomposing user-defined tasks in a reinforcement learning setup using TextWorld},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A design space for automated material handling vehicles.
<em>FROBT</em>, <em>10</em>, 1276258. (<a
href="https://doi.org/10.3389/frobt.2023.1276258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Material Handling Vehicles (loaders, excavators, forklifts, harvesters, etc.) have seen a strong increase in automation efforts in recent years. The contexts such vehicles operate in are frequently complex and due to the often very specific nature of industrial material handling scenarios, know-how is fragmented and literature is not as numerous as, for example, for passenger vehicle automation. In this paper, we present a contextual design space for automated material handling vehicles (AMHV), that is intended to inform context analysis and design activities across a wide spectrum of material handling use cases. It was developed on the basis of existing context and design spaces for vehicle and machine automation and extended via expert knowledge. The design space consists of separate context and interaction subspaces, that separately capture the situation and each individual point of interaction, respectively. Implications, opportunities, and limitations for the investigation and design of AMHV are discussed.},
  archive      = {J_FROBT},
  author       = {Mirnig, Alexander G. and Fröhlich, Peter and Zafari, Setareh and Gafert, Michael and Kröninger, Lukas and Tscheligi, Manfred},
  doi          = {10.3389/frobt.2023.1276258},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1276258},
  shortjournal = {Front. Robot. AI},
  title        = {A design space for automated material handling vehicles},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Advanced workstations and collaborative robots: Exploiting
eye-tracking and cardiac activity indices to unveil senior workers’
mental workload in assembly tasks. <em>FROBT</em>, <em>10</em>, 1275572.
(<a href="https://doi.org/10.3389/frobt.2023.1275572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: As a result of Industry 5.0’s technological advancements, collaborative robots (cobots) have emerged as pivotal enablers for refining manufacturing processes while re-focusing on humans. However, the successful integration of these cutting-edge tools hinges on a better understanding of human factors when interacting with such new technologies, eventually fostering workers’ trust and acceptance and promoting low-fatigue work. This study thus delves into the intricate dynamics of human-cobot interactions by adopting a human-centric view.Methods: With this intent, we targeted senior workers, who often contend with diminishing work capabilities, and we explored the nexus between various human factors and task outcomes during a joint assembly operation with a cobot on an ergonomic workstation. Exploiting a dual-task manipulation to increase the task demand, we measured performance, subjective perceptions, eye-tracking indices and cardiac activity during the task. Firstly, we provided an overview of the senior workers’ perceptions regarding their shared work with the cobot, by measuring technology acceptance, perceived wellbeing, work experience, and the estimated social impact of this technology in the industrial sector. Secondly, we asked whether the considered human factors varied significantly under dual-tasking, thus responding to a higher mental load while working alongside the cobot. Finally, we explored the predictive power of the collected measurements over the number of errors committed at the work task and the participants’ perceived workload.Results: The present findings demonstrated how senior workers exhibited strong acceptance and positive experiences with our advanced workstation and the cobot, even under higher mental strain. Besides, their task performance suffered increased errors and duration during dual-tasking, while the eye behavior partially reflected the increased mental demand. Some interesting outcomes were also gained about the predictive power of some of the collected indices over the number of errors committed at the assembly task, even though the same did not apply to predicting perceived workload levels.Discussion: Overall, the paper discusses possible applications of these results in the 5.0 manufacturing sector, emphasizing the importance of adopting a holistic human-centered approach to understand the human-cobot complex better.},
  archive      = {J_FROBT},
  author       = {Pluchino, Patrik and Pernice, Gabriella F. A. and Nenna, Federica and Mingardi, Michele and Bettelli, Alice and Bacchin, Davide and Spagnolli, Anna and Jacucci, Giulio and Ragazzon, Andrea and Miglioranzi, Leonardo and Pettenon, Carlo and Gamberini, Luciano},
  doi          = {10.3389/frobt.2023.1275572},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1275572},
  shortjournal = {Front. Robot. AI},
  title        = {Advanced workstations and collaborative robots: Exploiting eye-tracking and cardiac activity indices to unveil senior workers’ mental workload in assembly tasks},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development of a remotely controllable 4 m long
aerial-hose-type firefighting robot. <em>FROBT</em>, <em>10</em>,
1273676. (<a href="https://doi.org/10.3389/frobt.2023.1273676">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a fire outbreak, firefighters are expected to rapidly extinguish fires to stop the spread of damage and prevent secondary disasters. We proposed the concept of a dragon firefighter (DFF), which is a flying-hose-type firefighting robot. We developed a 3.6 m long DFF equipped with two nozzle units and achieved stable flight. However, the system was not yet completed because the root of the robot, which should have been operated remotely, was operated manually. In addition, the system’s reliability was insufficient to successfully repeat the demonstration several times. The development of a robot demonstration system is crucial for the practical application of such a firefighting robot. In this study, we developed a demonstration system for a remotely controllable 4 m flying firehose robot for demonstration at the World Robot Summit 2020 (WRS 2020) opening ceremony in Fukushima as a milestone. This paper focuses on the following issues: 1): installation of the remotely controllable mobile base, 2): redesign of the water channels (the sizes of nozzle outlets) to get enough thrusts to fly with a fire engine, 3): development of nozzle units with a larger movable range (1.5 times larger than the conventional nozzle) in addition to waterproofing technique to improve system reliability, and 4): redesign of a passive damping mechanism to ensure better stability. Thus, a firefighting demonstration was successfully conducted at the opening ceremony of the World Robot Summit 2020 in Fukushima, Japan, and we discuss the lessons learned through the demonstration. We found that the developed DFF system incorporating a mobile base could achieve remote fire extinguishing.},
  archive      = {J_FROBT},
  author       = {Yamauchi, Yu and Maezawa, Yukihiro and Ambe, Yuichi and Konyo, Masashi and Tadakuma, Kenjiro and Tadokoro, Satoshi},
  doi          = {10.3389/frobt.2023.1273676},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1273676},
  shortjournal = {Front. Robot. AI},
  title        = {Development of a remotely controllable 4 m long aerial-hose-type firefighting robot},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time emotion generation in human-robot dialogue using
large language models. <em>FROBT</em>, <em>10</em>, 1271610. (<a
href="https://doi.org/10.3389/frobt.2023.1271610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Affective behaviors enable social robots to not only establish better connections with humans but also serve as a tool for the robots to express their internal states. It has been well established that emotions are important to signal understanding in Human-Robot Interaction (HRI). This work aims to harness the power of Large Language Models (LLM) and proposes an approach to control the affective behavior of robots. By interpreting emotion appraisal as an Emotion Recognition in Conversation (ERC) tasks, we used GPT-3.5 to predict the emotion of a robot’s turn in real-time, using the dialogue history of the ongoing conversation. The robot signaled the predicted emotion using facial expressions. The model was evaluated in a within-subjects user study (N = 47) where the model-driven emotion generation was compared against conditions where the robot did not display any emotions and where it displayed incongruent emotions. The participants interacted with the robot by playing a card sorting game that was specifically designed to evoke emotions. The results indicated that the emotions were reliably generated by the LLM and the participants were able to perceive the robot’s emotions. It was found that the robot expressing congruent model-driven facial emotion expressions were perceived to be significantly more human-like, emotionally appropriate, and elicit a more positive impression. Participants also scored significantly better in the card sorting game when the robot displayed congruent facial expressions. From a technical perspective, the study shows that LLMs can be used to control the affective behavior of robots reliably in real-time. Additionally, our results could be used in devising novel human-robot interactions, making robots more effective in roles where emotional interaction is important, such as therapy, companionship, or customer service.},
  archive      = {J_FROBT},
  author       = {Mishra, Chinmaya and Verdonschot, Rinus and Hagoort, Peter and Skantze, Gabriel},
  doi          = {10.3389/frobt.2023.1271610},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1271610},
  shortjournal = {Front. Robot. AI},
  title        = {Real-time emotion generation in human-robot dialogue using large language models},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). It’s not what you think: Shaping beliefs about a robot to
influence a teleoperator’s expectations and behavior. <em>FROBT</em>,
<em>10</em>, 1271337. (<a
href="https://doi.org/10.3389/frobt.2023.1271337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present a novel design approach for shaping a teleoperator’s expectations and behaviors when teleoperating a robot. Just as how people may drive a car differently based on their expectations of it (e.g., the brakes may be poor), we assert that teleoperators may likewise operate a robot differently based on expectations of robot capability and robustness. We present 3 novel interaction designs that proactively shape teleoperator perceptions, and the results from formal studies that demonstrate that these techniques do indeed shape operator perceptions, and in some cases, measures of driving behavior such as changes in collisions. Our methods shape operator perceptions of a robot’s speed, weight, or overall safety, designed to encourage them to drive more safely. This approach shows promise as an avenue for improving teleoperator effectiveness without requiring changes to a robot, novel sensors, algorithms, or other functionality.},
  archive      = {J_FROBT},
  author       = {Rea, Daniel J. and Young, James E.},
  doi          = {10.3389/frobt.2023.1271337},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1271337},
  shortjournal = {Front. Robot. AI},
  title        = {It’s not what you think: Shaping beliefs about a robot to influence a teleoperator’s expectations and behavior},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The perceptions of university students on technological and
ethical risks of using robots in long-term care homes. <em>FROBT</em>,
<em>10</em>, 1268386. (<a
href="https://doi.org/10.3389/frobt.2023.1268386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: The COVID-19 pandemic has disproportionately impacted long-term care (LTC) residents and exacerbated residents’ risks of social isolation and loneliness. The unmet emotional needs of residents in LTC have driven researchers and decision-makers to consider novel technologies to improve care and quality of life for residents. Ageist stereotypes have contributed to the underuse of technologies by the older population. Telepresence robots have been found to be easy to use and do not require older adults to learn how to operate the robot but are remotely controlled by family members. The study aimed to understand the perspectives of multidisciplinary university students, including healthcare students, on using telepresence robots in LTC homes. The study would contribute to the future planning, implementation, and design of robotics in LTC.Methods: Between December 2021 and March 2022, our team conducted interviews with 15 multidisciplinary students. We employed a qualitative descriptive (QD) approach with semi-structured interview methods. Our study aimed to understand the perspectives of university students (under the age of 40) on using telepresence robots in LTC homes. Participants were invited to spend 15 min remotely driving a telepresence robot prior to the interview. A diverse team of young researchers and older adults (patient and family partners) conducted reflexive thematic analysis.Results: Six themes were identified: Robots as supplementary interaction; privacy, confidentiality, and physical harm; increased mental well-being and opportunities for interactions; intergenerational perspectives add values; staffing capacity; environmental and cultural factors influence acceptance.Conclusion: We identified a diverse range of perspectives regarding risk and privacy among participants regarding the implementation of telepresence robots in long-term care. Participants shared the importance of the voice of the resident and their own for creating more equitable decision-making and advocating for including this type of technology within LTC. Our study would contribute to the future planning, implementation, and design of robotics in LTC.},
  archive      = {J_FROBT},
  author       = {Young, Erika and Hung, Lillian and Wong, Joey and Wong, Karen Lok Yi and Yee, Amanda and Mann, Jim and Vasarhelyi, Krisztina},
  doi          = {10.3389/frobt.2023.1268386},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1268386},
  shortjournal = {Front. Robot. AI},
  title        = {The perceptions of university students on technological and ethical risks of using robots in long-term care homes},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Remember me - user-centered implementation of working memory
architectures on an industrial robot. <em>FROBT</em>, <em>10</em>,
1257690. (<a href="https://doi.org/10.3389/frobt.2023.1257690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present research is innovative as we followed a user-centered approach to implement and train two working memory architectures on an industrial RB-KAIROS + robot: GRU, a state-of-the-art architecture, and WorkMATe, a biologically-inspired alternative. Although user-centered approaches are essential to create a comfortable and safe HRI, they are still rare in industrial settings. Closing this research gap, we conducted two online user studies with large heterogeneous samples. The major aim of these studies was to evaluate the RB-KAIROS + robot’s appearance, movements, and perceived memory functions before (User Study 1) and after the implementation and training of robot working memory (User Study 2). In User Study 1, we furthermore explored participants’ ideas about robot memory and what aspects of the robot’s movements participants found positive and what aspects they would change. The effects of participants’ demographic background and attitudes were controlled for. In User Study 1, participants’ overall evaluations of the robot were moderate. Participant age and negative attitudes toward robots led to more negative robot evaluations. According to exploratory analyses, these effects were driven by perceived low experience with robots. Participants expressed clear ideas of robot memory and precise suggestions for a safe, efficient, and comfortable robot navigation which are valuable for further research and development. In User Study 2, the implementation of WorkMATe and GRU led to more positive evaluations of perceived robot memory, but not of robot appearance and movements. Participants’ robot evaluations were driven by their positive views of robots. Our results demonstrate that considering potential users’ views can greatly contribute to an efficient and positively perceived robot navigation, while users’ experience with robots is crucial for a positive HRI.},
  archive      = {J_FROBT},
  author       = {Bernotat, Jasmin and Landolfi, Lorenzo and Pasquali, Dario and Nardelli, Alice and Rea, Francesco},
  doi          = {10.3389/frobt.2023.1257690},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1257690},
  shortjournal = {Front. Robot. AI},
  title        = {Remember me - user-centered implementation of working memory architectures on an industrial robot},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RISE: An open-source architecture for interdisciplinary and
reproducible human–robot interaction research. <em>FROBT</em>,
<em>10</em>, 1245501. (<a
href="https://doi.org/10.3389/frobt.2023.1245501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present RISE—a Robotics Integration and Scenario-Management Extensible-Architecture—for designing human–robot dialogs and conducting Human–Robot Interaction (HRI) studies. In current HRI research, interdisciplinarity in the creation and implementation of interaction studies is becoming increasingly important. In addition, there is a lack of reproducibility of the research results. With the presented open-source architecture, we aim to address these two topics. Therefore, we discuss the advantages and disadvantages of various existing tools from different sub-fields within robotics. Requirements for an architecture can be derived from this overview of the literature, which 1) supports interdisciplinary research, 2) allows reproducibility of the research, and 3) is accessible to other researchers in the field of HRI. With our architecture, we tackle these requirements by providing a Graphical User Interface which explains the robot behavior and allows introspection into the current state of the dialog. Additionally, it offers controlling possibilities to easily conduct Wizard of Oz studies. To achieve transparency, the dialog is modeled explicitly, and the robot behavior can be configured. Furthermore, the modular architecture offers an interface for external features and sensors and is expandable to new robots and modalities.},
  archive      = {J_FROBT},
  author       = {Groß, André and Schütze, Christian and Brandt, Mara and Wrede, Britta and Richter, Birte},
  doi          = {10.3389/frobt.2023.1245501},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1245501},
  shortjournal = {Front. Robot. AI},
  title        = {RISE: An open-source architecture for interdisciplinary and reproducible human–robot interaction research},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). What should a robot disclose about me? A study about
privacy-appropriate behaviors for social robots. <em>FROBT</em>,
<em>10</em>, 1236733. (<a
href="https://doi.org/10.3389/frobt.2023.1236733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For robots to become integrated into our daily environment, they must be designed to gain sufficient trust of both users and bystanders. This is in particular important for social robots including those that assume the role of a mediator, working towards positively shaping relationships and interactions between individuals. One crucial factor influencing trust is the appropriate handling of personal information. Previous research on privacy has focused on data collection, secure storage, and abstract third-party disclosure risks. However, robot mediators may face situations where the disclosure of private information about one person to another specific person appears necessary. It is not clear if, how, and to what extent robots should share private information between people. This study presents an online investigation into appropriate robotic disclosure strategies. Using a vignette design, participants were presented with written descriptions of situations where a social robot reveals personal information about its owner to support pro-social human-human interaction. Participants were asked to choose the most appropriate robot behaviors, which differed in the level of information disclosure. We aimed to explore the effects of disclosure context, such as the relationship to the other person and the information content. The findings indicate that both the information content and relationship configurations significantly influence the perception of appropriate behavior but are not the sole determinants of disclosure-adequacy perception. The results also suggest that expected benefits of disclosure and individual general privacy attitudes serve as additional influential factors. These insights can inform the design of future mediating robots, enabling them to make more privacy-appropriate decisions which could foster trust and acceptance.},
  archive      = {J_FROBT},
  author       = {Dietrich, Manuel and Krüger, Matti and Weisswange, Thomas H.},
  doi          = {10.3389/frobt.2023.1236733},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1236733},
  shortjournal = {Front. Robot. AI},
  title        = {What should a robot disclose about me? a study about privacy-appropriate behaviors for social robots},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Working with troubles and failures in conversation between
humans and robots: Workshop report. <em>FROBT</em>, <em>10</em>,
1202306. (<a href="https://doi.org/10.3389/frobt.2023.1202306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper summarizes the structure and findings from the first Workshop on Troubles and Failures in Conversations between Humans and Robots. The workshop was organized to bring together a small, interdisciplinary group of researchers working on miscommunication from two complementary perspectives. One group of technology-oriented researchers was made up of roboticists, Human-Robot Interaction (HRI) researchers and dialogue system experts. The second group involved experts from conversation analysis, cognitive science, and linguistics. Uniting both groups of researchers is the belief that communication failures between humans and machines need to be taken seriously and that a systematic analysis of such failures may open fruitful avenues in research beyond current practices to improve such systems, including both speech-centric and multimodal interfaces. This workshop represents a starting point for this endeavour. The aim of the workshop was threefold: Firstly, to establish an interdisciplinary network of researchers that share a common interest in investigating communicative failures with a particular view towards robotic speech interfaces; secondly, to gain a partial overview of the “failure landscape” as experienced by roboticists and HRI researchers; and thirdly, to determine the potential for creating a robotic benchmark scenario for testing future speech interfaces with respect to the identified failures. The present article summarizes both the “failure landscape” surveyed during the workshop as well as the outcomes of the attempt to define a benchmark scenario.},
  archive      = {J_FROBT},
  author       = {Förster, Frank and Romeo, Marta and Holthaus, Patrick and Wood, Luke J. and Dondrup, Christian and Fischer, Joel E. and Liza, Farhana Ferdousi and Kaszuba, Sara and Hough, Julian and Nesset, Birthe and Hernández García, Daniel and Kontogiorgos, Dimosthenis and Williams, Jennifer and Özkan, Elif Ecem and Barnard, Pepita and Berumen, Gustavo and Price, Dominic and Cobb, Sue and Wiltschko, Martina and Tisserand, Lucien and Porcheron, Martin and Giuliani, Manuel and Skantze, Gabriel and Healey, Patrick G. T. and Papaioannou, Ioannis and Gkatzia, Dimitra and Albert, Saul and Huang, Guanyu and Maraev, Vladislav and Kapetanios, Epaminondas},
  doi          = {10.3389/frobt.2023.1202306},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1202306},
  shortjournal = {Front. Robot. AI},
  title        = {Working with troubles and failures in conversation between humans and robots: Workshop report},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploiting redundancy for UWB anomaly detection in
infrastructure-free multi-robot relative localization. <em>FROBT</em>,
<em>10</em>, 1190296. (<a
href="https://doi.org/10.3389/frobt.2023.1190296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultra-wideband (UWB) localization methods have emerged as a cost-effective and accurate solution for GNSS-denied environments. There is a significant amount of previous research in terms of resilience of UWB ranging, with non-line-of-sight and multipath detection methods. However, little attention has been paid to resilience against disturbances in relative localization systems involving multiple nodes. This paper presents an approach to detecting range anomalies in UWB ranging measurements from the perspective of multi-robot cooperative localization. We introduce an approach to exploiting redundancy for relative localization in multi-robot systems, where the position of each node is calculated using different subsets of available data. This enables us to effectively identify nodes that present ranging anomalies and eliminate their effect within the cooperative localization scheme. We analyze anomalies created by timing errors in the ranging process, e.g., owing to malfunctioning hardware. However, our method is generic and can be extended to other types of ranging anomalies. Our approach results in a more resilient cooperative localization framework with a negligible impact in terms of the computational workload.},
  archive      = {J_FROBT},
  author       = {Salimpour, Sahar and Morón, Paola Torrico and Yu, Xianjia and Westerlund, Tomi and Peña-Queralta, Jorge},
  doi          = {10.3389/frobt.2023.1190296},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1190296},
  shortjournal = {Front. Robot. AI},
  title        = {Exploiting redundancy for UWB anomaly detection in infrastructure-free multi-robot relative localization},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Social robotics for children: An investigation of
manufacturers’ claims. <em>FROBT</em>, <em>10</em>, 1080157. (<a
href="https://doi.org/10.3389/frobt.2023.1080157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the market for commercial children’s social robots grows, manufacturers’ claims around the functionality and outcomes of their products have the potential to impact consumer purchasing decisions. In this work, we qualitatively and quantitatively assess the content and scientific support for claims about social robots for children made on manufacturers’ websites. A sample of 21 robot websites was obtained using location-independent keyword searches on Google, Yahoo, and Bing from April to July 2021. All claims made on manufacturers’ websites about robot functionality and outcomes (n = 653 statements) were subjected to content analysis, and the quality of evidence for these claims was evaluated using a validated quality evaluation tool. Social robot manufacturers made clear claims about the impact of their products in the areas of interaction, education, emotion, and adaptivity. Claims tended to focus on the child rather than the parent or other users. Robots were primarily described in the context of interactive, educational, and emotional uses, rather than being for health, safety, or security. The quality of the information used to support these claims was highly variable and at times potentially misleading. Many websites used language implying that robots had interior thoughts and experiences; for example, that they would love the child. This study provides insight into the content and quality of parent-facing manufacturer claims regarding commercial social robots for children.},
  archive      = {J_FROBT},
  author       = {Dosso, Jill A. and Riminchan, Anna and Robillard, Julie M.},
  doi          = {10.3389/frobt.2023.1080157},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1080157},
  shortjournal = {Front. Robot. AI},
  title        = {Social robotics for children: An investigation of manufacturers’ claims},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Robotics in extreme environments, volume II.
<em>FROBT</em>, <em>10</em>, 1337681. (<a
href="https://doi.org/10.3389/frobt.2023.1337681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Takahashi, Chie and Lennox, Barry and Semini, Claudio and Giuliani, Manuel and Park, Young Soo and Hamel, William R.},
  doi          = {10.3389/frobt.2023.1337681},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1337681},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Robotics in extreme environments, volume II},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Technologies evolution in robot-assisted fracture reduction
systems: A comprehensive review. <em>FROBT</em>, <em>10</em>, 1315250.
(<a href="https://doi.org/10.3389/frobt.2023.1315250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Robot-assisted fracture reduction systems can potentially reduce the risk of infection and improve outcomes, leading to significant health and economic benefits. However, these systems are still in the laboratory stage and not yet ready for commercialization due to unresolved difficulties. While previous reviews have focused on individual technologies, system composition, and surgical stages, a comprehensive review is necessary to assist future scholars in selecting appropriate research directions for clinical use.Methods: A literature review using Google Scholar identified articles on robot-assisted fracture reduction systems. A comprehensive search yielded 17,800, 18,100, and 16,700 results for “fracture reduction,” “computer-assisted orthopedic surgery,” and “robot-assisted fracture reduction,” respectively. Approximately 340 articles were selected, and 90 highly relevant articles were chosen for further reading after reviewing the abstracts.Results and Conclusion: Robot-assisted fracture reduction systems offer several benefits, including improved reduction accuracy, reduced physical work and radiation exposure, enhanced preoperative planning and intraoperative visualization, and shortened learning curve for skill acquisition. In the future, these systems will become integrated and practical, with automatic preoperative planning and high intraoperative safety.},
  archive      = {J_FROBT},
  author       = {Kou, Wei and Zhou, Peiqing and Lin, Jihong and Kuang, Shaolong and Sun, Lining},
  doi          = {10.3389/frobt.2023.1315250},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1315250},
  shortjournal = {Front. Robot. AI},
  title        = {Technologies evolution in robot-assisted fracture reduction systems: A comprehensive review},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing postural stability in a musculoskeletal hopping
robot through stretch reflex application on biarticular thigh muscles.
<em>FROBT</em>, <em>10</em>, 1293365. (<a
href="https://doi.org/10.3389/frobt.2023.1293365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Postural stabilization during rapid and powerful hopping actions represents a significant challenge for legged robotics. One strategy utilized by humans to negotiate this difficulty is the robust activation of biarticular thigh muscles. Guided by this physiological principle, this study aims to enhance the postural stability of a hopping robot through the emulation of this human mechanism. A legged robot powered by pneumatic artificial muscles (PAMs) was designed to mimic human anatomical structures. A critical aspect of this development was creating a tension-oriented stretch reflex system engineered to initiate muscle activation in response to perturbations. Our research encompassed three experiments: 1) assessing the trunk pitch angle with and without the integration of stretch reflexes, 2) evaluating the consistency of hops made with and without reflexes, and 3) understanding the correlation between the reflex strength equilibrium in the biarticular thigh muscles and trunk pitch angle. The results indicated that the integration of the stretch reflex minimized perturbations, thereby allowing the robot to perform double the continuous hops. As hypothesized, adjusting the reflex strength equilibrium caused a shift in the angle. This reflex mechanism offers potential application to PAM-driven robots and signifies a promising avenue for enhancing postural stability in diverse forms of locomotion, including walking and running.},
  archive      = {J_FROBT},
  author       = {Takahashi, Ryu and Murakami, Yuki and Hosoda, Koh},
  doi          = {10.3389/frobt.2023.1293365},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1293365},
  shortjournal = {Front. Robot. AI},
  title        = {Enhancing postural stability in a musculoskeletal hopping robot through stretch reflex application on biarticular thigh muscles},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Review and critique of current testing protocols for
upper-limb prostheses: A call for standardization amidst rapid
technological advancements. <em>FROBT</em>, <em>10</em>, 1292632. (<a
href="https://doi.org/10.3389/frobt.2023.1292632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article provides a comprehensive narrative review of physical task-based assessments used to evaluate the multi-grasp dexterity and functional impact of varying control systems in pediatric and adult upper-limb prostheses. Our search returned 1,442 research articles from online databases, of which 25 tests—selected for their scientific rigor, evaluation metrics, and psychometric properties—met our review criteria. We observed that despite significant advancements in the mechatronics of upper-limb prostheses, these 25 assessments are the only validated evaluation methods that have emerged since the first measure in 1948. This not only underscores the lack of a consistently updated, standardized assessment protocol for new innovations, but also reveals an unsettling trend: as technology outpaces standardized evaluation measures, developers will often support their novel devices through custom, study-specific tests. These boutique assessments can potentially introduce bias and jeopardize validity. Furthermore, our analysis revealed that current validated evaluation methods often overlook the influence of competing interests on test success. Clinical settings and research laboratories differ in their time constraints, access to specialized equipment, and testing objectives, all of which significantly influence assessment selection and consistent use. Therefore, we propose a dual testing approach to address the varied demands of these distinct environments. Additionally, we found that almost all existing task-based assessments lack an integrated mechanism for collecting patient feedback, which we assert is essential for a holistic evaluation of upper-limb prostheses. Our review underscores the pressing need for a standardized evaluation protocol capable of objectively assessing the rapidly advancing prosthetic technologies across all testing domains.},
  archive      = {J_FROBT},
  author       = {Siegel, Joshua R. and Battraw, Marcus A. and Winslow, Eden J. and James, Michelle A. and Joiner, Wilsaan M. and Schofield, Jonathon S.},
  doi          = {10.3389/frobt.2023.1292632},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1292632},
  shortjournal = {Front. Robot. AI},
  title        = {Review and critique of current testing protocols for upper-limb prostheses: A call for standardization amidst rapid technological advancements},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing skill learning with dual-user haptic feedback:
Insights from a task-specific approach. <em>FROBT</em>, <em>10</em>,
1286282. (<a href="https://doi.org/10.3389/frobt.2023.1286282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: This study was to examine whether inter-user haptic feedback would have a differential impact on skill acquisition based on the nature of the surgical task involved. Specifically, we hypothesized that haptic feedback would facilitate target orientation more than cutting tasks in the context of laparoscopic surgery.Methods: Ten novice participants were recruited and assigned to one of two training groups. Each group underwent six half-hour training sessions dedicated to laparoscopic pattern-cutting tasks. In the haptic group, five participants received expert guidance during the training sessions, whereas the remaining five participants in the control group engaged in self-practice. All trials were recorded on video, enabling a comparative analysis of task performance between the participants’ left hand (target manipulation) and right hand (cutting task). Additionally, the number of haptic feedback instances provided to the trainees in the haptic group was recorded.Results: Practice led to a reduction in total task time, grasping time, and cutting errors. However, no significant differences were observed between the two training groups, except for the grasping time, where haptic feedback significantly reduced the grasping time compared to the control group. Moreover, the frequency of haptic feedback instances provided to the trainees was notably higher for the grasping than for the cutting task.Discussion: Our study suggests that haptic feedback has a more substantial impact on orientation tasks than on cutting tasks in laparoscopic surgery training. However, we acknowledge that a larger sample size would provide a more robust evaluation of this effect.},
  archive      = {J_FROBT},
  author       = {Zhang, Yao and Wang, Olyvia and Wang, Yanqing and Tavakoli, Mahdi and Zheng, Bin},
  doi          = {10.3389/frobt.2023.1286282},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1286282},
  shortjournal = {Front. Robot. AI},
  title        = {Enhancing skill learning with dual-user haptic feedback: Insights from a task-specific approach},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). End-to-end decentralized formation control using a graph
neural network-based learning method. <em>FROBT</em>, <em>10</em>,
1285412. (<a href="https://doi.org/10.3389/frobt.2023.1285412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-robot cooperative control has been extensively studied using model-based distributed control methods. However, such control methods rely on sensing and perception modules in a sequential pipeline design, and the separation of perception and controls may cause processing latencies and compounding errors that affect control performance. End-to-end learning overcomes this limitation by implementing direct learning from onboard sensing data, with control commands output to the robots. Challenges exist in end-to-end learning for multi-robot cooperative control, and previous results are not scalable. We propose in this article a novel decentralized cooperative control method for multi-robot formations using deep neural networks, in which inter-robot communication is modeled by a graph neural network (GNN). Our method takes LiDAR sensor data as input, and the control policy is learned from demonstrations that are provided by an expert controller for decentralized formation control. Although it is trained with a fixed number of robots, the learned control policy is scalable. Evaluation in a robot simulator demonstrates the triangular formation behavior of multi-robot teams of different sizes under the learned control policy.},
  archive      = {J_FROBT},
  author       = {Jiang, Chao and Huang, Xinchi and Guo, Yi},
  doi          = {10.3389/frobt.2023.1285412},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1285412},
  shortjournal = {Front. Robot. AI},
  title        = {End-to-end decentralized formation control using a graph neural network-based learning method},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Curriculum-based humanoid robot identification using
large-scale human motion database. <em>FROBT</em>, <em>10</em>, 1282299.
(<a href="https://doi.org/10.3389/frobt.2023.1282299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying an accurate dynamics model remains challenging for humanoid robots. The difficulty is mainly due to the following two points. First, a good initial model is required to evaluate the feasibility of motions for data acquisition. Second, a highly nonlinear optimization problem needs to be solved to design movements to acquire the identification data. To cope with the first point, in this paper, we propose a curriculum of identification to gradually learn an accurate dynamics model from an unreliable initial model. For the second point, we propose using a large-scale human motion database to efficiently design the humanoid movements for the parameter identification. The contribution of our study is developing a humanoid identification method that does not require the good initial model and does not need to solve the highly nonlinear optimization problem. We showed that our curriculum-based approach was able to more efficiently identify humanoid model parameters than a method that just randomly picked reference motions for identification. We evaluated our proposed method in a simulation experiment and demonstrated that our curriculum was led to obtain a wide variety of motion data for efficient parameter estimation. Consequently, our approach successfully identified an accurate model of an 18-DoF, simulated upper-body humanoid robot.},
  archive      = {J_FROBT},
  author       = {Kang, Sunhwi and Ishihara, Koji and Sugimoto, Norikazu and Morimoto, Jun},
  doi          = {10.3389/frobt.2023.1282299},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1282299},
  shortjournal = {Front. Robot. AI},
  title        = {Curriculum-based humanoid robot identification using large-scale human motion database},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust whole-hand spatial manipulation via energy maps with
caging, rolling, and sliding. <em>FROBT</em>, <em>10</em>, 1281188. (<a
href="https://doi.org/10.3389/frobt.2023.1281188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans regularly use all inner surfaces of the hand during manipulation, whereas traditional formulations for robots tend to use only the tips of their fingers, limiting overall dexterity. In this paper, we explore the use of the whole hand during spatial robotic dexterous within-hand manipulation. We present a novel four-fingered robotic hand called the Model B, which is designed and controlled using a straight-forward potential energy-based motion model that is based on the hand configuration and applied actuator torques. In this way the hand-object system is driven to a new desired configuration, often through sliding and rolling between the object and hand, and with the fingers “caging” the object to prevent ejection. This paper presents the first ever application of the energy model in three dimensions, which was used to compare the theoretical manipulability of popular robotic hands, which then inspired the design of the Model B. We experimentally validate the hand’s performance with extensive benchtop experimentation with test objects and real world objects, as well as on a robotic arm, and demonstrate complex spatial caging manipulation on a variety of objects in all six object dimensions (three translation and three rotation) using all inner surfaces of the fingers and the palm.},
  archive      = {J_FROBT},
  author       = {Bircher, Walter G. and Morgan, Andrew S. and Dollar, Aaron M.},
  doi          = {10.3389/frobt.2023.1281188},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1281188},
  shortjournal = {Front. Robot. AI},
  title        = {Robust whole-hand spatial manipulation via energy maps with caging, rolling, and sliding},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial consciousness: The missing ingredient for ethical
AI? <em>FROBT</em>, <em>10</em>, 1270460. (<a
href="https://doi.org/10.3389/frobt.2023.1270460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Can we conceive machines that can formulate autonomous intentions and make conscious decisions? If so, how would this ability affect their ethical behavior? Some case studies help us understand how advances in understanding artificial consciousness can contribute to creating ethical AI systems.},
  archive      = {J_FROBT},
  author       = {Chella, Antonio},
  doi          = {10.3389/frobt.2023.1270460},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1270460},
  shortjournal = {Front. Robot. AI},
  title        = {Artificial consciousness: The missing ingredient for ethical AI?},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A global bibliometric and visualized analysis of gait
analysis and artificial intelligence research from 1992 to 2022.
<em>FROBT</em>, <em>10</em>, 1265543. (<a
href="https://doi.org/10.3389/frobt.2023.1265543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gait is an important basic function of human beings and an integral part of life. Many mental and physical abnormalities can cause noticeable differences in a person’s gait. Abnormal gait can lead to serious consequences such as falls, limited mobility and reduced life satisfaction. Gait analysis, which includes joint kinematics, kinetics, and dynamic Electromyography (EMG) data, is now recognized as a clinically useful tool that can provide both quantifiable and qualitative information on performance to aid in treatment planning and evaluate its outcome. With the assistance of new artificial intelligence (AI) technology, the traditional medical environment has undergone great changes. AI has the potential to reshape medicine, making gait analysis more accurate, efficient and accessible. In this study, we analyzed basic information about gait analysis and AI articles that met inclusion criteria in the WoS Core Collection database from 1992–2022, and the VosViewer software was used for web visualization and keyword analysis. Through bibliometric and visual analysis, this article systematically introduces the research status of gait analysis and AI. We introduce the application of artificial intelligence in clinical gait analysis, which affects the identification and management of gait abnormalities found in various diseases. Machine learning (ML) and artificial neural networks (ANNs) are the most often utilized AI methods in gait analysis. By comparing the predictive capability of different AI algorithms in published studies, we evaluate their potential for gait analysis in different situations. Furthermore, the current challenges and future directions of gait analysis and AI research are discussed, which will also provide valuable reference information for investors in this field.},
  archive      = {J_FROBT},
  author       = {Bao, Tong and Gao, Jiasi and Wang, Jinyi and Chen, Yang and Xu, Feng and Qiao, Guanzhong and Li, Fei},
  doi          = {10.3389/frobt.2023.1265543},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1265543},
  shortjournal = {Front. Robot. AI},
  title        = {A global bibliometric and visualized analysis of gait analysis and artificial intelligence research from 1992 to 2022},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stereotypical nationality representations in HRI:
Perspectives from international young adults. <em>FROBT</em>,
<em>10</em>, 1264614. (<a
href="https://doi.org/10.3389/frobt.2023.1264614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {People often form immediate expectations about other people, or groups of people, based on visual appearance and characteristics of their voice and speech. These stereotypes, often inaccurate or overgeneralized, may translate to robots that carry human-like qualities. This study aims to explore if nationality-based preconceptions regarding appearance and accents can be found in people’s perception of a virtual and a physical social robot. In an online survey with 80 subjects evaluating different first-language-influenced accents of English and nationality-influenced human-like faces for a virtual robot, we find that accents, in particular, lead to preconceptions on perceived competence and likeability that correspond to previous findings in social science research. In a physical interaction study with 74 participants, we then studied if the perception of competence and likeability is similar after interacting with a robot portraying one of four different nationality representations from the online survey. We find that preconceptions on national stereotypes that appeared in the online survey vanish or are overshadowed by factors related to general interaction quality. We do, however, find some effects of the robot’s stereotypical alignment with the subject group, with Swedish subjects (the majority group in this study) rating the Swedish-accented robot as less competent than the international group, but, on the other hand, recalling more facts from the Swedish robot’s presentation than the international group does. In an extension in which the physical robot was replaced by a virtual robot interacting in the same scenario online, we further found the same results that preconceptions are of less importance after actual interactions, hence demonstrating that the differences in the ratings of the robot between the online survey and the interaction is not due to the interaction medium. We hence conclude that attitudes towards stereotypical national representations in HRI have a weak effect, at least for the user group included in this study (primarily educated young students in an international setting).},
  archive      = {J_FROBT},
  author       = {Cumbal, Ronald and Axelsson, Agnes and Mehta, Shivam and Engwall, Olov},
  doi          = {10.3389/frobt.2023.1264614},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1264614},
  shortjournal = {Front. Robot. AI},
  title        = {Stereotypical nationality representations in HRI: Perspectives from international young adults},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development and validation of a device for monitoring
laryngeal motion during swallowing. <em>FROBT</em>, <em>10</em>,
1259257. (<a href="https://doi.org/10.3389/frobt.2023.1259257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objectives: Hyolaryngeal movement during swallowing is essential to airway protection and bolus clearance. Although palpation is widely used to evaluate hyolaryngeal motion, insufficient accuracy has been reported. The Bando Stretchable Strain Sensor for Swallowing (B4S™) was developed to capture hyolaryngeal elevation and display it as waveforms. This study compared laryngeal movement time detected by the B4S™ with laryngeal movement time measured by videofluoroscopy (VF).Methods: Participants were 20 patients without swallowing difficulty (10 men, 10 women; age 30.6 ± 7.1 years). The B4S™ was attached to the anterior neck and two saliva swallows were measured on VF images to determine the relative and absolute reliability of laryngeal elevation time measured on VF and that measured by the B4S™.Results: The intra-class correlation coefficient of the VF and B4S™ times was very high [ICC (1.1) = 0.980]. A Bland–Altman plot showed a strong positive correlation with a 95% confidence interval of 0.00–3.01 for the mean VF time and mean B4S™ time, with a fixed error detected in the positive direction but with no proportional error detected. Thus, the VF and B4S™ time measurements showed high consistency.Conclusion: The strong relative and absolute reliability suggest that the B4S™ can accurately detect the duration of superior-inferior laryngeal motion during swallowing. Further study is needed to develop a method for measuring the distance of laryngeal elevation. It is also necessary to investigate the usefulness of this device for evaluation and treatment in clinical settings.},
  archive      = {J_FROBT},
  author       = {Aihara, Keiko and Inamoto, Yoko and Saitoh, Eiichi and Shibata, Seiko and Sato, Yuriko and Harada, Maki and Otaka, Yohei},
  doi          = {10.3389/frobt.2023.1259257},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1259257},
  shortjournal = {Front. Robot. AI},
  title        = {Development and validation of a device for monitoring laryngeal motion during swallowing},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Earwig-inspired foldable origami wing for micro air vehicle
gliding. <em>FROBT</em>, <em>10</em>, 1255666. (<a
href="https://doi.org/10.3389/frobt.2023.1255666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foldable wings serve as an effective solution for reducing the size of micro air vehicles (MAVs) during non-flight phases, without compromising the gliding capacity provided by the wing area. Among insects, earwigs exhibit the highest folding ratio in their wings. Inspired by the intricate folding mechanism in earwig hindwings, we aimed to develop artificial wings with similar high-folding ratios. By leveraging an origami hinge, which is a compliant mechanism, we successfully designed and prototyped wings capable of opening and folding in the wind, which helps reduce the surface area by a factor of seven. The experimental evaluation involved measuring the lift force generated by the wings under Reynolds numbers less than 2.2 × 104. When in the open position, our foldable wings demonstrated increased lift force proportional to higher wind speeds. Properties such as wind responsiveness, efficient folding ratios, and practical feasibility highlight the potential of these wings for diverse applications in MAVs.},
  archive      = {J_FROBT},
  author       = {Ishiguro, Risa and Kawasetsu, Takumi and Motoori, Yutaro and Paik, Jamie and Hosoda, Koh},
  doi          = {10.3389/frobt.2023.1255666},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1255666},
  shortjournal = {Front. Robot. AI},
  title        = {Earwig-inspired foldable origami wing for micro air vehicle gliding},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robotic world models—conceptualization, review, and
engineering best practices. <em>FROBT</em>, <em>10</em>, 1253049. (<a
href="https://doi.org/10.3389/frobt.2023.1253049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The term “world model” (WM) has surfaced several times in robotics, for instance, in the context of mobile manipulation, navigation and mapping, and deep reinforcement learning. Despite its frequent use, the term does not appear to have a concise definition that is consistently used across domains and research fields. In this review article, we bootstrap a terminology for WMs, describe important design dimensions found in robotic WMs, and use them to analyze the literature on WMs in robotics, which spans four decades. Throughout, we motivate the need for WMs by using principles from software engineering, including “Design for use,” “Do not repeat yourself,” and “Low coupling, high cohesion.” Concrete design guidelines are proposed for the future development and implementation of WMs. Finally, we highlight similarities and differences between the use of the term “world model” in robotic mobile manipulation and deep reinforcement learning.},
  archive      = {J_FROBT},
  author       = {Sakagami, Ryo and Lay, Florian S. and Dömel, Andreas and Schuster, Martin J. and Albu-Schäffer, Alin and Stulp, Freek},
  doi          = {10.3389/frobt.2023.1253049},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1253049},
  shortjournal = {Front. Robot. AI},
  title        = {Robotic world models—conceptualization, review, and engineering best practices},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The effect of human autonomy and robot work pace on
perceived workload in human-robot collaborative assembly work.
<em>FROBT</em>, <em>10</em>, 1244656. (<a
href="https://doi.org/10.3389/frobt.2023.1244656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative robots (in short: cobots) have the potential to assist workers with physically or cognitive demanding tasks. However, it is crucial to recognize that such assistance can have both positive and negative effects on job quality. A key aspect of human-robot collaboration is the interdependence between human and robotic tasks. This interdependence influences the autonomy of the operator and can impact the work pace, potentially leading to a situation where the human’s work pace becomes reliant on that of the robot. Given that autonomy and work pace are essential determinants of job quality, design decisions concerning these factors can greatly influence the overall success of a robot implementation. The impact of autonomy and work pace was systematically examined through an experimental study conducted in an industrial assembly task. 20 participants engaged in collaborative work with a robot under three conditions: human lead (HL), fast-paced robot lead (FRL), and slow-paced robot lead (SRL). Perceived workload was used as a proxy for job quality. To assess the perceived workload associated with each condition was assessed with the NASA Task Load Index (TLX). Specifically, the study aimed to evaluate the role of human autonomy by comparing the perceived workload between HL and FRL conditions, as well as the influence of robot pace by comparing SRL and FRL conditions. The findings revealed a significant correlation between a higher level of human autonomy and a lower perceived workload. Furthermore, a decrease in robot pace was observed to result in a reduction of two specific factors measuring perceived workload, namely cognitive and temporal demand. These results suggest that interventions aimed at increasing human autonomy and appropriately adjusting the robot’s work pace can serve as effective measures for optimizing the perceived workload in collaborative scenarios.},
  archive      = {J_FROBT},
  author       = {van Dijk, Wietse and Baltrusch, Saskia J. and Dessers, Ezra and de Looze, Michiel P.},
  doi          = {10.3389/frobt.2023.1244656},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1244656},
  shortjournal = {Front. Robot. AI},
  title        = {The effect of human autonomy and robot work pace on perceived workload in human-robot collaborative assembly work},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Invoking and identifying task-oriented interlocutor
confusion in human-robot interaction. <em>FROBT</em>, <em>10</em>,
1244381. (<a href="https://doi.org/10.3389/frobt.2023.1244381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Successful conversational interaction with a social robot requires not only an assessment of a user’s contribution to an interaction, but also awareness of their emotional and attitudinal states as the interaction unfolds. To this end, our research aims to systematically trigger, but then interpret human behaviors to track different states of potential user confusion in interaction so that systems can be primed to adjust their policies in light of users entering confusion states. In this paper, we present a detailed human-robot interaction study to prompt, investigate, and eventually detect confusion states in users. The study itself employs a Wizard-of-Oz (WoZ) style design with a Pepper robot to prompt confusion states for task-oriented dialogues in a well-defined manner. The data collected from 81 participants includes audio and visual data, from both the robot’s perspective and the environment, as well as participant survey data. From these data, we evaluated the correlations of induced confusion conditions with multimodal data, including eye gaze estimation, head pose estimation, facial emotion detection, silence duration time, and user speech analysis—including emotion and pitch analysis. Analysis shows significant differences of participants’ behaviors in states of confusion based on these signals, as well as a strong correlation between confusion conditions and participants own self-reported confusion scores. The paper establishes strong correlations between confusion levels and these observable features, and lays the ground or a more complete social and affect oriented strategy for task-oriented human-robot interaction. The contributions of this paper include the methodology applied, dataset, and our systematic analysis.},
  archive      = {J_FROBT},
  author       = {Li, Na and Ross, Robert},
  doi          = {10.3389/frobt.2023.1244381},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1244381},
  shortjournal = {Front. Robot. AI},
  title        = {Invoking and identifying task-oriented interlocutor confusion in human-robot interaction},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Should robots be polite? Expectations about politeness in
human–robot interaction. <em>FROBT</em>, <em>10</em>, 1242127. (<a
href="https://doi.org/10.3389/frobt.2023.1242127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interaction with artificial social agents is often designed based on models of human interaction and dialogue. While this is certainly useful for basic interaction mechanisms, it has been argued that social communication strategies and social language use, a “particularly human” ability, may not be appropriate and transferable to interaction with artificial conversational agents. In this paper, we present qualitative research exploring whether users expect artificial agents to use politeness—a fundamental mechanism of social communication—in language-based human-robot interaction. Based on semi-structured interviews, we found that humans mostly ascribe a functional, rule-based use of polite language to humanoid robots and do not expect them to apply socially motivated politeness strategies that they expect in human interaction. This study 1) provides insights for interaction design for social robots’ politeness use from a user perspective, and 2) contributes to politeness research based on the analysis of our participants’ perspectives on politeness.},
  archive      = {J_FROBT},
  author       = {Lumer, Eleonore and Buschmeier, Hendrik},
  doi          = {10.3389/frobt.2023.1242127},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1242127},
  shortjournal = {Front. Robot. AI},
  title        = {Should robots be polite? expectations about politeness in human–robot interaction},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review on model-based and model-free approaches to control
soft actuators and their potentials in colonoscopy. <em>FROBT</em>,
<em>10</em>, 1236706. (<a
href="https://doi.org/10.3389/frobt.2023.1236706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colorectal cancer (CRC) is the third most common cancer worldwide and responsible for approximately 1 million deaths annually. Early screening is essential to increase the chances of survival, and it can also reduce the cost of treatments for healthcare centres. Colonoscopy is the gold standard for CRC screening and treatment, but it has several drawbacks, including difficulty in manoeuvring the device, patient discomfort, and high cost. Soft endorobots, small and compliant devices thatcan reduce the force exerted on the colonic wall, offer a potential solution to these issues. However, controlling these soft robots is challenging due to their deformable materials and the limitations of mathematical models. In this Review, we discuss model-free and model-based approaches for controlling soft robots that can potentially be applied to endorobots for colonoscopy. We highlight the importance of selecting appropriate control methods based on various parameters, such as sensor and actuator solutions. This review aims to contribute to the development of smart control strategies for soft endorobots that can enhance the effectiveness and safety of robotics in colonoscopy. These strategies can be defined based on the available information about the robot and surrounding environment, control demands, mechanical design impact and characterization data based on calibration.},
  archive      = {J_FROBT},
  author       = {Asgari, Motahareh and Magerand, Ludovic and Manfredi, Luigi},
  doi          = {10.3389/frobt.2023.1236706},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1236706},
  shortjournal = {Front. Robot. AI},
  title        = {A review on model-based and model-free approaches to control soft actuators and their potentials in colonoscopy},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Socially, culturally and contextually aware
robots. <em>FROBT</em>, <em>10</em>, 1232215. (<a
href="https://doi.org/10.3389/frobt.2023.1232215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Engwall, Olov and Bandera Rubio, Juan Pedro and Bensch, Suna and Haring, Kerstin Sophie and Kanda, Takayuki and Núñez, Pedro and Rehm, Matthias and Sgorbissa, Antonio},
  doi          = {10.3389/frobt.2023.1232215},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1232215},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Socially, culturally and contextually aware robots},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Augmented feedback modes during functional grasp training
with an intelligent glove and virtual reality for persons with traumatic
brain injury. <em>FROBT</em>, <em>10</em>, 1230086. (<a
href="https://doi.org/10.3389/frobt.2023.1230086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Physical therapy is crucial to rehabilitating hand function needed for activities of daily living after neurological traumas such as traumatic brain injury (TBI). Virtual reality (VR) can motivate participation in motor rehabilitation therapies. This study examines how multimodal feedback in VR to train grasp-and-place function will impact the neurological and motor responses in TBI participants (n = 7) compared to neurotypicals (n = 13).Methods: We newly incorporated VR with our existing intelligent glove system to seamlessly enhance the augmented visual and audio feedback to inform participants about grasp security. We then assessed how multimodal feedback (audio plus visual cues) impacted electroencephalography (EEG) power, grasp-and-place task performance (motion pathlength, completion time), and electromyography (EMG) measures.Results: After training with multimodal feedback, electroencephalography (EEG) alpha power significantly increased for TBI and neurotypical groups. However, only the TBI group demonstrated significantly improved performance or significant shifts in EMG activity.Discussion: These results suggest that the effectiveness of motor training with augmented sensory feedback will depend on the nature of the feedback and the presence of neurological dysfunction. Specifically, adding sensory cues may better consolidate early motor learning when neurological dysfunction is present. Computerized interfaces such as virtual reality offer a powerful platform to personalize rehabilitative training and improve functional outcomes based on neuropathology.},
  archive      = {J_FROBT},
  author       = {Liu, Mingxiao and Wilder, Samuel and Sanford, Sean and Glassen, Michael and Dewil, Sophie and Saleh, Soha and Nataraj, Raviraj},
  doi          = {10.3389/frobt.2023.1230086},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1230086},
  shortjournal = {Front. Robot. AI},
  title        = {Augmented feedback modes during functional grasp training with an intelligent glove and virtual reality for persons with traumatic brain injury},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Do robots outperform humans in human-centered domains?
<em>FROBT</em>, <em>10</em>, 1223946. (<a
href="https://doi.org/10.3389/frobt.2023.1223946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The incessant progress of robotic technology and rationalization of human manpower induces high expectations in society, but also resentment and even fear. In this paper, we present a quantitative normalized comparison of performance, to shine a light onto the pressing question, “How close is the current state of humanoid robotics to outperforming humans in their typical functions (e.g., locomotion, manipulation), and their underlying structures (e.g., actuators/muscles) in human-centered domains?” This is the most comprehensive comparison of the literature so far. Most state-of-the-art robotic structures required for visual, tactile, or vestibular perception outperform human structures at the cost of slightly higher mass and volume. Electromagnetic and fluidic actuation outperform human muscles w.r.t. speed, endurance, force density, and power density, excluding components for energy storage and conversion. Artificial joints and links can compete with the human skeleton. In contrast, the comparison of locomotion functions shows that robots are trailing behind in energy efficiency, operational time, and transportation costs. Robots are capable of obstacle negotiation, object manipulation, swimming, playing soccer, or vehicle operation. Despite the impressive advances of humanoid robots in the last two decades, current robots are not yet reaching the dexterity and versatility to cope with more complex manipulation and locomotion tasks (e.g., in confined spaces). We conclude that state-of-the-art humanoid robotics is far from matching the dexterity and versatility of human beings. Despite the outperforming technical structures, robot functions are inferior to human ones, even with tethered robots that could place heavy auxiliary components off-board. The persistent advances in robotics let us anticipate the diminishing of the gap.},
  archive      = {J_FROBT},
  author       = {Riener, Robert and Rabezzana, Luca and Zimmermann, Yves},
  doi          = {10.3389/frobt.2023.1223946},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1223946},
  shortjournal = {Front. Robot. AI},
  title        = {Do robots outperform humans in human-centered domains?},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vision-based safe autonomous UAV docking with panoramic
sensors. <em>FROBT</em>, <em>10</em>, 1223157. (<a
href="https://doi.org/10.3389/frobt.2023.1223157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The remarkable growth of unmanned aerial vehicles (UAVs) has also sparked concerns about safety measures during their missions. To advance towards safer autonomous aerial robots, this work presents a vision-based solution to ensuring safe autonomous UAV landings with minimal infrastructure. During docking maneuvers, UAVs pose a hazard to people in the vicinity. In this paper, we propose the use of a single omnidirectional panoramic camera pointing upwards from a landing pad to detect and estimate the position of people around the landing area. The images are processed in real-time in an embedded computer, which communicates with the onboard computer of approaching UAVs to transition between landing, hovering or emergency landing states. While landing, the ground camera also aids in finding an optimal position, which can be required in case of low-battery or when hovering is no longer possible. We use a YOLOv7-based object detection model and a XGBooxt model for localizing nearby people, and the open-source ROS and PX4 frameworks for communication, interfacing, and control of the UAV. We present both simulation and real-world indoor experimental results to show the efficiency of our methods.},
  archive      = {J_FROBT},
  author       = {Nguyen, Phuoc Thuan and Westerlund, Tomi and Peña Queralta, Jorge},
  doi          = {10.3389/frobt.2023.1223157},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1223157},
  shortjournal = {Front. Robot. AI},
  title        = {Vision-based safe autonomous UAV docking with panoramic sensors},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Social robot for older adults with cognitive decline: A
preliminary trial. <em>FROBT</em>, <em>10</em>, 1213705. (<a
href="https://doi.org/10.3389/frobt.2023.1213705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The number of older adults living alone is rapidly increasing. Loneliness in older adults not only degrade their quality of life but also causes troubles such as heavy burden on the medical staff, especially when cognitive decline is present. Social robots could be used in several ways to reduce such problems. As a first step towards this goal, we introduced conversation robots into the homes of older adults with cognitive decline to evaluate the robot’s availability and acceptance during several months. The study involved two steps, one for evaluating the robustness of the proposed robotic system, and the second one to examine the long-term acceptance of social robots by older adults with cognitive decline living alone. Our data shows that after several weeks of human-robot interaction, the participants continued to use the robot and successfully integrated them into their lives. These results open the possibility of further research involving how sustained interaction can be achieved, as well as which factors contributed to the acceptance of the robot.},
  archive      = {J_FROBT},
  author       = {Figueroa, David and Yamazaki, Ryuji and Nishio, Shuichi and Maalouly, Elie and Nagata, Yuma and Satake, Yuto and Yamakawa, Miyae and Suzuki, Maki and Kanemoto, Hideki and Ikeda, Manabu and Ishiguro, Hiroshi},
  doi          = {10.3389/frobt.2023.1213705},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1213705},
  shortjournal = {Front. Robot. AI},
  title        = {Social robot for older adults with cognitive decline: A preliminary trial},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modeling multi-contact point physical interaction between
the anthropomorphic finger and soft robotic exo-digit for wearable
rehabilitation robotics applications. <em>FROBT</em>, <em>10</em>,
1209609. (<a href="https://doi.org/10.3389/frobt.2023.1209609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Effective control of rehabilitation robots requires considering the distributed and multi-contact point physical human–robot interaction and users’ biomechanical variation. This paper presents a quasi-static model for the motion of a soft robotic exo-digit while physically interacting with an anthropomorphic finger model for physical therapy.Methods: Quasi-static analytical models were developed for modeling the motion of the soft robot, the anthropomorphic finger, and their coupled physical interaction. An intertwining of kinematics and quasi-static motion was studied to model the distributed (multiple contact points) interaction between the robot and a human finger model. The anthropomorphic finger was modeled as an articulated multi-rigid body structure with multi-contact point interaction. The soft robot was modeled as an articulated hybrid soft-and-rigid model with a constant bending curvature and a constant length for each soft segment. A hyperelastic constitute model based on Yeoh’s 3rdorder material model was used for modeling the soft elastomer. The developed models were experimentally evaluated for 1) free motion of individual soft actuators and 2) constrained motion of the soft robotic exo-digit and anthropomorphic finger model.Results and Discussion: Simulation and experimental results were compared for performance evaluations. The theoretical and experimental results were in agreement for free motion, and the deviation from the constrained motion was in the range of the experimental errors. The outcomes also provided an insight into the importance of considering lengthening for the soft actuators.},
  archive      = {J_FROBT},
  author       = {Alam, Umme Kawsar and Shedd, Kassidy and Kirkland, Joshua and Yaksich, Kayla and Haghshenas-Jaryani, Mahdi},
  doi          = {10.3389/frobt.2023.1209609},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1209609},
  shortjournal = {Front. Robot. AI},
  title        = {Modeling multi-contact point physical interaction between the anthropomorphic finger and soft robotic exo-digit for wearable rehabilitation robotics applications},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time robot topological localization and mapping with
limited visual sampling in simulated buried pipe networks.
<em>FROBT</em>, <em>10</em>, 1202568. (<a
href="https://doi.org/10.3389/frobt.2023.1202568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Our work introduces a real-time robotic localization and mapping system for buried pipe networks.Methods: The system integrates non-vision-based exploration and navigation with an active-vision-based localization and topological mapping algorithm. This algorithm is selectively activated at topologically key locations, such as junctions. Non-vision-based sensors are employed to detect junctions, minimizing the use of visual data and limiting the number of images taken within junctions.Results: The primary aim is to provide an accurate and efficient mapping of the pipe network while ensuring real-time performance and reduced computational requirements.Discussion: Simulation results featuring robots with fully autonomous control in a virtual pipe network environment are presented. These simulations effectively demonstrate the feasibility of our approach in principle, offering a practical solution for mapping and localization in buried pipes.},
  archive      = {J_FROBT},
  author       = {Li, Xiangyu S. and Nguyen, T. L. and Cohn, Anthony G. and Dogar, Mehmet and Cohen, Netta},
  doi          = {10.3389/frobt.2023.1202568},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1202568},
  shortjournal = {Front. Robot. AI},
  title        = {Real-time robot topological localization and mapping with limited visual sampling in simulated buried pipe networks},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Bio-inspired soft locomotion. <em>FROBT</em>,
<em>10</em>, 1291839. (<a
href="https://doi.org/10.3389/frobt.2023.1291839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Ozcan, Onur and Reis, Murat and Nurzaman, Surya G.},
  doi          = {10.3389/frobt.2023.1291839},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1291839},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Bio-inspired soft locomotion},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Safety in close human-robot interaction.
<em>FROBT</em>, <em>10</em>, 1288713. (<a
href="https://doi.org/10.3389/frobt.2023.1288713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Valori, Marcello and Prange-Lasonder, Gerdienke and Saenz, José and Behrens, Roland and Bidard, Catherine and Lucet, Eric and Fassi, Irene},
  doi          = {10.3389/frobt.2023.1288713},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1288713},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Safety in close human-robot interaction},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Emerging technologies for assistive robotics:
Current challenges and perspectives. <em>FROBT</em>, <em>10</em>,
1288360. (<a href="https://doi.org/10.3389/frobt.2023.1288360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Alboul, Lyuba and Dimitrova, Maya and Lekova, Anna and Kaburlasos, Vassilis George and Mitrouchev, Peter},
  doi          = {10.3389/frobt.2023.1288360},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1288360},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: emerging technologies for assistive robotics: current challenges and perspectives},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient human 3D localization and free space segmentation
for human-aware mobile robots in warehouse facilities. <em>FROBT</em>,
<em>10</em>, 1283322. (<a
href="https://doi.org/10.3389/frobt.2023.1283322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time prediction of human location combined with the capability to perceive obstacles is crucial for socially-aware navigation in robotics. Our work focuses on localizing humans in the world and predicting the free space around them by incorporating other static and dynamic obstacles. We propose a multi-task learning strategy to handle both tasks, achieving this goal with minimal computational demands. We use a dataset captured in a typical warehouse environment by mounting a perception module consisting of a Jetson Xavier AGX and an Intel L515 LiDAR camera on a MiR100 mobile robot. Our method, which is built upon prior works in the field of human detection and localization demonstrates improved results in difficult cases that are not tackled in other works, such as human instances at a close distance or at the limits of the field of view of the capturing sensor. We further extend this work by using a lightweight network structure and integrating a free space segmentation branch that can independently segment the floor space without any prior maps or 3D data, relying instead on the characteristics of the floor. In conclusion, our method presents a lightweight and efficient solution for predicting human 3D location and segmenting the floor space for low-energy consumption platforms, tested in an industrial environment.},
  archive      = {J_FROBT},
  author       = {Arapis, Dimitrios and Jami, Milad and Nalpantidis, Lazaros},
  doi          = {10.3389/frobt.2023.1283322},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1283322},
  shortjournal = {Front. Robot. AI},
  title        = {Efficient human 3D localization and free space segmentation for human-aware mobile robots in warehouse facilities},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hidden markov models for presence detection based on CO2
fluctuations. <em>FROBT</em>, <em>10</em>, 1280745. (<a
href="https://doi.org/10.3389/frobt.2023.1280745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presence sensing systems are gaining importance and are utilized in various contexts such as smart homes, Ambient Assisted Living (AAL) and surveillance technology. Typically, these systems utilize motion sensors or cameras that have a limited field of view, leading to potential monitoring gaps within a room. However, humans release carbon dioxide (CO2) through respiration which spreads within an enclosed space. Consequently, an observable rise in CO2 concentration is noted when one or more individuals are present in a room. This study examines an approach to detect the presence or absence of individuals indoors by analyzing the ambient air’s CO2 concentration using simple Markov Chain Models. The proposed scheme achieved an accuracy of up to 97% in both experimental and real data demonstrating its efficacy in practical scenarios.},
  archive      = {J_FROBT},
  author       = {Karasoulas, Christos and Keroglou, Christoforos and Katsiri, Eleftheria and Sirakoulis, Georgios Ch.},
  doi          = {10.3389/frobt.2023.1280745},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1280745},
  shortjournal = {Front. Robot. AI},
  title        = {Hidden markov models for presence detection based on CO2 fluctuations},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). OSH related risks and opportunities for industrial
human-robot interaction: Results from literature and practice.
<em>FROBT</em>, <em>10</em>, 1277360. (<a
href="https://doi.org/10.3389/frobt.2023.1277360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic systems are an integral component of today’s work place automation, especially in industrial settings. Due to technological advancements, we see new forms of human-robot interaction emerge which are related to different OSH risks and benefits. We present a multifaceted analysis of risks and opportunities regarding robotic systems in the context of task automation in the industrial sector. This includes the scientific perspective through literature review as well as the workers’ expectations in form of use case evaluations. Based on the results, with regards to human-centred workplace design and occupational safety and health (OSH), implications for the practical application are derived and presented. For the literature review a selected subset of papers from a systematic review was extracted. Five systematic reviews and meta-analysis (492 primary studies) focused on the topic of task automation via robotic systems and OSH. These were extracted and categorised into physical, psychosocial and organisational factors based on an OSH-factors framework for advanced robotics developed for the European Agency for Safety and Health at Work (EU-OSHA). To assess the workers’ perspective, 27 workers from three European manufacturing companies were asked about their expectations regarding benefits and challenges of robotic systems at their workplace. The answers were translated and categorised in accordance with the framework as well. The statements, both from literature and the survey were then analysed according to the qualitative content analysis, to gain additional insight into the underlying structure and trends in them. As a result, new categories were formed deductively. The analysis showed that the framework is capable to help categorise both findings from literature and worker survey into basic categories with good interrater reliability. Regarding the proposed subcategories however, it failed to reflect the complexity of the workers’ expectations. The results of the worker evaluation as well as literature findings both predominantly highlight the psychosocial impact these systems may have on workers. Organisational risks or changes are underrepresented in both groups. Workers’ initial expectations lean towards a positive impact.},
  archive      = {J_FROBT},
  author       = {Heinold, Eva and Funk, Miriam and Niehaus, Susanne and Rosen, Patricia H. and Wischniewski, Sascha},
  doi          = {10.3389/frobt.2023.1277360},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1277360},
  shortjournal = {Front. Robot. AI},
  title        = {OSH related risks and opportunities for industrial human-robot interaction: Results from literature and practice},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Translational research in medical
robotics—challenges and opportunities. <em>FROBT</em>, <em>10</em>,
1270823. (<a href="https://doi.org/10.3389/frobt.2023.1270823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Dagnino, Giulio and Kundrat, Dennis and Moreira, Pedro and Wurdemann, Helge Arne and Abayazid, Momen},
  doi          = {10.3389/frobt.2023.1270823},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1270823},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Translational research in medical robotics—challenges and opportunities},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel socially assistive robotic platform for
cognitive-motor exercises for individuals with parkinson’s disease: A
participatory-design study from conception to feasibility testing with
end users. <em>FROBT</em>, <em>10</em>, 1267458. (<a
href="https://doi.org/10.3389/frobt.2023.1267458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The potential of socially assistive robots (SAR) to assist in rehabilitation has been demonstrated in contexts such as stroke and cardiac rehabilitation. Our objective was to design and test a platform that addresses specific cognitive-motor training needs of individuals with Parkinson’s disease (IwPD). We used the participatory design approach, and collected input from a total of 62 stakeholders (IwPD, their family members and clinicians) in interviews, brainstorming sessions and in-lab feasibility testing of the resulting prototypes. The platform we developed includes two custom-made mobile desktop robots, which engage users in concurrent cognitive and motor tasks. IwPD (n = 16) reported high levels of enjoyment when using the platform (median = 5/5) and willingness to use the platform in the long term (median = 4.5/5). We report the specifics of the hardware and software design as well as the detailed input from the stakeholders.},
  archive      = {J_FROBT},
  author       = {Raz, Dor and Barkan-Slater, Shirel and Baum-Cohen, Ilanit and Vissel, Gal and Lahav-Raz, Yeela and Shapiro, Amir and Levy-Tzedek, Shelly},
  doi          = {10.3389/frobt.2023.1267458},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1267458},
  shortjournal = {Front. Robot. AI},
  title        = {A novel socially assistive robotic platform for cognitive-motor exercises for individuals with parkinson&#39;s disease: A participatory-design study from conception to feasibility testing with end users},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Non-contact robotic manipulation of floating objects:
Exploiting emergent limit cycles. <em>FROBT</em>, <em>10</em>, 1267019.
(<a href="https://doi.org/10.3389/frobt.2023.1267019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of non-contact manipulation in water, and the ability to robotically control floating objects has gained recent attention due to wide-ranging potential applications, including the analysis of plastic pollution in the oceans and the optimization of procedures in food processing plants. However, modeling floating object movements can be complex, as their trajectories are influenced by various factors such as the object’s shape, size, mass, and the magnitude, frequency, and patterns of water waves. This study proposes an experimental investigation into the emergence ofrobotically controlled limit cycles in the movement of floating objects within a closed environment. The objects’ movements are driven by robot fins, and the experiment plan set up involves the use of up to four fins and variable motor parameters. By combining energy quantification of the system with an open-loop pattern generation, it is possible to demonstrate all main water-object interactions within the enclosed environment. A study using dynamic time warping around floating patterns gives insights on possible further studies.},
  archive      = {J_FROBT},
  author       = {Jacquart, Sylvain and Obayashi, Nana and Hughes, Josie},
  doi          = {10.3389/frobt.2023.1267019},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1267019},
  shortjournal = {Front. Robot. AI},
  title        = {Non-contact robotic manipulation of floating objects: Exploiting emergent limit cycles},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Tracing a new path in the field of AI and robotics:
Mimicking human intelligence through chemistry. Part II: Systems
chemistry. <em>FROBT</em>, <em>10</em>, 1266011. (<a
href="https://doi.org/10.3389/frobt.2023.1266011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by some traits of human intelligence, it is proposed that wetware approaches based on molecular, supramolecular, and systems chemistry can provide valuable models and tools for novel forms of robotics and AI, being constituted by soft matter and fluid states as the human nervous system and, more generally, life, is. Bottom-up mimicries of intelligence range from the molecular world to the multicellular level, i.e., from the Ångström (&lt;mml:math id=&quot;m1&quot; xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msup&gt;&lt;mml:mn&gt;10&lt;/mml:mn&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mn&gt;10&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt; meters) to the micrometer scales (&lt;mml:math id=&quot;m2&quot; xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msup&gt;&lt;mml:mn&gt;10&lt;/mml:mn&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mn&gt;6&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt; meters), and allows the development of unconventional chemical robotics. Whereas conventional robotics lets humans explore and colonise otherwise inaccessible environments, such as the deep oceanic abysses and other solar system planets, chemical robots will permit us to inspect and control the microscopic molecular and cellular worlds. This article suggests that systems made of properly chosen molecular compounds can implement all those modules that are the fundamental ingredients of every living being: sensory, processing, actuating, and metabolic networks. Autonomous chemical robotics will be within reach when such modules are compartmentalised and assembled. The design of a strongly intertwined web of chemical robots, with or without the involvement of living matter, will give rise to collective forms of intelligence that will probably reproduce, on a minimal scale, some sophisticated performances of the human intellect and will implement forms of “general AI.” These remarkable achievements will require a productive interdisciplinary collaboration among chemists, biotechnologists, computer scientists, engineers, physicists, neuroscientists, cognitive scientists, and philosophers to be achieved. The principal purpose of this paper is to spark this revolutionary collaborative scientific endeavour.},
  archive      = {J_FROBT},
  author       = {Gentili, Pier Luigi and Stano, Pasquale},
  doi          = {10.3389/frobt.2023.1266011},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1266011},
  shortjournal = {Front. Robot. AI},
  title        = {Tracing a new path in the field of AI and robotics: mimicking human intelligence through chemistry. part II: systems chemistry},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Zero-shot model-free learning of periodic movements for a
bio-inspired soft-robotic arm. <em>FROBT</em>, <em>10</em>, 1256763. (<a
href="https://doi.org/10.3389/frobt.2023.1256763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, soft robots gain increasing attention as a result of their compliance when operating in unstructured environments, and their flexibility that ensures safety when interacting with humans. However, challenges lie on the difficulty to develop control algorithms due to various limitations induced by their soft structure. In this paper, we introduce a novel technique that aims to perform motion control of a modular bio-inspired soft-robotic arm, with the main focus lying on facilitating the qualitative reproduction of well-specified periodic trajectories. The introduced method combines the notion behind two previously developed methodologies both based on the Movement Primitive (MP) theory, by exploiting their capabilities while coping with their main drawbacks. Concretely, the requested actuation is initially computed using a Probabilistic MP (ProMP)-based method that considers the trajectory as a combination of simple movements previously learned and stored as a MP library. Subsequently, the key components of the resulting actuation are extracted and filtered in the frequency domain. These are eventually used as input to a Central Pattern Generator (CPG)-based model that takes over the generation of rhythmic patterns at the motor level. The proposed methodology is evaluated on a two-module soft arm. Results show that the first algorithmic component (ProMP) provides an immediate estimation of the requested actuation by avoiding time-consuming training, while the latter (CPG) further simplifies the execution by allowing its control through a low-dimensional parameterization. Altogether, these results open new avenues for the rapid acquisition of periodic movements in soft robots, and their compression into CPG parameters for long-term storage and execution.},
  archive      = {J_FROBT},
  author       = {Oikonomou, Paris and Dometios, Athanasios and Khamassi, Mehdi and Tzafestas, Costas S.},
  doi          = {10.3389/frobt.2023.1256763},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1256763},
  shortjournal = {Front. Robot. AI},
  title        = {Zero-shot model-free learning of periodic movements for a bio-inspired soft-robotic arm},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Terrain-aware semantic mapping for cooperative subterranean
exploration. <em>FROBT</em>, <em>10</em>, 1249586. (<a
href="https://doi.org/10.3389/frobt.2023.1249586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Navigation over torturous terrain such as those in natural subterranean environments presents a significant challenge to field robots. The diversity of hazards, from large boulders to muddy or even partially submerged Earth, eludes complete definition. The challenge is amplified if the presence and nature of these hazards must be shared among multiple agents that are operating in the same space. Furthermore, highly efficient mapping and robust navigation solutions are absolutely critical to operations such as semi-autonomous search and rescue. We propose an efficient and modular framework for semantic grid mapping of subterranean environments. Our approach encodes occupancy and traversability information, as well as the presence of stairways, into a grid map that is distributed amongst a robot fleet despite bandwidth constraints. We demonstrate that the mapping method enables safe and enduring exploration of subterranean environments. The performance of the system is showcased in high-fidelity simulations, physical experiments, and Team MARBLE’s entry in the DARPA Subterranean Challenge which received third place.},
  archive      = {J_FROBT},
  author       = {Miles, Michael J. and Biggie, Harel and Heckman, Christoffer},
  doi          = {10.3389/frobt.2023.1249586},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1249586},
  shortjournal = {Front. Robot. AI},
  title        = {Terrain-aware semantic mapping for cooperative subterranean exploration},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lean back or lean in? Exploring social loafing in
human–robot teams. <em>FROBT</em>, <em>10</em>, 1249252. (<a
href="https://doi.org/10.3389/frobt.2023.1249252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Thanks to technological advances, robots are now being used for a wide range of tasks in the workplace. They are often introduced as team partners to assist workers. This teaming is typically associated with positive effects on work performance and outcomes. However, little is known about whether typical performance-reducing effects that occur in human teams also occur in human–robot teams. For example, it is not clear whether social loafing, defined as reduced individual effort on a task performed in a team compared to a task performed alone, can also occur in human–robot teams.Methods: We investigated this question in an experimental study in which participants worked on an industrial defect inspection task that required them to search for manufacturing defects on circuit boards. One group of participants worked on the task alone, while the other group worked with a robot team partner, receiving boards that had already been inspected by the robot. The robot was quite reliable and marked defects on the boards before handing them over to the human. However, it missed 5 defects. The dependent behavioural measures of interest were effort, operationalised as inspection time and area inspected on the board, and defect detection performance. In addition, subjects rated their subjective effort, performance, and perceived responsibility for the task.Results: Participants in both groups inspected almost the entire board surface, took their time searching, and rated their subjective effort as high. However, participants working in a team with the robot found on average 3.3 defects. People working alone found significantly more defects on these 5 occasions–an average of 4.2.Discussion: This suggests that participants may have searched the boards less attentively when working with a robot team partner. The participants in our study seemed to have maintained the motor effort to search the boards, but it appears that the search was carried out with less mental effort and less attention to the information being sampled. Changes in mental effort are much harder to measure, but need to be minimised to ensure good performance.},
  archive      = {J_FROBT},
  author       = {Cymek, Dietlind Helene and Truckenbrodt, Anna and Onnasch, Linda},
  doi          = {10.3389/frobt.2023.1249252},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1249252},
  shortjournal = {Front. Robot. AI},
  title        = {Lean back or lean in? exploring social loafing in human–robot teams},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mission analysis, dynamics and robust control of an indoor
blimp in a CERN detector magnetic environment. <em>FROBT</em>,
<em>10</em>, 1238081. (<a
href="https://doi.org/10.3389/frobt.2023.1238081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At the European Organization for Nuclear Research (CERN), a Research and Development (R&amp;amp;D) program studies robotic systems for inspection and maintenance of the next-generation of particle detectors. The design and operation of these systems are affected by the detector’s cavern harsh environment consisting of high magnetic fields and radiations. This work presents a feasibility study for aerial inspection and mapping around a CERN particle detector using a robotic Lighter-than-Air (LtA) Unmanned Aerial Vehicle (UAV), specifically a blimp. Firstly, mission scenarios and the detector environment are introduced; in this context a new empirical model is proposed for the estimation of magnetic disturbances resulting from the interaction of electromagnetic motors with the external magnetic field. Subsequently, the design of a reference blimp and the control system is presented, comparing different control techniques, namely, Computed Torque Control (CTC), Sliding Mode Control (SMC) and Nonsingular Terminal Sliding Mode Control (NTSMC). Finally, the results of trajectory tracking simulations are reported, considering both the uncertainties of the dynamic parameters and the estimated magnetic disturbances. This work demonstrates that the blimp successfully follows desired trajectory, navigating complex environments while maintaining stability and accuracy. Despite the challenges posed by high magnetic fields, indoor blimps can effectively offer safer and more efficient approaches to facility surveillance and maintenance, reducing radiation exposure for human personnel and minimizing detector downtime.},
  archive      = {J_FROBT},
  author       = {Mazzei, Francesco and Teofili, Lorenzo and Curti, Fabio and Gargiulo, Corrado},
  doi          = {10.3389/frobt.2023.1238081},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1238081},
  shortjournal = {Front. Robot. AI},
  title        = {Mission analysis, dynamics and robust control of an indoor blimp in a CERN detector magnetic environment},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scaffolding the human partner by contrastive guidance in an
explanatory human-robot dialogue. <em>FROBT</em>, <em>10</em>, 1236184.
(<a href="https://doi.org/10.3389/frobt.2023.1236184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explanation has been identified as an important capability for AI-based systems, but research on systematic strategies for achieving understanding in interaction with such systems is still sparse. Negation is a linguistic strategy that is often used in explanations. It creates a contrast space between the affirmed and the negated item that enriches explaining processes with additional contextual information. While negation in human speech has been shown to lead to higher processing costs and worse task performance in terms of recall or action execution when used in isolation, it can decrease processing costs when used in context. So far, it has not been considered as a guiding strategy for explanations in human-robot interaction. We conducted an empirical study to investigate the use of negation as a guiding strategy in explanatory human-robot dialogue, in which a virtual robot explains tasks and possible actions to a human explainee to solve them in terms of gestures on a touchscreen. Our results show that negation vs. affirmation 1) increases processing costs measured as reaction time and 2) increases several aspects of task performance. While there was no significant effect of negation on the number of initially correctly executed gestures, we found a significantly lower number of attempts—measured as breaks in the finger movement data before the correct gesture was carried out—when being instructed through a negation. We further found that the gestures significantly resembled the presented prototype gesture more following an instruction with a negation as opposed to an affirmation. Also, the participants rated the benefit of contrastive vs. affirmative explanations significantly higher. Repeating the instructions decreased the effects of negation, yielding similar processing costs and task performance measures for negation and affirmation after several iterations. We discuss our results with respect to possible effects of negation on linguistic processing of explanations and limitations of our study.},
  archive      = {J_FROBT},
  author       = {Groß, André and Singh, Amit and Banh, Ngoc Chi and Richter, Birte and Scharlau, Ingrid and Rohlfing, Katharina J. and Wrede, Britta},
  doi          = {10.3389/frobt.2023.1236184},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1236184},
  shortjournal = {Front. Robot. AI},
  title        = {Scaffolding the human partner by contrastive guidance in an explanatory human-robot dialogue},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integrating intention-based systems in human-robot
interaction: A scoping review of sensors, algorithms, and trust.
<em>FROBT</em>, <em>10</em>, 1233328. (<a
href="https://doi.org/10.3389/frobt.2023.1233328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing adoption of robot systems in industrial settings and teaming with humans have led to a growing interest in human-robot interaction (HRI) research. While many robots use sensors to avoid harming humans, they cannot elaborate on human actions or intentions, making them passive reactors rather than interactive collaborators. Intention-based systems can determine human motives and predict future movements, but their closer interaction with humans raises concerns about trust. This scoping review provides an overview of sensors, algorithms, and examines the trust aspect of intention-based systems in HRI scenarios. We searched MEDLINE, Embase, and IEEE Xplore databases to identify studies related to the forementioned topics of intention-based systems in HRI. Results from each study were summarized and categorized according to different intention types, representing various designs. The literature shows a range of sensors and algorithms used to identify intentions, each with their own advantages and disadvantages in different scenarios. However, trust of intention-based systems is not well studied. Although some research in AI and robotics can be applied to intention-based systems, their unique characteristics warrant further study to maximize collaboration performance. This review highlights the need for more research on the trust aspects of intention-based systems to better understand and optimize their role in human-robot interactions, at the same time establishes a foundation for future research in sensor and algorithm designs for intention-based systems.},
  archive      = {J_FROBT},
  author       = {Zhang, Yifei and Doyle, Thomas},
  doi          = {10.3389/frobt.2023.1233328},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1233328},
  shortjournal = {Front. Robot. AI},
  title        = {Integrating intention-based systems in human-robot interaction: A scoping review of sensors, algorithms, and trust},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). From real-time adaptation to social learning in robot
ecosystems. <em>FROBT</em>, <em>10</em>, 1232708. (<a
href="https://doi.org/10.3389/frobt.2023.1232708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While evolutionary robotics can create novel morphologies and controllers that are well-adapted to their environments, learning is still the most efficient way to adapt to changes that occur on shorter time scales. Learning proposals for evolving robots to date have focused on new individuals either learning a controller from scratch, or building on the experience of direct ancestors and/or robots with similar configurations. Here we propose and demonstrate a novel means for social learning of gait patterns, based on sensorimotor synchronization. Using movement patterns of other robots as input can drive nonlinear decentralized controllers such as CPGs into new limit cycles, hence encouraging diversity of movement patterns. Stable autonomous controllers can then be locked in, which we demonstrate using a quasi-Hebbian feedback scheme. We propose that in an ecosystem of robots evolving in a heterogeneous environment, such a scheme may allow for the emergence of generalist task-solvers from a population of specialists.},
  archive      = {J_FROBT},
  author       = {Szorkovszky, Alex and Veenstra, Frank and Glette, Kyrre},
  doi          = {10.3389/frobt.2023.1232708},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1232708},
  shortjournal = {Front. Robot. AI},
  title        = {From real-time adaptation to social learning in robot ecosystems},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Controlling the motion of gas-lubricated adhesive disks
using multiple vibration sources. <em>FROBT</em>, <em>10</em>, 1231976.
(<a href="https://doi.org/10.3389/frobt.2023.1231976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots capable of generating adhesion forces that can achieve free movement in application environments while overcoming their own gravity are a subject of interest for researchers. A robot with controllable adhesion could be useful in many engineered systems. Materials processing equipment, robots that climb walls, and pick-and-place machines are some examples. However, most adhesion methods either require a large energy supply system or are limited by the properties of the contact plane. For example, electromagnetic adhesion requires a ferromagnetic surface and pneumatic adhesion requires a flat surface. Furthermore, nearly all existing approaches are only used to generate adhesion forces and often require additional mechanisms to remove the adhesive component from the surface. In this study, we aimed to develop a simpler method of adhering to a surface while simultaneously moving in directions parallel to the surface, using multiple vibration sources to generate normal adhesion and propulsion. To test our approach, we constructed circular and elliptical models and conducted experiments with various inputs and model parameters. Our results show that such a gas-lubricated adhesive disk could achieve adhesive rotation and displacement in the plane without requiring any auxiliary operating system. Using only vibration sources, we were able to generate the necessary adhesion and propulsion forces to achieve the desired motion of the robot. This work represents a step towards the construction of a small-sized tetherless robot that can overcome gravity and move freely in a general environment.},
  archive      = {J_FROBT},
  author       = {Jia, Chengzhe and Ramanarayanan, Sankaran and Sanchez, Antonio L. and Tolley, Michael T.},
  doi          = {10.3389/frobt.2023.1231976},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1231976},
  shortjournal = {Front. Robot. AI},
  title        = {Controlling the motion of gas-lubricated adhesive disks using multiple vibration sources},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The MISLI-drive, a modular sterilizable robotic driver for
steerable laparoscopic instruments. <em>FROBT</em>, <em>10</em>,
1227708. (<a href="https://doi.org/10.3389/frobt.2023.1227708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Based on the success of the former “Shaft-Actuated, Tip-Articulated” SATA-Drive, a prototype robotic instrument driver for modular, steerable, laparoscopic instruments, a new driver is designed and tested to improve previously lacking features concerning cleanability, instrument adaptation, practical application and control. The design of the driver engages these issues with a modular design aimed at re-use of both the instrument and the driver, for which a set of design requirements are established.Methods: A new modular design has been developed to improve cleanability through separation of the electro-motors and the instrument mechanism which clutches the instrument. Contamination of the driver’s robotic side is prevented though a combination of a drape and a Sterile barrier interface, while the instrument side is made sterilizable. A novel instrument clutching mechanism enables quick-release features, while a motor-axis latching mechanism enables plug-and-play assembly. Embedded sensors allow precise and fast control. A user-experiment was conducted on instrument exchange and assembly time, while mechanical and electrical tests were conducted on the driver’s responsiveness.Results: The driver has proven its ability to control the instrument, after which it can be disassembled for cleaning and inspection. The driver is designed for re-use through disassembled sterilization where all possibly contaminated surfaces are exposable for cleaning and inspection. The new standardized instrument clutches allow easy instrument (dis-)assembly. Instrument exchange is possible in two methods, the fastest of which is a median of 11 (6.3–14.6) seconds. The driver’s instrument mechanism is separated in a median of 3.7 (1.8–8.1) seconds. After assembly, the driver is operational in less than 2 s.Discussion: Instrument exchange times are similar to the semi-reusable Da Vinci systems, yet the MISLI-Drive is designed for sterilization, inspection and continual re-use. The modular build of the driver also allows easier parts replacement during maintenance, and requires minimal adaptation to different future scenarios, which is expected to reduce the overall cost of use.},
  archive      = {J_FROBT},
  author       = {Lenssen, Tomas and Bîrjac, Radu and Dankelman, Jenny and Horeman, Tim},
  doi          = {10.3389/frobt.2023.1227708},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1227708},
  shortjournal = {Front. Robot. AI},
  title        = {The MISLI-drive, a modular sterilizable robotic driver for steerable laparoscopic instruments},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Playing the pipes: Acoustic sensing and machine learning for
performance feedback during endotracheal intubation simulation.
<em>FROBT</em>, <em>10</em>, 1218174. (<a
href="https://doi.org/10.3389/frobt.2023.1218174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective: In emergency medicine, airway management is a core skill that includes endotracheal intubation (ETI), a common technique that can result in ineffective ventilation and laryngotracheal injury if executed incorrectly. We present a method for automatically generating performance feedback during ETI simulator training, potentially augmenting training outcomes on robotic simulators.Method: Electret microphones recorded ultrasonic echoes pulsed through the complex geometry of a simulated airway during ETI performed on a full-size patient simulator. As the endotracheal tube is inserted deeper and the cuff is inflated, the resulting changes in geometry are reflected in the recorded signal. We trained machine learning models to classify 240 intubations distributed equally between six conditions: three insertion depths and two cuff inflation states. The best performing models were cross validated in a leave-one-subject-out scheme.Results: Best performance was achieved by transfer learning with a convolutional neural network pre-trained for sound classification, reaching global accuracy above 98% on 1-second-long audio test samples. A support vector machine trained on different features achieved a median accuracy of 85% on the full label set and 97% on a reduced label set of tube depth only.Significance: This proof-of-concept study demonstrates a method of measuring qualitative performance criteria during simulated ETI in a relatively simple way that does not damage ecological validity of the simulated anatomy. As traditional sonar is hampered by geometrical complexity compounded by the introduced equipment in ETI, the accuracy of machine learning methods in this confined design space enables application in other invasive procedures. By enabling better interaction between the human user and the robotic simulator, this approach could improve training experiences and outcomes in medical simulation for ETI as well as many other invasive clinical procedures.},
  archive      = {J_FROBT},
  author       = {Steffensen, Torjus L. and Bartnes, Barge and Fuglstad, Maja L. and Auflem, Marius and Steinert, Martin},
  doi          = {10.3389/frobt.2023.1218174},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1218174},
  shortjournal = {Front. Robot. AI},
  title        = {Playing the pipes: Acoustic sensing and machine learning for performance feedback during endotracheal intubation simulation},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sensemaking, adaptation and agency in human-exoskeleton
synchrony. <em>FROBT</em>, <em>10</em>, 1207052. (<a
href="https://doi.org/10.3389/frobt.2023.1207052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Wearable I robots such as exoskeletons combine the strength and precision of intelligent machines with the adaptability and creativity of human beings. Exoskeletons are unique in that humans interact with the technologies on both a physical and cognitive level, and as such, involve a complex, interdependent relationship between humans and robots. The aim of this paper was to explore the concepts of agency and adaptation as they relate to human-machine synchrony, as human users learned to operate a complex whole-body powered exoskeleton.Methods: Qualitative interviews were conducted with participants over multiple sessions in which they performed a range of basic functional tasks and simulated industrial tasks using a powered exoskeleton prototype, to understand their expectations of the human-technology partnership, any challenges that arose in their interaction with the device, and what strategies they used to resolve such challenges.Results: Analysis of the data revealed two overarching themes: 1) Participants faced physical, cognitive, and affective challenges to synchronizing with the exoskeleton; and 2) they engaged in sensemaking strategies such as drawing analogies with known prior experiences and anthropomorphized the exoskeleton as a partner entity in order to adapt and address challenges.Discussion: This research is an important first step to understanding how humans make sense of and adapt to a powerful and complex wearable robot with which they must synchronize in order to perform tasks. Implications for our understanding of human and machine agency as well as bidirectional coadaptation principles are discussed.},
  archive      = {J_FROBT},
  author       = {Wilkenfeld, J. Nan and Kim, Sunwook and Upasani, Satyajit and Kirkwood, Gavin Lawrence and Dunbar, Norah E. and Srinivasan, Divya},
  doi          = {10.3389/frobt.2023.1207052},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1207052},
  shortjournal = {Front. Robot. AI},
  title        = {Sensemaking, adaptation and agency in human-exoskeleton synchrony},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review on self-healing featured soft robotics.
<em>FROBT</em>, <em>10</em>, 1202584. (<a
href="https://doi.org/10.3389/frobt.2023.1202584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft robots are becoming more popular because they can solve issues stiff robots cannot. Soft component and system design have seen several innovations recently. Next-generation robot–human interactions will depend on soft robotics. Soft material technologies integrate safety at the material level, speeding its integration with biological systems. Soft robotic systems must be as resilient as biological systems in unexpected, uncontrolled situations. Self-healing materials, especially polymeric and elastomeric ones, are widely studied. Since most currently under-development soft robotic systems are composed of polymeric or elastomeric materials, this finding may provide immediate assistance to the community developing soft robots. Self-healing and damage-resilient systems are making their way into actuators, structures, and sensors, even if soft robotics remains in its infancy. In the future, self-repairing soft robotic systems composed of polymers might save both money and the environment. Over the last decade, academics and businesses have grown interested in soft robotics. Despite several literature evaluations of the soft robotics subject, there seems to be a lack of systematic research on its intellectual structure and development despite the rising number of articles. This article gives an in-depth overview of the existing knowledge base on damage resistance and self-healing materials’ fundamental structure and classifications. Current uses, problems with future implementation, and solutions to those problems are all included in this overview. Also discussed are potential applications and future directions for self-repairing soft robots.},
  archive      = {J_FROBT},
  author       = {Islam, Md. Ariful and Talukder, Labanya and Al, Md. Firoj and Sarker, Subrata K. and Muyeen, S. M. and Das, Prangon and Hasan, Md. Mehedi and Das, Sajal K. and Islam, Md. Manirul and Islam, Md. Robiul and Moyeen, Sumaya Ishrat and Badal, Faisal R. and Ahamed, Md. Hafiz and Abhi, Sarafat Hussain},
  doi          = {10.3389/frobt.2023.1202584},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1202584},
  shortjournal = {Front. Robot. AI},
  title        = {A review on self-healing featured soft robotics},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). XBot2D: Towards a robotics hybrid cloud architecture for
field robotics. <em>FROBT</em>, <em>10</em>, 1168694. (<a
href="https://doi.org/10.3389/frobt.2023.1168694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, robotics applications requiring the execution of complex tasks in real-world scenarios are still facing many challenges related to highly unstructured and dynamic environments in domains such as emergency response and search and rescue where robots have to operate for prolonged periods trading off computational performance with increased power autonomy and vice versa. In particular, there is a crucial need for robots capable of adapting to such settings while at the same time providing robustness and extended power autonomy. A possible approach to overcome the conflicting demand of a computational performing system with the need for long power autonomy is represented by cloud robotics, which can boost the computational capabilities of the robot while reducing the energy consumption by exploiting the offload of resources to the cloud. Nevertheless, the communication constraint due to limited bandwidth, latency, and connectivity, typical of field robotics, makes cloud-enabled robotics solutions challenging to deploy in real-world applications. In this context, we designed and realized the XBot2D software architecture, which provides a hybrid cloud manager capable of dynamically and seamlessly allocating robotics skills to perform a distributed computation based on the current network condition and the required latency, and computational/energy resources of the robot in use. The proposed framework leverage on the two dimensions, i.e., 2D (local and cloud), in a transparent way for the user, providing support for Real-Time (RT) skills execution on the local robot, as well as machine learning and A.I. resources on the cloud with the possibility to automatically relocate the above based on the required performances and communication quality. XBot2D implementation and its functionalities are presented and validated in realistic tasks involving the CENTAURO robot and the Amazon Web Service Elastic Computing Cloud (AWS EC2) infrastructure with different network conditions.},
  archive      = {J_FROBT},
  author       = {Muratore, Luca and Tsagarakis, Nikos},
  doi          = {10.3389/frobt.2023.1168694},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1168694},
  shortjournal = {Front. Robot. AI},
  title        = {XBot2D: Towards a robotics hybrid cloud architecture for field robotics},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Control and evaluation of a humanoid robot with rolling
contact joints on its lower body. <em>FROBT</em>, <em>10</em>, 1164660.
(<a href="https://doi.org/10.3389/frobt.2023.1164660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a new teen-sized humanoid platform dubbed DRACO 3, custom-built by Apptronik and altered for practical use by the Human Centered Robotics Laboratory at The University of Texas at Austin. The form factor of DRACO 3 is such that it can operate safely in human environments while reaching objects at human heights. To approximate the range of motion of humans, this robot features proximal actuation and mechanical artifacts to provide a high range of hip, knee, and ankle motions. In particular, rolling contact mechanisms on the lower body are incorporated using a proximal actuation principle to provide an extensive vertical pose workspace. To enable DRACO 3 to perform dexterous tasks while dealing with these complex transmissions, we introduce a novel whole-body controller (WBC) incorporating internal constraints to model the rolling motion behavior. In addition, details of our WBC for DRACO 3 are presented with an emphasis on practical points for hardware implementation. We perform a design analysis of DRACO 3, as well as empirical evaluations under the lens of the Centroidal Inertia Isotropy (CII) design metric. Lastly, we experimentally validate our design and controller by testing center of mass (CoM) balancing, one-leg balancing, and stepping-in-place behaviors.},
  archive      = {J_FROBT},
  author       = {Bang, Seung Hyeon and Gonzalez, Carlos and Ahn, Junhyeok and Paine, Nicholas and Sentis, Luis},
  doi          = {10.3389/frobt.2023.1164660},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1164660},
  shortjournal = {Front. Robot. AI},
  title        = {Control and evaluation of a humanoid robot with rolling contact joints on its lower body},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bioinspired robots can foster nature conservation.
<em>FROBT</em>, <em>10</em>, 1145798. (<a
href="https://doi.org/10.3389/frobt.2023.1145798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We live in a time of unprecedented scientific and human progress while being increasingly aware of its negative impacts on our planet’s health. Aerial, terrestrial, and aquatic ecosystems have significantly declined putting us on course to a sixth mass extinction event. Nonetheless, the advances made in science, engineering, and technology have given us the opportunity to reverse some of our ecosystem damage and preserve them through conservation efforts around the world. However, current conservation efforts are primarily human led with assistance from conventional robotic systems which limit their scope and effectiveness, along with negatively impacting the surroundings. In this perspective, we present the field of bioinspired robotics to develop versatile agents for future conservation efforts that can operate in the natural environment while minimizing the disturbance/impact to its inhabitants and the environment’s natural state. We provide an operational and environmental framework that should be considered while developing bioinspired robots for conservation. These considerations go beyond addressing the challenges of human-led conservation efforts and leverage the advancements in the field of materials, intelligence, and energy harvesting, to make bioinspired robots move and sense like animals. In doing so, it makes bioinspired robots an attractive, non-invasive, sustainable, and effective conservation tool for exploration, data collection, intervention, and maintenance tasks. Finally, we discuss the development of bioinspired robots in the context of collaboration, practicality, and applicability that would ensure their further development and widespread use to protect and preserve our natural world.},
  archive      = {J_FROBT},
  author       = {Chellapurath, Mrudul and Khandelwal, Pranav C. and Schulz, Andrew K.},
  doi          = {10.3389/frobt.2023.1145798},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1145798},
  shortjournal = {Front. Robot. AI},
  title        = {Bioinspired robots can foster nature conservation},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: New frontiers in parallel robotics.
<em>FROBT</em>, <em>10</em>, 1282798. (<a
href="https://doi.org/10.3389/frobt.2023.1282798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Briot, Sébastien and Burgner-Kahrs, Jessica},
  doi          = {10.3389/frobt.2023.1282798},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1282798},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: New frontiers in parallel robotics},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Enhanced GNSS-based localization solutions with
artificial intelligence. <em>FROBT</em>, <em>10</em>, 1265989. (<a
href="https://doi.org/10.3389/frobt.2023.1265989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Marais, Juliette and García Crespillo, Omar and Hsu, Li-Ta},
  doi          = {10.3389/frobt.2023.1265989},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1265989},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Enhanced GNSS-based localization solutions with artificial intelligence},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integrating sustainability in the design process of urban
service robots. <em>FROBT</em>, <em>10</em>, 1250697. (<a
href="https://doi.org/10.3389/frobt.2023.1250697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of sustainability and sustainable development has been well discussed and was subject to many conferences of the EU and UN resulting in agendas, goals, and resolutions. Yet, literature shows that the three dimensions of sustainability (ecological, social, and economic) are unevenly accounted for in the design of mechatronic products. The stated reasons range from a lack or inapplicability of tools for integration into the design process, models for simulation, and impact analyses to necessary changes in policy and social behavior. The influence designers have on the sustainability of a product lies mostly in the early design phases of the development process, such as requirements engineering and concept evaluation. Currently, these concepts emerge mostly from performance-based requirements rather than sustainability impact-based requirements, which are also true for service robots in urban environments. So far, the main focus of research in this innovative and growing product branch lies in performance in perception, navigation, and interaction. This paper sets its focus on integrating all three dimensions of sustainability into the design process. Therefore, we describe the development of an urban service robot supporting municipal waste management in the city of Berlin. It is the set goal for the robot to increase the service and support the employees while reducing emissions. For that, we make use of a product development process (PDP) and its adaptable nature to build a specific development process suited to include the three dimensions of sustainability during the requirements engineering and evaluation activities. Herein, we show how established design methods like the life cycle assessment or life cycle costing can be applied to the development of urban service robots and which aspects are underrepresented. Especially, the social dimension required us to look beyond standardized methods in the field of mechanical engineering. Based on our findings, we introduce a new activity to the development process that we call preliminary social assessment in order to incorporate social aspects in the early design phase.},
  archive      = {J_FROBT},
  author       = {van der Schoor, Michel Joop and Göhlich, Dietmar},
  doi          = {10.3389/frobt.2023.1250697},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1250697},
  shortjournal = {Front. Robot. AI},
  title        = {Integrating sustainability in the design process of urban service robots},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: New challenges and trends in rehabilitation
devices based on AI and optimization. <em>FROBT</em>, <em>10</em>,
1248973. (<a href="https://doi.org/10.3389/frobt.2023.1248973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Ponce, Pedro and Alfaro-Ponce, Mariel and López-Caudana, Edgar Omar and McDaniel, Troy and Montesinos, Luis and López-Gutiérrez, Jesús Ricardo and Lugo-González, Esther},
  doi          = {10.3389/frobt.2023.1248973},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1248973},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: New challenges and trends in rehabilitation devices based on AI and optimization},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Tracing a new path in the field of AI and robotics:
Mimicking human intelligence through chemistry. Part i: Molecular and
supramolecular chemistry. <em>FROBT</em>, <em>10</em>, 1238492. (<a
href="https://doi.org/10.3389/frobt.2023.1238492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chemical Artificial Intelligence (CAI) is a brand-new research line that exploits molecular, supramolecular, and systems chemistry in wetware (i.e., in fluid solutions) to imitate some performances of human intelligence and promote unconventional robotics based on molecular assemblies, which act in the microscopic world, otherwise tough to be accessed by humans. It is undoubtedly worth spreading the news that AI researchers can rely on the help of chemists and biotechnologists to reach the ambitious goals of building intelligent systems from scratch. This article reports the first attempt at building a Chemical Artificial Intelligence knowledge map and describes the basic intelligent functions that can be implemented through molecular and supramolecular chemistry. Chemical Artificial Intelligence provides new tools and concepts to mimic human intelligence because it shares, with biological intelligence, the same principles and materials. It enables peculiar dynamics, possibly not accessible in software and hardware domains. Moreover, the development of Chemical Artificial Intelligence will contribute to a deeper understanding of the strict link between intelligence and life, which are two of the most remarkable emergent properties shown by the Complex Systems we call biological organisms.},
  archive      = {J_FROBT},
  author       = {Gentili, Pier Luigi and Stano, Pasquale},
  doi          = {10.3389/frobt.2023.1238492},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1238492},
  shortjournal = {Front. Robot. AI},
  title        = {Tracing a new path in the field of AI and robotics: mimicking human intelligence through chemistry. part i: molecular and supramolecular chemistry},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Anthropomorphic framing and failure comprehensibility
influence different facets of trust towards industrial robots.
<em>FROBT</em>, <em>10</em>, 1235017. (<a
href="https://doi.org/10.3389/frobt.2023.1235017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Utilizing anthropomorphic features in industrial robots is a prevalent strategy aimed at enhancing their perception as collaborative team partners and promoting increased tolerance for failures. Nevertheless, recent research highlights the presence of potential drawbacks associated with this approach. It is still widely unknown, how anthropomorphic framing influences the dynamics of trust especially, in context of different failure experiences.Method: The current laboratory study wanted to close this research gap. To do so, fifty-one participants interacted with a robot that was either anthropomorphically or technically framed. In addition, each robot produced either a comprehensible or an incomprehensible failure.Results: The analysis revealed no differences in general trust towards the technically and anthropomorphically framed robot. Nevertheless, the anthropomorphic robot was perceived as more transparent than the technical robot. Furthermore, the robot’s purpose was perceived as more positive after experiencing a comprehensible failure.Discussion: The perceived higher transparency of anthropomorphically framed robots might be a double-edged sword, as the actual transparency did not differ between both conditions. In general, the results show that it is essential to consider trust multi-dimensionally, as a uni-dimensional approach which is often focused on performance might overshadow important facets of trust like transparency and purpose.},
  archive      = {J_FROBT},
  author       = {Roesler, Eileen},
  doi          = {10.3389/frobt.2023.1235017},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1235017},
  shortjournal = {Front. Robot. AI},
  title        = {Anthropomorphic framing and failure comprehensibility influence different facets of trust towards industrial robots},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Effect of underactuated parallelogram shape-shifting for
environmental adaptation movement of a three modular in-pipe robot.
<em>FROBT</em>, <em>10</em>, 1234835. (<a
href="https://doi.org/10.3389/frobt.2023.1234835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an in-pipe robot with three underactuated parallelogram crawler modules, which can automatically shift its body shape when encountering obstacles. The shape-shifting movement is achieved by only a single actuator through a simple differential mechanism by only combining a pair of spur gears. It can lead to downsizing, cost reduction, and simplification of control for adaptation to obstacles. The parallelogram shape does not change the total belt circumference length, thus, a new mechanism to maintain the belt tension is not necessary. Moreover, the proposed crawler can form the anterior-posterior symmetric parallelogram relative to the moving direction, which generates high adaptability in both forward and backward directions. However, whether the locomotion or shape-shifting is driven depends on the gear ratio of the differential mechanism because their movements are only switched mechanically. Therefore, to clarify the requirements of the gear ratio for the passive adaptation, two outputs of each crawler mechanism (torques of the flippers and front pulley) are quasi-statically analyzed, and how the environmental and design parameters influence the robot performance are verified by real experiments. From the experiments, although the robot could not adapt to the stepped pipe in vertical section, it successfully shifted its crawler’s shape to parallelogram in horizontal section only with our simulated output ratio.},
  archive      = {J_FROBT},
  author       = {Kakogawa, Atsushi and Ma, Shugen},
  doi          = {10.3389/frobt.2023.1234835},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1234835},
  shortjournal = {Front. Robot. AI},
  title        = {Effect of underactuated parallelogram shape-shifting for environmental adaptation movement of a three modular in-pipe robot},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed control for geometric pattern formation of
large-scale multirobot systems. <em>FROBT</em>, <em>10</em>, 1219931.
(<a href="https://doi.org/10.3389/frobt.2023.1219931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Geometric pattern formation is crucial in many tasks involving large-scale multi-agent systems. Examples include mobile agents performing surveillance, swarms of drones or robots, and smart transportation systems. Currently, most control strategies proposed to achieve pattern formation in network systems either show good performance but require expensive sensors and communication devices, or have lesser sensor requirements but behave more poorly.Methods and result: In this paper, we provide a distributed displacement-based control law that allows large groups of agents to achieve triangular and square lattices, with low sensor requirements and without needing communication between the agents. Also, a simple, yet powerful, adaptation law is proposed to automatically tune the control gains in order to reduce the design effort, while improving robustness and flexibility.Results: We show the validity and robustness of our approach via numerical simulations and experiments, comparing it, where possible, with other approaches from the existing literature.},
  archive      = {J_FROBT},
  author       = {Giusti, Andrea and Maffettone, Gian Carlo and Fiore, Davide and Coraggio, Marco and di Bernardo, Mario},
  doi          = {10.3389/frobt.2023.1219931},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1219931},
  shortjournal = {Front. Robot. AI},
  title        = {Distributed control for geometric pattern formation of large-scale multirobot systems},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards a conceptualisation and critique of everyday life in
HRI. <em>FROBT</em>, <em>10</em>, 1212034. (<a
href="https://doi.org/10.3389/frobt.2023.1212034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the topic of “everyday life” as it is addressed in Human-Robot Interaction (HRI) research. It starts from the argument that while human daily life with social robots has been increasingly discussed and studied in HRI, the concept of everyday life lacks clarity or systematic analysis, and it plays only a secondary role in supporting the study of the key HRI topics. In order to help conceptualise everyday life as a research theme in HRI in its own right, we provide an overview of the Social Science and Humanities (SSH) perspectives on everyday life and lived experiences, particularly in sociology, and identify the key elements that may serve to further develop and empirically study such a concept in HRI. We propose new angles of analysis that may help better explore unique aspects of human engagement with social robots. We look at the everyday not just as a reality as we know it (i.e., the realm of the “ordinary”) but also as the future that we need to envision and strive to materialise (i.e., the transformation that will take place through the “extraordinary” that comes with social robots). Finally, we argue that HRI research would benefit not only from engaging with a systematic conceptualisation but also critique of the contemporary everyday life with social robots. This is how HRI studies could play an important role in challenging the current ways of understanding of what makes different aspects of the human world “natural” and ultimately help bringing a social change towards what we consider a “good life.”},
  archive      = {J_FROBT},
  author       = {Zawieska, Karolina and Hannibal, Glenda},
  doi          = {10.3389/frobt.2023.1212034},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1212034},
  shortjournal = {Front. Robot. AI},
  title        = {Towards a conceptualisation and critique of everyday life in HRI},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Should we encourage the use of robotic technologies in
complicated diverticulitis? Results of systematic review and
meta-analysis. <em>FROBT</em>, <em>10</em>, 1208611. (<a
href="https://doi.org/10.3389/frobt.2023.1208611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Complicated diverticulitis is a common abdominal emergency that often requires a surgical intervention. The systematic review and meta-analysis below compare the benefits and harms of robotic vs. laparoscopic surgery in patients with complicated colonic diverticular disease.Methods: The following databases were searched before 1 March 2023: Cochrane Library, PubMed, Embase, CINAHL, and ClinicalTrials.gov. The internal validity of the selected non-randomized studies was assessed using the ROBINS-I tool. The meta-analysis and trial sequential analysis were performed using RevMan 5.4 (Cochrane Collaboration, London, United Kingdom) and Copenhagen Trial Unit Trial Sequential Analysis (TSA) software (Copenhagen Trial Unit, Center for Clinical Intervention Research, Rigshospitalet, Copenhagen, Denmark), respectively.Results: We found no relevant randomized controlled trials in the searched databases. Therefore, we analyzed 5 non-randomized studies with satisfactory internal validity and similar designs comprising a total of 442 patients (184 (41.6%) robotic and 258 (58.4%) laparoscopic interventions). The analysis revealed that robotic surgery for complicated diverticulitis (CD) took longer than laparoscopy (MD = 42 min; 95% CI: [-16, 101]). No statistically significant differences were detected between the groups regarding intraoperative blood loss (MD = −9 mL; 95% CI: [–26, 8]) and the rate of conversion to open surgery (2.17% or 4/184 for robotic surgery vs. 6.59% or 17/258 for laparoscopy; RR = 0.63; 95% CI: [0.10, 4.00]). The type of surgery did not affect the length of in-hospital stay (MD = 0.18; 95% CI: [–0.60, 0.97]) or the rate of postoperative complications (14.1% or 26/184 for robotic surgery vs. 19.8% or 51/258 for laparoscopy; RR = 0.81; 95% CI: [0.52, 1.26]). No deaths were reported in either group.Discussion: The meta-analysis suggests that robotic surgery is an appropriate option for managing complicated diverticulitis. It is associated with a trend toward a lower rate of conversion to open surgery and fewer postoperative complications; however, this trend does not reach the level of statistical significance. Since no high quality RCTs were available, this meta-analysis isnot able to provide reliable conclusion, but only a remarkable lack of proper evidence supporting robotic technology. The need for further evidence-based trials is important.},
  archive      = {J_FROBT},
  author       = {Panin, S. I. and Nechay, T. V. and Sazhin, A. V. and Tyagunov, A. E. and Shcherbakov, N. A. and Bykov, A. V. and Melnikov-Makarchuk, K. Yu and Yuldashev, A. G. and Kuznetsov, A. A.},
  doi          = {10.3389/frobt.2023.1208611},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1208611},
  shortjournal = {Front. Robot. AI},
  title        = {Should we encourage the use of robotic technologies in complicated diverticulitis? results of systematic review and meta-analysis},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Human-robot interaction for children with special
needs. <em>FROBT</em>, <em>10</em>, 1206079. (<a
href="https://doi.org/10.3389/frobt.2023.1206079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Taheri, Alireza and Atyabi, Adham and Meghdari, Ali and Alemi, Minoo},
  doi          = {10.3389/frobt.2023.1206079},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1206079},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Human-robot interaction for children with special needs},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Assessing handwriting task difficulty levels through
kinematic features: A deep-learning approach. <em>FROBT</em>,
<em>10</em>, 1193388. (<a
href="https://doi.org/10.3389/frobt.2023.1193388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Handwriting is a complex task that requires coordination of motor, sensory, cognitive, memory, and linguistic skills to master. The extent these processes are involved depends on the complexity of the handwriting task. Evaluating the difficulty of a handwriting task is a challenging problem since it relies on subjective judgment of experts.Methods: In this paper, we propose a machine learning approach for evaluating the difficulty level of handwriting tasks. We propose two convolutional neural network (CNN) models for single- and multilabel classification where single-label classification is based on the mean of expert evaluation while the multilabel classification predicts the distribution of experts’ assessment. The models are trained with a dataset containing 117 spatio-temporal features from the stylus and hand kinematics, which are recorded for all letters of the Arabic alphabet.Results: While single- and multilabel classification models achieve decent accuracy (96% and 88% respectively) using all features, the hand kinematics features do not significantly influence the performance of the models.Discussion: The proposed models are capable of extracting meaningful features from the handwriting samples and predicting their difficulty levels accurately. The proposed approach has the potential to be used to personalize handwriting learning tools and provide automatic evaluation of the quality of handwriting.},
  archive      = {J_FROBT},
  author       = {Babushkin, Vahan and Alsuradi, Haneen and Jamil, Muhammad Hassan and Al-Khalil, Muhamed Osman and Eid, Mohamad},
  doi          = {10.3389/frobt.2023.1193388},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1193388},
  shortjournal = {Front. Robot. AI},
  title        = {Assessing handwriting task difficulty levels through kinematic features: A deep-learning approach},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 6IMPOSE: Bridging the reality gap in 6D pose estimation for
robotic grasping. <em>FROBT</em>, <em>10</em>, 1176492. (<a
href="https://doi.org/10.3389/frobt.2023.1176492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {6D pose recognition has been a crucial factor in the success of robotic grasping, and recent deep learning based approaches have achieved remarkable results on benchmarks. However, their generalization capabilities in real-world applications remain unclear. To overcome this gap, we introduce 6IMPOSE, a novel framework for sim-to-real data generation and 6D pose estimation. 6IMPOSE consists of four modules: First, a data generation pipeline that employs the 3D software suite Blender to create synthetic RGBD image datasets with 6D pose annotations. Second, an annotated RGBD dataset of five household objects was generated using the proposed pipeline. Third, a real-time two-stage 6D pose estimation approach that integrates the object detector YOLO-V4 and a streamlined, real-time version of the 6D pose estimation algorithm PVN3D optimized for time-sensitive robotics applications. Fourth, a codebase designed to facilitate the integration of the vision system into a robotic grasping experiment. Our approach demonstrates the efficient generation of large amounts of photo-realistic RGBD images and the successful transfer of the trained inference model to robotic grasping experiments, achieving an overall success rate of 87% in grasping five different household objects from cluttered backgrounds under varying lighting conditions. This is made possible by fine-tuning data generation and domain randomization techniques and optimizing the inference pipeline, overcoming the generalization and performance shortcomings of the original PVN3D algorithm. Finally, we make the code, synthetic dataset, and all the pre-trained models available on GitHub.},
  archive      = {J_FROBT},
  author       = {Cao, Hongpeng and Dirnberger, Lukas and Bernardini, Daniele and Piazza, Cristina and Caccamo, Marco},
  doi          = {10.3389/frobt.2023.1176492},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1176492},
  shortjournal = {Front. Robot. AI},
  title        = {6IMPOSE: Bridging the reality gap in 6D pose estimation for robotic grasping},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vocal pain expression augmentation for a robopatient.
<em>FROBT</em>, <em>10</em>, 1122914. (<a
href="https://doi.org/10.3389/frobt.2023.1122914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abdominal palpation is one of the basic but important physical examination methods used by physicians. Visual, auditory, and haptic feedback from the patients are known to be the main sources of feedback they use in the diagnosis. However, learning to interpret this feedback and making accurate diagnosis require several years of training. Many abdominal palpation training simulators have been proposed to date, but very limited attempts have been reported in integrating vocal pain expressions into physical abdominal palpation simulators. Here, we present a vocal pain expression augmentation for a robopatient. The proposed robopatient is capable of providing real-time facial and vocal pain expressions based on the exerted palpation force and position on the abdominal phantom of the robopatient. A pilot study is conducted to test the proposed system, and we show the potential of integrating vocal pain expressions to the robopatient. The platform has also been tested by two clinical experts with prior experience in abdominal palpation. Their evaluations on functionality and suggestions for improvements are presented. We highlight the advantages of the proposed robopatient with real-time vocal and facial pain expressions as a controllable simulator platform for abdominal palpation training studies. Finally, we discuss the limitations of the proposed approach and suggest several future directions for improvements.},
  archive      = {J_FROBT},
  author       = {Protpagorn, Namnueng and Lalitharatne, Thilina Dulantha and Costi, Leone and Iida, Fumiya},
  doi          = {10.3389/frobt.2023.1122914},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1122914},
  shortjournal = {Front. Robot. AI},
  title        = {Vocal pain expression augmentation for a robopatient},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reduced order modeling and model order reduction for
continuum manipulators: An overview. <em>FROBT</em>, <em>10</em>,
1094114. (<a href="https://doi.org/10.3389/frobt.2023.1094114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft robot’s natural dynamics calls for the development of tailored modeling techniques for control. However, the high-dimensional configuration space of the geometrically exact modeling approaches for soft robots, i.e., Cosserat rod and Finite Element Methods (FEM), has been identified as a key obstacle in controller design. To address this challenge, Reduced Order Modeling (ROM), i.e., the approximation of the full-order models, and Model Order Reduction (MOR), i.e., reducing the state space dimension of a high fidelity FEM-based model, are enjoying extensive research. Although both techniques serve a similar purpose and their terms have been used interchangeably in the literature, they are different in their assumptions and implementation. This review paper provides the first in-depth survey of ROM and MOR techniques in the continuum and soft robotics landscape to aid Soft Robotics researchers in selecting computationally efficient models for their specific tasks.},
  archive      = {J_FROBT},
  author       = {Sadati, S.M.H. and Naghibi, S. Elnaz and da Cruz, Lyndon and Bergeles, Christos},
  doi          = {10.3389/frobt.2023.1094114},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1094114},
  shortjournal = {Front. Robot. AI},
  title        = {Reduced order modeling and model order reduction for continuum manipulators: An overview},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: From cobots to human-robot synergy–overview and
future trends. <em>FROBT</em>, <em>10</em>, 1270373. (<a
href="https://doi.org/10.3389/frobt.2023.1270373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Valente, Anna and Avram, Oliver},
  doi          = {10.3389/frobt.2023.1270373},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1270373},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: From cobots to human-robot synergy–overview and future trends},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Thought leaders in robotics and AI.
<em>FROBT</em>, <em>10</em>, 1265092. (<a
href="https://doi.org/10.3389/frobt.2023.1265092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Tanner, Herbert G.},
  doi          = {10.3389/frobt.2023.1265092},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1265092},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Thought leaders in robotics and AI},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Effect of incorporating wing veins on soft wings for
flapping micro air vehicles. <em>FROBT</em>, <em>10</em>, 1243238. (<a
href="https://doi.org/10.3389/frobt.2023.1243238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small insects with flapping wings, such as bees and flies, have flexible wings with veins, and their compliant motion enhances flight efficiency and robustness. This study investigated the effects of integrating wing veins into soft wings for micro-flapping aerial vehicles. Prototypes of soft wings, featuring various wing areas and vein patterns in both the wing-chord and wing-span directions, were fabricated and evaluated to determine the force generated through flapping. The results indicated that the force is not solely dependent upon the wing area and is influenced by the wing vein pattern. Wings incorporating wing-chord veins produced more force compared to those with wing-span veins. In contrast, when the wing area was the specific wing area, wings with crossed wing veins, comprising both wing-span veins and wing-chord veins, produced more force. Although wing-chord veins tended to exert more influence on the force generated than the wing-span veins, the findings suggested that a combination of wing-span and wing-chord veins may be requisite, depending upon the wing area.},
  archive      = {J_FROBT},
  author       = {Ishiguro, Risa and Kawasetsu, Takumi and Hosoda, Koh},
  doi          = {10.3389/frobt.2023.1243238},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1243238},
  shortjournal = {Front. Robot. AI},
  title        = {Effect of incorporating wing veins on soft wings for flapping micro air vehicles},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inspection and maintenance of industrial infrastructure with
autonomous underwater robots. <em>FROBT</em>, <em>10</em>, 1240276. (<a
href="https://doi.org/10.3389/frobt.2023.1240276">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater infrastructure, such as pipelines, requires regular inspection and maintenance including cleaning, welding of defects and valve-turning or hot-stabbing. At the moment, these tasks are mostly performed by divers and Remotely Operated Vehicles (ROVs) but the use of intervention Autonomous Underwater Vehicles (intervention-AUVs) can greatly reduce operation time, risk, and cost. However, autonomous underwater manipulation has not yet reached a high technological readiness and is an intensively researched topic. This review identifies key requirements based on necessary inspection and maintenance methods, linking them to the current technology and deriving major challenges which need to be addressed in development. These include the handling of tools, where a separation between handheld and mounted tools is detected in already employed underwater intervention vehicles such as the Sabertooth by Saab Seaeye or the Aquanaut by Nauticus robotics, two vehicles capable of semi-autonomous intervention. The main challenge identified concerns high level autonomy, i.e., the process of decision-making. This process includes detecting the correct point of interest, maximizing the workspace of the manipulator, planning the manipulation considering required forces, and monitoring the progress to allow for corrections and high quality results. In order to overcome these issues, reliable close range sensing and precise end point navigation is needed. By identifying these persisting challenges, the paper provides inspiration for further development directions in the field of autonomous underwater intervention.},
  archive      = {J_FROBT},
  author       = {Nauert, Franka and Kampmann, Peter},
  doi          = {10.3389/frobt.2023.1240276},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1240276},
  shortjournal = {Front. Robot. AI},
  title        = {Inspection and maintenance of industrial infrastructure with autonomous underwater robots},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Locomotion characteristics of a wheeled vibration-driven
robot with an enhanced pantograph-type suspension. <em>FROBT</em>,
<em>10</em>, 1239137. (<a
href="https://doi.org/10.3389/frobt.2023.1239137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: The paper considers the improved design of the wheeled vibration-driven robot equipped with an inertial exciter (unbalanced rotor) and enhanced pantograph-type suspension. The primary purpose and objectives of the study are focused on mathematical modeling, computer simulation, and experimental testing of locomotion conditions of the novel robot prototype. The primary scientific novelty of the present research consists in substantiating the possibilities of implementing the enhanced pantograph-type suspension in order to improve the robot’s kinematic characteristics, particularly the average translational speed.Methods: The simplified dynamic diagram of the robot’s oscillatory system is developed, and the mathematical model describing its locomotion conditions is derived using the Euler-Lagrange differential equations. The numerical modeling is carried out in the Mathematica software with the help of the Runge-Kutta methods. Computer simulation of the robot motion is performed in the SolidWorks Motion software using the variable step integration method (Gear’s method). The experimental investigations of the robot prototype operating conditions are conducted at the Vibroengineering Laboratory of Lviv Polytechnic National University using the WitMotion accelerometers and software. The experimental data is processed in the MathCad software.Results and discussion: The obtained results show the time dependencies of the robot body’s basic kinematic parameters (accelerations, velocities, displacements) under different operating conditions, particularly the angular frequencies of the unbalanced rotor. The numerical modeling, computer simulation, and experimental investigations present almost similar results: the smallest horizontal speed of about 1 mm/s is observed at the supplied voltage of 3.47 V when the forced frequency is equal to 500 rpm; the largest locomotion speed is approximately 40 mm/s at the supplied voltage of 10 V and forced frequency of 1,500 rpm. The paper may be interesting for designers and researchers of similar vibration-driven robotic systems based on wheeled chassis, and the results may be used while implementing the experimental and industrial prototypes of vibration-driven robots for various purposes, particularly, for inspecting and cleaning the pipelines. Further investigation on the subject of the paper should be focused on analyzing the relations between the power consumption, average translational speed, and working efficiency of the considerer robot under various operating conditions.},
  archive      = {J_FROBT},
  author       = {Korendiy, Vitaliy and Kachur, Oleksandr},
  doi          = {10.3389/frobt.2023.1239137},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1239137},
  shortjournal = {Front. Robot. AI},
  title        = {Locomotion characteristics of a wheeled vibration-driven robot with an enhanced pantograph-type suspension},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Seeing eye to eye: Trustworthy embodiment for task-based
conversational agents. <em>FROBT</em>, <em>10</em>, 1234767. (<a
href="https://doi.org/10.3389/frobt.2023.1234767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart speakers and conversational agents have been accepted into our homes for a number of tasks such as playing music, interfacing with the internet of things, and more recently, general chit-chat. However, they have been less readily accepted in our workplaces. This may be due to data privacy and security concerns that exist with commercially available smart speakers. However, one of the reasons for this may be that a smart speaker is simply too abstract and does not portray the social cues associated with a trustworthy work colleague. Here, we present an in-depth mixed method study, in which we investigate this question of embodiment in a serious task-based work scenario of a first responder team. We explore the concepts of trust, engagement, cognitive load, and human performance using a humanoid head style robot, a commercially available smart speaker, and a specially developed dialogue manager. Studying the effect of embodiment on trust, being a highly subjective and multi-faceted phenomena, is clearly challenging, and our results indicate that potentially, the robot, with its anthropomorphic facial features, expressions, and eye gaze, was trusted more than the smart speaker. In addition, we found that embodying a conversational agent helped increase task engagement and performance compared to the smart speaker. This study indicates that embodiment could potentially be useful for transitioning conversational agents into the workplace, and further in situ, “in the wild” experiments with domain workers could be conducted to confirm this.},
  archive      = {J_FROBT},
  author       = {Robb, David A. and Lopes, José and Ahmad, Muneeb I. and McKenna, Peter E. and Liu, Xingkun and Lohan, Katrin and Hastie, Helen},
  doi          = {10.3389/frobt.2023.1234767},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1234767},
  shortjournal = {Front. Robot. AI},
  title        = {Seeing eye to eye: Trustworthy embodiment for task-based conversational agents},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deciphering the connection between upstream obstacles, wake
structures, and root signals in seal whisker array sensing using
interpretable neural networks. <em>FROBT</em>, <em>10</em>, 1231715. (<a
href="https://doi.org/10.3389/frobt.2023.1231715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel method that combines a computational fluid-structure interaction model with an interpretable deep-learning model to explore the fundamental mechanisms of seal whisker sensing. By establishing connections between crucial signal patterns, flow characteristics, and attributes of upstream obstacles, the method has the potential to enhance our understanding of the intricate sensing mechanisms. The effectiveness of the method is demonstrated through its accurate prediction of the location and orientation of a circular plate placed in front of seal whisker arrays. The model also generates temporal and spatial importance values of the signals, enabling the identification of significant temporal-spatial signal patterns crucial for the network’s predictions. These signal patterns are further correlated with flow structures, allowing for the identification of important flow features relevant for accurate prediction. The study provides insights into seal whiskers’ perception of complex underwater environments, inspiring advancements in underwater sensing technologies.},
  archive      = {J_FROBT},
  author       = {Bodaghi, Dariush and Wang, Yuxing and Liu, Geng and Liu, Dongfang and Xue, Qian and Zheng, Xudong},
  doi          = {10.3389/frobt.2023.1231715},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1231715},
  shortjournal = {Front. Robot. AI},
  title        = {Deciphering the connection between upstream obstacles, wake structures, and root signals in seal whisker array sensing using interpretable neural networks},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development of a new set of heuristics for the evaluation of
human-robot interaction in industrial settings: Heuristics robots
experience (HEUROBOX). <em>FROBT</em>, <em>10</em>, 1227082. (<a
href="https://doi.org/10.3389/frobt.2023.1227082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans and robots will increasingly have to work together in the new industrial context. Therefore, it is necessary to improve the User Experience, Technology Acceptance, and overall wellbeing to achieve a smoother and more satisfying interaction while obtaining the maximum performance possible out of it. For this reason, it is essential to analyze these interactions to enhance User Experience. The heuristic evaluation is an easy-to-use, low-cost method that can be applied at different stages of a design process in an iterative manner. Despite these advantages, there is rarely a list of heuristics in the current literature that evaluates Human-Robot interactions both from a User Experience, Technology Acceptance, and Human-Centered approach. Such an approach should integrate key aspects like safety, trust, and perceived safety, ergonomics and workload, inclusivity, and multimodality, as well as robot characteristics and functionalities. Therefore, a new set of heuristics, namely, the HEUROBOX tool, is presented in this work in the form of the HEUROBOX tool to help practitioners and researchers in the assessment of human-robot systems in industrial environments. The HEUROBOX tool clusters design guidelines and methodologies as a logic list of heuristics for human-robot interaction and comprises four categories: Safety, Ergonomics, Functionality, and Interfaces. They include 84 heuristics in the basic evaluation, while the advanced evaluation lists a total of 228 heuristics in order to adapt the tool to the evaluation of different industrial requirements. Finally, the set of new heuristics has been validated by experts using the System Usability Scale (SUS) questionnaire and the categories has been prioritized in order of their importance in the evaluation of Human-Robot Interaction through the Analytic Hierarchy Process (AHP).},
  archive      = {J_FROBT},
  author       = {Apraiz, Ainhoa and Mulet Alberola, Jose Antonio and Lasa, Ganix and Mazmela, Maitane and Nguyen, Hien Ngoc},
  doi          = {10.3389/frobt.2023.1227082},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1227082},
  shortjournal = {Front. Robot. AI},
  title        = {Development of a new set of heuristics for the evaluation of human-robot interaction in industrial settings: Heuristics robots experience (HEUROBOX)},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal predictive neuro-navigator design for mobile robot
navigation with moving obstacles. <em>FROBT</em>, <em>10</em>, 1226028.
(<a href="https://doi.org/10.3389/frobt.2023.1226028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: The challenge of navigating a Mobile robot in dynamic environments has grasped significant attention in recent years. Despite the available techniques, there is still a need for efficient and reliable approaches that can address the challenges of real-time near optimal navigation and collision avoidance.Methods: This paper proposes a novel Log-concave Model Predictive Controller (MPC) algorithm that addresses these challenges by utilizing a unique formulation of cost functions and dynamic constraints, as well as a convergence criterion based on Lyapunov stability theory. The proposed approach is mapped onto a novel recurrent neural network (RNN) structure and compared with the CVXOPT optimization tool. The key contribution of this study is the combination of neural networks with model predictive controller to solve optimal control problems locally near the robot, which offers several advantages, including computational efficiency and the ability to handle nonlinear and complex systems.Results: The major findings of this study include the successful implementation and evaluation of the proposed algorithm, which outperforms other methods such as RRT, A-Star, and LQ-MPC in terms of reliability and speed. This approach has the potential to facilitate real-time navigation of mobile robots in dynamic environments and ensure a feasible solution for the proposed constrained-optimization problem.},
  archive      = {J_FROBT},
  author       = {Mohaghegh, Mahsa and Saeedinia, Samaneh-Alsadat and Roozbehi, Zahra},
  doi          = {10.3389/frobt.2023.1226028},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1226028},
  shortjournal = {Front. Robot. AI},
  title        = {Optimal predictive neuro-navigator design for mobile robot navigation with moving obstacles},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to reason over scene graphs: A case study of
finetuning GPT-2 into a robot language model for grounded task planning.
<em>FROBT</em>, <em>10</em>, 1221739. (<a
href="https://doi.org/10.3389/frobt.2023.1221739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-horizon task planning is essential for the development of intelligent assistive and service robots. In this work, we investigate the applicability of a smaller class of large language models (LLMs), specifically GPT-2, in robotic task planning by learning to decompose tasks into subgoal specifications for a planner to execute sequentially. Our method grounds the input of the LLM on the domain that is represented as a scene graph, enabling it to translate human requests into executable robot plans, thereby learning to reason over long-horizon tasks, as encountered in the ALFRED benchmark. We compare our approach with classical planning and baseline methods to examine the applicability and generalizability of LLM-based planners. Our findings suggest that the knowledge stored in an LLM can be effectively grounded to perform long-horizon task planning, demonstrating the promising potential for the future application of neuro-symbolic planning methods in robotics.},
  archive      = {J_FROBT},
  author       = {Chalvatzaki, Georgia and Younes, Ali and Nandha, Daljeet and Le, An Thai and Ribeiro, Leonardo F. R. and Gurevych, Iryna},
  doi          = {10.3389/frobt.2023.1221739},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1221739},
  shortjournal = {Front. Robot. AI},
  title        = {Learning to reason over scene graphs: A case study of finetuning GPT-2 into a robot language model for grounded task planning},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient reciprocating burrowing with anisotropic origami
feet. <em>FROBT</em>, <em>10</em>, 1214160. (<a
href="https://doi.org/10.3389/frobt.2023.1214160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Origami folding is an ancient art which holds promise for creating compliant and adaptable mechanisms, but has yet to be extensively studied for granular environments. At the same time, biological systems exploit anisotropic body forces for locomotion, such as the frictional anisotropy of a snake’s skin. In this work, we explore how foldable origami feet can be used to passively induce anisotropic force response in granular media, through varying their resistive plane. We present a reciprocating burrower which transfers pure symmetric linear motion into directed burrowing motion using a pair of deployable origami feet on either end. We also present an application of the reduced order model granular Resistive Force Theory to inform the design of deformable structures, and compare results with those from experiments and Discrete Element Method simulations. Through a single actuator, and without the use of advanced controllers or sensors, these origami feet enable burrowing locomotion. In this paper, we achieve burrowing translation ratios—net forward motion to overall linear actuation—over 46% by changing foot design without altering overall foot size. Specifically, anisotropic folding foot parameters should be tuned for optimal performance given a linear actuator’s stroke length.},
  archive      = {J_FROBT},
  author       = {Kim, Sareum and Treers, Laura K. and Huh, Tae Myung and Stuart, Hannah S.},
  doi          = {10.3389/frobt.2023.1214160},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1214160},
  shortjournal = {Front. Robot. AI},
  title        = {Efficient reciprocating burrowing with anisotropic origami feet},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Effects of repetitive low-acceleration impacts on attitude
estimation with micro-electromechanical inertial measurement units.
<em>FROBT</em>, <em>10</em>, 1211531. (<a
href="https://doi.org/10.3389/frobt.2023.1211531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inertial Measurement Units are present in several applications in aerospace, unmanned vehicle navigation, legged robots, and human motion tracking systems, due to their ability to estimate a body’s acceleration, orientation and angular rate. In contrast to rovers and drones, legged locomotion involves repeated impacts between the feet and the ground, and rapid locomotion (e.g., running) involves alternating stance and flight phases, resulting in substantial oscillations in vertical acceleration. The aim of this research is to investigate the effects of periodic low-acceleration impacts (4 g, 8 g and 16 g), which imitate the vertical motion of a running robot, on the attitude estimation of multiple Micro-Electromechanical Systems IMUs. The results reveal the presence of a significant drift in the attitude estimation of the sensors, which can provide important information during the design process of a robot (sensor selection), or during the control phase (e.g., the system will know that after a series of impacts the attitude estimations will be inaccurate).},
  archive      = {J_FROBT},
  author       = {Allione, Federico and Gamba, Juan D. and Gkikakis, Antonios E. and Featherstone, Roy and Caldwell, Darwin},
  doi          = {10.3389/frobt.2023.1211531},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1211531},
  shortjournal = {Front. Robot. AI},
  title        = {Effects of repetitive low-acceleration impacts on attitude estimation with micro-electromechanical inertial measurement units},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Practical hardware for evolvable robots. <em>FROBT</em>,
<em>10</em>, 1206055. (<a
href="https://doi.org/10.3389/frobt.2023.1206055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolutionary robotics field offers the possibility of autonomously generating robots that are adapted to desired tasks by iteratively optimising across successive generations of robots with varying configurations until a high-performing candidate is found. The prohibitive time and cost of actually building this many robots means that most evolutionary robotics work is conducted in simulation, but to apply evolved robots to real-world problems, they must be implemented in hardware, which brings new challenges. This paper explores in detail the design of an example system for realising diverse evolved robot bodies, and specifically how this interacts with the evolutionary process. We discover that every aspect of the hardware implementation introduces constraints that change the evolutionary space, and exploring this interplay between hardware constraints and evolution is the key contribution of this paper. In simulation, any robot that can be defined by a suitable genetic representation can be implemented and evaluated, but in hardware, real-world limitations like manufacturing/assembly constraints and electrical power delivery mean that many of these robots cannot be built, or will malfunction in operation. This presents the novel challenge of how to constrain an evolutionary process within the space of evolvable phenotypes to only those regions that are practically feasible: the viable phenotype space. Methods of phenotype filtering and repair were introduced to address this, and found to degrade the diversity of the robot population and impede traversal of the exploration space. Furthermore, the degrees of freedom permitted by the hardware constraints were found to be poorly matched to the types of morphological variation that would be the most useful in the target environment. Consequently, the ability of the evolutionary process to generate robots with effective adaptations was greatly reduced. The conclusions from this are twofold. 1) Designing a hardware platform for evolving robots requires different thinking, in which all design decisions should be made with reference to their impact on the viable phenotype space. 2) It is insufficient to just evolve robots in simulation without detailed consideration of how they will be implemented in hardware, because the hardware constraints have a profound impact on the evolutionary space.},
  archive      = {J_FROBT},
  author       = {Angus, Mike and Buchanan, Edgar and Le Goff, Léni K. and Hart, Emma and Eiben, Agoston E. and De Carlo, Matteo and Winfield, Alan F. and Hale, Matthew F. and Woolley, Robert and Timmis, Jon and Tyrrell, Andy M.},
  doi          = {10.3389/frobt.2023.1206055},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1206055},
  shortjournal = {Front. Robot. AI},
  title        = {Practical hardware for evolvable robots},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The effect of tail stiffness on a sprawling quadruped
locomotion. <em>FROBT</em>, <em>10</em>, 1198749. (<a
href="https://doi.org/10.3389/frobt.2023.1198749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A distinctive feature of quadrupeds that is integral to their locomotion is the tail. Tails serve many purposes in biological systems, including propulsion, counterbalance, and stabilization while walking, running, climbing, or jumping. Similarly, tails in legged robots may augment the stability and maneuverability of legged robots by providing an additional point of contact with the ground. However, in the field of terrestrial bio-inspired legged robotics, the tail is often ignored because of the difficulties in design and control. In this study, we test the hypothesis that a variable stiffness robotic tail can improve the performance of a sprawling quadruped robot by enhancing its stability and maneuverability in various environments. In order to validate our hypothesis, we integrated a cable-driven, flexible tail with multiple segments into the underactuated sprawling quadruped robot, where a single servo motor working alongside a reel and cable mechanism regulates the tail’s stiffness. Our results demonstrated that by controlling the stiffness of the tail, the stability of locomotion on rough terrain and the climbing ability of the robot are improved compared to the movement with a rigid tail and no tail. Our findings highlight that constant ground support provided by the flexible tail is key to maintaining stable locomotion. This ensured a predictable gait cycle, eliminating unexpected turning and slipping, resulting in an increase in locomotion speed and efficiency. Additionally, we observed the robot’s enhanced climbing ability on surfaces inclined up to 20°. The flexibility of the tail enabled the robot to overcome obstacles without external sensing, exhibiting significant adaptability across various terrains.},
  archive      = {J_FROBT},
  author       = {Buckley, Josh and Chikere, Nnamdi and Ozkan-Aydin, Yasemin},
  doi          = {10.3389/frobt.2023.1198749},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1198749},
  shortjournal = {Front. Robot. AI},
  title        = {The effect of tail stiffness on a sprawling quadruped locomotion},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The experimental investigation of foot slip-turning motion
of the musculoskeletal robot on toe joints. <em>FROBT</em>, <em>10</em>,
1187297. (<a href="https://doi.org/10.3389/frobt.2023.1187297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to their complex structural design and control system, musculoskeletal robots struggle to execute complicated tasks such as turning with their limited range of motion. This study investigates the utilization of passive toe joints in the foot slip-turning motion of a musculoskeletal robot to turn on its toes with minimum movements to reach the desired angle while increasing the turning angle and its range of mobility. The different conditions of plantar intrinsic muscles (PIM) were also studied in the experiment to investigate the effect of actively controlling the stiffness of toe joints. The results show that the usage of toe joints reduced frictional torque and improved rotational angle. Meanwhile, the results of the toe-lifting angle show that the usage of PIM could contribute to preventing over-dorsiflexion of toes and possibly improving postural stability. Lastly, the results of ground reaction force show that the foot with different stiffness can affect the curve pattern. These findings contribute to the implementations of biological features and utilize them in bipedal robots to simplify their motions, and improve adaptability, regardless of their complex structure.},
  archive      = {J_FROBT},
  author       = {Nipatphonsakun, Kawinna and Kawasetsu, Takumi and Hosoda, Koh},
  doi          = {10.3389/frobt.2023.1187297},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1187297},
  shortjournal = {Front. Robot. AI},
  title        = {The experimental investigation of foot slip-turning motion of the musculoskeletal robot on toe joints},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards reuse and recycling of lithium-ion batteries:
Tele-robotics for disassembly of electric vehicle batteries.
<em>FROBT</em>, <em>10</em>, 1179296. (<a
href="https://doi.org/10.3389/frobt.2023.1179296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disassembly of electric vehicle batteries is a critical stage in recovery, recycling and re-use of high-value battery materials, but is complicated by limited standardisation, design complexity, compounded by uncertainty and safety issues from varying end-of-life condition. Telerobotics presents an avenue for semi-autonomous robotic disassembly that addresses these challenges. However, it is suggested that quality and realism of the user’s haptic interactions with the environment is important for precise, contact-rich and safety-critical tasks. To investigate this proposition, we demonstrate the disassembly of a Nissan Leaf 2011 module stack as a basis for a comparative study between a traditional asymmetric haptic-“cobot” master-slave framework and identical master and slave cobots based on task completion time and success rate metrics. We demonstrate across a range of disassembly tasks a time reduction of 22%–57% is achieved using identical cobots, yet this improvement arises chiefly from an expanded workspace and 1:1 positional mapping, and suffers a 10%–30% reduction in first attempt success rate. For unbolting and grasping, the realism of force feedback was comparatively less important than directional information encoded in the interaction, however, 1:1 force mapping strengthened environmental tactile cues for vacuum pick-and-place and contact cutting tasks.},
  archive      = {J_FROBT},
  author       = {Hathaway, Jamie and Shaarawy, Abdelaziz and Akdeniz, Cansu and Aflakian, Ali and Stolkin, Rustam and Rastegarpanah, Alireza},
  doi          = {10.3389/frobt.2023.1179296},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1179296},
  shortjournal = {Front. Robot. AI},
  title        = {Towards reuse and recycling of lithium-ion batteries: Tele-robotics for disassembly of electric vehicle batteries},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Impact analysis of cooperative perception on the performance
of automated driving in unsignalized roundabouts. <em>FROBT</em>,
<em>10</em>, 1164950. (<a
href="https://doi.org/10.3389/frobt.2023.1164950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper reports the implementation and results of a simulation-based analysis of the impact of cloud/edge-enabled cooperative perception on the performance of automated driving in unsignalized roundabouts. This is achieved by comparing the performance of automated driving assisted by cooperative perception to that of a baseline system, where the automated vehicle relies only on its onboard sensing and perception for motion planning and control. The paper first provides the descriptions of the implemented simulation model, which integrates the SUMO road traffic generator and CARLA simulator. This includes descriptions of both the baseline and cooperative perception-assisted automated driving systems. We then define a set of relevant key performance indicators for traffic efficiency, safety, and ride comfort, as well as simulation scenarios to collect relevant data for our analysis. This is followed by the description of simulation scenarios, presentation of the results, and discussions of the insights learned from the results.},
  archive      = {J_FROBT},
  author       = {Zainudin, Hazim and Koufos, Konstantinos and Lee, Graham and Jiang, Lintong and Dianati, Mehrdad},
  doi          = {10.3389/frobt.2023.1164950},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1164950},
  shortjournal = {Front. Robot. AI},
  title        = {Impact analysis of cooperative perception on the performance of automated driving in unsignalized roundabouts},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring the effect of automation failure on the human’s
trustworthiness in human-agent teamwork. <em>FROBT</em>, <em>10</em>,
1143723. (<a href="https://doi.org/10.3389/frobt.2023.1143723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Collaboration in teams composed of both humans and automation has an interdependent nature, which demands calibrated trust among all the team members. For building suitable autonomous teammates, we need to study how trust and trustworthiness function in such teams. In particular, automation occasionally fails to do its job, which leads to a decrease in a human’s trust. Research has found interesting effects of such a reduction of trust on the human’s trustworthiness, i.e., human characteristics that make them more or less reliable. This paper investigates how automation failure in a human-automation collaborative scenario affects the human’s trust in the automation, as well as a human’s trustworthiness towards the automation.Methods: We present a 2 × 2 mixed design experiment in which the participants perform a simulated task in a 2D grid-world, collaborating with an automation in a “moving-out” scenario. During the experiment, we measure the participants’ trustworthiness, trust, and liking regarding the automation, both subjectively and objectively.Results: Our results show that automation failure negatively affects the human’s trustworthiness, as well as their trust in and liking of the automation.Discussion: Learning the effects of automation failure in trust and trustworthiness can contribute to a better understanding of the nature and dynamics of trust in these teams and improving human-automation teamwork.},
  archive      = {J_FROBT},
  author       = {Centeio Jorge, Carolina and Bouman, Nikki H. and Jonker, Catholijn M. and Tielman, Myrthe L.},
  doi          = {10.3389/frobt.2023.1143723},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1143723},
  shortjournal = {Front. Robot. AI},
  title        = {Exploring the effect of automation failure on the human’s trustworthiness in human-agent teamwork},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cognitive modeling, ecological psychology, and musical
improvisation. <em>FROBT</em>, <em>10</em>, 1126033. (<a
href="https://doi.org/10.3389/frobt.2023.1126033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding novelty and improvisation in music requires gathering insight from a variety of disciplines. One fruitful path for synthesizing these insights is via modeling. As such, my aim in this paper is to start building a bridge between traditional cognitive models and contemporary embodied and ecological approaches to cognitive science. To achieve this task, I offer a perspective on a model that would combine elements of ecological psychology (especially affordances) and the Learning Intelligent Decision Agent (LIDA) cognitive architecture. Jeff Pressing’s cognitive model of musical improvisation will also be a central link between these elements. While some overlap between these three areas already exists, there are several points of tension between them, notably concerning the nature of perception and the function of artificial general intelligence modeling. I thus aim to alleviate the most worrisome concerns here, introduce several future research questions, and conclude with several points on how my account is part of a general theory, rather than merely a redescription of existent work.},
  archive      = {J_FROBT},
  author       = {Ryan, Kevin J.},
  doi          = {10.3389/frobt.2023.1126033},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1126033},
  shortjournal = {Front. Robot. AI},
  title        = {Cognitive modeling, ecological psychology, and musical improvisation},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-dimensional task recognition for human-robot teaming:
Literature review. <em>FROBT</em>, <em>10</em>, 1123374. (<a
href="https://doi.org/10.3389/frobt.2023.1123374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-robot teams collaborating to achieve tasks under various conditions, especially in unstructured, dynamic environments will require robots to adapt autonomously to a human teammate’s state. An important element of such adaptation is the robot’s ability to infer the human teammate’s tasks. Environmentally embedded sensors (e.g., motion capture and cameras) are infeasible in such environments for task recognition, but wearable sensors are a viable task recognition alternative. Human-robot teams will perform a wide variety of composite and atomic tasks, involving multiple activity components (i.e., gross motor, fine-grained motor, tactile, visual, cognitive, speech and auditory) that may occur concurrently. A robot’s ability to recognize the human’s composite, concurrent tasks is a key requirement for realizing successful teaming. Over a hundred task recognition algorithms across multiple activity components are evaluated based on six criteria: sensitivity, suitability, generalizability, composite factor, concurrency and anomaly awareness. The majority of the reviewed task recognition algorithms are not viable for human-robot teams in unstructured, dynamic environments, as they only detect tasks from a subset of activity components, incorporate non-wearable sensors, and rarely detect composite, concurrent tasks across multiple activity components.},
  archive      = {J_FROBT},
  author       = {Baskaran, Prakash and Adams, Julie A.},
  doi          = {10.3389/frobt.2023.1123374},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1123374},
  shortjournal = {Front. Robot. AI},
  title        = {Multi-dimensional task recognition for human-robot teaming: Literature review},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A perspective on large-scale simulation as an enabler for
novel biorobotics applications. <em>FROBT</em>, <em>10</em>, 1102286.
(<a href="https://doi.org/10.3389/frobt.2023.1102286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our understanding of the complex mechanisms that power biological intelligence has been greatly enhanced through the explosive growth of large-scale neuroscience and robotics simulation tools that are used by the research community to perform previously infeasible experiments, such as the simulation of the neocortex’s circuitry. Nevertheless, simulation falls far from being directly applicable to biorobots due to the large discrepancy between the simulated and the real world. A possible solution for this problem is the further enhancement of existing simulation tools for robotics, AI and neuroscience with multi-physics capabilities. Previously infeasible or difficult to simulate scenarios, such as robots swimming on the water surface, interacting with soft materials, walking on granular materials etc., would be rendered possible within a multi-physics simulation environment designed for robotics. In combination with multi-physics simulation, large-scale simulation tools that integrate multiple simulation modules in a closed-loop manner help address fundamental questions around the organization of neural circuits and the interplay between the brain, body and environment. We analyze existing designs for large-scale simulation running on cloud and HPC infrastructure as well as their shortcomings. Based on this analysis we propose a next-gen modular architecture design based on multi-physics engines, that we believe would greatly benefit biorobotics and AI.},
  archive      = {J_FROBT},
  author       = {Angelidis, Emmanouil},
  doi          = {10.3389/frobt.2023.1102286},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1102286},
  shortjournal = {Front. Robot. AI},
  title        = {A perspective on large-scale simulation as an enabler for novel biorobotics applications},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Behavior adaptation for mobile robots via semantic map
compositions of constraint-based controllers. <em>FROBT</em>,
<em>10</em>, 917637. (<a
href="https://doi.org/10.3389/frobt.2023.917637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Specifying and solving Constraint-based Optimization Problems (COP) has become a mainstream technology for advanced motion control of mobile robots. COP programming still requires expert knowledge to transform specific application context into the right configuration of the COP parameters (i.e., objective functions and constraints). The research contribution of this paper is a methodology to couple the context knowledge of application developers to the robot knowledge of control engineers, which, to our knowledge, has not yet been carried out. The former is offered a selected set of symbolic descriptions of the robots’ capabilities (its so-called “behavior semantics”) that are translated in control actions via “templates” in a “semantic map”; the latter contains the parameters that cover contextual dependencies in an application and robot vendor-independent way. The translation from semantics to control templates takes place in an “interaction layer” that contains 1) generic knowledge about robot motion capabilities (e.g., depending on the kinematic type of the robots), 2) spatial queries to extract relevant COP parameters from a semantic map (e.g., what is the impact of entering different types of “collision areas”), and 3) generic application knowledge (e.g., how the robots’ behavior is impacted by priorities, emergency, safety, and prudence). This particular design of, and interplay between, the application, interaction, and control layers provides a structured, conceptually simple approach to advance the complexity of mobile robot applications. Eventually, industry-wide cooperation between representatives of the application and control communities should result in an interaction layer with different standardized versions of semantic complexity.},
  archive      = {J_FROBT},
  author       = {Chen, Hao Liang and Hendrikx, Bob and Torta, Elena and Bruyninckx, Herman and van de Molengraft, René},
  doi          = {10.3389/frobt.2023.917637},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {917637},
  shortjournal = {Front. Robot. AI},
  title        = {Behavior adaptation for mobile robots via semantic map compositions of constraint-based controllers},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Multi-robot systems for space applications.
<em>FROBT</em>, <em>10</em>, 1253381. (<a
href="https://doi.org/10.3389/frobt.2023.1253381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Pomares, Jorge and Felicetti, Leonard and Varagnolo, Damiano},
  doi          = {10.3389/frobt.2023.1253381},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1253381},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Multi-robot systems for space applications},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Corrigendum: Bioethics and artificial intelligence: Between
deliberation on values and rational choice theory. <em>FROBT</em>,
<em>10</em>, 1251568. (<a
href="https://doi.org/10.3389/frobt.2023.1251568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Pinto-Bustamante, Boris Julián and Riaño-Moreno, Julián C. and Clavijo-Montoya, Hernando Augusto and Cárdenas-Galindo, María Alejandra and Campos-Figueredo, Wilson David},
  doi          = {10.3389/frobt.2023.1251568},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1251568},
  shortjournal = {Front. Robot. AI},
  title        = {Corrigendum: bioethics and artificial intelligence: between deliberation on values and rational choice theory},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Corrigendum: CARMA II: A ground vehicle for autonomous
surveying of alpha, beta and gamma radiation. <em>FROBT</em>,
<em>10</em>, 1237449. (<a
href="https://doi.org/10.3389/frobt.2023.1237449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Nouri Rahmat Abadi, Bahman and West, Andrew and Peel, Harriet and Nancekievill, Matthew and Ballard, Christopher and Lennox, Barry and Marjanovic, Ognjen and Groves, Keir},
  doi          = {10.3389/frobt.2023.1237449},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1237449},
  shortjournal = {Front. Robot. AI},
  title        = {Corrigendum: CARMA II: a ground vehicle for autonomous surveying of alpha, beta and gamma radiation},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Research on path planning of autonomous manganese nodule
mining vehicle based on lifting mining system. <em>FROBT</em>,
<em>10</em>, 1224115. (<a
href="https://doi.org/10.3389/frobt.2023.1224115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep-sea manganese nodules are abundant in the ocean, with high exploitation potential and commercial value, and have become mineral resources that coastal countries compete to develop. The pipeline-lifting mining system is the most promising deep-sea mining system at present. A deep-sea mining vehicle is the core equipment of this system. Mining quality and efficiency rely on mining vehicles to a great extent. According to the topographic and geomorphic environmental characteristics of deep-sea manganese nodules at the bottom of the ocean, a new deep-sea mining system based on an autonomous manganese nodule mining vehicle is proposed in this paper. According to the operating environment and functional requirements of the seabed, a new mining method is proposed, and the global traverse path planning research of the autonomous manganese nodule mining vehicle based on this mining method is carried out. The arc round-trip acquisition path planning method is put forward, and the simulation verification shows that the method effectively solves the problems of low efficiency of mining vehicle traversing acquisition and obstacle avoidance.},
  archive      = {J_FROBT},
  author       = {Xie, Yingchun and Liu, Chaoqun and Chen, Xuguang and Liu, Guijie and Leng, Dingxin and Pan, Wei and Shao, Shuai},
  doi          = {10.3389/frobt.2023.1224115},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1224115},
  shortjournal = {Front. Robot. AI},
  title        = {Research on path planning of autonomous manganese nodule mining vehicle based on lifting mining system},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Physiological responses of mechanosensory systems in the
head of larval zebrafish (danio rerio). <em>FROBT</em>, <em>10</em>,
1212626. (<a href="https://doi.org/10.3389/frobt.2023.1212626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The lateral line system of zebrafish consists of the anterior lateral line, with neuromasts distributed on the head, and the posterior lateral line, with neuromasts distributed on the trunk. The sensory afferent neurons are contained in the anterior and posterior lateral line ganglia, respectively. So far, the vast majority of physiological and developmental studies have focused on the posterior lateral line. However, studies that focus on the anterior lateral line, especially on its physiology, are very rare. The anterior lateral line involves different neuromast patterning processes, specific distribution of synapses, and a unique role in behavior. Here, we report our observations regarding the development of the lateral line and analyze the physiological responses of the anterior lateral line to mechanical and water jet stimuli. Sensing in the fish head may be crucial to avoid obstacles, catch prey, and orient in water current, especially in the absence of visual cues. Alongside the lateral line, the trigeminal system, with its fine nerve endings innervating the skin, could contribute to perceiving mechanosensory stimulation. Therefore, we compare the physiological responses of the lateral line afferent neurons to responses of trigeminal neurons and responsiveness of auditory neurons. We show that anterior lateral line neurons are tuned to the velocity of mechanosensory ramp stimulation, while trigeminal neurons either only respond to mechanical step stimuli or fast ramp and step stimuli. Auditory neurons did not respond to mechanical or water jet stimuli. These results may prove to be essential in designing underwater robots and artificial lateral lines, with respect to the spectra of stimuli that the different mechanosensory systems in the larval head are tuned to, and underline the importance and functionality of the anterior lateral line system in the larval fish head.},
  archive      = {J_FROBT},
  author       = {Brehm, Nils and Wenke, Nils and Glessner, Keshia and Haehnel-Taguchi, Melanie},
  doi          = {10.3389/frobt.2023.1212626},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1212626},
  shortjournal = {Front. Robot. AI},
  title        = {Physiological responses of mechanosensory systems in the head of larval zebrafish (Danio rerio)},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised monocular depth estimation for high field of
view colonoscopy cameras. <em>FROBT</em>, <em>10</em>, 1212525. (<a
href="https://doi.org/10.3389/frobt.2023.1212525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical colonoscopy is the gold standard procedure to detect colorectal cancer, the fourth most common cancer in the United Kingdom. Up to 22%–28% of polyps can be missed during the procedure that is associated with interval cancer. A vision-based autonomous soft endorobot for colonoscopy can drastically improve the accuracy of the procedure by inspecting the colon more systematically with reduced discomfort. A three-dimensional understanding of the environment is essential for robot navigation and can also improve the adenoma detection rate. Monocular depth estimation with deep learning methods has progressed substantially, but collecting ground-truth depth maps remains a challenge as no 3D camera can be fitted to a standard colonoscope. This work addresses this issue by using a self-supervised monocular depth estimation model that directly learns depth from video sequences with view synthesis. In addition, our model accommodates wide field-of-view cameras typically used in colonoscopy and specific challenges such as deformable surfaces, specular lighting, non-Lambertian surfaces, and high occlusion. We performed qualitative analysis on a synthetic data set, a quantitative examination of the colonoscopy training model, and real colonoscopy videos in near real-time.},
  archive      = {J_FROBT},
  author       = {Mathew, Alwyn and Magerand, Ludovic and Trucco, Emanuele and Manfredi, Luigi},
  doi          = {10.3389/frobt.2023.1212525},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1212525},
  shortjournal = {Front. Robot. AI},
  title        = {Self-supervised monocular depth estimation for high field of view colonoscopy cameras},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Performance enhancement of the soft robotic segment for a
trunk-like arm. <em>FROBT</em>, <em>10</em>, 1210217. (<a
href="https://doi.org/10.3389/frobt.2023.1210217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trunk-like continuum robots have wide applications in manipulation and locomotion. In particular, trunk-like soft arms exhibit high dexterity and adaptability very similar to the creatures of the natural world. However, owing to the continuum and soft bodies, their performance in payload and spatial movements is limited. In this paper, we investigate the influence of key design parameters on robotic performance. It is verified that a larger workspace, lateral stiffness, payload, and bending moment could be achieved with adjustments to soft materials’ hardness, the height of module segments, and arrayed radius of actuators. Especially, a 55% increase in arrayed radius would enhance the lateral stiffness by 25% and a bending moment by 55%. An 80% increase in segment height would enlarge 112% of the elongation range and 70 % of the bending range. Around 200% and 150% increments in the segment’s lateral stiffness and payload forces, respectively, could be obtained by tuning the hardness of soft materials. These relations enable the design customization of trunk-like soft arms, in which this tapering structure ensures stability via the stocky base for an impact reduction of 50% compared to that of the tip and ensures dexterity of the long tip for a relatively larger bending range of over 400% compared to that of the base. The complete methodology of the design concept, analytical models, simulation, and experiments is developed to offer comprehensive guidelines for trunk-like soft robotic design and enable high performance in robotic manipulation.},
  archive      = {J_FROBT},
  author       = {Tang, Shaowu and Tang, Kailuan and Wu, Shijian and Xiao, Yin and Liu, Sicong and Yi, Juan and Wang, Zheng},
  doi          = {10.3389/frobt.2023.1210217},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1210217},
  shortjournal = {Front. Robot. AI},
  title        = {Performance enhancement of the soft robotic segment for a trunk-like arm},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gecko adhesion based sea star crawler robot. <em>FROBT</em>,
<em>10</em>, 1209202. (<a
href="https://doi.org/10.3389/frobt.2023.1209202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the years, efforts in bioinspired soft robotics have led to mobile systems that emulate features of natural animal locomotion. This includes combining mechanisms from multiple organisms to further improve movement. In this work, we seek to improve locomotion in soft, amphibious robots by combining two independent mechanisms: sea star locomotion gait and gecko adhesion. Specifically, we present a sea star-inspired robot with a gecko-inspired adhesive surface that is able to crawl on a variety of surfaces. It is composed of soft and stretchable elastomer and has five limbs that are powered with pneumatic actuation. The gecko-inspired adhesion provides additional grip on wet and dry surfaces, thus enabling the robot to climb on 25° slopes and hold on statically to 51° slopes.},
  archive      = {J_FROBT},
  author       = {Acharya, Sampada and Roberts, Peter and Rane, Tejas and Singhal, Raghav and Hong, Peize and Ranade, Viraj and Majidi, Carmel and Webster-Wood, Victoria and Reeja-Jayan, B.},
  doi          = {10.3389/frobt.2023.1209202},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1209202},
  shortjournal = {Front. Robot. AI},
  title        = {Gecko adhesion based sea star crawler robot},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vitrimeric shape memory polymer-based fingertips for
adaptive grasping. <em>FROBT</em>, <em>10</em>, 1206579. (<a
href="https://doi.org/10.3389/frobt.2023.1206579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The variability in the shapes and sizes of objects presents a significant challenge for two-finger robotic grippers when it comes to manipulating them. Based on the chemistry of vitrimers (a new class of polymer materials that have dynamic covalent bonds, which allow them to reversibly change their mechanical properties under specific conditions), we present two designs as 3D-printed shape memory polymer-based shape-adaptive fingertips (SMP-SAF). The fingertips have two main properties needed for an effective grasping. First, the ability to adapt their shape to different objects. Second, exhibiting variable rigidity, to lock and retain this new shape without the need for any continuous external triggering system. Our two design strategies are: 1) A curved part, which is suitable for grasping delicate and fragile objects. In this mode and prior to gripping, the SMP-SAFs are straightened by the force of the parallel gripper and are adapted to the object by shape memory activation. 2) A straight part that takes on the form of the objects by contact force with them. This mode is better suited for gripping hard bodies and provides a more straightforward shape programming process. The SMP-SAFs can be programmed by heating them up above glass transition temperature (54°C) via Joule-effect of the integrated electrically conductive wire or by using a heat gun, followed by reshaping by the external forces (without human intervention), and subsequently fixing the new shape upon cooling. As the shape programming process is time-consuming, this technique suits adaptive sorting lines where the variety of objects is not changed from grasp to grasp, but from batch to batch.},
  archive      = {J_FROBT},
  author       = {Kashef Tabrizian, Seyedreza and Alabiso, Walter and Shaukat, Usman and Terryn, Seppe and Rossegger, Elisabeth and Brancart, Joost and Legrand, Julie and Schlögl, Sandra and Vanderborght, Bram},
  doi          = {10.3389/frobt.2023.1206579},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1206579},
  shortjournal = {Front. Robot. AI},
  title        = {Vitrimeric shape memory polymer-based fingertips for adaptive grasping},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using human-in-the-loop optimization for guiding manual
prosthesis adjustments: A proof-of-concept study. <em>FROBT</em>,
<em>10</em>, 1183170. (<a
href="https://doi.org/10.3389/frobt.2023.1183170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Human-in-the-loop optimization algorithms have proven useful in optimizing complex interactive problems, such as the interaction between humans and robotic exoskeletons. Specifically, this methodology has been proven valid for reducing metabolic cost while wearing robotic exoskeletons. However, many prostheses and orthoses still consist of passive elements that require manual adjustments of settings.Methods: In the present study, we investigated if human-in-the-loop algorithms could guide faster manual adjustments in a procedure similar to fitting a prosthesis. Eight healthy participants wore a prosthesis simulator and walked on a treadmill at 0.8 ms−1 under 16 combinations of shoe heel height and pylon height. A human-in-the-loop optimization algorithm was used to find an optimal combination for reducing the loading rate on the limb contralateral to the prosthesis simulator. To evaluate the performance of the optimization algorithm, we used a convergence criterium. We evaluated the accuracy by comparing it against the optimum from a full sweep of all combinations.Results: In five out of the eight participants, the human-in-the-loop optimization reduced the time taken to find an optimal combination; however, in three participants, the human-in-the-loop optimization either converged by the last iteration or did not converge.Discussion: Findings from this study show that the human-in-the-loop methodology could be helpful in tasks that require manually adjusting an assistive device, such as optimizing an unpowered prosthesis. However, further research is needed to achieve robust performance and evaluate applicability in persons with amputation wearing an actual prosthesis.},
  archive      = {J_FROBT},
  author       = {Senatore, Siena C. and Takahashi, Kota Z. and Malcolm, Philippe},
  doi          = {10.3389/frobt.2023.1183170},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1183170},
  shortjournal = {Front. Robot. AI},
  title        = {Using human-in-the-loop optimization for guiding manual prosthesis adjustments: A proof-of-concept study},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The potential of robot eyes as predictive cues in HRI—an
eye-tracking study. <em>FROBT</em>, <em>10</em>, 1178433. (<a
href="https://doi.org/10.3389/frobt.2023.1178433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots currently provide only a limited amount of information about their future movements to human collaborators. In human interaction, communication through gaze can be helpful by intuitively directing attention to specific targets. Whether and how this mechanism could benefit the interaction with robots and how a design of predictive robot eyes in general should look like is not well understood. In a between-subjects design, four different types of eyes were therefore compared with regard to their attention directing potential: a pair of arrows, human eyes, and two anthropomorphic robot eye designs. For this purpose, 39 subjects performed a novel, screen-based gaze cueing task in the laboratory. Participants’ attention was measured using manual responses and eye-tracking. Information on the perception of the tested cues was provided through additional subjective measures. All eye models were overall easy to read and were able to direct participants’ attention. The anthropomorphic robot eyes were most efficient at shifting participants’ attention which was revealed by faster manual and saccadic reaction times. In addition, a robot equipped with anthropomorphic eyes was perceived as being more competent. Abstract anthropomorphic robot eyes therefore seem to trigger a reflexive reallocation of attention. This points to a social and automatic processing of such artificial stimuli.},
  archive      = {J_FROBT},
  author       = {Onnasch, Linda and Schweidler, Paul and Schmidt, Helena},
  doi          = {10.3389/frobt.2023.1178433},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1178433},
  shortjournal = {Front. Robot. AI},
  title        = {The potential of robot eyes as predictive cues in HRI—an eye-tracking study},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust design of a machine learning-based GNSS NLOS detector
with multi-frequency features. <em>FROBT</em>, <em>10</em>, 1171255. (<a
href="https://doi.org/10.3389/frobt.2023.1171255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The robust detection of GNSS non-line-of-sight (NLOS) signals is of vital importance for land- and close-to-land-based safe navigation applications. The usage of GNSS measurements affected by NLOS can lead to large unbounded positioning errors and loss of safety. Due to the complex signal conditions in urban environments, the use of machine learning or artificial intelligence techniques and algorithms has recently been identified as potential tools to classify GNSS LOS/NLOS signals. The design of machine learning algorithms with GNSS features is an emerging field of research that must, however, be tackled carefully to avoid biased estimation results and to guarantee algorithms that can be generalized for different scenarios, receivers, antennas, and their specific installations and configurations. This work first provides new options to guarantee a proper generalization of trained algorithms by means of a pre-normalization of features with models extracted in open-sky (nominal) scenarios. The second main contribution focuses on designing a branched (or parallel) machine learning process to handle the intermittent presence of GNSS features in certain frequencies. This allows to exploit measurements in all available frequencies as compared to current approaches in the literature based on only the single frequency. The detection by means of logistic regression not only provides a binary LOS/NLOS decision but also an associated probability which can be used in the future as a means to weight-specific measurements. The detection with the proposed branched logistic regression with pre-normalized multi-frequency features has shown better results than the state-of-the-art algorithms, reaching 90% detection accuracy in the validation scenarios evaluated.},
  archive      = {J_FROBT},
  author       = {García Crespillo, Omar and Ruiz-Sicilia, Juan Carlos and Kliman, Ana and Marais, Juliette},
  doi          = {10.3389/frobt.2023.1171255},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1171255},
  shortjournal = {Front. Robot. AI},
  title        = {Robust design of a machine learning-based GNSS NLOS detector with multi-frequency features},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development of a novel hybrid securing actuator for a
self-securing soft robotic hand exoskeleton. <em>FROBT</em>,
<em>10</em>, 1164819. (<a
href="https://doi.org/10.3389/frobt.2023.1164819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of soft robotic hand exoskeletons for rehabilitation has been well-reported in the literature, whereby the emphasis was placed on the development of soft actuators for flexion and extension. Little attention was focused on developing the glove interface and attachments of actuators to the hand. As these hand exoskeletons are largely developed for personnel with impaired hand function for rehabilitation, it may be tedious to aid the patients in donning and doffing the glove, given that patients usually have stiff fingers exhibiting high muscle tone. To address this issue, a hybrid securing actuator was developed and powered pneumatically to allow for rapid securing and release of a body segment. As a proof of concept, the actuator was further adapted into a self-securing glove mechanism and assembled into a complete self-securing soft robotic hand exoskeleton with the attachment of bidirectional actuators. Our validation tests show that the self-wearing soft robotic hand exoskeleton can easily conform and secure onto the human hand and assist with manipulation tasks.},
  archive      = {J_FROBT},
  author       = {Hernandez-Barraza, Luis and Fraiszudeen, Azmall and Yuan Lee, Daniel Lim and Chen-Hua Yeow, Raye},
  doi          = {10.3389/frobt.2023.1164819},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1164819},
  shortjournal = {Front. Robot. AI},
  title        = {Development of a novel hybrid securing actuator for a self-securing soft robotic hand exoskeleton},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimizing human-robot handovers: The impact of adaptive
transport methods. <em>FROBT</em>, <em>10</em>, 1155143. (<a
href="https://doi.org/10.3389/frobt.2023.1155143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans are increasingly coming into direct physical contact with robots in the context of object handovers. The technical development of robots is progressing so that handovers can be better adapted to humans. An important criterion for successful handovers between robots and humans is the predictability of the robot for the human. The better humans can anticipate the robot’s actions, the better they can adapt to them and thus achieve smoother handovers. In the context of this work, it was investigated whether a highly adaptive transport method of the object, adapted to the human hand, leads to better handovers than a non-adaptive transport method with a predefined target position. To ensure robust handovers at high repetition rates, a Franka Panda robotic arm with a gripper equipped with an Intel RealSense camera and capacitive proximity sensors in the gripper was used. To investigate the handover behavior, a study was conducted with n = 40 subjects, each performing 40 handovers in four consecutive runs. The dependent variables examined are physical handover time, early handover intervention before the robot reaches its target position, and subjects’ subjective ratings. The adaptive transport method does not result in significantly higher mean physical handover times than the non-adaptive transport method. The non-adaptive transport method does not lead to a significantly earlier handover intervention in the course of the runs than the adaptive transport method. Trust in the robot and the perception of safety are rated significantly lower for the adaptive transport method than for the non-adaptive transport method. The physical handover time decreases significantly for both transport methods within the first two runs. For both transport methods, the percentage of handovers with a physical handover time between 0.1 and 0.2 s increases sharply, while the percentage of handovers with a physical handover time of &amp;gt;0.5 s decreases sharply. The results can be explained by theories of motor learning. From the experience of this study, an increased understanding of motor learning and adaptation in the context of human-robot interaction can be of great benefit for further technical development in robotics and for the industrial use of robots.},
  archive      = {J_FROBT},
  author       = {Käppler, Marco and Mamaev, Ilshat and Alagi, Hosam and Stein, Thorsten and Deml, Barbara},
  doi          = {10.3389/frobt.2023.1155143},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1155143},
  shortjournal = {Front. Robot. AI},
  title        = {Optimizing human-robot handovers: The impact of adaptive transport methods},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interactively learning behavior trees from imperfect human
demonstrations. <em>FROBT</em>, <em>10</em>, 1152595. (<a
href="https://doi.org/10.3389/frobt.2023.1152595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: In Interactive Task Learning (ITL), an agent learns a new task through natural interaction with a human instructor. Behavior Trees (BTs) offer a reactive, modular, and interpretable way of encoding task descriptions but have not yet been applied a lot in robotic ITL settings. Most existing approaches that learn a BT from human demonstrations require the user to specify each action step-by-step or do not allow for adapting a learned BT without the need to repeat the entire teaching process from scratch.Method: We propose a new framework to directly learn a BT from only a few human task demonstrations recorded as RGB-D video streams. We automatically extract continuous pre- and post-conditions for BT action nodes from visual features and use a Backchaining approach to build a reactive BT. In a user study on how non-experts provide and vary demonstrations, we identify three common failure cases of an BT learned from potentially imperfect initial human demonstrations. We offer a way to interactively resolve these failure cases by refining the existing BT through interaction with a user over a web-interface. Specifically, failure cases or unknown states are detected automatically during the execution of a learned BT and the initial BT is adjusted or extended according to the provided user input.Evaluation and results: We evaluate our approach on a robotic trash disposal task with 20 human participants and demonstrate that our method is capable of learning reactive BTs from only a few human demonstrations and interactively resolving possible failure cases at runtime.},
  archive      = {J_FROBT},
  author       = {Scherf, Lisa and Schmidt, Aljoscha and Pal, Suman and Koert, Dorothea},
  doi          = {10.3389/frobt.2023.1152595},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1152595},
  shortjournal = {Front. Robot. AI},
  title        = {Interactively learning behavior trees from imperfect human demonstrations},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Influence of collaborative customer service by service
robots and clerks in bakery stores. <em>FROBT</em>, <em>10</em>,
1125308. (<a href="https://doi.org/10.3389/frobt.2023.1125308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, various service robots have been deployed in stores as recommendation systems. Previous studies have sought to increase the influence of these robots by enhancing their social acceptance and trust. However, when such service robots recommend a product to customers in real environments, the effect on the customers is influenced not only by the robot itself, but also by the social influence of the surrounding people such as store clerks. Therefore, leveraging the social influence of the clerks may increase the influence of the robots on the customers. Hence, we compared the influence of robots with and without collaborative customer service between the robots and clerks in two bakery stores. The experimental results showed that collaborative customer service increased the purchase rate of the recommended bread and improved the impressions of the robot and store experience of the customers. Because the results also showed that the workload required for the clerks to collaborate with the robot was not high, this study suggests that all stores with service robots may demonstrate high effectiveness in introducing collaborative customer service.},
  archive      = {J_FROBT},
  author       = {Okafuji, Yuki and Song, Sichao and Baba, Jun and Yoshikawa, Yuichiro and Ishiguro, Hiroshi},
  doi          = {10.3389/frobt.2023.1125308},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1125308},
  shortjournal = {Front. Robot. AI},
  title        = {Influence of collaborative customer service by service robots and clerks in bakery stores},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Compliant robotic behaviors for satellite servicing.
<em>FROBT</em>, <em>10</em>, 1124207. (<a
href="https://doi.org/10.3389/frobt.2023.1124207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The demands of traditional industrial robotics differ significantly from those of space robotics. While industry requires robots that can perform repetitive tasks with precision and speed, the space environment needs robots to cope with uncertainties, dynamics, and communication delays or interruptions, similar to human astronauts. These demands make a well-suited application for compliant robotics and behavior-based programming. Pose Target Wrench Limiting (PTWL) is a compliant behavior paradigm developed specifically to meet these demands. PTWL controls a robot by moving a virtual attractor to a target pose. The attractor applies virtual forces, based on stiffness and damping presets, to an underlying admittance controller. Guided by virtual forces, the robot will follow the attractor until safety conditions are violated or success criteria are met. We tested PTWL on a variety of quasi-static tasks that may be useful for future space operations. Our results demonstrate that PTWL is an extremely powerful tool. It makes teleoperation easy and safe for a wide range of quasi-static tasks. It also facilitates the creation of semi-autonomous state machines that can reliably complete complex tasks with minimal human intervention.},
  archive      = {J_FROBT},
  author       = {Cressman, Joseph and Pokharna, Rahul and Newman, Wyatt},
  doi          = {10.3389/frobt.2023.1124207},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1124207},
  shortjournal = {Front. Robot. AI},
  title        = {Compliant robotic behaviors for satellite servicing},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Curriculum-reinforcement learning on simulation platform of
tendon-driven high-degree of freedom underactuated manipulator.
<em>FROBT</em>, <em>10</em>, 1066518. (<a
href="https://doi.org/10.3389/frobt.2023.1066518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A high degree of freedom (DOF) benefits manipulators by presenting various postures when reaching a target. Using a tendon-driven system with an underactuated structure can provide flexibility and weight reduction to such manipulators. The design and control of such a composite system are challenging owing to its complicated architecture and modeling difficulties. In our previous study, we developed a tendon-driven, high-DOF underactuated manipulator inspired from an ostrich neck referred to as the Robostrich arm. This study particularly focused on the control problems and simulation development of such a tendon-driven high-DOF underactuated manipulator. We proposed a curriculum-based reinforcement-learning approach. Inspired by human learning, progressing from simple to complex tasks, the Robostrich arm can obtain manipulation abilities by step-by-step reinforcement learning ranging from simple position control tasks to practical application tasks. In addition, an approach was developed to simulate tendon-driven manipulation with a complicated structure. The results show that the Robostrich arm can continuously reach various targets and simultaneously maintain its tip at the desired orientation while mounted on a mobile platform in the presence of perturbation. These results show that our system can achieve flexible manipulation ability even if vibrations are presented by locomotion.},
  archive      = {J_FROBT},
  author       = {Or, Keung and Wu, Kehua and Nakano, Kazashi and Ikeda, Masahiro and Ando, Mitsuhito and Kuniyoshi, Yasuo and Niiyama, Ryuma},
  doi          = {10.3389/frobt.2023.1066518},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1066518},
  shortjournal = {Front. Robot. AI},
  title        = {Curriculum-reinforcement learning on simulation platform of tendon-driven high-degree of freedom underactuated manipulator},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SPaM: Soft patch matching for non-rigid pointcloud
registration. <em>FROBT</em>, <em>10</em>, 1019579. (<a
href="https://doi.org/10.3389/frobt.2023.1019579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3d reconstruction of deformable objects in dynamic scenes forms the fundamental basis of many robotic applications. Existing mesh-based approaches compromise registration accuracy, and lose important details due to interpolation and smoothing. Additionally, existing non-rigid registration techniques struggle with unindexed points and disconnected manifolds. We propose a novel non-rigid registration framework for raw, unstructured, deformable point clouds purely based on geometric features. The global non-rigid deformation of an object is formulated as an aggregation of locally rigid transformations. The concept of locality is embodied in soft patches described by geometrical properties based on SHOT descriptor and its neighborhood. By considering the confidence score of pairwise association between soft patches of two scans (not necessarily consecutive), a computed similarity matrix serves as the seed to grow a correspondence graph which leverages rigidity terms defined in As-Rigid-As-Possible for pruning and optimization. Experiments on simulated and publicly available datasets demonstrate the capability of the proposed approach to cope with large deformations blended with numerous missing parts in the scan process.},
  archive      = {J_FROBT},
  author       = {Maleki, Behnam and Falque, Raphael and Vidal-Calleja, Teresa and Alempijevic, Alen},
  doi          = {10.3389/frobt.2023.1019579},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1019579},
  shortjournal = {Front. Robot. AI},
  title        = {SPaM: Soft patch matching for non-rigid pointcloud registration},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Chat agents respond more empathetically by using hearsay
experience. <em>FROBT</em>, <em>10</em>, 960087. (<a
href="https://doi.org/10.3389/frobt.2023.960087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the responses of chat dialogue systems have become more natural, the empathy skill of dialogue systems has become an important new issue. In text-based chat dialogue systems, the definition of empathy is not precise, and how to design the kind of utterance that improves the user’s impression of receiving empathy is not clear since the main method used is to imitate utterances and dialogues that humans consider empathetic. In this study, we focus on the necessity of grasping an agent as an experienceable Other, which is considered the most important factor when empathy is performed by an agent, and propose an utterance design that directly conveys the fact that the agent can experience and feel empathy through text. Our system has an experience database including the system’s pseudo-experience and feelings to show empathetic feelings. Then, the system understands the user’s experiences and empathizes with the user on the basis of the system’s experience database, in line with the dialogue content. As a result of developing and evaluating several systems with different ways of conveying the aforementioned rationale, we found that conveying the rationale as a hearsay experience improved the user’s impression of receiving empathy more than conveying it as the system’s own experience. Moreover, an exhaustive evaluation shows that our empathetic utterance design using hearsay experience is effective to improve the user’s impression about the system’s cognitive empathy.},
  archive      = {J_FROBT},
  author       = {Narimatsu, Hiromi and Sugiyama, Hiroaki and Mizukami, Masahiro and Arimoto, Tsunehiro},
  doi          = {10.3389/frobt.2023.960087},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {960087},
  shortjournal = {Front. Robot. AI},
  title        = {Chat agents respond more empathetically by using hearsay experience},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Corrigendum: Soft robotics in wearable and implantable
medical applications: Translational challenges and future outlooks.
<em>FROBT</em>, <em>10</em>, 1243121. (<a
href="https://doi.org/10.3389/frobt.2023.1243121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Paternò, Linda and Lorenzon, Lucrezia},
  doi          = {10.3389/frobt.2023.1243121},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1243121},
  shortjournal = {Front. Robot. AI},
  title        = {Corrigendum: soft robotics in wearable and implantable medical applications: translational challenges and future outlooks},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Interaction between automated vehicles and other
road users. <em>FROBT</em>, <em>10</em>, 1228093. (<a
href="https://doi.org/10.3389/frobt.2023.1228093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Wintersberger, Philipp and Dey, Debargha and Löcken, Andreas},
  doi          = {10.3389/frobt.2023.1228093},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1228093},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Interaction between automated vehicles and other road users},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feeling the beat: A smart hand exoskeleton for learning to
play musical instruments. <em>FROBT</em>, <em>10</em>, 1212768. (<a
href="https://doi.org/10.3389/frobt.2023.1212768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Individuals who have suffered neurotrauma like a stroke or brachial plexus injury often experience reduced limb functionality. Soft robotic exoskeletons have been successful in assisting rehabilitative treatment and improving activities of daily life but restoring dexterity for tasks such as playing musical instruments has proven challenging. This research presents a soft robotic hand exoskeleton coupled with machine learning algorithms to aid in relearning how to play the piano by ‘feeling’ the difference between correct and incorrect versions of the same song. The exoskeleton features piezoresistive sensor arrays with 16 taxels integrated into each fingertip. The hand exoskeleton was created as a single unit, with polyvinyl acid (PVA) used as a stent and later dissolved to construct the internal pressure chambers for the five individually actuated digits. Ten variations of a song were produced, one that was correct and nine containing rhythmic errors. To classify these song variations, Random Forest (RF), K-Nearest Neighbor (KNN), and Artificial Neural Network (ANN) algorithms were trained with data from the 80 taxels combined from the tactile sensors in the fingertips. Feeling the differences between correct and incorrect versions of the song was done with the exoskeleton independently and while the exoskeleton was worn by a person. Results demonstrated that the ANN algorithm had the highest classification accuracy of 97.13% ± 2.00% with the human subject and 94.60% ± 1.26% without. These findings highlight the potential of the smart exoskeleton to aid disabled individuals in relearning dexterous tasks like playing musical instruments.},
  archive      = {J_FROBT},
  author       = {Lin, Maohua and Paul, Rudy and Abd, Moaed and Jones, James and Dieujuste, Darryl and Chim, Harvey and Engeberg, Erik D.},
  doi          = {10.3389/frobt.2023.1212768},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1212768},
  shortjournal = {Front. Robot. AI},
  title        = {Feeling the beat: A smart hand exoskeleton for learning to play musical instruments},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Navigation with minimal occupation volume for teleoperated
snake-like surgical robots: MOVE. <em>FROBT</em>, <em>10</em>, 1211876.
(<a href="https://doi.org/10.3389/frobt.2023.1211876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Master-Slave control is a common mode of operation for surgical robots as it ensures that surgeons are always in control and responsible for the procedure. Most teleoperated surgical systems use low degree-of-freedom (DOF) instruments, thus facilitating direct mapping of manipulator position to the instrument pose and tip location (tip-to-tip mapping). However, with the introduction of continuum and snake-like robots with much higher DOF supported by their inherent redundant architecture for navigating through curved anatomical pathways, there is a need for developing effective kinematic methods that can actuate all the joints in a controlled fashion. This paper introduces the concept of navigation with Minimal Occupation VolumE (MOVE), a teleoperation method that extends the concept of follow-the-leader navigation. It defines the path taken by the head while using all the available space surrounding the robot constrained by individual joint limits. The method was developed for the i2Snake robot and validated with detailed simulation and control experiments. The results validate key performance indices such as path following, body weights, path weights, fault tolerance and conservative motion. The MOVE solver can run in real-time on a standard computer at frequencies greater than 1 kHz.},
  archive      = {J_FROBT},
  author       = {Berthet-Rayne, Pierre and Yang, Guang-Zhong},
  doi          = {10.3389/frobt.2023.1211876},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1211876},
  shortjournal = {Front. Robot. AI},
  title        = {Navigation with minimal occupation volume for teleoperated snake-like surgical robots: MOVE},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Passivity based nonlinear model predictive control (PNMPC)
of multi-robot systems for space applications. <em>FROBT</em>,
<em>10</em>, 1181128. (<a
href="https://doi.org/10.3389/frobt.2023.1181128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past 2 decades, there has been increasing interest in autonomous multi-robot systems for space use. They can assemble space structures and provide services for other space assets. The utmost significance lies in the performance, stability, and robustness of these space operations. By considering system dynamics and constraints, the Model Predictive Control (MPC) framework optimizes performance. Unlike other methods, standard MPC can offer greater robustness due to its receding horizon nature. However, current literature on MPC application to space robotics primarily focuses on linear models, which is not suitable for highly non-linear multi-robot systems. Although Nonlinear MPC (NMPC) shows promise for free-floating space manipulators, current NMPC applications are limited to unconstrained non-linear systems and do not guarantee closed-loop stability. This paper introduces a novel approach to NMPC using the concept of passivity to multi-robot systems for space applications. By utilizing a passivity-based state constraint and a terminal storage function, the proposed PNMPC scheme ensures closed-loop stability and a superior performance. Therefore, this approach offers an alternative method to the control Lyapunov function for control of non-linear multi-robot space systems and applications, as stability and passivity exhibit a close relationship. Finally, this paper demonstrates that the benefits of passivity-based concepts and NMPC can be combined into a single NMPC scheme that maintains the advantages of each, including closed-loop stability through passivity and good performance through one-line optimization in NMPC.},
  archive      = {J_FROBT},
  author       = {Kalaycioglu, Serdar and De Ruiter, Anton},
  doi          = {10.3389/frobt.2023.1181128},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1181128},
  shortjournal = {Front. Robot. AI},
  title        = {Passivity based nonlinear model predictive control (PNMPC) of multi-robot systems for space applications},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed cooperative kalman filter constrained by
advection–diffusion equation for mobile sensor networks. <em>FROBT</em>,
<em>10</em>, 1175418. (<a
href="https://doi.org/10.3389/frobt.2023.1175418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a distributed cooperative filtering strategy for state estimation has been developed for mobile sensor networks in a spatial–temporal varying field modeled by the advection–diffusion equation. Sensors are organized into distributed cells that resemble a mesh grid covering a spatial area, and estimation of the field value and gradient information at each cell center is obtained by running a constrained cooperative Kalman filter while incorporating the sensor measurements and information from neighboring cells. Within each cell, the finite volume method is applied to discretize and approximate the advection–diffusion equation. These approximations build the weakly coupled relationships between neighboring cells and define the constraints that the cooperative Kalman filters are subjected to. With the estimated information, a gradient-based formation control law has been developed that enables the sensor network to adjust formation size by utilizing the estimated gradient information. Convergence analysis has been conducted for both the distributed constrained cooperative Kalman filter and the formation control. Simulation results with a 9-cell 12-sensor network validate the proposed distributed filtering method and control law.},
  archive      = {J_FROBT},
  author       = {Zhang, Ziqiao and Mayberry, Scott T. and Wu, Wencen and Zhang, Fumin},
  doi          = {10.3389/frobt.2023.1175418},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1175418},
  shortjournal = {Front. Robot. AI},
  title        = {Distributed cooperative kalman filter constrained by advection–diffusion equation for mobile sensor networks},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Virtual reality check: A comparison of virtual reality,
screen-based, and real world settings as research methods for HRI.
<em>FROBT</em>, <em>10</em>, 1156715. (<a
href="https://doi.org/10.3389/frobt.2023.1156715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To reduce costs and effort, experiments in human-robot interaction can be carried out in Virtual Reality (VR) or in screen-based (SB) formats. However, it is not well examined whether robots are perceived and experienced in the same way in VR and SB as they are in the physical world. This study addresses this topic in a between-subjects experiment, measuring trust and engagement of an interaction with a mobile service robot in a museum scenario. Measures were made in three different settings, either the real world, in VR or in a game-like SB and then compared with an ANOVA. The results indicate, that neither trust nor engagement differ dependent on the experimental setting. The results imply that both VR and SB are eligible ways to explore the interaction with a mobile service robot, if some peculiarities of each medium are taken into account.},
  archive      = {J_FROBT},
  author       = {Plomin, Jana and Schweidler, Paul and Oehme, Astrid},
  doi          = {10.3389/frobt.2023.1156715},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1156715},
  shortjournal = {Front. Robot. AI},
  title        = {Virtual reality check: A comparison of virtual reality, screen-based, and real world settings as research methods for HRI},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feeling with a robot—the role of anthropomorphism by design
and the tendency to anthropomorphize in human-robot interaction.
<em>FROBT</em>, <em>10</em>, 1149601. (<a
href="https://doi.org/10.3389/frobt.2023.1149601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The implementation of anthropomorphic features in regard to appearance and framing is widely supposed to increase empathy towards robots. However, recent research used mainly tasks that are rather atypical for daily human-robot interactions like sacrificing or destroying robots. The scope of the current study was to investigate the influence of anthropomorphism by design on empathy and empathic behavior in a more realistic, collaborative scenario. In this online experiment, participants collaborated either with an anthropomorphic or a technical looking robot and received either an anthropomorphic or a technical description of the respective robot. After the task completion, we investigated situational empathy by displaying a choice-scenario in which participants needed to decide whether they wanted to act empathically towards the robot (sign a petition or a guestbook for the robot) or non empathically (leave the experiment). Subsequently, the perception of and empathy towards the robot was assessed. The results revealed no significant influence of anthropomorphism on empathy and participants’ empathic behavior. However, an exploratory follow-up analysis indicates that the individual tendency to anthropomorphize might be crucial for empathy. This result strongly supports the importance to consider individual difference in human-robot interaction. Based on the exploratory analysis, we propose six items to be further investigated as empathy questionnaire in HRI.},
  archive      = {J_FROBT},
  author       = {Schömbs, Sarah and Klein, Jacobe and Roesler, Eileen},
  doi          = {10.3389/frobt.2023.1149601},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1149601},
  shortjournal = {Front. Robot. AI},
  title        = {Feeling with a robot—the role of anthropomorphism by design and the tendency to anthropomorphize in human-robot interaction},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Bioethics and artificial intelligence: Between deliberation
on values and rational choice theory. <em>FROBT</em>, <em>10</em>,
1140901. (<a href="https://doi.org/10.3389/frobt.2023.1140901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present work revisits how artificial intelligence, as technology and ideology, is based on the rational choice theory and the techno-liberal discourse, supported by large corporations and investment funds. Those that promote using different algorithmic processes (such as filter bubbles or echo chambers) create homogeneous and polarized spaces that reinforces people’s ethical, ideological, and political narratives. These mechanisms validate bubbles of choices as statements of fact and contravene the prerequisites for exercising deliberation in pluralistic societies, such as the distinction between data and values, the affirmation of reasonable dissent, and the relevance of diversity as a condition indispensable for democratic deliberation.},
  archive      = {J_FROBT},
  author       = {Pinto-Bustamante, Boris Julián and Riaño-Moreno, Julián C. and Clavijo-Montoya, Hernando Augusto and Cárdenas-Galindo, María Alejandra and Campos-Figueredo, Wilson David},
  doi          = {10.3389/frobt.2023.1140901},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1140901},
  shortjournal = {Front. Robot. AI},
  title        = {Bioethics and artificial intelligence: Between deliberation on values and rational choice theory},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Airborne gamma-ray mapping using fixed-wing vertical
take-off and landing (VTOL) uncrewed aerial vehicles. <em>FROBT</em>,
<em>10</em>, 1137763. (<a
href="https://doi.org/10.3389/frobt.2023.1137763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-cost uncrewed aerial vehicles (UAVs) are replacing manned aircraft for airborne radiation mapping applications such as nuclear accident response scenarios or surveying ore deposits and mine sites because of their cost-effectiveness and ability to conduct surveys at lower altitude compared to manned counterparts. Both multi-rotor UAVs and fixed-wing UAVs are well established technologies for aerial radiation mapping applications, however, both also have drawbacks: multi-rotor UAVs are very limited in flight time and range, and fixed-wing UAVs usually require facilities for take-off and landing. A compromise solution is introduced in this work, using a fixed-wing vertical take-off and landing (VTOL) UAV that combines the flexibility of a multi-rotor UAV with the range and flight time of a fixed-wing UAV. The first implementation of a VTOL with radiation mapping capabilities is presented, based on a commercial WingtraOne UAV augmented with CsI scintillator and CZT semiconductor gamma spectrometers. The radiation mapping capabilities of the prototype are demonstrated in a case study, mapping the distribution of radionuclides around the South Terras legacy uranium mine in the south of England, United Kingdom, and the results are compared with previous studies using multi-rotor and manned aircraft to survey the same area.},
  archive      = {J_FROBT},
  author       = {Woodbridge, Ewan and Connor, Dean T. and Verbelen, Yannick and Hine, Duncan and Richardson, Tom and Scott, Thomas B.},
  doi          = {10.3389/frobt.2023.1137763},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1137763},
  shortjournal = {Front. Robot. AI},
  title        = {Airborne gamma-ray mapping using fixed-wing vertical take-off and landing (VTOL) uncrewed aerial vehicles},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Does a robot’s gaze aversion affect human gaze aversion?
<em>FROBT</em>, <em>10</em>, 1127626. (<a
href="https://doi.org/10.3389/frobt.2023.1127626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaze cues serve an important role in facilitating human conversations and are generally considered to be one of the most important non-verbal cues. Gaze cues are used to manage turn-taking, coordinate joint attention, regulate intimacy, and signal cognitive effort. In particular, it is well established that gaze aversion is used in conversations to avoid prolonged periods of mutual gaze. Given the numerous functions of gaze cues, there has been extensive work on modelling these cues in social robots. Researchers have also tried to identify the impact of robot gaze on human participants. However, the influence of robot gaze behavior on human gaze behavior has been less explored. We conducted a within-subjects user study (N = 33) to verify if a robot’s gaze aversion influenced human gaze aversion behavior. Our results show that participants tend to avert their gaze more when the robot keeps staring at them as compared to when the robot exhibits well-timed gaze aversions. We interpret our findings in terms of intimacy regulation: humans try to compensate for the robot’s lack of gaze aversion.},
  archive      = {J_FROBT},
  author       = {Mishra, Chinmaya and Offrede, Tom and Fuchs, Susanne and Mooshammer, Christine and Skantze, Gabriel},
  doi          = {10.3389/frobt.2023.1127626},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1127626},
  shortjournal = {Front. Robot. AI},
  title        = {Does a robot’s gaze aversion affect human gaze aversion?},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robots with tears can convey enhanced sadness and elicit
support intentions. <em>FROBT</em>, <em>10</em>, 1121624. (<a
href="https://doi.org/10.3389/frobt.2023.1121624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The behaviour of shedding tears is a unique human expression of emotion. Human tears have an emotional signalling function that conveys sadness and a social signalling function that elicits support intention from others. The present study aimed to clarify whether the tears of robots have the same emotional and social signalling functions as human tears, using methods employed in previous studies conducted on human tears. Tear processing was applied to robot pictures to create pictures with and without tears, which were used as visual stimuli. In Study 1, the participants viewed pictures of robots with and without tears and rated the intensity of the emotion experienced by the robot in the picture. The results showed that adding tears to a robot’s picture significantly increased the rated intensity of sadness. Study 2 measured support intentions towards a robot by presenting a robot’s picture with a scenario. The results showed that adding tears to the robot’s picture also increased the support intentions indicating that robot tears have emotional and social signalling functions similar to those of human tears.},
  archive      = {J_FROBT},
  author       = {Yasuhara, Akiko and Takehara, Takuma},
  doi          = {10.3389/frobt.2023.1121624},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1121624},
  shortjournal = {Front. Robot. AI},
  title        = {Robots with tears can convey enhanced sadness and elicit support intentions},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Maneuvering on non-newtonian fluidic terrain: A survey of
animal and bio-inspired robot locomotion techniques on soft yielding
grounds. <em>FROBT</em>, <em>10</em>, 1113881. (<a
href="https://doi.org/10.3389/frobt.2023.1113881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frictionally yielding media are a particular type of non-Newtonian fluids that significantly deform under stress and do not recover their original shape. For example, mud, snow, soil, leaf litters, or sand are such substrates because they flow when stress is applied but do not bounce back when released. Some robots have been designed to move on those substrates. However, compared to moving on solid ground, significantly fewer prototypes have been developed and only a few prototypes have been demonstrated outside of the research laboratory. This paper surveys the existing biology and robotics literature to analyze principles of physics facilitating motion on yielding substrates. We categorize animal and robot locomotion based on the mechanical principles and then further on the nature of the contact: discrete contact, continuous contact above the material, or through the medium. Then, we extract different hardware solutions and motion strategies enabling different robots and animals to progress. The result reveals which design principles are more widely used and which may represent research gaps for robotics. We also discuss that higher level of abstraction helps transferring the solutions to the robotics domain also when the robot is not explicitly meant to be bio-inspired. The contribution of this paper is a review of the biology and robotics literature for identifying locomotion principles that can be applied for future robot design in yielding environments, as well as a catalog of existing solutions either in nature or man-made, to enable locomotion on yielding grounds.},
  archive      = {J_FROBT},
  author       = {Godon, Simon and Kruusmaa, Maarja and Ristolainen, Asko},
  doi          = {10.3389/frobt.2023.1113881},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1113881},
  shortjournal = {Front. Robot. AI},
  title        = {Maneuvering on non-newtonian fluidic terrain: A survey of animal and bio-inspired robot locomotion techniques on soft yielding grounds},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid soft material robotic end-effector for reversible
in-space assembly of strut components. <em>FROBT</em>, <em>10</em>,
1099297. (<a href="https://doi.org/10.3389/frobt.2023.1099297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the NASA in-Space Assembled Telescope (iSAT) study (Bulletin of the American Astronomical Society, 2019, 51, 50) which details the design and requirements for a 20-m parabolic in-space telescope, NASA Langley Research Center (LaRC) has been developing structural and robotic solutions to address the needs of building larger in-space assets. One of the structural methods studied involves stackable and collapsible modular solutions to address launch vehicle volume constraints. This solution uses a packing method that stacks struts in a dixie-cup like manner and a chemical composite bonding technique that reduces weight of the structure, adds strength, and offers the ability to de-bond the components for structural modifications. We present in this paper work towards a soft material robot end-effector, capable of suppling the manipulability, pressure, and temperature requirements for the bonding/de-bonding of these conical structural components. This work is done to investigate the feasibility of a hybrid soft robotic end-effector actuated by Twisted and Coiled Artificial Muscles (TCAMs) for in-space assembly tasks. TCAMs are a class of actuator which have garnered significant recent research interest due to their allowance for high force to weight ratio when compared to other popular methods of actuation within the field of soft robotics, and a muscle-tendon actuation design using TCAMs leads to a compact and lightweight system with controllable and tunable behavior. In addition to the muscle-tendon design, this paper also details the early investigation of an induction system for adhesive bonding/de-bonding and the sensors used for benchtop design and testing. Additionally, we discuss the viability of Robotic Operating System 2 (ROS2) and Gazebo modeling environments for soft robotics as they pertain to larger simulation efforts at LaRC. We show real world test results against simulation results for a method which divides the soft, continuous material of the end-effector into discrete links connected by spring-like joints.},
  archive      = {J_FROBT},
  author       = {Hammond, Maxwell and Dempsey, Anthony and Ward, William and Stewart, Stephen and Neilan, James H. and Friz, Jessica and Lamuta, Caterina and Cichella, Venanzio},
  doi          = {10.3389/frobt.2023.1099297},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1099297},
  shortjournal = {Front. Robot. AI},
  title        = {A hybrid soft material robotic end-effector for reversible in-space assembly of strut components},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An embarrassingly simple approach for visual navigation of
forest environments. <em>FROBT</em>, <em>10</em>, 1086798. (<a
href="https://doi.org/10.3389/frobt.2023.1086798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Navigation in forest environments is a challenging and open problem in the area of field robotics. Rovers in forest environments are required to infer the traversability of a priori unknown terrains, comprising a number of different types of compliant and rigid obstacles, under varying lighting and weather conditions. The challenges are further compounded for inexpensive small-sized (portable) rovers. While such rovers may be useful for collaboratively monitoring large tracts of forests as a swarm, with low environmental impact, their small-size affords them only a low viewpoint of their proximal terrain. Moreover, their limited view may frequently be partially occluded by compliant obstacles in close proximity such as shrubs and tall grass. Perhaps, consequently, most studies on off-road navigation typically use large-sized rovers equipped with expensive exteroceptive navigation sensors. We design a low-cost navigation system tailored for small-sized forest rovers. For navigation, a light-weight convolution neural network is used to predict depth images from RGB input images from a low-viewpoint monocular camera. Subsequently, a simple coarse-grained navigation algorithm aggregates the predicted depth information to steer our mobile platform towards open traversable areas in the forest while avoiding obstacles. In this study, the steering commands output from our navigation algorithm direct an operator pushing the mobile platform. Our navigation algorithm has been extensively tested in high-fidelity forest simulations and in field trials. Using no more than a 16 × 16 pixel depth prediction image from a 32 × 32 pixel RGB image, our algorithm running on a Raspberry Pi was able to successfully navigate a total of over 750 m of real-world forest terrain comprising shrubs, dense bushes, tall grass, fallen branches, fallen tree trunks, small ditches and mounds, and standing trees, under five different weather conditions and four different times of day. Furthermore, our algorithm exhibits robustness to changes in the mobile platform’s camera pitch angle, motion blur, low lighting at dusk, and high-contrast lighting conditions.},
  archive      = {J_FROBT},
  author       = {Niu, Chaoyue and Newlands, Callum and Zauner, Klaus-Peter and Tarapore, Danesh},
  doi          = {10.3389/frobt.2023.1086798},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1086798},
  shortjournal = {Front. Robot. AI},
  title        = {An embarrassingly simple approach for visual navigation of forest environments},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Corrigendum: Introducing a healthcare-assistive robot in
primary care: A preliminary questionnaire survey. <em>FROBT</em>,
<em>10</em>, 1224492. (<a
href="https://doi.org/10.3389/frobt.2023.1224492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Tan, N. C. and Yusoff, Y. and Koot, D. and Lau, Q. C. and Lim, H. and Hui, T. F. and Cher, H. Y. and Tan, P. Y. A. and Koh, Y. L. E.},
  doi          = {10.3389/frobt.2023.1224492},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1224492},
  shortjournal = {Front. Robot. AI},
  title        = {Corrigendum: introducing a healthcare-assistive robot in primary care: a preliminary questionnaire survey},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Corrigendum: Terrain awareness using a tracked skid-steering
vehicle with passive independent suspensions. <em>FROBT</em>,
<em>10</em>, 1204228. (<a
href="https://doi.org/10.3389/frobt.2023.1204228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Galati, Rocco and Reina, Giulio},
  doi          = {10.3389/frobt.2023.1204228},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1204228},
  shortjournal = {Front. Robot. AI},
  title        = {Corrigendum: Terrain awareness using a tracked skid-steering vehicle with passive independent suspensions},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A length-adjustable vacuum-powered artificial muscle for
wearable physiotherapy assistance in infants. <em>FROBT</em>,
<em>10</em>, 1190387. (<a
href="https://doi.org/10.3389/frobt.2023.1190387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft pneumatic artificial muscles are increasingly popular in the field of soft robotics due to their light-weight, complex motions, and safe interfacing with humans. In this paper, we present a Vacuum-Powered Artificial Muscle (VPAM) with an adjustable operating length that offers adaptability throughout its use, particularly in settings with variable workspaces. To achieve the adjustable operating length, we designed the VPAM with a modular structure consisting of cells that can be clipped in a collapsed state and unclipped as desired. We then conducted a case study in infant physical therapy to demonstrate the capabilities of our actuator. We developed a dynamic model of the device and a model-informed open-loop control system, and validated their accuracy in a simulated patient setup. Our results showed that the VPAM maintains its performance as it grows. This is crucial in applications such as infant physical therapy where the device must adapt to the growth of the patient during a 6-month treatment regime without actuator replacement. The ability to adjust the length of the VPAM on demand offers a significant advantage over traditional fixed-length actuators, making it a promising solution for soft robotics. This actuator has potential for various applications that can leverage on demand expansion and shrinking, including exoskeletons, wearable devices, medical robots, and exploration robots.},
  archive      = {J_FROBT},
  author       = {Gollob, Samuel Dutra and Mendoza, Mijaíl Jaén and Koo, Bon Ho Brandon and Centeno, Esteban and Vela, Emir A. and Roche, Ellen T.},
  doi          = {10.3389/frobt.2023.1190387},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1190387},
  shortjournal = {Front. Robot. AI},
  title        = {A length-adjustable vacuum-powered artificial muscle for wearable physiotherapy assistance in infants},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved jacobian matrix estimation applied to snake robots.
<em>FROBT</em>, <em>10</em>, 1190349. (<a
href="https://doi.org/10.3389/frobt.2023.1190349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two manipulator Jacobian matrix estimators for constrained planar snake robots are developed and tested, which enables the implementation of Jacobian-based obstacle-aided locomotion (OAL) control schemes. These schemes use obstacles in the robot’s vicinity to obtain propulsion. The devised estimators infer manipulator Jacobians for constrained planar snake robots in situations where the positions and number of surrounding obstacle constraints might change or are not precisely known. The first proposed estimator is an adaptation of contemporary research in soft robots and builds on convex optimization. The second estimator builds on the unscented Kalman filter. By simulations, we evaluate and compare the two devised algorithms in terms of their statistical performance, execution times, and robustness to measurement noise. We find that both algorithms lead to Jacobian matrix estimates that are similarly useful to predict end-effector movements. However, the unscented filter approach requires significantly lower computing resources and is not poised by convergence issues displayed by the convex optimization-based method. We foresee that the estimators may have use in other fields of research, such as soft robotics and visual servoing. The estimators may also be adapted for use in general non-planar snake robots.},
  archive      = {J_FROBT},
  author       = {Løwer, Jostein and Varagnolo, Damiano and Stavdahl, Øyvind},
  doi          = {10.3389/frobt.2023.1190349},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1190349},
  shortjournal = {Front. Robot. AI},
  title        = {Improved jacobian matrix estimation applied to snake robots},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Developing ChatGPT’s theory of mind. <em>FROBT</em>,
<em>10</em>, 1189525. (<a
href="https://doi.org/10.3389/frobt.2023.1189525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Marchetti, Antonella and Di Dio, Cinzia and Cangelosi, Angelo and Manzi, Federico and Massaro, Davide},
  doi          = {10.3389/frobt.2023.1189525},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1189525},
  shortjournal = {Front. Robot. AI},
  title        = {Developing ChatGPT’s theory of mind},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Point cloud completion in challenging indoor scenarios with
human motion. <em>FROBT</em>, <em>10</em>, 1184614. (<a
href="https://doi.org/10.3389/frobt.2023.1184614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combining and completing point cloud data from two or more sensors with arbitrarily relative perspectives in a dynamic, cluttered, and complex environment is challenging, especially when the two sensors have significant perspective differences while the large overlap ratio and feature-rich scene cannot be guaranteed. We create a novel approach targeting this challenging scenario by registering two camera captures in a time series with unknown perspectives and human movements to easily use our system in a real-life scene. In our approach, we first reduce the six unknowns of 3D point cloud completion to three by aligning the ground planes found by our previous perspective-independent 3D ground plane estimation algorithm. Subsequently, we use a histogram-based approach to identify and extract all the humans from each frame generating a three-dimensional (3D) human walking sequence in a time series. To enhance accuracy and performance, we convert 3D human walking sequences to lines by calculating the center of mass (CoM) point of each human body and connecting them. Finally, we match the walking paths in different data trials by minimizing the Fréchet distance between two walking paths and using 2D iterative closest point (ICP) to find the remaining three unknowns in the overall transformation matrix for the final alignment. Using this approach, we can successfully register the corresponding walking path of the human between the two cameras’ captures and estimate the transformation matrix between the two sensors.},
  archive      = {J_FROBT},
  author       = {Zhang, Chengsi and Czarnuch, Stephen},
  doi          = {10.3389/frobt.2023.1184614},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1184614},
  shortjournal = {Front. Robot. AI},
  title        = {Point cloud completion in challenging indoor scenarios with human motion},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptivity: A path towards general swarm intelligence?
<em>FROBT</em>, <em>10</em>, 1163185. (<a
href="https://doi.org/10.3389/frobt.2023.1163185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of multi-robot systems (MRS) has recently been gaining increasing popularity among various research groups, practitioners, and a wide range of industries. Compared to single-robot systems, multi-robot systems are able to perform tasks more efficiently or accomplish objectives that are simply not feasible with a single unit. This makes such multi-robot systems ideal candidates for carrying out distributed tasks in large environments—e.g., performing object retrieval, mapping, or surveillance. However, the traditional approach to multi-robot systems using global planning and centralized operation is, in general, ill-suited for fulfilling tasks in unstructured and dynamic environments. Swarming multi-robot systems have been proposed to deal with such steep challenges, primarily owing to its adaptivity. These qualities are expressed by the system’s ability to learn or change its behavior in response to new and/or evolving operating conditions. Given its importance, in this perspective, we focus on the critical importance of adaptivity for effective multi-robot system swarming and use it as the basis for defining, and potentially quantifying, swarm intelligence. In addition, we highlight the importance of establishing a suite of benchmark tests to measure a swarm’s level of adaptivity. We believe that a focus on achieving increased levels of swarm intelligence through the focus on adaptivity will further be able to elevate the field of swarm robotics.},
  archive      = {J_FROBT},
  author       = {Kwa, Hian Lee and Kit, Jabez Leong and Horsevad, Nikolaj and Philippot, Julien and Savari, Mohammad and Bouffanais, Roland},
  doi          = {10.3389/frobt.2023.1163185},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1163185},
  shortjournal = {Front. Robot. AI},
  title        = {Adaptivity: A path towards general swarm intelligence?},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimization of electrode positions for equalizing local
spatial performance of a tomographic tactile sensor. <em>FROBT</em>,
<em>10</em>, 1157911. (<a
href="https://doi.org/10.3389/frobt.2023.1157911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A tomographic tactile sensor based on the contact resistance of conductors is a high sensitive pressure distribution imaging method and has advantages on the flexibility and scalability of device. While the addition of internal electrodes improves the sensor’s spatial resolution, there still remain variations in resolution that depend on the contact position. In this study, we propose an optimization algorithm for electrode positions that improves entire spatial resolution by compensating for local variations in spatial resolution. Simulation results for sensors with 16 or 64 electrodes show that the proposed algorithm improves performance to 0.81 times and 0.93 times in the worst spatial resolution region of the detection area compared to equally spaced grid electrodes. The proposed methods enable tomographic tactile sensors to detect contact pressure distribution more accurately than the conventional methods, providing high-performance tactile sensing for many applications.},
  archive      = {J_FROBT},
  author       = {Kojima, Akira and Yoshimoto, Shunsuke and Yamamoto, Akio},
  doi          = {10.3389/frobt.2023.1157911},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1157911},
  shortjournal = {Front. Robot. AI},
  title        = {Optimization of electrode positions for equalizing local spatial performance of a tomographic tactile sensor},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interactive and incremental learning of spatial object
relations from human demonstrations. <em>FROBT</em>, <em>10</em>,
1151303. (<a href="https://doi.org/10.3389/frobt.2023.1151303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans use semantic concepts such as spatial relations between objects to describe scenes and communicate tasks such as “Put the tea to the right of the cup” or “Move the plate between the fork and the spoon.” Just as children, assistive robots must be able to learn the sub-symbolic meaning of such concepts from human demonstrations and instructions. We address the problem of incrementally learning geometric models of spatial relations from few demonstrations collected online during interaction with a human. Such models enable a robot to manipulate objects in order to fulfill desired spatial relations specified by verbal instructions. At the start, we assume the robot has no geometric model of spatial relations. Given a task as above, the robot requests the user to demonstrate the task once in order to create a model from a single demonstration, leveraging cylindrical probability distribution as generative representation of spatial relations. We show how this model can be updated incrementally with each new demonstration without access to past examples in a sample-efficient way using incremental maximum likelihood estimation, and demonstrate the approach on a real humanoid robot.},
  archive      = {J_FROBT},
  author       = {Kartmann, Rainer and Asfour, Tamim},
  doi          = {10.3389/frobt.2023.1151303},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1151303},
  shortjournal = {Front. Robot. AI},
  title        = {Interactive and incremental learning of spatial object relations from human demonstrations},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Epistemic planning for multi-robot systems in
communication-restricted environments. <em>FROBT</em>, <em>10</em>,
1149439. (<a href="https://doi.org/10.3389/frobt.2023.1149439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world robotic applications such as search and rescue, disaster relief, and inspection operations are often set in unstructured environments with a restricted or unreliable communication infrastructure. In such environments, a multi-robot system must either be deployed to i) remain constantly connected, hence sacrificing operational efficiency or ii) allow disconnections considering when and how to regroup. In communication-restricted environments, we insist that the latter approach is desired to achieve a robust and predictable method for cooperative planning. One of the main challenges in achieving this goal is that optimal planning in partially unknown environments without communication requires an intractable sequence of possibilities. To solve this problem, we propose a novel epistemic planning approach for propagating beliefs about the system’s states during communication loss to ensure cooperative operations. Typically used for discrete multi-player games or natural language processing, epistemic planning is a powerful representation of reasoning through events, actions, and belief revisions, given new information. Most robot applications use traditional planning to interact with their immediate environment and only consider knowledge of their own state. By including an epistemic notion in planning, a robot may enact depth-of-reasoning about the system’s state, analyzing its beliefs about each robot in the system. In this method, a set of possible beliefs about other robots in the system are propagated using a Frontier-based planner to accomplish the coverage objective. As disconnections occur, each robot tracks beliefs about the system state and reasons about multiple objectives: i) coverage of the environment, ii) dissemination of new observations, and iii) possible information sharing from other robots. A task allocation optimization algorithm with gossip protocol is used in conjunction with the epistemic planning mechanism to locally optimize all three objectives, considering that in a partially unknown environment, the belief propagation may not be safe or possible to follow and that another robot may be attempting an information relay using the belief state. Results indicate that our framework performs better than the standard solution for communication restrictions and even shows similar performance to simulations with no communication limitations. Extensive experiments provide evidence of the framework’s performance in real-world scenarios.},
  archive      = {J_FROBT},
  author       = {Bramblett, Lauren and Bezzo, Nicola},
  doi          = {10.3389/frobt.2023.1149439},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1149439},
  shortjournal = {Front. Robot. AI},
  title        = {Epistemic planning for multi-robot systems in communication-restricted environments},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Introducing a healthcare-assistive robot in primary care: A
preliminary questionnaire survey. <em>FROBT</em>, <em>10</em>, 1123153.
(<a href="https://doi.org/10.3389/frobt.2023.1123153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Healthcare-assistive Infection-control RObot (HIRO) is a healthcare-assistive robot that is deployed in an outpatient primary care clinic to sanitise the premises, monitor people in its proximity for their temperature and donning of masks, and usher them to service points. This study aimed to determine the acceptability, perceptions of safety, and concerns among the patients, visitors, and polyclinic healthcare workers (HCWs) regarding the HIRO. A cross-sectional questionnaire survey was conducted from March to April 2022 when the HIRO was at Tampines Polyclinic in eastern Singapore. A total of 170 multidisciplinary HCWs serve approximately 1,000 patients and visitors daily at this polyclinic. The sample size of 385 was computed using a proportion of 0.5, 5% precision, and 95% confidence interval. Research assistants administered an e-survey to gather demographic data and feedback from 300 patients/visitors and 85 HCWs on their perceptions of the HIRO using Likert scales. The participants watched a video on the HIRO’s functionalities and were given the opportunity to directly interact with it. Descriptive statistics was performed and figures were presented in frequencies and percentages. The majority of the participants viewed the HIRO’s functionalities favourably: sanitising (96.7%/91.2%); checking proper mask donning (97%/89.4%); temperature monitoring (97%/91.7%); ushering (91.7%/81.1%); perceived user friendliness (93%/88.3%), and improvement in the clinic experience (96%/94.2%). A minority of the participants perceived harm from the HIRO’s liquid disinfectant (29.6%/31.5%) and that its voice-annotated instructions may be upsetting (14%/24.8%). Most of the participants accepted the HIRO’s deployment at the polyclinic and perceived it to be safe. The HIRO used ultraviolet irradiation for sanitisation during after-clinic hours instead of disinfectants due to the perceived harm.},
  archive      = {J_FROBT},
  author       = {Tan, N. C. and Yusoff, Y. and Koot, D. and Lau, Q. C. and Lim, H. and Hui, T. F. and Cher, H. Y. and Tan, P. Y. A. and Koh, Y. L. E.},
  doi          = {10.3389/frobt.2023.1123153},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1123153},
  shortjournal = {Front. Robot. AI},
  title        = {Introducing a healthcare-assistive robot in primary care: A preliminary questionnaire survey},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using convolutional neural networks to detect GNSS
multipath. <em>FROBT</em>, <em>10</em>, 1106439. (<a
href="https://doi.org/10.3389/frobt.2023.1106439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global Navigation Satellite System (GNSS) multipath has always been extensively researched as it is one of the hardest error sources to predict and model. External sensors are often used to remove or detect it, which transforms the process into a cumbersome data set-up. Thus, we decided to only use GNSS correlator outputs to detect a large-amplitude multipath, on Galileo E1-B and GPS L1 C/A, using a convolutional neural network (CNN). This network was trained using 101 correlator outputs being used as a theoretical classifier. To take advantage of the strengths of convolutional neural networks for image detection, images representing the correlator output values as a function of delay and time were generated. The presented model has an F score of 94.7% on Galileo E1-B and 91.6% on GPS L1 C/A. To reduce the computational load, the number of correlator outputs and correlator sampling frequency was then decreased by a factor of 4, and the convolutional neural network still has an F score of 91.8% on Galileo E1-B and 90.5% on GPS L1 C/A.},
  archive      = {J_FROBT},
  author       = {Guillard, Anthony and Thevenon, Paul and Milner, Carl},
  doi          = {10.3389/frobt.2023.1106439},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1106439},
  shortjournal = {Front. Robot. AI},
  title        = {Using convolutional neural networks to detect GNSS multipath},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vision-based particle filtering for quad-copter attitude
estimation using multirate delayed measurements. <em>FROBT</em>,
<em>10</em>, 1090174. (<a
href="https://doi.org/10.3389/frobt.2023.1090174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of attitude estimation of a quad-copter system equipped with a multi-rate camera and gyroscope sensors is addressed through extension of a sampling importance re-sampling (SIR) particle filter (PF). Attitude measurement sensors, such as cameras, usually suffer from a slow sampling rate and processing time delay compared to inertial sensors, such as gyroscopes. A discretized attitude kinematics in Euler angles is employed where the gyroscope noisy measurements are considered the model input, leading to a stochastic uncertain system model. Then, a multi-rate delayed PF is proposed so that when no camera measurement is available, the sampling part is performed only. In this case, the delayed camera measurements are used for weight computation and re-sampling. Finally, the efficiency of the proposed method is demonstrated through both numerical simulation and experimental work on the DJI Tello quad-copter system. The images captured by the camera are processed using the ORB feature extraction method and the homography method in Python-OpenCV, which is used to calculate the rotation matrix from the Tello’s image frames.},
  archive      = {J_FROBT},
  author       = {Sadeghzadeh-Nokhodberiz, Nargess and Iranshahi, Mohammad and Montazeri, Allahyar},
  doi          = {10.3389/frobt.2023.1090174},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1090174},
  shortjournal = {Front. Robot. AI},
  title        = {Vision-based particle filtering for quad-copter attitude estimation using multirate delayed measurements},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fully robotic social environment for teaching and practicing
affective interaction: Case of teaching emotion recognition skills to
children with autism spectrum disorder, a pilot study. <em>FROBT</em>,
<em>10</em>, 1088582. (<a
href="https://doi.org/10.3389/frobt.2023.1088582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {21st century brought along a considerable decrease in social interactions, due to the newly emerged lifestyle around the world, which became more noticeable recently of the COVID-19 pandemic. On the other hand, children with autism spectrum disorder have further complications regarding their social interactions with other humans. In this paper, a fully Robotic Social Environment (RSE), designed to simulate the needed social environment for children, especially those with autism is described. An RSE can be used to simulate many social situations, such as affective interpersonal interactions, in which observational learning can take place. In order to investigate the effectiveness of the proposed RSE, it has been tested on a group of children with autism, who had difficulties in emotion recognition, which in turn, can influence social interaction. An A-B-A single case study was designed to show how RSE can help children with autism recognize four basic facial expressions, i.e., happiness, sadness, anger, and fear, through observing the social interactions of two robots speaking about these facial expressions. The results showed that the emotion recognition skills of the participating children were improved. Furthermore, the results showed that the children could maintain and generalize their emotion recognition skills after the intervention period. In conclusion, the study shows that the proposed RSE, along with other rehabilitation methods, can be effective in improving the emotion recognition skills of children with autism and preparing them to enter human social environments.},
  archive      = {J_FROBT},
  author       = {Soleiman, Pegah and Moradi, Hadi and Mehralizadeh, Bijan and Ameri, Hamed and Arriaga, Rosa I. and Pouretemad, Hamid Reza and Baghbanzadeh, Negin and Vahid, Leila Kashani},
  doi          = {10.3389/frobt.2023.1088582},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1088582},
  shortjournal = {Front. Robot. AI},
  title        = {Fully robotic social environment for teaching and practicing affective interaction: Case of teaching emotion recognition skills to children with autism spectrum disorder, a pilot study},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AROS: Affordance recognition with one-shot human stances.
<em>FROBT</em>, <em>10</em>, 1076780. (<a
href="https://doi.org/10.3389/frobt.2023.1076780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present Affordance Recognition with One-Shot Human Stances (AROS), a one-shot learning approach that uses an explicit representation of interactions between highly articulated human poses and 3D scenes. The approach is one-shot since it does not require iterative training or retraining to add new affordance instances. Furthermore, only one or a small handful of examples of the target pose are needed to describe the interactions. Given a 3D mesh of a previously unseen scene, we can predict affordance locations that support the interactions and generate corresponding articulated 3D human bodies around them. We evaluate the performance of our approach on three public datasets of scanned real environments with varied degrees of noise. Through rigorous statistical analysis of crowdsourced evaluations, our results show that our one-shot approach is preferred up to 80% of the time over data-intensive baselines.},
  archive      = {J_FROBT},
  author       = {Pacheco-Ortega, Abel and Mayol-Cuevas, Walterio},
  doi          = {10.3389/frobt.2023.1076780},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1076780},
  shortjournal = {Front. Robot. AI},
  title        = {AROS: Affordance recognition with one-shot human stances},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cable failure tolerant control and planning in a planar
reconfigurable cable driven parallel robot. <em>FROBT</em>, <em>10</em>,
1070627. (<a href="https://doi.org/10.3389/frobt.2023.1070627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The addition of geometric reconfigurability in a cable driven parallel robot (CDPR) introduces kinematic redundancies which can be exploited for manipulating structural and mechanical properties of the robot through redundancy resolution. In the event of a cable failure, a reconfigurable CDPR (rCDPR) can also realign its geometric arrangement to overcome the effects of cable failure and recover the original expected trajectory and complete the trajectory tracking task. In this paper we discuss a fault tolerant control (FTC) framework that relies on an Interactive Multiple Model (IMM) adaptive estimation filter for simultaneous fault detection and diagnosis (FDD) and task recovery. The redundancy resolution scheme for the kinematically redundant CDPR takes into account singularity avoidance, manipulability and wrench quality maximization during trajectory tracking. We further introduce a trajectory tracking methodology that enables the automatic task recovery algorithm to consistently return to the point of failure. This is particularly useful for applications where the planned trajectory is of greater importance than the goal positions, such as painting, welding or 3D printing applications. The proposed control framework is validated in simulation on a planar rCDPR with elastic cables and parameter uncertainties to introduce modeled and unmodeled dynamics in the system as it tracks a complete trajectory despite the occurrence of multiple cable failures. As cables fail one by one, the robot topology changes from an over-constrained to a fully constrained and then an under-constrained CDPR. The framework is applied with a constant-velocity kinematic feedforward controller which has the advantage of generating steady-state inputs despite dynamic oscillations during cable failures, as well as a Linear Quadratic Regulator (LQR) feedback controller to locally dampen these oscillations.},
  archive      = {J_FROBT},
  author       = {Raman, Adhiti and Walker, Ian and Krovi, Venkat and Schmid, Matthias},
  doi          = {10.3389/frobt.2023.1070627},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1070627},
  shortjournal = {Front. Robot. AI},
  title        = {Cable failure tolerant control and planning in a planar reconfigurable cable driven parallel robot},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). End-to-end dialogue structure parsing on multi-floor
dialogue based on multi-task learning. <em>FROBT</em>, <em>10</em>,
949600. (<a href="https://doi.org/10.3389/frobt.2023.949600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multi-floor dialogue consists of multiple sets of dialogue participants, each conversing within their own floor. In the multi-floor dialogue, at least one multi-communicating member who is a participant of multiple floors and coordinates each to achieve a shared dialogue goal. The structure of such dialogues can be complex, involving intentional structure and relations that are within or across floors. In this study, We proposed a neural dialogue structure parser with an attention mechanism that applies multi-task learning to automatically identify the dialogue structure of multi-floor dialogues in a collaborative robot navigation domain. Furthermore, we propose to use dialogue response prediction as an auxiliary objective of the multi-floor dialogue structure parser to enhance the consistency of the multi-floor dialogue structure parsing. Our experimental results show that our proposed model improved the dialogue structure parsing performance more than conventional models in multi-floor dialogue.},
  archive      = {J_FROBT},
  author       = {Kawano, Seiya and Yoshino, Koichiro and Traum, David and Nakamura, Satoshi},
  doi          = {10.3389/frobt.2023.949600},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {949600},
  shortjournal = {Front. Robot. AI},
  title        = {End-to-end dialogue structure parsing on multi-floor dialogue based on multi-task learning},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Image-based robot navigation with task achievability.
<em>FROBT</em>, <em>10</em>, 944375. (<a
href="https://doi.org/10.3389/frobt.2023.944375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image-based robot action planning is becoming an active area of research owing to recent advances in deep learning. To evaluate and execute robot actions, recently proposed approaches require the estimation of the optimal cost-minimizing path, such as the shortest distance or time, between two states. To estimate the cost, parametric models consisting of deep neural networks are widely used. However, such parametric models require large amounts of correctly labeled data to accurately estimate the cost. In real robotic tasks, collecting such data is not always feasible, and the robot itself may require collecting it. In this study, we empirically show that when a model is trained with data autonomously collected by a robot, the estimation of such parametric models could be inaccurate to perform a task. Specifically, the higher the maximum predicted distance, the more inaccurate the estimation, and the robot fails navigating in the environment. To overcome this issue, we propose an alternative metric, “task achievability” (TA), which is defined as the probability that a robot will reach a goal state within a specified number of timesteps. Compared to the training of optimal cost estimator, TA can use both optimal and non-optimal trajectories in the training dataset to train, which leads to a stable estimation. We demonstrate the effectiveness of TA through robot navigation experiments in an environment resembling a real living room. We show that TA-based navigation succeeds in navigating a robot to different target positions, even when conventional cost estimator-based navigation fails.},
  archive      = {J_FROBT},
  author       = {Ishihara, Yu and Takahashi, Masaki},
  doi          = {10.3389/frobt.2023.944375},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {944375},
  shortjournal = {Front. Robot. AI},
  title        = {Image-based robot navigation with task achievability},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: From batch-size 1 to serial production: Adaptive
robots for scalable and flexible production systems. <em>FROBT</em>,
<em>10</em>, 1201488. (<a
href="https://doi.org/10.3389/frobt.2023.1201488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Bdiwi, Mohamad and Ihlenfeldt, Steffen},
  doi          = {10.3389/frobt.2023.1201488},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1201488},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: from batch-size 1 to serial production: adaptive robots for scalable and flexible production systems},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Corrigendum: QUaRTM: A quadcopter with unactuated rotor
tilting mechanism capable of faster, more agile, and more efficient
flight. <em>FROBT</em>, <em>10</em>, 1199090. (<a
href="https://doi.org/10.3389/frobt.2023.1199090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Tang, Jerry and Jain, Karan P. and Mueller, Mark W.},
  doi          = {10.3389/frobt.2023.1199090},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1199090},
  shortjournal = {Front. Robot. AI},
  title        = {Corrigendum: QUaRTM: a quadcopter with unactuated rotor tilting mechanism capable of faster, more agile, and more efficient flight},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Soft aerial robots: Design, control, and
applications of morphologically adaptive flyers. <em>FROBT</em>,
<em>10</em>, 1196942. (<a
href="https://doi.org/10.3389/frobt.2023.1196942">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Nguyen, Pham Huy and Kovač, Mirko and Arrue, Begoña C.},
  doi          = {10.3389/frobt.2023.1196942},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1196942},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: soft aerial robots: design, control, and applications of morphologically adaptive flyers},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predicting the metabolic cost of exoskeleton-assisted
squatting using foot pressure features and machine learning.
<em>FROBT</em>, <em>10</em>, 1166248. (<a
href="https://doi.org/10.3389/frobt.2023.1166248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Recent studies found that wearable exoskeletons can reduce physical effort and fatigue during squatting. In particular, subject-specific assistance helped to significantly reduce physical effort, shown by reduced metabolic cost, using human-in-the-loop optimization of the exoskeleton parameters. However, measuring metabolic cost using respiratory data has limitations, such as long estimation times, presence of noise, and user discomfort. A recent study suggests that foot contact forces can address those challenges and be used as an alternative metric to the metabolic cost to personalize wearable robot assistance during walking.Methods: In this study, we propose that foot center of pressure (CoP) features can be used to estimate the metabolic cost of squatting using a machine learning method. Five subjects’ foot pressure and metabolic cost data were collected as they performed squats with an ankle exoskeleton at different assistance conditions in our prior study. In this study, we extracted statistical features from the CoP squat trajectories and fed them as input to a random forest model, with the metabolic cost as the output.Results: The model predicted the metabolic cost with a mean error of 0.55 W/kg on unseen test data, with a high correlation (r = 0.89, p &amp;lt; 0.01) between the true and predicted cost. The features of the CoP trajectory in the medial-lateral direction of the foot (xCoP), which relate to ankle eversion-inversion, were found to be important and highly correlated with metabolic cost.Conclusion: Our findings indicate that increased ankle eversion (outward roll of the ankle), which reflects a suboptimal squatting strategy, results in higher metabolic cost. Higher ankle eversion has been linked with the etiology of chronic lower limb injuries. Hence, a CoP-based cost function in human-in-the-loop optimization could offer several advantages, such as reduced estimation time, injury risk mitigation, and better user comfort.},
  archive      = {J_FROBT},
  author       = {Ramadurai, Sruthi and Jeong, Heejin and Kim, Myunghee},
  doi          = {10.3389/frobt.2023.1166248},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1166248},
  shortjournal = {Front. Robot. AI},
  title        = {Predicting the metabolic cost of exoskeleton-assisted squatting using foot pressure features and machine learning},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Force-based control strategy for a collaborative robotic
camera holder in laparoscopic surgery using pivoting motion.
<em>FROBT</em>, <em>10</em>, 1145265. (<a
href="https://doi.org/10.3389/frobt.2023.1145265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Laparoscopic surgery often relies on a fixed Remote Center of Motion (RCM) for robot mobility control, which assumes that the patient’s abdominal walls are immobile. However, this assumption is inaccurate, especially in collaborative surgical environments. In this paper, we present a force-based strategy for the mobility of a robotic camera-holder system for laparoscopic surgery based on a pivoting motion. This strategy re-conceptualizes the conventional mobility control paradigm of surgical robotics.Methods: The proposed strategy involves direct control of the Tool Center Point’s (TCP) position and orientation without any constraints associated with the spatial position of the incision. It is based on pivoting motions to minimize contact forces between the abdominal walls and the laparoscope. The control directly relates the measured force and angular velocity of the laparoscope, resulting in the reallocation of the trocar, whose position becomes a consequence of the natural accommodation allowed by this pivoting.Results: The effectiveness and safety of the proposed control were evaluated through a series of experiments. The experiments showed that the control was able to minimize an external force of 9 N to ±0.2 N in 0.7 s and reduce it to 2 N in just 0.3 s. Furthermore, the camera was able to track a region of interest by displacing the TCP as desired, leveraging the strategy’s property that dynamically constrains its orientation.Discussion: The proposed control strategy has proven to be effective minimizing the risk caused by sudden high forces resulting from accidents and maintaining the field of view despite any movements in the surgical environment, such as physiological movements of the patient or undesired movements of other surgical instruments. This control strategy can be implemented for laparoscopic robots without mechanical RCMs, as well as commercial collaborative robots, thereby improving the safety of surgical interventions in collaborative environments.},
  archive      = {J_FROBT},
  author       = {Fontúrbel, Carlos and Cisnal, Ana and Fraile-Marinero, Juan Carlos and Pérez-Turiel, Javier},
  doi          = {10.3389/frobt.2023.1145265},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1145265},
  shortjournal = {Front. Robot. AI},
  title        = {Force-based control strategy for a collaborative robotic camera holder in laparoscopic surgery using pivoting motion},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recent trends in robot learning and evolution for swarm
robotics. <em>FROBT</em>, <em>10</em>, 1134841. (<a
href="https://doi.org/10.3389/frobt.2023.1134841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Swarm robotics is a promising approach to control large groups of robots. However, designing the individual behavior of the robots so that a desired collective behavior emerges is still a major challenge. In recent years, many advances in the automatic design of control software for robot swarms have been made, thus making automatic design a promising tool to address this challenge. In this article, I highlight and discuss recent advances and trends in offline robot evolution, embodied evolution, and offline robot learning for swarm robotics. For each approach, I describe recent design methods of interest, and commonly encountered challenges. In addition to the review, I provide a perspective on recent trends and discuss how they might influence future research to help address the remaining challenges of designing robot swarms.},
  archive      = {J_FROBT},
  author       = {Kuckling, Jonas},
  doi          = {10.3389/frobt.2023.1134841},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1134841},
  shortjournal = {Front. Robot. AI},
  title        = {Recent trends in robot learning and evolution for swarm robotics},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An online learning algorithm for adapting leg stiffness and
stride angle for efficient quadruped robot trotting. <em>FROBT</em>,
<em>10</em>, 1127898. (<a
href="https://doi.org/10.3389/frobt.2023.1127898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Animals adjust their leg stiffness and stride angle in response to changing ground conditions and gait parameters, resulting in improved stability and reduced energy consumption. This paper presents an online learning algorithm that attempts to mimic such animal behavior by maximizing energy efficiency on the fly or equivalently, minimizing the cost of transport of legged robots by adaptively changing the leg stiffness and stride angle while the robot is traversing on grounds with unknown characteristics. The algorithm employs an approximate stochastic gradient method to change the parameters in real-time, and has the following advantages: (1) the algorithm is computationally efficient and suitable for real-time operation; (2) it does not require training; (3) it is model-free, implying that precise modeling of the robot is not required for good performance; and (4) the algorithm is generally applicable and can be easily incorporated into a variety of legged robots with adaptable parameters and gaits beyond those implemented in this paper. Results of exhaustive performance assessment through numerical simulations and experiments on an under-actuated quadruped robot with compliant legs are included in the paper. The robot platform used a pneumatic piston in each leg as a variable, passive compliant element. Performance evaluation using simulations and experiments indicated that the algorithm was capable of converging to near-optimal values of the cost of transport for given operating conditions, terrain properties, and gait characteristics with no prior knowledge of the terrain and gait conditions. The simplicity of the algorithm and its demonstrably improved performance make the approach of this paper an excellent candidate for adaptively controlling tunable parameters of compliant, legged robots.},
  archive      = {J_FROBT},
  author       = {Aboufazeli, Mahtab and Samare Filsoofi, Ali and Gurney, Jason and Meek, Sanford G. and Mathews, V John},
  doi          = {10.3389/frobt.2023.1127898},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1127898},
  shortjournal = {Front. Robot. AI},
  title        = {An online learning algorithm for adapting leg stiffness and stride angle for efficient quadruped robot trotting},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Observation vs. Interaction in the recognition of human-like
movements. <em>FROBT</em>, <em>10</em>, 1112986. (<a
href="https://doi.org/10.3389/frobt.2023.1112986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A crucial aspect in human-robot collaboration is the robot acceptance by human co-workers. Based on previous experiences of interaction with their fellow beings, humans are able to recognize natural movements of their companions and associate them with the concepts of trust and acceptance. Throughout this process, the judgment is influenced by several percepts, first of all the visual similarity to the companion, which triggers a process of self-identification. When the companion is a robot, the lack of these percepts challenges such a self-identification process, unavoidably lowering the level of acceptance. Hence, while, on the one hand, the robotics industry moves towards manufacturing robots that visually resemble humans, on the other hand, a question is still open on whether the acceptance of robots can be increased by virtue of the movements they exhibit, regardless of their exterior aspect. In order to contribute to answering this question, this paper presents two experimental setups for Turing tests, where an artificial agent performs human-recorded and artificial movements, and a human subject is to judge the human likeness of the movement in two different circumstances: by observing the movement replicated on a screen and by physically interacting with a robot executing the movements. The results reveal that humans are more likely to recognize human movements through interaction than observation, and that, under the interaction condition, artificial movements can be designed to resemble human ones for future robots to be more easily accepted by human co-workers.},
  archive      = {J_FROBT},
  author       = {Mignone, Giovanni and Parziale, Antonio and Ferrentino, Enrico and Marcelli, Angelo and Chiacchio, Pasquale},
  doi          = {10.3389/frobt.2023.1112986},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1112986},
  shortjournal = {Front. Robot. AI},
  title        = {Observation vs. interaction in the recognition of human-like movements},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time myoelectric control of wrist/hand motion in
duchenne muscular dystrophy: A case study. <em>FROBT</em>, <em>10</em>,
1100411. (<a href="https://doi.org/10.3389/frobt.2023.1100411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Duchenne muscular dystrophy (DMD) is a genetic disorder that induces progressive muscular degeneration. Currently, the increase in DMD individuals&#39; life expectancy is not being matched by an increase in quality of life. The functioning of the hand and wrist is central for performing daily activities and for providing a higher degree of independence. Active exoskeletons can assist this functioning but require the accurate decoding of the users&#39; motor intention. These methods have, however, never been systematically analyzed in the context of DMD.Methods: This case study evaluated direct control (DC) and pattern recognition (PR), combined with an admittance model. This enabled customization of myoelectric controllers to one DMD individual and to a control population of ten healthy participants during a target-reaching task in 1- and 2- degrees of freedom (DOF). We quantified real-time myocontrol performance using target reaching times and compared the differences between the healthy individuals and the DMD individual.Results and Discussion: Our findings suggest that despite the muscle tissue degeneration, the myocontrol performance of the DMD individual was comparable to that of the healthy individuals in both DOFs and with both control approaches. It was also evident that PR control performed better for the 2-DOF tasks for both DMD and healthy participants, while DC performed better for the 1-DOF tasks. The insights gained from this study can lead to further developments for the intuitive multi-DOF myoelectric control of active hand exoskeletons for individuals with DMD.},
  archive      = {J_FROBT},
  author       = {Nizamis, Kostas and Ayvaz, Anıl and Rijken, Noortje H. M. and Koopman, Bart F. J. M. and Sartori, Massimo},
  doi          = {10.3389/frobt.2023.1100411},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1100411},
  shortjournal = {Front. Robot. AI},
  title        = {Real-time myoelectric control of wrist/hand motion in duchenne muscular dystrophy: A case study},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the role and opportunities in teamwork design for
advanced multi-robot search systems. <em>FROBT</em>, <em>10</em>,
1089062. (<a href="https://doi.org/10.3389/frobt.2023.1089062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent robotic systems are becoming ever more present in our lives across a multitude of domains such as industry, transportation, agriculture, security, healthcare and even education. Such systems enable humans to focus on the interesting and sophisticated tasks while robots accomplish tasks that are either too tedious, routine or potentially dangerous for humans to do. Recent advances in perception technologies and accompanying hardware, mainly attributed to rapid advancements in the deep-learning ecosystem, enable the deployment of robotic systems equipped with onboard sensors as well as the computational power to perform autonomous reasoning and decision making online. While there has been significant progress in expanding the capabilities of single and multi-robot systems during the last decades across a multitude of domains and applications, there are still many promising areas for research that can advance the state of cooperative searching systems that employ multiple robots. In this article, several prospective avenues of research in teamwork cooperation with considerable potential for advancement of multi-robot search systems will be visited and discussed. In previous works we have shown that multi-agent search tasks can greatly benefit from intelligent cooperation between team members and can achieve performance close to the theoretical optimum. The techniques applied can be used in a variety of domains including planning against adversarial opponents, control of forest fires and coordinating search-and-rescue missions. The state-of-the-art on methods of multi-robot search across several selected domains of application is explained, highlighting the pros and cons of each method, providing an up-to-date view on the current state of the domains and their future challenges.},
  archive      = {J_FROBT},
  author       = {Francos, Roee M. and Bruckstein, Alfred M.},
  doi          = {10.3389/frobt.2023.1089062},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1089062},
  shortjournal = {Front. Robot. AI},
  title        = {On the role and opportunities in teamwork design for advanced multi-robot search systems},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A compact underactuated gripper with two fingers and a
retractable suction cup. <em>FROBT</em>, <em>10</em>, 1066516. (<a
href="https://doi.org/10.3389/frobt.2023.1066516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern industrial applications of robotics such as small-series production and automated warehousing require versatile grippers, i.e., grippers that can pick up the widest possible variety of objects. These objects must often be grasped or placed inside a container, which limits the size of the gripper. In this article, we propose to combine the two most popular gripper technologies in order to maximise versatility: finger grippers and suction-cup (vacuum) grippers. Many researchers and a few companies have followed this same idea in the past, but their gripper designs are often overly complex or too bulky to pick up objects inside containers. Here, we develop a gripper where the suction cup is lodged inside the palm of a two-finger robotic hand. The suction cup is mounted on a retractile rod that can extend to pick up objects inside containers without interference from the two fingers. A single actuator drives both the finger and sliding-rod motions so as to minimise the gripper complexity. The opening and closing sequence of the gripper is achieved by using a planetary gear train as transmission between the actuator, the fingers and the suction cup sliding mechanism. Special attention is paid to minimise the overall gripper size; its diameter being kept to 75 mm, which is that of the end link of the common UR5 robot. A prototype of the gripper is built and its versatility is demonstrated in a short accompanying video.},
  archive      = {J_FROBT},
  author       = {Courchesne, Julien and Cardou, Philippe and Rachide Onadja, Palamanga Abdoul},
  doi          = {10.3389/frobt.2023.1066516},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1066516},
  shortjournal = {Front. Robot. AI},
  title        = {A compact underactuated gripper with two fingers and a retractable suction cup},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robotic gaze and human views: A systematic exploration of
robotic gaze aversion and its effects on human behaviors and attitudes.
<em>FROBT</em>, <em>10</em>, 1062714. (<a
href="https://doi.org/10.3389/frobt.2023.1062714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Similar to human–human interaction (HHI), gaze is an important modality in conversational human–robot interaction (HRI) settings. Previously, human-inspired gaze parameters have been used to implement gaze behavior for humanoid robots in conversational settings and improve user experience (UX). Other robotic gaze implementations disregard social aspects of gaze behavior and pursue a technical goal (e.g., face tracking). However, it is unclear how deviating from human-inspired gaze parameters affects the UX. In this study, we use eye-tracking, interaction duration, and self-reported attitudinal measures to study the impact of non-human inspired gaze timings on the UX of the participants in a conversational setting. We show the results for systematically varying the gaze aversion ratio (GAR) of a humanoid robot over a broad parameter range from almost always gazing at the human conversation partner to almost always averting the gaze. The main results reveal that on a behavioral level, a low GAR leads to shorter interaction durations and that human participants change their GAR to mimic the robot. However, they do not copy the robotic gaze behavior strictly. Additionally, in the lowest gaze aversion setting, participants do not gaze back as much as expected, which indicates a user aversion to the robot gaze behavior. However, participants do not report different attitudes toward the robot for different GARs during the interaction. In summary, the urge of humans in conversational settings with a humanoid robot to adapt to the perceived GAR is stronger than the urge of intimacy regulation through gaze aversion, and a high mutual gaze is not always a sign of high comfort, as suggested earlier. This result can be used as a justification to deviate from human-inspired gaze parameters when necessary for specific robot behavior implementations.},
  archive      = {J_FROBT},
  author       = {Koller, Michael and Weiss, Astrid and Hirschmanner, Matthias and Vincze, Markus},
  doi          = {10.3389/frobt.2023.1062714},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1062714},
  shortjournal = {Front. Robot. AI},
  title        = {Robotic gaze and human views: A systematic exploration of robotic gaze aversion and its effects on human behaviors and attitudes},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning-based robotic grasping: A review. <em>FROBT</em>,
<em>10</em>, 1038658. (<a
href="https://doi.org/10.3389/frobt.2023.1038658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As personalization technology increasingly orchestrates individualized shopping or marketing experiences in industries such as logistics, fast-moving consumer goods, and food delivery, these sectors require flexible solutions that can automate object grasping for unknown or unseen objects without much modification or downtime. Most solutions in the market are based on traditional object recognition and are, therefore, not suitable for grasping unknown objects with varying shapes and textures. Adequate learning policies enable robotic grasping to accommodate high-mix and low-volume manufacturing scenarios. In this paper, we review the recent development of learning-based robotic grasping techniques from a corpus of over 150 papers. In addition to addressing the current achievements from researchers all over the world, we also point out the gaps and challenges faced in AI-enabled grasping, which hinder robotization in the aforementioned industries. In addition to 3D object segmentation and learning-based grasping benchmarks, we have also performed a comprehensive market survey regarding tactile sensors and robot skin. Furthermore, we reviewed the latest literature on how sensor feedback can be trained by a learning model to provide valid inputs for grasping stability. Finally, learning-based soft gripping is evaluated as soft grippers can accommodate objects of various sizes and shapes and can even handle fragile objects. In general, robotic grasping can achieve higher flexibility and adaptability, when equipped with learning algorithms.},
  archive      = {J_FROBT},
  author       = {Xie, Zhen and Liang, Xinquan and Roberto, Canale},
  doi          = {10.3389/frobt.2023.1038658},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1038658},
  shortjournal = {Front. Robot. AI},
  title        = {Learning-based robotic grasping: A review},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Flexible sensor concept and an integrated collision sensing
for efficient human-robot collaboration using 3D local global sensors.
<em>FROBT</em>, <em>10</em>, 1028411. (<a
href="https://doi.org/10.3389/frobt.2023.1028411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-robot collaboration with traditional industrial robots is a cardinal step towards agile manufacturing and re-manufacturing processes. These processes require constant human presence, which results in lower operational efficiency based on current industrial collision avoidance systems. The work proposes a novel local and global sensing framework, which discusses a flexible sensor concept comprising a single 2D or 3D LiDAR while formulating occlusion due to the robot body. Moreover, this work extends the previous local global sensing methodology to incorporate local (co-moving) 3D sensors on the robot body. The local 3D camera faces toward the robot occlusion area, resulted from the robot body in front of a single global 3D LiDAR. Apart from the sensor concept, this work also proposes an efficient method to estimate sensitivity and reactivity of sensing and control sub-systems The proposed methodologies are tested with a heavy-duty industrial robot along with a 3D LiDAR and camera. The integrated local global sensing methods allow high robot speeds resulting in process efficiency while ensuring human safety and sensor flexibility.},
  archive      = {J_FROBT},
  author       = {Rashid, Aquib and Alnaser, Ibrahim and Bdiwi, Mohamad and Ihlenfeldt, Steffen},
  doi          = {10.3389/frobt.2023.1028411},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1028411},
  shortjournal = {Front. Robot. AI},
  title        = {Flexible sensor concept and an integrated collision sensing for efficient human-robot collaboration using 3D local global sensors},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning hybrid locomotion skills—learn to exploit residual
actions and modulate model-based gait control. <em>FROBT</em>,
<em>10</em>, 1004490. (<a
href="https://doi.org/10.3389/frobt.2023.1004490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work has developed a hybrid framework that combines machine learning and control approaches for legged robots to achieve new capabilities of balancing against external perturbations. The framework embeds a kernel which is a model-based, full parametric closed-loop and analytical controller as the gait pattern generator. On top of that, a neural network with symmetric partial data augmentation learns to automatically adjust the parameters for the gait kernel, and also generate compensatory actions for all joints, thus significantly augmenting the stability under unexpected perturbations. Seven Neural Network policies with different configurations were optimized to validate the effectiveness and the combined use of the modulation of the kernel parameters and the compensation for the arms and legs using residual actions. The results validated that modulating kernel parameters alongside the residual actions have improved the stability significantly. Furthermore, The performance of the proposed framework was evaluated across a set of challenging simulated scenarios, and demonstrated considerable improvements compared to the baseline in recovering from large external forces (up to 118%). Besides, regarding measurement noise and model inaccuracies, the robustness of the proposed framework has been assessed through simulations, which demonstrated the robustness in the presence of these uncertainties. Furthermore, the trained policies were validated across a set of unseen scenarios and showed the generalization to dynamic walking.},
  archive      = {J_FROBT},
  author       = {Kasaei, Mohammadreza and Abreu, Miguel and Lau, Nuno and Pereira, Artur and Reis, Luis Paulo and Li, Zhibin},
  doi          = {10.3389/frobt.2023.1004490},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1004490},
  shortjournal = {Front. Robot. AI},
  title        = {Learning hybrid locomotion skills—Learn to exploit residual actions and modulate model-based gait control},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring the utility of robots as distractors during a
delay-of-gratification task in preschool children. <em>FROBT</em>,
<em>10</em>, 1001119. (<a
href="https://doi.org/10.3389/frobt.2023.1001119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of executive function (EF) in children, particularly with respect to self-regulation skills, has been linked to long-term benefits in terms of social and health outcomes. One such skill is the ability to deal with frustrations when waiting for a delayed, preferred reward. Although robots have increasingly been utilized in educational situations that involve teaching psychosocial skills to children, including various aspects related to self-control, the utility of robots in increasing the likelihood of self-imposed delay of gratification remains to be explored. Using a single-case experimental design, the present study exposed 24 preschoolers to three experimental conditions where a choice was provided between an immediately available reward and a delayed but larger reward. The likelihood of waiting increased over sessions when children were simply asked to wait, but waiting times did not increase further during a condition where teachers offered activities as a distraction. However, when children were exposed to robots and given the opportunity to interact with them, waiting times for the majority of children increased with medium to large effect sizes. Given the positive implications of strong executive function, how it might be increased in children in which it is lacking, limited, or in the process of developing, is of considerable import. This study highlights the effectiveness of robots as a distractor during waiting times and outlines a potential new application of robots in educational contexts.},
  archive      = {J_FROBT},
  author       = {Bharatharaj, Jaishankar and Pepperberg, Irene M. and Sasthan Kutty, Senthil Kumar and Munisamy, Achudhan and Krägeloh, Chris},
  doi          = {10.3389/frobt.2023.1001119},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1001119},
  shortjournal = {Front. Robot. AI},
  title        = {Exploring the utility of robots as distractors during a delay-of-gratification task in preschool children},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Markerless motion tracking to quantify behavioral changes
during robot-assisted gait training: A validation study. <em>FROBT</em>,
<em>10</em>, 1155542. (<a
href="https://doi.org/10.3389/frobt.2023.1155542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Measuring kinematic behavior during robot-assisted gait therapy requires either laborious set up of a marker-based motion capture system or relies on the internal sensors of devices that may not cover all relevant degrees of freedom. This presents a major barrier for the adoption of kinematic measurements in the normal clinical schedule. However, to advance the field of robot-assisted therapy many insights could be gained from evaluating patient behavior during regular therapies.Methods: For this reason, we recently developed and validated a method for extracting kinematics from recordings of a low-cost RGB-D sensor, which relies on a virtual 3D body model to estimate the patient’s body shape and pose in each frame. The present study aimed to evaluate the robustness of the method to the presence of a lower limb exoskeleton. 10 healthy children without gait impairment walked on a treadmill with and without wearing the exoskeleton to evaluate the estimated body shape, and 8 custom stickers were placed on the body to evaluate the accuracy of estimated poses.Results &amp;amp; Conclusion: We found that the shape is generally robust to wearing the exoskeleton, and systematic pose tracking errors were around 5 mm. Therefore, the method can be a valuable measurement tool for the clinical evaluation, e.g., to measure compensatory movements of the trunk.},
  archive      = {J_FROBT},
  author       = {van Dellen, Florian and Hesse, Nikolas and Labruyère, Rob},
  doi          = {10.3389/frobt.2023.1155542},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1155542},
  shortjournal = {Front. Robot. AI},
  title        = {Markerless motion tracking to quantify behavioral changes during robot-assisted gait training: A validation study},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Three-dimensional catheter tip force sensing using
multi-core fiber bragg gratings. <em>FROBT</em>, <em>10</em>, 1154494.
(<a href="https://doi.org/10.3389/frobt.2023.1154494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Awareness of catheter tip interaction forces is a crucial aspect during cardiac ablation procedures. The most important contact forces are the ones that originate between the catheter tip and the beating cardiac tissue. Clinical studies have shown that effective ablation occurs when contact forces are in the proximity of 0.2 N. Lower contact forces lead to ineffective ablation, while higher contact forces may result in complications such as cardiac perforation. Accurate and high resolution force sensing is therefore indispensable in such critical situations. Accordingly, this work presents the development of a unique and novel catheter tip force sensor utilizing a multi-core fiber with inscribed fiber Bragg gratings. A customizable helical compression spring is designed to serve as the flexural component relaying external forces to the multi-core fiber. The limited number of components, simple construction, and compact nature of the sensor makes it an appealing solution towards clinical translation. An elaborated approach is proposed for the design and dimensioning of the necessary sensor components. The approach also presents a unique method to decouple longitudinal and lateral force measurements. A force sensor prototype and a dedicated calibration setup are developed to experimentally validate the theoretical performance. Results show that the proposed force sensor exhibits 7.4 mN longitudinal resolution, 0.8 mN lateral resolution, 0.72 mN mean longitudinal error, 0.96 mN mean lateral error, a high repeatability, and excellent decoupling between longitudinal and lateral forces.},
  archive      = {J_FROBT},
  author       = {Al-Ahmad, Omar and Ourak, Mouloud and Vlekken, Johan and Lindner, Eric and Vander Poorten, Emmanuel},
  doi          = {10.3389/frobt.2023.1154494},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1154494},
  shortjournal = {Front. Robot. AI},
  title        = {Three-dimensional catheter tip force sensing using multi-core fiber bragg gratings},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A robust method for approximate visual robot localization in
feature-sparse sewer pipes. <em>FROBT</em>, <em>10</em>, 1150508. (<a
href="https://doi.org/10.3389/frobt.2023.1150508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Buried sewer pipe networks present many challenges for robot localization systems, which require non-standard solutions due to the unique nature of these environments: they cannot receive signals from global positioning systems (GPS) and can also lack visual features necessary for standard visual odometry algorithms. In this paper, we exploit the fact that pipe joints are equally spaced and develop a robot localization method based on pipe joint detection that operates in one degree-of-freedom along the pipe length. Pipe joints are detected in visual images from an on-board forward facing (electro-optical) camera using a bag-of-keypoints visual categorization algorithm, which is trained offline by unsupervised learning from images of sewer pipe joints. We augment the pipe joint detection algorithm with drift correction using vision-based manhole recognition. We evaluated the approach using real-world data recorded from three sewer pipes (of lengths 30, 50 and 90 m) and benchmarked against a standard method for visual odometry (ORB-SLAM3), which demonstrated that our proposed method operates more robustly and accurately in these feature-sparse pipes: ORB-SLAM3 completely failed on one tested pipe due to a lack of visual features and gave a mean absolute error in localization of approximately 12%–20% on the other pipes (and regularly lost track of features, having to re-initialize multiple times), whilst our method worked successfully on all tested pipes and gave a mean absolute error in localization of approximately 2%–4%. In summary, our results highlight an important trade-off between modern visual odometry algorithms that have potentially high precision and estimate full six degree-of-freedom pose but are potentially fragile in feature sparse pipes, versus simpler, approximate localization methods that operate in one degree-of-freedom along the pipe length that are more robust and can lead to substantial improvements in accuracy.},
  archive      = {J_FROBT},
  author       = {Edwards, S. and Zhang, R. and Worley, R. and Mihaylova, L. and Aitken, J. and Anderson, S. R.},
  doi          = {10.3389/frobt.2023.1150508},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1150508},
  shortjournal = {Front. Robot. AI},
  title        = {A robust method for approximate visual robot localization in feature-sparse sewer pipes},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-robot cooperation for lunar in-situ resource
utilization. <em>FROBT</em>, <em>10</em>, 1149080. (<a
href="https://doi.org/10.3389/frobt.2023.1149080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a cooperative, multi-robot solution for searching, excavating, and transporting mineral resources on the Moon. Our work was developed in the context of the Space Robotics Challenge Phase 2 (SRCP2), which was part of the NASA Centennial Challenges and was motivated by the current NASA Artemis program, a flagship initiative that intends to establish a long-term human presence on the Moon. In the SRCP2 a group of simulated mobile robots was tasked with reporting volatile locations within a realistic lunar simulation environment, and excavating and transporting these resources to target locations in such an environment. In this paper, we describe our solution to the SRCP2 competition that includes our strategies for rover mobility hazard estimation (e.g. slippage level, stuck status), immobility recovery, rover-to-rover, and rover-to-infrastructure docking, rover coordination and cooperation, and cooperative task planning and autonomy. Our solution was able to successfully complete all tasks required by the challenge, granting our team sixth place among all participants of the challenge. Our results demonstrate the potential of using autonomous robots for autonomous in-situ resource utilization (ISRU) on the Moon. Our results also highlight the effectiveness of realistic simulation environments for testing and validating robot autonomy and coordination algorithms. The successful completion of the SRCP2 challenge using our solution demonstrates the potential of cooperative, multi-robot systems for resource utilization on the Moon.},
  archive      = {J_FROBT},
  author       = {Martinez Rocamora, Bernardo and Kilic, Cagri and Tatsch, Christopher and Pereira, Guilherme A. S. and Gross, Jason N.},
  doi          = {10.3389/frobt.2023.1149080},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1149080},
  shortjournal = {Front. Robot. AI},
  title        = {Multi-robot cooperation for lunar in-situ resource utilization},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). High-speed running quadruped robot with a multi-joint spine
adopting a 1DoF closed-loop linkage. <em>FROBT</em>, <em>10</em>,
1148816. (<a href="https://doi.org/10.3389/frobt.2023.1148816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the mobility of robots is an important goal for many real-world applications and implementing an animal-like spine structure in a quadruped robot is a promising approach to achieving high-speed running. This paper proposes a feline-like multi-joint spine adopting a one-degree-of-freedom closed-loop linkage for a quadruped robot to realize high-speed running. We theoretically prove that the proposed spine structure can realize 1.5 times the horizontal range of foot motion compared to a spine structure with a single joint. Experimental results demonstrate that a robot with the proposed spine structure achieves 1.4 times the horizontal range of motion and 1.9 times the speed of a robot with a single-joint spine structure.},
  archive      = {J_FROBT},
  author       = {Matsumoto, Ojiro and Tanaka, Hiroaki and Kawasetsu, Takumi and Hosoda, Koh},
  doi          = {10.3389/frobt.2023.1148816},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1148816},
  shortjournal = {Front. Robot. AI},
  title        = {High-speed running quadruped robot with a multi-joint spine adopting a 1DoF closed-loop linkage},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hand rehabilitation based on the RobHand exoskeleton in
stroke patients: A case series study. <em>FROBT</em>, <em>10</em>,
1146018. (<a href="https://doi.org/10.3389/frobt.2023.1146018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: The RobHand (Robot for Hand Rehabilitation) is a robotic neuromotor rehabilitation exoskeleton that assists in performing flexion and extension movements of the fingers. The present case study assesses changes in manual function and hand muscle strength of four selected stroke patients after completion of an established training program. In addition, safety and user satisfaction are also evaluated.Methods: The training program consisted of 16 sessions; two 60-minute training sessions per week for eight consecutive weeks. During each session, patients moved through six consecutive rehabilitation stages using the RobHand. Manual function assessments were applied before and after the training program and safety tests were carried out after each session. A user evaluation questionnaire was filled out after each patient completed the program.Results: The safety test showed the absence of significant adverse events, such as skin lesions or fatigue. An average score of 4 out of 5 was obtained on the Quebec User Evaluation of Satisfaction with Assistive Technology 2.0 Scale. Users were very satisfied with the weight, comfort, and quality of professional services. A Kruskal-Wallis test revealed that there were not statistically significant changes in the manual function tests between the beginning and the end of the training program.Discussion: It can be concluded that the RobHand is a safe rehabilitation technology and users were satisfied with the system. No statistically significant differences in manual function were found. This could be due to the high influence of the stroke stage on motor recovery since the study was performed with chronic patients. Hence, future studies should evaluate the rehabilitation effectiveness of the repetitive use of the RobHand exoskeleton on subacute patients.Clinical Trial Registration:https://clinicaltrials.gov/ct2/show/NCT05598892?id=NCT05598892&amp;amp;draw=2&amp;amp;rank=1, identifier NCT05598892.},
  archive      = {J_FROBT},
  author       = {Barria, Patricio and Riquelme, Matías and Reppich, Hannah and Cisnal, Ana and Fraile, Juan-Carlos and Pérez-Turiel, Javier and Sierra, David and Aguilar, Rolando and Andrade, Asterio and Nuñez-Espinosa, Cristian},
  doi          = {10.3389/frobt.2023.1146018},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1146018},
  shortjournal = {Front. Robot. AI},
  title        = {Hand rehabilitation based on the RobHand exoskeleton in stroke patients: A case series study},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Synthetic cell research: Is technical progress leaving
theoretical and epistemological investigations one step behind?
<em>FROBT</em>, <em>10</em>, 1143196. (<a
href="https://doi.org/10.3389/frobt.2023.1143196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancements in the research on so-called “synthetic (artificial) cells” have been mainly characterized by an important acceleration in all sorts of experimental approaches, providing a growing amount of knowledge and techniques that will shape future successful developments. Synthetic cell technology, indeed, shows potential in driving a revolution in science and technology. On the other hand, theoretical and epistemological investigations related to what synthetic cells “are,” how they behave, and what their role is in generating knowledge have not received sufficient attention. Open questions about these less explored subjects range from the analysis of the organizational theories applied to synthetic cells to the study of the “relevance” of synthetic cells as scientific tools to investigate life and cognition; and from the recognition and the cultural reappraisal of cybernetic inheritance in synthetic biology to the need for developing concepts on synthetic cells and to the exploration, in a novel perspective, of information theories, complexity, and artificial intelligence applied in this novel field. In these contributions, we will briefly sketch some crucial aspects related to the aforementioned issues, based on our ongoing studies. An important take-home message will result: together with their impactful experimental results and potential applications, synthetic cells can play a major role in the exploration of theoretical questions as well.},
  archive      = {J_FROBT},
  author       = {Stano, Pasquale and Damiano, Luisa},
  doi          = {10.3389/frobt.2023.1143196},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1143196},
  shortjournal = {Front. Robot. AI},
  title        = {Synthetic cell research: Is technical progress leaving theoretical and epistemological investigations one step behind?},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parameter search of a CPG network using a genetic algorithm
for a snake robot with tactile sensors moving on a soft floor.
<em>FROBT</em>, <em>10</em>, 1138019. (<a
href="https://doi.org/10.3389/frobt.2023.1138019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When a snake robot explores a collapsed house as a rescue robot, it needs to move through various obstacles, some of which may be made of soft materials, such as mattresses. In this study, we call mattress-like environment as a soft floor, which deforms when some force is added to it. We focused on the central pattern generator (CPG) network as a control for the snake robot to propel itself on the soft floor and constructed a CPG network that feeds back contact information between the robot and the floor. A genetic algorithm was used to determine the parameters of the CPG network suitable for the soft floor. To verify the obtained parameters, comparative simulations were conducted using the parameters obtained for the soft and hard floor, and the parameters were confirmed to be appropriate for each environment. By observing the difference in snake robot’s propulsion depending on the presence or absence of the tactile sensor feedback signal, we confirmed the effectiveness of the tactile sensor considered in the parameter search.},
  archive      = {J_FROBT},
  author       = {Tamura, Hajime and Kamegawa, Tetsushi},
  doi          = {10.3389/frobt.2023.1138019},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1138019},
  shortjournal = {Front. Robot. AI},
  title        = {Parameter search of a CPG network using a genetic algorithm for a snake robot with tactile sensors moving on a soft floor},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). CARMA II: A ground vehicle for autonomous surveying of
alpha, beta and gamma radiation. <em>FROBT</em>, <em>10</em>, 1137750.
(<a href="https://doi.org/10.3389/frobt.2023.1137750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surveying active nuclear facilities for spread of alpha and beta contamination is currently performed by human operators. However, a skills gap of qualified workers is emerging and is set to worsen in the near future due to under recruitment, retirement and increased demand. This paper presents an autonomous ground vehicle that can survey nuclear facilities for alpha, beta and gamma radiation and generate radiation heatmaps. New methods for preventing the robot from spreading radioactive contamination using a state-machine and radiation costmaps are introduced. This is the first robot that can detect alpha and beta contamination and autonomously re-plan around the contamination without the wheels passing over the contaminated area. Radiation avoidance functionality is proven experimentally to reduce alpha and beta contamination spread as well as gamma radiation dose to the robot. The robot’s survey area is defined using a custom designed, graphically controlled area coverage planner. It was concluded that the robot is highly suited to certain monotonous room scale radiation surveying tasks and therefore provides the opportunity for financial savings, to mitigate a future skills gap, and provision of radiation surveys that are more granular, accurate and repeatable than those currently performed by human operators.},
  archive      = {J_FROBT},
  author       = {Nouri Rahmat Abadi, Bahman and West, Andrew and Peel, Harriet and Nancekievill, Matthew and Ballard, Christopher and Lennox, Barry and Marjanovic, Ognjen and Groves, Keir},
  doi          = {10.3389/frobt.2023.1137750},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1137750},
  shortjournal = {Front. Robot. AI},
  title        = {CARMA II: A ground vehicle for autonomous surveying of alpha, beta and gamma radiation},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reproducibility challenges in robotic surgery.
<em>FROBT</em>, <em>10</em>, 1127972. (<a
href="https://doi.org/10.3389/frobt.2023.1127972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reproducibility of results is, in all research fields, the cornerstone of the scientific method and the minimum standard for assessing the value of scientific claims and conclusions drawn by other scientists. It requires a systematic approach and accurate description of the experimental procedure and data analysis, which allows other scientists to follow the steps described in the published work and obtain the “same results.” In general and in different research contexts with “same” results, we mean different things. It can be almost identical measures in a fully deterministic experiment or “validation of a hypothesis” or statistically similar results in a non-deterministic context. Unfortunately, it has been shown by systematic meta-analysis studies that many findings in fields like psychology, sociology, medicine, and economics do not hold up when other researchers try to replicate them. Many scientific fields are experiencing what is generally referred to as a “reproducibility crisis,” which undermines the trust in published results, imposes a thorough revision of the methodology in scientific research, and makes progress difficult. In general, the reproducibility of experiments is not a mainstream practice in artificial intelligence and robotics research. Surgical robotics is no exception. There is a need for developing new tools and putting in place a community effort to allow the transition to more reproducible research and hence faster progress in research. Reproducibility, replicability, and benchmarking (operational procedures for the assessment and comparison of research results) are made more complex for medical robotics and surgical systems, due to patenting, safety, and ethical issues. In this review paper, we selected 10 relevant published manuscripts on surgical robotics to analyze their clinical applicability and underline the problems related to reproducibility of the reported experiments, with the aim of finding possible solutions to the challenges that limit the translation of many scientific research studies into real-world applications and slow down research progress.},
  archive      = {J_FROBT},
  author       = {Faragasso, Angela and Bonsignorio, Fabio},
  doi          = {10.3389/frobt.2023.1127972},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1127972},
  shortjournal = {Front. Robot. AI},
  title        = {Reproducibility challenges in robotic surgery},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). REALMS: Resilient exploration and lunar mapping system.
<em>FROBT</em>, <em>10</em>, 1127496. (<a
href="https://doi.org/10.3389/frobt.2023.1127496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Space resource utilisation is opening a new space era. The scientific proof of the presence of water ice on the south pole of the Moon, the recent advances in oxygen extraction from lunar regolith, and its use as a material to build shelters are positioning the Moon, again, at the centre of important space programs. These worldwide programs, led by ARTEMIS, expect robotics to be the disrupting technology enabling humankind’s next giant leap. However, Moon robots require a high level of autonomy to perform lunar exploration tasks more efficiently without being constantly controlled from Earth. Furthermore, having more than one robotic system will increase the resilience and robustness of the global system, improving its success rate, as well as providing additional redundancy. This paper introduces the Resilient Exploration and Lunar Mapping System, developed with a scalable architecture for semi-autonomous lunar mapping. It leverages Visual Simultaneous Localization and Mapping techniques on multiple rovers to map large lunar environments. Several resilience mechanisms are implemented, such as two-agent redundancy, delay invariant communications, a multi-master architecture different control modes. This study presents the experimental results of REALMS with two robots and its potential to be scaled to a larger number of robots, increasing the map coverage and system redundancy. The system’s performance is verified and validated in a lunar analogue facility, and a larger lunar environment during the European Space Agency (ESA)-European Space Resources Innovation Centre Space Resources Challenge. The results of the different experiments show the efficiency of REALMS and the benefits of using semi-autonomous systems.},
  archive      = {J_FROBT},
  author       = {van der Meer, D. and Chovet, L. and Bera, A. and Richard, A. and Sánchez Cuevas, Pedro Jesus and Sánchez-Ibáñez, J. R. and Olivares-Mendez, M.},
  doi          = {10.3389/frobt.2023.1127496},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1127496},
  shortjournal = {Front. Robot. AI},
  title        = {REALMS: Resilient exploration and lunar mapping system},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interactive robot teaching based on finger trajectory using
multimodal RGB-d-t-data. <em>FROBT</em>, <em>10</em>, 1120357. (<a
href="https://doi.org/10.3389/frobt.2023.1120357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of Industry 4.0 brings the change of industry manufacturing patterns that become more efficient and more flexible. In response to this tendency, an efficient robot teaching approach without complex programming has become a popular research direction. Therefore, we propose an interactive finger-touch based robot teaching schema using a multimodal 3D image (color (RGB), thermal (T) and point cloud (3D)) processing. Here, the resulting heat trace touching the object surface will be analyzed on multimodal data, in order to precisely identify the true hand/object contact points. These identified contact points are used to calculate the robot path directly. To optimize the identification of the contact points we propose a calculation scheme using a number of anchor points which are first predicted by hand/object point cloud segmentation. Subsequently a probability density function is defined to calculate the prior probability distribution of true finger trace. The temperature in the neighborhood of each anchor point is then dynamically analyzed to calculate the likelihood. Experiments show that the trajectories estimated by our multimodal method have significantly better accuracy and smoothness than only by analyzing point cloud and static temperature distribution.},
  archive      = {J_FROBT},
  author       = {Zhang, Yan and Fütterer, Richard and Notni, Gunther},
  doi          = {10.3389/frobt.2023.1120357},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1120357},
  shortjournal = {Front. Robot. AI},
  title        = {Interactive robot teaching based on finger trajectory using multimodal RGB-D-T-data},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Soft robotics towards sustainable development goals and
climate actions. <em>FROBT</em>, <em>10</em>, 1116005. (<a
href="https://doi.org/10.3389/frobt.2023.1116005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft robotics technology can aid in achieving United Nations’ Sustainable Development Goals (SDGs) and the Paris Climate Agreement through development of autonomous, environmentally responsible machines powered by renewable energy. By utilizing soft robotics, we can mitigate the detrimental effects of climate change on human society and the natural world through fostering adaptation, restoration, and remediation. Moreover, the implementation of soft robotics can lead to groundbreaking discoveries in material science, biology, control systems, energy efficiency, and sustainable manufacturing processes. However, to achieve these goals, we need further improvements in understanding biological principles at the basis of embodied and physical intelligence, environment-friendly materials, and energy-saving strategies to design and manufacture self-piloting and field-ready soft robots. This paper provides insights on how soft robotics can address the pressing issue of environmental sustainability. Sustainable manufacturing of soft robots at a large scale, exploring the potential of biodegradable and bioinspired materials, and integrating onboard renewable energy sources to promote autonomy and intelligence are some of the urgent challenges of this field that we discuss in this paper. Specifically, we will present field-ready soft robots that address targeted productive applications in urban farming, healthcare, land and ocean preservation, disaster remediation, and clean and affordable energy, thus supporting some of the SDGs. By embracing soft robotics as a solution, we can concretely support economic growth and sustainable industry, drive solutions for environment protection and clean energy, and improve overall health and well-being.},
  archive      = {J_FROBT},
  author       = {Giordano, Goffredo and Murali Babu, Saravana Prashanth and Mazzolai, Barbara},
  doi          = {10.3389/frobt.2023.1116005},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1116005},
  shortjournal = {Front. Robot. AI},
  title        = {Soft robotics towards sustainable development goals and climate actions},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). High-altitude vertical wind profile estimation using
multirotor vehicles. <em>FROBT</em>, <em>10</em>, 1112889. (<a
href="https://doi.org/10.3389/frobt.2023.1112889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capturing vertical profiles of the atmosphere and measuring wind conditions can be of significant value for weather forecasting and pollution monitoring however, collecting such data can be limited by current approaches using balloon-based radiosondes and expensive ground-based sensors. Multirotor vehicles can be significantly affected by the local wind conditions, and due to their under-actuated nature, the response to the flow is visible in the changes in the orientation. From these changes in orientation, wind speed and direction estimates can be determined, allowing accurate estimation with no additional sensors. In this work, we expand on and improve this method of wind speed and direction estimation and incorporate corrections for climbing flight to improve estimation during vertical profiling. These corrections were validated against sonic anemometer data before being used to gather vertical profiles of the wind conditions around Volcan De Fuego in Guatemala up to altitudes of 3000 m Above Ground Level (AGL). From the results of this work, we show we can improve the accuracy of multirotor wind estimation in vertical profiling through our improved model and some of the practical limitations of radiosondes that can be overcome through the use of UAS in this application.},
  archive      = {J_FROBT},
  author       = {McConville, Alexander and Richardson, Thomas},
  doi          = {10.3389/frobt.2023.1112889},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1112889},
  shortjournal = {Front. Robot. AI},
  title        = {High-altitude vertical wind profile estimation using multirotor vehicles},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to generate pointing gestures in situated embodied
conversational agents. <em>FROBT</em>, <em>10</em>, 1110534. (<a
href="https://doi.org/10.3389/frobt.2023.1110534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the main goals of robotics and intelligent agent research is to enable them to communicate with humans in physically situated settings. Human communication consists of both verbal and non-verbal modes. Recent studies in enabling communication for intelligent agents have focused on verbal modes, i.e., language and speech. However, in a situated setting the non-verbal mode is crucial for an agent to adapt flexible communication strategies. In this work, we focus on learning to generate non-verbal communicative expressions in situated embodied interactive agents. Specifically, we show that an agent can learn pointing gestures in a physically simulated environment through a combination of imitation and reinforcement learning that achieves high motion naturalness and high referential accuracy. We compared our proposed system against several baselines in both subjective and objective evaluations. The subjective evaluation is done in a virtual reality setting where an embodied referential game is played between the user and the agent in a shared 3D space, a setup that fully assesses the communicative capabilities of the generated gestures. The evaluations show that our model achieves a higher level of referential accuracy and motion naturalness compared to a state-of-the-art supervised learning motion synthesis model, showing the promise of our proposed system that combines imitation and reinforcement learning for generating communicative gestures. Additionally, our system is robust in a physically-simulated environment thus has the potential of being applied to robots.},
  archive      = {J_FROBT},
  author       = {Deichler, Anna and Wang, Siyang and Alexanderson, Simon and Beskow, Jonas},
  doi          = {10.3389/frobt.2023.1110534},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1110534},
  shortjournal = {Front. Robot. AI},
  title        = {Learning to generate pointing gestures in situated embodied conversational agents},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Polyvinyl chloride-added dibutyl adipate for
high-performance electrohydrodynamic pumps. <em>FROBT</em>, <em>10</em>,
1109563. (<a href="https://doi.org/10.3389/frobt.2023.1109563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrohydrodynamic (EHD) pumps are a promising driving source for various fluid-driven systems owing to features such as simple structure and silent operation. The performance of EHD pumps depends on the properties of the working fluid, such as conductivity, viscosity, and permittivity. This implies that the tuning of these parameters in a working fluid can enhance the EHD performance. This study reports a method to modify the properties of a liquid for EHD pumps by mixing an additive. Specifically, dibutyl adipate (DBA) and polyvinyl chloride (PVC) are employed as the working fluid and the additive, respectively. The results show that when the concentration of PVC is 0.2%, the flow rate and pressure at applied voltage of 8 kV take highest value of 7.85 μL/s and 1.63 kPa, respectively. These values correspond to an improvement of 109% and 40% for the flow rate and pressure, respectively, compared to the pure DBA (PVC 0%). When the voltage is 10 kV, the flow rate of 10.95 μL/s and the pressure of 2.07 kPa are observed for DBA with PVC concentration of 0.2%. These values are more than five times higher than those observed for FC40 at the same voltage (2.02 μL/s and 0.32 kPa). The results also suggest that optimal conductivity and viscosity values exist for maximizing the EHD performance of a liquid. This demonstrates the validity of the proposed method for realizing high-performance EHD pumps by using additives in the working fluid.},
  archive      = {J_FROBT},
  author       = {Shimizu, Keita and Murakami, Kazuya and Ogawa, Naoki and Akai, Hideko and Shintake, Jun},
  doi          = {10.3389/frobt.2023.1109563},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1109563},
  shortjournal = {Front. Robot. AI},
  title        = {Polyvinyl chloride-added dibutyl adipate for high-performance electrohydrodynamic pumps},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards automated video-based assessment of dystonia in
dyskinetic cerebral palsy: A novel approach using markerless motion
tracking and machine learning. <em>FROBT</em>, <em>10</em>, 1108114. (<a
href="https://doi.org/10.3389/frobt.2023.1108114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Video-based clinical rating plays an important role in assessing dystonia and monitoring the effect of treatment in dyskinetic cerebral palsy (CP). However, evaluation by clinicians is time-consuming, and the quality of rating is dependent on experience. The aim of the current study is to provide a proof-of-concept for a machine learning approach to automatically assess scoring of dystonia using 2D stick figures extracted from videos. Model performance was compared to human performance.Methods: A total of 187 video sequences of 34 individuals with dyskinetic CP (8–23 years, all non-ambulatory) were filmed at rest during lying and supported sitting. Videos were scored by three raters according to the Dyskinesia Impairment Scale (DIS) for arm and leg dystonia (normalized scores ranging from 0–1). Coordinates in pixels of the left and right wrist, elbow, shoulder, hip, knee and ankle were extracted using DeepLabCut, an open source toolbox that builds on a pose estimation algorithm. Within a subset, tracking accuracy was assessed for a pretrained human model and for models trained with an increasing number of manually labeled frames. The mean absolute error (MAE) between DeepLabCut’s prediction of the position of body points and manual labels was calculated. Subsequently, movement and position features were calculated from extracted body point coordinates. These features were fed into a Random Forest Regressor to train a model to predict the clinical scores. The model performance trained with data from one rater evaluated by MAEs (model-rater) was compared to inter-rater accuracy.Results: A tracking accuracy of 4.5 pixels (approximately 1.5 cm) could be achieved by adding 15–20 manually labeled frames per video. The MAEs for the trained models ranged from 0.21 ± 0.15 for arm dystonia to 0.14 ± 0.10 for leg dystonia (normalized DIS scores). The inter-rater MAEs were 0.21 ± 0.22 and 0.16 ± 0.20, respectively.Conclusion: This proof-of-concept study shows the potential of using stick figures extracted from common videos in a machine learning approach to automatically assess dystonia. Sufficient tracking accuracy can be reached by manually adding labels within 15–20 frames per video. With a relatively small data set, it is possible to train a model that can automatically assess dystonia with a performance comparable to human scoring.},
  archive      = {J_FROBT},
  author       = {Haberfehlner, Helga and van de Ven, Shankara S. and van der Burg, Sven A. and Huber, Florian and Georgievska, Sonja and Aleo, Ignazio and Harlaar, Jaap and Bonouvrié, Laura A. and van der Krogt, Marjolein M. and Buizer, Annemieke I.},
  doi          = {10.3389/frobt.2023.1108114},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1108114},
  shortjournal = {Front. Robot. AI},
  title        = {Towards automated video-based assessment of dystonia in dyskinetic cerebral palsy: A novel approach using markerless motion tracking and machine learning},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analysis of the therapeutic interaction provided by a
humanoid robot serving stroke survivors as a therapeutic assistant for
arm rehabilitation. <em>FROBT</em>, <em>10</em>, 1103017. (<a
href="https://doi.org/10.3389/frobt.2023.1103017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective: To characterize a socially active humanoid robot’s therapeutic interaction as a therapeutic assistant when providing arm rehabilitation (i.e., arm basis training (ABT) for moderate-to-severe arm paresis or arm ability training (AAT) for mild arm paresis) to stroke survivors when using the digital therapeutic system Evidence-Based Robot-Assistant in Neurorehabilitation (E-BRAiN) and to compare it to human therapists’ interaction.Methods: Participants and therapy: Seventeen stroke survivors receiving arm rehabilitation (i.e., ABT [n = 9] or AAT [n = 8]) using E-BRAiN over a course of nine sessions and twenty-one other stroke survivors receiving arm rehabilitation sessions (i.e., ABT [n = 6] or AAT [n = 15]) in a conventional 1:1 therapist–patient setting. Analysis of therapeutic interaction: Therapy sessions were videotaped, and all therapeutic interactions (information provision, feedback, and bond-related interaction) were documented offline both in terms of their frequency of occurrence and time used for the respective type of interaction using the instrument THER-I-ACT. Statistical analyses: The therapeutic interaction of the humanoid robot, supervising staff/therapists, and helpers on day 1 is reported as mean across subjects for each type of therapy (i.e., ABT and AAT) as descriptive statistics. Effects of time (day 1 vs. day 9) on the humanoid robot interaction were analyzed by repeated-measures analysis of variance (rmANOVA) together with the between-subject factor type of therapy (ABT vs. AAT). The between-subject effect of the agent (humanoid robot vs. human therapist; day 1) was analyzed together with the factor therapy (ABT vs. AAT) by ANOVA.Main results and interpretation: The overall pattern of the therapeutic interaction by the humanoid robot was comprehensive and varied considerably with the type of therapy (as clinically indicated and intended), largely comparable to human therapists’ interaction, and adapted according to needs for interaction over time. Even substantially long robot-assisted therapy sessions seemed acceptable to stroke survivors and promoted engaged patients’ training behavior.Conclusion: Humanoid robot interaction as implemented in the digital system E-BRAiN matches the human therapeutic interaction and its modification across therapies well and promotes engaged training behavior by patients. These characteristics support its clinical use as a therapeutic assistant and, hence, its application to support specific and intensive restorative training for stroke survivors.},
  archive      = {J_FROBT},
  author       = {Platz, Thomas and Pedersen, Ann Louise and Deutsch, Philipp and Umlauft, Alexandru-Nicolae and Bader, Sebastian},
  doi          = {10.3389/frobt.2023.1103017},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1103017},
  shortjournal = {Front. Robot. AI},
  title        = {Analysis of the therapeutic interaction provided by a humanoid robot serving stroke survivors as a therapeutic assistant for arm rehabilitation},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). µRT: A lightweight real-time middleware with integrated
validation of timing constraints. <em>FROBT</em>, <em>10</em>, 1081875.
(<a href="https://doi.org/10.3389/frobt.2023.1081875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Middlewares are standard tools for modern software development in many areas, especially in robotics. Although such have become common for high-level applications, there is little support for real-time systems and low-level control. Therefore, µRT provides a lightweight solution for resource-constrained embedded systems, such as microcontrollers. It features publish–subscribe communication and remote procedure calls (RPCs) and can validate timing constraints at runtime. In contrast to other middlewares, µRT does not rely on specific transports for communication but can be used with any technology. Empirical results prove the small memory footprint, consistent temporal behavior, and predominantly linear scaling. The usability of µRT was found to be competitive with state-of-the-art solutions by means of a study.},
  archive      = {J_FROBT},
  author       = {Schöpping, Thomas and Kenneweg, Svenja and Hesse, Marc and Rückert, Ulrich},
  doi          = {10.3389/frobt.2023.1081875},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1081875},
  shortjournal = {Front. Robot. AI},
  title        = {µRT: A lightweight real-time middleware with integrated validation of timing constraints},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Traffic lights detection and tracking for HD map creation.
<em>FROBT</em>, <em>10</em>, 1065394. (<a
href="https://doi.org/10.3389/frobt.2023.1065394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {HD-maps are one of the core components of the self-driving pipeline. Despite the effort of many companies to develop a completely independent vehicle, many state-of-the-art solutions rely on high-definition maps of the environment for localization and navigation. Nevertheless, the creation process of such maps can be complex and error-prone or expensive if performed via ad-hoc surveys. For this reason, robust automated solutions are required. One fundamental component of an high-definition map is traffic lights. In particular, traffic light detection has been a well-known problem in the autonomous driving field. Still, the focus has always been on the light state, not the features (i.e., shape, orientation, pictogram). This work presents a pipeline for lights HD-map creation designed to provide accurate georeferenced position and description of all traffic lights seen by a camera mounted on a surveying vehicle. Our algorithm considers consecutive detection of the same light and uses Kalman filtering techniques to provide each target’s smoother and more precise position. Our pipeline has been validated for the detection and mapping task using the state-of-the-art dataset DriveU Traffic Light Dataset. The results show that our model is robust even with noisy GPS data. Moreover, for the detection task, we highlight how our model can correctly identify even far-away targets which are not labeled in the original dataset.},
  archive      = {J_FROBT},
  author       = {Mentasti, Simone and Simsek, Yusuf Can and Matteucci, Matteo},
  doi          = {10.3389/frobt.2023.1065394},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1065394},
  shortjournal = {Front. Robot. AI},
  title        = {Traffic lights detection and tracking for HD map creation},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). OSM-SLAM: Aiding SLAM with OpenStreetMaps priors.
<em>FROBT</em>, <em>10</em>, 1064934. (<a
href="https://doi.org/10.3389/frobt.2023.1064934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decades, Simultaneous Localization and Mapping (SLAM) proved to be a fundamental topic in the field of robotics, due to the many applications, ranging from autonomous driving to 3D reconstruction. Many systems have been proposed in literature exploiting a heterogeneous variety of sensors. State-of-the-art methods build their own map from scratch, using only data coming from the equipment of the robot, and not exploiting possible reconstructions of the environment. Moreover, temporary loss of data proves to be a challenge for SLAM systems, as it demands efficient re-localization to continue the localization process. In this paper, we present a SLAM system that exploits additional information coming from mapping services like OpenStreetMaps, hence the name OSM-SLAM, to face these issues. We extend an existing LiDAR-based Graph SLAM system, ART-SLAM, making it able to integrate the 2D geometry of buildings in the trajectory estimation process, by matching a prior OpenStreetMaps map with a single LiDAR scan. Each estimated pose of the robot is then associated with all buildings surrounding it. This association allows to improve localization accuracy, but also to adjust possible mistakes in the prior map. The pose estimates coming from SLAM are then jointly optimized with the constraints associated with the various OSM buildings, which can assume one of the following types: Buildings are always fixed (Prior SLAM); buildings surrounding a robot are movable in chunks, for every scan (Rigid SLAM); and every single building is free to move independently from the others (Non-rigid SLAM). Lastly, OSM maps can also be used to re-localize the robot when sensor data is lost. We compare the accuracy of the proposed system with existing methods for LiDAR-based SLAM, including the baseline, also providing a visual inspection of the results. The comparison is made by evaluating the estimated trajectory displacement using the KITTI odometry dataset. Moreover, the experimental campaign, along with an ablation study on the re-localization capabilities of the proposed system and its accuracy in loop detection-denied scenarios, allow a discussion about how the quality of prior maps influences the SLAM procedure, which may lead to worse estimates than the baseline.},
  archive      = {J_FROBT},
  author       = {Frosi, Matteo and Gobbi, Veronica and Matteucci, Matteo},
  doi          = {10.3389/frobt.2023.1064934},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1064934},
  shortjournal = {Front. Robot. AI},
  title        = {OSM-SLAM: Aiding SLAM with OpenStreetMaps priors},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Lighter and more efficient robotic joints in
prostheses and exoskeletons: Design, actuation and control.
<em>FROBT</em>, <em>10</em>, 1063712. (<a
href="https://doi.org/10.3389/frobt.2023.1063712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Sun, Yuanxi and Bai, Long and Dong, Dianbiao},
  doi          = {10.3389/frobt.2023.1063712},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1063712},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: lighter and more efficient robotic joints in prostheses and exoskeletons: design, actuation and control},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive control of a soft pneumatic actuator using
experimental characterization data. <em>FROBT</em>, <em>10</em>,
1056118. (<a href="https://doi.org/10.3389/frobt.2023.1056118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fiber reinforced soft pneumatic actuators are hard to control due to their non-linear behavior and non-uniformity introduced by the fabrication process. Model-based controllers generally have difficulty compensating non-uniform and non-linear material behaviors, whereas model-free approaches are harder to interpret and tune intuitively. In this study, we present the design, fabrication, characterization, and control of a fiber reinforced soft pneumatic module with an outer diameter size of 12 mm. Specifically, we utilized the characterization data to adaptively control the soft pneumatic actuator. From the measured characterization data, we fitted mapping functions between the actuator input pressures and the actuator space angles. These maps were used to construct the feedforward control signal and tune the feedback controller adaptively depending on the actuator bending configuration. The performance of the proposed control approach is experimentally validated by comparing the measured 2D tip orientation against the reference trajectory. The adaptive controller was able to successfully follow the prescribed trajectory with a mean absolute error of 0.68° for the magnitude of the bending angle and 3.5° for the bending phase around the axial direction. The data-driven control method introduced in this paper may offer a solution to intuitively tune and control soft pneumatic actuators, compensating for their non-uniform and non-linear behavior.},
  archive      = {J_FROBT},
  author       = {Mak, Yoeko Xavier and Naghibi, Hamid and Lin, Yuanxiang and Abayazid, Momen},
  doi          = {10.3389/frobt.2023.1056118},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1056118},
  shortjournal = {Front. Robot. AI},
  title        = {Adaptive control of a soft pneumatic actuator using experimental characterization data},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pedestrian detection model based on tiny-yolov3 architecture
for wearable devices to visually impaired assistance. <em>FROBT</em>,
<em>10</em>, 1052509. (<a
href="https://doi.org/10.3389/frobt.2023.1052509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Wearable assistive devices for the visually impaired whose technology is based on video camera devices represent a challenge in rapid evolution, where one of the main problems is to find computer vision algorithms that can be implemented in low-cost embedded devices.Objectives and Methods: This work presents a Tiny You Only Look Once architecture for pedestrian detection, which can be implemented in low-cost wearable devices as an alternative for the development of assistive technologies for the visually impaired.Results: The recall results of the proposed refined model represent an improvement of 71% working with four anchor boxes and 66% with six anchor boxes compared to the original model. The accuracy achieved on the same data set shows an increase of 14% and 25%, respectively. The F1 calculation shows a refinement of 57% and 55%. The average accuracy of the models achieved an improvement of 87% and 99%. The number of correctly detected objects was 3098 and 2892 for four and six anchor boxes, respectively, whose performance is better by 77% and 65% compared to the original, which correctly detected 1743 objects.Discussion: Finally, the model was optimized for the Jetson Nano embedded system, a case study for low-power embedded devices, and in a desktop computer. In both cases, the graphics processing unit (GPU) and central processing unit were tested, and a documented comparison of solutions aimed at serving visually impaired people was performed.Conclusion: We performed the desktop tests with a RTX 2070S graphics card, and the image processing took about 2.8 ms. The Jetson Nano board could process an image in about 110 ms, offering the opportunity to generate alert notification procedures in support of visually impaired mobility.},
  archive      = {J_FROBT},
  author       = {Maya-Martínez, Sergio-Uriel and Argüelles-Cruz, Amadeo-José and Guzmán-Zavaleta, Zobeida-Jezabel and Ramírez-Cadena, Miguel-de-Jesús},
  doi          = {10.3389/frobt.2023.1052509},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1052509},
  shortjournal = {Front. Robot. AI},
  title        = {Pedestrian detection model based on tiny-yolov3 architecture for wearable devices to visually impaired assistance},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Advanced learning control in physical interaction
tasks. <em>FROBT</em>, <em>10</em>, 1166759. (<a
href="https://doi.org/10.3389/frobt.2023.1166759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Zeng, Chao and Guo, Jing and Li, Qiang and Yang, Chenguang},
  doi          = {10.3389/frobt.2023.1166759},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1166759},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Advanced learning control in physical interaction tasks},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Computational intelligence advances in
educational robotics. <em>FROBT</em>, <em>10</em>, 1150409. (<a
href="https://doi.org/10.3389/frobt.2023.1150409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Bellas, Francisco and Sousa, Armando},
  doi          = {10.3389/frobt.2023.1150409},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1150409},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Computational intelligence advances in educational robotics},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fixed-time regulation of spacecraft orbit and attitude
coordination with optimal actuation allocation using dual quaternion.
<em>FROBT</em>, <em>10</em>, 1138115. (<a
href="https://doi.org/10.3389/frobt.2023.1138115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On-orbit service spacecraft with redundant actuators need to overcome orbital and attitude coupling when performing proximity maneuvers. In addition, transient/steady-state performance is required to fulfill the user-defined requirements. To these ends, this paper introduces a fixed-time tracking regulation and actuation allocation scheme for redundantly actuated spacecraft. The coupling effect of translational and rotational motions is described by dual quaternion. Based on this, we propose a non-singular fast terminal sliding mode controller to guarantee fixed-time tracking performance in the presence of external disturbances and system uncertainties, where the settling time is only dependent on user-defined control parameters rather than initial values. The unwinding problem caused by the redundancy of dual quaternion is handled by a novel attitude error function. Moreover, optimal quadratic programming is incorporated into null space pseudo-inverse control allocation that ensures the actuation smoothness and never violates the maximum output capability of each actuator. Numerical simulations on a spacecraft platform with symmetric thruster configuration demonstrate the validity of the proposed approach.},
  archive      = {J_FROBT},
  author       = {Sun, Lichao and Huang, Yanpei and Fei, Haolin and Xiao, Bo and Yeatman, Eric M. and Montazeri, Allahyar and Wang, Ziwei},
  doi          = {10.3389/frobt.2023.1138115},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1138115},
  shortjournal = {Front. Robot. AI},
  title        = {Fixed-time regulation of spacecraft orbit and attitude coordination with optimal actuation allocation using dual quaternion},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Robots in assisted living environments:
Enhancements, challenges and future perspectives. <em>FROBT</em>,
<em>10</em>, 1134462. (<a
href="https://doi.org/10.3389/frobt.2023.1134462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Freddi, Alessandro and Monteriù, Andrea and De Lucena, Vicente Ferreira and Ferracuti, Francesco and Iarlori, Sabrina},
  doi          = {10.3389/frobt.2023.1134462},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1134462},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: robots in assisted living environments: enhancements, challenges and future perspectives},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Early career scientists converse on the future of soft
robotics. <em>FROBT</em>, <em>10</em>, 1129827. (<a
href="https://doi.org/10.3389/frobt.2023.1129827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the recent decade, we have witnessed an extraordinary flourishing of soft robotics. Rekindled interest in soft robots is partially associated with the advances in manufacturing techniques that enable the fabrication of sophisticated multi-material robotic bodies with dimensions ranging across multiple length scales. In recent manuscripts, a reader might find peculiar-looking soft robots capable of grasping, walking, or swimming. However, the growth in publication numbers does not always reflect the real progress in the field since many manuscripts employ very similar ideas and just tweak soft body geometries. Therefore, we unreservedly agree with the sentiment that future research must move beyond “soft for soft’s sake.” Soft robotics is an undoubtedly fascinating field, but it requires a critical assessment of the limitations and challenges, enabling us to spotlight the areas and directions where soft robots will have the best leverage over their traditional counterparts. In this perspective paper, we discuss the current state of robotic research related to such important aspects as energy autonomy, electronic-free logic, and sustainability. The goal is to critically look at perspectives of soft robotics from two opposite points of view provided by early career researchers and highlight the most promising future direction, that is, in our opinion, the employment of soft robotic technologies for soft bio-inspired artificial organs.},
  archive      = {J_FROBT},
  author       = {Tauber, Falk J. and Slesarenko, Viacheslav},
  doi          = {10.3389/frobt.2023.1129827},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1129827},
  shortjournal = {Front. Robot. AI},
  title        = {Early career scientists converse on the future of soft robotics},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Research on automatic emergency steering collision avoidance
and stability control of intelligent driving vehicle. <em>FROBT</em>,
<em>10</em>, 1120658. (<a
href="https://doi.org/10.3389/frobt.2023.1120658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In view of the need for emergency steering to avoid collision when the vehicle is in a dangerous scene, and the stability control of the vehicle during collision avoidance. This paper proposes a planning and control framework. A path planner considering the kinematics and dynamics of the vehicle system is used to formulate the safe driving path under emergency conditions. LQR lateral control algorithm is designed to calculate the output steering wheel angle. On this basis, adaptive MPC control algorithm and four-wheel braking force distribution control algorithm are designed to achieve coordinated control of vehicle driving stability and collision avoidance safety. The simulation results show that the proposed algorithm can complete the steering collision avoidance task quickly and stably.},
  archive      = {J_FROBT},
  author       = {Liu, Zhaoyong and Wen, Gaobo and Liu, Wudong and Tan, TanXiaoqiang and Wu, Guangqiang},
  doi          = {10.3389/frobt.2023.1120658},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1120658},
  shortjournal = {Front. Robot. AI},
  title        = {Research on automatic emergency steering collision avoidance and stability control of intelligent driving vehicle},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reconfiguration strategy for fully actuated translational
cable-suspended parallel robots. <em>FROBT</em>, <em>10</em>, 1112856.
(<a href="https://doi.org/10.3389/frobt.2023.1112856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Cable-Suspended Parallel Robots (CSPRs), reconfigurability, i.e., the possibility of modifying the position of the cable connection points on the base frame, is particularly interesting to investigate, since it paves the way for future industrial and service applications of CSPRs, where the base frame can also be replaced by mobile agents. This report focuses on fully actuated Translational Reconfigurable CSPRs (TR-CSPRs), i.e., reconfigurable CSPRs with a point mass end-effector driven by three cables. The objective of the work is twofold. First, it is shown that the Wrench Exertion Capability (WEC) performance index can be exploited to identify the configurations of the cable connection points optimizing a task-related performance in a single point or throughout the workspace, and hence to implement a workspace analysis. Then, by referring to the case of a TR-CSPR with a single reconfigurable connection point and in quasi-static working condition, an analytical approach is provided to reconfigure the robot while executing a task to avoid one of the paramount problems of cable robots: cable slackness. Brought together, the two contributions allow defining a reconfiguration strategy for TR-CSPRs. The strategy is presented by applying it to a numerical example of a TR-CSPR used for lifting and moving a load along a prescribed path: the use of the WEC allows analyzing the workspace and predicting if robot reconfigurability makes it possible to pass quasi-statically along all the points of a given path; then reconfigurability is exploited to avoid cable slackness along the path.},
  archive      = {J_FROBT},
  author       = {Bettega, Jason and Boschetti, Giovanni and Piva, Giulio and Richiedei, Dario and Trevisani, Alberto},
  doi          = {10.3389/frobt.2023.1112856},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1112856},
  shortjournal = {Front. Robot. AI},
  title        = {Reconfiguration strategy for fully actuated translational cable-suspended parallel robots},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Built on-orbit robotically assembled gigatruss (BORG): A
mixed assembly architecture trade study. <em>FROBT</em>, <em>10</em>,
1109131. (<a href="https://doi.org/10.3389/frobt.2023.1109131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores a mixed assembly architecture trade study for a Built On-orbit Robotically assembled Gigatruss (BORG). Robotic in-space assembly (ISA) and servicing is a crucial field to expand endeavors in space. Currently, large structures in space are commonly only deployable and must be efficiently folded and packed into a launch vehicle (LV) and then deployed perfectly for operational status to be achieved. To actualize being able to build increasingly large structures in space, this scheme becomes less feasible, being constrained by LV volume and mass requirements. ISA allows the use of multiple launches to create even larger structures. The common ISA proposals consist of either strut-by-strut or multiple deployable module construction methodologies. In this paper, a mixed assembly scheme is explored and a trade study is conducted on its possible advantages with respect to many phases of a mission: 1) manufacturing, 2) stowage and transport, 3) ISA, and 4) servicing. Finally, a weighted decision matrix was created to help compare the various advantages and disadvantages of different architectural schemes.},
  archive      = {J_FROBT},
  author       = {Chapin, Samantha and Everson, Holly and Chapin, William and Quartaro, Amy and Komendera, Erik},
  doi          = {10.3389/frobt.2023.1109131},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1109131},
  shortjournal = {Front. Robot. AI},
  title        = {Built on-orbit robotically assembled gigatruss (BORG): A mixed assembly architecture trade study},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Soft-body dynamics induces energy efficiency in undulatory
swimming: A deep learning study. <em>FROBT</em>, <em>10</em>, 1102854.
(<a href="https://doi.org/10.3389/frobt.2023.1102854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, soft robotics has gained considerable attention as it promises numerous applications thanks to unique features originating from the physical compliance of the robots. Biomimetic underwater robots are a promising application in soft robotics and are expected to achieve efficient swimming comparable to the real aquatic life in nature. However, the energy efficiency of soft robots of this type has not gained much attention and has been fully investigated previously. This paper presents a comparative study to verify the effect of soft-body dynamics on energy efficiency in underwater locomotion by comparing the swimming of soft and rigid snake robots. These robots have the same motor capacity, mass, and body dimensions while maintaining the same actuation degrees of freedom. Different gait patterns are explored using a controller based on grid search and the deep reinforcement learning controller to cover the large solution space for the actuation space. The quantitative analysis of the energy consumption of these gaits indicates that the soft snake robot consumed less energy to reach the same velocity as the rigid snake robot. When the robots swim at the same average velocity of 0.024 m/s, the required power for the soft-body robot is reduced by 80.4% compared to the rigid counterpart. The present study is expected to contribute to promoting a new research direction to emphasize the energy efficiency advantage of soft-body dynamics in robot design.},
  archive      = {J_FROBT},
  author       = {Li, Guanda and Shintake, Jun and Hayashibe, Mitsuhiro},
  doi          = {10.3389/frobt.2023.1102854},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1102854},
  shortjournal = {Front. Robot. AI},
  title        = {Soft-body dynamics induces energy efficiency in undulatory swimming: A deep learning study},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intrinsic motivation learning for real robot applications.
<em>FROBT</em>, <em>10</em>, 1102438. (<a
href="https://doi.org/10.3389/frobt.2023.1102438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Rayyes, Rania},
  doi          = {10.3389/frobt.2023.1102438},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1102438},
  shortjournal = {Front. Robot. AI},
  title        = {Intrinsic motivation learning for real robot applications},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An online method to monitor hand muscle tone during
robot-assisted rehabilitation. <em>FROBT</em>, <em>10</em>, 1093124. (<a
href="https://doi.org/10.3389/frobt.2023.1093124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Robot-assisted neurorehabilitation is becoming an established method to complement conventional therapy after stroke and provide intensive therapy regimes in unsupervised settings (e.g., home rehabilitation). Intensive therapies may temporarily contribute to increasing muscle tone and spasticity, especially in stroke patients presenting tone alterations. If sustained without supervision, such an increase in muscle tone could have negative effects (e.g., functional disability, pain). We propose an online perturbation-based method that monitors finger muscle tone during unsupervised robot-assisted hand therapy exercises.Methods: We used the ReHandyBot, a novel 2 degrees of freedom (DOF) haptic device to perform robot-assisted therapy exercises training hand grasping (i.e., flexion-extension of the fingers) and forearm pronosupination. The tone estimation method consisted of fast (150 ms) and slow (250 ms) 20 mm ramp-and-hold perturbations on the grasping DOF, which were applied during the exercises to stretch the finger flexors. The perturbation-induced peak force at the finger pads was used to compute tone. In this work, we evaluated the method performance in a stiffness identification experiment with springs (0.97 and 1.57 N/mm), which simulated the stiffness of a human hand, and in a pilot study with subjects with increased muscle tone after stroke and unimpaired, which performed one active sensorimotor exercise embedding the tone monitoring method.Results: The method accurately estimates forces with root mean square percentage errors of 3.8% and 11.3% for the soft and stiff spring, respectively. In the pilot study, six chronic ischemic stroke patients [141.8 (56.7) months after stroke, 64.3 (9.5) years old, expressed as mean (std)] and ten unimpaired subjects [59.9 (6.1) years old] were tested without adverse events. The average reaction force at the level of the fingertip during slow and fast perturbations in the exercise were respectively 10.7 (5.6) N and 13.7 (5.6) N for the patients and 5.8 (4.2) N and 6.8 (5.1) N for the unimpaired subjects.Discussion: The proposed method estimates reaction forces of physical springs accurately, and captures online increased reaction forces in persons with stroke compared to unimpaired subjects within unsupervised human-robot interactions. In the future, the identified range of muscle tone increase after stroke could be used to customize therapy for each subject and maintain safety during intensive robot-assisted rehabilitation.},
  archive      = {J_FROBT},
  author       = {Ranzani, Raffaele and Chiriatti, Giorgia and Schwarz, Anne and Devittori, Giada and Gassert, Roger and Lambercy, Olivier},
  doi          = {10.3389/frobt.2023.1093124},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1093124},
  shortjournal = {Front. Robot. AI},
  title        = {An online method to monitor hand muscle tone during robot-assisted rehabilitation},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feasibility, coverage, and inter-rater reliability of the
assessment of therapeutic interaction by a humanoid robot providing arm
rehabilitation to stroke survivors using the instrument THER-i-ACT.
<em>FROBT</em>, <em>10</em>, 1091283. (<a
href="https://doi.org/10.3389/frobt.2023.1091283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective: The instrument THERapy-related InterACTion (THER-I-ACT) was developed to document therapeutic interactions comprehensively in the human therapist–patient setting. Here, we investigate whether the instrument can also reliably be used to characterise therapeutic interactions when a digital system with a humanoid robot as a therapeutic assistant is used.Methods:Participants and therapy: Seventeen stroke survivors receiving arm rehabilitation (i.e., arm basis training (ABT) for moderate-to-severe arm paresis [n = 9] or arm ability training (AAT) for mild arm paresis [n = 8]) using the digital therapy system E-BRAiN over a course of nine sessions. Analysis of the therapeutic interaction: A total of 34 therapy sessions were videotaped. All therapeutic interactions provided by the humanoid robot during the first and the last (9th) session of daily training were documented both in terms of their frequency and time used for that type of interaction using THER-I-ACT. Any additional therapeutic interaction spontaneously given by the supervising staff or a human helper providing physical assistance (ABT only) was also documented. All ratings were performed by two trained independent raters.Statistical analyses: Intraclass correlation coefficients (ICCs) were calculated for the frequency of occurrence and time used for each category of interaction observed.Results: Therapeutic interactions could comprehensively be documented and were observed across the dimensions provision of information, feedback, and bond-related interactions. ICCs for therapeutic interaction category assessments from 34 therapy sessions by two independent raters were high (ICC ≥0.90) for almost all categories of the therapeutic interaction observed, both for the occurrence frequency and time used for categories of therapeutic interactions, and both for the therapeutic interaction performed by the robot and, even though much less frequently observed, additional spontaneous therapeutic interactions by the supervisory staff and a helper being present. The ICC was similarly high for an overall subjective rating of the concentration and engagement of patients (0.87).Conclusion: Therapeutic interactions can comprehensively and reliably be documented by trained raters using the instrument THER-I-ACT not only in the traditional patient–therapist setting, as previously shown, but also in a digital therapy setting with a humanoid robot as the therapeutic agent and for more complex therapeutic settings with more than one therapeutic agent being present.},
  archive      = {J_FROBT},
  author       = {Platz, Thomas and Pedersen, Ann Louise and Bobe, Stephanie},
  doi          = {10.3389/frobt.2023.1091283},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1091283},
  shortjournal = {Front. Robot. AI},
  title        = {Feasibility, coverage, and inter-rater reliability of the assessment of therapeutic interaction by a humanoid robot providing arm rehabilitation to stroke survivors using the instrument THER-I-ACT},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A bioinspired stiffness tunable sucker for passive
adaptation and firm attachment to angular substrates. <em>FROBT</em>,
<em>10</em>, 1080015. (<a
href="https://doi.org/10.3389/frobt.2023.1080015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to adapt and conform to angular and uneven surfaces improves the suction cup’s performance in grasping and manipulation. However, in most cases, the adaptation costs lack of required stiffness for manipulation after surface attachment; thus, the ideal scenario is to have compliance during adaptation and stiffness after attachment to the surface. Inspired by the capability of stiffness regulation in octopus suction cup, this article presents a suction cup that adapts to steep angular surfaces due to compliance and has high stiffness after attachment. In this design, the stiffness after attachment is provided by using granular jamming as vacuum driven stiffness modulation. Thus, the design is composed of a conventional active suction pad connected to a granular stalk, emulating a hinge behavior during adaptation and creating high stiffness by jamming granular particles driven by the same vacuum as the suction pad. During the experiment, the suction cup can adapt to angles up to 85° with a force lower than 0.5 N. We also investigated the effect of granular stalk’s length on the adaptation and how this design performs compared to passive adaptation without stiffness modulation.},
  archive      = {J_FROBT},
  author       = {Goshtasbi, Arman and Sadeghi, Ali},
  doi          = {10.3389/frobt.2023.1080015},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1080015},
  shortjournal = {Front. Robot. AI},
  title        = {A bioinspired stiffness tunable sucker for passive adaptation and firm attachment to angular substrates},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Switchable MPC-based multi-objective regenerative brake
control via flow regulation for electric vehicles. <em>FROBT</em>,
<em>10</em>, 1078253. (<a
href="https://doi.org/10.3389/frobt.2023.1078253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent investigations of the electric braking booster (E-Booster) focus on its potential to enhance brake energy regeneration. A vehicle’s hydraulic system is composed of the E-Booster and electric stability control to control the master cylinder and wheel cylinders. This paper aims to address the independent closed-loop control of the position and pressure as well as the maintenance of the pedal feel. To track both the reference signals related to piston displacement and the wheel cylinder pressure, an explicit model predictive control (MPC) is developed. First, the new flow model is introduced as the foundation for controller design and simulation. Next, in accordance with the operational conditions, the entire system is divided into three switchable subsystems. The three distributed MPCs are constructed based on the linearized subsystems, and a state machine is used to perform the state jump across the controllers. A linear piecewise affine control law can then be obtained by solving the quadratic program (QP) of explicit MPC. Afterwards, the non-linear extended Kalman filter including the recorded time-variant process noise is used to estimate all the state variables. The effectiveness of the explicit MPC is evidenced by the simulations compared with a single MPC in regenerative and dead-zone conditions. The proposed controller decreases the latency significantly by 85 milliseconds, which also helps to improve accuracy by 22.6%. Furthermore, the pedal feel remains consistent, even when factoring in the number of vibrations caused by the inherent hydraulic characteristic of pressure versus volume.},
  archive      = {J_FROBT},
  author       = {Mei, Mingming and Cheng, Shuo and Mu, Hongyuan and Pei, Yuxuan and Li, Bo},
  doi          = {10.3389/frobt.2023.1078253},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1078253},
  shortjournal = {Front. Robot. AI},
  title        = {Switchable MPC-based multi-objective regenerative brake control via flow regulation for electric vehicles},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Soft robotics in wearable and implantable medical
applications: Translational challenges and future outlooks.
<em>FROBT</em>, <em>10</em>, 1075634. (<a
href="https://doi.org/10.3389/frobt.2023.1075634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work explores the recent research conducted towards the development of novel classes of devices in wearable and implantable medical applications allowed by the introduction of the soft robotics approach. In the medical field, the need for materials with mechanical properties similar to biological tissues is one of the first considerations that arises to improve comfort and safety in the physical interaction with the human body. Thus, soft robotic devices are expected to be able of accomplishing tasks no traditional rigid systems can do. In this paper, we describe future perspectives and possible routes to address scientific and clinical issues still hampering the accomplishment of ideal solutions in clinical practice.},
  archive      = {J_FROBT},
  author       = {Paternò, Linda and Lorenzon, Lucrezia},
  doi          = {10.3389/frobt.2023.1075634},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1075634},
  shortjournal = {Front. Robot. AI},
  title        = {Soft robotics in wearable and implantable medical applications: Translational challenges and future outlooks},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Low limb prostheses and complex human prosthetic
interaction: A systematic literature review. <em>FROBT</em>,
<em>10</em>, 1032748. (<a
href="https://doi.org/10.3389/frobt.2023.1032748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A few years ago, powered prostheses triggered new technological advances in diverse areas such as mobility, comfort, and design, which have been essential to improving the quality of life of individuals with lower limb disability. The human body is a complex system involving mental and physical health, meaning a dependant relationship between its organs and lifestyle. The elements used in the design of these prostheses are critical and related to lower limb amputation level, user morphology and human-prosthetic interaction. Hence, several technologies have been employed to accomplish the end user’s needs, for example, advanced materials, control systems, electronics, energy management, signal processing, and artificial intelligence. This paper presents a systematic literature review on such technologies, to identify the latest advances, challenges, and opportunities in developing lower limb prostheses with the analysis on the most significant papers. Powered prostheses for walking in different terrains were illustrated and examined, with the kind of movement the device should perform by considering the electronics, automatic control, and energy efficiency. Results show a lack of a specific and generalised structure to be followed by new developments, gaps in energy management and improved smoother patient interaction. Additionally, Human Prosthetic Interaction (HPI) is a term introduced in this paper since no other research has integrated this interaction in communication between the artificial limb and the end-user. The main goal of this paper is to provide, with the found evidence, a set of steps and components to be followed by new researchers and experts looking to improve knowledge in this field.},
  archive      = {J_FROBT},
  author       = {Domínguez-Ruiz, Adan and López-Caudana, Edgar Omar and Lugo-González, Esther and Espinosa-García, Francisco Javier and Ambrocio-Delgado, Rocío and García, Ulises D. and López-Gutiérrez, Ricardo and Alfaro-Ponce, Mariel and Ponce, Pedro},
  doi          = {10.3389/frobt.2023.1032748},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1032748},
  shortjournal = {Front. Robot. AI},
  title        = {Low limb prostheses and complex human prosthetic interaction: A systematic literature review},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning from humans to build social cognition among robots.
<em>FROBT</em>, <em>10</em>, 1030416. (<a
href="https://doi.org/10.3389/frobt.2023.1030416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-organized groups of robots have generally coordinated their behaviors using quite simple social interactions. Although simple interactions are sufficient for some group behaviors, future research needs to investigate more elaborate forms of coordination, such as social cognition, to progress towards real deployments. In this perspective, we define social cognition among robots as the combination of social inference, social learning, social influence, and knowledge transfer, and propose that these abilities can be established in robots by building underlying mechanisms based on behaviors observed in humans. We review key social processes observed in humans that could inspire valuable capabilities in robots and propose that relevant insights from human social cognition can be obtained by studying human-controlled avatars in virtual environments that have the correct balance of embodiment and constraints. Such environments need to allow participants to engage in embodied social behaviors, for instance through situatedness and bodily involvement, but, at the same time, need to artificially constrain humans to the operational conditions of robots, for instance in terms of perception and communication. We illustrate our proposed experimental method with example setups in a multi-user virtual environment.},
  archive      = {J_FROBT},
  author       = {Coucke, Nicolas and Heinrich, Mary Katherine and Cleeremans, Axel and Dorigo, Marco},
  doi          = {10.3389/frobt.2023.1030416},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1030416},
  shortjournal = {Front. Robot. AI},
  title        = {Learning from humans to build social cognition among robots},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel approach for automatic annotation of human actions
in 3D point clouds for flexible collaborative tasks with industrial
robots. <em>FROBT</em>, <em>10</em>, 1028329. (<a
href="https://doi.org/10.3389/frobt.2023.1028329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manual annotation for human action recognition with content semantics using 3D Point Cloud (3D-PC) in industrial environments consumes a lot of time and resources. This work aims to recognize, analyze, and model human actions to develop a framework for automatically extracting content semantics. Main Contributions of this work: 1. design a multi-layer structure of various DNN classifiers to detect and extract humans and dynamic objects using 3D-PC preciously, 2. empirical experiments with over 10 subjects for collecting datasets of human actions and activities in one industrial setting, 3. development of an intuitive GUI to verify human actions and its interaction activities with the environment, 4. design and implement a methodology for automatic sequence matching of human actions in 3D-PC. All these procedures are merged in the proposed framework and evaluated in one industrial Use-Case with flexible patch sizes. Comparing the new approach with standard methods has shown that the annotation process can be accelerated by 5.2 times through automation.},
  archive      = {J_FROBT},
  author       = {Krusche, Sebastian and Al Naser, Ibrahim and Bdiwi, Mohamad and Ihlenfeldt, Steffen},
  doi          = {10.3389/frobt.2023.1028329},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1028329},
  shortjournal = {Front. Robot. AI},
  title        = {A novel approach for automatic annotation of human actions in 3D point clouds for flexible collaborative tasks with industrial robots},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Event-based feature tracking in a visual inertial odometry
framework. <em>FROBT</em>, <em>10</em>, 994488. (<a
href="https://doi.org/10.3389/frobt.2023.994488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Event cameras report pixel-wise brightness changes at high temporal resolutions, allowing for high speed tracking of features in visual inertial odometry (VIO) estimation, but require a paradigm shift, as common practices from the past decades using conventional cameras, such as feature detection and tracking, do not translate directly. One method for feature detection and tracking is the Eventbased Kanade-Lucas-Tomasi tracker (EKLT), an hybrid approach that combines frames with events to provide a high speed tracking of features. Despite the high temporal resolution of the events, the local nature of the registration of features imposes conservative limits to the camera motion speed.Methods: Our proposed approach expands on EKLT by relying on the concurrent use of the event-based feature tracker with a visual inertial odometry system performing pose estimation, leveraging frames, events and Inertial Measurement Unit (IMU) information to improve tracking. The problem of temporally combining high-rate IMU information with asynchronous event cameras is solved by means of an asynchronous probabilistic filter, in particular an Unscented Kalman Filter (UKF). The proposed method of feature tracking based on EKLT takes into account the state estimation of the pose estimator running in parallel and provides this information to the feature tracker, resulting in a synergy that can improve not only the feature tracking, but also the pose estimation. This approach can be seen as a feedback, where the state estimation of the filter is fed back into the tracker, which then produces visual information for the filter, creating a “closed loop”.Results: The method is tested on rotational motions only, and comparisons between a conventional (not event-based) approach and the proposed approach are made, using synthetic and real datasets. Results support that the use of events for the task improve performance.Discussion: To the best of our knowledge, this is the first work proposing the fusion of visual with inertial information using events cameras by means of an UKF, as well as the use of EKLT in the context of pose estimation. Furthermore, our closed loop approach proved to be an improvement over the base EKLT, resulting in better feature tracking and pose estimation. The inertial information, despite prone to drifting over time, allows keeping track of the features that would otherwise be lost. Then, feature tracking synergically helps estimating and minimizing the drift.},
  archive      = {J_FROBT},
  author       = {Ribeiro-Gomes, José and Gaspar, José and Bernardino, Alexandre},
  doi          = {10.3389/frobt.2023.994488},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {994488},
  shortjournal = {Front. Robot. AI},
  title        = {Event-based feature tracking in a visual inertial odometry framework},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the precision of 6 DoF IMU-LiDAR based localization in
GNSS-denied scenarios. <em>FROBT</em>, <em>10</em>, 1064930. (<a
href="https://doi.org/10.3389/frobt.2023.1064930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Positioning and navigation represent relevant topics in the field of robotics, due to their multiple applications in real-world scenarios, ranging from autonomous driving to harsh environment exploration. Despite localization in outdoor environments is generally achieved using a Global Navigation Satellite System (GNSS) receiver, global navigation satellite system-denied environments are typical of many situations, especially in indoor settings. Autonomous robots are commonly equipped with multiple sensors, including laser rangefinders, IMUs, and odometers, which can be used for mapping and localization, overcoming the need for global navigation satellite system data. In literature, almost no information can be found on the positioning accuracy and precision of 6 Degrees of Freedom Light Detection and Ranging (LiDAR) localization systems, especially for real-world scenarios. In this paper, we present a short review of state-of-the-art light detection and ranging localization methods in global navigation satellite system-denied environments, highlighting their advantages and disadvantages. Then, we evaluate two state-of-the-art Simultaneous Localization and Mapping (SLAM) systems able to also perform localization, one of which implemented by us. We benchmark these two algorithms on manually collected dataset, with the goal of providing an insight into their attainable precision in real-world scenarios. In particular, we present two experimental campaigns, one indoor and one outdoor, to measure the precision of these algorithms. After creating a map for each of the two environments, using the simultaneous localization and mapping part of the systems, we compute a custom localization error for multiple, different trajectories. Results show that the two algorithms are comparable in terms of precision, having a similar mean translation and rotation errors of about 0.01 m and 0.6°, respectively. Nevertheless, the system implemented by us has the advantage of being modular, customizable and able to achieve real-time performance.},
  archive      = {J_FROBT},
  author       = {Frosi, Matteo and Bertoglio, Riccardo and Matteucci, Matteo},
  doi          = {10.3389/frobt.2023.1064930},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1064930},
  shortjournal = {Front. Robot. AI},
  title        = {On the precision of 6 DoF IMU-LiDAR based localization in GNSS-denied scenarios},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fundamentals of burrowing in soft animals and robots.
<em>FROBT</em>, <em>10</em>, 1057876. (<a
href="https://doi.org/10.3389/frobt.2023.1057876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Creating burrows through natural soils and sediments is a problem that evolution has solved numerous times, yet burrowing locomotion is challenging for biomimetic robots. As for every type of locomotion, forward thrust must overcome resistance forces. In burrowing, these forces will depend on the sediment mechanical properties that can vary with grain size and packing density, water saturation, organic matter and depth. The burrower typically cannot change these environmental properties, but can employ common strategies to move through a range of sediments. Here we propose four challenges for burrowers to solve. First, the burrower has to create space in a solid substrate, overcoming resistance by e.g., excavation, fracture, compression, or fluidization. Second, the burrower needs to locomote into the confined space. A compliant body helps fit into the possibly irregular space, but reaching the new space requires non-rigid kinematics such as longitudinal extension through peristalsis, unbending, or eversion. Third, to generate the required thrust to overcome resistance, the burrower needs to anchor within the burrow. Anchoring can be achieved through anisotropic friction or radial expansion, or both. Fourth, the burrower must sense and navigate to adapt the burrow shape to avoid or access different parts of the environment. Our hope is that by breaking the complexity of burrowing into these component challenges, engineers will be better able to learn from biology, since animal performance tends to exceed that of their robotic counterparts. Since body size strongly affects space creation, scaling may be a limiting factor for burrowing robotics, which are typically built at larger scales. Small robots are becoming increasingly feasible, and larger robots with non-biologically-inspired anteriors (or that traverse pre-existing tunnels) can benefit from a deeper understanding of the breadth of biological solutions in current literature and to be explored by continued research.},
  archive      = {J_FROBT},
  author       = {Dorgan, Kelly M. and Daltorio, Kathryn A.},
  doi          = {10.3389/frobt.2023.1057876},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1057876},
  shortjournal = {Front. Robot. AI},
  title        = {Fundamentals of burrowing in soft animals and robots},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Socio-cultural perception of robot backchannels.
<em>FROBT</em>, <em>10</em>, 988042. (<a
href="https://doi.org/10.3389/frobt.2023.988042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Backchannels, i.e., short interjections by an interlocutor to indicate attention, understanding or agreement regarding utterances by another conversation participant, are fundamental in human-human interaction. Lack of backchannels or if they have unexpected timing or formulation may influence the conversation negatively, as misinterpretations regarding attention, understanding or agreement may occur. However, several studies over the years have shown that there may be cultural differences in how backchannels are provided and perceived and that these differences may affect intercultural conversations. Culturally aware robots must hence be endowed with the capability to detect and adapt to the way these conversational markers are used across different cultures. Traditionally, culture has been defined in terms of nationality, but this is more and more considered to be a stereotypic simplification. We therefore investigate several socio-cultural factors, such as the participants’ gender, age, first language, extroversion and familiarity with robots, that may be relevant for the perception of backchannels.Methods: We first cover existing research on cultural influence on backchannel formulation and perception in human-human interaction and on backchannel implementation in Human-Robot Interaction. We then present an experiment on second language spoken practice, in which we investigate how backchannels from the social robot Furhat influence interaction (investigated through speaking time ratios and ethnomethodology and multimodal conversation analysis) and impression of the robot (measured by post-session ratings). The experiment, made in a triad word game setting, is focused on if activity-adaptive robot backchannels may redistribute the participants’ speaking time ratio, and/or if the participants’ assessment of the robot is influenced by the backchannel strategy. The goal is to explore how robot backchannels should be adapted to different language learners to encourage their participation while being perceived as socio-culturally appropriate.Results: We find that a strategy that displays more backchannels towards a less active speaker may substantially decrease the difference in speaking time between the two speakers, that different socio-cultural groups respond differently to the robot’s backchannel strategy and that they also perceive the robot differently after the session.Discussion: We conclude that the robot may need different backchanneling strategies towards speakers from different socio-cultural groups in order to encourage them to speak and have a positive perception of the robot.},
  archive      = {J_FROBT},
  author       = {Engwall, Olov and Cumbal, Ronald and Majlesi, Ali Reza},
  doi          = {10.3389/frobt.2023.988042},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {988042},
  shortjournal = {Front. Robot. AI},
  title        = {Socio-cultural perception of robot backchannels},
  volume       = {10},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Expansion in speech time can restore comprehension in a
simultaneously speaking bilingual robot. <em>FROBT</em>, <em>9</em>,
1032811. (<a href="https://doi.org/10.3389/frobt.2022.1032811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: In this study, the development of a social robot, capable of giving speech simultaneously in more than one language was in mind. However, the negative effect of background noise on speech comprehension is well-documented in previous works. This deteriorating effect is more highlighted when the background noise has speech-like properties. Hence, the presence of speech as the background noise in a simultaneously speaking bilingual robot can be fatal for the speech comprehension of each person listening to the robot.Methods: To improve speech comprehension and consequently, user experience in the intended bilingual robot, the effect of time expansion on speech comprehension in a multi-talker speech scenario was investigated. Sentence recognition, speech comprehension, and subjective evaluation tasks were implemented in the study.Results: The obtained results suggest that a reduced speech rate, leading to an expansion in the speech time, in addition to increased pause duration in both the target and background speeches can lead to statistically significant improvement in both sentence recognition, and speech comprehension of participants. More interestingly, participants got a higher score in the time-expanded multi-talker speech than in the standard-speed single-talker speech in the speech comprehension and, in the sentence recognition task. However, this positive effect could not be attributed merely to the time expansion, as we could not repeat the same positive effect in a time-expanded single-talker speech.Discussion: The results obtained in this study suggest a facilitating effect of the presence of the background speech in a simultaneously speaking bilingual robot provided that both languages are presented in a time-expanded manner. The implications of such a simultaneously speaking robot are discussed.},
  archive      = {J_FROBT},
  author       = {Pourfannan, Hamed and Mahzoon, Hamed and Yoshikawa, Yuichiro and Ishiguro, Hiroshi},
  doi          = {10.3389/frobt.2022.1032811},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1032811},
  shortjournal = {Front. Robot. AI},
  title        = {Expansion in speech time can restore comprehension in a simultaneously speaking bilingual robot},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Robotics for smart farms. <em>FROBT</em>,
<em>9</em>, 1113440. (<a
href="https://doi.org/10.3389/frobt.2022.1113440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Emmi, Luis and Fernandez, Roemi and Guerrero, José Miguel},
  doi          = {10.3389/frobt.2022.1113440},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1113440},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Robotics for smart farms},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Robotic grasping and manipulation of deformable
objects. <em>FROBT</em>, <em>9</em>, 1108038. (<a
href="https://doi.org/10.3389/frobt.2022.1108038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Bimbo, Joao and Liarokapis, Minas and Malvezzi, Monica and Salvietti, Gionata},
  doi          = {10.3389/frobt.2022.1108038},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1108038},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Robotic grasping and manipulation of deformable objects},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Organ curvature sensing using pneumatically attachable
flexible rails in robotic-assisted laparoscopic surgery. <em>FROBT</em>,
<em>9</em>, 1099275. (<a
href="https://doi.org/10.3389/frobt.2022.1099275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In robotic-assisted partial nephrectomy, surgeons remove a part of a kidney often due to the presence of a mass. A drop-in ultrasound probe paired to a surgical robot is deployed to execute multiple swipes over the kidney surface to localise the mass and define the margins of resection. This sub-task is challenging and must be performed by a highly-skilled surgeon. Automating this sub-task may reduce cognitive load for the surgeon and improve patient outcomes. The eventual goal of this work is to autonomously move the ultrasound probe on the surface of the kidney taking advantage of the use of the Pneumatically Attachable Flexible (PAF) rail system, a soft robotic device used for organ scanning and repositioning. First, we integrate a shape-sensing optical fibre into the PAF rail system to evaluate the curvature of target organs in robotic-assisted laparoscopic surgery. Then, we investigate the impact of the PAF rail’s material stiffness on the curvature sensing accuracy, considering that soft targets are present in the surgical field. We found overall curvature sensing accuracy to be between 1.44% and 7.27% over the range of curvatures present in adult kidneys. Finally, we use shape sensing to plan the trajectory of the da Vinci surgical robot paired with a drop-in ultrasound probe and autonomously generate an Ultrasound scan of a kidney phantom.},
  archive      = {J_FROBT},
  author       = {McDonald-Bowyer, A. and Dietsch, S. and Dimitrakakis, E. and Coote, J. M. and Lindenroth, L. and Stoyanov, D. and Stilli, A.},
  doi          = {10.3389/frobt.2022.1099275},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1099275},
  shortjournal = {Front. Robot. AI},
  title        = {Organ curvature sensing using pneumatically attachable flexible rails in robotic-assisted laparoscopic surgery},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid controller method with genetic algorithm
optimization to measure position and angular for mobile robot motion
control. <em>FROBT</em>, <em>9</em>, 1087371. (<a
href="https://doi.org/10.3389/frobt.2022.1087371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the complexity of autonomous mobile robot’s requirement and drastic technological changes, the safe and efficient path tracking development is becoming complex and requires intensive knowledge and information, thus the demand for advanced algorithm has rapidly increased. Analyzing unstructured gain data has been a growing interest among researchers, resulting in valuable information in many fields such as path planning and motion control. Among those, motion control is a vital part of a fast, secure operation. Yet, current approaches face problems in managing unstructured gain data and producing accurate local planning due to the lack of formulation in the knowledge on the gain optimization. Therefore, this research aims to design a new gain optimization approach to assist researcher in identifying the value of the gain’s product with a qualitative comparative study of the up-to-date controllers. Gains optimization in this context is to classify the near perfect value of the gain’s product and processes. For this, a domain controller will be developed based on the attributes of the Fuzzy-PID parameters. The development of the Fuzzy Logic Controller requires information on the PID controller parameters that will be fuzzified and defuzzied based on the resulting 49 fuzzy rules. Furthermore, this fuzzy inference will be optimized for its usability by a genetic algorithm (GA). It is expected that the domain controller will give a positive impact to the path planning position and angular PID controller algorithm that meet the autonomous demand.},
  archive      = {J_FROBT},
  author       = {Razali, Muhammad Razmi and Mohd Faudzi, Ahmad Athif and Shamsudin, Abu Ubaidah and Mohamaddan, Shahrol},
  doi          = {10.3389/frobt.2022.1087371},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1087371},
  shortjournal = {Front. Robot. AI},
  title        = {A hybrid controller method with genetic algorithm optimization to measure position and angular for mobile robot motion control},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Advanced medical micro-robotics for early diagnosis and
therapeutic interventions. <em>FROBT</em>, <em>9</em>, 1086043. (<a
href="https://doi.org/10.3389/frobt.2022.1086043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent technological advances in micro-robotics have demonstrated their immense potential for biomedical applications. Emerging micro-robots have versatile sensing systems, flexible locomotion and dexterous manipulation capabilities that can significantly contribute to the healthcare system. Despite the appreciated and tangible benefits of medical micro-robotics, many challenges still remain. Here, we review the major challenges, current trends and significant achievements for developing versatile and intelligent micro-robotics with a focus on applications in early diagnosis and therapeutic interventions. We also consider some recent emerging micro-robotic technologies that employ synthetic biology to support a new generation of living micro-robots. We expect to inspire future development of micro-robots toward clinical translation by identifying the roadblocks that need to be overcome.},
  archive      = {J_FROBT},
  author       = {Zhang, Dandan and Gorochowski, Thomas E. and Marucci, Lucia and Lee, Hyun-Taek and Gil, Bruno and Li, Bing and Hauert, Sabine and Yeatman, Eric},
  doi          = {10.3389/frobt.2022.1086043},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1086043},
  shortjournal = {Front. Robot. AI},
  title        = {Advanced medical micro-robotics for early diagnosis and therapeutic interventions},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Singularity analysis of 3-DOF planar parallel continuum
robots with constant curvature links. <em>FROBT</em>, <em>9</em>,
1082185. (<a href="https://doi.org/10.3389/frobt.2022.1082185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the singularity analysis of 3-DOF planar parallel continuum robots (PCR) with three identical legs. Each of the legs contains two passive conventional rigid 1-DOF joints and one actuated planar continuum link, which bends with a constant curvature. All possible PCR architectures featuring such legs are enumerated and the kinematic velocity equations are provided for each of them. Afterwards, a singularity analysis is conducted based on the obtained Jacobian matrices, providing a geometrical understanding of singularity occurences. It is shown that while loci and occurrences of type II singularities are mostly analogous to conventional parallel kinematic mechanisms (PKM), type I singularity occurences for the PCR studied in this work are quite different from conventional PKM and less geometrically intuitive. The study provided in this paper can promote further investigations on planar parallel continuum robots, such as structural design and control.},
  archive      = {J_FROBT},
  author       = {Lilge, Sven and Wen, Kefei and Burgner-Kahrs, Jessica},
  doi          = {10.3389/frobt.2022.1082185},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1082185},
  shortjournal = {Front. Robot. AI},
  title        = {Singularity analysis of 3-DOF planar parallel continuum robots with constant curvature links},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A method to create real-like point clouds for 3D object
classification. <em>FROBT</em>, <em>9</em>, 1077895. (<a
href="https://doi.org/10.3389/frobt.2022.1077895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are a large number of publicly available datasets of 3D data, they generally suffer from some drawbacks, such as small number of data samples, and class imbalance. Data augmentation is a set of techniques that aim to increase the size of datasets and solve such defects, and hence to overcome the problem of overfitting when training a classifier. In this paper, we propose a method to create new synthesized data by converting complete meshes into occluded 3D point clouds similar to those in real-world datasets. The proposed method involves two main steps, the first one is hidden surface removal (HSR), where the occluded parts of objects surfaces from the viewpoint of a camera are deleted. A low-complexity method has been proposed to implement HSR based on occupancy grids. The second step is a random sampling of the detected visible surfaces. The proposed two-step method is applied to a subset of ModelNet40 dataset to create a new dataset, which is then used to train and test three different deep-learning classifiers (VoxNet, PointNet, and 3DmFV). We studied classifiers performance as a function of the camera elevation angle. We also conducted another experiment to show how the newly generated data samples can improve the classification performance when they are combined with the original data during training process. Simulation results show that the proposed method enables us to create a large number of new data samples with a small size needed for storage. Results also show that the performance of classifiers is highly dependent on the elevation angle of the camera. In addition, there may exist some angles where performance degrades significantly. Furthermore, data augmentation using our created data improves the performance of classifiers not only when they are tested on the original data, but also on real data.},
  archive      = {J_FROBT},
  author       = {Syryamkin, Vladimir Ivanovich and Msallam, Majdi and Klestov, Semen Aleksandrovich},
  doi          = {10.3389/frobt.2022.1077895},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1077895},
  shortjournal = {Front. Robot. AI},
  title        = {A method to create real-like point clouds for 3D object classification},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast and optimal branch-and-bound planner for the grid-based
coverage path planning problem based on an admissible heuristic
function. <em>FROBT</em>, <em>9</em>, 1076897. (<a
href="https://doi.org/10.3389/frobt.2022.1076897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces an optimal algorithm for solving the discrete grid-based coverage path planning (CPP) problem. This problem consists in finding a path that covers a given region completely. First, we propose a CPP-solving baseline algorithm based on the iterative deepening depth-first search (ID-DFS) approach. Then, we introduce two branch-and-bound strategies (Loop detection and an Admissible heuristic function) to improve the results of our baseline algorithm. We evaluate the performance of our planner using six types of benchmark grids considered in this study: Coast-like, Random links, Random walk, Simple-shapes, Labyrinth and Wide-Labyrinth grids. We are first to consider these types of grids in the context of CPP. All of them find their practical applications in real-world CPP problems from a variety of fields. The obtained results suggest that the proposed branch-and-bound algorithm solves the problem optimally (i.e., the exact solution is found in each case) orders of magnitude faster than an exhaustive search CPP planner. To the best of our knowledge, no general CPP-solving exact algorithms, apart from an exhaustive search planner, have been proposed in the literature.},
  archive      = {J_FROBT},
  author       = {Champagne Gareau, Jaël and Beaudry, Éric and Makarenkov, Vladimir},
  doi          = {10.3389/frobt.2022.1076897},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1076897},
  shortjournal = {Front. Robot. AI},
  title        = {Fast and optimal branch-and-bound planner for the grid-based coverage path planning problem based on an admissible heuristic function},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using robot-assisted stiffness perturbations to evoke
aftereffects useful to post-stroke gait rehabilitation. <em>FROBT</em>,
<em>9</em>, 1073746. (<a
href="https://doi.org/10.3389/frobt.2022.1073746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stroke is a major global issue, affecting millions every year. When a stroke occurs, survivors are often left with physical disabilities or difficulties, frequently marked by abnormal gait. Post-stroke gait normally presents as one of or a combination of unilaterally shortened step length, decreased dorsiflexion during swing phase, and decreased walking speed. These factors lead to an increased chance of falling and an overall decrease in quality of life due to a reduced ability to locomote quickly and safely under one’s own power. Many current rehabilitation techniques fail to show lasting results that suggest the potential for producing permanent changes. As technology has advanced, robot-assisted rehabilitation appears to have a distinct advantage, as the precision and repeatability of such an intervention are not matched by conventional human-administered therapy. The possible role in gait rehabilitation of the Variable Stiffness Treadmill (VST), a unique, robotic treadmill, is further investigated in this paper. The VST is a split-belt treadmill that can reduce the vertical stiffness of one of the belts, while the other belt remains rigid. In this work, we show that the repeated unilateral stiffness perturbations created by this device elicit an aftereffect of increased step length that is seen for over 575 gait cycles with healthy subjects after a single 10-min intervention. These long aftereffects are currently unmatched in the literature according to our knowledge. This step length increase is accompanied by kinematics and muscle activity aftereffects that help explain functional changes and have their own independent value when considering the characteristics of post-stroke gait. These results suggest that repeated unilateral stiffness perturbations could possibly be a useful form of post-stroke gait rehabilitation.},
  archive      = {J_FROBT},
  author       = {Chambers, Vaughn and Artemiadis, Panagiotis},
  doi          = {10.3389/frobt.2022.1073746},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1073746},
  shortjournal = {Front. Robot. AI},
  title        = {Using robot-assisted stiffness perturbations to evoke aftereffects useful to post-stroke gait rehabilitation},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Assessment of movement disorders using wearable sensors
during upper limb tasks: A scoping review. <em>FROBT</em>, <em>9</em>,
1068413. (<a href="https://doi.org/10.3389/frobt.2022.1068413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Studies aiming to objectively quantify movement disorders during upper limb tasks using wearable sensors have recently increased, but there is a wide variety in described measurement and analyzing methods, hampering standardization of methods in research and clinics. Therefore, the primary objective of this review was to provide an overview of sensor set-up and type, included tasks, sensor features and methods used to quantify movement disorders during upper limb tasks in multiple pathological populations. The secondary objective was to identify the most sensitive sensor features for the detection and quantification of movement disorders on the one hand and to describe the clinical application of the proposed methods on the other hand.Methods: A literature search using Scopus, Web of Science, and PubMed was performed. Articles needed to meet following criteria: 1) participants were adults/children with a neurological disease, 2) (at least) one sensor was placed on the upper limb for evaluation of movement disorders during upper limb tasks, 3) comparisons between: groups with/without movement disorders, sensor features before/after intervention, or sensor features with a clinical scale for assessment of the movement disorder. 4) Outcome measures included sensor features from acceleration/angular velocity signals.Results: A total of 101 articles were included, of which 56 researched Parkinson’s Disease. Wrist(s), hand(s) and index finger(s) were the most popular sensor locations. Most frequent tasks were: finger tapping, wrist pro/supination, keeping the arms extended in front of the body and finger-to-nose. Most frequently calculated sensor features were mean, standard deviation, root-mean-square, ranges, skewness, kurtosis/entropy of acceleration and/or angular velocity, in combination with dominant frequencies/power of acceleration signals. Examples of clinical applications were automatization of a clinical scale or discrimination between a patient/control group or different patient groups.Conclusion: Current overview can support clinicians and researchers in selecting the most sensitive pathology-dependent sensor features and methodologies for detection and quantification of upper limb movement disorders and objective evaluations of treatment effects. Insights from Parkinson’s Disease studies can accelerate the development of wearable sensors protocols in the remaining pathologies, provided that there is sufficient attention for the standardisation of protocols, tasks, feasibility and data analysis methods.},
  archive      = {J_FROBT},
  author       = {Vanmechelen, Inti and Haberfehlner, Helga and De Vleeschhauwer, Joni and Van Wonterghem, Ellen and Feys, Hilde and Desloovere, Kaat and Aerts, Jean-Marie and Monbaliu, Elegast},
  doi          = {10.3389/frobt.2022.1068413},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1068413},
  shortjournal = {Front. Robot. AI},
  title        = {Assessment of movement disorders using wearable sensors during upper limb tasks: A scoping review},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sim-to-real via latent prediction: Transferring visual
non-prehensile manipulation policies. <em>FROBT</em>, <em>9</em>,
1067502. (<a href="https://doi.org/10.3389/frobt.2022.1067502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement Learning has been shown to have a great potential for robotics. It demonstrated the capability to solve complex manipulation and locomotion tasks, even by learning end-to-end policies that operate directly on visual input, removing the need for custom perception systems. However, for practical robotics applications, its scarce sample efficiency, the need for huge amounts of resources, data, and computation time can be an insurmountable obstacle. One potential solution to this sample efficiency issue is the use of simulated environments. However, the discrepancy in visual and physical characteristics between reality and simulation, namely the sim-to-real gap, often significantly reduces the real-world performance of policies trained within a simulator. In this work we propose a sim-to-real technique that trains a Soft-Actor Critic agent together with a decoupled feature extractor and a latent-space dynamics model. The decoupled nature of the method allows to independently perform the sim-to-real transfer of feature extractor and control policy, and the presence of the dynamics model acts as a constraint on the latent representation when finetuning the feature extractor on real-world data. We show how this architecture can allow the transfer of a trained agent from simulation to reality without retraining or finetuning the control policy, but using real-world data only for adapting the feature extractor. By avoiding training the control policy in the real domain we overcome the need to apply Reinforcement Learning on real-world data, instead, we only focus on the unsupervised training of the feature extractor, considerably reducing real-world experience collection requirements. We evaluate the method on sim-to-sim and sim-to-real transfer of a policy for table-top robotic object pushing. We demonstrate how the method is capable of adapting to considerable variations in the task observations, such as changes in point-of-view, colors, and lighting, all while substantially reducing the training time with respect to policies trained directly in the real.},
  archive      = {J_FROBT},
  author       = {Rizzardo, Carlo and Chen, Fei and Caldwell, Darwin},
  doi          = {10.3389/frobt.2022.1067502},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1067502},
  shortjournal = {Front. Robot. AI},
  title        = {Sim-to-real via latent prediction: Transferring visual non-prehensile manipulation policies},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The science of soft robot design: A review of motivations,
methods and enabling technologies. <em>FROBT</em>, <em>9</em>, 1059026.
(<a href="https://doi.org/10.3389/frobt.2022.1059026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Novel technologies, fabrication methods, controllers and computational methods are rapidly advancing the capabilities of soft robotics. This is creating the need for design techniques and methodologies that are suited for the multi-disciplinary nature of soft robotics. These are needed to provide a formalized and scientific approach to design. In this paper, we formalize the scientific questions driving soft robotic design; what motivates the design of soft robots, and what are the fundamental challenges when designing soft robots? We review current methods and approaches to soft robot design including bio-inspired design, computational design and human-driven design, and highlight the implications that each design methods has on the resulting soft robotic systems. To conclude, we provide an analysis of emerging methods which could assist robot design, and we present a review some of the necessary technologies that may enable these approaches.},
  archive      = {J_FROBT},
  author       = {Stella, Francesco and Hughes, Josie},
  doi          = {10.3389/frobt.2022.1059026},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1059026},
  shortjournal = {Front. Robot. AI},
  title        = {The science of soft robot design: A review of motivations, methods and enabling technologies},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vulcano: A new robotic challenge for legged robots.
<em>FROBT</em>, <em>9</em>, 1057832. (<a
href="https://doi.org/10.3389/frobt.2022.1057832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Vulcano challenge is a new and innovative robotic challenge for legged robots in a physical and simulated scenario of a volcanic eruption. In this scenario, robots must climb a volcano’s escarpment and collect data from areas with high temperatures and toxic gases. This paper presents the main idea behind this challenge, with a detailed description of the simulated and physical scenario of the volcano ramp, the rules proposed for the competition, and the conception of a robot prototype, Vulcano, used in the competition. Finally, it discusses the performance of teams invited to participate in the challenge in the context of Azorean Robotics Open, the Azoresbot 2022. This first test for this challenge provided insights into what the participants found exciting and positive and what they found less positive.},
  archive      = {J_FROBT},
  author       = {Domingos, Manuel and Pedro, Francisco and Ramos, Alberto and Funk, Matthias G. and Mendes, Armando and Cascalho, José},
  doi          = {10.3389/frobt.2022.1057832},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1057832},
  shortjournal = {Front. Robot. AI},
  title        = {Vulcano: A new robotic challenge for legged robots},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Energetic optimization of an autonomous mobile socially
assistive robot for autism spectrum disorder. <em>FROBT</em>,
<em>9</em>, 1053115. (<a
href="https://doi.org/10.3389/frobt.2022.1053115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The usage of socially assistive robots for autism therapies has increased in recent years. This novel therapeutic tool allows the specialist to keep track of the improvement in socially assistive tasks for autistic children, who hypothetically prefer object-based over human interactions. These kinds of tools also allow the collection of new information to early diagnose neurodevelopment disabilities. This work presents the integration of an output feedback adaptive controller for trajectory tracking and energetic autonomy of a mobile socially assistive robot for autism spectrum disorder under an event-driven control scheme. The proposed implementation integrates facial expression and emotion recognition algorithms to detect the emotions and identities of users (providing robustness to the algorithm since it automatically generates the missing input parameters, which allows it to complete the recognition) to detonate a set of adequate trajectories. The algorithmic implementation for the proposed socially assistive robot is presented and implemented in the Linux-based Robot Operating System. It is considered that the optimization of energetic consumption of the proposal is the main contribution of this work, as it will allow therapists to extend and adapt sessions with autistic children. The experiment that validates the energetic optimization of the proposed integration of an event-driven control scheme is presented.},
  archive      = {J_FROBT},
  author       = {Fuentes-Alvarez, Ruben and Morfin-Santana, Alejandro and Ibañez, Karlo and Chairez, Isaac and Salazar, Sergio},
  doi          = {10.3389/frobt.2022.1053115},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1053115},
  shortjournal = {Front. Robot. AI},
  title        = {Energetic optimization of an autonomous mobile socially assistive robot for autism spectrum disorder},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A data-driven approach for motion planning of industrial
robots controlled by high-level motion commands. <em>FROBT</em>,
<em>9</em>, 1030668. (<a
href="https://doi.org/10.3389/frobt.2022.1030668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most motion planners generate trajectories as low-level control inputs, such as joint torque or interpolation of joint angles, which cannot be deployed directly in most industrial robot control systems. Some industrial robot systems provide interfaces to execute planned trajectories by an additional control loop with low-level control inputs. However, there is a geometric and temporal deviation between the executed and the planned motions due to the inaccurate estimation of the inaccessible robot dynamic behavior and controller parameters in the planning phase. This deviation can lead to collisions or dangerous situations, especially in heavy-duty industrial robot applications where high-speed and long-distance motions are widely used. When deploying the planned robot motion, the actual robot motion needs to be iteratively checked and adjusted to avoid collisions caused by the deviation between the planned and the executed motions. This process takes a lot of time and engineering effort. Therefore, the state-of-the-art methods no longer meet the needs of today’s agile manufacturing for robotic systems that should rapidly plan and deploy new robot motions for different tasks. We present a data-driven motion planning approach using a neural network structure to simultaneously learn high-level motion commands and robot dynamics from acquired realistic collision-free trajectories. The trained neural network can generate trajectory in the form of high-level commands, such as Point-to-Point and Linear motion commands, which can be executed directly by the robot control system. The result carried out in various experimental scenarios has shown that the geometric and temporal deviation between the executed and the planned motions by the proposed approach has been significantly reduced, even if without access to the “black box” parameters of the robot. Furthermore, the proposed approach can generate new collision-free trajectories up to 10 times faster than benchmark motion planners.},
  archive      = {J_FROBT},
  author       = {Hou, Shuxiao and Bdiwi, Mohamad and Rashid, Aquib and Krusche, Sebastian and Ihlenfeldt, Steffen},
  doi          = {10.3389/frobt.2022.1030668},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1030668},
  shortjournal = {Front. Robot. AI},
  title        = {A data-driven approach for motion planning of industrial robots controlled by high-level motion commands},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robot tool use: A survey. <em>FROBT</em>, <em>9</em>,
1009488. (<a href="https://doi.org/10.3389/frobt.2022.1009488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using human tools can significantly benefit robots in many application domains. Such ability would allow robots to solve problems that they were unable to without tools. However, robot tool use is a challenging task. Tool use was initially considered to be the ability that distinguishes human beings from other animals. We identify three skills required for robot tool use: perception, manipulation, and high-level cognition skills. While both general manipulation tasks and tool use tasks require the same level of perception accuracy, there are unique manipulation and cognition challenges in robot tool use. In this survey, we first define robot tool use. The definition highlighted the skills required for robot tool use. The skills coincide with an affordance model which defined a three-way relation between actions, objects, and effects. We also compile a taxonomy of robot tool use with insights from animal tool use literature. Our definition and taxonomy lay a theoretical foundation for future robot tool use studies and also serve as practical guidelines for robot tool use applications. We first categorize tool use based on the context of the task. The contexts are highly similar for the same task (e.g., cutting) in non-causal tool use, while the contexts for causal tool use are diverse. We further categorize causal tool use based on the task complexity suggested in animal tool use studies into single-manipulation tool use and multiple-manipulation tool use. Single-manipulation tool use are sub-categorized based on tool features and prior experiences of tool use. This type of tool may be considered as building blocks of causal tool use. Multiple-manipulation tool use combines these building blocks in different ways. The different combinations categorize multiple-manipulation tool use. Moreover, we identify different skills required in each sub-type in the taxonomy. We then review previous studies on robot tool use based on the taxonomy and describe how the relations are learned in these studies. We conclude with a discussion of the current applications of robot tool use and open questions to address future robot tool use.},
  archive      = {J_FROBT},
  author       = {Qin, Meiying and Brawer, Jake and Scassellati, Brian},
  doi          = {10.3389/frobt.2022.1009488},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1009488},
  shortjournal = {Front. Robot. AI},
  title        = {Robot tool use: A survey},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Framework for environment perception: Ensemble method for
vision-based scene understanding algorithms in agriculture.
<em>FROBT</em>, <em>9</em>, 982581. (<a
href="https://doi.org/10.3389/frobt.2022.982581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The safe and reliable operation of autonomous agricultural vehicles requires an advanced environment perception system. An important component of perception systems is vision-based algorithms for detecting objects and other structures in the fields. This paper presents an ensemble method for combining outputs of three scene understanding tasks: semantic segmentation, object detection and anomaly detection in the agricultural context. The proposed framework uses an object detector to detect seven agriculture-specific classes. The anomaly detector detects all other objects that do not belong to these classes. In addition, the segmentation map of the field is utilized to provide additional information if the objects are located inside or outside the field area. The detections of different algorithms are combined at inference time, and the proposed ensemble method is independent of underlying algorithms. The results show that combining object detection with anomaly detection can increase the number of detected objects in agricultural scene images.},
  archive      = {J_FROBT},
  author       = {Mujkic, Esma and Ravn, Ole and Christiansen, Martin Peter},
  doi          = {10.3389/frobt.2022.982581},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {982581},
  shortjournal = {Front. Robot. AI},
  title        = {Framework for environment perception: Ensemble method for vision-based scene understanding algorithms in agriculture},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A neural flexible PID controller for task-space control of
robotic manipulators. <em>FROBT</em>, <em>9</em>, 975850. (<a
href="https://doi.org/10.3389/frobt.2022.975850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an adaptive robust Jacobian-based controller for task-space position-tracking control of robotic manipulators. Structure of the controller is built up on a traditional Proportional-Integral-Derivative (PID) framework. An additional neural control signal is next synthesized under a non-linear learning law to compensate for internal and external disturbances in the robot dynamics. To provide the strong robustness of such the controller, a new gain learning feature is then integrated to automatically adjust the PID gains for various working conditions. Stability of the closed-loop system is guaranteed by Lyapunov constraints. Effectiveness of the proposed controller is carefully verified by intensive simulation results.},
  archive      = {J_FROBT},
  author       = {Minh Nguyet, Nguyen Tran and Ba, Dang Xuan},
  doi          = {10.3389/frobt.2022.975850},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {975850},
  shortjournal = {Front. Robot. AI},
  title        = {A neural flexible PID controller for task-space control of robotic manipulators},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Leveraging explainability for understanding object
descriptions in ambiguous 3D environments. <em>FROBT</em>, <em>9</em>,
937772. (<a href="https://doi.org/10.3389/frobt.2022.937772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For effective human-robot collaboration, it is crucial for robots to understand requests from users perceiving the three-dimensional space and ask reasonable follow-up questions when there are ambiguities. While comprehending the users’ object descriptions in the requests, existing studies have focused on this challenge for limited object categories that can be detected or localized with existing object detection and localization modules. Further, they have mostly focused on comprehending the object descriptions using flat RGB images without considering the depth dimension. On the other hand, in the wild, it is impossible to limit the object categories that can be encountered during the interaction, and 3-dimensional space perception that includes depth information is fundamental in successful task completion. To understand described objects and resolve ambiguities in the wild, for the first time, we suggest a method leveraging explainability. Our method focuses on the active areas of an RGB scene to find the described objects without putting the previous constraints on object categories and natural language instructions. We further improve our method to identify the described objects considering depth dimension. We evaluate our method in varied real-world images and observe that the regions suggested by our method can help resolve ambiguities. When we compare our method with a state-of-the-art baseline, we show that our method performs better in scenes with ambiguous objects which cannot be recognized by existing object detectors. We also show that using depth features significantly improves performance in scenes where depth data is critical to disambiguate the objects and across our evaluation dataset that contains objects that can be specified with and without the depth dimension.},
  archive      = {J_FROBT},
  author       = {Doğan, Fethiye Irmak and Melsión, Gaspar I. and Leite, Iolanda},
  doi          = {10.3389/frobt.2022.937772},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {937772},
  shortjournal = {Front. Robot. AI},
  title        = {Leveraging explainability for understanding object descriptions in ambiguous 3D environments},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A study of error diversity in robotic swarms for task
partitioning in foraging tasks. <em>FROBT</em>, <em>9</em>, 904341. (<a
href="https://doi.org/10.3389/frobt.2022.904341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Often in swarm robotics, an assumption is made that all robots in the swarm behave the same and will have a similar (if not the same) error model. However, in reality, this is not the case, and this lack of uniformity in the error model, and other operations, can lead to various emergent behaviors. This paper considers the impact of the error model and compares robots in a swarm that operate using the same error model (uniform error) against each robot in the swarm having a different error model (thus introducing error diversity). Experiments are presented in the context of a foraging task. Simulation and physical experimental results show the importance of the error model and diversity in achieving the expected swarm behavior.},
  archive      = {J_FROBT},
  author       = {Buchanan, Edgar and Alden, Kieran and Pomfret, Andrew and Timmis, Jon and Tyrrell, Andy M.},
  doi          = {10.3389/frobt.2022.904341},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {904341},
  shortjournal = {Front. Robot. AI},
  title        = {A study of error diversity in robotic swarms for task partitioning in foraging tasks},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A method to benchmark the balance resilience of robots.
<em>FROBT</em>, <em>9</em>, 817870. (<a
href="https://doi.org/10.3389/frobt.2022.817870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots that work in unstructured scenarios are often subjected to collisions with the environment or external agents. Accordingly, recently, researchers focused on designing robust and resilient systems. This work presents a framework that quantitatively assesses the balancing resilience of self-stabilizing robots subjected to external perturbations. Our proposed framework consists of a set of novel Performance Indicators (PIs), experimental protocols for the reliable and repeatable measurement of the PIs, and a novel testbed to execute the protocols. The design of the testbed, the control structure, the post-processing software, and all the documentation related to the performance indicators and protocols are provided as open-source material so that other institutions can replicate the system. As an example of the application of our method, we report a set of experimental tests on a two-wheeled humanoid robot, with an experimental campaign of more than 1100 tests. The investigation demonstrates high repeatability and efficacy in executing reliable and precise perturbations.},
  archive      = {J_FROBT},
  author       = {Monteleone, Simone and Negrello, Francesca and Grioli, Giorgio and Catalano, Manuel G. and Bicchi, Antonio and Garabini, Manolo},
  doi          = {10.3389/frobt.2022.817870},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {817870},
  shortjournal = {Front. Robot. AI},
  title        = {A method to benchmark the balance resilience of robots},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ergonomic human-robot collaboration in industry: A review.
<em>FROBT</em>, <em>9</em>, 813907. (<a
href="https://doi.org/10.3389/frobt.2022.813907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current industrial context, the importance of assessing and improving workers’ health conditions is widely recognised. Both physical and psycho-social factors contribute to jeopardising the underlying comfort and well-being, boosting the occurrence of diseases and injuries, and affecting their quality of life. Human-robot interaction and collaboration frameworks stand out among the possible solutions to prevent and mitigate workplace risk factors. The increasingly advanced control strategies and planning schemes featured by collaborative robots have the potential to foster fruitful and efficient coordination during the execution of hybrid tasks, by meeting their human counterparts’ needs and limits. To this end, a thorough and comprehensive evaluation of an individual’s ergonomics, i.e. direct effect of workload on the human psycho-physical state, must be taken into account. In this review article, we provide an overview of the existing ergonomics assessment tools as well as the available monitoring technologies to drive and adapt a collaborative robot’s behaviour. Preliminary attempts of ergonomic human-robot collaboration frameworks are presented next, discussing state-of-the-art limitations and challenges. Future trends and promising themes are finally highlighted, aiming to promote safety, health, and equality in worldwide workplaces.},
  archive      = {J_FROBT},
  author       = {Lorenzini, Marta and Lagomarsino, Marta and Fortini, Luca and Gholami, Soheil and Ajoudani, Arash},
  doi          = {10.3389/frobt.2022.813907},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {813907},
  shortjournal = {Front. Robot. AI},
  title        = {Ergonomic human-robot collaboration in industry: A review},
  volume       = {9},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
