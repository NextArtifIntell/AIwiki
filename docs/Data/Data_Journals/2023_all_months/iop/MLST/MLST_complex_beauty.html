<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MLST_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="mlst---196">MLST - 196</h2>
<ul>
<li><details>
<summary>
(2023). FAIR AI models in high energy physics. <em>MLST</em>,
<em>4</em>(4), 045062. (<a
href="https://doi.org/10.1088/2632-2153/ad12e3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The findable, accessible, interoperable, and reusable (FAIR) data principles provide a framework for examining, evaluating, and improving how data is shared to facilitate scientific discovery. Generalizing these principles to research software and other digital products is an active area of research. Machine learning models—algorithms that have been trained on data without being explicitly programmed—and more generally, artificial intelligence (AI) models, are an important target for this because of the ever-increasing pace with which AI is transforming scientific domains, such as experimental high energy physics (HEP). In this paper, we propose a practical definition of FAIR principles for AI models in HEP and describe a template for the application of these principles. We demonstrate the template&#39;s use with an example AI model applied to HEP, in which a graph neural network is used to identify Higgs bosons decaying to two bottom quarks. We report on the robustness of this FAIR AI model, its portability across hardware architectures and software frameworks, and its interpretability.},
  archive      = {J_MLST},
  author       = {Javier Duarte and Haoyang Li and Avik Roy and Ruike Zhu and E A Huerta and Daniel Diaz and Philip Harris and Raghav Kansal and Daniel S Katz and Ishaan H Kavoori and Volodymyr V Kindratenko and Farouk Mokhtar and Mark S Neubauer and Sang Eon Park and Melissa Quinnan and Roger Rusack and Zhizhen Zhao},
  doi          = {10.1088/2632-2153/ad12e3},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045062},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {FAIR AI models in high energy physics},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring explainable AI: Category theory insights into
machine learning algorithms. <em>MLST</em>, <em>4</em>(4), 045061. (<a
href="https://doi.org/10.1088/2632-2153/ad1534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explainable artificial intelligence (XAI) is a growing field that aims to increase the transparency and interpretability of machine learning (ML) models. The aim of this work is to use the categorical properties of learning algorithms in conjunction with the categorical perspective of the information in the datasets to give a framework for explainability. In order to achieve this, we are going to define the enriched categories, with decorated morphisms, \pmb{\mathcal{Learn}} , \pmb{\mathcal{Para}} and \pmb{\mathcal{MNet}} of learners, parameterized functions, and neural networks over metric spaces respectively. The main idea is to encode information from the dataset via categorical methods, see how it propagates, and lastly, interpret the results thanks again to categorical (metric) information. This means that we can attach numerical (computable) information via enrichment to the structural information of the category. With this, we can translate theoretical information into parameters that are easily understandable. We will make use of different categories of enrichment to keep track of different kinds of information. That is, to see how differences in attributes of the data are modified by the algorithm to result in differences in the output to achieve better separation. In that way, the categorical framework gives us an algorithm to interpret what the learning algorithm is doing. Furthermore, since it is designed with generality in mind, it should be applicable in various different contexts. There are three main properties of category theory that help with the interpretability of ML models: formality, the existence of universal properties, and compositionality. The last property offers a way to combine smaller, simpler models that are easily understood to build larger ones. This is achieved by formally representing the structure of ML algorithms and information contained in the model. Finally, universal properties are a cornerstone of category theory. They help us characterize an object, not by its attributes, but by how it interacts with other objects. Thus, we can formally characterize an algorithm by how it interacts with the data. The main advantage of the framework is that it can unify under the same language different techniques used in XAI. Thus, using the same language and concepts we can describe a myriad of techniques and properties of ML algorithms, streamlining their explanation and making them easier to generalize and extrapolate.},
  archive      = {J_MLST},
  author       = {Ares Fabregat-Hernández and Javier Palanca and Vicent Botti},
  doi          = {10.1088/2632-2153/ad1534},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045061},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Exploring explainable AI: Category theory insights into machine learning algorithms},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Role of multifidelity data in sequential active learning
materials discovery campaigns: Case study of electronic bandgap.
<em>MLST</em>, <em>4</em>(4), 045060. (<a
href="https://doi.org/10.1088/2632-2153/ad1627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Materials discovery and design typically proceeds through iterative evaluation (both experimental and computational) to obtain data, generally targeting improvement of one or more properties under one or more constraints (e.g. time or budget). However, there can be great variation in the quality and cost of different data, and when they are mixed together in what we here call multifidelity data, the optimal approaches to their utilization are not established. It is therefore important to develop strategies to acquire and use multifidelity data to realize the most efficient iterative materials exploration. In this work, we assess the impact of using multifidelity data through mock demonstration of designing solar cell materials, using the electronic bandgap as the target property. We propose a new approach of using multifidelity data through leveraging machine learning models of both low- and high-fidelity data, where using predicted low-fidelity data as an input feature in the high-fidelity model can improve the impact of a multifidelity data approach. We show how tradeoffs of low- versus high-fidelity measurement cost and acquisition can impact the materials discovery process. We find that the use of multifidelity data has maximal impact on the materials discovery campaign when approximately five low-fidelity measurements per high-fidelity measurement are performed, and when the cost of low-fidelity measurements is approximately 5% or less than that of high-fidelity measurements. This work provides practical guidance and useful qualitative measures for improving materials discovery campaigns that involve multifidelity data.},
  archive      = {J_MLST},
  author       = {Ryan Jacobs and Philip E Goins and Dane Morgan},
  doi          = {10.1088/2632-2153/ad1627},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045060},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Role of multifidelity data in sequential active learning materials discovery campaigns: Case study of electronic bandgap},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MLGN: Multi-scale local-global feature learning network for
long-term series forecasting. <em>MLST</em>, <em>4</em>(4), 045059. (<a
href="https://doi.org/10.1088/2632-2153/ad1436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although Transformer-based methods have achieved remarkable performance in the field of long-term series forecasting, they can be computationally expensive and lack the ability to specifically model local features as CNNs. CNN-based methods, such as temporal convolutional network (TCN), utilize convolutional filters to capture local temporal features. However, the intermediate layers of TCN suffer from a limited effective receptive field, which can result in the loss of temporal relations during global feature extraction.To solve the above problems, we propose to combine local features and global correlations to capture the overall view of time series (e.g. fluctuations, trends). To fully exploit the underlying information in the time series, a multi-scale branch structure is adopted to model different potential patterns separately. Each pattern is extracted using a combination of interactive learning convolution and causal frequency enhancement to capture both local features and global correlations. Furthermore, our proposed method,multi-scale local-global feature learning network (MLGN), achieves a time and memory complexity of O ( L ) and consistently achieve state-of-the-art results on six benchmark datasets. In comparision with previous best method Fedformer, MLGN yields 12.98% and 11.38% relative improvements for multivariate and univariate time series, respectively. Our code and data are available on Github at https://github.com/Zero-coder/MLGN .},
  archive      = {J_MLST},
  author       = {Maowei Jiang and Kai Wang and Yue Sun and Wenbo Chen and Bingjie Xia and Ruiqi Li},
  doi          = {10.1088/2632-2153/ad1436},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045059},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {MLGN: Multi-scale local-global feature learning network for long-term series forecasting},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differentiable earth mover’s distance for data compression
at the high-luminosity LHC. <em>MLST</em>, <em>4</em>(4), 045058. (<a
href="https://doi.org/10.1088/2632-2153/ad1139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Earth mover&#39;s distance (EMD) is a useful metric for image recognition and classification, but its usual implementations are not differentiable or too slow to be used as a loss function for training other algorithms via gradient descent. In this paper, we train a convolutional neural network (CNN) to learn a differentiable, fast approximation of the EMD and demonstrate that it can be used as a substitute for computing-intensive EMD implementations. We apply this differentiable approximation in the training of an autoencoder-inspired neural network (encoder NN) for data compression at the high-luminosity LHC at CERN The goal of this encoder NN is to compress the data while preserving the information related to the distribution of energy deposits in particle detectors. We demonstrate that the performance of our encoder NN trained using the differentiable EMD CNN surpasses that of training with loss functions based on mean squared error.},
  archive      = {J_MLST},
  author       = {Rohan Shenoy and Javier Duarte and Christian Herwig and James Hirschauer and Daniel Noonan and Maurizio Pierini and Nhan Tran and Cristina Mantilla Suarez},
  doi          = {10.1088/2632-2153/ad1139},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045058},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Differentiable earth mover’s distance for data compression at the high-luminosity LHC},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). High-dimensional reinforcement learning for optimization and
control of ultracold quantum gases. <em>MLST</em>, <em>4</em>(4),
045057. (<a href="https://doi.org/10.1088/2632-2153/ad1437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine-learning (ML) techniques are emerging as a valuable tool in experimental physics, and among them, reinforcement learning (RL) offers the potential to control high-dimensional, multistage processes in the presence of fluctuating environments. In this experimental work, we apply RL to the preparation of an ultracold quantum gas to realize a consistent and large number of atoms at microkelvin temperatures. This RL agent determines an optimal set of 30 control parameters in a dynamically changing environment that is characterized by 30 sensed parameters. By comparing this method to that of training supervised-learning regression models, as well as to human-driven control schemes, we find that both ML approaches accurately predict the number of cooled atoms and both result in occasional superhuman control schemes. However, only the RL method achieves consistent outcomes, even in the presence of a dynamic environment.},
  archive      = {J_MLST},
  author       = {N Milson and A Tashchilina and T Ooi and A Czarnecka and Z F Ahmad and L J LeBlanc},
  doi          = {10.1088/2632-2153/ad1437},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045057},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {High-dimensional reinforcement learning for optimization and control of ultracold quantum gases},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bayesian experimental design and parameter estimation for
ultrafast spin dynamics. <em>MLST</em>, <em>4</em>(4), 045056. (<a
href="https://doi.org/10.1088/2632-2153/ad113a">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced experimental measurements are crucial for driving theoretical developments and unveiling novel phenomena in condensed matter and materials physics, which often suffer from the scarcity of large-scale facility resources, such as x-ray or neutron scattering centers. To address these limitations, we introduce a methodology that leverages the Bayesian optimal experimental design paradigm to efficiently uncover key quantum spin fluctuation parameters from x-ray photon fluctuation spectroscopy (XPFS) data. Our method is compatible with existing theoretical simulation pipelines and can also be used in combination with fast machine learning surrogate models in the event that real-time simulations are unfeasible. Our numerical benchmarks demonstrate the superior performance in predicting model parameters and in delivering more informative measurements within limited experimental time. Our method can be adapted to many different types of experiments beyond XPFS and spin fluctuation studies, facilitating more efficient data collection and accelerating scientific discoveries.},
  archive      = {J_MLST},
  author       = {Zhantao Chen and Cheng Peng and Alexander N Petsch and Sathya R Chitturi and Alana Okullo and Sugata Chowdhury and Chun Hong Yoon and Joshua J Turner},
  doi          = {10.1088/2632-2153/ad113a},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045056},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Bayesian experimental design and parameter estimation for ultrafast spin dynamics},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Physics-enhanced neural networks for equation-of-state
calculations. <em>MLST</em>, <em>4</em>(4), 045055. (<a
href="https://doi.org/10.1088/2632-2153/ad13b9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid access to accurate equation-of-state (EOS) data is crucial in the warm-dense matter (WDM) regime, as it is employed in various applications, such as providing input for hydrodynamic codes to model inertial confinement fusion processes. In this study, we develop neural network models for predicting the EOS based on first-principles data. The first model utilises basic physical properties, while the second model incorporates more sophisticated physical information, using output from average-atom (AA) calculations as features. AA models are often noted for providing a reasonable balance of accuracy and speed; however, our comparison of AA models and higher-fidelity calculations shows that more accurate models are required in the WDM regime. Both the neural network models we propose, particularly the physics-enhanced one, demonstrate significant potential as accurate and efficient methods for computing EOS data in WDM.},
  archive      = {J_MLST},
  author       = {Timothy J Callow and Jan Nikl and Eli Kraisler and Attila Cangi},
  doi          = {10.1088/2632-2153/ad13b9},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045055},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Physics-enhanced neural networks for equation-of-state calculations},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel multi-layer modular approach for real-time
fuzzy-identification of gravitational-wave signals. <em>MLST</em>,
<em>4</em>(4), 045054. (<a
href="https://doi.org/10.1088/2632-2153/ad1200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced LIGO and Advanced Virgo ground-based interferometers are instruments capable to detect gravitational wave (GW) signals exploiting advanced laser interferometry techniques. The underlying data analysis task consists in identifying specific patterns in noisy timeseries, but it is made extremely complex by the incredibly small amplitude of the target signals. In this scenario, the development of effective GW detection algorithms is crucial. We propose a novel layered framework for real-time detection of GWs inspired by speech processing techniques and, in the present implementation, based on a state-of-the-art machine learning approach involving a hybridization of genetic programming and neural networks. The key aspects of the newly proposed framework are: the well structured, layered approach, and the low computational complexity. The paper describes the basic concepts of the framework and the derivation of the first three layers. Even if, in the present implementation, the layers are based on models derived using a machine learning approach, the proposed layered structure has a universal nature. Compared to more complex approaches, such as convolutional neural networks, which comprise a parameter set of several tens of MB and were tested exclusively for fixed length data samples, our framework has lower accuracy (e.g. it identifies 45\% of low signal-to-noise-ration GW signals, against 65\% of the state-of-the-art, at a false alarm probability of 10 −2 ), but has a much lower computational complexity (it exploits only 4 numerical features in the present implementation) and a higher degree of modularity. Furthermore, the exploitation of short-term features makes the results of the new framework virtually independent against time-position of GW signals, simplifying its future exploitation in real-time multi-layer pipelines for gravitational-wave detection with new generation interferometers.},
  archive      = {J_MLST},
  author       = {Francesco Pio Barone and Daniele Dell’Aquila and Marco Russo},
  doi          = {10.1088/2632-2153/ad1200},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045054},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A novel multi-layer modular approach for real-time fuzzy-identification of gravitational-wave signals},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using random forest for brain tissue identification by raman
spectroscopy. <em>MLST</em>, <em>4</em>(4), 045053. (<a
href="https://doi.org/10.1088/2632-2153/ad1349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional definitive diagnosis of brain tumors is performed by needle biopsy under the guidance of imaging-based exams. This paradigm is based on the experience of radiogolists, and accuracy could be affected by uncertainty in imaging interpretation and needle placement. Raman spectroscopy has the potential to improve needle biopsy by providing fingerprints of different materials and performing in situ tissue identification. In this paper, we present the development of a supervised machine learning algorithm using random forest (RF) to distinguish the Raman spectrum of different types of tissue. An integral process from raw data collection and preprocessing to model training and evaluation is presented. To illustrate the feasibility of this approach, viable animal tissues were used, including ectocinerea (grey matter), alba (white matter) and blood vessels. Raman spectra were acquired using a custom-built Raman spectrometer. The hyperparameters of the RF model were determined by combining a cross-validation-based algorithm and manually adjusting. The experimental results show the ability of our approach to discriminate different types of tissues with high accuracy.},
  archive      = {J_MLST},
  author       = {Weiyi Zhang and Chau Minh Giang and Qingan Cai and Behnam Badie and Jun Sheng and Chen Li},
  doi          = {10.1088/2632-2153/ad1349},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045053},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Using random forest for brain tissue identification by raman spectroscopy},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A finite element-convolutional neural network model (FE-CNN)
for stress field analysis around arbitrary inclusions. <em>MLST</em>,
<em>4</em>(4), 045052. (<a
href="https://doi.org/10.1088/2632-2153/ad134a">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a data-driven finite element-machine learning surrogate model for predicting the end-to-end full-field stress distribution and stress concentration around an arbitrary-shaped inclusion. This is important because the model&#39;s capacity to handle large datasets, consider variations in size and shape, and accurately replicate stress fields makes it a valuable tool for studying how inclusion characteristics affect material performance. An automatized dataset generation method using finite element simulation is proposed, validated, and used for attaining a dataset with one thousand inclusion shapes motivated by experimental observations and their corresponding spatially-varying stress distributions. A U-Net-based convolutional neural network (CNN) is trained using the dataset, and its performance is evaluated through quantitative and qualitative comparisons. The dataset, consisting of these stress data arrays, is directly fed into the CNN model for training and evaluation. This approach bypasses the need for converting the stress data into image format, allowing for a more direct and efficient input representation for the CNN. The model was evaluated through a series of sensitivity analyses, focusing on the impact of dataset size and model resolution on accuracy and performance. The results demonstrated that increasing the dataset size significantly improved the model&#39;s prediction accuracy, as indicated by the correlation values. Additionally, the investigation into the effect of model resolution revealed that higher resolutions led to better stress field predictions and reduced error. Overall, the surrogate model proved effective in accurately predicting the effective stress concentration in inclusions, showcasing its potential in practical applications requiring stress analysis such as structural engineering, material design, failure analysis, and multi-scale modeling.},
  archive      = {J_MLST},
  author       = {Mohammad Rezasefat and James D Hogan},
  doi          = {10.1088/2632-2153/ad134a},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045052},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A finite element-convolutional neural network model (FE-CNN) for stress field analysis around arbitrary inclusions},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scalable quantum measurement error mitigation via
conditional independence and transfer learning. <em>MLST</em>,
<em>4</em>(4), 045051. (<a
href="https://doi.org/10.1088/2632-2153/ad1007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mitigating measurement errors in quantum systems without relying on quantum error correction is of critical importance for the practical development of quantum technology. Deep learning-based quantum measurement error mitigation (QMEM) has exhibited advantages over the linear inversion method due to its capability to correct non-linear noise. However, scalability remains a challenge for both methods. In this study, we propose a scalable QMEM method that leverages the conditional independence (CI) of distant qubits and incorporates transfer learning (TL) techniques. By leveraging the CI assumption, we achieve an exponential reduction in the size of neural networks used for error mitigation. This enhancement also offers the benefit of reducing the number of training data needed for the machine learning model to successfully converge. Additionally, incorporating TL provides a constant speedup. We validate the effectiveness of our approach through experiments conducted on IBM quantum devices with 7 and 13 qubits, demonstrating excellent error mitigation performance and highlighting the efficiency of our method.},
  archive      = {J_MLST},
  author       = {Changwon Lee and Daniel K Park},
  doi          = {10.1088/2632-2153/ad1007},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045051},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Scalable quantum measurement error mitigation via conditional independence and transfer learning},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rescuing off-equilibrium simulation data through dynamic
experimental data with dynAMMo. <em>MLST</em>, <em>4</em>(4), 045050.
(<a href="https://doi.org/10.1088/2632-2153/ad10ce">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-timescale behavior of proteins is fundamental to many biological processes. Molecular dynamics (MD) simulations and biophysical experiments are often used to study protein dynamics. However, high computational demands of MD limit what timescales are feasible to study, often missing rare events, which are critical to explain experiments. On the other hand, experiments are limited by low resolution. We present dynamic augmented Markov models (dynAMMo) to bridge the gap between these data and overcome their respective limitations. For the first time, dynAMMo enables the construction of mechanistic models of slow exchange processes that have been not observed in MD data by integrating dynamic experimental observables. As a consequence, dynAMMo allows us to bypass costly and extensive simulations, yet providing mechanistic insights of the system. Validated with controlled model systems and a well-studied protein, dynAMMo offers a new approach to quantitatively model protein dynamics on long timescales in an unprecedented manner.},
  archive      = {J_MLST},
  author       = {Christopher Kolloff and Simon Olsson},
  doi          = {10.1088/2632-2153/ad10ce},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045050},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Rescuing off-equilibrium simulation data through dynamic experimental data with dynAMMo},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parameter-free basis allocation for efficient multiple
metric learning. <em>MLST</em>, <em>4</em>(4), 045049. (<a
href="https://doi.org/10.1088/2632-2153/ad113b">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metric learning involves learning a metric function for distance measurement, which plays an important role in improving the performance of classification or similarity-based algorithms. Multiple metric learning is essential for efficiently reflecting the local properties between instances, as single metric learning has limitations in reflecting the nonlinear structure of complex datasets. Previous research has proposed a method for learning a smooth metric matrix function through data manifold to address the challenge of independently learning multiple metrics. However, this method uses the basic distance-based clustering algorithm to set the anchor points, which are the basis for local metric learning, and the number of basis metrics is dependent on the user. We propose a new method that can assign sophisticated anchor points by iteratively partitioning to identify mixed clusters of multi-class instances and cluster the most similar class instances together. In an experiment, we demonstrate the reliability of the automatically set parameter by comparison with the distribution of error rates according to the number of basis metrics of the existing algorithm. Furthermore, we show the superior performance of the proposed method over a fixed parameter setting of existing algorithms and confirm the relative classification accuracy superiority through performance comparison with baseline algorithms.},
  archive      = {J_MLST},
  author       = {Dongyeon Kim and Yejin Kan and Seungmin Lee and Gangman Yi},
  doi          = {10.1088/2632-2153/ad113b},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045049},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Parameter-free basis allocation for efficient multiple metric learning},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application of kernel principal component analysis for
optical vector atomic magnetometry. <em>MLST</em>, <em>4</em>(4),
045048. (<a href="https://doi.org/10.1088/2632-2153/ad0fa4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vector atomic magnetometers that incorporate electromagnetically induced transparency (EIT) allow for precision measurements of magnetic fields that are sensitive to the directionality of the observed field by virtue of fundamental physics. However, a practical methodology of accurately recovering the longitudinal angle of the local field through observations of EIT spectra has not been established. In this work, we address this problem of angle determination with an unsupervised machine learning algorithm utilizing nonlinear dimensionality reduction. The proposed algorithm was developed to interface with spectroscopic measurements from an EIT-based atomic rubidium magnetometer and uses kernel principal component analysis (KPCA) as an unsupervised feature extraction tool. The resulting KPCA features allow each EIT spectrum measurement to be represented by a single coordinate in a new reduced dimensional feature space, thereby streamlining the process of angle determination. A supervised support vector regression (SVR) machine was implemented to model the resulting relationship between the KPCA projections and field direction. If the magnetometer is configured so that the azimuthal angle of the field is defined with a polarization lock, the KPCA-SVR algorithm is capable of predicting the longitudinal angle of the local magnetic field within 1 degree of accuracy and the magnitude of the absolute field with a resolution of 70 nT. The combined scalar and angular sensitivity of this method make the KPCA-enabled EIT magnetometer competitive with conventional vector magnetometry methods. © 2023. All rights reserved.},
  archive      = {J_MLST},
  author       = {James A McKelvy and Irina Novikova and Eugeniy E Mikhailov and Mario A Maldonado and Isaac Fan and Yang Li and Ying-Ju Wang and John Kitching and Andrey B Matsko},
  doi          = {10.1088/2632-2153/ad0fa4},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045048},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Application of kernel principal component analysis for optical vector atomic magnetometry},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Breast cancer diagnosis through knowledge distillation of
swin transformer-based teacher–student models. <em>MLST</em>,
<em>4</em>(4), 045047. (<a
href="https://doi.org/10.1088/2632-2153/ad10cc">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is a significant global health concern, emphasizing the crucial need for a timely and accurate diagnosis to enhance survival rates. Traditional diagnostic methods rely on pathologists analyzing whole-slide images (WSIs) to identify and diagnose malignancies. However, this task is complex, demanding specialized expertise and imposing a substantial workload on pathologists. Additionally, existing deep learning models, commonly employed for classifying histopathology images, often need enhancements to ensure their suitability for real-time deployment on WSI, especially when trained for small regions of interest (ROIs). This article introduces two Swin transformer-based architectures: the teacher model, characterized by its moderate size, and the lightweight student model. Both models are trained using a publicly available dataset of breast cancer histopathology images, focusing on ROIs with varying magnification factors. Transfer learning is applied to train the teacher model, and knowledge distillation (KD) transfers its capabilities to the student model. To enhance validation accuracy and minimize the total loss in KD, we employ the state–action–reward–state–action (SARSA) reinforcement learning algorithm. The algorithm dynamically computes temperature and a weighting factor throughout the KD process to achieve high accuracy within a considerably shorter training timeframe. Additionally, the student model is deployed to analyze malignancies in WSI. Despite the student model being only one-third the size and flops of the teacher model, it achieves an impressive accuracy of 98.71%, slightly below the teacher&#39;s accuracy of 98.91%. Experimental results demonstrate that the student model can process WSIs at a throughput of 1.67 samples s −1 with an accuracy of 82%. The proposed student model, trained using KD and the SARSA algorithm, exhibits promising breast cancer classification and WSI analysis performance. These findings indicate its potential for assisting pathologists in diagnosing breast cancer accurately and effectively.},
  archive      = {J_MLST},
  author       = {Bhavannarayanna Kolla and Venugopal P},
  doi          = {10.1088/2632-2153/ad10cc},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045047},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Breast cancer diagnosis through knowledge distillation of swin transformer-based teacher–student models},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning for enhanced free-space optical
communications. <em>MLST</em>, <em>4</em>(4), 045046. (<a
href="https://doi.org/10.1088/2632-2153/ad10cd">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Atmospheric effects, such as turbulence and background thermal noise, inhibit the propagation of light used in ON–OFF keying (OOK) free-space optical (FSO) communication. Here we present and experimentally validate a convolutional neural network (CNN) to reduce the bit error rate of FSO communication in post-processing that is significantly simpler and cheaper than existing solutions based on advanced optics. Our approach consists of two neural networks, the first determining the presence of bit sequences in thermal noise and turbulence and the second demodulating the bit sequences. All data used for training and testing our network is obtained experimentally by generating OOK bit streams, combining these with thermal light, and passing the resultant light through a turbulent water tank which we have verified mimics turbulence in the air to a high degree of accuracy. Our CNN improves detection accuracy over threshold classification schemes and has the capability to be integrated with current demodulation and error correction schemes.},
  archive      = {J_MLST},
  author       = {M P Bart and N J Savino and P Regmi and L Cohen and H Safavi and H C Shaw and S Lohani and T A Searles and B T Kirby and H Lee and R T Glasser},
  doi          = {10.1088/2632-2153/ad10cd},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045046},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Deep learning for enhanced free-space optical communications},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GA-based weighted ensemble learning for multi-label aerial
image classification using convolutional neural networks and vision
transformers. <em>MLST</em>, <em>4</em>(4), 045045. (<a
href="https://doi.org/10.1088/2632-2153/ad10cf">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label classification (MLC) of aerial images is a crucial task in remote sensing image analysis. Traditional image classification methods have limitations in image feature extraction, leading to an increasing use of deep learning models, such as convolutional neural networks (CNN) and vision transformers (ViT). However, the standalone use of these models may have limitations when dealing with MLC. To enhance the generalization performance of MLC of aerial images, this paper combines two CNN and two ViT models, comparing four single deep learning models, a manually weighted ensemble learning method, and a GA-based weighted ensemble method. The experimental results using two public multi-label aerial image datasets show that the classification performance of ViT models is better than CNN models, the traditional weighted ensemble learning model performs better than a single deep learning model, and the GA-based weighted ensemble method performs better than the manually weighted ensemble learning method. The GA-based weighted ensemble method proposed in this study can achieve better MLC performance of aerial images than previous results.},
  archive      = {J_MLST},
  author       = {Ming-Hseng Tseng},
  doi          = {10.1088/2632-2153/ad10cf},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045045},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {GA-based weighted ensemble learning for multi-label aerial image classification using convolutional neural networks and vision transformers},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning of microscopic structure-dynamics
relationships in complex molecular systems. <em>MLST</em>,
<em>4</em>(4), 045044. (<a
href="https://doi.org/10.1088/2632-2153/ad0fa5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many complex molecular systems, the macroscopic ensemble&#39;s properties are controlled by microscopic dynamic events (or fluctuations) that are often difficult to detect via pattern-recognition approaches. Discovering the relationships between local structural environments and the dynamical events originating from them would allow unveiling microscopic-level structure-dynamics relationships fundamental to understand the macroscopic behavior of complex systems. Here we show that, by coupling advanced structural (e.g. Smooth Overlap of Atomic Positions, SOAP) with local dynamical descriptors (e.g. Local Environment and Neighbor Shuffling, LENS) in a unique dataset, it is possible to improve both individual SOAP- and LENS-based analyses, obtaining a more complete characterization of the system under study. As representative examples, we use various molecular systems with diverse internal structural dynamics. On the one hand, we demonstrate how the combination of structural and dynamical descriptors facilitates decoupling relevant dynamical fluctuations from noise, overcoming the intrinsic limits of the individual analyses. Furthermore, machine learning approaches also allow extracting from such combined structural/dynamical dataset useful microscopic-level relationships, relating key local dynamical events (e.g. LENS fluctuations) occurring in the systems to the local structural (SOAP) environments they originate from. Given its abstract nature, we believe that such an approach will be useful in revealing hidden microscopic structure-dynamics relationships fundamental to rationalize the behavior of a variety of complex systems, not necessarily limited to the atomistic and molecular scales.},
  archive      = {J_MLST},
  author       = {Martina Crippa and Annalisa Cardellini and Matteo Cioni and Gábor Csányi and Giovanni M Pavan},
  doi          = {10.1088/2632-2153/ad0fa5},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045044},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Machine learning of microscopic structure-dynamics relationships in complex molecular systems},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved decision making with similarity based machine
learning: Applications in chemistry. <em>MLST</em>, <em>4</em>(4),
045043. (<a href="https://doi.org/10.1088/2632-2153/ad0fa3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the fundamental progress in autonomous molecular and materials discovery, data scarcity throughout chemical compound space still severely hampers the use of modern ready-made machine learning models as they rely heavily on the paradigm, &#39;the bigger the data the better&#39;. Presenting similarity based machine learning (SML), we show an approach to select data and train a model on-the-fly for specific queries, enabling decision making in data scarce scenarios in chemistry. By solely relying on query and training data proximity to choose training points, only a fraction of data is necessary to converge to competitive performance. After introducing SML for the harmonic oscillator and the Rosenbrock function, we describe applications to scarce data scenarios in chemistry which include quantum mechanics based molecular design and organic synthesis planning. Finally, we derive a relationship between the intrinsic dimensionality and volume of feature space, governing the overall model accuracy.},
  archive      = {J_MLST},
  author       = {Dominik Lemm and Guido Falk von Rudorff and O Anatole von Lilienfeld},
  doi          = {10.1088/2632-2153/ad0fa3},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045043},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Improved decision making with similarity based machine learning: Applications in chemistry},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Harnessing data augmentation to quantify uncertainty in the
early estimation of single-photon source quality. <em>MLST</em>,
<em>4</em>(4), 045042. (<a
href="https://doi.org/10.1088/2632-2153/ad0d11">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Novel methods for rapidly estimating single-photon source (SPS) quality have been promoted in recent literature to address the expensive and time-consuming nature of experimental validation via intensity interferometry. However, the frequent lack of uncertainty discussions and reproducible details raises concerns about their reliability. This study investigates the use of data augmentation, a machine learning technique, to supplement experimental data with bootstrapped samples and quantify the uncertainty of such estimates. Eight datasets obtained from measurements involving a single InGaAs/GaAs epitaxial quantum dot serve as a proof-of-principle example. Analysis of one of the SPS quality metrics derived from efficient histogram fitting of the synthetic samples, i.e. the probability of multi-photon emission events, reveals significant uncertainty contributed by stochastic variability in the Poisson processes that describe detection rates. Ignoring this source of error risks severe overconfidence in both early quality estimates and claims for state-of-the-art SPS devices. Additionally, this study finds that standard least-squares fitting is comparable to using a Poisson likelihood, and expanding averages show some promise for early estimation. Also, reducing background counts improves fitting accuracy but does not address the Poisson-process variability. Ultimately, data augmentation demonstrates its value in supplementing physical experiments; its benefit here is to emphasise the need for a cautious assessment of SPS quality.},
  archive      = {J_MLST},
  author       = {David Jacob Kedziora and Anna Musiał and Wojciech Rudno-Rudziński and Bogdan Gabrys},
  doi          = {10.1088/2632-2153/ad0d11},
  journal      = {Machine Learning: Science and Technology},
  month        = {12},
  number       = {4},
  pages        = {045042},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Harnessing data augmentation to quantify uncertainty in the early estimation of single-photon source quality},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent processing of electromagnetic data using
detrended and identification. <em>MLST</em>, <em>4</em>(4), 045041. (<a
href="https://doi.org/10.1088/2632-2153/ad0c40">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of the electromagnetic method has accelerated due to the demand for the development of mineral resource, however the strong electromagnetic interference seriously lowers the data quality, resolution and detect effect. To suppress the electromagnetic interference, this paper proposes an intelligent processing method based on detrended and identification, and applies for wide field electromagnetic method (WFEM) data. First, we combined the improved intrinsic time scale decomposition and detrended fluctuation analysis algorithm for removing the trend noise. Then, we extracted the time domain characteristics of the WFEM data after removing the trend noise. Next, the arithmetic optimization algorithm was utilized to search for the optimal smoothing factor of the probabilistic neural network (PNN) algorithm, which realized to intelligently identify the noise data and WFEM effective data. Finally, the Fourier transform was performed to extract the spectrum amplitude of the effective frequency points from the reconstructed WFEM data, and the electric field curve was obtained. In these studies and applications, the fuzzy c-mean and PNN algorithm are contrasted. The proposed method indicated that the trend noise can be adaptively extracted and eliminated, the abnormal waveform or noise interference can be intelligently identified, the reconstructed WFEM data can effectively recover the pseudo-random signal waveform, and the shape of electric field curves were more stable. Simulation experiments and measured applications has verified that the proposed method can provide technical support for deep underground exploration.},
  archive      = {J_MLST},
  author       = {Xian Zhang and Diquan Li and Bei Liu and Yanfang Hu and Yao Mo},
  doi          = {10.1088/2632-2153/ad0c40},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045041},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Intelligent processing of electromagnetic data using detrended and identification},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast neural network inference on FPGAs for triggering on
long-lived particles at colliders. <em>MLST</em>, <em>4</em>(4), 045040.
(<a href="https://doi.org/10.1088/2632-2153/ad087a">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experimental particle physics demands a sophisticated trigger and acquisition system capable to efficiently retain the collisions of interest for further investigation. Heterogeneous computing with the employment of FPGA cards may emerge as a trending technology for the triggering strategy of the upcoming high-luminosity program of the Large Hadron Collider at CERN In this context, we present two machine-learning algorithms for selecting events where neutral long-lived particles decay within the detector volume studying their accuracy and inference time when accelerated on commercially available Xilinx FPGA accelerator cards. The inference time is also confronted with a CPU- and GPU-based hardware setup. The proposed new algorithms are proven efficient for the considered benchmark physics scenario and their accuracy is found to not degrade when accelerated on the FPGA cards. The results indicate that all tested architectures fit within the latency requirements of a second-level trigger farm and that exploiting accelerator technologies for real-time processing of particle-physics collisions is a promising research field that deserves additional investigations, in particular with machine-learning models with a large number of trainable parameters.},
  archive      = {J_MLST},
  author       = {Andrea Coccaro and Francesco Armando Di Bello and Stefano Giagu and Lucrezia Rambelli and Nicola Stocchetti},
  doi          = {10.1088/2632-2153/ad087a},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045040},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Fast neural network inference on FPGAs for triggering on long-lived particles at colliders},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligent identification of apatite fission
tracks based on machine learning. <em>MLST</em>, <em>4</em>(4), 045039.
(<a href="https://doi.org/10.1088/2632-2153/ad0e17">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past half century, apatite fission track (AFT) thermochronometry has been widely used in the studies of thermal histories of Earth&#39;s uppermost crust. The acquired thermal histories in turn can be used to quantify many geologic processes such as erosion, sedimentary burial, and tectonic deformation. However, the current practice of acquiring AFT data has major limitations due to the use of traditional microscopes by human operators, which is slow and error-prone. This study uses the local binary pattern feature based on the OpenCV cascade classifier and the faster region-based convolutional neural network model based on the TensorFlow Object Detection API, these two methods offer a means for the rapid identification and measurement of apatite fission tracks, leading to significant improvements in the efficiency and accuracy of track counting. We employed a training dataset consisting of 50 spontaneous fission track images and 65 Durango standard samples as training data for both techniques. Subsequently, the performance of these methods was evaluated using additional 10 spontaneous fission track images and 15 Durango standard samples, which resulted in higher Precision, Recall, and F1-Score values. Through these illustrative examples, we have effectively demonstrated the higher accuracy of these newly developed methods in identifying apatite fission tracks. This suggests their potential for widespread applications in future apatite fission track research.},
  archive      = {J_MLST},
  author       = {Zuoting Ren and Shichao Li and Perry Xiao and Xiaopeng Yang and Hongtao Wang},
  doi          = {10.1088/2632-2153/ad0e17},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045039},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Artificial intelligent identification of apatite fission tracks based on machine learning},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Time-warping invariant quantum recurrent neural networks via
quantum-classical adaptive gating. <em>MLST</em>, <em>4</em>(4), 045038.
(<a href="https://doi.org/10.1088/2632-2153/acff39">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive gating plays a key role in temporal data processing via classical recurrent neural networks (RNNs), as it facilitates retention of past information necessary to predict the future, providing a mechanism that preserves invariance to time warping transformations. This paper builds on quantum RNNs (QRNNs), a dynamic model with quantum memory, to introduce a novel class of temporal data processing quantum models that preserve invariance to time-warping transformations of the (classical) input-output sequences. The model, referred to as time warping-invariant QRNN (TWI-QRNN) , augments a QRNN with a quantum–classical adaptive gating mechanism that chooses whether to apply a parameterized unitary transformation at each time step as a function of the past samples of the input sequence via a classical recurrent model. The TWI-QRNN model class is derived from first principles, and its capacity to successfully implement time-warping transformations is experimentally demonstrated on examples with classical or quantum dynamics.},
  archive      = {J_MLST},
  author       = {Ivana Nikoloska and Osvaldo Simeone and Leonardo Banchi and Petar Veličković},
  doi          = {10.1088/2632-2153/acff39},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045038},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Time-warping invariant quantum recurrent neural networks via quantum-classical adaptive gating},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph machine learning framework for depicting wavefunction
on interface. <em>MLST</em>, <em>4</em>(4), 045037. (<a
href="https://doi.org/10.1088/2632-2153/ad0937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The wavefunction, as the basic hypothesis of quantum mechanics, describes the motion of particles and plays a pivotal role in determining physical properties at the atomic scale. However, its conventional acquisition method, such as density functional theory, requires a considerable amount of calculation, which brings numerous problems to wide application. Here, we propose an algorithmic framework based on graph neural network to machine-learn the wavefunction of electrons. This framework primarily generates atomic features containing information about chemical environment and geometric structure and subsequently constructs a scalable distribution map. For the first time, the visualization of wavefunction of interface is realized by machine learning methods, bypassing complex calculation and obscure comprehension. In this way, we vividly illustrate quantum mechanics, which can inspire theoretical exploration. As an intriguing case to verify the ability of our method, a novel quantum confinement phenomenon on interfaces based on graphene nanoribbon is uncovered. We believe that the versatility of this framework paves the way for swiftly linking quantum physics and atom-level structures.},
  archive      = {J_MLST},
  author       = {Ao Wu and Li Liu and Zifeng Wang and Shurong Pan and Jiangxue Huang and Qijun Huang and Jin He and Hao Wang and Sheng Chang},
  doi          = {10.1088/2632-2153/ad0937},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045037},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Graph machine learning framework for depicting wavefunction on interface},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Set-conditional set generation for particle physics.
<em>MLST</em>, <em>4</em>(4), 045036. (<a
href="https://doi.org/10.1088/2632-2153/ad035b">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The simulation of particle physics data is a fundamental but computationally intensive ingredient for physics analysis at the large Hadron collider, where observational set-valued data is generated conditional on a set of incoming particles. To accelerate this task, we present a novel generative model based on a graph neural network and slot-attention components, which exceeds the performance of pre-existing baselines.},
  archive      = {J_MLST},
  author       = {Nathalie Soybelman and Nilotpal Kakati and Lukas Heinrich and Francesco Armando Di Bello and Etienne Dreyer and Sanmay Ganguly and Eilam Gross and Marumi Kado and Jonathan Shlomi},
  doi          = {10.1088/2632-2153/ad035b},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045036},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Set-conditional set generation for particle physics},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring machine learning to hardware implementations for
large data rate x-ray instrumentation. <em>MLST</em>, <em>4</em>(4),
045035. (<a href="https://doi.org/10.1088/2632-2153/ad0d12">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, innovations in radiation and photonic detectors considerably improved their resolution, pixel density, sensitivity, and sampling rate, which all contribute to increased data generation rates. This huge data increases the amount of storage required, as well as the cabling between the source and the storage units. To overcome this problem, edge machine learning (EdgeML) proposes to move computation units near the detectors, utilizing machine learning (ML) models to emulate non-linear mathematical relationships between detector&#39;s output data. ML algorithms can be implemented in digital circuits, such as application-specific integrated circuits and field-programmable gate arrays, which support both parallelization and pipelining. EdgeML has both the benefits of edge computing and ML models to compress data near the detectors. This paper explores the currently available tool-flows designed to translate software ML algorithms to digital circuits near the edge. The main focus is on tool-flows that provide a diverse range of supported models, optimization techniques, and compression methods. We compare their accessibility, performance, and ease of use, and compare them for two high data-rate instrumentation applications: (1) CookieBox, and (2) billion-pixel camera.},
  archive      = {J_MLST},
  author       = {Mohammad Mehdi Rahimifar and Quentin Wingering and Berthié Gouin-Ferland and Hamza Ezzaoui Rahali and Charles-Étienne Granger and Audrey C Therrien},
  doi          = {10.1088/2632-2153/ad0d12},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045035},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Exploring machine learning to hardware implementations for large data rate x-ray instrumentation},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Calibration of uncertainty in the active learning of machine
learning force fields. <em>MLST</em>, <em>4</em>(4), 045034. (<a
href="https://doi.org/10.1088/2632-2153/ad0ab5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {FFLUX is a machine learning force field that uses the maximum expected prediction error (MEPE) active learning algorithm to improve the efficiency of model training. MEPE uses the predictive uncertainty of a Gaussian process (GP) to balance exploration and exploitation when selecting the next training sample. However, the predictive uncertainty of a GP is unlikely to be accurate or precise immediately after training. We hypothesize that calibrating the uncertainty quantification within MEPE will improve active learning performance. We develop and test two methods to improve uncertainty estimates: post-hoc calibration of predictive uncertainty using the CRUDE algorithm, and replacing the GP with a student- t process. We investigate the impact of these methods on MEPE for single sample and batch sample active learning. Our findings suggest that post-hoc calibration does not improve the performance of active learning using the MEPE method. However, we do find that the student- t process can outperform active learning strategies and random sampling using a GP if the training set is sufficiently large.},
  archive      = {J_MLST},
  author       = {Adam Thomas-Mitchell and Glenn Hawe and Paul L A Popelier},
  doi          = {10.1088/2632-2153/ad0ab5},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045034},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Calibration of uncertainty in the active learning of machine learning force fields},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finding simplicity: Unsupervised discovery of features,
patterns, and order parameters via shift-invariant variational
autoencoders *. <em>MLST</em>, <em>4</em>(4), 045033. (<a
href="https://doi.org/10.1088/2632-2153/ad073b">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in scanning tunneling and transmission electron microscopies (STM and STEM) have allowed routine generation of large volumes of imaging data containing information on the structure and functionality of materials. The experimental data sets contain signatures of long-range phenomena such as physical order parameter fields, polarization, and strain gradients in STEM, or standing electronic waves and carrier-mediated exchange interactions in STM, all superimposed onto scanning system distortions and gradual changes of contrast due to drift and/or mis-tilt effects. Correspondingly, while the human eye can readily identify certain patterns in the images such as lattice periodicities, repeating structural elements, or microstructures, their automatic extraction and classification are highly non-trivial and universal pathways to accomplish such analyses are absent. We pose that the most distinctive elements of the patterns observed in STM and (S)TEM images are similarity and (almost-) periodicity, behaviors stemming directly from the parsimony of elementary atomic structures, superimposed on the gradual changes reflective of order parameter distributions. However, the discovery of these elements via global Fourier methods is non-trivial due to variability and lack of ideal discrete translation symmetry. To address this problem, we explore the shift-invariant variational autoencoders (shift-VAEs) that allow disentangling characteristic repeating features in the images, their variations, and shifts that inevitably occur when randomly sampling the image space. Shift-VAEs balance the uncertainty in the position of the object of interest with the uncertainty in shape reconstruction. This approach is illustrated for model 1D data, and further extended to synthetic and experimental STM and STEM 2D data. We further introduce an approach for training shift-VAEs that allows finding the latent variables that comport to known physical behavior. In this specific case, the condition is that the latent variable maps should be smooth on the length scale of the atomic lattice (as expected for physical order parameters), but other conditions can be imposed. The opportunities and limitations of the shift VAE analysis for pattern discovery are elucidated.},
  archive      = {J_MLST},
  author       = {Maxim Ziatdinov and Chun Yin (Tommy) Wong and Sergei V Kalinin},
  doi          = {10.1088/2632-2153/ad073b},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045033},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Finding simplicity: Unsupervised discovery of features, patterns, and order parameters via shift-invariant variational autoencoders *},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Looking at the posterior: Accuracy and uncertainty of
neural-network predictions. <em>MLST</em>, <em>4</em>(4), 045032. (<a
href="https://doi.org/10.1088/2632-2153/ad0ab4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian inference can quantify uncertainty in the predictions of neural networks using posterior distributions for model parameters and network output. By looking at these posterior distributions, one can separate the origin of uncertainty into aleatoric and epistemic contributions. One goal of uncertainty quantification is to inform on prediction accuracy. Here we show that prediction accuracy depends on both epistemic and aleatoric uncertainty in an intricate fashion that cannot be understood in terms of marginalized uncertainty distributions alone. How the accuracy relates to epistemic and aleatoric uncertainties depends not only on the model architecture, but also on the properties of the dataset. We discuss the significance of these results for active learning and introduce a novel acquisition function that outperforms common uncertainty-based methods. To arrive at our results, we approximated the posteriors using deep ensembles, for fully-connected, convolutional and attention-based neural networks.},
  archive      = {J_MLST},
  author       = {Hampus Linander and Oleksandr Balabanov and Henry Yang and Bernhard Mehlig},
  doi          = {10.1088/2632-2153/ad0ab4},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045032},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Looking at the posterior: Accuracy and uncertainty of neural-network predictions},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unravelling physics beyond the standard model with classical
and quantum anomaly detection. <em>MLST</em>, <em>4</em>(4), 045031. (<a
href="https://doi.org/10.1088/2632-2153/ad07f7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Much hope for finding new physics phenomena at microscopic scale relies on the observations obtained from High Energy Physics experiments, like the ones performed at the Large Hadron Collider (LHC). However, current experiments do not indicate clear signs of new physics that could guide the development of additional Beyond Standard Model (BSM) theories. Identifying signatures of new physics out of the enormous amount of data produced at the LHC falls into the class of anomaly detection and constitutes one of the greatest computational challenges. In this article, we propose a novel strategy to perform anomaly detection in a supervised learning setting, based on the artificial creation of anomalies through a random process. For the resulting supervised learning problem, we successfully apply classical and quantum support vector classifiers (CSVC and QSVC respectively) to identify the artificial anomalies among the SM events. Even more promising, we find that employing an SVC trained to identify the artificial anomalies, it is possible to identify realistic BSM events with high accuracy. In parallel, we also explore the potential of quantum algorithms for improving the classification accuracy and provide plausible conditions for the best exploitation of this novel computational paradigm.},
  archive      = {J_MLST},
  author       = {Julian Schuhmacher and Laura Boggia and Vasilis Belis and Ema Puljak and Michele Grossi and Maurizio Pierini and Sofia Vallecorsa and Francesco Tacchino and Panagiotis Barkoutsos and Ivano Tavernelli},
  doi          = {10.1088/2632-2153/ad07f7},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045031},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Unravelling physics beyond the standard model with classical and quantum anomaly detection},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A machine-learning approach to setting optimal thresholds
and its application in rolling bearing fault diagnosis. <em>MLST</em>,
<em>4</em>(4), 045030. (<a
href="https://doi.org/10.1088/2632-2153/ad0ab3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bearings are one of the critical components of any mechanical equipment. They induce most equipment faults, and their health status directly impacts the overall performance of equipment. Therefore, effective bearing fault diagnosis is essential, as it helps maintain the equipment stability, increasing economic benefits through timely maintenance. Currently, most studies focus on extracting fault features, with limited attention to establishing fault thresholds. As a result, these thresholds are challenging to utilize in the automatic monitoring diagnosis of intelligent devices. This study employed the generalized fractal dimensions to effectively extract the feature of time-domain vibration signals of bearings. The optimal fault threshold model was developed using the receiver operating characteristic curve, which served as the baseline of exception judgment. The extracted fault threshold model was verified using two bearing operation experiments. The experimental results revealed different damaged positions and components observed in the two experiments. The same fault threshold model was obtained using the method proposed in this study, and it effectively diagnosed the abnormal states within the signals. This finding confirms the effectiveness of the diagnostic method proposed in this study.},
  archive      = {J_MLST},
  author       = {Yao-Chi Tang and Kuo-Hao Li},
  doi          = {10.1088/2632-2153/ad0ab3},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045030},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A machine-learning approach to setting optimal thresholds and its application in rolling bearing fault diagnosis},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CAD system for epileptic seizure detection from EEG through
image processing and SURF-BOF technique. <em>MLST</em>, <em>4</em>(4),
045029. (<a href="https://doi.org/10.1088/2632-2153/ad0572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is one of the most debilitating neurological diseases that abruptly alters a person&#39;s way of life. Manual diagnosis is a laborious and time-consuming task prone to human error. Therefore, automating this task by developing an intelligent system is necessary. Existing deep learning (DL) models require high training time, large datasets, and machines with more memory and processing power. In addition, owing to the black-box nature of DL models, no one can determine the features that the network prefers for classification decisions. To overcome these challenges, this study proposes an accurate, automatic, and fast-intelligent system for epilepsy detection using a computer-aided diagnosis (CAD) -two-dimensional machine learning (ML) framework. Existing ML models struggle to produce reliable and acceptable diagnostic results owing to the low amplitude and nonstationary nature of electroencephalograms (EEGs), particularly in clinical situations where environmental influences are almost impossible to eliminate. The proposed model was built using the Children&#39;s Hospital Boston and the Massachusetts Institute of Technology dataset, and represents the first study that employs the speeded-up robust feature (SURF) bag of features technique for this application, which generates local features from spectrogram images of the respective one-dimensional EEG signal inputs. In addition, DL features were extracted from the spectrogram images for model performance comparison. Both features were used separately to train the ML classifiers. Implementing SURF offers fast computation and makes the model invariant to distortions, noise, scaling, and so on. Therefore, the proposed model is more suitable for real-time applications, and this ML framework provides an enhanced accuracy of 99.78% compared to the support vector machine-RBF classifier, along with 99.56% sensitivity, 100% specificity, and an error rate of 0.22%. The higher detection accuracy demonstrates the effectiveness of the proposed framework for medical disease diagnosis applications.},
  archive      = {J_MLST},
  author       = {Mohammad H Alshayeji},
  doi          = {10.1088/2632-2153/ad0572},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045029},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {CAD system for epileptic seizure detection from EEG through image processing and SURF-BOF technique},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards a robust and reliable deep learning approach for
detection of compact binary mergers in gravitational wave data.
<em>MLST</em>, <em>4</em>(4), 045028. (<a
href="https://doi.org/10.1088/2632-2153/ad0938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability of deep learning (DL) approaches to learn generalised signal and noise models, coupled with their fast inference on GPUs, holds great promise for enhancing gravitational-wave (GW) searches in terms of speed, parameter space coverage, and search sensitivity. However, the opaque nature of DL models severely harms their reliability. In this work, we meticulously develop a DL model stage-wise and work towards improving its robustness and reliability. First, we address the problems in maintaining the purity of training data by deriving a new metric that better reflects the visual strength of the &#39;chirp&#39; signal features in the data. Using a reduced, smooth representation obtained through a variational auto-encoder (VAE), we build a classifier to search for compact binary coalescence (CBC) signals. Our tests on real LIGO data show an impressive performance of the model. However, upon probing the robustness of the model through adversarial attacks, its simple failure modes were identified, underlining how such models can still be highly fragile. As a first step towards bringing robustness, we retrain the model in a novel framework involving a generative adversarial network (GAN). Over the course of training, the model learns to eliminate the primary modes of failure identified by the adversaries. Although absolute robustness is practically impossible to achieve, we demonstrate some fundamental improvements earned through such training, like sparseness and reduced degeneracy in the extracted features at different layers inside the model. We show that these gains are achieved at practically zero loss in terms of model performance on real LIGO data before and after GAN training. Through a direct search on {\sim}8.8 days of LIGO data, we recover two significant CBC events from GWTC-2.1 (Abbott et al 2022 2108.01045 [gr-qc]), GW190519_153544 and GW190521_074359. We also report the search sensitivity obtained from an injection study.},
  archive      = {J_MLST},
  author       = {Shreejit Jadhav and Mihir Shrivastava and Sanjit Mitra},
  doi          = {10.1088/2632-2153/ad0938},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045028},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Towards a robust and reliable deep learning approach for detection of compact binary mergers in gravitational wave data},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural network gaussian processes as efficient models of
potential energy surfaces for polyatomic molecules. <em>MLST</em>,
<em>4</em>(4), 045027. (<a
href="https://doi.org/10.1088/2632-2153/ad0652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel models of potential energy surfaces (PESs) for polyatomic molecules are often restricted by a specific choice of the kernel function. This can be avoided by optimizing the complexity of the kernel function. For regression problems with very expensive data, the functional form of the model kernels can be optimized in the Gaussian process (GP) setting through compositional function search guided by the Bayesian information criterion. However, the compositional kernel search is computationally demanding and relies on greedy strategies, which may yield sub-optimal kernels. An alternative strategy of increasing complexity of GP kernels treats a GP as a Bayesian neural network (NN) with a variable number of hidden layers, which yields NNGP models. Here, we present a direct comparison of GP models with composite kernels and NNGP models for applications aiming at the construction of global PES for polyatomic molecules. We show that NNGP models of PES can be trained much more efficiently and yield better generalization accuracy without relying on any specific form of the kernel function. We illustrate that NNGP models trained by distributions of energy points at low energies produce accurate predictions of PES at high energies. We also illustrate that NNGP models can extrapolate in the input variable space by building the free energy surface of the Heisenberg model trained in the paramagnetic phase and validated in the ferromagnetic phase. By construction, composite kernels yield more accurate models than kernels with a fixed functional form. Therefore, by illustrating that NNGP models outperform GP models with composite kernels, our work suggests that NNGP models should be a preferred choice of kernel models for PES.},
  archive      = {J_MLST},
  author       = {J Dai and R V Krems},
  doi          = {10.1088/2632-2153/ad0652},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045027},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Neural network gaussian processes as efficient models of potential energy surfaces for polyatomic molecules},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). How deep convolutional neural networks lose spatial
information with training. <em>MLST</em>, <em>4</em>(4), 045026. (<a
href="https://doi.org/10.1088/2632-2153/ad092c">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A central question of machine learning is how deep nets manage to learn tasks in high dimensions. An appealing hypothesis is that they achieve this feat by building a representation of the data where information irrelevant to the task is lost. For image datasets, this view is supported by the observation that after (and not before) training, the neural representation becomes less and less sensitive to diffeomorphisms acting on images as the signal propagates through the network. This loss of sensitivity correlates with performance and surprisingly correlates with a gain of sensitivity to white noise acquired during training. Which are the mechanisms learned by convolutional neural networks (CNNs) responsible for the these phenomena? In particular, why is the sensitivity to noise heightened with training? Our approach consists of two steps. (1) Analyzing the layer-wise representations of trained CNNs, we disentangle the role of spatial pooling in contrast to channel pooling in decreasing their sensitivity to image diffeomorphisms while increasing their sensitivity to noise. (2) We introduce model scale-detection tasks, which qualitatively reproduce the phenomena reported in our empirical analysis. In these models we can assess quantitatively how spatial pooling affects these sensitivities. We find that the increased sensitivity to noise observed in deep ReLU networks is a mechanistic consequence of the perturbing noise piling up during spatial pooling, after being rectified by ReLU units. Using odd activation functions like tanh drastically reduces the CNNs&#39; sensitivity to noise.},
  archive      = {J_MLST},
  author       = {Umberto M Tomasini and Leonardo Petrini and Francesco Cagnetta and Matthieu Wyart},
  doi          = {10.1088/2632-2153/ad092c},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045026},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {How deep convolutional neural networks lose spatial information with training},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial neural networks exploiting point cloud data for
fragmented solid objects classification. <em>MLST</em>, <em>4</em>(4),
045025. (<a href="https://doi.org/10.1088/2632-2153/ad035e">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel approach for fragmented solid object classification exploiting neural networks based on point clouds. This work is the initial step of a project in collaboration with the Institution of &#39;Ente Parco Archeologico del Colosseo&#39; in Rome, which aims to reconstruct ancient artifacts from their fragments. We built from scratch a synthetic dataset (DS) of fragments of different 3D objects including aging effects. We used this DS to train deep learning models for the task of classifying internal and external fragments. As model architectures, we adopted PointNet and dynamical graph convolutional neural network, which take as input a point cloud representing the spatial geometry of a fragment, and we optimized model performance by adding additional features sensitive to local geometry characteristics. We tested the approach by performing several experiments to check the robustness and generalization capabilities of the models. Finally, we test the models on a real case using a 3D scan of artifacts preserved in different museums, artificially fragmented, obtaining good performance.},
  archive      = {J_MLST},
  author       = {A Baiocchi and S Giagu and C Napoli and M Serra and P Nardelli and M Valleriani},
  doi          = {10.1088/2632-2153/ad035e},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045025},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Artificial neural networks exploiting point cloud data for fragmented solid objects classification},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpretable surrogate models to approximate the
predictions of convolutional neural networks in glaucoma diagnosis.
<em>MLST</em>, <em>4</em>(4), 045024. (<a
href="https://doi.org/10.1088/2632-2153/ad0798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning systems, especially in critical fields like medicine, suffer from a significant drawback, their black box nature, which lacks mechanisms for explaining or interpreting their decisions. In this regard, our research aims to evaluate the use of surrogate models for interpreting convolutional neural network (CNN) decisions in glaucoma diagnosis. Our approach is novel in that we approximate the original model with an interpretable one and also change the input features, replacing pixels with tabular geometric features of the optic disc, cup, and neuroretinal rim. We trained CNNs with two types of images: original images of the optic nerve head and simplified images showing only the disc and cup contours on a uniform background. Decision trees were used as surrogate models due to their simplicity and visualization properties, while saliency maps were calculated for some images for comparison. The experiments carried out with 1271 images of healthy subjects and 721 images of glaucomatous eyes demonstrate that decision trees can closely approximate the predictions of neural networks trained on simplified contour images, with R-squared values near 0.9 for VGG19, Resnet50, InceptionV3 and Xception architectures. Saliency maps proved difficult to interpret and showed inconsistent results across architectures, in contrast to the decision trees. Additionally, some decision trees trained as surrogate models outperformed a decision tree trained on the actual outcomes without surrogation. Decision trees may be a more interpretable alternative to saliency methods. Moreover, the fact that we matched the performance of a decision tree without surrogation to that obtained by decision trees using knowledge distillation from neural networks is a great advantage since decision trees are inherently interpretable. Therefore, based on our findings, we think this approach would be the most recommendable choice for specialists as a diagnostic tool.},
  archive      = {J_MLST},
  author       = {Jose Sigut and Francisco Fumero and Rafael Arnay and José Estévez and Tinguaro Díaz-Alemán},
  doi          = {10.1088/2632-2153/ad0798},
  journal      = {Machine Learning: Science and Technology},
  month        = {11},
  number       = {4},
  pages        = {045024},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Interpretable surrogate models to approximate the predictions of convolutional neural networks in glaucoma diagnosis},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reply to comment on “physics-based representations for
machine learning properties of chemical reactions.” <em>MLST</em>,
<em>4</em>(4), 048002. (<a
href="https://doi.org/10.1088/2632-2153/acee43">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, we published an article in this journal that explored physics-based representations in combination with kernel models for predicting reaction properties (i.e. TS barrier heights). In an anonymous comment on our contribution, the authors argue, amongst other points, that deep learning models relying on atom-mapped reaction SMILES are more appropriate for the same task. This raises the question: are deep learning models sounding the death knell for kernel based models? By studying several datasets that vary in the type of chemical (i.e. high-quality atom-mapping) and structural information (i.e. Cartesian coordinates of reactants and products) contained within, we illustrate that physics-based representations combined with kernel models are competitive with deep learning models. Indeed, in some cases, such as when reaction barriers are sensitive to the geometry, physics-based models represent the only viable candidate. Furthermore, we illustrate that the good performance of deep learning models relies on high-quality atom-mapping, which comes with significant human time-cost and, in some cases, is impossible. As such, both physics-based and graph models offer their own relative benefits to predict reaction barriers of differing datasets.},
  archive      = {J_MLST},
  author       = {Puck van Gerwen and Matthew D Wodrich and Ruben Laplaza and Clemence Corminboeuf},
  doi          = {10.1088/2632-2153/acee43},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {048002},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Reply to comment on ‘Physics-based representations for machine learning properties of chemical reactions’},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comment on “physics-based representations for machine
learning properties of chemical reactions.” <em>MLST</em>,
<em>4</em>(4), 048001. (<a
href="https://doi.org/10.1088/2632-2153/acee42">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a recent article in this journal, van Gerwen et al (2022 Mach. Learn.: Sci. Technol. 3 045005) presented a kernel ridge regression model to predict reaction barrier heights. Here, we comment on the utility of that model and present references and results that contradict several statements made in that article. Our primary interest is to offer a broader perspective by presenting three aspects that are essential for researchers to consider when creating models for chemical kinetics: (1) are the model&#39;s prediction targets and associated errors sufficient for practical applications? (2) Does the model prioritize user-friendly inputs so it is practical for others to integrate into prediction workflows? (3) Does the analysis report performance on both interpolative and more challenging extrapolative data splits so users have a realistic idea of the likely errors in the model&#39;s predictions?},
  archive      = {J_MLST},
  author       = {Kevin A Spiekermann and Thijs Stuyver and Lagnajit Pattanaik and William H Green},
  doi          = {10.1088/2632-2153/acee42},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {048001},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Comment on ‘Physics-based representations for machine learning properties of chemical reactions’},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LHC hadronic jet generation using convolutional variational
autoencoders with normalizing flows. <em>MLST</em>, <em>4</em>(4),
045023. (<a href="https://doi.org/10.1088/2632-2153/ad04ea">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In high energy physics, one of the most important processes for collider data analysis is the comparison of collected and simulated data. Nowadays the state-of-the-art for data generation is in the form of Monte Carlo (MC) generators. However, because of the upcoming high-luminosity upgrade of the Large Hadron Collider (LHC), there will not be enough computational power or time to match the amount of needed simulated data using MC methods. An alternative approach under study is the usage of machine learning generative methods to fulfill that task. Since the most common final-state objects of high-energy proton collisions are hadronic jets, which are collections of particles collimated in a given region of space, this work aims to develop a convolutional variational autoencoder (ConVAE) for the generation of particle-based LHC hadronic jets. Given the ConVAE&#39;s limitations, a normalizing flow (NF) network is coupled to it in a two-step training process, which shows improvements on the results for the generated jets. The ConVAE+NF network is capable of generating a jet in 18.30 \pm 0.04\,\,{\mu\text{s}} , making it one of the fastest methods for this task up to now.},
  archive      = {J_MLST},
  author       = {Breno Orzari and Nadezda Chernyavskaya and Raphael Cobe and Javier Duarte and Jefferson Fialho and Dimitrios Gunopulos and Raghav Kansal and Maurizio Pierini and Thiago Tomei and Mary Touranakou},
  doi          = {10.1088/2632-2153/ad04ea},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045023},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {LHC hadronic jet generation using convolutional variational autoencoders with normalizing flows},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep bayesian experimental design for quantum many-body
systems. <em>MLST</em>, <em>4</em>(4), 045022. (<a
href="https://doi.org/10.1088/2632-2153/ad020d">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian experimental design is a technique that allows to efficiently select measurements to characterize a physical system by maximizing the expected information gain. Recent developments in deep neural networks and normalizing flows allow for a more efficient approximation of the posterior and thus the extension of this technique to complex high-dimensional situations. In this paper, we show how this approach holds promise for adaptive measurement strategies to characterize present-day quantum technology platforms. In particular, we focus on arrays of coupled cavities and qubit arrays. Both represent model systems of high relevance for modern applications, like quantum simulations and computing, and both have been realized in platforms where measurement and control can be exploited to characterize and counteract unavoidable disorder. Thus, they represent ideal targets for applications of Bayesian experimental design.},
  archive      = {J_MLST},
  author       = {Leopoldo Sarra and Florian Marquardt},
  doi          = {10.1088/2632-2153/ad020d},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045022},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Deep bayesian experimental design for quantum many-body systems},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimating truncation effects of quantum bosonic systems
using sampling algorithms. <em>MLST</em>, <em>4</em>(4), 045021. (<a
href="https://doi.org/10.1088/2632-2153/ad035c">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To simulate bosons on a qubit- or qudit-based quantum computer, one has to regularize the theory by truncating infinite-dimensional local Hilbert spaces to finite dimensions. In the search for practical quantum applications, it is important to know how big the truncation errors can be. In general, it is not easy to estimate errors unless we have a good quantum computer. In this paper, we show that traditional sampling methods on classical devices, specifically Markov Chain Monte Carlo, can address this issue for a rather generic class of bosonic systems with a reasonable amount of computational resources available today. As a demonstration, we apply this idea to the scalar field theory on a two-dimensional lattice, with a size that goes beyond what is achievable using exact diagonalization methods. This method can be used to estimate the resources needed for realistic quantum simulations of bosonic theories, and also, to check the validity of the results of the corresponding quantum simulations.},
  archive      = {J_MLST},
  author       = {Masanori Hanada and Junyu Liu and Enrico Rinaldi and Masaki Tezuka},
  doi          = {10.1088/2632-2153/ad035c},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045021},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Estimating truncation effects of quantum bosonic systems using sampling algorithms},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Label-free timing analysis of SiPM-based modularized
detectors with physics-constrained deep learning. <em>MLST</em>,
<em>4</em>(4), 045020. (<a
href="https://doi.org/10.1088/2632-2153/acfd09">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pulse timing is an important topic in nuclear instrumentation, with far-reaching applications from high energy physics to radiation imaging. While high-speed analog-to-digital converters become more and more developed and accessible, their potential uses and merits in nuclear detector signal processing are still uncertain, partially due to associated timing algorithms which are not fully understood and utilized. In this paper, we propose a novel method based on deep learning for timing analysis of modularized detectors without explicit needs of labeling event data. By taking advantage of the intrinsic time correlations, a label-free loss function with a specially designed regularizer is formed to supervise the training of neural networks (NNs) towards a meaningful and accurate mapping function. We mathematically demonstrate the existence of the optimal function desired by the method, and give a systematic algorithm for training and calibration of the model. The proposed method is validated on two experimental datasets based on silicon photomultipliers as main transducers. In the toy experiment, the NN model achieves the single-channel time resolution of 8.8 ps and exhibits robustness against concept drift in the dataset. In the electromagnetic calorimeter experiment, several NN models (fully-connected, convolutional neural network and long short-term memory) are tested to show their conformance to the underlying physical constraint and to judge their performance against traditional methods. In total, the proposed method works well in either ideal or noisy experimental condition and recovers the time information from waveform samples successfully and precisely.},
  archive      = {J_MLST},
  author       = {Pengcheng Ai and Le Xiao and Zhi Deng and Yi Wang and Xiangming Sun and Guangming Huang and Dong Wang and Yulei Li and Xinchi Ran},
  doi          = {10.1088/2632-2153/acfd09},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045020},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Label-free timing analysis of SiPM-based modularized detectors with physics-constrained deep learning},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The information of attribute uncertainties: What
convolutional neural networks can learn about errors in input data.
<em>MLST</em>, <em>4</em>(4), 045019. (<a
href="https://doi.org/10.1088/2632-2153/ad0285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Errors in measurements are key to weighting the value of data, but are often neglected in machine learning (ML). We show how convolutional neural networks (CNNs) are able to learn about the context and patterns of signal and noise, leading to improvements in the performance of classification methods. We construct a model whereby two classes of objects follow an underlying Gaussian distribution, and where the features (the input data) have varying, but known, levels of noise—in other words, each data point has a different error bar. This model mimics the nature of scientific data sets, such as those from astrophysical surveys, where noise arises as a realization of random processes with known underlying distributions. The classification of these objects can then be performed using standard statistical techniques (e.g. least squares minimization), as well as ML techniques. This allows us to take advantage of a maximum likelihood approach to object classification, and to measure the amount by which the ML methods are incorporating the information in the input data uncertainties. We show that, when each data point is subject to different levels of noise (i.e. noises with different distribution functions, which is typically the case in scientific data sets), that information can be learned by the CNNs, raising the ML performance to at least the same level of the least squares method—and sometimes even surpassing it. Furthermore, we show that, with varying noise levels, the confidence of the ML classifiers serves as a proxy for the underlying cumulative distribution function, but only if the information about specific input data uncertainties is provided to the CNNs.},
  archive      = {J_MLST},
  author       = {Natália V N Rodrigues and L Raul Abramo and Nina S T Hirata},
  doi          = {10.1088/2632-2153/ad0285},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045019},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {The information of attribute uncertainties: What convolutional neural networks can learn about errors in input data},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A filter-based feature selection approach in multilabel
classification. <em>MLST</em>, <em>4</em>(4), 045018. (<a
href="https://doi.org/10.1088/2632-2153/ad035d">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label classification is a fast-growing field of machine learning. Recent developments have shown several applications, including social media, healthcare, bio-molecular analysis, scene, and music classification associated with the multilabel classification. In classification problems, multiple labels (multilabel or more than one class label) are assigned to an unseen record instead of a single-label class assignment. Feature selection is a preprocessing phase used to identify the most relevant features that could improve the accuracy of the multilabel classifiers. The focus of this study is the feature selection method in multilabel classification. The study used a feature selection filter method involving the Fisher score, analysis of variance test, mutual information, Chi-Square, and ensembles of these statistical methods. An extensive range of machine learning algorithms is applied in the modelling phase of a multilabel classification model that includes binary relevance, classifier chain, label powerset, binary relevance KNN, multi-label twin support vector machine, multi-label KNN. Besides, label space partitioning and majority voting of ensemble methods are used and Random Forest is the base learner. The experiments are carried out over five different multilabel benchmarking datasets. The evaluation of the classification model is measured using accuracy, precision, recall, F1 score, and hamming loss. The study demonstrated that the filter methods (i.e. mutual information) having top weighted 80\% to 20\% features provided significant outcomes.},
  archive      = {J_MLST},
  author       = {Rafia Shaikh and Muhammad Rafi and Naeem Ahmed Mahoto and Adel Sulaiman and Asadullah Shaikh},
  doi          = {10.1088/2632-2153/ad035d},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045018},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A filter-based feature selection approach in multilabel classification},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vortex detection in atomic bose–einstein condensates using
neural networks trained on synthetic images. <em>MLST</em>,
<em>4</em>(4), 045017. (<a
href="https://doi.org/10.1088/2632-2153/ad03ad">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum vortices in atomic Bose–Einstein condensates (BECs) are topological defects characterized by quantized circulation of particles around them. In experimental studies, vortices are commonly detected by time-of-flight imaging, where their density-depleted cores are enlarged. In this work, we describe a machine learning-based method for detecting vortices in experimental BEC images, particularly focusing on turbulent condensates containing irregularly distributed vortices. Our approach employs a convolutional neural network (CNN) trained solely on synthetic simulated images, eliminating the need for manual labeling of the vortex positions as ground truth. We find that the CNN achieves accurate vortex detection in real experimental images, thereby facilitating analysis of large experimental datasets without being constrained by specific experimental conditions. This novel approach represents a significant advancement in studying quantum vortex dynamics and streamlines the analysis process in the investigation of turbulent BECs.},
  archive      = {J_MLST},
  author       = {Myeonghyeon Kim and Junhwan Kwon and Tenzin Rabga and Y Shin},
  doi          = {10.1088/2632-2153/ad03ad},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045017},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Vortex detection in atomic Bose–Einstein condensates using neural networks trained on synthetic images},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven dynamics reconstruction using RBF network *.
<em>MLST</em>, <em>4</em>(4), 045016. (<a
href="https://doi.org/10.1088/2632-2153/acec31">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constructing the governing dynamical equations of complex systems from observational data is of great interest for both theory and applications. However, it is a difficult inverse problem to explicitly construct the dynamical equations for many real complex systems based on observational data. Here, we propose to implicitly represent the dynamical equations of a complex system using a radial basis function (RBF) network trained on the observed data of the system. We show that the RBF network trained on trajectory data of the classical Lorenz and Chen system can faithfully reproduce the orbits, fixed points, and local bifurcations of the original dynamical equations. We also apply this method to electrocardiogram (ECG) data and show that the fixed points of the RBF network trained using ECG can discriminate healthy people from patients with heart disease, indicating that the method can be applied to real complex systems.},
  archive      = {J_MLST},
  author       = {Cong-Cong Du and Xuan Wang and Zhangsen Wang and Da-Hui Wang},
  doi          = {10.1088/2632-2153/acec31},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045016},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Data-driven dynamics reconstruction using RBF network *},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Physics-informed neural networks for solving forward and
inverse vlasov–poisson equation via fully kinetic simulation.
<em>MLST</em>, <em>4</em>(4), 045015. (<a
href="https://doi.org/10.1088/2632-2153/ad03d5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Vlasov–Poisson equation is one of the most fundamental models in plasma physics. It has been widely used in areas such as confined plasmas in thermonuclear research and space plasmas in planetary magnetospheres. In this study, we explore the feasibility of the physics-informed neural networks for solving forward and inverse Vlasov–Poisson equation (PINN-Vlasov). The PINN-Vlasov method employs a multilayer perceptron (MLP) to represent the solution of the Vlasov–Poisson equation. The training dataset comprises the randomly sampled time, space, and velocity coordinates and the corresponding distribution function. We generate training data using the fully kinetic PIC simulation rather than the analytical solution to the Vlasov–Poisson equation to eliminate the correlation between data and equations. The Vlasov equation and Poisson equation are concurrently integrated into the PINN-Vlasov framework using automatic differentiation and the trapezoidal rule, respectively. By minimizing the residuals between the reconstructed distribution function and labeled data, and the physically constrained residuals of the Vlasov–Poisson equation, the PINN-Vlasov method is capable of dealing with both forward and inverse problems. For forward problems, the PINN-Vlasov method can solve the Vlasov–Poisson equation with given initial and boundary conditions. For inverse problems, the completely unknown electric field and equation coefficients can be predicted with the PINN-Vlasov method using little particle distribution data.},
  archive      = {J_MLST},
  author       = {Baiyi Zhang and Guobiao Cai and Huiyan Weng and Weizong Wang and Lihui Liu and Bijiao He},
  doi          = {10.1088/2632-2153/ad03d5},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045015},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Physics-informed neural networks for solving forward and inverse Vlasov–Poisson equation via fully kinetic simulation},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). High-dimensional multi-fidelity bayesian optimization for
quantum control. <em>MLST</em>, <em>4</em>(4), 045014. (<a
href="https://doi.org/10.1088/2632-2153/ad0100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the first multi-fidelity Bayesian optimization (BO) approach for solving inverse problems in the quantum control of prototypical quantum systems. Our approach automatically constructs time-dependent control fields that enable transitions between initial and desired final quantum states. Most importantly, our BO approach gives impressive performance in constructing time-dependent control fields, even for cases that are difficult to converge with existing gradient-based approaches. We provide detailed descriptions of our machine learning methods as well as performance metrics for a variety of machine learning algorithms. Taken together, our results demonstrate that BO is a promising approach to efficiently and autonomously design control fields in general quantum dynamical systems.},
  archive      = {J_MLST},
  author       = {Marjuka F Lazin and Christian R Shelton and Simon N Sandhofer and Bryan M Wong},
  doi          = {10.1088/2632-2153/ad0100},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045014},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {High-dimensional multi-fidelity bayesian optimization for quantum control},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stokesian processes: Inferring stokes flows using
physics-informed gaussian processes. <em>MLST</em>, <em>4</em>(4),
045013. (<a href="https://doi.org/10.1088/2632-2153/ad0286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a probabilistic Stokes flow framework, using physics informed Gaussian processes, which can be used to solve both forward/inverse flow problems with missing and/or noisy data. The physics of the problem, specified by the Stokes and continuity equations, is exactly encoded into the inference framework. Crucially, this means that we do not need to explicitly solve the Poisson equation for the pressure field, as a physically meaningful (divergence-free) velocity field will automatically be selected. We test our method on a simple pressure driven flow problem, i.e. flow through a sinusoidal channel, and compare against standard numerical methods (Finite Element and Direct Numerical Simulations). We obtain excellent agreement, even when solving inverse problems given only sub-sampled velocity data on low dimensional sub-spaces (i.e. 1 component of the velocity on 1 D domains to reconstruct 2 D flows). The proposed method will be a valuable tool for analyzing experimental data, where noisy/missing data is the norm.},
  archive      = {J_MLST},
  author       = {John J Molina and Kenta Ogawa and Takashi Taniguchi},
  doi          = {10.1088/2632-2153/ad0286},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045013},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Stokesian processes: Inferring stokes flows using physics-informed gaussian processes},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature space reduction method for ultrahigh-dimensional,
multiclass data: Random forest-based multiround screening (RFMS).
<em>MLST</em>, <em>4</em>(4), 045012. (<a
href="https://doi.org/10.1088/2632-2153/ad020e">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, several screening methods have been published for ultrahigh-dimensional data that contain hundreds of thousands of features, many of which are irrelevant or redundant. However, most of these methods cannot handle data with thousands of classes. Prediction models built to authenticate users based on multichannel biometric data result in this type of problem. In this study, we present a novel method known as random forest-based multiround screening (RFMS) that can be effectively applied under such circumstances. The proposed algorithm divides the feature space into small subsets and executes a series of partial model builds. These partial models are used to implement tournament-based sorting and the selection of features based on their importance. This algorithm successfully filters irrelevant features and also discovers binary and higher-order feature interactions. To benchmark RFMS, a synthetic biometric feature space generator known as BiometricBlender is employed. Based on the results, the RFMS is on par with industry-standard feature screening methods, while simultaneously possessing many advantages over them.},
  archive      = {J_MLST},
  author       = {Gergely Hanczár and Marcell Stippinger and Dávid Hanák and Marcell T Kurbucz and Olivér M Törteli and Ágnes Chripkó and Zoltán Somogyvári},
  doi          = {10.1088/2632-2153/ad020e},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045012},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Feature space reduction method for ultrahigh-dimensional, multiclass data: Random forest-based multiround screening (RFMS)},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bayesian renormalization. <em>MLST</em>, <em>4</em>(4),
045011. (<a href="https://doi.org/10.1088/2632-2153/ad0102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this note we present a fully information theoretic approach to renormalization inspired by Bayesian statistical inference, which we refer to as Bayesian renormalization. The main insight of Bayesian renormalization is that the Fisher metric defines a correlation length that plays the role of an emergent renormalization group (RG) scale quantifying the distinguishability between nearby points in the space of probability distributions. This RG scale can be interpreted as a proxy for the maximum number of unique observations that can be made about a given system during a statistical inference experiment. The role of the Bayesian renormalization scheme is subsequently to prepare an effective model for a given system up to a precision which is bounded by the aforementioned scale. In applications of Bayesian renormalization to physical systems, the emergent information theoretic scale is naturally identified with the maximum energy that can be probed by current experimental apparatus, and thus Bayesian renormalization coincides with ordinary renormalization. However, Bayesian renormalization is sufficiently general to apply even in circumstances in which an immediate physical scale is absent, and thus provides an ideal approach to renormalization in data science contexts. To this end, we provide insight into how the Bayesian renormalization scheme relates to existing methods for data compression and data generation such as the information bottleneck and the diffusion learning paradigm. We conclude by designing an explicit form of Bayesian renormalization inspired by Wilson&#39;s momentum shell renormalization scheme in quantum field theory. We apply this Bayesian renormalization scheme to a simple neural network and verify the sense in which it organizes the parameters of the model according to a hierarchy of information theoretic importance.},
  archive      = {J_MLST},
  author       = {David S Berman and Marc S Klinger and Alexander G Stapleton},
  doi          = {10.1088/2632-2153/ad0102},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045011},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Bayesian renormalization},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning renormalization group for statistical
physics. <em>MLST</em>, <em>4</em>(4), 045010. (<a
href="https://doi.org/10.1088/2632-2153/ad0101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a machine-learning renormalization group (MLRG) algorithm to explore and analyze many-body lattice models in statistical physics. Using the representation learning capability of generative modeling, MLRG automatically learns the optimal renormalization group (RG) transformations from self-generated spin configurations and formulates RG equations without human supervision. The algorithm does not focus on simulating any particular lattice model but broadly explores all possible models compatible with the internal and lattice symmetries given the on-site symmetry representation. It can uncover the RG monotone that governs the RG flow, assuming a strong form of the c -theorem. This enables several downstream tasks, including unsupervised classification of phases, automatic location of phase transitions or critical points, controlled estimation of critical exponents, and operator scaling dimensions. We demonstrate the MLRG method in two-dimensional lattice models with Ising symmetry and show that the algorithm correctly identifies and characterizes the Ising criticality.},
  archive      = {J_MLST},
  author       = {Wanda Hou and Yi-Zhuang You},
  doi          = {10.1088/2632-2153/ad0101},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045010},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Machine learning renormalization group for statistical physics},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Universal adversarial perturbations for multiple
classification tasks with quantum classifiers. <em>MLST</em>,
<em>4</em>(4), 045009. (<a
href="https://doi.org/10.1088/2632-2153/acffa3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum adversarial machine learning is an emerging field that studies the vulnerability of quantum learning systems against adversarial perturbations and develops possible defense strategies. Quantum universal adversarial perturbations are small perturbations, which can make different input samples into adversarial examples that may deceive a given quantum classifier. This is a field that was rarely looked into but worthwhile investigating because universal perturbations might simplify malicious attacks to a large extent, causing unexpected devastation to quantum machine learning models. In this paper, we take a step forward and explore the quantum universal perturbations in the context of heterogeneous classification tasks. In particular, we find that quantum classifiers that achieve almost state-of-the-art accuracy on two different classification tasks can be both conclusively deceived by one carefully-crafted universal perturbation. This result is explicitly demonstrated with well-designed quantum continual learning models with elastic weight consolidation method to avoid catastrophic forgetting, as well as real-life heterogeneous datasets from hand-written digits and medical MRI images. Our results provide a simple and efficient way to generate universal perturbations on heterogeneous classification tasks and thus would provide valuable guidance for future quantum learning technologies.},
  archive      = {J_MLST},
  author       = {Yun-Zhong Qiu},
  doi          = {10.1088/2632-2153/acffa3},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045009},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Universal adversarial perturbations for multiple classification tasks with quantum classifiers},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Governing equation discovery based on causal graph for
nonlinear dynamic systems. <em>MLST</em>, <em>4</em>(4), 045008. (<a
href="https://doi.org/10.1088/2632-2153/acffa4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The governing equations of nonlinear dynamic systems is of great significance for understanding the internal physical characteristics. In order to learn the governing equations of nonlinear systems from noisy observed data, we propose a novel method named governing equation discovery based on causal graph that combines spatio-temporal graph convolution network with governing equation modeling. The essence of our method is to first devise the causal graph encoding based on transfer entropy to obtain the adjacency matrix with causal significance between variables. Then, the spatio-temporal graph convolutional network is used to obtain approximate solutions for the system variables. On this basis, automatic differentiation is applied to obtain basic derivatives and form a dictionary of candidate algebraic terms. Finally, sparse regression is used to obtain the coefficient matrix and determine the explicit formulation of the governing equations. We also design a novel cross-combinatorial optimization strategy to learn the heterogeneous parameters that include neural network parameters and control equation coefficients. We conduct extensive experiments on seven datasets from different physical fields. The experimental results demonstrate the proposed method can automatically discover the underlying governing equation of the systems, and has great robustness.},
  archive      = {J_MLST},
  author       = {Dongni Jia and Xiaofeng Zhou and Shuai Li and Shurui Liu and Haibo Shi},
  doi          = {10.1088/2632-2153/acffa4},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045008},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Governing equation discovery based on causal graph for nonlinear dynamic systems},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving SOH estimation for lithium-ion batteries using
TimeGAN. <em>MLST</em>, <em>4</em>(4), 045007. (<a
href="https://doi.org/10.1088/2632-2153/acfd08">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the xEV market has been expanding by strengthening regulations on fossil fuel vehicles. It is essential to ensure the safety and reliability of batteries, one of the core components of xEVs. Furthermore, estimating the battery&#39;s state of health (SOH) is critical. There are model-based and data-based methods for SOH estimation. Model-based methods have limitations in linearly modeling the nonlinear internal state changes of batteries. In data-based methods, high-quality datasets containing large quantities of data are crucial. Since obtaining battery datasets through measurement is difficult, this paper supplements insufficient battery datasets using time-series generative adversarial network and compares the improvement rate in SOH estimation accuracy through long short-term memory and gated recurrent unit based on recurrent neural networks. According to the results, the average root mean square error of battery SOH estimation improved by approximately 25%, and the learning stability improved by approximately 40%.},
  archive      = {J_MLST},
  author       = {Sujin Seol and Jungeun Lee and Jaewoo Yoon and Byeongwoo Kim},
  doi          = {10.1088/2632-2153/acfd08},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045007},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Improving SOH estimation for lithium-ion batteries using TimeGAN},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Equivariant neural networks for spin dynamics simulations of
itinerant magnets. <em>MLST</em>, <em>4</em>(4), 045006. (<a
href="https://doi.org/10.1088/2632-2153/acffa2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {I present a novel equivariant neural network architecture for the large-scale spin dynamics simulation of the Kondo lattice model. This neural network mainly consists of tensor-product-based convolution layers and ensures two equivariances: translations of the lattice and rotations of the spins. I implement equivariant neural networks for two Kondo lattice models on two-dimensional square and triangular lattices, and perform training and validation. In the equivariant model for the square lattice, the validation error (based on root mean squared error) is reduced to less than one-third compared to a model using invariant descriptors as inputs. Furthermore, I demonstrate the ability to simulate phase transitions of skyrmion crystals in the triangular lattice, by performing dynamics simulations using the trained model.},
  archive      = {J_MLST},
  author       = {Yu Miyazaki},
  doi          = {10.1088/2632-2153/acffa2},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045006},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Equivariant neural networks for spin dynamics simulations of itinerant magnets},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Polynomial differentiation decreases the training time
complexity of physics-informed neural networks and strengthens their
approximation power. <em>MLST</em>, <em>4</em>(4), 045005. (<a
href="https://doi.org/10.1088/2632-2153/acf97a">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present novel approximates of variational losses, being applicable for the training of physics-informed neural networks (PINNs). The formulations reflect classic Sobolev space theory for partial differential equations (PDEs) and their weak formulations. The loss approximates rest on polynomial differentiation realised by an extension of classic Gauss–Legendre cubatures , we term Sobolev cubatures , and serve as a replacement of automatic differentiation . We prove the training time complexity of the resulting Sobolev -PINNs with polynomial differentiation to be less than required by PINNs relying on automatic differentiation. On top of one-to-two order of magnitude speed-up the Sobolev-PINNs are demonstrated to achieve closer solution approximations for prominent forward and inverse, linear and non-linear PDE problems compared to established PINNs.},
  archive      = {J_MLST},
  author       = {Juan-Esteban Suarez Cardona and Michael Hecht},
  doi          = {10.1088/2632-2153/acf97a},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045005},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Polynomial differentiation decreases the training time complexity of physics-informed neural networks and strengthens their approximation power},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combining variational autoencoders and physical bias for
improved microscopy data analysis ∗. <em>MLST</em>, <em>4</em>(4),
045004. (<a href="https://doi.org/10.1088/2632-2153/acf6a9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electron and scanning probe microscopy produce vast amounts of data in the form of images or hyperspectral data, such as electron energy loss spectroscopy or 4D scanning transmission electron microscope, that contain information on a wide range of structural, physical, and chemical properties of materials. To extract valuable insights from these data, it is crucial to identify physically separate regions in the data, such as phases, ferroic variants, and boundaries between them. In order to derive an easily interpretable feature analysis, combining with well-defined boundaries in a principled and unsupervised manner, here we present a physics augmented machine learning method which combines the capability of variational autoencoders to disentangle factors of variability within the data and the physics driven loss function that seeks to minimize the total length of the discontinuities in images corresponding to latent representations. Our method is applied to various materials, including NiO-LSMO, BiFeO 3 , and graphene. The results demonstrate the effectiveness of our approach in extracting meaningful information from large volumes of imaging data. The customized codes of the required functions and classes to develop phyVAE is available at https://github.com/arpanbiswas52/phy-VAE .},
  archive      = {J_MLST},
  author       = {Arpan Biswas and Maxim Ziatdinov and Sergei V Kalinin},
  doi          = {10.1088/2632-2153/acf6a9},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045004},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Combining variational autoencoders and physical bias for improved microscopy data analysis ∗},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Probing reaction channels via reinforcement learning.
<em>MLST</em>, <em>4</em>(4), 045003. (<a
href="https://doi.org/10.1088/2632-2153/acfc33">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chemical reactions are dynamical processes involving the correlated reorganization of atomic configurations, driving the conversion of an initial reactant into a result product. By virtue of the metastability of both the reactants and products, chemical reactions are rare events, proceeding fleetingly. Reaction pathways can be modelled probabilistically by using the notion of reactive density in the phase space of the molecular system. Such density is related to a function known as the committor function, which describes the likelihood of a configuration evolving to one of the nearby metastable regions. In theory, the committor function can be obtained by solving the backward Kolmogorov equation (BKE), which is a partial differential equation (PDE) defined in the full dimensional phase space. However, using traditional methods to solve this problem is not practical for high dimensional systems. In this work, we propose a reinforcement learning based method to identify important configurations that connect reactant and product states along chemical reaction paths. By shooting multiple trajectories from these configurations, we can generate an ensemble of states that concentrate on the transition path ensemble. This configuration ensemble can be effectively employed in a neural network-based PDE solver to obtain an approximation solution of a restricted BKE, even when the dimension of the problem is very high. The resulting solution provides an approximation for the committor function that encodes mechanistic information for the reaction, paving a new way for understanding of complex chemical reactions and evaluation of reaction rates.},
  archive      = {J_MLST},
  author       = {Senwei Liang and Aditya N Singh and Yuanran Zhu and David T Limmer and Chao Yang},
  doi          = {10.1088/2632-2153/acfc33},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045003},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Probing reaction channels via reinforcement learning},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rediscovering orbital mechanics with machine learning.
<em>MLST</em>, <em>4</em>(4), 045002. (<a
href="https://doi.org/10.1088/2632-2153/acfa63">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an approach for using machine learning to automatically discover the governing equations and unknown properties (in this case, masses) of real physical systems from observations. We train a &#39;graph neural network&#39; to simulate the dynamics of our Solar System&#39;s Sun, planets, and large moons from 30 years of trajectory data. We then use symbolic regression to correctly infer an analytical expression for the force law implicitly learned by the neural network, which our results showed is equivalent to Newton&#39;s law of gravitation. The key assumptions our method makes are translational and rotational equivariance, and Newton&#39;s second and third laws of motion. It did not, however, require any assumptions about the masses of planets and moons or physical constants, but nonetheless, they, too, were accurately inferred with our method. Naturally, the classical law of gravitation has been known since Isaac Newton, but our results demonstrate that our method can discover unknown laws and hidden properties from observed data.},
  archive      = {J_MLST},
  author       = {Pablo Lemos and Niall Jeffrey and Miles Cranmer and Shirley Ho and Peter Battaglia},
  doi          = {10.1088/2632-2153/acfa63},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045002},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Rediscovering orbital mechanics with machine learning},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). About the generalizability of deep learning based image
quality assessment in mammography. <em>MLST</em>, <em>4</em>(4), 045001.
(<a href="https://doi.org/10.1088/2632-2153/acf914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One method of assessing the image quality of a mammography unit is to estimate a contrast-detail-curve (CDC) that is obtained from images of a technical phantom. It has been proposed to estimate this CDC by using an end-to-end neural network (NN) which only needs one image to determine the CDC. That approach, however, has been developed on the basis of images of one single mammography unit. In this work, we train NNs on synthetic images of contrast-detail phantoms for mammography and test the so-trained NNs on images that are obtained from real mammography units. The goal of this paper is to demonstrate that such a deep learning approach is capable to generalize to predict CDCs for various real mammography units. Our experiments cover various manufacturers and the proposed approach is shown to work across different NN architectures and preprocessing methods which highlights its generalizability.},
  archive      = {J_MLST},
  author       = {Josua Faller and Narbota Amanova and Ruben van Engen and Jörg Martin and Clemens Elster},
  doi          = {10.1088/2632-2153/acf914},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045001},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {About the generalizability of deep learning based image quality assessment in mammography},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Conditioning boltzmann generators for rare event sampling.
<em>MLST</em>, <em>4</em>(3), 035050. (<a
href="https://doi.org/10.1088/2632-2153/acf55c">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the dynamics of complex molecular processes is often linked to the study of infrequent transitions between long-lived stable states. The standard approach to the sampling of such rare events is to generate an ensemble of transition paths using a random walk in trajectory space. This, however, comes with the drawback of strong correlations between subsequently sampled paths and with an intrinsic difficulty in parallelizing the sampling process. We propose a transition path sampling scheme based on neural-network generated configurations. These are obtained employing normalizing flows, a neural network class able to generate statistically independent samples from a given distribution. With this approach, not only are correlations between visited paths removed, but the sampling process becomes easily parallelizable. Moreover, by conditioning the normalizing flow, the sampling of configurations can be steered towards regions of interest. We show that this approach enables the resolution of both the thermodynamics and kinetics of the transition region for systems that can be sampled using exact-likelihood generative models.},
  archive      = {J_MLST},
  author       = {Sebastian Falkner and Alessandro Coretti and Salvatore Romano and Phillip L Geissler and Christoph Dellago},
  doi          = {10.1088/2632-2153/acf55c},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035050},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Conditioning boltzmann generators for rare event sampling},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning of hidden variables in multiscale fluid
simulation. <em>MLST</em>, <em>4</em>(3), 035049. (<a
href="https://doi.org/10.1088/2632-2153/acf81a">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving fluid dynamics equations often requires the use of closure relations that account for missing microphysics. For example, when solving equations related to fluid dynamics for systems with a large Reynolds number, sub-grid effects become important and a turbulence closure is required, and in systems with a large Knudsen number, kinetic effects become important and a kinetic closure is required. By adding an equation governing the growth and transport of the quantity requiring the closure relation, it becomes possible to capture microphysics through the introduction of &#39;hidden variables&#39; that are non-local in space and time. The behavior of the &#39;hidden variables&#39; in response to the fluid conditions can be learned from a higher fidelity or ab-initio model that contains all the microphysics. In our study, a partial differential equation simulator that is end-to-end differentiable is used to train judiciously placed neural networks against ground-truth simulations. We show that this method enables an Euler equation based approach to reproduce non-linear, large Knudsen number plasma physics that can otherwise only be modeled using Boltzmann-like equation simulators such as Vlasov or particle-in-cell modeling.},
  archive      = {J_MLST},
  author       = {Archis S Joglekar and Alexander G R Thomas},
  doi          = {10.1088/2632-2153/acf81a},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035049},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Machine learning of hidden variables in multiscale fluid simulation},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical bayesian pharmacometrics analysis of baclofen
for alcohol use disorder. <em>MLST</em>, <em>4</em>(3), 035048. (<a
href="https://doi.org/10.1088/2632-2153/acf6aa">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alcohol use disorder (AUD), also called alcohol dependence, is a major public health problem, affecting almost 10 \% of the world&#39;s population. Baclofen, as a selective \mathrm{GABA}_\mathrm{B} receptor agonist, has emerged as a promising drug for the treatment of AUD. However, the inter-trial, inter-individual and residual variability in drug concentration over time in a population of patients with AUD is unknown. In this study, we use a hierarchical Bayesian workflow to estimate the parameters of a pharmacokinetic (PK) population model from Baclofen administration to patients with AUD. By monitoring various convergence diagnostics, the probabilistic methodology is first validated on synthetic longitudinal datasets and then applied to infer the PK model parameters based on the clinical data that were retrospectively collected from outpatients treated with oral Baclofen. We show that state-of-the-art advances in automatic Bayesian inference using self-tuning Hamiltonian Monte Carlo (HMC) algorithms provide accurate and decisive predictions on Baclofen plasma concentration at both individual and group levels. Importantly, leveraging the information in prior provides faster computation, better convergence diagnostics, and substantially higher out-of-sample prediction accuracy. Moreover, the root mean squared error as a measure of within-sample predictive accuracy can be misleading for model evaluation, whereas the fully Bayesian information criteria correctly select the true data generating parameters. This study points out the capability of non-parametric Bayesian estimation using adaptive HMC sampling methods for easy and reliable estimation in clinical settings to optimize dosing regimens and efficiently treat AUD.},
  archive      = {J_MLST},
  author       = {Nina Baldy and Nicolas Simon and Viktor K Jirsa and Meysam Hashemi},
  doi          = {10.1088/2632-2153/acf6aa},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035048},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Hierarchical bayesian pharmacometrics analysis of baclofen for alcohol use disorder},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DIM: Long-tailed object detection and instance segmentation
via dynamic instance memory. <em>MLST</em>, <em>4</em>(3), 035047. (<a
href="https://doi.org/10.1088/2632-2153/acf362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection and instance segmentation have been successful on benchmarks with relatively balanced category distribution (e.g. MSCOCO). However, state-of-the-art object detection and segmentation methods still struggle to generalize on long-tailed datasets (e.g. LVIS), where a few classes (head classes) dominate the instance samples, while most classes (tailed classes) have only a few samples. To address this challenge, we propose a plug-and-play module within the Mask R-CNN framework called dynamic instance memory (DIM). Specifically, we augment Mask R-CNN with an auxiliary branch for training. It maintains a dynamic memory bank storing an instance-level prototype representation for each category , and shares the classifier with the existing instance branch. With a simple metric loss, the representations in DIM can be dynamically updated by the instance proposals in the mini-batch during training. Our DIM introduces a bias toward tailed classes to the classifier learning along with a class frequency reversed sampler, which learns generalizable representations from the original data distribution, complementing the existing instance branch. Comprehensive experiments on LVIS demonstrate the effectiveness of DIM, as well as the significant advantages of DIM over the baseline Mask R-CNN.},
  archive      = {J_MLST},
  author       = {Zhao-Min Chen and Xin Jin and Xiaoqin Zhang and Chaoqun Xia and Zhiyong Pan and Ruoxi Deng and Jie Hu and Heng Chen},
  doi          = {10.1088/2632-2153/acf362},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035047},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {DIM: Long-tailed object detection and instance segmentation via dynamic instance memory},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning neural network for approaching schrödinger
problems with arbitrary two-dimensional confinement. <em>MLST</em>,
<em>4</em>(3), 035046. (<a
href="https://doi.org/10.1088/2632-2153/acf55b">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an approach to the two-dimensional Schrödinger equation based on automatic learning methods with neural networks. It is intended to determine the ground state of a particle confined in any two-dimensional potential, starting from the knowledge of the solutions to a large number of arbitrary sample problems. A network architecture with two hidden layers is proposed to predict the wave function and energy of the ground state. Several accuracy indicators are proposed for validating the estimates provided by the neural network. The testing of the trained network is done by applying it to a large set of confinement potentials different from those used in the learning process. Some particular cases with symmetrical potentials are solved as concrete examples, and a good network prediction accuracy is found.},
  archive      = {J_MLST},
  author       = {A Radu and C A Duque},
  doi          = {10.1088/2632-2153/acf55b},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035046},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Deep learning neural network for approaching schrödinger problems with arbitrary two-dimensional confinement},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpretable delta-learning of GW quasiparticle energies
from GGA-DFT. <em>MLST</em>, <em>4</em>(3), 035045. (<a
href="https://doi.org/10.1088/2632-2153/acf545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of the ionization potential and electron affinity energies of small molecules are important for many applications. Density functional theory (DFT) is computationally inexpensive, but can be very inaccurate for frontier orbital energies or ionization energies. The GW method is sufficiently accurate for many relevant applications, but much more expensive than DFT. Here we study how we can learn to predict orbital energies with GW accuracy using machine learning (ML) on molecular graphs and fingerprints using an interpretable delta-learning approach. ML models presented here can be used to predict quasiparticle energies of small organic molecules even beyond the size of the molecules used for training. We furthermore analyze the learned DFT-to-GW corrections by mapping them to specific localized fragments of the molecules, in order to develop an intuitive interpretation of the learned corrections, and thus to better understand DFT errors.},
  archive      = {J_MLST},
  author       = {Artem Fediai and Patrick Reiser and Jorge Enrique Olivares Peña and Wolfgang Wenzel and Pascal Friederich},
  doi          = {10.1088/2632-2153/acf545},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035045},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Interpretable delta-learning of GW quasiparticle energies from GGA-DFT},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). New angles on fast calorimeter shower simulation.
<em>MLST</em>, <em>4</em>(3), 035044. (<a
href="https://doi.org/10.1088/2632-2153/acefa9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The demands placed on computational resources by the simulation requirements of high energy physics experiments motivate the development of novel simulation tools. Machine learning based generative models offer a solution that is both fast and accurate. In this work we extend the Bounded Information Bottleneck Autoencoder (BIB-AE) architecture, designed for the simulation of particle showers in highly granular calorimeters, in two key directions. First, we generalise the model to a multi-parameter conditioning scenario, while retaining a high degree of physics fidelity. In a second step, we perform a detailed study of the effect of applying a state-of-the-art particle flow-based reconstruction procedure to the generated showers. We demonstrate that the performance of the model remains high after reconstruction. These results are an important step towards creating a more general simulation tool, where maintaining physics performance after reconstruction is the ultimate target.},
  archive      = {J_MLST},
  author       = {Sascha Diefenbacher and Engin Eren and Frank Gaede and Gregor Kasieczka and Anatolii Korol and Katja Krüger and Peter McKeown and Lennart Rustige},
  doi          = {10.1088/2632-2153/acefa9},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035044},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {New angles on fast calorimeter shower simulation},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated gadget discovery in the quantum domain.
<em>MLST</em>, <em>4</em>(3), 035043. (<a
href="https://doi.org/10.1088/2632-2153/acf098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, reinforcement learning (RL) has become increasingly successful in its application to the quantum domain and the process of scientific discovery in general. However, while RL algorithms learn to solve increasingly complex problems, interpreting the solutions they provide becomes ever more challenging. In this work, we gain insights into an RL agent&#39;s learned behavior through a post-hoc analysis based on sequence mining and clustering. Specifically, frequent and compact subroutines, used by the agent to solve a given task, are distilled as gadgets and then grouped by various metrics. This process of gadget discovery develops in three stages: First, we use an RL agent to generate data, then, we employ a mining algorithm to extract gadgets and finally, the obtained gadgets are grouped by a density-based clustering algorithm. We demonstrate our method by applying it to two quantum-inspired RL environments. First, we consider simulated quantum optics experiments for the design of high-dimensional multipartite entangled states where the algorithm finds gadgets that correspond to modern interferometer setups. Second, we consider a circuit-based quantum computing environment where the algorithm discovers various gadgets for quantum information processing, such as quantum teleportation. This approach for analyzing the policy of a learned agent is agent and environment agnostic and can yield interesting insights into any agent&#39;s policy.},
  archive      = {J_MLST},
  author       = {Lea M Trenkwalder and Andrea López-Incera and Hendrik Poulsen Nautrup and Fulvio Flamini and Hans J Briegel},
  doi          = {10.1088/2632-2153/acf098},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035043},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Automated gadget discovery in the quantum domain},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Configurable calorimeter simulation for AI applications.
<em>MLST</em>, <em>4</em>(3), 035042. (<a
href="https://doi.org/10.1088/2632-2153/acf186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A configurable calorimeter simulation for AI (CoCoA) applications is presented, based on the Geant4 toolkit and interfaced with the Pythia event generator. This open-source project is aimed to support the development of machine learning algorithms in high energy physics that rely on realistic particle shower descriptions, such as reconstruction, fast simulation, and low-level analysis. Specifications such as the granularity and material of its nearly hermetic geometry are user-configurable. The tool is supplemented with simple event processing including topological clustering, jet algorithms, and a nearest-neighbors graph construction. Formatting is also provided to visualise events using the Phoenix event display software.},
  archive      = {J_MLST},
  author       = {Anton Charkin-Gorbulin and Kyle Cranmer and Francesco Armando Di Bello and Etienne Dreyer and Sanmay Ganguly and Eilam Gross and Lukas Heinrich and Marumi Kado and Nilotpal Kakati and Patrick Rieck and Lorenzo Santi and Matteo Tusoni},
  doi          = {10.1088/2632-2153/acf186},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035042},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Configurable calorimeter simulation for AI applications},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving resilience of sensors in planetary exploration
using data-driven models. <em>MLST</em>, <em>4</em>(3), 035041. (<a
href="https://doi.org/10.1088/2632-2153/acefaa">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the resilience of sensor systems in space exploration is a key objective since the environmental conditions to which they are exposed are very harsh. For example, it is known that the presence of flying debris and Dust Devils on the Martian surface can partially damage sensors present in rovers/landers. The objective of this work is to show how data-driven methods can improve sensor resilience, particularly in the case of complex sensors, with multiple intermediate variables, feeding an inverse algorithm (IA) based on calibration data. The method considers three phases: an initial phase in which the sensor is calibrated in the laboratory and an IA is designed; a second phase, in which the sensor is placed at its intended location and sensor data is used to train data-driven model; and a third phase, once the model has been trained and partial damage is detected, in which the data-driven algorithm is reducing errors. The proposed method is tested with the intermediate data of the wind sensor of the TWINS instrument (NASA InSight mission), consisting of two booms placed on the deck of the lander, and three boards per boom. Wind speed and angle are recovered from the intermediate variables provided by the sensor and predicted by the proposed method. A comparative analysis of various data-driven methods including machine learning and deep learning (DL) methods is carried out for the proposed research. It is shown that even a simple method such as k-nearest neighbor is capable of successfully recovering missing data of a board compared to complex DL models. Depending on the selected missing board, errors are reduced by a factor between 2.43 and 4.78, for horizontal velocity; and by a factor between 1.74 and 4.71, for angle, compared with the situation of using only the two remaining boards.},
  archive      = {J_MLST},
  author       = {Dileep Kumar and Manuel Dominguez-Pumar and Elisa Sayrol-Clols and Josefina Torres and Mercedes Marín and Javier Gómez-Elvira and Luis Mora and Sara Navarro and Jose Rodríguez-Manfredi},
  doi          = {10.1088/2632-2153/acefaa},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035041},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Improving resilience of sensors in planetary exploration using data-driven models},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards a phenomenological understanding of neural networks:
data. <em>MLST</em>, <em>4</em>(3), 035040. (<a
href="https://doi.org/10.1088/2632-2153/acf099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A theory of neural networks (NNs) built upon collective variables would provide scientists with the tools to better understand the learning process at every stage. In this work, we introduce two such variables, the entropy and the trace of the empirical neural tangent kernel (NTK) built on the training data passed to the model. We empirically analyze the NN performance in the context of these variables and find that there exists correlation between the starting entropy, the trace of the NTK, and the generalization of the model computed after training is complete. This framework is then applied to the problem of optimal data selection for the training of NNs. To this end, random network distillation (RND) is used as a means of selecting training data which is then compared with random selection of data. It is shown that not only does RND select data-sets capable of outperforming random selection, but that the collective variables associated with the RND data-sets are larger than those of the randomly selected sets. The results of this investigation provide a stable ground from which the selection of data for NN training can be driven by this phenomenological framework.},
  archive      = {J_MLST},
  author       = {Samuel Tovey and Sven Krippendorf and Konstantin Nikolaou and Christian Holm},
  doi          = {10.1088/2632-2153/acf099},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035040},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Towards a phenomenological understanding of neural networks: Data},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimating gibbs free energies via isobaric-isothermal
flows. <em>MLST</em>, <em>4</em>(3), 035039. (<a
href="https://doi.org/10.1088/2632-2153/acefa8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a machine-learning model based on normalizing flows that is trained to sample from the isobaric-isothermal ensemble. In our approach, we approximate the joint distribution of a fully-flexible triclinic simulation box and particle coordinates to achieve a desired internal pressure. This novel extension of flow-based sampling to the isobaric-isothermal ensemble yields direct estimates of Gibbs free energies. We test our NPT -flow on monatomic water in the cubic and hexagonal ice phases and find excellent agreement of Gibbs free energies and other observables compared with established baselines.},
  archive      = {J_MLST},
  author       = {Peter Wirnsberger and Borja Ibarz and George Papamakarios},
  doi          = {10.1088/2632-2153/acefa8},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035039},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Estimating gibbs free energies via isobaric-isothermal flows},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning-based detection and identification of brain
tumor biomarkers in quantitative MR-images. <em>MLST</em>,
<em>4</em>(3), 035038. (<a
href="https://doi.org/10.1088/2632-2153/acf095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The infiltrative nature of malignant gliomas results in active tumor spreading into the peritumoral edema, which is not visible in conventional magnetic resonance imaging (cMRI) even after contrast injection. MR relaxometry (qMRI) measures relaxation rates dependent on tissue properties and can offer additional contrast mechanisms to highlight the non-enhancing infiltrative tumor. To investigate if qMRI data provides additional information compared to cMRI sequences when considering deep learning-based brain tumor detection and segmentation, preoperative conventional (T1w per- and post-contrast, T2w and FLAIR) and quantitative (pre- and post-contrast R 1 , R 2 and proton density) MR data was obtained from 23 patients with typical radiological findings suggestive of a high-grade glioma. 2D deep learning models were trained on transversal slices ( n = 528) for tumor detection and segmentation using either cMRI or qMRI. Moreover, trends in quantitative R 1 and R 2 rates of regions identified as relevant for tumor detection by model explainability methods were qualitatively analyzed. Tumor detection and segmentation performance for models trained with a combination of qMRI pre- and post-contrast was the highest (detection Matthews correlation coefficient (MCC) = 0.72, segmentation dice similarity coefficient (DSC) = 0.90), however, the difference compared to cMRI was not statistically significant. Overall analysis of the relevant regions identified using model explainability showed no differences between models trained on cMRI or qMRI. When looking at the individual cases, relaxation rates of brain regions outside the annotation and identified as relevant for tumor detection exhibited changes after contrast injection similar to region inside the annotation in the majority of cases. In conclusion, models trained on qMRI data obtained similar detection and segmentation performance to those trained on cMRI data, with the advantage of quantitatively measuring brain tissue properties within a similar scan time. When considering individual patients, the analysis of relaxation rates of regions identified by model explainability suggests the presence of infiltrative tumor outside the cMRI-based tumor annotation.},
  archive      = {J_MLST},
  author       = {Iulian Emil Tampu and Neda Haj-Hosseini and Ida Blystad and Anders Eklund},
  doi          = {10.1088/2632-2153/acf095},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035038},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Deep learning-based detection and identification of brain tumor biomarkers in quantitative MR-images},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-equivariant conditional normalizing flows, with
applications to target-aware molecule generation. <em>MLST</em>,
<em>4</em>(3), 035037. (<a
href="https://doi.org/10.1088/2632-2153/ace58c">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning over the domain of 3D graphs has applications in a number of scientific and engineering disciplines, including molecular chemistry, high energy physics, and computer vision. We consider a specific problem in this domain, namely: given one such 3D graph, dubbed the base graph, our goal is to learn a conditional distribution over another such graph, dubbed the complement graph. Due to the three-dimensional nature of the graphs in question, there are certain natural invariances such a distribution should satisfy: it should be invariant to rigid body transformations that act jointly on the base graph and the complement graph, and it should also be invariant to permutations of the vertices of either graph. We propose a general method for learning the conditional probabilistic model, the central part of which is a continuous normalizing flow. We establish semi-equivariance conditions on the flow which guarantee the aforementioned invariance conditions on the conditional distribution. Additionally, we propose a graph neural network architecture which implements this flow, and which is designed to learn effectively despite the typical differences in size between the base graph and the complement graph. We demonstrate the utility of our technique in the molecular setting by training a conditional generative model which, given a receptor, can generate ligands which may successfully bind to that receptor. The resulting model, which has potential applications in drug design, displays high quality performance in the key ΔBinding metric.},
  archive      = {J_MLST},
  author       = {Eyal Rozenberg and Daniel Freedman},
  doi          = {10.1088/2632-2153/ace58c},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035037},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Semi-equivariant conditional normalizing flows, with applications to target-aware molecule generation},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Manifold learning in atomistic simulations: A conceptual
review. <em>MLST</em>, <em>4</em>(3), 031001. (<a
href="https://doi.org/10.1088/2632-2153/ace81a">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing large volumes of high-dimensional data requires dimensionality reduction: finding meaningful low-dimensional structures hidden in their high-dimensional observations. Such practice is needed in atomistic simulations of complex systems where even thousands of degrees of freedom are sampled. An abundance of such data makes gaining insight into a specific physical problem strenuous. Our primary aim in this review is to focus on unsupervised machine learning methods that can be used on simulation data to find a low-dimensional manifold providing a collective and informative characterization of the studied process. Such manifolds can be used for sampling long-timescale processes and free-energy estimation. We describe methods that can work on datasets from standard and enhanced sampling atomistic simulations. Unlike recent reviews on manifold learning for atomistic simulations, we consider only methods that construct low-dimensional manifolds based on Markov transition probabilities between high-dimensional samples. We discuss these techniques from a conceptual point of view, including their underlying theoretical frameworks and possible limitations.},
  archive      = {J_MLST},
  author       = {Jakub Rydzewski and Ming Chen and Omar Valsson},
  doi          = {10.1088/2632-2153/ace81a},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {031001},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Manifold learning in atomistic simulations: A conceptual review},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An exponentially-growing family of universal quantum
circuits. <em>MLST</em>, <em>4</em>(3), 035036. (<a
href="https://doi.org/10.1088/2632-2153/ace757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum machine learning has become an area of growing interest but has certain theoretical and hardware-specific limitations. Notably, the problem of vanishing gradients, or barren plateaus, renders the training impossible for circuits with high qubit counts, imposing a limit on the number of qubits that data scientists can use for solving problems. Independently, angle-embedded supervised quantum neural networks were shown to produce truncated Fourier series with a degree directly dependent on two factors: the depth of the encoding and the number of parallel qubits the encoding applied to. The degree of the Fourier series limits the model expressivity. This work introduces two new architectures whose Fourier degrees grow exponentially: the sequential and parallel exponential quantum machine learning architectures. This is done by efficiently using the available Hilbert space when encoding, increasing the expressivity of the quantum encoding. Therefore, the exponential growth allows staying at the low-qubit limit to create highly expressive circuits avoiding barren plateaus. Practically, parallel exponential architecture was shown to outperform the existing linear architectures by reducing their final mean square error value by up to 44.7% in a one-dimensional test problem. Furthermore, the feasibility of this technique was also shown on a trapped ion quantum processing unit.},
  archive      = {J_MLST},
  author       = {Mo Kordzanganeh and Pavel Sekatski and Leonid Fedichkin and Alexey Melnikov},
  doi          = {10.1088/2632-2153/ace757},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035036},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {An exponentially-growing family of universal quantum circuits},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven plasma modelling: Surrogate collisional
radiative models of fluorocarbon plasmas from deep generative
autoencoders. <em>MLST</em>, <em>4</em>(3), 035035. (<a
href="https://doi.org/10.1088/2632-2153/aced7f">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We have developed a deep generative model that can produce accurate optical emission spectra and colour images of an ICP plasma using only the applied coil power, electrode power, pressure and gas flows as inputs—essentially an empirical surrogate collisional radiative model. An autoencoder was trained on a dataset of 812 500 image/spectra pairs in argon, oxygen, Ar/O 2 , CF 4 /O 2 and SF 6 /O 2 plasmas in an industrial plasma etch tool, taken across the entire operating space of the tool. The autoencoder learns to encode the input data into a compressed latent representation and then decode it back to a reconstruction of the data. We learn to map the plasma tool&#39;s inputs to the latent space and use the decoder to create a generative model. The model is very fast, taking just over 10 s to generate 10 000 measurements on a single GPU. This type of model can become a building block for a wide range of experiments and simulations. To aid this, we have released the underlying dataset of 812 500 image/spectra pairs used to train the model, the trained models and the model code for the community to accelerate the development and use of this exciting area of deep learning. Anyone can try the model, for free, on Google Colab.},
  archive      = {J_MLST},
  author       = {G A Daly and J E Fieldsend and G Hassall and G R Tabor},
  doi          = {10.1088/2632-2153/aced7f},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035035},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Data-driven plasma modelling: Surrogate collisional radiative models of fluorocarbon plasmas from deep generative autoencoders},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A study of transfer learning in digital rock properties
measurement. <em>MLST</em>, <em>4</em>(3), 035034. (<a
href="https://doi.org/10.1088/2632-2153/acf117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The measurement of physical parameters of porous rock, which constitute reservoirs, is an essential part of hydrocarbon exploration. Typically, the measurement of these physical parameters is carried out through core analysis in a laboratory, which requires considerable time and high costs. Another approach involves using digital rock models, where the physical parameters are calculated through image processing and numerical simulations. However, this method also requires a significant amount of time for estimating the physical parameters of each rock sample. Machine learning, specifically convolutional neural network (CNN) algorithms, has been developed as an alternative method for estimating the physical parameters of porous rock in a shorter time frame. The advancement of CNN, particularly through transfer learning using pre-trained models, has contributed to rapid prediction capabilities. However, not all pre-trained models are suitable for estimating the physical parameters of porous rock. In this study, transfer learning was applied to estimate parameters of sandstones such as porosity, specific surface area, average grain size, average coordination number, and average throat radius. Six types of pre-trained models were utilized: ResNet152, DenseNet201, Xception, InceptionV3, InceptionResNetV2, and MobileNetV2. The results of this study indicate that the DenseNet201 model achieved the best performance with an error rate of 2.11%. Overall, this study highlights the potential of transfer learning to ultimately lead to more efficient and effective computation.},
  archive      = {J_MLST},
  author       = {M I K Haq and I N Yulita and I A Dharmawan},
  doi          = {10.1088/2632-2153/acf117},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035034},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A study of transfer learning in digital rock properties measurement},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Error scaling laws for kernel classification under source
and capacity conditions. <em>MLST</em>, <em>4</em>(3), 035033. (<a
href="https://doi.org/10.1088/2632-2153/acf041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this manuscript we consider the problem of kernel classification. While worst-case bounds on the decay rate of the prediction error with the number of samples are known for some classifiers, they often fail to accurately describe the learning curves of real data sets. In this work, we consider the important class of data sets satisfying the standard source and capacity conditions, comprising a number of real data sets as we show numerically. Under the Gaussian design, we derive the decay rates for the misclassification (prediction) error as a function of the source and capacity coefficients. We do so for two standard kernel classification settings, namely margin-maximizing support vector machines and ridge classification, and contrast the two methods. We find that our rates tightly describe the learning curves for this class of data sets, and are also observed on real data. Our results can also be seen as an explicit prediction of the exponents of a scaling law for kernel classification that is accurate on some real datasets.},
  archive      = {J_MLST},
  author       = {Hugo Cui and Bruno Loureiro and Florent Krzakala and Lenka Zdeborová},
  doi          = {10.1088/2632-2153/acf041},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035033},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Error scaling laws for kernel classification under source and capacity conditions},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Physics-informed neural networks for modeling astrophysical
shocks. <em>MLST</em>, <em>4</em>(3), 035032. (<a
href="https://doi.org/10.1088/2632-2153/acf116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-informed neural networks (PINNs) are machine learning models that integrate data-based learning with partial differential equations (PDEs). In this work, for the first time we extend PINNs to model the numerically challenging case of astrophysical shock waves in the presence of a stellar gravitational field. Notably, PINNs suffer from competing losses during gradient descent that can lead to poor performance especially in physical setups involving multiple scales, which is the case for shocks in the gravitationally stratified solar atmosphere. We applied PINNs in three different setups ranging from modeling astrophysical shocks in cases with no or little data to data-intensive cases. Namely, we used PINNs (a) to determine the effective polytropic index controlling the heating mechanism of the space plasma within 1% error, (b) to quantitatively show that data assimilation is seamless in PINNs and small amounts of data can significantly increase the model&#39;s accuracy, and (c) to solve the forward time-dependent problem for different temporal horizons. We addressed the poor performance of PINNs through an effective normalization approach by reformulating the fluid dynamics PDE system to absorb the gravity-caused variability. This led to a huge improvement in the overall model performance with the density accuracy improving between 2 and 16 times. Finally, we present a detailed critique on the strengths and drawbacks of PINNs in tackling realistic physical problems in astrophysics and conclude that PINNs can be a powerful complimentary modeling approach to classical fluid dynamics solvers.},
  archive      = {J_MLST},
  author       = {S P Moschou and E Hicks and R Y Parekh and D Mathew and S Majumdar and N Vlahakis},
  doi          = {10.1088/2632-2153/acf116},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035032},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Physics-informed neural networks for modeling astrophysical shocks},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data efficiency and extrapolation trends in neural network
interatomic potentials. <em>MLST</em>, <em>4</em>(3), 035031. (<a
href="https://doi.org/10.1088/2632-2153/acf115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, key architectural advances have been proposed for neural network interatomic potentials (NNIPs), such as incorporating message-passing networks, equivariance, or many-body expansion terms. Although modern NNIP models exhibit small differences in test accuracy, this metric is still considered the main target when developing new NNIP architectures. In this work, we show how architectural and optimization choices influence the generalization of NNIPs, revealing trends in molecular dynamics (MD) stability, data efficiency, and loss landscapes. Using the 3BPA dataset, we uncover trends in NNIP errors and robustness to noise, showing these metrics are insufficient to predict MD stability in the high-accuracy regime. With a large-scale study on NequIP, MACE, and their optimizers, we show that our metric of loss entropy predicts out-of-distribution error and data efficiency despite being computed only on the training set. This work provides a deep learning justification for probing extrapolation and can inform the development of next-generation NNIPs.},
  archive      = {J_MLST},
  author       = {Joshua A Vita and Daniel Schwalbe-Koda},
  doi          = {10.1088/2632-2153/acf115},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035031},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Data efficiency and extrapolation trends in neural network interatomic potentials},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving materials property predictions for graph neural
networks with minimal feature engineering *. <em>MLST</em>,
<em>4</em>(3), 035030. (<a
href="https://doi.org/10.1088/2632-2153/acefab">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have been employed in materials research to predict physical and functional properties, and have achieved superior performance in several application domains over prior machine learning approaches. Recent studies incorporate features of increasing complexity such as Gaussian radial functions, plane wave functions, and angular terms to augment the neural network models, with the expectation that these features are critical for achieving a high performance. Here, we propose a GNN that adopts edge convolution where hidden edge features evolve during training and extensive attention mechanisms, and operates on simple graphs with atoms as nodes and distances between them as edges. As a result, the same model can be used for very different tasks as no other domain-specific features are used. With a model that uses no feature engineering, we achieve performance comparable with state-of-the-art models with elaborate features for formation energy and band gap prediction with standard benchmarks; we achieve even better performance when the dataset size increases. Although some domain-specific datasets still require hand-crafted features to achieve state-of-the-art results, our selected architecture choices greatly reduce the need for elaborate feature engineering and still maintain predictive power in comparison.},
  archive      = {J_MLST},
  author       = {Guojing Cong and Victor Fung},
  doi          = {10.1088/2632-2153/acefab},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035030},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Improving materials property predictions for graph neural networks with minimal feature engineering *},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast kernel methods for data quality monitoring as a
goodness-of-fit test. <em>MLST</em>, <em>4</em>(3), 035029. (<a
href="https://doi.org/10.1088/2632-2153/acebb7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an accurate and efficient machine learning approach for monitoring particle detectors in real-time. The goal is to assess the compatibility of incoming experimental data with a reference dataset, characterising the data behaviour under normal circumstances, via a likelihood-ratio hypothesis test. The model is based on a modern implementation of kernel methods, nonparametric algorithms that can learn any continuous function given enough data. The resulting approach is efficient and agnostic to the type of anomaly that may be present in the data. Our study demonstrates the effectiveness of this strategy on multivariate data from drift tube chamber muon detectors.},
  archive      = {J_MLST},
  author       = {Gaia Grosso and Nicolò Lai and Marco Letizia and Jacopo Pazzini and Marco Rando and Lorenzo Rosasco and Andrea Wulzer and Marco Zanetti},
  doi          = {10.1088/2632-2153/acebb7},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035029},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Fast kernel methods for data quality monitoring as a goodness-of-fit test},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated visual inspection of CMS HGCAL silicon sensor
surface using an ensemble of a deep convolutional autoencoder and
classifier. <em>MLST</em>, <em>4</em>(3), 035028. (<a
href="https://doi.org/10.1088/2632-2153/aced7e">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {More than a thousand 8&#39;&#39; silicon sensors will be visually inspected to look for anomalies on their surface during the quality control preceding assembly into the High-Granularity Calorimeter for the CMS experiment at CERN. A deep learning-based algorithm that pre-selects potentially anomalous images of the sensor surface in real time was developed to automate the visual inspection. The anomaly detection is done by an ensemble of independent deep convolutional neural networks: an autoencoder and a classifier. The algorithm was deployed and has been continuously running in production, and data gathered were used to evaluate its performance. The pre-selection reduces the number of images requiring human inspection by 85%, with recall of 97%, and saves 15 person-hours per a batch of a hundred sensors. Data gathered in production can be used for continuous learning to improve the accuracy incrementally.},
  archive      = {J_MLST},
  author       = {Sonja Grönroos and Maurizio Pierini and Nadezda Chernyavskaya},
  doi          = {10.1088/2632-2153/aced7e},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035028},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Automated visual inspection of CMS HGCAL silicon sensor surface using an ensemble of a deep convolutional autoencoder and classifier},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reflection equivariant quantum neural networks for enhanced
image classification. <em>MLST</em>, <em>4</em>(3), 035027. (<a
href="https://doi.org/10.1088/2632-2153/acf096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning is among the most widely anticipated use cases for near-term quantum computers, however there remain significant theoretical and implementation challenges impeding its scale up. In particular, there is an emerging body of work which suggests that generic, data agnostic quantum machine learning (QML) architectures may suffer from severe trainability issues, with the gradient of typical variational parameters vanishing exponentially in the number of qubits. Additionally, the high expressibility of QML models can lead to overfitting on training data and poor generalisation performance. A promising strategy to combat both of these difficulties is to construct models which explicitly respect the symmetries inherent in their data, so-called geometric quantum machine learning (GQML). In this work, we utilise the techniques of GQML for the task of image classification, building new QML models which are equivariant with respect to reflections of the images. We find that these networks are capable of consistently and significantly outperforming generic ansatze on complicated real-world image datasets, bringing high-resolution image classification via quantum computers closer to reality. Our work highlights a potential pathway for the future development and implementation of powerful QML models which directly exploit the symmetries of data.},
  archive      = {J_MLST},
  author       = {Maxwell T West and Martin Sevior and Muhammad Usman},
  doi          = {10.1088/2632-2153/acf096},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035027},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Reflection equivariant quantum neural networks for enhanced image classification},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph neural networks and 3-dimensional topology.
<em>MLST</em>, <em>4</em>(3), 035026. (<a
href="https://doi.org/10.1088/2632-2153/acf097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We test the efficiency of applying geometric deep learning to the problems in low-dimensional topology in a certain simple setting. Specifically, we consider the class of 3-manifolds described by plumbing graphs and use graph neural networks (GNN) for the problem of deciding whether a pair of graphs give homeomorphic 3-manifolds. We use supervised learning to train a GNN that provides the answer to such a question with high accuracy. Moreover, we consider reinforcement learning by a GNN to find a sequence of Neumann moves that relates the pair of graphs if the answer is positive. The setting can be understood as a toy model of the problem of deciding whether a pair of Kirby diagrams give diffeomorphic 3- or 4-manifolds.},
  archive      = {J_MLST},
  author       = {Song Jin Ri and Pavel Putrov},
  doi          = {10.1088/2632-2153/acf097},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035026},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Graph neural networks and 3-dimensional topology},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Molecular machine learning with conformer ensembles.
<em>MLST</em>, <em>4</em>(3), 035025. (<a
href="https://doi.org/10.1088/2632-2153/acefa7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual screening can accelerate drug discovery by identifying promising candidates for experimental evaluation. Machine learning is a powerful method for screening, as it can learn complex structure–property relationships from experimental data and make rapid predictions over virtual libraries. Molecules inherently exist as a three-dimensional ensemble and their biological action typically occurs through supramolecular recognition. However, most deep learning approaches to molecular property prediction use a 2D graph representation as input, and in some cases a single 3D conformation. Here we investigate how the 3D information of multiple conformers, traditionally known as 4D information in the cheminformatics community, can improve molecular property prediction in deep learning models. We introduce multiple deep learning models that expand upon key architectures such as ChemProp and SchNet, adding elements such as multiple-conformer inputs and conformer attention. We then benchmark the performance trade-offs of these models on 2D, 3D and 4D representations in the prediction of drug activity using a large training set of geometrically resolved molecules. The new architectures perform significantly better than 2D models, but their performance is often just as strong with a single conformer as with many. We also find that 4D deep learning models learn interpretable attention weights for each conformer.},
  archive      = {J_MLST},
  author       = {Simon Axelrod and Rafael Gómez-Bombarelli},
  doi          = {10.1088/2632-2153/acefa7},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035025},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Molecular machine learning with conformer ensembles},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Denoising gravitational-wave signals from binary black holes
with a dilated convolutional autoencoder. <em>MLST</em>, <em>4</em>(3),
035024. (<a href="https://doi.org/10.1088/2632-2153/acd90f">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The broadband frequency output of gravitational-wave (GW) detectors is a non-stationary and non-Gaussian time series data stream dominated by noise populated by local disturbances and transient artifacts, which evolve on the same timescale as the GW signals and may corrupt the astrophysical information. We study a denoising algorithm dedicated to expose the astrophysical signals by employing a convolutional neural network in the encoder-decoder configuration, i.e. apply the denoising procedure of coalescing binary black hole signals to the publicly available LIGO O1 time series strain data. The denoising convolutional autoencoder neural network is trained on a dataset of simulated astrophysical signals injected into the real detector&#39;s noise and a dataset of detector noise artifacts (&#39;glitches&#39;), and its fidelity is tested on real GW events from O1 and O2 LIGO-Virgo observing runs.},
  archive      = {J_MLST},
  author       = {Philippe Bacon and Agata Trovato and Michał Bejger},
  doi          = {10.1088/2632-2153/acd90f},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035024},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Denoising gravitational-wave signals from binary black holes with a dilated convolutional autoencoder},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven modeling of noise time series with convolutional
generative adversarial networks ∗. <em>MLST</em>, <em>4</em>(3), 035023.
(<a href="https://doi.org/10.1088/2632-2153/acee44">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random noise arising from physical processes is an inherent characteristic of measurements and a limiting factor for most signal processing and data analysis tasks. Given the recent interest in generative adversarial networks (GANs) for data-driven modeling, it is important to determine to what extent GANs can faithfully reproduce noise in target data sets. In this paper, we present an empirical investigation that aims to shed light on this issue for time series. Namely, we assess two general-purpose GANs for time series that are based on the popular deep convolutional GAN architecture, a direct time-series model and an image-based model that uses a short-time Fourier transform data representation. The GAN models are trained and quantitatively evaluated using distributions of simulated noise time series with known ground-truth parameters. Target time series distributions include a broad range of noise types commonly encountered in physical measurements, electronics, and communication systems: band-limited thermal noise, power law noise, shot noise, and impulsive noise. We find that GANs are capable of learning many noise types, although they predictably struggle when the GAN architecture is not well suited to some aspects of the noise, e.g. impulsive time-series with extreme outliers. Our findings provide insights into the capabilities and potential limitations of current approaches to time-series GANs and highlight areas for further research. In addition, our battery of tests provides a useful benchmark to aid the development of deep generative models for time series.},
  archive      = {J_MLST},
  author       = {Adam Wunderlich and Jack Sklar},
  doi          = {10.1088/2632-2153/acee44},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035023},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Data-driven modeling of noise time series with convolutional generative adversarial networks ∗},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine-learning kohn–sham potential from dynamics in
time-dependent kohn–sham systems. <em>MLST</em>, <em>4</em>(3), 035022.
(<a href="https://doi.org/10.1088/2632-2153/ace8f0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The construction of a better exchange-correlation potential in time-dependent density functional theory (TDDFT) can improve the accuracy of TDDFT calculations and provide more accurate predictions of the properties of many-electron systems. Here, we propose a machine learning method to develop the energy functional and the Kohn–Sham potential of a time-dependent Kohn–Sham (TDKS) system is proposed. The method is based on the dynamics of the Kohn–Sham system and does not require any data on the exact Kohn–Sham potential for training the model. We demonstrate the results of our method with a 1D harmonic oscillator example and a 1D two-electron example. We show that the machine-learned Kohn–Sham potential matches the exact Kohn–Sham potential in the absence of memory effect. Our method can still capture the dynamics of the Kohn–Sham system in the presence of memory effects. The machine learning method developed in this article provides insight into making better approximations of the energy functional and the Kohn–Sham potential in the TDKS system.},
  archive      = {J_MLST},
  author       = {Jun Yang and James Whitfield},
  doi          = {10.1088/2632-2153/ace8f0},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035022},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Machine-learning Kohn–Sham potential from dynamics in time-dependent Kohn–Sham systems},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transfer learning application of self-supervised learning in
ARPES. <em>MLST</em>, <em>4</em>(3), 035021. (<a
href="https://doi.org/10.1088/2632-2153/aced7d">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a growing recognition that electronic band structure is a local property of materials and devices, and there is steep growth in capabilities to collect the relevant data. New photon sources, from small-laboratory-based lasers to free electron lasers, together with focusing beam optics and advanced electron spectrometers, are beginning to enable angle-resolved photoemission spectroscopy (ARPES) in scanning mode with a spatial resolution of near to and below microns, two- to three orders of magnitude smaller than what has been typical for ARPES hitherto. The results are vast data sets inhabiting a five-dimensional subspace of the ten-dimensional space spanned by two scanning dimensions of real space, three of reciprocal space, three of spin-space, time, and energy. In this work, we demonstrate that recent developments in representational learning (self-supervised learning) combined with k -means clustering can help automate the labeling and spatial mapping of dispersion cuts, thus saving precious time relative to manual analysis, albeit with low performance. Finally, we introduce a few-shot learning ( k -nearest neighbor) in representational space where we selectively choose one ( k = 1) image reference for each known label and subsequently label the rest of the data with respect to the nearest reference image. This last approach demonstrates the strength of self-supervised learning to automate image analysis in ARPES in particular and can be generalized to any scientific image analysis.},
  archive      = {J_MLST},
  author       = {Sandy Adhitia Ekahana and Genta Indra Winata and Y Soh and Anna Tamai and Radovic Milan and Gabriel Aeppli and Ming Shi},
  doi          = {10.1088/2632-2153/aced7d},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035021},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Transfer learning application of self-supervised learning in ARPES},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust and provably monotonic networks. <em>MLST</em>,
<em>4</em>(3), 035020. (<a
href="https://doi.org/10.1088/2632-2153/aced80">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Lipschitz constant of the map between the input and output space represented by a neural network is a natural metric for assessing the robustness of the model. We present a new method to constrain the Lipschitz constant of dense deep learning models that can also be generalized to other architectures. The method relies on a simple weight normalization scheme during training that ensures the Lipschitz constant of every layer is below an upper limit specified by the analyst. A simple monotonic residual connection can then be used to make the model monotonic in any subset of its inputs, which is useful in scenarios where domain knowledge dictates such dependence. Examples can be found in algorithmic fairness requirements or, as presented here, in the classification of the decays of subatomic particles produced at the CERN Large Hadron Collider. Our normalization is minimally constraining and allows the underlying architecture to maintain higher expressiveness compared to other techniques which aim to either control the Lipschitz constant of the model or ensure its monotonicity. We show how the algorithm was used to train a powerful, robust, and interpretable discriminator for heavy-flavor-quark decays, which has been adopted for use as the primary data-selection algorithm in the LHCb real-time data-processing system in the current LHC data-taking period known as Run 3. In addition, our algorithm has also achieved state-of-the-art performance on benchmarks in medicine, finance, and other applications.},
  archive      = {J_MLST},
  author       = {Ouail Kitouni and Niklas Nolte and Mike Williams},
  doi          = {10.1088/2632-2153/aced80},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035020},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Robust and provably monotonic networks},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The effects of topological features on convolutional neural
networks—an explanatory analysis via grad-CAM. <em>MLST</em>,
<em>4</em>(3), 035019. (<a
href="https://doi.org/10.1088/2632-2153/ace6f3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topological data analysis (TDA) characterizes the global structure of data based on topological invariants such as persistent homology, whereas convolutional neural networks (CNNs) are capable of characterizing local features in the global structure of the data. In contrast, a combined model of TDA and CNN, a family of multimodal networks, simultaneously takes the image and the corresponding topological features as the input to the network for classification, thereby significantly improving the performance of a single CNN. This innovative approach has been recently successful in various applications. However, there is a lack of explanation regarding how and why topological signatures, when combined with a CNN, improve discriminative power. In this paper, we use persistent homology to compute topological features and subsequently demonstrate both qualitatively and quantitatively the effects of topological signatures on a CNN model, for which the Grad-CAM analysis of multimodal networks and topological inverse image map are proposed and appropriately utilized. For experimental validation, we utilize two famous datasets: the transient versus bogus image dataset and the HAM10000 dataset. Using Grad-CAM analysis of multimodal networks, we demonstrate that topological features enforce the image network of a CNN to focus more on significant and meaningful regions across images rather than task-irrelevant artifacts such as background noise and texture.},
  archive      = {J_MLST},
  author       = {Dongjin Lee and Seong-Heon Lee and Jae-Hun Jung},
  doi          = {10.1088/2632-2153/ace6f3},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035019},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {The effects of topological features on convolutional neural networks—an explanatory analysis via grad-CAM},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Anomaly detection in aeronautics data with
quantum-compatible discrete deep generative model. <em>MLST</em>,
<em>4</em>(3), 035018. (<a
href="https://doi.org/10.1088/2632-2153/ace756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep generative learning cannot only be used for generating new data with statistical characteristics derived from input data but also for anomaly detection, by separating nominal and anomalous instances based on their reconstruction quality. In this paper, we explore the performance of three unsupervised deep generative models—variational autoencoders (VAEs) with Gaussian, Bernoulli, and Boltzmann priors—in detecting anomalies in multivariate time series of commercial-flight operations. We created two VAE models with discrete latent variables (DVAEs), one with a factorized Bernoulli prior and one with a restricted Boltzmann machine (RBM) with novel positive-phase architecture as prior, because of the demand for discrete-variable models in machine-learning applications and because the integration of quantum devices based on two-level quantum systems requires such models. To the best of our knowledge, our work is the first that applies DVAE models to anomaly-detection tasks in the aerospace field. The DVAE with RBM prior, using a relatively simple—and classically or quantum-mechanically enhanceable—sampling technique for the evolution of the RBM&#39;s negative phase, performed better in detecting anomalies than the Bernoulli DVAE and on par with the Gaussian model, which has a continuous latent space. The transfer of a model to an unseen dataset with the same anomaly but without re-tuning of hyperparameters or re-training noticeably impaired anomaly-detection performance, but performance could be improved by post-training on the new dataset. The RBM model was robust to change of anomaly type and phase of flight during which the anomaly occurred. Our studies demonstrate the competitiveness of a discrete deep generative model with its Gaussian counterpart on anomaly-detection problems. Moreover, the DVAE model with RBM prior can be easily integrated with quantum sampling by outsourcing its generative process to measurements of quantum states obtained from a quantum annealer or gate-model device.},
  archive      = {J_MLST},
  author       = {Thomas Templin and Milad Memarzadeh and Walter Vinci and P Aaron Lott and Ata Akbari Asanjan and Anthony Alexiades Armenakas and Eleanor Rieffel},
  doi          = {10.1088/2632-2153/ace756},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035018},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Anomaly detection in aeronautics data with quantum-compatible discrete deep generative model},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural-prior stochastic block model. <em>MLST</em>,
<em>4</em>(3), 035017. (<a
href="https://doi.org/10.1088/2632-2153/ace60f">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stochastic block model (SBM) is widely studied as a benchmark for graph clustering aka community detection. In practice, graph data often come with node attributes that bear additional information about the communities. Previous works modeled such data by considering that the node attributes are generated from the node community memberships. In this work, motivated by a recent surge of works in signal processing using deep neural networks as priors, we propose to model the communities as being determined by the node attributes rather than the opposite. We define the corresponding model; we call it the neural-prior SBM. We propose an algorithm, stemming from statistical physics, based on a combination of belief propagation and approximate message passing. We analyze the performance of the algorithm as well as the Bayes-optimal performance. We identify detectability and exact recovery phase transitions, as well as an algorithmically hard region. The proposed model and algorithm can be used as a benchmark for both theory and algorithms. To illustrate this, we compare the optimal performances to the performance of simple graph neural networks.},
  archive      = {J_MLST},
  author       = {O Duranthon and L Zdeborová},
  doi          = {10.1088/2632-2153/ace60f},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035017},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Neural-prior stochastic block model},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of molecular field points using SE(3)-transformer
model. <em>MLST</em>, <em>4</em>(3), 035016. (<a
href="https://doi.org/10.1088/2632-2153/ace67b">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to their computational efficiency, 2D fingerprints are typically used in similarity-based high-content screening. The interaction of a ligand with its target protein, however, relies on its physicochemical interactions in 3D space. Thus, ligands with different 2D scaffolds can bind to the same protein if these ligands share similar interaction patterns. Molecular fields can represent those interaction profiles. For efficiency, the extrema of those molecular fields, named field points, are used to quantify the ligand similarity in 3D. The calculation of field points involves the evaluation of the interaction energy between the ligand and a small probe shifted on a fine grid representing the molecular surface. These calculations are computationally prohibitive for large datasets of ligands, making field point representations of molecules intractable for high-content screening. Here, we overcome this roadblock by one-shot prediction of field points using generative neural networks based on the molecular structure alone. Field points are predicted by training an SE(3)-Transformer, an equivariant, attention-based graph neural network architecture, on a large set of ligands with field point data. Resulting data demonstrates the feasibility of this approach to precisely generate negative, positive and hydrophobic field points within 0.5 Å of the ground truth for a diverse set of drug-like molecules.},
  archive      = {J_MLST},
  author       = {Florian B Hinz and Amr H Mahmoud and Markus A Lill},
  doi          = {10.1088/2632-2153/ace67b},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035016},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Prediction of molecular field points using SE(3)-transformer model},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep neural network approach for parameterized PDEs and
bayesian inverse problems. <em>MLST</em>, <em>4</em>(3), 035015. (<a
href="https://doi.org/10.1088/2632-2153/ace67c">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the simulation of Bayesian statistical inverse problems governed by large-scale linear and nonlinear partial differential equations (PDEs). Markov chain Monte Carlo (MCMC) algorithms are standard techniques to solve such problems. However, MCMC techniques are computationally challenging as they require a prohibitive number of forward PDE solves. The goal of this paper is to introduce a fractional deep neural network (fDNN) based approach for the forward solves within an MCMC routine. Moreover, we discuss some approximation error estimates. We illustrate the efficiency of fDNN on inverse problems governed by nonlinear elliptic PDEs and the unsteady Navier–Stokes equations. In the former case, two examples are discussed, respectively depending on two and 100 parameters, with significant observed savings. The unsteady Navier–Stokes example illustrates that fDNN can outperform existing DNNs, doing a better job of capturing essential features such as vortex shedding.},
  archive      = {J_MLST},
  author       = {Harbir Antil and Howard C Elman and Akwum Onwunta and Deepanshu Verma},
  doi          = {10.1088/2632-2153/ace67c},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035015},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A deep neural network approach for parameterized PDEs and bayesian inverse problems},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Standardizing chemical compounds with language models.
<em>MLST</em>, <em>4</em>(3), 035014. (<a
href="https://doi.org/10.1088/2632-2153/ace878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing amount of chemical data stored digitally, it has become crucial to represent chemical compounds accurately and consistently. Harmonized representations facilitate the extraction of insightful information from datasets, and are advantageous for machine learning applications. To achieve consistent representations throughout datasets, one relies on molecule standardization, which is typically accomplished using rule-based algorithms that modify descriptions of functional groups. Here, we present the first deep-learning model for molecular standardization. We enable custom standardization schemes based solely on data, which, as additional benefit, support standardization options that are difficult to encode into rules. Our model achieves over 98\% accuracy in learning two popular rule-based standardization protocols. We then follow a transfer learning approach to standardize metal-organic compounds (for which there is currently no automated standardization practice), based on a human-curated dataset of 1512 compounds. This model predicts the expected standardized molecular format with a test accuracy of 80.7%. As standardization can be considered, more broadly, a transformation from undesired to desired representations of compounds, the same data-driven architecture can be applied to other tasks. For instance, we demonstrate the application to compound canonicalization and to the determination of major tautomers in solution, based on computed and experimental data.},
  archive      = {J_MLST},
  author       = {Miruna T Cretu and Alessandra Toniato and Amol Thakkar and Amin A Debabeche and Teodoro Laino and Alain C Vaucher},
  doi          = {10.1088/2632-2153/ace878},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035014},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Standardizing chemical compounds with language models},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ScGMM-VGAE: A gaussian mixture model-based variational graph
autoencoder algorithm for clustering single-cell RNA-seq data.
<em>MLST</em>, <em>4</em>(3), 035013. (<a
href="https://doi.org/10.1088/2632-2153/acd7c3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cell type identification using single-cell RNA sequencing data is critical for understanding disease mechanisms and drug discovery. Cell clustering analysis has been widely studied in health research for rare tumor cell detection. In this study, we propose a Gaussian mixture model-based variational graph autoencoder on scRNA-seq data (scGMM-VGAE) that integrates a statistical clustering model to a deep learning algorithm to significantly improve the cell clustering performance. This model feeds a cell-cell graph adjacency matrix and a gene feature matrix into a graph variational autoencoder (VGAE) to generate latent data. These data are then used for cell clustering by the Gaussian mixture model (GMM) module. To optimize the algorithm, a designed loss function is derived by combining parameter estimates from the GMM and VGAE. We test the proposed method on four publicly available and three simulated datasets which contain many biological and technical zeros. The scGMM-VGAE outperforms four selected baseline methods on three evaluation metrics in cell clustering. By successfully incorporating GMM into deep learning VGAE on scRNA-seq data, the proposed method shows higher accuracy in cell clustering on scRNA-seq data. This improvement has a significant impact on detecting rare cell types in health research. All source codes used in this study can be found at https://github.com/ericlin1230/scGMM-VGAE .},
  archive      = {J_MLST},
  author       = {Eric Lin and Boyuan Liu and Leann Lac and Daryl L X Fung and Carson K Leung and Pingzhao Hu},
  doi          = {10.1088/2632-2153/acd7c3},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035013},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {ScGMM-VGAE: A gaussian mixture model-based variational graph autoencoder algorithm for clustering single-cell RNA-seq data},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Probability flow solution of the fokker–planck equation.
<em>MLST</em>, <em>4</em>(3), 035012. (<a
href="https://doi.org/10.1088/2632-2153/ace2aa">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The method of choice for integrating the time-dependent Fokker–Planck equation (FPE) in high-dimension is to generate samples from the solution via integration of the associated stochastic differential equation (SDE). Here, we study an alternative scheme based on integrating an ordinary differential equation that describes the flow of probability. Acting as a transport map, this equation deterministically pushes samples from the initial density onto samples from the solution at any later time. Unlike integration of the stochastic dynamics, the method has the advantage of giving direct access to quantities that are challenging to estimate from trajectories alone, such as the probability current, the density itself, and its entropy. The probability flow equation depends on the gradient of the logarithm of the solution (its &#39;score&#39;), and so is a-priori unknown. To resolve this dependence, we model the score with a deep neural network that is learned on-the-fly by propagating a set of samples according to the instantaneous probability current. We show theoretically that the proposed approach controls the Kullback–Leibler (KL) divergence from the learned solution to the target, while learning on external samples from the SDE does not control either direction of the KL divergence. Empirically, we consider several high-dimensional FPEs from the physics of interacting particle systems. We find that the method accurately matches analytical solutions when they are available as well as moments computed via Monte-Carlo when they are not. Moreover, the method offers compelling predictions for the global entropy production rate that out-perform those obtained from learning on stochastic trajectories, and can effectively capture non-equilibrium steady-state probability currents over long time intervals.},
  archive      = {J_MLST},
  author       = {Nicholas M Boffi and Eric Vanden-Eijnden},
  doi          = {10.1088/2632-2153/ace2aa},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035012},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Probability flow solution of the Fokker–Planck equation},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Importance nested sampling with normalising flows.
<em>MLST</em>, <em>4</em>(3), 035011. (<a
href="https://doi.org/10.1088/2632-2153/acd5aa">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an improved version of the nested sampling algorithm nessai in which the core algorithm is modified to use importance weights. In the modified algorithm, samples are drawn from a mixture of normalising flows and the requirement for samples to be independently and identically distributed (i.i.d.) according to the prior is relaxed. Furthermore, it allows for samples to be added in any order, independently of a likelihood constraint, and for the evidence to be updated with batches of samples. We call the modified algorithm i-nessai . We first validate i-nessai using analytic likelihoods with known Bayesian evidences and show that the evidence estimates are unbiased in up to 32 dimensions. We compare i-nessai to standard nessai for the analytic likelihoods and the Rosenbrock likelihood, the results show that i-nessai is consistent with nessai whilst producing more precise evidence estimates. We then test i-nessai on 64 simulated gravitational-wave signals from binary black hole coalescence and show that it produces unbiased estimates of the parameters. We compare our results to those obtained using standard nessai and dynesty and find that i-nessai requires 2.68 and 13.3 times fewer likelihood evaluations to converge, respectively. We also test i-nessai of an 80 s simulated binary neutron star signal using a reduced-order-quadrature basis and find that, on average, it converges in 24 min, whilst only requiring 1.01 \times 10^{6} likelihood evaluations compared to 1.42 \times 10^{6} for nessai and 4.30 \times 10^{7} for dynesty . These results demonstrate that i-nessai is consistent with nessai and dynesty whilst also being more efficient.},
  archive      = {J_MLST},
  author       = {Michael J Williams and John Veitch and Chris Messenger},
  doi          = {10.1088/2632-2153/acd5aa},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035011},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Importance nested sampling with normalising flows},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient determination of the hamiltonian and electronic
properties using graph neural network with complete local coordinates.
<em>MLST</em>, <em>4</em>(3), 035010. (<a
href="https://doi.org/10.1088/2632-2153/accb26">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the successes of machine learning methods in physical sciences, the prediction of the Hamiltonian, and thus the electronic properties, is still unsatisfactory. Based on graph neural network (NN) architecture, we present an extendable NN model to determine the Hamiltonian from ab initio data, with only local atomic structures as inputs. The rotational equivariance of the Hamiltonian is achieved by our complete local coordinates (LCs). The LC information, encoded using a convolutional NN and designed to preserve Hermitian symmetry, is used to map hopping parameters onto local structures. We demonstrate the performance of our model using graphene and SiGe random alloys as examples. We show that our NN model, although trained using small-size systems, can predict the Hamiltonian, as well as electronic properties such as band structures and densities of states for large-size systems within the ab initio accuracy, justifying its extensibility. In combination with the high efficiency of our model, which takes only seconds to get the Hamiltonian of a 1728-atom system, the present work provides a general framework to predict electronic properties efficiently and accurately, which provides new insights into computational physics and will accelerate the research for large-scale materials.},
  archive      = {J_MLST},
  author       = {Mao Su and Ji-Hui Yang and Hong-Jun Xiang and Xin-Gao Gong},
  doi          = {10.1088/2632-2153/accb26},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035010},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Efficient determination of the hamiltonian and electronic properties using graph neural network with complete local coordinates},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Symmetric tensor networks for generative modeling and
constrained combinatorial optimization. <em>MLST</em>, <em>4</em>(3),
035009. (<a href="https://doi.org/10.1088/2632-2153/ace0f5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained combinatorial optimization problems abound in industry, from portfolio optimization to logistics. One of the major roadblocks in solving these problems is the presence of non-trivial hard constraints which limit the valid search space. In some heuristic solvers, these are typically addressed by introducing certain Lagrange multipliers in the cost function, by relaxing them in some way, or worse yet, by generating many samples and only keeping valid ones, which leads to very expensive and inefficient searches. In this work, we encode arbitrary integer-valued equality constraints of the form A \vec{x} = \vec{b} , directly into U (1) symmetric tensor networks (TNs) and leverage their applicability as quantum-inspired generative models to assist in the search of solutions to combinatorial optimization problems within the generator-enhanced optimization framework of Alcazar et al (2021 arXiv: 2101.06250 ). This allows us to exploit the generalization capabilities of TN generative models while constraining them so that they only output valid samples. Our constrained TN generative model efficiently captures the constraints by reducing number of parameters and computational costs. We find that at tasks with constraints given by arbitrary equalities, symmetric matrix product states outperform their standard unconstrained counterparts at finding novel and better solutions to combinatorial optimization problems.},
  archive      = {J_MLST},
  author       = {Javier Lopez-Piqueres and Jing Chen and Alejandro Perdomo-Ortiz},
  doi          = {10.1088/2632-2153/ace0f5},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035009},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Symmetric tensor networks for generative modeling and constrained combinatorial optimization},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive active brownian particles searching for targets of
unknown positions. <em>MLST</em>, <em>4</em>(3), 035008. (<a
href="https://doi.org/10.1088/2632-2153/ace6f4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing behavioral policies designed to efficiently solve target-search problems is a crucial issue both in nature and in the nanotechnology of the 21st century. Here, we characterize the target-search strategies of simple microswimmers in a homogeneous environment containing sparse targets of unknown positions. The microswimmers are capable of controlling their dynamics by switching between Brownian motion and an active Brownian particle and by selecting the time duration of each of the two phases. The specific conduct of a single microswimmer depends on an internal decision-making process determined by a simple neural network associated with the agent itself. Starting from a population of individuals with random behavior, we exploit the genetic algorithm NeuroEvolution of augmenting topologies to show how an evolutionary pressure based on the target-search performances of single individuals helps to find the optimal duration of the two different phases. Our findings reveal that the optimal policy strongly depends on the magnitude of the particle&#39;s self-propulsion during the active phase and that a broad spectrum of network topology solutions exists, differing in the number of connections and hidden nodes.},
  archive      = {J_MLST},
  author       = {Harpreet Kaur and Thomas Franosch and Michele Caraglio},
  doi          = {10.1088/2632-2153/ace6f4},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035008},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Adaptive active brownian particles searching for targets of unknown positions},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust detection of marine life with label-free image
feature learning and probability calibration. <em>MLST</em>,
<em>4</em>(3), 035007. (<a
href="https://doi.org/10.1088/2632-2153/ace417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in in situ marine life imaging have significantly increased the size and quality of available datasets, but automatic image analysis has not kept pace. Machine learning has shown promise for image processing, but its effectiveness is limited by several open challenges: the requirement for large expert-labeled training datasets, disagreement among experts, under-representation of various species and unreliable or overconfident predictions. To overcome these obstacles for automated underwater imaging, we combine and test recent developments in deep classifier networks and self-supervised feature learning. We use unlabeled images for pretraining deep neural networks to extract task-relevant image features, allowing learning algorithms to cope with scarcity in expert labels, and carefully evaluate performance in subsequent label-based tasks. Performance on rare classes is improved by applying data rebalancing together with a Bayesian correction to avoid biasing inferred in situ class frequencies. A divergence-based loss allows training on multiple, conflicting labels for the same image, leading to better estimates of uncertainty which we quantify with a novel accuracy measure. Together, these techniques can reduce the required label counts ∼100-fold while maintaining the accuracy of standard supervised training, shorten training time, cope with expert disagreement and reduce overconfidence.},
  archive      = {J_MLST},
  author       = {Tobias Schanz and Klas Ove Möller and Saskia Rühl and David S Greenberg},
  doi          = {10.1088/2632-2153/ace417},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035007},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Robust detection of marine life with label-free image feature learning and probability calibration},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intramolecular proton transfer reaction dynamics using
machine-learned ab initio potential energy surfaces. <em>MLST</em>,
<em>4</em>(3), 035006. (<a
href="https://doi.org/10.1088/2632-2153/acdbbc">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hydrogen bonding interactions, which are central to various physicochemical processes, are investigated in the present study using ab initio -based machine learning potential energy surfaces. Abnormally strong intramolecular O–H⋯O hydrogen bonds, occurring in β -diketone enols of malonaldehyde and its derivatives, with substituents ranging from various electron-withdrawing to electron-donating functional groups, are studied. Machine learning force fields were constructed using a kernel-based force learning model employing ab initio molecular dynamics reference data. These models were used for molecular dynamics simulations at finite temperature, and dynamical properties were determined by computing proton transfer free-energy surfaces. The chemical systems studied here show progression toward barrier-less proton transfer events at an accuracy of correlated electronic structure methods. Markov state models of the conformational states indicate shorter intramolecular hydrogen bonds exhibiting higher proton transfer rates. We demonstrate how functional group substitution can modulate the strength of intramolecular hydrogen bonds by studying the thermodynamic and kinetic properties.},
  archive      = {J_MLST},
  author       = {Shampa Raghunathan and Sai Ajay Kashyap Nakirikanti},
  doi          = {10.1088/2632-2153/acdbbc},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035006},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Intramolecular proton transfer reaction dynamics using machine-learned ab initio potential energy surfaces},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient generation of stable linear machine-learning force
fields with uncertainty-aware active learning. <em>MLST</em>,
<em>4</em>(3), 035005. (<a
href="https://doi.org/10.1088/2632-2153/ace418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine-learning (ML) force fields (FFs) enable an accurate and universal description of the potential energy surface of molecules and materials on the basis of a training set of ab initio data. However, large-scale applications of these methods rest on the possibility to train accurate ML models with a small number of ab initio data. In this respect, active-learning (AL) strategies, where the training set is self-generated by the model itself, combined with linear ML models are particularly promising. In this work, we explore an AL strategy based on linear regression and able to predict the model&#39;s uncertainty on predictions for molecular configurations not sampled by the training set, thus providing a straightforward recipe for the extension of the latter. We apply this strategy to the spectral neighbor analysis potential and show that only tens of ab initio simulations of atomic forces are required to generate FFs for room-temperature molecular dynamics at or close to chemical accuracy and which stability can be systematically improved by the user at modest computational expenses. Moreover, the method does not necessitate any conformational pre-sampling, thus requiring minimal user intervention and parametrization.},
  archive      = {J_MLST},
  author       = {Valerio Briganti and Alessandro Lunghi},
  doi          = {10.1088/2632-2153/ace418},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035005},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Efficient generation of stable linear machine-learning force fields with uncertainty-aware active learning},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning latent functions for causal discovery.
<em>MLST</em>, <em>4</em>(3), 035004. (<a
href="https://doi.org/10.1088/2632-2153/ace151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal discovery from observational data offers unique opportunities in many scientific disciplines: reconstructing causal drivers, testing causal hypotheses, and comparing and evaluating models for optimizing targeted interventions. Recent causal discovery methods focused on estimating the latent space of the data to get around a lack of causal sufficiency or additivity constraints. However, estimating the latent space significantly increases model complexity, compromising causal identifiability and making it hard to compare models that correspond to different causal hypotheses. We propose a kernel, non-parametric latent-space modelling approach and deal with the difficulty of comparing causal directions by measuring and controlling for the level of causal assumption fulfilment. We introduce a latent noise causal inference framework to estimate latent factors associated with the hypothesized causal direction by optimizing a loss function with kernel independence criteria. We extend the framework to work with time series using an additional time-dependent kernel regularizer. We discuss the additivity assumption and model complexity and give empirical evidence of performance in a wide range of synthetic and real causal discovery problems.},
  archive      = {J_MLST},
  author       = {Emiliano Díaz and Gherardo Varando and J Emmanuel Johnson and Gustau Camps-Valls},
  doi          = {10.1088/2632-2153/ace151},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035004},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Learning latent functions for causal discovery},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A detailed study of interpretability of deep neural network
based top taggers. <em>MLST</em>, <em>4</em>(3), 035003. (<a
href="https://doi.org/10.1088/2632-2153/ace0a1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent developments in the methods of explainable artificial intelligence (XAI) allow researchers to explore the inner workings of deep neural networks (DNNs), revealing crucial information about input–output relationships and realizing how data connects with machine learning models. In this paper we explore interpretability of DNN models designed to identify jets coming from top quark decay in high energy proton–proton collisions at the Large Hadron Collider. We review a subset of existing top tagger models and explore different quantitative methods to identify which features play the most important roles in identifying the top jets. We also investigate how and why feature importance varies across different XAI metrics, how correlations among features impact their explainability, and how latent space representations encode information as well as correlate with physically meaningful quantities. Our studies uncover some major pitfalls of existing XAI methods and illustrate how they can be overcome to obtain consistent and meaningful interpretation of these models. We additionally illustrate the activity of hidden layers as neural activation pattern diagrams and demonstrate how they can be used to understand how DNNs relay information across the layers and how this understanding can help to make such models significantly simpler by allowing effective model reoptimization and hyperparameter tuning. These studies not only facilitate a methodological approach to interpreting models but also unveil new insights about what these models learn. Incorporating these observations into augmented model design, we propose the particle flow interaction network model and demonstrate how interpretability-inspired model augmentation can improve top tagging performance.},
  archive      = {J_MLST},
  author       = {Ayush Khot and Mark S Neubauer and Avik Roy},
  doi          = {10.1088/2632-2153/ace0a1},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035003},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A detailed study of interpretability of deep neural network based top taggers},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Magnetohydrodynamics with physics informed neural operators.
<em>MLST</em>, <em>4</em>(3), 035002. (<a
href="https://doi.org/10.1088/2632-2153/ace30a">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The modeling of multi-scale and multi-physics complex systems typically involves the use of scientific software that can optimally leverage extreme scale computing. Despite major developments in recent years, these simulations continue to be computationally intensive and time consuming. Here we explore the use of AI to accelerate the modeling of complex systems at a fraction of the computational cost of classical methods, and present the first application of physics informed neural operators (NOs) (PINOs) to model 2D incompressible magnetohydrodynamics (MHD) simulations. Our AI models incorporate tensor Fourier NOs as their backbone, which we implemented with the TensorLY package. Our results indicate that PINOs can accurately capture the physics of MHD simulations that describe laminar flows with Reynolds numbers \mathrm{Re}\leqslant250 . We also explore the applicability of our AI surrogates for turbulent flows, and discuss a variety of methodologies that may be incorporated in future work to create AI models that provide a computationally efficient and high fidelity description of MHD simulations for a broad range of Reynolds numbers. The scientific software developed in this project is released with this manuscript.},
  archive      = {J_MLST},
  author       = {Shawn G Rosofsky and E A Huerta},
  doi          = {10.1088/2632-2153/ace30a},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035002},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Magnetohydrodynamics with physics informed neural operators},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial neural network potentials for mechanics and
fracture dynamics of two-dimensional crystals **. <em>MLST</em>,
<em>4</em>(3), 035001. (<a
href="https://doi.org/10.1088/2632-2153/accd45">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the mechanics and failure of materials at the nanoscale is critical for their engineering and applications. The accurate atomistic modeling of brittle failure with crack propagation in covalent crystals requires a quantum mechanics-based description of individual bond-breaking events. Artificial neural network potentials (NNPs) have emerged to overcome the traditional, physics-based modeling tradeoff between accuracy and accessible time and length scales. Previous studies have shown successful applications of NNPs for describing the structure and dynamics of molecular systems and amorphous or liquid phases of materials. However, their application to deformation and failure processes in materials is still uncommon. In this study, we discuss the apparent limitations of NNPs for the description of deformation and fracture under loadings and propose a way to generate and select training data for their employment in simulations of deformation and fracture simulations of crystals. We applied the proposed approach to 2D crystalline graphene, utilizing the density-functional tight-binding method for more efficient and extensive data generation in place of density functional theory. Then, we explored how the data selection affects the accuracy of the developed artificial NNPs. It revealed that NNP&#39;s reliability should not only be measured based on the total energy and atomic force comparisons for reference structures but also utilize comparisons for physical properties, e.g. stress–strain curves and geometric deformation. In sharp contrast to popular reactive bond order potentials, our optimized NNP predicts straight crack propagation in graphene along both armchair and zigzag (ZZ) lattice directions, as well as higher fracture toughness of ZZ edge direction. Our study provides significant insight into crack propagation mechanisms on atomic scales and highlights strategies for NNP developments of broader materials.},
  archive      = {J_MLST},
  author       = {Gang Seob Jung and Hunjoo Myung and Stephan Irle},
  doi          = {10.1088/2632-2153/accd45},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035001},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Artificial neural network potentials for mechanics and fracture dynamics of two-dimensional crystals **},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Infinite neural network quantum states: Entanglement and
training dynamics. <em>MLST</em>, <em>4</em>(2), 025038. (<a
href="https://doi.org/10.1088/2632-2153/ace02f">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study infinite limits of neural network quantum states ( \infty -NNQS), which exhibit representation power through ensemble statistics, and also tractable gradient descent dynamics. Ensemble averages of entanglement entropies are expressed in terms of neural network correlators, and architectures that exhibit volume-law entanglement are presented. The analytic calculations of entanglement entropy bound are tractable because the ensemble statistics are simplified in the Gaussian process limit. A general framework is developed for studying the gradient descent dynamics of neural network quantum states (NNQS), using a quantum state neural tangent kernel (QS-NTK). For \infty -NNQS the training dynamics is simplified, since the QS-NTK becomes deterministic and constant. An analytic solution is derived for quantum state supervised learning, which allows an \infty -NNQS to recover any target wavefunction. Numerical experiments on finite and infinite NNQS in the transverse field Ising model and Fermi Hubbard model demonstrate excellent agreement with theory. \infty -NNQS opens up new opportunities for studying entanglement and training dynamics in other physics applications, such as in finding ground states.},
  archive      = {J_MLST},
  author       = {Di Luo and James Halverson},
  doi          = {10.1088/2632-2153/ace02f},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {2},
  pages        = {025038},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Infinite neural network quantum states: Entanglement and training dynamics},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Shape sensing of optical fiber bragg gratings based on deep
learning. <em>MLST</em>, <em>4</em>(2), 025037. (<a
href="https://doi.org/10.1088/2632-2153/acda10">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuum robots in robot-assisted minimally invasive surgeries provide adequate access to target anatomies that are not directly reachable through small incisions. Achieving precise and reliable shape estimation of such snake-like manipulators necessitates an accurate navigation system, that requires no line-of-sight and is immune to electromagnetic noise. Fiber Bragg grating (FBG) shape sensing, particularly eccentric FBG (eFBG), is a promising and cost-effective solution for this task. However, in eFBG sensors, the spectral intensity of the Bragg wavelengths that carries the strain information can be affected by undesired bending-induced phenomena, making standard characterization techniques less suitable for these sensors. We showed in our previous work that a deep learning model has the potential to extract the strain information from the eFBG sensor&#39;s spectrum and accurately predict its shape. In this paper, we conducted a more thorough investigation to find a suitable architectural design of the deep learning model to further increase shape prediction accuracy. We used the Hyperband algorithm to search for optimal hyperparameters in two steps. First, we limited the search space to layer settings of the network, from which, the best-performing configuration was selected. Then, we modified the search space for tuning the training and loss calculation hyperparameters. We also analyzed various data transformations on the network&#39;s input and output variables, as data rescaling can directly influence the model&#39;s performance. Additionally, we performed discriminative training using the Siamese network architecture that employs two convolutional neural networks (CNN) with identical parameters to learn similarity metrics between the spectra of similar target values. The best-performing network architecture among all evaluated configurations can predict the shape of a 30 cm long sensor with a median tip error of 3.11 mm in a curvature range of 1.4 m −1 to 35.3 m −1 .},
  archive      = {J_MLST},
  author       = {Samaneh Manavi Roodsari and Antal Huck-Horvath and Sara Freund and Azhar Zam and Georg Rauter and Wolfgang Schade and Philippe C Cattin},
  doi          = {10.1088/2632-2153/acda10},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {2},
  pages        = {025037},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Shape sensing of optical fiber bragg gratings based on deep learning},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). End-to-end AI framework for interpretable prediction of
molecular and crystal properties. <em>MLST</em>, <em>4</em>(2), 025036.
(<a href="https://doi.org/10.1088/2632-2153/acd434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce an end-to-end computational framework that allows for hyperparameter optimization using the DeepHyper library, accelerated model training, and interpretable AI inference. The framework is based on state-of-the-art AI models including CGCNN , PhysNet , SchNet , MPNN , MPNN-transformer , and TorchMD-NET . We employ these AI models along with the benchmark QM9 , hMOF , and MD17 datasets to showcase how the models can predict user-specified material properties within modern computing environments. We demonstrate transferable applications in the modeling of small molecules, inorganic crystals and nanoporous metal organic frameworks with a unified, standalone framework. We have deployed and tested this framework in the ThetaGPU supercomputer at the Argonne Leadership Computing Facility, and in the Delta supercomputer at the National Center for Supercomputing Applications to provide researchers with modern tools to conduct accelerated AI-driven discovery in leadership-class computing environments. We release these digital assets as open source scientific software in GitLab, and ready-to-use Jupyter notebooks in Google Colab.},
  archive      = {J_MLST},
  author       = {Hyun Park and Ruijie Zhu and E A Huerta and Santanu Chaudhuri and Emad Tajkhorshid and Donny Cooper},
  doi          = {10.1088/2632-2153/acd434},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025036},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {End-to-end AI framework for interpretable prediction of molecular and crystal properties},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SELFormer: Molecular representation learning via SELFIES
language models. <em>MLST</em>, <em>4</em>(2), 025035. (<a
href="https://doi.org/10.1088/2632-2153/acdb30">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated computational analysis of the vast chemical space is critical for numerous fields of research such as drug discovery and material science. Representation learning techniques have recently been employed with the primary objective of generating compact and informative numerical expressions of complex data, for efficient usage in subsequent prediction tasks. One approach to efficiently learn molecular representations is processing string-based notations of chemicals via natural language processing algorithms. Majority of the methods proposed so far utilize SMILES notations for this purpose, which is the most extensively used string-based encoding for molecules. However, SMILES is associated with numerous problems related to validity and robustness, which may prevent the model from effectively uncovering the knowledge hidden in the data. In this study, we propose SELFormer, a transformer architecture-based chemical language model (CLM) that utilizes a 100% valid, compact and expressive notation, SELFIES, as input, in order to learn flexible and high-quality molecular representations. SELFormer is pre-trained on two million drug-like compounds and fine-tuned for diverse molecular property prediction tasks. Our performance evaluation has revealed that, SELFormer outperforms all competing methods, including graph learning-based approaches and SMILES-based CLMs, on predicting aqueous solubility of molecules and adverse drug reactions, while producing comparable results for the remaining tasks. We also visualized molecular representations learned by SELFormer via dimensionality reduction, which indicated that even the pre-trained model can discriminate molecules with differing structural properties. We shared SELFormer as a programmatic tool, together with its datasets and pre-trained models at https://github.com/HUBioDataLab/SELFormer . Overall, our research demonstrates the benefit of using the SELFIES notations in the context of chemical language modeling and opens up new possibilities for the design and discovery of novel drug candidates with desired features.},
  archive      = {J_MLST},
  author       = {Atakan Yüksel and Erva Ulusoy and Atabey Ünlü and Tunca Doğan},
  doi          = {10.1088/2632-2153/acdb30},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025035},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {SELFormer: Molecular representation learning via SELFIES language models},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scalable neural quantum states architecture for quantum
chemistry. <em>MLST</em>, <em>4</em>(2), 025034. (<a
href="https://doi.org/10.1088/2632-2153/acdb2f">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational optimization of neural-network representations of quantum states has been successfully applied to solve interacting fermionic problems. Despite rapid developments, significant scalability challenges arise when considering molecules of large scale, which correspond to non-locally interacting quantum spin Hamiltonians consisting of sums of thousands or even millions of Pauli operators. In this work, we introduce scalable parallelization strategies to improve neural-network-based variational quantum Monte Carlo calculations for ab-initio quantum chemistry applications. We establish GPU-supported local energy parallelism to compute the optimization objective for Hamiltonians of potentially complex molecules. Using autoregressive sampling techniques, we demonstrate systematic improvement in wall-clock timings required to achieve coupled cluster with up to double excitations baseline target energies. The performance is further enhanced by accommodating the structure of resultant spin Hamiltonians into the autoregressive sampling ordering. The algorithm achieves promising performance in comparison with the classical approximate methods and exhibits both running time and scalability advantages over existing neural-network based methods.},
  archive      = {J_MLST},
  author       = {Tianchen Zhao and James Stokes and Shravan Veerapaneni},
  doi          = {10.1088/2632-2153/acdb2f},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025034},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Scalable neural quantum states architecture for quantum chemistry},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Koopman-inspired approach for identification of exogenous
anomalies in nonstationary time-series data. <em>MLST</em>,
<em>4</em>(2), 025033. (<a
href="https://doi.org/10.1088/2632-2153/acdd50">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many scenarios, it is necessary to monitor a complex system via a time-series of observations and determine when anomalous exogenous events have occurred so that relevant actions can be taken. Determining whether current observations are abnormal is challenging. It requires learning an extrapolative probabilistic model of the dynamics from historical data, and using a limited number of current observations to make a classification. We leverage recent advances in long-term probabilistic forecasting, namely Deep Probabilistic Koopman , to build a general method for classifying anomalies in multi-dimensional time-series data. We also show how to utilize models with domain knowledge of the dynamics to reduce type I and type II error. We demonstrate our proposed method on the important real-world task of global atmospheric pollution monitoring, integrating it with NASA&#39;s Global Earth Observing System Model. The system successfully detects localized anomalies in air quality due to events such as COVID-19 lockdowns and wildfires.},
  archive      = {J_MLST},
  author       = {Alex Mallen and Christoph A Keller and J Nathan Kutz},
  doi          = {10.1088/2632-2153/acdd50},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025033},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Koopman-inspired approach for identification of exogenous anomalies in nonstationary time-series data},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MeGen - generation of gallium metal clusters using
reinforcement learning. <em>MLST</em>, <em>4</em>(2), 025032. (<a
href="https://doi.org/10.1088/2632-2153/acdc03">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generation of low-energy 3D structures of metal clusters depends on the efficiency of the search algorithm and the accuracy of inter-atomic interaction description. In this work, we formulate the search algorithm as a reinforcement learning (RL) problem. Concisely, we propose a novel actor-critic architecture that generates low-lying isomers of metal clusters at a fraction of computational cost than conventional methods. Our RL-based search algorithm uses a previously developed DART model as a reward function to describe the inter-atomic interactions to validate predicted structures. Using the DART model as a reward function incentivizes the RL model to generate low-energy structures and helps generate valid structures. We demonstrate the advantages of our approach over conventional methods for scanning local minima on potential energy surface. Our approach not only generates isomer of gallium clusters at a minimal computational cost but also predicts isomer families that were not discovered through previous density-functional theory (DFT)-based approaches.},
  archive      = {J_MLST},
  author       = {Rohit Modee and Ashwini Verma and Kavita Joshi and U Deva Priyakumar},
  doi          = {10.1088/2632-2153/acdc03},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025032},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {MeGen - generation of gallium metal clusters using reinforcement learning},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CYJAX: A package for calabi-yau metrics with JAX.
<em>MLST</em>, <em>4</em>(2), 025031. (<a
href="https://doi.org/10.1088/2632-2153/acdc84">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the first version of CYJAX, a package for machine learning Calabi–Yau metrics using JAX. It is meant to be accessible both as a top-level tool and as a library of modular functions. CYJAX is currently centered around the algebraic ansatz for the Kähler potential which automatically satisfies Kählerity and compatibility on patch overlaps. As of now, this implementation is limited to varieties defined by a single defining equation on one complex projective space. We comment on some planned generalizations. More documentation can be found at: https://cyjax.readthedocs.io . The code is available at: https://github.com/ml4physics/cyjax .},
  archive      = {J_MLST},
  author       = {Mathis Gerdes and Sven Krippendorf},
  doi          = {10.1088/2632-2153/acdc84},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025031},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {CYJAX: A package for calabi-yau metrics with JAX},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 3D positioning and autofocus of the particle field based on
the depth-from-defocus method and the deep networks. <em>MLST</em>,
<em>4</em>(2), 025030. (<a
href="https://doi.org/10.1088/2632-2153/acdb2e">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate three-dimensional positioning of particles is a critical task in microscopic particle research, with one of the main challenges being the measurement of particle depths. In this paper, we propose a method for detecting particle depths from their blurred images using the depth-from-defocus technique and a deep neural network-based object detection framework called you-only-look-once. Our method provides simultaneous lateral position information for the particles and has been tested and evaluated on various samples, including synthetic particles, polystyrene particles, blood cells, and plankton, even in a noise-filled environment. We achieved autofocus for target particles in different depths using generative adversarial networks, obtaining clear-focused images. Our algorithm can process a single multi-target image in 0.008 s, allowing real-time application. Our proposed method provides new opportunities for particle field research.},
  archive      = {J_MLST},
  author       = {Xiaolei Zhang and Zhao Dong and Huaying Wang and Xiaohui Sha and Wenjian Wang and Xinyu Su and Zhengsheng Hu and Shaokai Yang},
  doi          = {10.1088/2632-2153/acdb2e},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025030},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {3D positioning and autofocus of the particle field based on the depth-from-defocus method and the deep networks},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Theoretical characterization of uncertainty in
high-dimensional linear classification. <em>MLST</em>, <em>4</em>(2),
025029. (<a href="https://doi.org/10.1088/2632-2153/acd749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Being able to reliably assess not only the accuracy but also the uncertainty of models&#39; predictions is an important endeavor in modern machine learning. Even if the model generating the data and labels is known, computing the intrinsic uncertainty after learning the model from a limited number of samples amounts to sampling the corresponding posterior probability measure. Such sampling is computationally challenging in high-dimensional problems and theoretical results on heuristic uncertainty estimators in high-dimensions are thus scarce. In this manuscript, we characterize uncertainty for learning from a limited number of samples of high-dimensional Gaussian input data and labels generated by the probit model. In this setting, the Bayesian uncertainty (i.e. the posterior marginals) can be asymptotically obtained by the approximate message passing algorithm, bypassing the canonical but costly Monte Carlo sampling of the posterior. We then provide a closed-form formula for the joint statistics between the logistic classifier, the uncertainty of the statistically optimal Bayesian classifier and the ground-truth probit uncertainty. The formula allows us to investigate the calibration of the logistic classifier learning from a limited amount of samples. We discuss how over-confidence can be mitigated by appropriately regularizing.},
  archive      = {J_MLST},
  author       = {Lucas Clarté and Bruno Loureiro and Florent Krzakala and Lenka Zdeborová},
  doi          = {10.1088/2632-2153/acd749},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025029},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Theoretical characterization of uncertainty in high-dimensional linear classification},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Realistic mask generation for matter-wave lithography via
machine learning. <em>MLST</em>, <em>4</em>(2), 025028. (<a
href="https://doi.org/10.1088/2632-2153/acd988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fast production of large-area patterns is crucial for the established semiconductor industry and enables industrial-scale production of next-generation quantum devices. Metastable atom lithography with binary holography masks has been suggested as a higher resolution/low-cost alternative to the current state of the art: extreme ultraviolet lithography. However, it was recently shown that the interaction of the metastable atoms with the mask material (SiN) leads to a strong perturbation of the wavefront, not included in the existing mask generation theory, which is based on classical scalar waves. This means that the inverse problem (creating a mask based on the desired pattern) cannot be solved analytically, even in 1D. Here we present a machine-learning approach to mask generation targeted for metastable atoms. Our algorithm uses a combination of genetic optimisation and deep learning to obtain the mask. A novel deep neural architecture is trained to produce an initial approximation of the mask. This approximation is then used to generate the initial population of the genetic optimisation algorithm that can converge to arbitrary precision. We demonstrate the generation of arbitrary 1D patterns for system dimensions within the Fraunhofer approximation limit.},
  archive      = {J_MLST},
  author       = {Johannes Fiedler and Adriá Salvador Palau and Eivind Kristen Osestad and Pekka Parviainen and Bodil Holst},
  doi          = {10.1088/2632-2153/acd988},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025028},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Realistic mask generation for matter-wave lithography via machine learning},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning symmetries and their lie groups, algebras, and
subalgebras from first principles. <em>MLST</em>, <em>4</em>(2), 025027.
(<a href="https://doi.org/10.1088/2632-2153/acd989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We design a deep-learning algorithm for the discovery and identification of the continuous group of symmetries present in a labeled dataset. We use fully connected neural networks to model the symmetry transformations and the corresponding generators. The constructed loss functions ensure that the applied transformations are symmetries and the corresponding set of generators forms a closed (sub)algebra. Our procedure is validated with several examples illustrating different types of conserved quantities preserved by symmetry. In the process of deriving the full set of symmetries, we analyze the complete subgroup structure of the rotation groups SO (2), SO (3), and SO (4), and of the Lorentz group SO(1,3) . Other examples include squeeze mapping, piecewise discontinuous labels, and SO (10), demonstrating that our method is completely general, with many possible applications in physics and data science. Our study also opens the door for using a machine learning approach in the mathematical study of Lie groups and their properties.},
  archive      = {J_MLST},
  author       = {Roy T Forestano and Konstantin T Matchev and Katia Matcheva and Alexander Roman and Eyup B Unlu and Sarunas Verner},
  doi          = {10.1088/2632-2153/acd989},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025027},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Deep learning symmetries and their lie groups, algebras, and subalgebras from first principles},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning model with l1 penalty for predicting breast
cancer metastasis using gene expression data. <em>MLST</em>,
<em>4</em>(2), 025026. (<a
href="https://doi.org/10.1088/2632-2153/acd987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer has the highest incidence and death rate among women; moreover, its metastasis to other organs increases the mortality rate. Since several studies have reported gene expression and cancer prognosis to be related, the study of breast cancer metastasis using gene expression is crucial. To this end, a novel deep neural network architecture, deep learning-based cancer metastasis estimator (DeepCME), is proposed in this paper for predicting breast cancer metastasis. However, the problem of overfitting occurs frequently while training deep learning models using gene expression data because they contain a large number of genes and the sample size is rather small. To address overfitting, several regularization methods are implemented, such as L1 penalty, batch normalization, and dropout. To demonstrate the superior performance of our model, area under curve (AUC) scores are evaluated and then compared with five baseline models: logistic regression, support vector classifier (SVC), random forest, decision tree, and k -nearest neighbor. Considering results, DeepCME demonstrates the highest average AUC scores in most cross-validation cases, and the average AUC score of DeepCME is 0.754, which is approximately 12.9% higher than SVC, the second-best model. In addition, the 30 most significant genes related to breast cancer metastasis are identified based on DeepCME results and some are discussed in further detail considering the reports from some previous medical studies. Considering the high expense involved in measuring the expression of a single gene, the ability to develop the cost-effective and time-efficient tests using only a few key genes is valuable. Based on this study, we expect DeepCME to be utilized clinically for predicting breast cancer metastasis and be applied to other types of cancer as well after further research.},
  archive      = {J_MLST},
  author       = {Jaeyoon Kim and Minhyeok Lee and Junhee Seok},
  doi          = {10.1088/2632-2153/acd987},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025026},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Deep learning model with l1 penalty for predicting breast cancer metastasis using gene expression data},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpretable machine learning model to predict survival
days of malignant brain tumor patients. <em>MLST</em>, <em>4</em>(2),
025025. (<a href="https://doi.org/10.1088/2632-2153/acd5a9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An artificial intelligence (AI) model&#39;s performance is strongly influenced by the input features. Therefore, it is vital to find the optimal feature set. It is more crucial for the survival prediction of the glioblastoma multiforme (GBM) type of brain tumor. In this study, we identify the best feature set for predicting the survival days (SD) of GBM patients that outrank the current state-of-the-art methodologies. The proposed approach is an end-to-end AI model. This model first segments tumors from healthy brain parts in patients&#39; MRI images, extracts features from the segmented results, performs feature selection, and makes predictions about patients&#39; survival days (SD) based on selected features. The extracted features are primarily shape-based, location-based, and radiomics-based features. Additionally, patient metadata is also included as a feature. The selection methods include recursive feature elimination, permutation importance (PI), and finding the correlation between the features. Finally, we examined features&#39; behavior at local (single sample) and global (all the samples) levels. In this study, we find that out of 1265 extracted features, only 29 dominant features play a crucial role in predicting patients&#39; SD. Among these 29 features, one is metadata (age of patient), three are location-based, and the rest are radiomics features. Furthermore, we find explanations of these features using post-hoc interpretability methods to validate the model&#39;s robust prediction and understand its decision. Finally, we analyzed the behavioral impact of the top six features on survival prediction, and the findings drawn from the explanations were coherent with the medical domain. We find that after the age of 50 years, the likelihood of survival of a patient deteriorates, and survival after 80 years is scarce. Again, for location-based features, the SD is less if the tumor location is in the central or back part of the brain. All these trends derived from the developed AI model are in sync with medically proven facts. The results show an overall 33% improvement in the accuracy of SD prediction compared to the top-performing methods of the BraTS-2020 challenge.},
  archive      = {J_MLST},
  author       = {Snehal Rajput and Rupal A Kapdi and Mehul S Raval and Mohendra Roy},
  doi          = {10.1088/2632-2153/acd5a9},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025025},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Interpretable machine learning model to predict survival days of malignant brain tumor patients},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spectrally adapted physics-informed neural networks for
solving unbounded domain problems. <em>MLST</em>, <em>4</em>(2), 025024.
(<a href="https://doi.org/10.1088/2632-2153/acd0a1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving analytically intractable partial differential equations (PDEs) that involve at least one variable defined on an unbounded domain arises in numerous physical applications. Accurately solving unbounded domain PDEs requires efficient numerical methods that can resolve the dependence of the PDE on the unbounded variable over at least several orders of magnitude. We propose a solution to such problems by combining two classes of numerical methods: (i) adaptive spectral methods and (ii) physics-informed neural networks (PINNs). The numerical approach that we develop takes advantage of the ability of PINNs to easily implement high-order numerical schemes to efficiently solve PDEs and extrapolate numerical solutions at any point in space and time. We then show how recently introduced adaptive techniques for spectral methods can be integrated into PINN-based PDE solvers to obtain numerical solutions of unbounded domain problems that cannot be efficiently approximated by standard PINNs. Through a number of examples, we demonstrate the advantages of the proposed spectrally adapted PINNs in solving PDEs and estimating model parameters from noisy observations in unbounded domains.},
  archive      = {J_MLST},
  author       = {Mingtao Xia and Lucas Böttcher and Tom Chou},
  doi          = {10.1088/2632-2153/acd0a1},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025024},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Spectrally adapted physics-informed neural networks for solving unbounded domain problems},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mapping confinement potentials and charge densities of
interacting quantum systems using conditional generative adversarial
networks. <em>MLST</em>, <em>4</em>(2), 025023. (<a
href="https://doi.org/10.1088/2632-2153/acd6d8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and efficient tools for calculating the ground state properties of interacting quantum systems are essential in the design of nanoelectronic devices. The exact diagonalization method fully accounts for the Coulomb interaction beyond mean field approximations and it is regarded as the gold-standard for few electron systems. However, by increasing the number of instances to be solved, the computational costs become prohibitive and new approaches based on machine learning techniques can provide a significant reduction in computational time and resources, maintaining a reasonable accuracy. Here, we employ pix2pix , a general-purpose image-to-image translation method based on conditional generative adversarial network (cGAN), for predicting ground state densities from randomly generated confinement potentials. Other mappings were also investigated, like potentials to non-interacting densities and the translation from non-interacting to interacting densities. The architecture of the cGAN was optimized with respect to the internal parameters of the generator and discriminator. Moreover, the inverse problem of finding the confinement potential given the interacting density can also be approached by the pix2pix mapping, which is an important step in finding near-optimal solutions for confinement potentials.},
  archive      = {J_MLST},
  author       = {Calin-Andrei Pantis-Simut and Amanda Teodora Preda and Lucian Ion and Andrei Manolescu and George Alexandru Nemnes},
  doi          = {10.1088/2632-2153/acd6d8},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025023},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Mapping confinement potentials and charge densities of interacting quantum systems using conditional generative adversarial networks},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Applications of physics informed neural operators.
<em>MLST</em>, <em>4</em>(2), 025022. (<a
href="https://doi.org/10.1088/2632-2153/acd168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a critical analysis of physics-informed neural operators (PINOs) to solve partial differential equations (PDEs) that are ubiquitous in the study and modeling of physics phenomena using carefully curated datasets. Further, we provide a benchmarking suite which can be used to evaluate PINOs in solving such problems. We first demonstrate that our methods reproduce the accuracy and performance of other neural operators published elsewhere in the literature to learn the 1D wave equation and the 1D Burgers equation. Thereafter, we apply our PINOs to learn new types of equations, including the 2D Burgers equation in the scalar, inviscid and vector types. Finally, we show that our approach is also applicable to learn the physics of the 2D linear and nonlinear shallow water equations, which involve three coupled PDEs. We release our artificial intelligence surrogates and scientific software to produce initial data and boundary conditions to study a broad range of physically motivated scenarios. We provide the source code , an interactive website to visualize the predictions of our PINOs, and a tutorial for their use at the Data and Learning Hub for Science .},
  archive      = {J_MLST},
  author       = {Shawn G Rosofsky and Hani Al Majed and E A Huerta},
  doi          = {10.1088/2632-2153/acd168},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025022},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Applications of physics informed neural operators},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CX-net: An efficient ensemble semantic deep neural network
for ROI identification from chest-x-ray images for COPD diagnosis.
<em>MLST</em>, <em>4</em>(2), 025021. (<a
href="https://doi.org/10.1088/2632-2153/acd2a5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic identification of salient features in large medical datasets, particularly in chest x-ray (CXR) images, is a crucial research area. Accurately detecting critical findings such as emphysema, pneumothorax, and chronic bronchitis can aid radiologists in prioritizing time-sensitive cases and screening for abnormalities. However, traditional deep neural network approaches often require bounding box annotations, which can be time-consuming and challenging to obtain. This study proposes an explainable ensemble learning approach, CX-Net, for lung segmentation and diagnosing lung disorders using CXR images. We compare four state-of-the-art convolutional neural network models, including feature pyramid network, U-Net, LinkNet, and a customized U-Net model with ImageNet feature extraction, data augmentation, and dropout regularizations. All models are trained on the Montgomery and VinDR-CXR datasets with and without segmented ground-truth masks. To achieve model explainability, we integrate SHapley Additive exPlanations (SHAP) and gradient-weighted class activation mapping (Grad-CAM) techniques, which enable a better understanding of the decision-making process and provide visual explanations of critical regions within the CXR images. By employing ensembling, our outlier-resistant CX-Net achieves superior performance in lung segmentation, with Jaccard overlap similarity of 0.992, Dice coefficients of 0.994, precision of 0.993, recall of 0.980, and accuracy of 0.976. The proposed approach demonstrates strong generalization capabilities on the VinDr-CXR dataset and is the first study to use these datasets for semantic lung segmentation with semi-supervised localization. In conclusion, this paper presents an explainable ensemble learning approach for lung segmentation and diagnosing lung disorders using CXR images. Extensive experimental results show that our method efficiently and accurately extracts regions of interest in CXR images from publicly available datasets, indicating its potential for integration into clinical decision support systems. Furthermore, incorporating SHAP and Grad-CAM techniques further enhances the interpretability and trustworthiness of the AI-driven diagnostic system.},
  archive      = {J_MLST},
  author       = {Agughasi Victor Ikechukwu and Murali S},
  doi          = {10.1088/2632-2153/acd2a5},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025021},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {CX-net: An efficient ensemble semantic deep neural network for ROI identification from chest-x-ray images for COPD diagnosis},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Closed-loop control of a noisy qubit with reinforcement
learning. <em>MLST</em>, <em>4</em>(2), 025020. (<a
href="https://doi.org/10.1088/2632-2153/acd048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exotic nature of quantum mechanics differentiates machine learning applications in the quantum realm from classical ones. Stream learning is a powerful approach that can be applied to extract knowledge continuously from quantum systems in a wide range of tasks. In this paper, we propose a deep reinforcement learning method that uses streaming data from a continuously measured qubit in the presence of detuning, dephasing, and relaxation. The model receives streaming quantum information for learning and decision-making, providing instant feedback on the quantum system. We also explore the agent&#39;s adaptability to other quantum noise patterns through transfer learning. Our protocol offers insights into closed-loop quantum control, potentially advancing the development of quantum technologies.},
  archive      = {J_MLST},
  author       = {Yongcheng Ding and Xi Chen and Rafael Magdalena-Benedito and José D Martín-Guerrero},
  doi          = {10.1088/2632-2153/acd048},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025020},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Closed-loop control of a noisy qubit with reinforcement learning},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Clarifying trust of materials property predictions using
neural networks with distribution-specific uncertainty quantification.
<em>MLST</em>, <em>4</em>(2), 025019. (<a
href="https://doi.org/10.1088/2632-2153/accace">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is critical that machine learning (ML) model predictions be trustworthy for high-throughput catalyst discovery approaches. Uncertainty quantification (UQ) methods allow estimation of the trustworthiness of an ML model, but these methods have not been well explored in the field of heterogeneous catalysis. Herein, we investigate different UQ methods applied to a crystal graph convolutional neural network to predict adsorption energies of molecules on alloys from the Open Catalyst 2020 dataset, the largest existing heterogeneous catalyst dataset. We apply three UQ methods to the adsorption energy predictions, namely k -fold ensembling, Monte Carlo dropout, and evidential regression. The effectiveness of each UQ method is assessed based on accuracy, sharpness, dispersion, calibration, and tightness. Evidential regression is demonstrated to be a powerful approach for rapidly obtaining tunable, competitively trustworthy UQ estimates for heterogeneous catalysis applications when using neural networks. Recalibration of model uncertainties is shown to be essential in practical screening applications of catalysts using uncertainties.},
  archive      = {J_MLST},
  author       = {Cameron J Gruich and Varun Madhavan and Yixin Wang and Bryan R Goldsmith},
  doi          = {10.1088/2632-2153/accace},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025019},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Clarifying trust of materials property predictions using neural networks with distribution-specific uncertainty quantification},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Extending the extended dynamic mode decomposition with
latent observables: The latent EDMD framework. <em>MLST</em>,
<em>4</em>(2), 025018. (<a
href="https://doi.org/10.1088/2632-2153/acccd6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bernard O Koopman proposed an alternative view of dynamical systems based on linear operator theory, in which the time evolution of a dynamical system is analogous to the linear propagation of an infinite-dimensional vector of observables. In the last few years, several works have shown that finite-dimensional approximations of this operator can be extremely useful for several applications, such as prediction, control, and data assimilation. In particular, a Koopman representation of a dynamical system with a finite number of dimensions will avoid all the problems caused by nonlinearity in classical state-space models. In this work, the identification of finite-dimensional approximations of the Koopman operator and its associated observables is expressed through the inversion of an unknown augmented linear dynamical system. The proposed framework can be regarded as an extended dynamical mode decomposition that uses a collection of latent observables. The use of a latent dictionary applies to a large class of dynamical regimes, and it provides new means for deriving appropriate finite-dimensional linear approximations to high-dimensional nonlinear systems.},
  archive      = {J_MLST},
  author       = {Said Ouala and Bertrand Chapron and Fabrice Collard and Lucile Gaultier and Ronan Fablet},
  doi          = {10.1088/2632-2153/acccd6},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025018},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Extending the extended dynamic mode decomposition with latent observables: The latent EDMD framework},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Probe microscopy is all you need *. <em>MLST</em>,
<em>4</em>(2), 023001. (<a
href="https://doi.org/10.1088/2632-2153/acccd5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We pose that microscopy offers an ideal real-world experimental environment for the development and deployment of active Bayesian and reinforcement learning methods. Indeed, the tremendous progress achieved by machine learning (ML) and artificial intelligence over the last decade has been largely achieved via the utilization of static data sets, from the paradigmatic MNIST to the bespoke corpora of text and image data used to train large models such as GPT3, DALL·E and others. However, it is now recognized that continuous, minute improvements to state-of-the-art do not necessarily translate to advances in real-world applications. We argue that a promising pathway for the development of ML methods is via the route of domain-specific deployable algorithms in areas such as electron and scanning probe microscopy and chemical imaging. This will benefit both fundamental physical studies and serve as a test bed for more complex autonomous systems such as robotics and manufacturing. Favorable environment characteristics of scanning and electron microscopy include low risk, extensive availability of domain-specific priors and rewards, relatively small effects of exogenous variables, and often the presence of both upstream first principles as well as downstream learnable physical models for both statics and dynamics. Recent developments in programmable interfaces, edge computing, and access to application programming interfaces (APIs) facilitating microscope control, all render the deployment of ML codes on operational microscopes straightforward. We discuss these considerations and hope that these arguments will lead to create novel set of development targets for the ML community by accelerating both real world ML applications and scientific progress.},
  archive      = {J_MLST},
  author       = {Sergei V Kalinin and Rama Vasudevan and Yongtao Liu and Ayana Ghosh and Kevin Roccapriore and Maxim Ziatdinov},
  doi          = {10.1088/2632-2153/acccd5},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {023001},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Probe microscopy is all you need *},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Numerical and geometrical aspects of flow-based variational
quantum monte carlo. <em>MLST</em>, <em>4</em>(2), 021001. (<a
href="https://doi.org/10.1088/2632-2153/acc8b9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article aims to summarize recent and ongoing efforts to simulate continuous-variable quantum systems using flow-based variational quantum Monte Carlo techniques, focusing for pedagogical purposes on the example of bosons in the field amplitude (quadrature) basis. Particular emphasis is placed on the variational real- and imaginary-time evolution problems, carefully reviewing the stochastic estimation of the time-dependent variational principles and their relationship with information geometry. Some practical instructions are provided to guide the implementation of a PyTorch code. The review is intended to be accessible to researchers interested in machine learning and quantum information science.},
  archive      = {J_MLST},
  author       = {James Stokes and Brian Chen and Shravan Veerapaneni},
  doi          = {10.1088/2632-2153/acc8b9},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {021001},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Numerical and geometrical aspects of flow-based variational quantum monte carlo},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tackling multimodal device distributions in inverse photonic
design using invertible neural networks. <em>MLST</em>, <em>4</em>(2),
02LT02. (<a href="https://doi.org/10.1088/2632-2153/acd619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show how conditional generative neural networks can be used to efficiently find nanophotonic devices with desired properties, also known as inverse photonic design. Machine learning has emerged as a promising approach to overcome limitations imposed by the dimensionality and topology of the parameter space. Importantly, traditional optimization routines assume an invertible mapping between the design parameters and response. However, different designs may have comparable or even identical performance confusing the optimization algorithm when performing inverse design. Our generative modeling approach provides the full distribution of possible solutions to the inverse design problem, including multiple solutions. We compare a commonly used conditional variational autoencoder (cVAE) and a conditional invertible neural network (cINN) on a proof-of-principle nanophotonic problem, consisting in tailoring the transmission spectrum trough a metallic film milled by subwavelength indentations. We show how cINNs have superior flexibility compared to cVAEs when dealing with multimodal device distributions.},
  archive      = {J_MLST},
  author       = {Michel Frising and Jorge Bravo-Abad and Ferry Prins},
  doi          = {10.1088/2632-2153/acd619},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {02LT02},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Tackling multimodal device distributions in inverse photonic design using invertible neural networks},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning enhanced noise spectroscopy of a spin qubit
environment. <em>MLST</em>, <em>4</em>(2), 02LT01. (<a
href="https://doi.org/10.1088/2632-2153/acd2a6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The undesired interaction of a quantum system with its environment generally leads to a coherence decay of superposition states in time. A precise knowledge of the spectral content of the noise induced by the environment is crucial to protect qubit coherence and optimize its employment in quantum device applications. We experimentally show that the use of neural networks (NNs) can highly increase the accuracy of noise spectroscopy, by reconstructing the power spectral density that characterizes an ensemble of carbon impurities around a nitrogen-vacancy (NV) center in diamond. NNs are trained over spin coherence functions of the NV center subjected to different Carr–Purcell sequences, typically used for dynamical decoupling (DD). As a result, we determine that deep learning models can be more accurate than standard DD noise-spectroscopy techniques, by requiring at the same time a much smaller number of DD sequences.},
  archive      = {J_MLST},
  author       = {Stefano Martina and Santiago Hernández-Gómez and Stefano Gherardini and Filippo Caruso and Nicole Fabbri},
  doi          = {10.1088/2632-2153/acd2a6},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {02LT01},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Deep learning enhanced noise spectroscopy of a spin qubit environment},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Encrypted machine learning of molecular quantum properties.
<em>MLST</em>, <em>4</em>(2), 025017. (<a
href="https://doi.org/10.1088/2632-2153/acc928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large machine learning (ML) models with improved predictions have become widely available in the chemical sciences. Unfortunately, these models do not protect the privacy necessary within commercial settings, prohibiting the use of potentially extremely valuable data by others. Encrypting the prediction process can solve this problem by double-blind model evaluation and prohibits the extraction of training or query data. However, contemporary ML models based on fully homomorphic encryption or federated learning are either too expensive for practical use or have to trade higher speed for weaker security. We have implemented secure and computationally feasible encrypted ML models using oblivious transfer enabling and secure predictions of molecular quantum properties across chemical compound space. However, we find that encrypted predictions using kernel ridge regression models are a million times more expensive than without encryption. This demonstrates a dire need for a compact ML model architecture, including molecular representation and kernel matrix size, that minimizes model evaluation costs.},
  archive      = {J_MLST},
  author       = {Jan Weinreich and Guido Falk von Rudorff and O Anatole von Lilienfeld},
  doi          = {10.1088/2632-2153/acc928},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025017},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Encrypted machine learning of molecular quantum properties},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards automatic setup of 18 MeV electron beamline using
machine learning. <em>MLST</em>, <em>4</em>(2), 025016. (<a
href="https://doi.org/10.1088/2632-2153/acce21">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the performance-critical stability and brightness of the electron bunch at injection into the proton-driven plasma wakefield at the AWAKE CERN experiment, automation approaches based on unsupervised machine learning (ML) were developed and deployed. Numerical optimisers were tested together with different model-free reinforcement learning (RL) agents. In order to avoid any bias, RL agents have been trained also using a completely unsupervised state encoding using auto-encoders. To aid hyper-parameter selection, a full synthetic model of the beamline was constructed using a variational auto-encoder trained to generate surrogate data from equipment settings. This paper describes the novel approaches based on deep learning and RL to aid the automatic setup of a low energy line, as the one used to deliver beam to the AWAKE facility. The results obtained with the different ML approaches, including automatic unsupervised feature extraction from images using computer vision are presented. The prospects for operational deployment and wider applicability are discussed.},
  archive      = {J_MLST},
  author       = {Francesco Maria Velotti and Brennan Goddard and Verena Kain and Rebecca Ramjiawan and Giovanni Zevi Della Porta and Simon Hirlaender},
  doi          = {10.1088/2632-2153/acce21},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025016},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Towards automatic setup of 18 MeV electron beamline using machine learning},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Effectual pre-processing with quantization error elimination
in pose detector with the aid of image-guided progressive graph
convolution network (IGP-GCN) for multi-person pose estimation.
<em>MLST</em>, <em>4</em>(2), 025015. (<a
href="https://doi.org/10.1088/2632-2153/acc9fc">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-person pose estimation (MPE) remains a significant and intricate issue in computer vision. This is considered the human skeleton joint identification issue and resolved by the joint heat map regression network lately. Learning robust and discriminative feature maps is essential for attaining precise pose estimation. Even though the present methodologies established vital progression via feature map&#39;s interlayer fusion and intralevel fusion, some studies show consideration for the combination of these two methodologies. This study focuses upon three phases of pre-processing stages like occlusion elimination, suppression strategy, and heat map methodology to lessen noise within the database. Subsequent to pre-processing errors will be eliminated by employing the quantization phase by embracing the pose detector. Lastly, Image-Guided Progressive Graph Convolution Network (IGP-GCN) has been built for MPE. This IGP-GCN consistently learns rich fundamental spatial information by merging features inside the layers. In order to enhance high-level semantic information and reuse low-level spatial information for correct keypoint representation, this also provides hierarchical connections across feature maps of the same resolution for interlayer fusion. Furthermore, a missing connection between the output high level information and low-level information was noticed. For resolving the issue, the effectual shuffled attention mechanism has been proffered. This shuffle intends to support the cross-channel data interchange between pyramid feature maps, whereas attention creates a trade-off between the high level and low-level representations of output features. This proffered methodology can be called Occlusion Removed_Image Guided Progressive Graph Convolution Network (OccRem_IGP-GCN), and, thus, this can be correlated with the other advanced methodologies. The experimental outcomes exhibit that the OccRem_IGP-GCN methodology attains 98% of accuracy, 93% of sensitivity, 92% of specificity, 88% of f1-score, 42% of relative absolute error, and 30% of mean absolute error.},
  archive      = {J_MLST},
  author       = {Jhansi Rani Challapalli and Nagaraju Devarakonda},
  doi          = {10.1088/2632-2153/acc9fc},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025015},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Effectual pre-processing with quantization error elimination in pose detector with the aid of image-guided progressive graph convolution network (IGP-GCN) for multi-person pose estimation},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Plug &amp; play directed evolution of proteins with
gradient-based discrete MCMC. <em>MLST</em>, <em>4</em>(2), 025014. (<a
href="https://doi.org/10.1088/2632-2153/accacd">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A long-standing goal of machine-learning-based protein engineering is to accelerate the discovery of novel mutations that improve the function of a known protein. We introduce a sampling framework for evolving proteins in silico that supports mixing and matching a variety of unsupervised models, such as protein language models, and supervised models that predict protein function from sequence. By composing these models, we aim to improve our ability to evaluate unseen mutations and constrain search to regions of sequence space likely to contain functional proteins. Our framework achieves this without any model fine-tuning or re-training by constructing a product of experts distribution directly in discrete protein space. Instead of resorting to brute force search or random sampling, which is typical of classic directed evolution, we introduce a fast Markov chain Monte Carlo sampler that uses gradients to propose promising mutations. We conduct in silico directed evolution experiments on wide fitness landscapes and across a range of different pre-trained unsupervised models, including a 650 M parameter protein language model. Our results demonstrate an ability to efficiently discover variants with high evolutionary likelihood as well as estimated activity multiple mutations away from a wild type protein, suggesting our sampler provides a practical and effective new paradigm for machine-learning-based protein engineering.},
  archive      = {J_MLST},
  author       = {Patrick Emami and Aidan Perreault and Jeffrey Law and David Biagioni and Peter St. John},
  doi          = {10.1088/2632-2153/accacd},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025014},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Plug &amp; play directed evolution of proteins with gradient-based discrete MCMC},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DeepAstroUDA: Semi-supervised universal domain adaptation
for cross-survey galaxy morphology classification and anomaly detection.
<em>MLST</em>, <em>4</em>(2), 025013. (<a
href="https://doi.org/10.1088/2632-2153/acca5f">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence methods show great promise in increasing the quality and speed of work with large astronomical datasets, but the high complexity of these methods leads to the extraction of dataset-specific, non-robust features. Therefore, such methods do not generalize well across multiple datasets. We present a universal domain adaptation method, DeepAstroUDA , as an approach to overcome this challenge. This algorithm performs semi-supervised domain adaptation (DA) and can be applied to datasets with different data distributions and class overlaps. Non-overlapping classes can be present in any of the two datasets (the labeled source domain, or the unlabeled target domain), and the method can even be used in the presence of unknown classes. We apply our method to three examples of galaxy morphology classification tasks of different complexities (three-class and ten-class problems), with anomaly detection: (1) datasets created after different numbers of observing years from a single survey (Legacy Survey of Space and Time mock data of one and ten years of observations); (2) data from different surveys (Sloan Digital Sky Survey (SDSS) and DECaLS); and (3) data from observing fields with different depths within one survey (wide field and Stripe 82 deep field of SDSS). For the first time, we demonstrate the successful use of DA between very discrepant observational datasets. DeepAstroUDA is capable of bridging the gap between two astronomical surveys, increasing classification accuracy in both domains (up to 40\% on the unlabeled data), and making model performance consistent across datasets. Furthermore, our method also performs well as an anomaly detection algorithm and successfully clusters unknown class samples even in the unlabeled target dataset.},
  archive      = {J_MLST},
  author       = {A Ćiprijanović and A Lewis and K Pedro and S Madireddy and B Nord and G N Perdue and S M Wild},
  doi          = {10.1088/2632-2153/acca5f},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025013},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {DeepAstroUDA: Semi-supervised universal domain adaptation for cross-survey galaxy morphology classification and anomaly detection},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven prediction of the performance of enhanced
surfaces from an extensive CFD-generated parametric search space.
<em>MLST</em>, <em>4</em>(2), 025012. (<a
href="https://doi.org/10.1088/2632-2153/acca60">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning has rapidly been adopted in virtually all areas of engineering in recent years. This paper develops a machine learning model capable of predicting the performance of parametrically generated enhanced microsurface geometries for cooling electronic and power systems. Designing this type of geometry usually involves expensive computational fluid dynamics (CFD) simulations, limiting the number of candidate geometries that may be tested. For this reason, when searching for new geometries for a given application, designs are usually restricted to a simplified subset of basic shapes to reduce the complexity and dimension of the search space. In an effort to add geometrical diversity and explore singular morphologies, we have developed an algorithm capable of characterizing almost any geometry, based on an extensive CFD database with more than 15 800 geometries obtained from a Monte Carlo sampling of the space of possible geometries. With this framework, it is possible to estimate various quantities of interest, such as the heat flux in the enhanced zone and total drag, with relative errors below 10% and 2%, respectively. Thus, we establish the utility of machine learning to develop surrogate models for the rapid performance prediction of novel enhanced microsurfaces.},
  archive      = {J_MLST},
  author       = {A Larrañaga and S L Brunton and J Martínez and S Chapela and J Porteiro},
  doi          = {10.1088/2632-2153/acca60},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025012},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Data-driven prediction of the performance of enhanced surfaces from an extensive CFD-generated parametric search space},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The reusability prior: Comparing deep learning models
without training. <em>MLST</em>, <em>4</em>(2), 025011. (<a
href="https://doi.org/10.1088/2632-2153/acc713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various choices can affect the performance of deep learning models. We conjecture that differences in the number of contexts for model components during training are critical. We generalize this notion by defining the reusability prior as follows: model components are forced to function in diverse contexts not only due to the training data, augmentation, and regularization choices, but also due to the model design itself. We focus on the design aspect and introduce a graph-based methodology to estimate the number of contexts for each learnable parameter. This allows a comparison of models without requiring any training. We provide supporting evidence with experiments using cross-layer parameter sharing on CIFAR-10, CIFAR-100, and Imagenet-1K benchmarks. We give examples of models that share parameters outperforming baselines that have at least 60% more parameters. The graph-analysis-based quantities we introduced for the reusability prior align well with the results, including at least two important edge cases. We conclude that the reusability prior provides a viable research direction for model analysis based on a very simple idea: counting the number of contexts for model parameters.},
  archive      = {J_MLST},
  author       = {Aydın Göze Polat and Ferda Nur Alpaslan},
  doi          = {10.1088/2632-2153/acc713},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025011},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {The reusability prior: Comparing deep learning models without training},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamics of supercooled liquids from static averaged
quantities using machine learning. <em>MLST</em>, <em>4</em>(2), 025010.
(<a href="https://doi.org/10.1088/2632-2153/acc7e1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a machine-learning approach to predict the complex non-Markovian dynamics of supercooled liquids from static averaged quantities. Compared to techniques based on particle propensity, our method is built upon a theoretical framework that uses as input and output system-averaged quantities, thus being easier to apply in an experimental context where particle resolved information is not available. In this work, we train a deep neural network to predict the self intermediate scattering function of binary mixtures using their static structure factor as input. While its performance is excellent for the temperature range of the training data, the model also retains some transferability in making decent predictions at temperatures lower than the ones it was trained for, or when we use it for similar systems. We also develop an evolutionary strategy that is able to construct a realistic memory function underlying the observed non-Markovian dynamics. This method lets us conclude that the memory function of supercooled liquids can be effectively parameterized as the sum of two stretched exponentials, which physically corresponds to two dominant relaxation modes.},
  archive      = {J_MLST},
  author       = {Simone Ciarella and Massimiliano Chiappini and Emanuele Boattini and Marjolein Dijkstra and Liesbeth M C Janssen},
  doi          = {10.1088/2632-2153/acc7e1},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025010},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Dynamics of supercooled liquids from static averaged quantities using machine learning},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simulation-based inference of single-molecule force
spectroscopy. <em>MLST</em>, <em>4</em>(2), 025009. (<a
href="https://doi.org/10.1088/2632-2153/acc8b8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-molecule force spectroscopy (smFS) is a powerful approach to studying molecular self-organization. However, the coupling of the molecule with the ever-present experimental device introduces artifacts, that complicate the interpretation of these experiments. Performing statistical inference to learn hidden molecular properties is challenging because these measurements produce non-Markovian time series, and even minimal models lead to intractable likelihoods. To overcome these challenges, we developed a computational framework built on novel statistical methods called simulation-based inference (SBI). SBI enabled us to directly estimate the Bayesian posterior, and extract reduced quantitative models from smFS, by encoding a mechanistic model into a simulator in combination with probabilistic deep learning. Using synthetic data, we could systematically disentangle the measurement of hidden molecular properties from experimental artifacts. The integration of physical models with machine-learning density estimation is general, transparent, easy to use, and broadly applicable to other types of biophysical experiments.},
  archive      = {J_MLST},
  author       = {Lars Dingeldein and Pilar Cossio and Roberto Covino},
  doi          = {10.1088/2632-2153/acc8b8},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025009},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Simulation-based inference of single-molecule force spectroscopy},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ICEGAN: Inverse covariance estimating generative adversarial
network. <em>MLST</em>, <em>4</em>(2), 025008. (<a
href="https://doi.org/10.1088/2632-2153/acc638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the recent explosive expansion of deep learning, several challenging problems in a variety of fields have been handled by deep learning, yet deep learning methods have been limited in their application to the network estimation problem. While network estimation has a possibility to be a useful method in various domains, deep learning-based network estimation has a limitation in that the number of variables must be fixed and the estimation cannot be performed by convolutional layers. In this study, we propose a Generative Adversarial Network (GAN) based method, called Inverse Covariance Estimating GAN (ICEGAN), which can alleviate these limitations. In ICEGAN, the concepts in Cycle-Consistent Adversarial Networks are modified for the problem and employed to adopt gene expression data. Additionally, the Monte Carlo approach is used to address the fixed size in the network estimation process. Thus, sub-networks are sampled from the entire network and estimated by ICEGAN; then, the Monte Carlo approach reconstructs the entire network with the estimations. In the simulation study, ICEGAN demonstrated superior performances compared to conventional models and the ordinary GAN model in estimating networks. Specifically, ICEGAN outperformed an ordinary GAN by 85.9% on average when the models were evaluated using the area under curve. In addition, ICEGAN performed gene network estimation of breast cancer using a gene expression dataset. Consequently, ICEGAN demonstrated promising results, considering the deep learning-based network estimation and the proposed Monte Carlo approach for GAN models, both of which can be expanded to other domains.},
  archive      = {J_MLST},
  author       = {Insoo Kim and Minhyeok Lee and Junhee Seok},
  doi          = {10.1088/2632-2153/acc638},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025008},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {ICEGAN: Inverse covariance estimating generative adversarial network},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bayesian learning of parameterised quantum circuits.
<em>MLST</em>, <em>4</em>(2), 025007. (<a
href="https://doi.org/10.1088/2632-2153/acc8b7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently available quantum computers suffer from constraints including hardware noise and a limited number of qubits. As such, variational quantum algorithms that utilise a classical optimiser in order to train a parameterised quantum circuit have drawn significant attention for near-term practical applications of quantum technology. In this work, we take a probabilistic point of view and reformulate the classical optimisation as an approximation of a Bayesian posterior. The posterior is induced by combining the cost function to be minimised with a prior distribution over the parameters of the quantum circuit. We describe a dimension reduction strategy based on a maximum a posteriori point estimate with a Laplace prior. Experiments on the Quantinuum H1-2 computer show that the resulting circuits are faster to execute and less noisy than the circuits trained without the dimension reduction strategy. We subsequently describe a posterior sampling strategy based on stochastic gradient Langevin dynamics. Numerical simulations on three different problems show that the strategy is capable of generating samples from the full posterior and avoiding local optima.},
  archive      = {J_MLST},
  author       = {Samuel Duffield and Marcello Benedetti and Matthias Rosenkranz},
  doi          = {10.1088/2632-2153/acc8b7},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025007},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Bayesian learning of parameterised quantum circuits},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A robust estimator of mutual information for deep learning
interpretability. <em>MLST</em>, <em>4</em>(2), 025006. (<a
href="https://doi.org/10.1088/2632-2153/acc444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop the use of mutual information (MI), a well-established metric in information theory, to interpret the inner workings of deep learning (DL) models. To accurately estimate MI from a finite number of samples, we present GMM-MI (pronounced &#39;Jimmie&#39;), an algorithm based on Gaussian mixture models that can be applied to both discrete and continuous settings. GMM-MI is computationally efficient, robust to the choice of hyperparameters and provides the uncertainty on the MI estimate due to the finite sample size. We extensively validate GMM-MI on toy data for which the ground truth MI is known, comparing its performance against established MI estimators. We then demonstrate the use of our MI estimator in the context of representation learning, working with synthetic data and physical datasets describing highly non-linear processes. We train DL models to encode high-dimensional data within a meaningful compressed (latent) representation, and use GMM-MI to quantify both the level of disentanglement between the latent variables, and their association with relevant physical quantities, thus unlocking the interpretability of the latent representation. We make GMM-MI publicly available in this GitHub repository.},
  archive      = {J_MLST},
  author       = {Davide Piras and Hiranya V Peiris and Andrew Pontzen and Luisa Lucie-Smith and Ningyuan Guo and Brian Nord},
  doi          = {10.1088/2632-2153/acc444},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025006},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A robust estimator of mutual information for deep learning interpretability},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A generative adversarial network to speed up optical monte
carlo simulations. <em>MLST</em>, <em>4</em>(2), 025005. (<a
href="https://doi.org/10.1088/2632-2153/acc782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detailed simulation of optical photon transport and detection in radiation detectors is often used for crystal-based gamma detector optimization. However, the time and memory burden associated with the track-wise approach to particle transport and detection in commonly used Monte Carlo codes makes optical simulation prohibitive at a system level, where hundreds to thousands of scintillators must be modeled. Consequently, current large system simulations do not include detailed detector models to analyze the potential performance gain with new radiation detector technologies. Generative adversarial networks (GANs) are explored as a tool to speed up the optical simulation of crystal-based detectors. These networks learn training datasets made of high-dimensional data distributions. Once trained, the resulting model can produce distributions belonging to the training data probability distribution. In this work, we present the proof of concept of using a GAN to enable high-fidelity optical simulations of nuclear medicine systems, mitigating their computational complexity. The architecture of the first network version and high-fidelity training dataset is discussed. The latter is generated through accurate optical simulation with GATE/Geant4, and contains the position, direction, and energy distributions of the optical photons emitted by 511 keV gamma rays in bismuth germanate and detected on the photodetector face. We compare the GAN and simulation-generated distributions in terms of similarity using the Jensen–Shannon distance. Excellent agreement was found with similarity values higher than 93.5% for all distributions. Moreover, the GAN speeded the optical photon distribution generation by up to two orders of magnitude. These very promising results have the potential to drastically change the use of nuclear imaging system optical simulations by enabling high-fidelity system-level simulations in reasonable computation times. The ultimate is to integrate the GAN within GATE/Geant4 since numerous applications (large detectors, bright scintillators, Cerenkov-based timing positron emission tomography) can benefit from these improvements.},
  archive      = {J_MLST},
  author       = {Carlotta Trigila and Anirudh Srikanth and Emilie Roncali},
  doi          = {10.1088/2632-2153/acc782},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025005},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A generative adversarial network to speed up optical monte carlo simulations},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ultra-low latency recurrent neural network inference on
FPGAs for physics applications with hls4ml. <em>MLST</em>,
<em>4</em>(2), 025004. (<a
href="https://doi.org/10.1088/2632-2153/acc0d7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent neural networks have been shown to be effective architectures for many tasks in high energy physics, and thus have been widely adopted. Their use in low-latency environments has, however, been limited as a result of the difficulties of implementing recurrent architectures on field-programmable gate arrays (FPGAs). In this paper we present an implementation of two types of recurrent neural network layers—long short-term memory and gated recurrent unit—within the hls4ml framework. We demonstrate that our implementation is capable of producing effective designs for both small and large models, and can be customized to meet specific design requirements for inference latencies and FPGA resources. We show the performance and synthesized designs for multiple neural networks, many of which are trained specifically for jet identification tasks at the CERN Large Hadron Collider.},
  archive      = {J_MLST},
  author       = {Elham E Khoda and Dylan Rankin and Rafael Teixeira de Lima and Philip Harris and Scott Hauck and Shih-Chieh Hsu and Michael Kagan and Vladimir Loncar and Chaitanya Paikara and Richa Rao and Sioni Summers and Caterina Vernieri and Aaron Wang},
  doi          = {10.1088/2632-2153/acc0d7},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025004},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Ultra-low latency recurrent neural network inference on FPGAs for physics applications with hls4ml},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantum kerr learning. <em>MLST</em>, <em>4</em>(2), 025003.
(<a href="https://doi.org/10.1088/2632-2153/acc726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum machine learning is a rapidly evolving field of research that could facilitate important applications for quantum computing and also significantly impact data-driven sciences. In our work, based on various arguments from complexity theory and physics, we demonstrate that a single Kerr mode can provide some &#39;quantum enhancements&#39; when dealing with kernel-based methods. Using kernel properties, neural tangent kernel theory, first-order perturbation theory of the Kerr non-linearity, and non-perturbative numerical simulations, we show that quantum enhancements could happen in terms of convergence time and generalization error. Furthermore, we make explicit indications on how higher-dimensional input data could be considered. Finally, we propose an experimental protocol, that we call quantum Kerr learning , based on circuit QED.},
  archive      = {J_MLST},
  author       = {Junyu Liu and Changchun Zhong and Matthew Otten and Anirban Chandra and Cristian L Cortes and Chaoyang Ti and Stephen K Gray and Xu Han},
  doi          = {10.1088/2632-2153/acc726},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025003},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Quantum kerr learning},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of the morphological evolution of a splashing
drop using an encoder–decoder. <em>MLST</em>, <em>4</em>(2), 025002. (<a
href="https://doi.org/10.1088/2632-2153/acc727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The impact of a drop on a solid surface is an important phenomenon that has various implications and applications. However, the multiphase nature of this phenomenon causes complications in the prediction of its morphological evolution, especially when the drop splashes. While most machine-learning-based drop-impact studies have centred around physical parameters, this study used a computer-vision strategy by training an encoder–decoder to predict the drop morphologies using image data. Herein, we show that this trained encoder–decoder is able to successfully generate videos that show the morphologies of splashing and non-splashing drops. Remarkably, in each frame of these generated videos, the spreading diameter of the drop was found to be in good agreement with that of the actual videos. Moreover, there was also a high accuracy in splashing/non-splashing prediction. These findings demonstrate the ability of the trained encoder–decoder to generate videos that can accurately represent the drop morphologies. This approach provides a faster and cheaper alternative to experimental and numerical studies.},
  archive      = {J_MLST},
  author       = {Jingzu Yee and Daichi Igarashi(五十嵐大地) and Shun Miyatake(宮武駿) and Yoshiyuki Tagawa(田川義之)},
  doi          = {10.1088/2632-2153/acc727},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025002},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Prediction of the morphological evolution of a splashing drop using an encoder–decoder},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive sampling for accelerating neutron diffraction-based
strain mapping *. <em>MLST</em>, <em>4</em>(2), 025001. (<a
href="https://doi.org/10.1088/2632-2153/acc512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neutron diffraction is a useful technique for mapping residual strains in dense metal objects. The technique works by placing an object in the path of a neutron beam, measuring the diffracted signals and inferring the local lattice strain values from the measurement. In order to map the strains across the entire object, the object is stepped one position at a time in the path of the neutron beam, typically in raster order, and at each position a strain value is estimated. Typical dwell times at neutron diffraction instruments result in an overall measurement that can take several hours to map an object that is several tens of centimeters in each dimension at a resolution of a few millimeters, during which the end users do not have an estimate of the global strain features and are at risk of incomplete information in case of instruments outages. In this paper, we propose an object adaptive sampling strategy to measure the significant points first. We start with a small initial uniform set of measurement points across the object to be mapped, compute the strain in those positions and use a machine learning technique to predict the next position to measure in the object. Specifically, we use a Bayesian optimization based on a Gaussian process regression method to infer the underlying strain field from a sparse set of measurements and predict the next most informative positions to measure based on estimates of the mean and variance in the strain fields estimated from the previously measured points. We demonstrate our real-time measure-infer-predict workflow on additively manufactured steel parts—demonstrating that we can get an accurate strain estimate even with 30%–40% of the typical number of measurements—leading the path to faster strain mapping with useful real-time feedback. We emphasize that the proposed method is general and can be used for fast mapping of other material properties such as phase fractions from time-consuming point-wise neutron measurements.},
  archive      = {J_MLST},
  author       = {S V Venkatakrishnan and Chris M Fancher and Maxim Ziatdinov and Rama Vasudevan and Kyle Saleeby and James Haley and Dunji Yu and Ke An and Alex Plotkowski},
  doi          = {10.1088/2632-2153/acc512},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025001},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Adaptive sampling for accelerating neutron diffraction-based strain mapping *},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predicting thermoelectric transport properties from
composition with attention-based deep learning. <em>MLST</em>,
<em>4</em>(1), 015037. (<a
href="https://doi.org/10.1088/2632-2153/acc4a9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thermoelectric materials can be used to construct devices which recycle waste heat into electricity. However, the best known thermoelectrics are based on rare, expensive or even toxic elements, which limits their widespread adoption. To enable deployment on global scales, new classes of effective thermoelectrics are thus required. Ab initio models of transport properties can help in the design of new thermoelectrics, but they are still too computationally expensive to be solely relied upon for high-throughput screening in the vast chemical space of all possible candidates. Here, we use models constructed with modern machine learning techniques to scan very large areas of inorganic materials space for novel thermoelectrics, using composition as an input. We employ an attention-based deep learning model, trained on data derived from ab initio calculations, to predict a material&#39;s Seebeck coefficient, electrical conductivity, and power factor over a range of temperatures and n - or p -type doping levels, with surprisingly good performance given the simplicity of the input, and with significantly lower computational cost. The results of applying the model to a space of known and hypothetical binary and ternary selenides reveal several materials that may represent promising thermoelectrics. Our study establishes a protocol for composition-based prediction of thermoelectric behaviour that can be easily enhanced as more accurate theoretical or experimental databases become available.},
  archive      = {J_MLST},
  author       = {Luis M Antunes and Keith T Butler and Ricardo Grau-Crespo},
  doi          = {10.1088/2632-2153/acc4a9},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {1},
  pages        = {015037},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Predicting thermoelectric transport properties from composition with attention-based deep learning},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). B2-net: An artificial intelligence powered machine learning
framework for the classification of pneumonia in chest x-ray images.
<em>MLST</em>, <em>4</em>(1), 015036. (<a
href="https://doi.org/10.1088/2632-2153/acc30f">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A chest x-ray radiograph is still the global standard for diagnosing pneumonia and helps distinguish between bacterial and viral pneumonia. Despite several studies, radiologists and physicians still have trouble correctly diagnosing and classifying pneumonia without false negatives. Modern mathematical modeling and artificial intelligence could help to reduce false-negative rates and improve diagnostic accuracy. This research aims to create a novel and efficient multiclass machine learning framework for analyzing and classifying chest x-ray images on a graphics processing unit (GPU). Researchers initially applied a geometric augmentation using a positional transformation function to the original dataset to enhance the sample size and aid future transfer learning. Models with the best accuracy, area under the receiver operating characteristics (AUROC), F1 score, precision, recall, and specificity are chosen from a pool of nine state-of-the-art neural network models. The best-performing models are then retrained using an ensemble technique using depth-wise convolutions, demonstrating significant improvements over the baseline models employed in this research. With a remarkable 97.69% accuracy, 100% recall, and 0.9977 AUROC scores, the proposed Bek-Bas network (B2-Net) model can differentiate between normal, bacterial, and viral pneumonia in chest x-ray images. A superior model is retrained using the chosen dense convolutional network-160, residual network-121, and visual geometry group network-16 ensemble models. The diagnostic accuracy of the x-ray classification unit is enhanced by the newly designed multiclass network, the B2-Net model. The developed GPU-based framework has been examined and tested to the highest clinical standards. After extensive clinical testing, the final B2-Net model is implemented on an NVIDIA Jetson Nano GPU computer. Healthcare facilities have confirmed the B2-Net is the most effective framework for identifying bacterial and viral pneumonia in chest x-rays.},
  archive      = {J_MLST},
  author       = {K M Abubeker and S Baskar},
  doi          = {10.1088/2632-2153/acc30f},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {1},
  pages        = {015036},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {B2-net: An artificial intelligence powered machine learning framework for the classification of pneumonia in chest x-ray images},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning representations for quantum many-body systems
on heterogeneous hardware. <em>MLST</em>, <em>4</em>(1), 015035. (<a
href="https://doi.org/10.1088/2632-2153/acc56a">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quantum many-body problems are important for condensed matter physics, however solving the problems are challenging because the Hilbert space grows exponentially with the size of the problem. The recently developed deep learning methods provide a promising new route to solve long-standing quantum many-body problems. We report that a deep learning based simulation can achieve solutions with competitive precision for the spin J1 – J2 model and fermionic t - J model, on rectangular lattices within periodic boundary conditions. The optimizations of the deep neural networks are performed on the heterogeneous platforms, such as the new generation Sunway supercomputer and the multi graphical-processing-unit clusters. Both high scalability and high performance are achieved within an AI-HPC hybrid framework. The accomplishment of this work opens the door to simulate spin and fermionic lattice models with state-of-the-art lattice size and precision.},
  archive      = {J_MLST},
  author       = {Xiao Liang and Mingfan Li and Qian Xiao and Junshi Chen and Chao Yang and Hong An and Lixin He},
  doi          = {10.1088/2632-2153/acc56a},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015035},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Deep learning representations for quantum many-body systems on heterogeneous hardware},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning-based signal quality assessment for cardiac
volume monitoring in electrical impedance tomography. <em>MLST</em>,
<em>4</em>(1), 015034. (<a
href="https://doi.org/10.1088/2632-2153/acc637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to recent advances in thoracic electrical impedance tomography (EIT), a patient&#39;s hemodynamic function can be noninvasively and continuously estimated in real-time by surveilling a cardiac volume signal (CVS) associated with stroke volume and cardiac output. In clinical applications, however, a CVS is often of low quality, mainly because of the patient&#39;s deliberate movements or inevitable motions during clinical interventions. This study aims to develop a signal quality indexing method that assesses the influence of motion artifacts on transient CVSs. The assessment is performed on each cardiac cycle to take advantage of the periodicity and regularity in cardiac volume changes. Time intervals are identified using the synchronized electrocardiography system. We apply divergent machine-learning methods, which can be sorted into discriminative-model and manifold-learning approaches. The use of machine-learning could be suitable for our real-time monitoring application that requires fast inference and automation as well as high accuracy. In the clinical environment, the proposed method can be utilized to provide immediate warnings so that clinicians can minimize confusion regarding patients&#39; conditions, reduce clinical resource utilization, and improve the confidence level of the monitoring system. Numerous experiments using actual EIT data validate the capability of CVSs degraded by motion artifacts to be accurately and automatically assessed in real-time by machine learning. The best model achieved an accuracy of 0.95, positive and negative predictive values of 0.96 and 0.86, sensitivity of 0.98, specificity of 0.77, and AUC of 0.96.},
  archive      = {J_MLST},
  author       = {Chang Min Hyun and Tae Jun Jang and Jeongchan Nam and Hyeuknam Kwon and Kiwan Jeon and Kyounghun Lee},
  doi          = {10.1088/2632-2153/acc637},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015034},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Machine learning-based signal quality assessment for cardiac volume monitoring in electrical impedance tomography},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Novel heuristic-based hybrid ResNeXt with recurrent neural
network to handle multi class classification of sentiment analysis.
<em>MLST</em>, <em>4</em>(1), 015033. (<a
href="https://doi.org/10.1088/2632-2153/acc0d5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Present-day, interdisciplinary research is increasing in social network-related applications, and it is a daily routine activity in every human life. So, sentiment analysis (SA) based on opinion mining is the most sophisticated concept in the well-known social network environment. Different machine learning methods were implemented to extract different text label features in SA, and all of those methods can detect whether a given text is positive or negative based on the text features. Analysis of sentiment has been suffering from inaccuracies while using machine learning and sentiment-based lexical methods dependent on domain-specific problems. Multi-class SA is an expensive task where memory, label samples, and other parameters are insufficient. So, we propose and implement a novel hybrid model which is a combination of ResNeXt and recurrent neural framework (NH-ResNeXt-RNF) to explore multi-class sentiment from textual features. This framework investigates the polarity of words connected to a specific domain across the entire dataset and eliminates noisy data in an unsupervised manner using pre-processing. Optimization is required to perform efficient multi-class classification to reduce the effort associated with annotation for multi-class SA via unsupervised learning. The proposed model performance is evaluated on two data sets namely: Amazon and Twitter. We increase the accuracy of the sentiment of polarity on each sentence present in the data set. Experimental results of the proposed approach give better and more efficient multi-class ( positive, negative, very positive, neutral and highly negative) domain-specific sentiment than traditional approaches related to supervised, semi-supervised, and unsupervised domains. The proposed hybrid model accuracy is 96.5% and 95.37% for Amazon and Twitter datasets respectively.},
  archive      = {J_MLST},
  author       = {Lakshmi Revathi Krosuri and Rama Satish Aravapalli},
  doi          = {10.1088/2632-2153/acc0d5},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015033},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Novel heuristic-based hybrid ResNeXt with recurrent neural network to handle multi class classification of sentiment analysis},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quaternion-based machine learning on topological quantum
systems. <em>MLST</em>, <em>4</em>(1), 015032. (<a
href="https://doi.org/10.1088/2632-2153/acc0d6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topological phase classifications have been intensively studied via machine-learning techniques where different forms of the training data are proposed in order to maximize the information extracted from the systems of interests. Due to the complexity in quantum physics, advanced mathematical architecture should be considered in designing machines. In this work, we incorporate quaternion algebras into data analysis either in the frame of supervised and unsupervised learning to classify two-dimensional Chern insulators. For the unsupervised-learning aspect, we apply the principal component analysis on the quaternion-transformed eigenstates to distinguish topological phases. For the supervised-learning aspect, we construct our machine by adding one quaternion convolutional layer on top of a conventional convolutional neural network. The machine takes quaternion-transformed configurations as inputs and successfully classify all distinct topological phases, even for those states that have different distributions from those states seen by the machine during the training process. Our work demonstrates the power of quaternion algebras on extracting crucial features from the targeted data and the advantages of quaternion-based neural networks than conventional ones in the tasks of topological phase classifications.},
  archive      = {J_MLST},
  author       = {Min-Ruei Lin and Wan-Ju Li and Shin-Ming Huang},
  doi          = {10.1088/2632-2153/acc0d6},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015032},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Quaternion-based machine learning on topological quantum systems},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiresolution equivariant graph variational autoencoder.
<em>MLST</em>, <em>4</em>(1), 015031. (<a
href="https://doi.org/10.1088/2632-2153/acc0d8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose Multiresolution Equivariant Graph Variational Autoencoders (MGVAE), the first hierarchical generative model to learn and generate graphs in a multiresolution and equivariant manner. At each resolution level, MGVAE employs higher order message passing to encode the graph while learning to partition it into mutually exclusive clusters and coarsening into a lower resolution that eventually creates a hierarchy of latent distributions. MGVAE then constructs a hierarchical generative model to variationally decode into a hierarchy of coarsened graphs. Importantly, our proposed framework is end-to-end permutation equivariant with respect to node ordering. MGVAE achieves competitive results with several generative tasks including general graph generation, molecular generation, unsupervised molecular representation learning to predict molecular properties, link prediction on citation graphs, and graph-based image generation. Our implementation is available at https://github.com/HyTruongSon/MGVAE .},
  archive      = {J_MLST},
  author       = {Truong Son Hy and Risi Kondor},
  doi          = {10.1088/2632-2153/acc0d8},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015031},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Multiresolution equivariant graph variational autoencoder},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning to predict the antimicrobial activity of
cold atmospheric plasma-activated liquids. <em>MLST</em>, <em>4</em>(1),
015030. (<a href="https://doi.org/10.1088/2632-2153/acc1c0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plasma is defined as the fourth state of matter, and non-thermal plasma can be produced at atmospheric pressure under a high electrical field. The strong and broad-spectrum antimicrobial effect of plasma-activated liquids (PALs) is now well known. The antimicrobial effects of PALs depend on many different variables, which complicates the comparison of different studies and determining the most dominant parameters for the antimicrobial effect. The proven applicability of machine learning (ML) in the medical field is encouraging for its application in the field of plasma medicine as well. Thus, ML applications on PALs could present a new perspective to better understand the influences of various parameters on their antimicrobial effects. In this paper, comparative supervised ML models are presented by using previously obtained data to predict the in vitro antimicrobial activity of PALs. A comprehensive literature search was performed, and 12 distinct features related to PAL-microorganism interactions were collected from 33 relevant articles to automatically predict the antimicrobial activity of PALs. After the required normalization, feature encoding, and resampling steps, two supervised ML methods, namely classification and regression, are applied to the data to obtain microbial inactivation (MI) predictions. For classification, MI is labeled in four categories, and for regression, MI is used as a continuous variable. Sixteen different classifiers and 14 regressors are implemented to predict the MI value. Two different robust cross-validation strategies are conducted for classification and regression models to evaluate the proposed method: repeated stratified k -fold cross-validation and k -fold cross-validation, respectively. We also investigate the effect of different features on models. The results demonstrated that the hyperparameter-optimized Random Forest Classifier (oRFC) and Random Forest Regressor (oRFR) provided superior performance compared to other models for classification and regression. Finally, the best test accuracy of 82.68% for oRFC and R 2 of 0.75 for the oRFR are obtained. Furthermore, the determined most important features of predictive models are in line with the outcomes of PALs reported in the literature. An ML framework can accurately predict the antimicrobial activity of PALs without the need for any experimental studies. To the best of our knowledge, this is the first study that investigates the antimicrobial efficacy of PALs with ML. Furthermore, ML techniques could contribute to a better understanding of plasma parameters that have a dominant role in the desired antimicrobial effect. Moreover, such findings may contribute to the definition of a plasma dose in the future.},
  archive      = {J_MLST},
  author       = {Mehmet Akif Özdemir and Gizem Dilara Özdemir and Merve Gül and Onan Güren and Utku Kürşat Ercan},
  doi          = {10.1088/2632-2153/acc1c0},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015030},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Machine learning to predict the antimicrobial activity of cold atmospheric plasma-activated liquids},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Developing novel machine-learning-based fire weather
indices. <em>MLST</em>, <em>4</em>(1), 015029. (<a
href="https://doi.org/10.1088/2632-2153/acc008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate wildfire risk estimation is an essential yet challenging task. As the frequency of extreme fire weather and wildfires is on the rise, forest managers and firefighters require accurate wildfire risk estimations to successfully implement forest management and firefighting strategies. Wildfire risk depends on non-linear interactions between multiple factors; therefore, the performance of linear models in its estimation is limited. To date, several traditional fire weather indices (FWIs) have been commonly used by weather services, such as the Canadian FWI.@Traditional FWIs are primarily based on empirical and statistical analyses. In this paper, we propose a novel FWI that was developed using machine learning—the machine learning based fire weather index (MLFWI). We present the performance of the MLFWI and compare it with various traditional FWIs. We find that the MLFWI significantly outperforms traditional indices in predicting wildfire occurrence, achieving an area under the curve score of 0.99 compared to 0.62–0.80. We recommend applying the MLFWI in wildfire warning systems.},
  archive      = {J_MLST},
  author       = {Assaf Shmuel and Eyal Heifetz},
  doi          = {10.1088/2632-2153/acc008},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015029},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Developing novel machine-learning-based fire weather indices},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning phases in swarming systems. <em>MLST</em>,
<em>4</em>(1), 015028. (<a
href="https://doi.org/10.1088/2632-2153/acc007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed a growing interest in using machine learning to predict and identify phase transitions (PTs) in various systems. Here we adopt convolutional neural networks (CNNs) to study the PTs of Vicsek model, solving the problem that traditional order parameters are insufficiently able to do. Within the large-scale simulations, there are four phases, and we confirm that all the PTs between two neighboring phases are first-order. We have successfully classified the phase by using CNNs with a high accuracy and identified the PT points, while traditional approaches using various order parameters fail to obtain. These results indicate the great potential of machine learning approach in understanding the complexities in collective behaviors, and in related complex systems in general.},
  archive      = {J_MLST},
  author       = {Tingting Xue and Xu Li and Xiaosong Chen and Li Chen and Zhangang Han},
  doi          = {10.1088/2632-2153/acc007},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015028},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Machine learning phases in swarming systems},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine-learning-assisted monte carlo fails at sampling
computationally hard problems. <em>MLST</em>, <em>4</em>(1), 010501. (<a
href="https://doi.org/10.1088/2632-2153/acbe91">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several strategies have been recently proposed in order to improve Monte Carlo sampling efficiency using machine learning tools. Here, we challenge these methods by considering a class of problems that are known to be exponentially hard to sample using conventional local Monte Carlo at low enough temperatures. In particular, we study the antiferromagnetic Potts model on a random graph, which reduces to the coloring of random graphs at zero temperature. We test several machine-learning-assisted Monte Carlo approaches, and we find that they all fail. Our work thus provides good benchmarks for future proposals for smart sampling algorithms.},
  archive      = {J_MLST},
  author       = {Simone Ciarella and Jeanne Trinquier and Martin Weigt and Francesco Zamponi},
  doi          = {10.1088/2632-2153/acbe91},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {010501},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Machine-learning-assisted monte carlo fails at sampling computationally hard problems},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A recipe for cracking the quantum scaling limit with machine
learned electron densities. <em>MLST</em>, <em>4</em>(1), 015027. (<a
href="https://doi.org/10.1088/2632-2153/acb314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A long-standing goal of science is to accurately simulate large molecular systems using quantum mechanics. The poor scaling of current quantum chemistry algorithms on classical computers, however, imposes an effective limit of about a few dozen atoms on traditional electronic structure calculations. We present a machine learning (ML) method to break through this scaling limit for electron densities. We show that Euclidean neural networks can be trained to predict molecular electron densities from limited data. By learning the electron density, the model can be trained on small systems and make accurate predictions on large ones. In the context of water clusters, we show that an ML model trained on clusters of just 12 molecules contains all the information needed to make accurate electron density predictions on cluster sizes of 50 or more, beyond the scaling limit of current quantum chemistry methods.},
  archive      = {J_MLST},
  author       = {Joshua A Rackers and Lucas Tecot and Mario Geiger and Tess E Smidt},
  doi          = {10.1088/2632-2153/acb314},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015027},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A recipe for cracking the quantum scaling limit with machine learned electron densities},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Supplementing recurrent neural networks with annealing to
solve combinatorial optimization problems. <em>MLST</em>, <em>4</em>(1),
015026. (<a href="https://doi.org/10.1088/2632-2153/acb895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combinatorial optimization problems can be solved by heuristic algorithms such as simulated annealing (SA) which aims to find the optimal solution within a large search space through thermal fluctuations. This algorithm generates new solutions through Markov-chain Monte Carlo techniques which can result in severe limitations, such as slow convergence and a tendency to stay within the same local search space at small temperatures. To overcome these shortcomings, we use the variational classical annealing (VCA) framework that combines autoregressive recurrent neural networks (RNNs) with traditional annealing to sample solutions that are uncorrelated. In this paper, we demonstrate the potential of using VCA as an approach to solving real-world optimization problems. We explore VCA&#39;s performance in comparison with SA at solving three popular optimization problems: the maximum cut problem (Max-Cut), the nurse scheduling problem (NSP), and the traveling salesman problem (TSP). For all three problems, we find that VCA outperforms SA on average in the asymptotic limit by one or more orders of magnitude in terms of relative error. Interestingly, we reach large system sizes of up to 256 cities for the TSP. We also conclude that in the best case scenario, VCA can serve as a great alternative when SA fails to find the optimal solution.},
  archive      = {J_MLST},
  author       = {Shoummo Ahsan Khandoker and Jawaril Munshad Abedin and Mohamed Hibat-Allah},
  doi          = {10.1088/2632-2153/acb895},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015026},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Supplementing recurrent neural networks with annealing to solve combinatorial optimization problems},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine-learning approach for quantified resolvability
enhancement of low-dose STEM data. <em>MLST</em>, <em>4</em>(1), 015025.
(<a href="https://doi.org/10.1088/2632-2153/acbb52">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-resolution electron microscopy is achievable only when a high electron dose is employed, a practice that may cause damage to the specimen and, in general, affects the observation. This drawback sets some limitations on the range of applications of high-resolution electron microscopy. Our work proposes a strategy, based on machine learning, which enables a significant improvement in the quality of Scanning Transmission Electron Microscope images generated at low electron dose, strongly affected by Poisson noise. In particular, we develop an autoencoder, trained on a large database of images, which is thoroughly tested on both synthetic and actual microscopy data. The algorithm is demonstrated to drastically reduce the noise level and approach ground-truth precision over a broad range of electron beam intensities. Importantly, it does not require human data pre-processing or the explicit knowledge of the dose level employed and can run at a speed compatible with live data acquisition. Furthermore, a quantitative unbiased benchmarking protocol is proposed to compare different denoising workflows.},
  archive      = {J_MLST},
  author       = {Laura Gambini and Tiarnan Mullarkey and Lewys Jones and Stefano Sanvito},
  doi          = {10.1088/2632-2153/acbb52},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015025},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Machine-learning approach for quantified resolvability enhancement of low-dose STEM data},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Confined hydrogen atom: Endohedrals h@C36 and h@C60.
<em>MLST</em>, <em>4</em>(1), 015024. (<a
href="https://doi.org/10.1088/2632-2153/acb901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, for the lowest states with angular momentum, l = 0,1,2 the energies and eigenfunctions of the endohedrals H@C 36 and H@C 60 are presented. The confining spherically-symmetric barrier was modeled by an inverted Gaussian function of depth ω 0 , width σ and centered at r c , w(r) = -\,\omega_0\, \textrm{exp}[-(r-r_c)^2/\sigma^2] . The spectra of the system as a function of the parameters ( \omega_0,\sigma,r_c ) is calculated using three distinct numerical methods: ( i ) Lagrange-mesh method, ( ii ) fourth order finite differences and ( iii ) the finite element method. Concrete results with not less than 11 significant figures are displayed. Also, within the Lagrange-mesh approach the corresponding eigenfunctions and the expectation value of r for the first six states of s, p , and d symmetries, respectively, are presented as well. Our accurate energies are taken as initial data to train an artificial neural network that generates faster and efficient numerical interpolation. The present numerical results improve and extend those reported in the literature.},
  archive      = {J_MLST},
  author       = {H Olivares-Pilón and A M Escobar-Ruiz and M A Quiroz-Juárez and N Aquino},
  doi          = {10.1088/2632-2153/acb901},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015024},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Confined hydrogen atom: Endohedrals H@C36 and H@C60},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantum machine learning framework for virtual screening in
drug discovery: A prospective quantum advantage. <em>MLST</em>,
<em>4</em>(1), 015023. (<a
href="https://doi.org/10.1088/2632-2153/acb900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Learning for ligand based virtual screening (LB-VS) is an important in-silico tool for discovering new drugs in a faster and cost-effective manner, especially for emerging diseases such as COVID-19. In this paper, we propose a general-purpose framework combining a classical Support Vector Classifier algorithm with quantum kernel estimation for LB-VS on real-world databases, and we argue in favor of its prospective quantum advantage. Indeed, we heuristically prove that our quantum integrated workflow can, at least in some relevant instances, provide a tangible advantage compared to state-of-art classical algorithms operating on the same datasets, showing strong dependence on target and features selection method. Finally, we test our algorithm on IBM Quantum processors using ADRB2 and COVID-19 datasets, showing that hardware simulations provide results in line with the predicted performances and can surpass classical equivalents.},
  archive      = {J_MLST},
  author       = {Stefano Mensa and Emre Sahin and Francesco Tacchino and Panagiotis Kl Barkoutsos and Ivano Tavernelli},
  doi          = {10.1088/2632-2153/acb900},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015023},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Quantum machine learning framework for virtual screening in drug discovery: A prospective quantum advantage},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multivariate prediction intervals for bagged models.
<em>MLST</em>, <em>4</em>(1), 015022. (<a
href="https://doi.org/10.1088/2632-2153/acb9d5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate uncertainty estimates can significantly improve the performance of iterative design of experiments, as in sequential and reinforcement learning. For many such problems in engineering and the physical sciences, the design task depends on multiple correlated model outputs as objectives and/or constraints. To better solve these problems, we propose a recalibrated bootstrap method to generate multivariate prediction intervals for bagged models such as random forest and show that it is well-calibrated. We apply the recalibrated bootstrap to a simulated sequential learning problem with multiple objectives and show that it leads to a marked decrease in the number of iterations required to find a satisfactory candidate. This indicates that the recalibrated bootstrap could be a valuable tool for practitioners using machine learning to optimize systems with multiple competing targets.},
  archive      = {J_MLST},
  author       = {Brendan Folie and Maxwell Hutchinson},
  doi          = {10.1088/2632-2153/acb9d5},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015022},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Multivariate prediction intervals for bagged models},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A smart alarm for particle accelerator beamline operations.
<em>MLST</em>, <em>4</em>(1), 015021. (<a
href="https://doi.org/10.1088/2632-2153/acb98d">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the initial results of a proof-of-concept &#39;smart alarm&#39; for the Continuous Electron Beam Accelerator Facility injector beamline at Jefferson Lab. To minimize machine downtime and improve operational efficiency, an autonomous alarm system able to identify and diagnose unusual machine states is needed. Our approach leverages a trained neural network capable of alerting operators (a) when an anomalous condition exists in the beamline and (b) identifying the element setting that is the root cause. The tool is based on an inverse model that maps beamline readings (diagnostic readbacks) to settings (beamline attributes operators can modify). The model takes as input readings from the machine and computes machine settings which are compared to control setpoints. Instances where predictions differ from setpoints by a user-defined threshold are flagged as anomalous. Given data corresponding to 354 anomalous injector configurations, the model can narrow the root cause of an anomalous condition to three potential candidates with 94.6% accuracy. Furthermore, compared to the current method of identifying anomalous conditions which raises an alarm when machine parameters drift outside their normal tolerances, the data-driven model can identify 83% more anomalous conditions.},
  archive      = {J_MLST},
  author       = {Chris Tennant and Brian Freeman and Reza Kazimi and Daniel Moser and Dan Abell and Jonathan Edelen and Joshua Einstein-Curtis},
  doi          = {10.1088/2632-2153/acb98d},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015021},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A smart alarm for particle accelerator beamline operations},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Massively parallel fitting of gaussian approximation
potentials. <em>MLST</em>, <em>4</em>(1), 015020. (<a
href="https://doi.org/10.1088/2632-2153/aca743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a data-parallel software package for fitting Gaussian approximation potentials (GAPs) on multiple nodes using the ScaLAPACK library with MPI and OpenMP. Until now the maximum training set size for GAP models has been limited by the available memory on a single compute node. In our new implementation, descriptor evaluation is carried out in parallel with no communication requirement. The subsequent linear solve required to determine the model coefficients is parallelised with ScaLAPACK. Our approach scales to thousands of cores, lifting the memory limitation and also delivering substantial speedups. This development expands the applicability of the GAP approach to more complex systems as well as opening up opportunities for efficiently embedding GAP model fitting within higher-level workflows such as committee models or hyperparameter optimisation.},
  archive      = {J_MLST},
  author       = {Sascha Klawohn and James R Kermode and Albert P Bartók},
  doi          = {10.1088/2632-2153/aca743},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015020},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Massively parallel fitting of gaussian approximation potentials},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning curves for the multi-class teacher–student
perceptron. <em>MLST</em>, <em>4</em>(1), 015019. (<a
href="https://doi.org/10.1088/2632-2153/acb428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most classical results in high-dimensional learning theory provides a closed-form expression for the generalisation error of binary classification with a single-layer teacher–student perceptron on i.i.d. Gaussian inputs. Both Bayes-optimal (BO) estimation and empirical risk minimisation (ERM) were extensively analysed in this setting. At the same time, a considerable part of modern machine learning practice concerns multi-class classification. Yet, an analogous analysis for the multi-class teacher–student perceptron was missing. In this manuscript we fill this gap by deriving and evaluating asymptotic expressions for the BO and ERM generalisation errors in the high-dimensional regime. For Gaussian teacher, we investigate the performance of ERM with both cross-entropy and square losses, and explore the role of ridge regularisation in approaching Bayes-optimality. In particular, we observe that regularised cross-entropy minimisation yields close-to-optimal accuracy. Instead, for Rademacher teacher we show that a first-order phase transition arises in the BO performance.},
  archive      = {J_MLST},
  author       = {Elisabetta Cornacchia and Francesca Mignacco and Rodrigo Veiga and Cédric Gerbelot and Bruno Loureiro and Lenka Zdeborová},
  doi          = {10.1088/2632-2153/acb428},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015019},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Learning curves for the multi-class teacher–student perceptron},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Autonomous victim detection system based on deep learning
and multispectral imagery. <em>MLST</em>, <em>4</em>(1), 015018. (<a
href="https://doi.org/10.1088/2632-2153/acb6cf">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Post-disaster environments resulting from catastrophic events, leave sequels such as victims trapped in debris, which are difficult to detect by rescuers in a first inspection. Technological advances in electronics and perception have allowed the development of versatile and powerful optical sensors capable of capturing light in spectrums that humans cannot. new deep learning techniques, such as convolutional neural networks (CNNs), has allowed the generation of network models capable of autonomously detecting specific image patterns according to previous training. This work introduces an autonomous victim detection system to be deployed by using search and rescue robots. The proposed system defines new indexes based on combining the multispectral bands (Blue, Green, Red, Nir, Red Edge) to obtain new multispectral images where relevant characteristics of victims and the environment are highlighted. CNNs have been used as a second phase for automatically detecting victims in these new multispectral images. A qualitative and quantitative analysis of new indexes proposed by the authors has been carried out to evaluate their efficiency in contrast to the state-of-the-art ones. A data set has been generated to train different CNN models based on the best obtained index to analyze their effectiveness in detecting victims. The results show an efficiency of 92% in automatically detecting victims when applying the best multispectral index to new data. This method has also been contrasted with others based on thermal and RGB imagery to detect victims, where it has been proven that it generates better results in situations of outdoor environments and different weather conditions.},
  archive      = {J_MLST},
  author       = {Christyan Cruz Ulloa and Luis Garrido and Jaime del Cerro and Antonio Barrientos},
  doi          = {10.1088/2632-2153/acb6cf},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015018},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Autonomous victim detection system based on deep learning and multispectral imagery},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differentiable physics-enabled closure modeling for burgers’
turbulence. <em>MLST</em>, <em>4</em>(1), 015017. (<a
href="https://doi.org/10.1088/2632-2153/acb19c">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven turbulence modeling is experiencing a surge in interest following algorithmic and hardware developments in the data sciences. We discuss an approach using the differentiable physics paradigm that combines known physics with machine learning to develop closure models for Burgers&#39; turbulence. We consider the one-dimensional Burgers system as a prototypical test problem for modeling the unresolved terms in advection-dominated turbulence problems. We train a series of models that incorporate varying degrees of physical assumptions on an a posteriori loss function to test the efficacy of models across a range of system parameters, including viscosity, time, and grid resolution. We find that constraining models with inductive biases in the form of partial differential equations that contain known physics or existing closure approaches produces highly data-efficient, accurate, and generalizable models, outperforming state-of-the-art baselines. Addition of structure in the form of physics information also brings a level of interpretability to the models, potentially offering a stepping stone to the future of closure modeling.},
  archive      = {J_MLST},
  author       = {Varun Shankar and Vedant Puri and Ramesh Balakrishnan and Romit Maulik and Venkatasubramanian Viswanathan},
  doi          = {10.1088/2632-2153/acb19c},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015017},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Differentiable physics-enabled closure modeling for burgers’ turbulence},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural network enhanced measurement efficiency for molecular
groundstates. <em>MLST</em>, <em>4</em>(1), 015016. (<a
href="https://doi.org/10.1088/2632-2153/acb4df">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is believed that one of the first useful applications for a quantum computer will be the preparation of groundstates of molecular Hamiltonians. A crucial task involving state preparation and readout is obtaining physical observables of such states, which are typically estimated using projective measurements on the qubits. At present, measurement data is costly and time-consuming to obtain on any quantum computing architecture, which has significant consequences for the statistical errors of estimators. In this paper, we adapt common neural network models (restricted Boltzmann machines and recurrent neural networks) to learn complex groundstate wavefunctions for several prototypical molecular qubit Hamiltonians from typical measurement data. By relating the accuracy ɛ of the reconstructed groundstate energy to the number of measurements, we find that using a neural network model provides a robust improvement over using single-copy measurement outcomes alone to reconstruct observables. This enhancement yields an asymptotic scaling near ɛ −1 for the model-based approaches, as opposed to ɛ −2 in the case of classical shadow tomography.},
  archive      = {J_MLST},
  author       = {Dmitri Iouchtchenko and Jérôme F Gonthier and Alejandro Perdomo-Ortiz and Roger G Melko},
  doi          = {10.1088/2632-2153/acb4df},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015016},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Neural network enhanced measurement efficiency for molecular groundstates},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated real-space lattice extraction for atomic force
microscopy images. <em>MLST</em>, <em>4</em>(1), 015015. (<a
href="https://doi.org/10.1088/2632-2153/acb5e0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing atomically resolved images is a time-consuming process requiring solid experience and substantial human intervention. In addition, the acquired images contain a large amount of information such as crystal structure, presence and distribution of defects, and formation of domains, which need to be resolved to understand a material&#39;s surface structure. Therefore, machine learning techniques have been applied in scanning probe and electron microscopies during the last years, aiming for automatized and efficient image analysis. This work introduces a free and open source tool (AiSurf: Automated Identification of Surface Images) developed to inspect atomically resolved images via scale-invariant feature transform and clustering algorithms. AiSurf extracts primitive lattice vectors, unit cells, and structural distortions from the original image, with no pre-assumption on the lattice and minimal user intervention. The method is applied to various atomically resolved non-contact atomic force microscopy images of selected surfaces with different levels of complexity: anatase TiO 2 (101), oxygen deficient rutile TiO 2 (110) with and without CO adsorbates, SrTiO 3 (001) with Sr vacancies and graphene with C vacancies. The code delivers excellent results and is tested against atom misclassification and artifacts, thereby facilitating the interpretation of scanning probe microscopy images.},
  archive      = {J_MLST},
  author       = {Marco Corrias and Lorenzo Papa and Igor Sokolović and Viktor Birschitzky and Alexander Gorfer and Martin Setvin and Michael Schmid and Ulrike Diebold and Michele Reticcioli and Cesare Franchini},
  doi          = {10.1088/2632-2153/acb5e0},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015015},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Automated real-space lattice extraction for atomic force microscopy images},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Investigation of inverse design of multilayer thin-films
with conditional invertible neural networks. <em>MLST</em>,
<em>4</em>(1), 015014. (<a
href="https://doi.org/10.1088/2632-2153/acb48d">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we apply conditional invertible neural networks (cINN) to inversely design multilayer thin-films given an optical target in order to overcome limitations of state-of-the-art optimization approaches. Usually, state-of-the-art algorithms depend on a set of carefully chosen initial thin-film parameters or employ neural networks which must be retrained for every new application. We aim to overcome those limitations by training the cINN to learn the loss landscape of all thin-film configurations within a training dataset. We show that cINNs can generate a stochastic ensemble of proposals for thin-film configurations that are reasonably close to the desired target depending only on random variables. By refining the proposed configurations further by a local optimization, we show that the generated thin-films reach the target with significantly greater precision than comparable state-of-the-art approaches. Furthermore, we tested the generative capabilities on samples which are outside of the training data distribution and found that the cINN was able to predict thin-films for out-of-distribution targets, too. The results suggest that in order to improve the generative design of thin-films, it is instructive to use established and new machine learning methods in conjunction in order to obtain the most favorable results.},
  archive      = {J_MLST},
  author       = {Alexander Luce and Ali Mahdavi and Heribert Wankerl and Florian Marquardt},
  doi          = {10.1088/2632-2153/acb48d},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015014},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Investigation of inverse design of multilayer thin-films with conditional invertible neural networks},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recipes for when physics fails: Recovering robust learning
of physics informed neural networks. <em>MLST</em>, <em>4</em>(1),
015013. (<a href="https://doi.org/10.1088/2632-2153/acb416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-informed neural networks (PINNs) have been shown to be effective in solving partial differential equations by capturing the physics induced constraints as a part of the training loss function. This paper shows that a PINN can be sensitive to errors in training data and overfit itself in dynamically propagating these errors over the domain of the solution of the PDE. It also shows how physical regularizations based on continuity criteria and conservation laws fail to address this issue and rather introduce problems of their own causing the deep network to converge to a physics-obeying local minimum instead of the global minimum. We introduce Gaussian process (GP) based smoothing that recovers the performance of a PINN and promises a robust architecture against noise/errors in measurements. Additionally, we illustrate an inexpensive method of quantifying the evolution of uncertainty based on the variance estimation of GPs on boundary data. Robust PINN performance is also shown to be achievable by choice of sparse sets of inducing points based on sparsely induced GPs. We demonstrate the performance of our proposed methods and compare the results from existing benchmark models in literature for time-dependent Schrödinger and Burgers&#39; equations.},
  archive      = {J_MLST},
  author       = {Chandrajit Bajaj and Luke McLennan and Timothy Andeen and Avik Roy},
  doi          = {10.1088/2632-2153/acb416},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015013},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Recipes for when physics fails: Recovering robust learning of physics informed neural networks},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Categorical representation learning and RG flow operators
for algorithmic classifiers. <em>MLST</em>, <em>4</em>(1), 015012. (<a
href="https://doi.org/10.1088/2632-2153/acb488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Following the earlier formalism of the categorical representation learning, we discuss the construction of the &#39;RG-flow-based categorifier&#39;. Borrowing ideas from the theory of renormalization group (RG) flows in quantum field theory, holographic duality, and hyperbolic geometry and combining them with neural ordinary differential equation techniques, we construct a new algorithmic natural language processing architecture, called the RG-flow categorifier or for short the RG categorifier, which is capable of data classification and generation in all layers. We apply our algorithmic platform to biomedical data sets and show its performance in the field of sequence-to-function mapping. In particular, we apply the RG categorifier to particular genomic sequences of flu viruses and show how our technology is capable of extracting the information from given genomic sequences, finding their hidden symmetries and dominant features, classifying them, and using the trained data to make a stochastic prediction of new plausible generated sequences associated with a new set of viruses which could avoid the human immune system.},
  archive      = {J_MLST},
  author       = {Artan Sheshmani and Yi-Zhuang You and Wenbo Fu and Ahmadreza Azizi},
  doi          = {10.1088/2632-2153/acb488},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015012},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Categorical representation learning and RG flow operators for algorithmic classifiers},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimizing training trajectories in variational autoencoders
via latent bayesian optimization approach *. <em>MLST</em>,
<em>4</em>(1), 015011. (<a
href="https://doi.org/10.1088/2632-2153/acb316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised and semi-supervised ML methods such as variational autoencoders (VAE) have become widely adopted across multiple areas of physics, chemistry, and materials sciences due to their capability in disentangling representations and ability to find latent manifolds for classification and/or regression of complex experimental data. Like other ML problems, VAEs require hyperparameter tuning, e.g. balancing the Kullback–Leibler and reconstruction terms. However, the training process and resulting manifold topology and connectivity depend not only on hyperparameters, but also their evolution during training. Because of the inefficiency of exhaustive search in a high-dimensional hyperparameter space for the expensive-to-train models, here we have explored a latent Bayesian optimization (zBO) approach for the hyperparameter trajectory optimization for the unsupervised and semi-supervised ML and demonstrated for joint-VAE with rotational invariances. We have demonstrated an application of this method for finding joint discrete and continuous rotationally invariant representations for modified national institute of standards and technology database (MNIST) and experimental data of a plasmonic nanoparticles material system. The performance of the proposed approach has been discussed extensively, where it allows for any high dimensional hyperparameter trajectory optimization of other ML models.},
  archive      = {J_MLST},
  author       = {Arpan Biswas and Rama Vasudevan and Maxim Ziatdinov and Sergei V Kalinin},
  doi          = {10.1088/2632-2153/acb316},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015011},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Optimizing training trajectories in variational autoencoders via latent bayesian optimization approach *},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Direct prediction of inelastic neutron scattering spectra
from the crystal structure*. <em>MLST</em>, <em>4</em>(1), 015010. (<a
href="https://doi.org/10.1088/2632-2153/acb315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inelastic neutron scattering (INS) is a powerful technique to study vibrational dynamics of materials with several unique advantages. However, analysis and interpretation of INS spectra often require advanced modeling that needs specialized computing resources and relevant expertise. This difficulty is compounded by the limited experimental resources available to perform INS measurements. In this work, we develop a machine-learning based predictive framework which is capable of directly predicting both one-dimensional INS spectra and two-dimensional INS spectra with additional momentum resolution. By integrating symmetry-aware neural networks with autoencoders, and using a large scale synthetic INS database, high-dimensional spectral data are compressed into a latent-space representation, and a high-quality spectra prediction is achieved by using only atomic coordinates as input. Our work offers an efficient approach to predict complex multi-dimensional neutron spectra directly from simple input; it allows for improved efficiency in using the limited INS measurement resources, and sheds light on building structure-property relationships in a variety of on-the-fly experimental data analysis scenarios.},
  archive      = {J_MLST},
  author       = {Yongqiang Cheng and Geoffrey Wu and Daniel M Pajerowski and Matthew B Stone and Andrei T Savici and Mingda Li and Anibal J Ramirez-Cuesta},
  doi          = {10.1088/2632-2153/acb315},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015010},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Direct prediction of inelastic neutron scattering spectra from the crystal structure*},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Noise-aware physics-informed machine learning for robust PDE
discovery. <em>MLST</em>, <em>4</em>(1), 015009. (<a
href="https://doi.org/10.1088/2632-2153/acb1f0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work is concerned with discovering the governing partial differential equation (PDE) of a physical system. Existing methods have demonstrated the PDE identification from finite observations but failed to maintain satisfying results against noisy data, partly owing to suboptimal estimated derivatives and found PDE coefficients. We address the issues by introducing a noise-aware physics-informed machine learning framework to discover the governing PDE from data following arbitrary distributions. We propose training a couple of neural networks, namely solver and preselector, in a multi-task learning paradigm, which yields important scores of basis candidates that constitute the hidden physical constraint. After they are jointly trained, the solver network estimates potential candidates, e.g. partial derivatives, for the sparse regression to initially unveil the most likely parsimonious PDE, decided according to information criterion. Denoising physics-informed neural networks, based on discrete Fourier transform, is proposed to deliver the optimal PDE coefficients respecting the noise-reduced variables. Extensive experiments on five canonical PDEs affirm that the proposed framework presents a robust and interpretable approach for PDE discovery, leading to a new automatic PDE selection algorithm established on minimization of the information criterion decay rate.},
  archive      = {J_MLST},
  author       = {Pongpisit Thanasutives and Takashi Morita and Masayuki Numao and Ken-ichi Fukui},
  doi          = {10.1088/2632-2153/acb1f0},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015009},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Noise-aware physics-informed machine learning for robust PDE discovery},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust simulation-based inference in cosmology with bayesian
neural networks. <em>MLST</em>, <em>4</em>(1), 01LT01. (<a
href="https://doi.org/10.1088/2632-2153/acbb53">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulation-based inference (SBI) is rapidly establishing itself as a standard machine learning technique for analyzing data in cosmological surveys. Despite continual improvements to the quality of density estimation by learned models, applications of such techniques to real data are entirely reliant on the generalization power of neural networks far outside the training distribution, which is mostly unconstrained. Due to the imperfections in scientist-created simulations, and the large computational expense of generating all possible parameter combinations, SBI methods in cosmology are vulnerable to such generalization issues. Here, we discuss the effects of both issues, and show how using a Bayesian neural network framework for training SBI can mitigate biases, and result in more reliable inference outside the training set. We introduce cosmoSWAG , the first application of stochastic weight averaging to cosmology, and apply it to SBI trained for inference on the cosmic microwave background.},
  archive      = {J_MLST},
  author       = {Pablo Lemos and Miles Cranmer and Muntazir Abidi and ChangHoon Hahn and Michael Eickenberg and Elena Massara and David Yallup and Shirley Ho},
  doi          = {10.1088/2632-2153/acbb53},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {01LT01},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Robust simulation-based inference in cosmology with bayesian neural networks},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast regression of the tritium breeding ratio in fusion
reactors. <em>MLST</em>, <em>4</em>(1), 015008. (<a
href="https://doi.org/10.1088/2632-2153/acb2b3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The tritium breeding ratio (TBR) is an essential quantity for the design of modern and next-generation D-T fueled nuclear fusion reactors. Representing the ratio between tritium fuel generated in breeding blankets and fuel consumed during reactor runtime, the TBR depends on reactor geometry and material properties in a complex manner. In this work, we explored the training of surrogate models to produce a cheap but high-quality approximation for a Monte Carlo (MC) TBR model in use at the UK Atomic Energy Authority. We investigated possibilities for dimensional reduction of its feature space, reviewed 9 families of surrogate models for potential applicability, and performed hyperparameter optimization. Here we present the performance and scaling properties of these models, the fastest of which, an artificial neural network, demonstrated R^2 = 0.985 and a mean prediction time of 0.898~\mu\textrm{s} , representing a relative speedup of 8\times 10^6 with respect to the expensive MC model. We further present a novel adaptive sampling algorithm, Quality-Adaptive Surrogate Sampling, capable of interfacing with any of the individually studied surrogates. Our preliminary testing on a toy TBR theory has demonstrated the efficacy of this algorithm for accelerating the surrogate modelling process.},
  archive      = {J_MLST},
  author       = {P Mánek and G Van Goffrier and V Gopakumar and N Nikolaou and J Shimwell and I Waldmann},
  doi          = {10.1088/2632-2153/acb2b3},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015008},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Fast regression of the tritium breeding ratio in fusion reactors},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SYMBA: Symbolic computation of squared amplitudes in high
energy physics with machine learning. <em>MLST</em>, <em>4</em>(1),
015007. (<a href="https://doi.org/10.1088/2632-2153/acb2b2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cross section is one of the most important physical quantities in high-energy physics and the most time consuming to compute. While machine learning has proven to be highly successful in numerical calculations in high-energy physics, analytical calculations using machine learning are still in their infancy. In this work, we use a sequence-to-sequence model, specifically, a transformer, to compute a key element of the cross section calculation, namely, the squared amplitude of an interaction. We show that a transformer model is able to predict correctly 97.6% and 99% of squared amplitudes of quantum chromodynamics and quantum electrodynamics processes, respectively, at a speed that is up to orders of magnitude faster than current symbolic computation frameworks. We discuss the performance of the current model, its limitations and possible future directions for this work.},
  archive      = {J_MLST},
  author       = {Abdulhakim Alnuqaydan and Sergei Gleyzer and Harrison Prosper},
  doi          = {10.1088/2632-2153/acb2b2},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015007},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {SYMBA: Symbolic computation of squared amplitudes in high energy physics with machine learning},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Variational quantum one-class classifier. <em>MLST</em>,
<em>4</em>(1), 015006. (<a
href="https://doi.org/10.1088/2632-2153/acafd5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-class classification (OCC) is a fundamental problem in pattern recognition with a wide range of applications. This work presents a semi-supervised quantum machine learning algorithm for such a problem, which we call a variational quantum one-class classifier (VQOCC). The algorithm is suitable for noisy intermediate-scale quantum computing because the VQOCC trains a fully-parameterized quantum autoencoder with a normal dataset and does not require decoding. The performance of the VQOCC is compared with that of the one-class support vector machine (OC-SVM), the kernel principal component analysis (PCA), and the deep convolutional autoencoder (DCAE) using handwritten digit and Fashion-MNIST datasets. The numerical experiment examined various structures of VQOCC by varying data encoding, the number of parameterized quantum circuit layers, and the size of the latent feature space. The benchmark shows that the classification performance of VQOCC is comparable to that of OC-SVM and PCA, although the number of model parameters grows only logarithmically with the data size. The quantum algorithm outperformed DCAE in most cases under similar training conditions. Therefore, our algorithm constitutes an extremely compact and effective machine learning model for OCC.},
  archive      = {J_MLST},
  author       = {Gunhee Park and Joonsuk Huh and Daniel K Park},
  doi          = {10.1088/2632-2153/acafd5},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015006},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Variational quantum one-class classifier},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantum machine learning of large datasets using randomized
measurements. <em>MLST</em>, <em>4</em>(1), 015005. (<a
href="https://doi.org/10.1088/2632-2153/acb0b4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computers promise to enhance machine learning for practical applications. Quantum machine learning for real-world data has to handle extensive amounts of high-dimensional data. However, conventional methods for measuring quantum kernels are impractical for large datasets as they scale with the square of the dataset size. Here, we measure quantum kernels using randomized measurements. The quantum computation time scales linearly with dataset size and quadratic for classical post-processing. While our method scales in general exponentially in qubit number, we gain a substantial speed-up when running on intermediate-sized quantum computers. Further, we efficiently encode high-dimensional data into quantum computers with the number of features scaling linearly with the circuit depth. The encoding is characterized by the quantum Fisher information metric and is related to the radial basis function kernel. Our approach is robust to noise via a cost-free error mitigation scheme. We demonstrate the advantages of our methods for noisy quantum computers by classifying images with the IBM quantum computer. To achieve further speedups we distribute the quantum computational tasks between different quantum computers. Our method enables benchmarking of quantum machine learning algorithms with large datasets on currently available quantum computers.},
  archive      = {J_MLST},
  author       = {Tobias Haug and Chris N Self and M S Kim},
  doi          = {10.1088/2632-2153/acb0b4},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015005},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Quantum machine learning of large datasets using randomized measurements},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The impact of cost function globality and locality in hybrid
quantum neural networks on NISQ devices. <em>MLST</em>, <em>4</em>(1),
015004. (<a href="https://doi.org/10.1088/2632-2153/acb12f">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum neural networks (QNNs) are often challenged with the problem of flat cost function landscapes during training, known as barren plateaus (BP). A solution to potentially overcome the problem of the BP has recently been proposed by Cerezo et al In this solution, it is shown that, for an arbitrary deep quantum layer(s) in QNNs, a global cost function (all qubits measured in an n -qubit system) will always experience BP, whereas a local cost function (single qubit measured in an n -qubit system) can help to alleviate the problem of BP to a certain depth ( \mathcal{O}(\mathrm {log}(n) )). In this paper, we empirically analyze the locality and globality of the cost function in hybrid quantum neural networks. We consider two application scenarios namely, binary and multi-class classification, and show that for multiclass classification, the local cost function setting does not follow the claims of Cerezo et al ; that is, the local cost function does not result in an extended quantum layer&#39;s depth. We also show that for multiclass classification, the overall performance in terms of accuracy for the global cost function setting is significantly higher than the local cost function setting. On the other hand, for binary classification, our results show that the local cost function setting follows the claims of Cerezo et al , and results in an extended depth of quantum layers. However, the global cost function setting still performs slightly better than the local cost function.},
  archive      = {J_MLST},
  author       = {Muhammad Kashif and Saif Al-Kuwari},
  doi          = {10.1088/2632-2153/acb12f},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015004},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {The impact of cost function globality and locality in hybrid quantum neural networks on NISQ devices},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning the dynamics of particle-based systems with
lagrangian graph neural networks. <em>MLST</em>, <em>4</em>(1), 015003.
(<a href="https://doi.org/10.1088/2632-2153/acb03e">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physical systems are commonly represented as a combination of particles, the individual dynamics of which govern the system dynamics. However, traditional approaches require the knowledge of several abstract quantities such as the energy or force to infer the dynamics of these particles. Here, we present a framework, namely, Lagrangian graph neural network ( LGnn ), that provides a strong inductive bias to learn the Lagrangian of a particle-based system directly from the trajectory. We test our approach on challenging systems with constraints and drag— LGnn outperforms baselines such as feed-forward Lagrangian neural network ( Lnn ) with improved performance. We also show the zero-shot generalizability of the system by simulating systems two orders of magnitude larger than the trained one and also hybrid systems that are unseen by the model, a unique feature. The graph architecture of LGnn significantly simplifies the learning in comparison to Lnn with ∼25 times better performance on ∼20 times smaller amounts of data. Finally, we show the interpretability of LGnn , which directly provides physical insights on drag and constraint forces learned by the model. LGnn can thus provide a fillip toward understanding the dynamics of physical systems purely from observable quantities.},
  archive      = {J_MLST},
  author       = {Ravinder Bhattoo and Sayan Ranu and N M Anoop Krishnan},
  doi          = {10.1088/2632-2153/acb03e},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015003},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Learning the dynamics of particle-based systems with lagrangian graph neural networks},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Convolutional neural network analysis of x-ray diffraction
data: Strain profile retrieval in ion beam modified materials.
<em>MLST</em>, <em>4</em>(1), 015002. (<a
href="https://doi.org/10.1088/2632-2153/acab4c">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work describes a proof of concept demonstrating that convolutional neural networks (CNNs) can be used to invert x-ray diffraction (XRD) data, so as to, for instance, retrieve depth-resolved strain profiles. The determination of strain distributions in disordered materials is critical in several technological domains, such as the semiconductor industry for instance. Using numerically generated data, a dedicated CNN has been developed, optimized, and trained, with the ultimate objective of inferring spatial strain profiles on the sole basis of XRD data, without the need of a priori knowledge or human intervention. With the example ZrO 2 single crystals, in which atomic disorder and strain are introduced by means of ion irradiation, we investigate the physical parameters of the disordered material that condition the performances of the CNN. Simple descriptors of the strain distribution, such as the maximum strain and the strained depth, are predicted with accuracies of 94% and 91%, respectively. The exact shape of the strain distribution is predicted with a 82% accuracy, and 76% for strain levels &lt;2% where the amount of meaningful information in the XRD data is significantly decreased. The robustness of the CNN against the number of predicted parameters and the size of the training dataset, as well as the uniqueness of the solution in some challenging cases, are critically discussed. Finally, the potential of the CNN has been tested on real, experimental, data. Interestingly, while the CNN has not been trained to operate on experimental data, it still shows promising performances with predictions achieved in a few seconds and corresponding root-mean-square errors in the 0.12–0.17 range for a fully automated approach, vs. a 0.06–0.12 range for a classical, human-based, approach that, in turn, requires several tens of minutes to optimize the solution. While the overall accuracy of the CNN has to be improved, these results pave the way for a fully automated XRD data analysis.},
  archive      = {J_MLST},
  author       = {A Boulle and A Debelle},
  doi          = {10.1088/2632-2153/acab4c},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015002},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Convolutional neural network analysis of x-ray diffraction data: Strain profile retrieval in ion beam modified materials},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Material transformers: Deep learning language models for
generative materials design. <em>MLST</em>, <em>4</em>(1), 015001. (<a
href="https://doi.org/10.1088/2632-2153/acadcd">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-trained transformer language models (LMs) on large unlabeled corpus have produced state-of-the-art results in natural language processing, organic molecule design, and protein sequence generation. However, no such models have been applied to learn the composition patterns for the generative design of material compositions. Here we train a series of seven modern transformer models (GPT, GPT-2, GPT-Neo, GPT-J, BLMM, BART, and RoBERTa) for materials design using the expanded formulas of the ICSD, OQMD, and Materials Projects databases. Six different datasets with/out non-charge-neutral or EB samples are used to benchmark the generative design performances and uncover the biases of modern transformer models for the generative design of materials compositions. Our experiments show that the materials transformers based on causal LMs can generate chemically valid material compositions with as high as 97.61% to be charge neutral and 91.22% to be electronegativity balanced, which has more than six times higher enrichment compared to the baseline pseudo-random sampling algorithm. Our LMs also demonstrate high generation novelty and their potential in new materials discovery is proved by their capability to recover the leave-out materials. We also find that the properties of the generated compositions can be tailored by training the models with selected training sets such as high-bandgap samples. Our experiments also show that different models each have their own preference in terms of the properties of the generated samples and their running time complexity varies a lot. We have applied our materials transformers to discover a set of new materials as validated using density functional theory calculations. All our trained materials transformer models and code can be accessed freely at http://www.github.com/usccolumbia/MTransformer .},
  archive      = {J_MLST},
  author       = {Nihang Fu and Lai Wei and Yuqi Song and Qinyang Li and Rui Xin and Sadman Sadeed Omee and Rongzhi Dong and Edirisuriya M Dilanga Siriwardane and Jianjun Hu},
  doi          = {10.1088/2632-2153/acadcd},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015001},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Material transformers: Deep learning language models for generative materials design},
  volume       = {4},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
