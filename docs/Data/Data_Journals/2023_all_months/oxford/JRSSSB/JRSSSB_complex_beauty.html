<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JRSSSB_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jrsssb---77">JRSSSB - 77</h2>
<ul>
<li><details>
<summary>
(2023c). Correction to: Sensitivity analysis for inverse probability
weighting estimators via the percentile bootstrap. <em>JRSSSB</em>,
<em>85</em>(4), 1355. (<a
href="https://doi.org/10.1093/jrsssb/qkad079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  doi          = {10.1093/jrsssb/qkad079},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1355},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Correction to: Sensitivity analysis for inverse probability weighting estimators via the percentile bootstrap},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quasi-newton updating for large-scale distributed learning.
<em>JRSSSB</em>, <em>85</em>(4), 1326–1354. (<a
href="https://doi.org/10.1093/jrsssb/qkad059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed computing is critically important for modern statistical analysis. Herein, we develop a distributed quasi-Newton (DQN) framework with excellent statistical, computation, and communication efficiency. In the DQN method, no Hessian matrix inversion or communication is needed. This considerably reduces the computation and communication complexity of the proposed method. Notably, related existing methods only analyse numerical convergence and require a diverging number of iterations to converge. However, we investigate the statistical properties of the DQN method and theoretically demonstrate that the resulting estimator is statistically efficient over a small number of iterations under mild conditions. Extensive numerical analyses demonstrate the finite sample performance.},
  archive      = {J_JRSSSB},
  author       = {Wu, Shuyuan and Huang, Danyang and Wang, Hansheng},
  doi          = {10.1093/jrsssb/qkad059},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1326-1354},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Quasi-newton updating for large-scale distributed learning},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Two-stage estimation and bias-corrected empirical likelihood
in a partially linear single-index varying-coefficient model.
<em>JRSSSB</em>, <em>85</em>(4), 1299–1325. (<a
href="https://doi.org/10.1093/jrsssb/qkad060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The estimation and empirical likelihood (EL) of the parameters of interest in a partially linear single-index varying-coefficient model are studied. A two-stage method is presented to estimate the regression parameters and the coefficient functions. The asymptotic distributions of the proposed estimators are obtained. Meanwhile, a bias-corrected EL ratio for the regression parameters is proposed. It is shown that the ratio is asymptotically standard chi-squared. The result can be directly used to construct the EL confidence regions of the regression parameters. Simulation studies are carried out to evaluate the finite sample behaviour of the proposed method. An application example of a real data set is given.},
  archive      = {J_JRSSSB},
  author       = {Xue, Liugen},
  doi          = {10.1093/jrsssb/qkad060},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1299-1325},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Two-stage estimation and bias-corrected empirical likelihood in a partially linear single-index varying-coefficient model},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Strategic two-sample test via the two-armed bandit process.
<em>JRSSSB</em>, <em>85</em>(4), 1271–1298. (<a
href="https://doi.org/10.1093/jrsssb/qkad061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to improve the power of two-sample tests by analysing whether the difference between two population parameters is larger than a prespecified positive equivalence margin. The classic test statistic treats the original data as exchangeable, while the proposed test statistic breaks the structure and proposes employing a two-armed bandit process to strategically integrate the data and thus a strategy-specific test statistic is constructed by combining the classic CLT with the law of large numbers. The developed asymptotic theory is investigated by using nonlinear limit theory in a larger probability space and relates to the ‘strategic CLT’ with a clearly defined density function. The asymptotic distribution demonstrates that the proposed statistic is more concentrated under the null hypothesis and less concentrated under the alternative than the classic CLT, thereby enhancing the testing power. Simulation studies provide supporting evidence for the theoretical results and portray a more powerful performance when using finite samples. A real example is also added for illustration.},
  archive      = {J_JRSSSB},
  author       = {Chen, Zengjing and Yan, Xiaodong and Zhang, Guodong},
  doi          = {10.1093/jrsssb/qkad061},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1271-1298},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Strategic two-sample test via the two-armed bandit process},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Normalised latent measure factor models. <em>JRSSSB</em>,
<em>85</em>(4), 1247–1270. (<a
href="https://doi.org/10.1093/jrsssb/qkad062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a methodology for modelling and comparing probability distributions within a Bayesian nonparametric framework. Building on dependent normalised random measures, we consider a prior distribution for a collection of discrete random measures where each measure is a linear combination of a set of latent measures, interpretable as characteristic traits shared by different distributions, with positive random weights. The model is nonidentified and a method for postprocessing posterior samples to achieve identified inference is developed. This uses Riemannian optimisation to solve a nontrivial optimisation problem over a Lie group of matrices. The effectiveness of our approach is validated on simulated data and in two applications to two real-world data sets: school student test scores and personal incomes in California. Our approach leads to interesting insights for populations and easily interpretable posterior inference.},
  archive      = {J_JRSSSB},
  author       = {Beraha, Mario and Griffin, Jim E},
  doi          = {10.1093/jrsssb/qkad062},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1247-1270},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Normalised latent measure factor models},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust estimation and inference for expected shortfall
regression with many regressors. <em>JRSSSB</em>, <em>85</em>(4),
1223–1246. (<a href="https://doi.org/10.1093/jrsssb/qkad063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expected shortfall (ES), also known as superquantile or conditional value-at-risk, is an important measure in risk analysis and stochastic optimisation and has applications beyond these fields. In finance, it refers to the conditional expected return of an asset given that the return is below some quantile of its distribution. In this paper, we consider a joint regression framework recently proposed to model the quantile and ES of a response variable simultaneously, given a set of covariates. The current state-of-the-art approach to this problem involves minimising a non-differentiable and non-convex joint loss function, which poses numerical challenges and limits its applicability to large-scale data. Motivated by the idea of using Neyman-orthogonal scores to reduce sensitivity to nuisance parameters, we propose a statistically robust and computationally efficient two-step procedure for fitting joint quantile and ES regression models that can handle highly skewed and heavy-tailed data. We establish explicit non-asymptotic bounds on estimation and Gaussian approximation errors that lay the foundation for statistical inference, even with increasing covariate dimensions. Finally, through numerical experiments and two data applications, we demonstrate that our approach well balances robustness, statistical, and numerical efficiencies for expected shortfall regression.},
  archive      = {J_JRSSSB},
  author       = {He, Xuming and Tan, Kean Ming and Zhou, Wen-Xin},
  doi          = {10.1093/jrsssb/qkad063},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1223-1246},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Robust estimation and inference for expected shortfall regression with many regressors},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Testing for the markov property in time series via deep
conditional generative learning. <em>JRSSSB</em>, <em>85</em>(4),
1204–1222. (<a href="https://doi.org/10.1093/jrsssb/qkad064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Markov property is widely imposed in analysis of time series data. Correspondingly, testing the Markov property, and relatedly, inferring the order of a Markov model, are of paramount importance. In this article, we propose a nonparametric test for the Markov property in high-dimensional time series via deep conditional generative learning. We also apply the test sequentially to determine the order of the Markov model. We show that the test controls the type-I error asymptotically, and has the power approaching one. Our proposal makes novel contributions in several ways. We utilise and extend state-of-the-art deep generative learning to estimate the conditional density functions, and establish a sharp upper bound on the approximation error of the estimators. We derive a doubly robust test statistic, which employs a nonparametric estimation but achieves a parametric convergence rate. We further adopt sample splitting and cross-fitting to minimise the conditions required to ensure the consistency of the test. We demonstrate the efficacy of the test through both simulations and the three data applications.},
  archive      = {J_JRSSSB},
  author       = {Zhou, Yunzhe and Shi, Chengchun and Li, Lexin and Yao, Qiwei},
  doi          = {10.1093/jrsssb/qkad064},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1204-1222},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Testing for the markov property in time series via deep conditional generative learning},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Consistent and fast inference in compartmental models of
epidemics using poisson approximate likelihoods. <em>JRSSSB</em>,
<em>85</em>(4), 1173–1203. (<a
href="https://doi.org/10.1093/jrsssb/qkad065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addressing the challenge of scaling-up epidemiological inference to complex and heterogeneous models, we introduce Poisson approximate likelihood (PAL) methods. In contrast to the popular ordinary differential equation (ODE) approach to compartmental modelling, in which a large population limit is used to motivate a deterministic model, PALs are derived from approximate filtering equations for finite-population, stochastic compartmental models, and the large population limit drives consistency of maximum PAL estimators. Our theoretical results appear to be the first likelihood-based parameter estimation consistency results which apply to a broad class of partially observed stochastic compartmental models and address the large population limit. PALs are simple to implement, involving only elementary arithmetic operations and no tuning parameters, and fast to evaluate, requiring no simulation from the model and having computational cost independent of population size. Through examples we demonstrate how PALs can be used to: fit an age-structured model of influenza, taking advantage of automatic differentiation in Stan; compare over-dispersion mechanisms in a model of rotavirus by embedding PALs within sequential Monte Carlo; and evaluate the role of unit-specific parameters in a meta-population model of measles.},
  archive      = {J_JRSSSB},
  author       = {Whitehouse, Michael and Whiteley, Nick and Rimella, Lorenzo},
  doi          = {10.1093/jrsssb/qkad065},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1173-1203},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Consistent and fast inference in compartmental models of epidemics using poisson approximate likelihoods},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the causal interpretation of randomised interventional
indirect effects. <em>JRSSSB</em>, <em>85</em>(4), 1154–1172. (<a
href="https://doi.org/10.1093/jrsssb/qkad066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identification of standard mediated effects such as the natural indirect effect relies on heavy causal assumptions. By circumventing such assumptions, so-called randomised interventional indirect effects have gained popularity in the mediation literature. Here, I introduce properties one might demand of an indirect effect measure in order for it to have a true mediational interpretation. For instance, the sharp null criterion requires an indirect effect measure to be null whenever no individual-level indirect effect exists. I show that without stronger assumptions, randomised interventional indirect effects do not satisfy such criteria. I additionally discuss alternative causal interpretations of such effects.},
  archive      = {J_JRSSSB},
  author       = {Miles, Caleb H},
  doi          = {10.1093/jrsssb/qkad066},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1154-1172},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {On the causal interpretation of randomised interventional indirect effects},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cluster extent inference revisited: Quantification and
localisation of brain activity. <em>JRSSSB</em>, <em>85</em>(4),
1128–1153. (<a href="https://doi.org/10.1093/jrsssb/qkad067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cluster inference based on spatial extent thresholding is a popular analysis method multiple testing in spatial data, and is frequently used for finding activated brain areas in neuroimaging. However, the method has several well-known issues. While powerful for finding regions with some activation, the method as currently defined does not allow any further quantification or localisation of signal. In this paper, we repair this gap. We show that cluster-extent inference can be used (1) to infer the presence of signal in any region of interest and (2) to quantify the percentage of activation in such regions. These additional inferences come for free, i.e. they do not require any further adjustment of the alpha-level of tests, while retaining full family-wise error control. We achieve this extension of the possibilities of cluster inference by embedding the method into a closed testing procedure, and solving the graph-theoretic k -separator problem that results from this embedding. We demonstrate the usefulness of the improved method in a large-scale application to neuroimaging data from the Neurovault database.},
  archive      = {J_JRSSSB},
  author       = {Goeman, Jelle J and Górecki, Paweł and Monajemi, Ramin and Chen, Xu and Nichols, Thomas E and Weeda, Wouter},
  doi          = {10.1093/jrsssb/qkad067},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1128-1153},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Cluster extent inference revisited: Quantification and localisation of brain activity},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantile autoregressive conditional heteroscedasticity.
<em>JRSSSB</em>, <em>85</em>(4), 1099–1127. (<a
href="https://doi.org/10.1093/jrsssb/qkad068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel conditional heteroscedastic time series model by applying the framework of quantile regression processes to the ARCH ( ∞ ) form of the GARCH model. This model can provide varying structures for conditional quantiles of the time series across different quantile levels, while including the commonly used GARCH model as a special case. The strict stationarity of the model is discussed. For robustness against heavy-tailed distributions, a self-weighted quantile regression (QR) estimator is proposed. While QR performs satisfactorily at intermediate quantile levels, its accuracy deteriorates at high quantile levels due to data scarcity. As a remedy, a self-weighted composite quantile regression estimator is further introduced and, based on an approximate GARCH model with a flexible Tukey-lambda distribution for the innovations, we can extrapolate the high quantile levels by borrowing information from intermediate ones. Asymptotic properties for the proposed estimators are established. Simulation experiments are carried out to access the finite sample performance of the proposed methods, and an empirical example is presented to illustrate the usefulness of the new model.},
  archive      = {J_JRSSSB},
  author       = {Zhu, Qianqian and Tan, Songhua and Zheng, Yao and Li, Guodong},
  doi          = {10.1093/jrsssb/qkad068},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1099-1127},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Quantile autoregressive conditional heteroscedasticity},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Karl rohe and muzhe zeng’s reply to the discussion of
“vintage factor analysis with varimax performs statistical inference.”
<em>JRSSSB</em>, <em>85</em>(4), 1094–1098. (<a
href="https://doi.org/10.1093/jrsssb/qkad074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Rohe, Karl and Zeng, Muzhe},
  doi          = {10.1093/jrsssb/qkad074},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1094-1098},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Karl rohe and muzhe zeng’s reply to the discussion of ‘Vintage factor analysis with varimax performs statistical inference’},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ying zhou and xinyi zhang’s contribution to the discussion
of “vintage factor analysis with varimax performs statistical inference”
by rohe &amp; zeng. <em>JRSSSB</em>, <em>85</em>(4), 1093–1094. (<a
href="https://doi.org/10.1093/jrsssb/qkad056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Zhou, Ying and Zhang, Xinyi},
  doi          = {10.1093/jrsssb/qkad056},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1093-1094},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Ying zhou and xinyi zhang&#39;s contribution to the discussion of ‘Vintage factor analysis with varimax performs statistical inference’ by rohe &amp; zeng},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tao wang’s contribution to the discussion of “vintage factor
analysis with varimax performs statistical inference” by rohe &amp;
zeng. <em>JRSSSB</em>, <em>85</em>(4), 1092–1093. (<a
href="https://doi.org/10.1093/jrsssb/qkad046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Wang, Tao},
  doi          = {10.1093/jrsssb/qkad046},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1092-1093},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Tao wang&#39;s contribution to the discussion of ‘Vintage factor analysis with varimax performs statistical inference’ by rohe &amp; zeng},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tyler j. VanderWeele’s contribution to the discussion of
“vintage factor analysis with varimax performs statistical inference” by
rohe &amp; zeng. <em>JRSSSB</em>, <em>85</em>(4), 1091–1092. (<a
href="https://doi.org/10.1093/jrsssb/qkad045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {VanderWeele, Tyler J},
  doi          = {10.1093/jrsssb/qkad045},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1091-1092},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Tyler j. VanderWeele&#39;s contribution to the discussion of ‘Vintage factor analysis with varimax performs statistical inference’ by rohe &amp; zeng},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mark pilling’s contribution to the discussion of “vintage
factor analysis with varimax performs statistical inference” by rohe
&amp; zeng. <em>JRSSSB</em>, <em>85</em>(4), 1089. (<a
href="https://doi.org/10.1093/jrsssb/qkad044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Pilling, Mark},
  doi          = {10.1093/jrsssb/qkad044},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1089},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Mark pilling&#39;s contribution to the discussion of ‘Vintage factor analysis with varimax performs statistical inference’ by rohe &amp; zeng},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Konstantin siroki and korbinian strimmer’s contribution to
the discussion of “vintage factor analysis with varimax performs
statistical inference” by rohe and zeng. <em>JRSSSB</em>,
<em>85</em>(4), 1089–1090. (<a
href="https://doi.org/10.1093/jrsssb/qkad055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Siroki, Konstantin and Strimmer, Korbinian},
  doi          = {10.1093/jrsssb/qkad055},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1089-1090},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Konstantin siroki and korbinian strimmer’s contribution to the discussion of ‘Vintage factor analysis with varimax performs statistical inference’ by rohe and zeng},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Florian pargent, david goretzko and timo von oertzen’s
contribution to the discussion of “vintage factor analysis with varimax
performs statistical inference” by rohe &amp; zeng. <em>JRSSSB</em>,
<em>85</em>(4), 1087–1088. (<a
href="https://doi.org/10.1093/jrsssb/qkad054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Pargent, Florian and Goretzko, David and von Oertzen, Timo},
  doi          = {10.1093/jrsssb/qkad054},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1087-1088},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Florian pargent, david goretzko and timo von oertzen&#39;s contribution to the discussion of ‘Vintage factor analysis with varimax performs statistical inference’ by rohe &amp; zeng},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Xiaoyue niu’s contribution to the discussion of “vintage
factor analysis with varimax performs statistical inference” by rohe
&amp; zeng. <em>JRSSSB</em>, <em>85</em>(4), 1086–1087. (<a
href="https://doi.org/10.1093/jrsssb/qkad043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Niu, Xiaoyue},
  doi          = {10.1093/jrsssb/qkad043},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1086-1087},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Xiaoyue niu&#39;s contribution to the discussion of ‘Vintage factor analysis with varimax performs statistical inference’ by rohe &amp; zeng},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Yang liu’s contribution to the discussion of “vintage factor
analysis with varimax performs statistical inference” by rohe &amp;
zeng. <em>JRSSSB</em>, <em>85</em>(4), 1085–1086. (<a
href="https://doi.org/10.1093/jrsssb/qkad042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Liu, Yang},
  doi          = {10.1093/jrsssb/qkad042},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1085-1086},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Yang liu&#39;s contribution to the discussion of ‘Vintage factor analysis with varimax performs statistical inference’ by rohe &amp; zeng},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Kuldeep kumar’s contribution to the discussion of “vintage
factor analysis with varimax performs statistical inference” by rohe
&amp; zeng. <em>JRSSSB</em>, <em>85</em>(4), 1084. (<a
href="https://doi.org/10.1093/jrsssb/qkad041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Kumar, Kuldeep},
  doi          = {10.1093/jrsssb/qkad041},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1084},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Kuldeep kumar&#39;s contribution to the discussion of ‘Vintage factor analysis with varimax performs statistical inference’ by rohe &amp; zeng},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Yunxiao chen and gongjun xu’s contribution to the discussion
of “vintage factor analysis with varimax performs statistical inference”
by rohe &amp; zeng. <em>JRSSSB</em>, <em>85</em>(4), 1082–1084. (<a
href="https://doi.org/10.1093/jrsssb/qkad040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Chen, Yunxiao and Xu, Gongjun},
  doi          = {10.1093/jrsssb/qkad040},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1082-1084},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Yunxiao chen and gongjun xu&#39;s contribution to the discussion of ‘Vintage factor analysis with varimax performs statistical inference’ by rohe &amp; zeng},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Christine p chai’s contribution to the discussion of
“vintage factor analysis with varimax performs statistical inference” by
rohe &amp; zeng. <em>JRSSSB</em>, <em>85</em>(4), 1081–1082. (<a
href="https://doi.org/10.1093/jrsssb/qkad039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Chai, Christine P},
  doi          = {10.1093/jrsssb/qkad039},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1081-1082},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Christine p chai&#39;s contribution to the discussion of ‘Vintage factor analysis with varimax performs statistical inference’ by rohe &amp; zeng},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Junhui cai, dan yang, linda zhao and wu zhu’s contribution
to the discussion of “vintage factor analysis with varimax performs
statistical inference” by rohe &amp; zeng. <em>JRSSSB</em>,
<em>85</em>(4), 1076–1080. (<a
href="https://doi.org/10.1093/jrsssb/qkad038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Cai, Junhui and Yang, Dan and Zhao, Linda and Zhu, Wu},
  doi          = {10.1093/jrsssb/qkad038},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1076-1080},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Junhui cai, dan yang, linda zhao and wu zhu&#39;s contribution to the discussion of ‘Vintage factor analysis with varimax performs statistical inference’ by rohe &amp; zeng},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Peter j. Bickel, derek bean, aiyou chen and purnamrita
sarkar’s contribution to the discussion of “vintage factor analysis with
varimax performs statistical inference” by rohe &amp; zeng.
<em>JRSSSB</em>, <em>85</em>(4), 1074–1075. (<a
href="https://doi.org/10.1093/jrsssb/qkad037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Bickel, Peter J and Bean, Derek and Chen, Aiyou and Sarkar, Purnamrita},
  doi          = {10.1093/jrsssb/qkad037},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1074-1075},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Peter j. bickel, derek bean, aiyou chen and purnamrita sarkar&#39;s contribution to the discussion of ‘Vintage factor analysis with varimax performs statistical inference’ by rohe &amp; zeng},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Yinqiu he, yuqi gu and zhilian ying’s contribution to the
discussion of “vintage factor analysis with varimax performs statistical
inference” by rohe &amp; zeng. <em>JRSSSB</em>, <em>85</em>(4),
1071–1074. (<a href="https://doi.org/10.1093/jrsssb/qkad036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {He, Yinqiu and Gu, Yuqi and Ying, Zhiliang},
  doi          = {10.1093/jrsssb/qkad036},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1071-1074},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Yinqiu he, yuqi gu and zhilian ying&#39;s contribution to the discussion of ‘Vintage factor analysis with varimax performs statistical inference’ by rohe &amp; zeng},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Alexander van werde’s contribution to the discussion of
“vintage factor analysis with varimax performs statistical inference” by
rohe &amp; zeng. <em>JRSSSB</em>, <em>85</em>(4), 1070–1071. (<a
href="https://doi.org/10.1093/jrsssb/qkad035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Van Werde, Alexander},
  doi          = {10.1093/jrsssb/qkad035},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1070-1071},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Alexander van werde&#39;s contribution to the discussion of ‘Vintage factor analysis with varimax performs statistical inference’ by rohe &amp; zeng},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rungang han and anru r. Zhangs contribution to the
discussion of “vintage factor analysis with varimax performs statistical
inference” by rohe &amp; zeng. <em>JRSSSB</em>, <em>85</em>(4),
1069–1070. (<a href="https://doi.org/10.1093/jrsssb/qkad034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Han, Rungang and Zhang, Anru R},
  doi          = {10.1093/jrsssb/qkad034},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1069-1070},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Rungang han and anru r. zhangs contribution to the discussion of ‘Vintage factor analysis with varimax performs statistical inference’ by rohe &amp; zeng},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Kaizheng wang’s contribution to the discussion of “vintage
factor analysis with varimax performs statistical inference” by rohe
&amp; zeng. <em>JRSSSB</em>, <em>85</em>(4), 1068. (<a
href="https://doi.org/10.1093/jrsssb/qkad033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Wang, Kaizheng},
  doi          = {10.1093/jrsssb/qkad033},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1068},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Kaizheng wang&#39;s contribution to the discussion of ‘Vintage factor analysis with varimax performs statistical inference’ by rohe &amp; zeng},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joshua cape’s contribution to the discussion of “vintage
factor analysis with varimax performs statistical inference” by rohe
&amp; zeng. <em>JRSSSB</em>, <em>85</em>(4), 1066–1067. (<a
href="https://doi.org/10.1093/jrsssb/qkad032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Cape, Joshua},
  doi          = {10.1093/jrsssb/qkad032},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1066-1067},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Joshua cape&#39;s contribution to the discussion of ‘Vintage factor analysis with varimax performs statistical inference’ by rohe &amp; zeng},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Seconder of the vote of thanks to rohe &amp; zeng and
contribution to the discussion of “vintage factor analysis with varimax
performs statistical inference.” <em>JRSSSB</em>, <em>85</em>(4),
1062–1066. (<a href="https://doi.org/10.1093/jrsssb/qkad031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Pensky, Marianna},
  doi          = {10.1093/jrsssb/qkad031},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1062-1066},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Seconder of the vote of thanks to rohe &amp; zeng and contribution to the discussion of ‘Vintage factor analysis with varimax performs statistical inference’},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Proposer of the vote of thanks to rohe &amp; zeng and
contribution to the discussion of “vintage factor analysis with varimax
performs statistical inference.” <em>JRSSSB</em>, <em>85</em>(4),
1061–1062. (<a href="https://doi.org/10.1093/jrsssb/qkad030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Hoff, Peter},
  doi          = {10.1093/jrsssb/qkad030},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1061-1062},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Proposer of the vote of thanks to rohe &amp; zeng and contribution to the discussion of ‘Vintage factor analysis with varimax performs statistical inference’},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Vintage factor analysis with varimax performs statistical
inference. <em>JRSSSB</em>, <em>85</em>(4), 1037–1060. (<a
href="https://doi.org/10.1093/jrsssb/qkad029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the 1930s, Psychologists began developing Multiple-Factor Analysis to decompose multivariate data into a small number of interpretable factors without any a priori knowledge about those factors. In this form of factor analysis, the Varimax factor rotation redraws the axes through the multi-dimensional factors to make them sparse and thus make them more interpretable. Charles Spearman and many others objected to factor rotations because the factors seem to be rotationally invariant. Despite the controversy, factor rotations have remained widely popular among people analyzing data. Reversing nearly a century of statistical thinking on the topic, we show that the rotation makes the factors easier to interpret because the Varimax performs statistical inference; in particular, principal components analysis (PCA) with a Varimax rotation provides a unified spectral estimation strategy for a broad class of semi-parametric factor models, including the Stochastic Blockmodel and a natural variation of Latent Dirichlet Allocation. In addition, we show that Thurstone’s widely employed sparsity diagnostics implicitly assess a key leptokurtic condition that makes the axes statistically identifiable in these models. PCA with Varimax is fast, stable, and practical. Combined with Thurstone’s straightforward diagnostics, this vintage approach is suitable for a wide array of modern applications.},
  archive      = {J_JRSSSB},
  author       = {Rohe, Karl and Zeng, Muzhe},
  doi          = {10.1093/jrsssb/qkad029},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {4},
  pages        = {1037-1060},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Vintage factor analysis with varimax performs statistical inference},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Correction to: Autoregressive optimal transport models.
<em>JRSSSB</em>, <em>85</em>(3), 1035. (<a
href="https://doi.org/10.1093/jrsssb/qkad057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  doi          = {10.1093/jrsssb/qkad057},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {3},
  pages        = {1035},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Correction to: Autoregressive optimal transport models},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Correction to: Ordering factorial experiments.
<em>JRSSSB</em>, <em>85</em>(3), 1034. (<a
href="https://doi.org/10.1093/jrsssb/qkad053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  doi          = {10.1093/jrsssb/qkad053},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {3},
  pages        = {1034},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Correction to: Ordering factorial experiments},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Autoregressive optimal transport models. <em>JRSSSB</em>,
<em>85</em>(3), 1012–1033. (<a
href="https://doi.org/10.1093/jrsssb/qkad051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Series of univariate distributions indexed by equally spaced time points are ubiquitous in applications and their analysis constitutes one of the challenges of the emerging field of distributional data analysis. To quantify such distributional time series, we propose a class of intrinsic autoregressive models that operate in the space of optimal transport maps. The autoregressive transport models that we introduce here are based on regressing optimal transport maps on each other, where predictors can be transport maps from an overall barycenter to a current distribution or transport maps between past consecutive distributions of the distributional time series. Autoregressive transport models and their associated distributional regression models specify the link between predictor and response transport maps by moving along geodesics in Wasserstein space. These models emerge as natural extensions of the classical autoregressive models in Euclidean space. Unique stationary solutions of autoregressive transport models are shown to exist under a geometric moment contraction condition of Wu &amp; Shao [(2004) Limit theorems for iterated random functions. Journal of Applied Probability 41 , 425–436)], using properties of iterated random functions. We also discuss an extension to a varying coefficient model for first-order autoregressive transport models. In addition to simulations, the proposed models are illustrated with distributional time series of house prices across U.S. counties and annual summer temperature distributions.},
  archive      = {J_JRSSSB},
  author       = {Zhu, Changbo and Müller, Hans-Georg},
  doi          = {10.1093/jrsssb/qkad051},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {3},
  pages        = {1012-1033},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Autoregressive optimal transport models},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A kernel stein test for comparing latent variable models.
<em>JRSSSB</em>, <em>85</em>(3), 986–1011. (<a
href="https://doi.org/10.1093/jrsssb/qkad050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a kernel-based nonparametric test of relative goodness of fit, where the goal is to compare two models, both of which may have unobserved latent variables, such that the marginal distribution of the observed variables is intractable. The proposed test generalizes the recently proposed kernel Stein discrepancy (KSD) tests (Liu et al., Proceedings of the 33rd international conference on machine learning (pp. 276–284); Chwialkowski et al., (2016), In Proceedings of the 33rd international conference on machine learning (pp. 2606–2615); Yang et al., (2018), In Proceedings of the 35th international conference on machine learning (pp. 5561–5570)) to the case of latent variable models, a much more general class than the fully observed models treated previously. The new test, with a properly calibrated threshold, has a well-controlled type-I error. In the case of certain models with low-dimensional latent structures and high-dimensional observations, our test significantly outperforms the relative maximum mean discrepancy test, which is based on samples from the models and does not exploit the latent structure.},
  archive      = {J_JRSSSB},
  author       = {Kanagawa, Heishiro and Jitkrittum, Wittawat and Mackey, Lester and Fukumizu, Kenji and Gretton, Arthur},
  doi          = {10.1093/jrsssb/qkad050},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {3},
  pages        = {986-1011},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {A kernel stein test for comparing latent variable models},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Causal inference with invalid instruments: Post-selection
problems and a solution using searching and sampling. <em>JRSSSB</em>,
<em>85</em>(3), 959–985. (<a
href="https://doi.org/10.1093/jrsssb/qkad049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instrumental variable methods are among the most commonly used causal inference approaches to deal with unmeasured confounders in observational studies. The presence of invalid instruments is the primary concern for practical applications, and a fast-growing area of research is inference for the causal effect with possibly invalid instruments. This paper illustrates that the existing confidence intervals may undercover when the valid and invalid instruments are hard to separate in a data-dependent way. To address this, we construct uniformly valid confidence intervals that are robust to the mistakes in separating valid and invalid instruments. We propose to search for a range of treatment effect values that lead to sufficiently many valid instruments. We further devise a novel sampling method, which, together with searching, leads to a more precise confidence interval. Our proposed searching and sampling confidence intervals are uniformly valid and achieve the parametric length under the finite-sample majority and plurality rules. We apply our proposal to examine the effect of education on earnings. The proposed method is implemented in the R package R o b u s t I V available from CRAN.},
  archive      = {J_JRSSSB},
  author       = {Guo, Zijian},
  doi          = {10.1093/jrsssb/qkad049},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {3},
  pages        = {959-985},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Causal inference with invalid instruments: Post-selection problems and a solution using searching and sampling},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computationally efficient and data-adaptive changepoint
inference in high dimension. <em>JRSSSB</em>, <em>85</em>(3), 936–958.
(<a href="https://doi.org/10.1093/jrsssb/qkad048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional changepoint inference that adapts to various change patterns has received much attention recently. We propose a simple, fast yet effective approach for adaptive changepoint testing. The key observation is that two statistics based on aggregating cumulative sum statistics over all dimensions and possible changepoints by taking their maximum and summation, respectively, are asymptotically independent under some mild conditions. Hence, we are able to form a new test by combining the p -values of the maximum- and summation-type statistics according to their asymptotic null distributions. To this end, we develop new tools and techniques to establish the asymptotic distribution of the maximum-type statistic under a more relaxed condition on componentwise correlations among all variables than those in existing literature. The proposed method is simple to use. It is adaptive to different levels of the sparsity of change signals, and is comparable to or even outperforms existing approaches as revealed by our numerical studies.},
  archive      = {J_JRSSSB},
  author       = {Wang, Guanghui and Feng, Long},
  doi          = {10.1093/jrsssb/qkad048},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {3},
  pages        = {936-958},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Computationally efficient and data-adaptive changepoint inference in high dimension},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Non-parametric inference about mean functionals of
non-ignorable non-response data without identifying the joint
distribution. <em>JRSSSB</em>, <em>85</em>(3), 913–935. (<a
href="https://doi.org/10.1093/jrsssb/qkad047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider identification and inference about mean functionals of observed covariates and an outcome variable subject to non-ignorable missingness. By leveraging a shadow variable, we establish a necessary and sufficient condition for identification of the mean functional even if the full data distribution is not identified. We further characterize a necessary condition for n -estimability of the mean functional. This condition naturally strengthens the identifying condition, and it requires the existence of a function as a solution to a representer equation that connects the shadow variable to the mean functional. Solutions to the representer equation may not be unique, which presents substantial challenges for non-parametric estimation, and standard theories for non-parametric sieve estimators are not applicable here. We construct a consistent estimator of the solution set and then adapt the theory of extremum estimators to find from the estimated set a consistent estimator of an appropriately chosen solution. The estimator is asymptotically normal, locally efficient and attains the semi-parametric efficiency bound under certain regularity conditions. We illustrate the proposed approach via simulations and a real data application on home pricing.},
  archive      = {J_JRSSSB},
  author       = {Li, Wei and Miao, Wang and Tchetgen Tchetgen, Eric},
  doi          = {10.1093/jrsssb/qkad047},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {3},
  pages        = {913-935},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Non-parametric inference about mean functionals of non-ignorable non-response data without identifying the joint distribution},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A model where the least trimmed squares estimator is maximum
likelihood. <em>JRSSSB</em>, <em>85</em>(3), 886–912. (<a
href="https://doi.org/10.1093/jrsssb/qkad028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The least trimmed squares (LTS) estimator is a popular robust regression estimator. It finds a subsample of h ‘good’ observations among n observations and applies least squares on that subsample. We formulate a model in which this estimator is maximum likelihood. The model has ‘outliers’ of a new type, where the outlying observations are drawn from a distribution with values outside the realized range of h ‘good’, normal observations. The LTS estimator is found to be h 1 / 2 consistent and asymptotically standard normal in the location-scale case. Consistent estimation of h is discussed. The model differs from the commonly used ϵ -contamination models and opens the door for statistical discussion on contamination schemes, new methodological developments on tests for contamination as well as inferences based on the estimated good data.},
  archive      = {J_JRSSSB},
  author       = {Berenguer-Rico, Vanessa and Johansen, Søren and Nielsen, Bent},
  doi          = {10.1093/jrsssb/qkad028},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {3},
  pages        = {886-912},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {A model where the least trimmed squares estimator is maximum likelihood},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ordering factorial experiments. <em>JRSSSB</em>,
<em>85</em>(3), 869–885. (<a
href="https://doi.org/10.1093/jrsssb/qkad027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many practical experiments, both the level combinations of factors and the addition orders will affect the responses. However, virtually no construction methods have been provided for such experimental designs. This paper focuses on such experiments, introduces a new type of design called the ordering factorial design, and proposes the nominal main effect component-position model and interaction-main effect component-position model. To obtain efficient fractional designs, we provide some deterministic construction methods. The resulting designs are D -optimal, and the run sizes are much smaller than that of the full designs. Moreover, in some cases, some constructed designs are still D -optimal after reducing the number of components and factors.},
  archive      = {J_JRSSSB},
  author       = {Yang, Liuqing and Zhou, Yongdao and Liu, Min-Qian},
  doi          = {10.1093/jrsssb/qkad027},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {3},
  pages        = {869-885},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Ordering factorial experiments},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast and fair simultaneous confidence bands for functional
parameters. <em>JRSSSB</em>, <em>85</em>(3), 842–868. (<a
href="https://doi.org/10.1093/jrsssb/qkad026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantifying uncertainty using confidence regions is a central goal of statistical inference. Despite this, methodologies for confidence bands in functional data analysis are still underdeveloped compared to estimation and hypothesis testing. In this work, we present a new methodology for constructing simultaneous confidence bands for functional parameter estimates. Our bands possess a number of positive qualities: (1) they are not based on resampling and thus are fast to compute, (2) they are constructed under the fairness constraint of balanced false positive rates across partitions of the bands’ domain which facilitates the typical global, but also novel local interpretations, and (3) they do not require an estimate of the full covariance function and thus can be used in the case of fragmentary functional data. Simulations show the excellent finite-sample behaviour of our bands in comparison to existing alternatives. The practical use of our bands is demonstrated in two case studies on sports biomechanics and fragmentary growth curves.},
  archive      = {J_JRSSSB},
  author       = {Liebl, Dominik and Reimherr, Matthew},
  doi          = {10.1093/jrsssb/qkad026},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {3},
  pages        = {842-868},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Fast and fair simultaneous confidence bands for functional parameters},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The variational method of moments. <em>JRSSSB</em>,
<em>85</em>(3), 810–841. (<a
href="https://doi.org/10.1093/jrsssb/qkad025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conditional moment problem is a powerful formulation for describing structural causal parameters in terms of observables, a prominent example being instrumental variable regression. We introduce a very general class of estimators called the variational method of moments (VMM), motivated by a variational minimax reformulation of optimally weighted generalized method of moments for finite sets of moments. VMM controls infinitely for many moments characterized by flexible function classes such as neural nets and kernel methods, while provably maintaining statistical efficiency unlike existing related minimax estimators. We also develop inference algorithms and demonstrate the empirical strengths of VMM estimation and inference in experiments.},
  archive      = {J_JRSSSB},
  author       = {Bennett, Andrew and Kallus, Nathan},
  doi          = {10.1093/jrsssb/qkad025},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {3},
  pages        = {810-841},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {The variational method of moments},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sparse kronecker product decomposition: A general framework
of signal region detection in image regression. <em>JRSSSB</em>,
<em>85</em>(3), 783–809. (<a
href="https://doi.org/10.1093/jrsssb/qkad024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to present the first Frequentist framework on signal region detection in high-resolution and high-order image regression problems. Image data and scalar-on-image regression are intensively studied in recent years. However, most existing studies on such topics focussed on outcome prediction, while the research on region detection is rather limited, even though the latter is often more important. In this paper, we develop a general framework named Sparse Kronecker Product Decomposition (SKPD) to tackle this issue. The SKPD framework is general in the sense that it works for both matrices and tensors represented image data. Our framework includes one-term, multi-term, and nonlinear SKPDs. We propose nonconvex optimization problems for one-term and multi-term SKPDs and develop path-following algorithms for the nonconvex optimization. Under a Restricted Isometric Property, the computed solutions of the path-following algorithm are guaranteed to converge to the truth with a particularly chosen initialization even though the optimization is nonconvex. Moreover, the region detection consistency could also be guaranteed. The nonlinear SKPD is highly connected to shallow convolutional neural networks (CNN), particularly to CNN with one convolutional layer and one fully-connected layer. Effectiveness of SKPD is validated by real brain imaging data in the UK Biobank database.},
  archive      = {J_JRSSSB},
  author       = {Wu, Sanyou and Feng, Long},
  doi          = {10.1093/jrsssb/qkad024},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {3},
  pages        = {783-809},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Sparse kronecker product decomposition: A general framework of signal region detection in image regression},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Manifold lifting: Scaling markov chain monte carlo to the
vanishing noise regime. <em>JRSSSB</em>, <em>85</em>(3), 757–782. (<a
href="https://doi.org/10.1093/jrsssb/qkad023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Standard Markov chain Monte Carlo methods struggle to explore distributions that concentrate in the neighbourhood of low-dimensional submanifolds. This pathology naturally occurs in Bayesian inference settings when there is a high signal-to-noise ratio in the observational data but the model is inherently over-parametrised or nonidentifiable. In this paper, we propose a strategy that transforms the original sampling problem into the task of exploring a distribution supported on a manifold embedded in a higher-dimensional space; in contrast to the original posterior this lifted distribution remains diffuse in the limit of vanishing observation noise. We employ a constrained Hamiltonian Monte Carlo method, which exploits the geometry of this lifted distribution, to perform efficient approximate inference. We demonstrate in numerical experiments that, contrarily to competing approaches, the sampling efficiency of our proposed methodology does not degenerate as the target distribution to be explored concentrates near low-dimensional submanifolds. Python code reproducing the results is available at https://doi.org/10.5281/zenodo.6551654 .},
  archive      = {J_JRSSSB},
  author       = {Au, Khai Xiang and Graham, Matthew M and Thiery, Alexandre H},
  doi          = {10.1093/jrsssb/qkad023},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {3},
  pages        = {757-782},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Manifold lifting: Scaling markov chain monte carlo to the vanishing noise regime},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exact monte carlo likelihood-based inference for
jump-diffusion processes. <em>JRSSSB</em>, <em>85</em>(3), 732–756. (<a
href="https://doi.org/10.1093/jrsssb/qkad022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Statistical inference for discretely observed jump-diffusion processes is a complex problem which motivates new methodological challenges. Thus, existing approaches invariably resort to time-discretisations which inevitably lead to approximations in inference. In this paper, we give the first general collection of methodologies for exact (in this context meaning discretisation-free) likelihood-based inference for discretely observed finite activity jump-diffusions. The only sources of error involved are Monte Carlo error and convergence of expectation maximisation (EM) or Markov chain Monte Carlo (MCMC) algorithms. We shall introduce both frequentist and Bayesian approaches, illustrating the methodology through simulated and real examples.},
  archive      = {J_JRSSSB},
  author       = {Gonçalves, Flávio B and Łatuszyński, Krzysztof and Roberts, Gareth O},
  doi          = {10.1093/jrsssb/qkad022},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {3},
  pages        = {732-756},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Exact monte carlo likelihood-based inference for jump-diffusion processes},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Testing homogeneity: The trouble with sparse functional
data. <em>JRSSSB</em>, <em>85</em>(3), 705–731. (<a
href="https://doi.org/10.1093/jrsssb/qkad021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Testing the homogeneity between two samples of functional data is an important task. While this is feasible for intensely measured functional data, we explain why it is challenging for sparsely measured functional data and show what can be done for such data. In particular, we show that testing the marginal homogeneity based on point-wise distributions is feasible under some mild constraints and propose a new two-sample statistic that works well with both intensively and sparsely measured functional data. The proposed test statistic is formulated upon energy distance, and the convergence rate of the test statistic to its population version is derived along with the consistency of the associated permutation test. The aptness of our method is demonstrated on both synthetic and real data sets.},
  archive      = {J_JRSSSB},
  author       = {Zhu, Changbo and Wang, Jane-Ling},
  doi          = {10.1093/jrsssb/qkad021},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {3},
  pages        = {705-731},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Testing homogeneity: The trouble with sparse functional data},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Proximal causal inference for complex longitudinal studies.
<em>JRSSSB</em>, <em>85</em>(3), 684–704. (<a
href="https://doi.org/10.1093/jrsssb/qkad020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A standard assumption for causal inference about the joint effects of time-varying treatment is that one has measured sufficient covariates to ensure that within covariate strata, subjects are exchangeable across observed treatment values, also known as ‘sequential randomization assumption (SRA)’. SRA is often criticized as it requires one to accurately measure all confounders. Realistically, measured covariates can rarely capture all confounders with certainty. Often covariate measurements are at best proxies of confounders, thus invalidating inferences under SRA. In this paper, we extend the proximal causal inference (PCI) framework of Miao, Geng, et al. (2018. Identifying causal effects with proxy variables of an unmeasured confounder. Biometrika , 105 (4), 987–993. https://doi.org/10.1093/biomet/asy038 ) to the longitudinal setting under a semiparametric marginal structural mean model (MSMM). PCI offers an opportunity to learn about joint causal effects in settings where SRA based on measured time-varying covariates fails, by formally accounting for the covariate measurements as imperfect proxies of underlying confounding mechanisms. We establish nonparametric identification with a pair of time-varying proxies and provide a corresponding characterization of regular and asymptotically linear estimators of the parameter indexing the MSMM, including a rich class of doubly robust estimators, and establish the corresponding semiparametric efficiency bound for the MSMM. Extensive simulation studies and a data application illustrate the finite sample behaviour of proposed methods.},
  archive      = {J_JRSSSB},
  author       = {Ying, Andrew and Miao, Wang and Shi, Xu and Tchetgen Tchetgen, Eric J},
  doi          = {10.1093/jrsssb/qkad020},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {3},
  pages        = {684-704},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Proximal causal inference for complex longitudinal studies},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Permutation-based true discovery guarantee by sum tests.
<em>JRSSSB</em>, <em>85</em>(3), 664–683. (<a
href="https://doi.org/10.1093/jrsssb/qkad019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sum-based global tests are highly popular in multiple hypothesis testing. In this paper, we propose a general closed testing procedure for sum tests, which provides lower confidence bounds for the proportion of true discoveries (TDPs), simultaneously over all subsets of hypotheses. These simultaneous inferences come for free, i.e., without any adjustment of the α -level, whenever a global test is used. Our method allows for an exploratory approach, as simultaneity ensures control of the TDP even when the subset of interest is selected post hoc. It adapts to the unknown joint distribution of the data through permutation testing. Any sum test may be employed, depending on the desired power properties. We present an iterative shortcut for the closed testing procedure, based on the branch and bound algorithm, which converges to the full closed testing results, often after few iterations; even if it is stopped early, it controls the TDP. We compare the properties of different choices for the sum test through simulations, then we illustrate the feasibility of the method for high-dimensional data on brain imaging and genomics data.},
  archive      = {J_JRSSSB},
  author       = {Vesely, Anna and Finos, Livio and Goeman, Jelle J},
  doi          = {10.1093/jrsssb/qkad019},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {3},
  pages        = {664-683},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Permutation-based true discovery guarantee by sum tests},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Statistical testing under distributional shifts.
<em>JRSSSB</em>, <em>85</em>(3), 597–663. (<a
href="https://doi.org/10.1093/jrsssb/qkad018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce statistical testing under distributional shifts. We are interested in the hypothesis P * ∈ H 0 for a target distribution P * ⁠ , but observe data from a different distribution Q * ⁠ . We assume that P * is related to Q * through a known shift τ and formally introduce hypothesis testing in this setting. We propose a general testing procedure that first resamples from the observed data to construct an auxiliary data set (similarly to sampling importance resampling) and then applies an existing test in the target domain. We prove that if the size of the resample is of order o ( n ) and the resampling weights are well behaved, this procedure inherits the pointwise asymptotic level and power from the target test. If the map τ is estimated from data, we maintain the above guarantees under mild conditions on the estimation. Our results extend to finite sample level, uniform asymptotic level, a different resampling scheme, and statistical inference different from testing. Testing under distributional shifts allows us to tackle a diverse set of problems. We argue that it may prove useful in contextual bandit problems and covariate shift, show how it reduces conditional to unconditional independence testing and provide example applications in causal inference.},
  archive      = {J_JRSSSB},
  author       = {Thams, Nikolaj and Saengkyongam, Sorawit and Pfister, Niklas and Peters, Jonas},
  doi          = {10.1093/jrsssb/qkad018},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {3},
  pages        = {597-663},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Statistical testing under distributional shifts},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Elastic integrative analysis of randomised trial and
real-world data for treatment heterogeneity estimation. <em>JRSSSB</em>,
<em>85</em>(3), 575–596. (<a
href="https://doi.org/10.1093/jrsssb/qkad017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a test-based elastic integrative analysis of the randomised trial and real-world data to estimate treatment effect heterogeneity with a vector of known effect modifiers. When the real-world data are not subject to bias, our approach combines the trial and real-world data for efficient estimation. Utilising the trial design, we construct a test to decide whether or not to use real-world data. We characterise the asymptotic distribution of the test-based estimator under local alternatives. We provide a data-adaptive procedure to select the test threshold that promises the smallest mean square error and an elastic confidence interval with a good finite-sample coverage property.},
  archive      = {J_JRSSSB},
  author       = {Yang, Shu and Gao, Chenyin and Zeng, Donglin and Wang, Xiaofei},
  doi          = {10.1093/jrsssb/qkad017},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {3},
  pages        = {575-596},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Elastic integrative analysis of randomised trial and real-world data for treatment heterogeneity estimation},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bayesian likelihood-based regression for estimation of
optimal dynamic treatment regimes. <em>JRSSSB</em>, <em>85</em>(3),
551–574. (<a href="https://doi.org/10.1093/jrsssb/qkad016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinicians often make sequences of treatment decisions that can be framed as dynamic treatment regimes. In this paper, we propose a Bayesian likelihood-based dynamic treatment regime model that incorporates regression specifications to yield interpretable relationships between covariates and stage-wise outcomes. We define a set of probabilistically-coherent properties for dynamic treatment regime processes and present the theoretical advantages that are consequential to these properties. We justify the likelihood-based approach by showing that it guarantees these probabilistically-coherent properties, whereas existing methods lead to process spaces that typically violate these properties and lead to modelling assumptions that are infeasible. Through a numerical study, we show that our proposed method can achieve superior performance over existing state-of-the-art methods.},
  archive      = {J_JRSSSB},
  author       = {Yu, Weichang and Bondell, Howard D},
  doi          = {10.1093/jrsssb/qkad016},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {3},
  pages        = {551-574},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Bayesian likelihood-based regression for estimation of optimal dynamic treatment regimes},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Statistical inference for high-dimensional panel functional
time series. <em>JRSSSB</em>, <em>85</em>(2), 523–549. (<a
href="https://doi.org/10.1093/jrsssb/qkad015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop statistical inference tools for high-dimensional functional time series. We introduce a new concept of physical dependent processes in the space of square integrable functions, which adopts the idea of basis decomposition of functional data in these spaces, and derive Gaussian and multiplier bootstrap approximations for sums of high-dimensional functional time series. These results have numerous important statistical consequences. Exemplarily, we consider the development of joint simultaneous confidence bands for the mean functions and the construction of tests for the hypotheses that the mean functions in the panel dimension are parallel. The results are illustrated by means of a small simulation study and in the analysis of Canadian temperature data.},
  archive      = {J_JRSSSB},
  author       = {Zhou, Zhou and Dette, Holger},
  doi          = {10.1093/jrsssb/qkad015},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {2},
  pages        = {523-549},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Statistical inference for high-dimensional panel functional time series},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Monotone response surface of multi-factor condition:
Estimation and bayes classifiers. <em>JRSSSB</em>, <em>85</em>(2),
497–522. (<a href="https://doi.org/10.1093/jrsssb/qkad014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We formulate the estimation of monotone response surface of multiple factors as the inverse of an iteration of partially ordered classifier ensembles. Each ensemble (called product-of-independent-probability-escalation (PIPE)-classifiers) is a projection of Bayes classifiers on the constrained space. We prove that the inverse of PIPE-classifiers (iPIPE) exists, and propose algorithms to efficiently compute iPIPE by reducing the space over which optimisation is conducted. The methods are applied in analysis and simulation settings where the surface dimension is higher than what the isotonic regression literature typically considers. Simulation shows that iPIPE-based credible intervals achieve nominal coverage probability and are more precise compared to unconstrained estimation.},
  archive      = {J_JRSSSB},
  author       = {Cheung, Ying Kuen and Diaz, Keith M},
  doi          = {10.1093/jrsssb/qkad014},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {2},
  pages        = {497-522},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Monotone response surface of multi-factor condition: Estimation and bayes classifiers},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nonparametric estimation of the continuous treatment effect
with measurement error. <em>JRSSSB</em>, <em>85</em>(2), 474–496. (<a
href="https://doi.org/10.1093/jrsssb/qkad013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We identify the average dose–response function (ADRF) for a continuously valued error-contaminated treatment by a weighted conditional expectation. We then estimate the weights nonparametrically by maximising a local generalised empirical likelihood subject to an expanding set of conditional moment equations incorporated into the deconvolution kernels. Thereafter, we construct a deconvolution kernel estimator of ADRF. We derive the asymptotic bias and variance of our ADRF estimator and provide its asymptotic linear expansion, which helps conduct statistical inference. To select our smoothing parameters, we adopt the simulation-extrapolation method and propose a new extrapolation procedure to stabilise the computation. Monte Carlo simulations and a real data study illustrate our method’s practical performance.},
  archive      = {J_JRSSSB},
  author       = {Huang, Wei and Zhang, Zheng},
  doi          = {10.1093/jrsssb/qkad013},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {2},
  pages        = {474-496},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Nonparametric estimation of the continuous treatment effect with measurement error},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Model identification via total frobenius norm of
multivariate spectra. <em>JRSSSB</em>, <em>85</em>(2), 454–473. (<a
href="https://doi.org/10.1093/jrsssb/qkad012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the integral of the Frobenius norm as a measure of the discrepancy between two multivariate spectra. Such a measure can be used to fit time series models, and ensures proximity between model and process at all frequencies of the spectral density. We develop new asymptotic results for linear and quadratic functionals of the periodogram, and apply the integrated Frobenius norm to fit time series models and test whether model residuals are white noise. The case of structural time series models is addressed, wherein co-integration rank testing is formally developed. Both applications are studied through simulation studies and time series data. The numerical results show that the proposed estimator can fit moderate- to large-dimensional structural timeseries in real time.},
  archive      = {J_JRSSSB},
  author       = {McElroy, Tucker S and Roy, Anindya},
  doi          = {10.1093/jrsssb/qkad012},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {2},
  pages        = {454-473},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Model identification via total frobenius norm of multivariate spectra},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimating and improving dynamic treatment regimes with a
time-varying instrumental variable. <em>JRSSSB</em>, <em>85</em>(2),
427–453. (<a href="https://doi.org/10.1093/jrsssb/qkad011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating dynamic treatment regimes (DTRs) from retrospective observational data is challenging as some degree of unmeasured confounding is often expected. In this work, we develop a framework of estimating properly defined ‘optimal’ DTRs with a time-varying instrumental variable (IV) when unmeasured covariates confound the treatment and outcome, rendering the potential outcome distributions only partially identified. We derive a novel Bellman equation under partial identification, use it to define a generic class of estimands (termed IV-optimal DTRs ) and study the associated estimation problem. We then extend the IV-optimality framework to tackle the policy improvement problem, delivering IV-improved DTRs that are guaranteed to perform no worse and potentially better than a prespecified baseline DTR. Importantly, this IV-improvement framework opens up the possibility of strictly improving upon DTRs that are optimal under the no unmeasured confounding assumption (NUCA). We demonstrate via extensive simulations the superior performance of IV-optimal and IV-improved DTRs over the DTRs that are optimal only under the NUCA. In a real data example, we embed retrospective observational registry data into a natural, two-stage experiment with noncompliance using a differential-distance-based, time-varying IV and estimate useful IV-optimal DTRs that assign mothers to a high-level or low-level neonatal intensive care unit based on their prognostic variables.},
  archive      = {J_JRSSSB},
  author       = {Chen, Shuxiao and Zhang, Bo},
  doi          = {10.1093/jrsssb/qkad011},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {2},
  pages        = {427-453},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Estimating and improving dynamic treatment regimes with a time-varying instrumental variable},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bayesian pyramids: Identifiable multilayer discrete latent
structure models for discrete data. <em>JRSSSB</em>, <em>85</em>(2),
399–426. (<a href="https://doi.org/10.1093/jrsssb/qkad010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional categorical data are routinely collected in biomedical and social sciences. It is of great importance to build interpretable parsimonious models that perform dimension reduction and uncover meaningful latent structures from such discrete data. Identifiability is a fundamental requirement for valid modeling and inference in such scenarios, yet is challenging to address when there are complex latent structures. In this article, we propose a class of identifiable multilayer (potentially deep) discrete latent structure models for discrete data, termed Bayesian Pyramids . We establish the identifiability of Bayesian Pyramids by developing novel transparent conditions on the pyramid-shaped deep latent directed graph. The proposed identifiability conditions can ensure Bayesian posterior consistency under suitable priors. As an illustration, we consider the two-latent-layer model and propose a Bayesian shrinkage estimation approach. Simulation results for this model corroborate the identifiability and estimatability of model parameters. Applications of the methodology to DNA nucleotide sequence data uncover useful discrete latent features that are highly predictive of sequence types. The proposed framework provides a recipe for interpretable unsupervised learning of discrete data and can be a useful alternative to popular machine learning methods.},
  archive      = {J_JRSSSB},
  author       = {Gu, Yuqi and Dunson, David B},
  doi          = {10.1093/jrsssb/qkad010},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {2},
  pages        = {399-426},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Bayesian pyramids: Identifiable multilayer discrete latent structure models for discrete data},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Causal inference on distribution functions. <em>JRSSSB</em>,
<em>85</em>(2), 378–398. (<a
href="https://doi.org/10.1093/jrsssb/qkad008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding causal relationships is one of the most important goals of modern science. So far, the causal inference literature has focused almost exclusively on outcomes coming from the Euclidean space R p ⁠ . However, it is increasingly common that complex datasets are best summarized as data points in nonlinear spaces. In this paper, we present a novel framework of causal effects for outcomes from the Wasserstein space of cumulative distribution functions, which in contrast to the Euclidean space, is nonlinear. We develop doubly robust estimators and associated asymptotic theory for these causal effects. As an illustration, we use our framework to quantify the causal effect of marriage on physical activity patterns using wearable device data collected through the National Health and Nutrition Examination Survey.},
  archive      = {J_JRSSSB},
  author       = {Lin, Zhenhua and Kong, Dehan and Wang, Linbo},
  doi          = {10.1093/jrsssb/qkad008},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {2},
  pages        = {378-398},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Causal inference on distribution functions},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimating the efficiency gain of covariate-adjusted
analyses in future clinical trials using external data. <em>JRSSSB</em>,
<em>85</em>(2), 356–377. (<a
href="https://doi.org/10.1093/jrsssb/qkad007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a framework for using existing external data to identify and estimate the relative efficiency of a covariate-adjusted estimator compared to an unadjusted estimator in a future randomized trial. Under conditions, these relative efficiencies approximate the ratio of sample sizes needed to achieve a desired power. We develop semiparametrically efficient estimators of the relative efficiencies for several treatment effect estimands of interest with either fully or partially observed outcomes, allowing for the application of flexible statistical learning tools to estimate the nuisance functions. We propose an analytic Wald-type confidence interval and a double bootstrap scheme for statistical inference. We demonstrate the performance of the proposed methods through simulation studies and apply these methods to estimate the efficiency gain of covariate adjustment in Covid-19 therapeutic trials.},
  archive      = {J_JRSSSB},
  author       = {Li, Xiudi and Li, Sijia and Luedtke, Alex},
  doi          = {10.1093/jrsssb/qkad007},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {2},
  pages        = {356-377},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Estimating the efficiency gain of covariate-adjusted analyses in future clinical trials using external data},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Debiased and thresholded ridge regression for linear models
with heteroskedastic and correlated errors. <em>JRSSSB</em>,
<em>85</em>(2), 327–355. (<a
href="https://doi.org/10.1093/jrsssb/qkad006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional linear models with independent errors have been well-studied. However, statistical inference on a high-dimensional linear model with heteroskedastic, dependent (and possibly nonstationary) errors is still a novel topic. Under such complex assumptions, the paper at hand introduces a debiased and thresholded ridge regression estimator that is consistent, and is able to recover the model sparsity. Moreover, we derive a Gaussian approximation theorem for the estimator, and apply a dependent wild bootstrap algorithm to construct simultaneous confidence interval and hypothesis tests for linear combinations of parameters. Numerical experiments with both real and simulated data show that the proposed estimator has good finite sample performance. Of independent interest is the development of a new class of heteroscedastic, (weakly) dependent, and nonstationary random variables that can be used as a general model for regression errors.},
  archive      = {J_JRSSSB},
  author       = {Zhang, Yunyi and Politis, Dimitris N},
  doi          = {10.1093/jrsssb/qkad006},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {2},
  pages        = {327-355},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Debiased and thresholded ridge regression for linear models with heteroskedastic and correlated errors},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Designing to detect heteroscedasticity in a regression
model. <em>JRSSSB</em>, <em>85</em>(2), 315–326. (<a
href="https://doi.org/10.1093/jrsssb/qkad004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of designing experiments to detect the presence of a specified heteroscedastity in Gaussian regression models. We study the relationship of the D s - and KL-criteria with the noncentrality parameter of the asymptotic chi-squared distribution of a likelihood-based test, for local alternatives. We found that, when the heteroscedastity depends on one parameter, the two criteria coincide asymptotically and that the D 1 -criterion is proportional to the noncentrality parameter. Differently, when it depends on several parameters, the KL-optimum design converges to the design that maximizes the noncentrality parameter. Our theoretical findings are confirmed through a simulation study.},
  archive      = {J_JRSSSB},
  author       = {Lanteri, Alessandro and Leorato, Samantha and López-Fidalgo, Jesús and Tommasi, Chiara},
  doi          = {10.1093/jrsssb/qkad004},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {2},
  pages        = {315-326},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Designing to detect heteroscedasticity in a regression model},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A quantitative heppes theorem and multivariate bernoulli
distributions. <em>JRSSSB</em>, <em>85</em>(2), 293–314. (<a
href="https://doi.org/10.1093/jrsssb/qkad003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using some extensions of a theorem of Heppes on finitely supported discrete probability measures, we address the problems of classification and testing based on projections. In particular, when the support of the distributions is known in advance (as for instance for multivariate Bernoulli distributions), a single suitably chosen projection determines the distribution. Several applications of these results are considered.},
  archive      = {J_JRSSSB},
  author       = {Fraiman, Ricardo and Moreno, Leonardo and Ransford, Thomas},
  doi          = {10.1093/jrsssb/qkad003},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {2},
  pages        = {293-314},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {A quantitative heppes theorem and multivariate bernoulli distributions},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identifying the latent space geometry of network models
through analysis of curvature. <em>JRSSSB</em>, <em>85</em>(2), 240–292.
(<a href="https://doi.org/10.1093/jrsssb/qkad002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A common approach to modelling networks assigns each node to a position on a low-dimensional manifold where distance is inversely proportional to connection likelihood. More positive manifold curvature encourages more and tighter communities; negative curvature induces repulsion. We consistently estimate manifold type, dimension, and curvature from simply connected, complete Riemannian manifolds of constant curvature. We represent the graph as a noisy distance matrix based on the ties between cliques, then develop hypothesis tests to determine whether the observed distances could plausibly be embedded isometrically in each of the candidate geometries. We apply our approach to datasets from economics and neuroscience.},
  archive      = {J_JRSSSB},
  author       = {Lubold, Shane and Chandrasekhar, Arun G and McCormick, Tyler H},
  doi          = {10.1093/jrsssb/qkad002},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {2},
  pages        = {240-292},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Identifying the latent space geometry of network models through analysis of curvature},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A nested error regression model with high-dimensional
parameter for small area estimation. <em>JRSSSB</em>, <em>85</em>(2),
212–239. (<a href="https://doi.org/10.1093/jrsssb/qkac010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a flexible nested error regression small area model with high-dimensional parameter that incorporates heterogeneity in regression coefficients and variance components. We develop a new robust small area-specific estimating equations method that allows appropriate pooling of a large number of areas in estimating small area-specific model parameters. We propose a parametric bootstrap and jackknife method to estimate not only the mean squared errors but also other commonly used uncertainty measures such as standard errors and coefficients of variation. We conduct both model-based and design-based simulation experiments and real-life data analysis to evaluate the proposed methodology.},
  archive      = {J_JRSSSB},
  author       = {Lahiri, Partha and Salvati, Nicola},
  doi          = {10.1093/jrsssb/qkac010},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {2},
  pages        = {212-239},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {A nested error regression model with high-dimensional parameter for small area estimation},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimating heterogeneous treatment effects with
right-censored data via causal survival forests. <em>JRSSSB</em>,
<em>85</em>(2), 179–211. (<a
href="https://doi.org/10.1093/jrsssb/qkac001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forest-based methods have recently gained in popularity for non-parametric treatment effect estimation. Building on this line of work, we introduce causal survival forests, which can be used to estimate heterogeneous treatment effects in survival and observational setting where outcomes may be right-censored. Our approach relies on orthogonal estimating equations to robustly adjust for both censoring and selection effects under unconfoundedness. In our experiments, we find our approach to perform well relative to a number of baselines.},
  archive      = {J_JRSSSB},
  author       = {Cui, Yifan and Kosorok, Michael R and Sverdrup, Erik and Wager, Stefan and Zhu, Ruoqing},
  doi          = {10.1093/jrsssb/qkac001},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {2},
  pages        = {179-211},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Estimating heterogeneous treatment effects with right-censored data via causal survival forests},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Erratum: Usable and precise asymptotics for generalized
linear mixed model analysis and design. <em>JRSSSB</em>, <em>85</em>(1),
177. (<a href="https://doi.org/10.1093/jrsssb/qkac002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  doi          = {10.1093/jrsssb/qkac002},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {1},
  pages        = {177},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Erratum: Usable and precise asymptotics for generalized linear mixed model analysis and design},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Corrigendum: Exact bayesian inference in spatiotemporal cox
processes driven by multivariate gaussian processes. <em>JRSSSB</em>,
<em>85</em>(1), 176. (<a
href="https://doi.org/10.1093/jrsssb/qkac008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Gonçalves, Flávio B and Gamerman, Dani},
  doi          = {10.1093/jrsssb/qkac008},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {1},
  pages        = {176},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Corrigendum: Exact bayesian inference in spatiotemporal cox processes driven by multivariate gaussian processes},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On inference in high-dimensional regression.
<em>JRSSSB</em>, <em>85</em>(1), 149–175. (<a
href="https://doi.org/10.1093/jrsssb/qkad001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops an approach to inference in a linear regression model when the number of potential explanatory variables is larger than the sample size. The approach treats each regression coefficient in turn as the interest parameter, the remaining coefficients being nuisance parameters, and seeks an optimal interest-respecting transformation, inducing sparsity on the relevant blocks of the notional Fisher information matrix. The induced sparsity is exploited through a marginal least-squares analysis for each variable, as in a factorial experiment, thereby avoiding penalization. One parameterization of the problem is found to be particularly convenient, both computationally and mathematically. In particular, it permits an analytic solution to the optimal transformation problem, facilitating theoretical analysis and comparison to other work. In contrast to regularized regression, such as the lasso and its extensions, neither adjustment for selection nor rescaling of the explanatory variables is needed, ensuring the physical interpretation of regression coefficients is retained. Recommended usage is within a broader set of inferential statements, so as to reflect uncertainty over the model as well as over the parameters. The considerations involved in extending the work to other regression models are briefly discussed.},
  archive      = {J_JRSSSB},
  author       = {Battey, Heather S and Reid, Nancy},
  doi          = {10.1093/jrsssb/qkad001},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {1},
  pages        = {149-175},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {On inference in high-dimensional regression},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modelling matrix time series via a tensor CP-decomposition.
<em>JRSSSB</em>, <em>85</em>(1), 127–148. (<a
href="https://doi.org/10.1093/jrsssb/qkac011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider to model matrix time series based on a tensor canonical polyadic (CP)-decomposition. Instead of using an iterative algorithm which is the standard practice for estimating CP-decompositions, we propose a new and one-pass estimation procedure based on a generalized eigenanalysis constructed from the serial dependence structure of the underlying process. To overcome the intricacy of solving a rank-reduced generalized eigenequation, we propose a further refined approach which projects it into a lower-dimensional full-ranked eigenequation. This refined method can significantly improve the finite-sample performance. We show that all the component coefficient vectors in the CP-decomposition can be estimated consistently. The proposed model and the estimation method are also illustrated with both simulated and real data, showing effective dimension-reduction in modelling and forecasting matrix time series.},
  archive      = {J_JRSSSB},
  author       = {Chang, Jinyuan and He, Jing and Yang, Lin and Yao, Qiwei},
  doi          = {10.1093/jrsssb/qkac011},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {1},
  pages        = {127-148},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Modelling matrix time series via a tensor CP-decomposition},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Informative core identification in complex networks.
<em>JRSSSB</em>, <em>85</em>(1), 108–126. (<a
href="https://doi.org/10.1093/jrsssb/qkac009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a complex network, the core component with interesting structures is usually hidden within noninformative connections. The noises and bias introduced by the noninformative component can obscure the salient structure and limit many network modeling procedures’ effectiveness. This paper introduces a novel core–periphery model for the noninformative periphery structure of networks without imposing a specific form of the core. We propose spectral algorithms for core identification for general downstream network analysis tasks under the model. The algorithms enjoy strong performance guarantees and are scalable for large networks. We evaluate the methods by extensive simulation studies demonstrating advantages over multiple traditional core–periphery methods. The methods are also used to extract the core structure from a citation network, which results in a more interpretable hierarchical community detection.},
  archive      = {J_JRSSSB},
  author       = {Miao, Ruizhong and Li, Tianxi},
  doi          = {10.1093/jrsssb/qkac009},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {1},
  pages        = {108-126},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Informative core identification in complex networks},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bayesian fusion: Scalable unification of distributed
statistical analyses. <em>JRSSSB</em>, <em>85</em>(1), 84–107. (<a
href="https://doi.org/10.1093/jrsssb/qkac007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been considerable interest in addressing the problem of unifying distributed analyses into a single coherent inference, which arises in big-data settings, when working under privacy constraints, and in Bayesian model choice. Most existing approaches relied upon approximations of the distributed analyses, which have significant shortcomings—the quality of the inference can degrade rapidly with the number of analyses being unified, and can be substantially biased when unifying analyses that do not concur. In contrast, recent Monte Carlo fusion approach is exact and based on rejection sampling. In this paper, we introduce a practical Bayesian fusion approach by embedding the Monte Carlo fusion framework within a sequential Monte Carlo algorithm. We demonstrate theoretically and empirically that Bayesian fusion is more robust than existing methods.},
  archive      = {J_JRSSSB},
  author       = {Dai, Hongsheng and Pollock, Murray and Roberts, Gareth O},
  doi          = {10.1093/jrsssb/qkac007},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {1},
  pages        = {84-107},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Bayesian fusion: Scalable unification of distributed statistical analyses},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Biased-sample empirical likelihood weighting for missing
data problems: An alternative to inverse probability weighting.
<em>JRSSSB</em>, <em>85</em>(1), 67–83. (<a
href="https://doi.org/10.1093/jrsssb/qkac006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverse probability weighting (IPW) is widely used in many areas when data are subject to unrepresentativeness, missingness, or selection bias. An inevitable challenge with the use of IPW is that the IPW estimator can be remarkably unstable if some probabilities are very close to zero. To overcome this problem, at least three remedies have been developed in the literature: stabilizing, thresholding, and trimming. However, the final estimators are still IPW-type estimators, and inevitably inherit certain weaknesses of the naive IPW estimator: they may still be unstable or biased. We propose a biased-sample empirical likelihood weighting (ELW) method to serve the same general purpose as IPW, while completely overcoming the instability of IPW-type estimators by circumventing the use of inverse probabilities. The ELW weights are always well defined and easy to implement. We show theoretically that the ELW estimator is asymptotically normal and more efficient than the IPW estimator and its stabilized version for missing data problems. Our simulation results and a real data analysis indicate that the ELW estimator is shift-equivariant, nearly unbiased, and usually outperforms the IPW-type estimators in terms of mean square error.},
  archive      = {J_JRSSSB},
  author       = {Liu, Yukun and Fan, Yan},
  doi          = {10.1093/jrsssb/qkac006},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {1},
  pages        = {67-83},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Biased-sample empirical likelihood weighting for missing data problems: An alternative to inverse probability weighting},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Trace-class gaussian priors for bayesian learning of neural
networks with MCMC. <em>JRSSSB</em>, <em>85</em>(1), 46–66. (<a
href="https://doi.org/10.1093/jrsssb/qkac005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new neural network based prior for real valued functions. Each weight and bias of the neural network has an independent Gaussian prior, with the key novelty that the variances decrease in the width of the network in such a way that the resulting function is well defined in the limit of an infinite width network. We show that the induced posterior over functions is amenable to Monte Carlo sampling using Hilbert space Markov chain Monte Carlo (MCMC) methods. This type of MCMC is stable under mesh refinement , i.e. the acceptance probability does not degenerate as more parameters of the function&#39;s prior are introduced, even ad infinitum . We demonstrate these advantages over other function space priors, for example in Bayesian Reinforcement Learning.},
  archive      = {J_JRSSSB},
  author       = {Sell, Torben and Singh, Sumeetpal Sidhu},
  doi          = {10.1093/jrsssb/qkac005},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {1},
  pages        = {46-66},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Trace-class gaussian priors for bayesian learning of neural networks with MCMC},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Conformalized survival analysis. <em>JRSSSB</em>,
<em>85</em>(1), 24–45. (<a
href="https://doi.org/10.1093/jrsssb/qkac004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop an inferential method based on conformal prediction, which can wrap around any survival prediction algorithm to produce calibrated, covariate-dependent lower predictive bounds on survival times. In the Type I right-censoring setting, when the censoring times are completely exogenous, the lower predictive bounds have guaranteed coverage in finite samples without any assumptions other than that of operating on independent and identically distributed data points. Under a more general conditionally independent censoring assumption, the bounds satisfy a doubly robust property which states the following: marginal coverage is approximately guaranteed if either the censoring mechanism or the conditional survival function is estimated well. The validity and efficiency of our procedure are demonstrated on synthetic data and real COVID-19 data from the UK Biobank.},
  archive      = {J_JRSSSB},
  author       = {Candès, Emmanuel and Lei, Lihua and Ren, Zhimei},
  doi          = {10.1093/jrsssb/qkac004},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {1},
  pages        = {24-45},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Conformalized survival analysis},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Covariate adjustment in multiarmed, possibly factorial
experiments. <em>JRSSSB</em>, <em>85</em>(1), 1–23. (<a
href="https://doi.org/10.1093/jrsssb/qkac003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Randomized experiments are the gold standard for causal inference and enable unbiased estimation of treatment effects. Regression adjustment provides a convenient way to incorporate covariate information for additional efficiency. This article provides a unified account of its utility for improving estimation efficiency in multiarmed experiments. We start with the commonly used additive and fully interacted models for regression adjustment in estimating average treatment effects (ATE), and clarify the trade-offs between the resulting ordinary least squares (OLS) estimators in terms of finite sample performance and asymptotic efficiency. We then move on to regression adjustment based on restricted least squares (RLS), and establish for the first time its properties for inferring ATE from the design-based perspective. The resulting inference has multiple guarantees. First, it is asymptotically efficient when the restriction is correctly specified. Second, it remains consistent as long as the restriction on the coefficients of the treatment indicators, if any, is correctly specified and separate from that on the coefficients of the treatment-covariate interactions. Third, it can have better finite sample performance than the unrestricted counterpart even when the restriction is moderately misspecified. It is thus our recommendation when the OLS fit of the fully interacted regression risks large finite sample variability in case of many covariates, many treatments, yet a moderate sample size. In addition, the newly established theory of RLS also provides a unified way of studying OLS-based inference from general regression specifications. As an illustration, we demonstrate its value for studying OLS-based regression adjustment in factorial experiments. Importantly, although we analyse inferential procedures that are motivated by OLS, we do not invoke any assumptions required by the underlying linear models.},
  archive      = {J_JRSSSB},
  author       = {Zhao, Anqi and Ding, Peng},
  doi          = {10.1093/jrsssb/qkac003},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  number       = {1},
  pages        = {1-23},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Covariate adjustment in multiarmed, possibly factorial experiments},
  volume       = {85},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
