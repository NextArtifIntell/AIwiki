<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJOO_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijoo---17">IJOO - 17</h2>
<ul>
<li><details>
<summary>
(2023). Data-driven distributionally robust optimization over time.
<em>IJOO</em>, <em>5</em>(4), 376–394. (<a
href="https://doi.org/10.1287/ijoo.2023.0091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic optimization (SO) is a classical approach for optimization under uncertainty that typically requires knowledge about the probability distribution of uncertain parameters. Because the latter is often unknown, distributionally robust optimization (DRO) provides a strong alternative that determines the best guaranteed solution over a set of distributions (ambiguity set). In this work, we present an approach for DRO over time that uses online learning and scenario observations arriving as a data stream to learn more about the uncertainty. Our robust solutions adapt over time and reduce the cost of protection with shrinking ambiguity. For various kinds of ambiguity sets, the robust solutions converge to the SO solution. Our algorithm achieves the optimization and learning goals without solving the DRO problem exactly at any step. We also provide a regret bound for the quality of the online strategy that converges at a rate of O ( log T / T ) , where T is the number of iterations. Furthermore, we illustrate the effectiveness of our procedure by numerical experiments on mixed-integer optimization instances from popular benchmark libraries and give practical examples stemming from telecommunications and routing. Our algorithm is able to solve the DRO over time problem significantly faster than standard reformulations. Funding: This work was supported by Deutsche Forschungsgemeinschaft (DFG): Projects B06 and B10 in CRC TRR 154 and Project-ID 416229255 - SFB 1411 and Federal Ministry for Economic Affairs and Energy, Germany [Grant 03EI1036A]. Supplemental Material: The e-companion is available at https://doi.org/10.1287/ijoo.2023.0091 .},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2023.0091},
  journal      = {INFORMS Journal on Optimization},
  number       = {4},
  pages        = {376-394},
  shortjournal = {INFORMS J. Optim.},
  title        = {Data-driven distributionally robust optimization over time},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Geometric analysis of noisy low-rank matrix recovery in the
exact parametrized and the overparametrized regimes. <em>IJOO</em>,
<em>5</em>(4), 356–375. (<a
href="https://doi.org/10.1287/ijoo.2023.0090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The matrix sensing problem is an important low-rank optimization problem that has found a wide range of applications, such as matrix completion, phase synchornization/retrieval, robust principal component analysis (PCA), and power system state estimation. In this work, we focus on the general matrix sensing problem with linear measurements that are corrupted by random noise. We investigate the scenario where the search rank r is equal to the true rank r * of the unknown ground truth (the exact parametrized case), as well as the scenario where r is greater than r * (the overparametrized case). We quantify the role of the restricted isometry property (RIP) in shaping the landscape of the nonconvex factorized formulation and assisting with the success of local search algorithms. First, we develop a global guarantee on the maximum distance between an arbitrary local minimizer of the nonconvex problem and the ground truth under the assumption that the RIP constant is smaller than 1 / ( 1 + r * / r ) . We then present a local guarantee for problems with an arbitrary RIP constant, which states that any local minimizer is either considerably close to the ground truth or far away from it. More importantly, we prove that this noisy, overparametrized problem exhibits the strict saddle property, which leads to the global convergence of perturbed gradient descent algorithm in polynomial time. The results of this work provide a comprehensive understanding of the geometric landscape of the matrix sensing problem in the noisy and overparametrized regime. Funding: This work was supported by grants from the National Science Foundation, Office of Naval Research, Air Force Office of Scientific Research, and Army Research Office.},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2023.0090},
  journal      = {INFORMS Journal on Optimization},
  number       = {4},
  pages        = {356-375},
  shortjournal = {INFORMS J. Optim.},
  title        = {Geometric analysis of noisy low-rank matrix recovery in the exact parametrized and the overparametrized regimes},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Local optimality conditions for a family of hidden convex
optimization. <em>IJOO</em>, <em>5</em>(4), 340–355. (<a
href="https://doi.org/10.1287/ijoo.2023.0089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hidden convex optimization is a class of nonconvex optimization problems that can be globally solved in polynomial time via equivalent convex programming reformulations. In this paper, we study a family of hidden convex optimization that joints the classical trust region subproblem (TRS) with convex optimization (CO). It also includes p -regularized subproblem ( p &gt; 2) as a special case. We present a comprehensive study on local optimality conditions. In particular, a sufficient condition is given to ensure that there is at most one local nonglobal minimizer, and at this point, the standard second-order sufficient optimality condition is necessary. To our surprise, although (TRS) has at most one local nonglobal minimizer and (CO) has no local nonglobal minimizer, their joint problem could have any finite number of local nonglobal minimizers. Funding: This work was supported by the National Natural Science Foundation of China [Grants 12171021, 12131004, and 11822103], the Beijing Natural Science Foundation [Grant Z180005], and the Fundamental Research Funds for the Central Universities. Supplemental Material: The online appendix is available at https://doi.org/10.1287/ijoo.2023.0089 .},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2023.0089},
  journal      = {INFORMS Journal on Optimization},
  number       = {4},
  pages        = {340-355},
  shortjournal = {INFORMS J. Optim.},
  title        = {Local optimality conditions for a family of hidden convex optimization},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Algorithms for difference-of-convex programs based on
difference-of-moreau-envelopes smoothing. <em>IJOO</em>, <em>5</em>(4),
321–339. (<a href="https://doi.org/10.1287/ijoo.2022.0087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider minimization of a difference-of-convex (DC) function with and without linear equality constraints. We first study a smooth approximation of a generic DC function, termed difference-of-Moreau-envelopes (DME) smoothing, where both components of the DC function are replaced by their respective Moreau envelopes. The resulting smooth approximation is shown to be Lipschitz differentiable, capture stationary points, local, and global minima of the original DC function, and enjoy some growth conditions, such as level-boundedness and coercivity, for broad classes of DC functions. For a smoothed DC program without linear constraints, it is shown that the classic gradient descent method and an inexact variant converge to a stationary solution of the original DC function in the limit with a rate of O ( K − 1 / 2 ) , where K is the number of proximal evaluations of both components. Furthermore, when the DC program is explicitly constrained in an affine subspace, we combine the smoothing technique with the augmented Lagrangian function and derive two variants of the augmented Lagrangian method (ALM), named linearly constrained DC (LCDC)-ALM and composite LCDC-ALM, targeting on different structures of the DC objective function. We show that both algorithms find an ϵ-approximate stationary solution of the original DC program in O ( ϵ − 2 ) iterations. Comparing to existing methods designed for linearly constrained weakly convex minimization, the proposed ALM-based algorithms can be applied to a broader class of problems, where the objective contains a nonsmooth concave component. Finally, numerical experiments are presented to demonstrate the performance of the proposed algorithms. Funding: This work was partially supported by the NSF [Grant ECCS1751747]. Supplemental Material: The e-companion is available at https://doi.org/10.1287/ijoo.2022.0087 .},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2022.0087},
  journal      = {INFORMS Journal on Optimization},
  number       = {4},
  pages        = {321-339},
  shortjournal = {INFORMS J. Optim.},
  title        = {Algorithms for difference-of-convex programs based on difference-of-moreau-envelopes smoothing},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Smart predict-then-optimize for two-stage linear programs
with side information. <em>IJOO</em>, <em>5</em>(3), 295–320. (<a
href="https://doi.org/10.1287/ijoo.2023.0088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study two-stage linear programs with uncertainty in the right-hand side in which the uncertain parameters of the problem are correlated with a variable called the side information, which is observed before an action is made. We propose an approach in which a linear regression model is used to provide a point prediction for the uncertain parameters of the problem. We use an approach called smart predict-then-optimize . Rather than minimizing a typical loss function for regression, such as squared error, we approximately minimize the objective value of the resulting solutions to the optimization problem. We conduct computational tests that compare our method with other approaches for optimization problems with side information. The results indicate that our method can provide better objective values in situations where the true model is reasonably close to a linear model. Although the procedure we propose requires a longer time for fitting than existing methods, it requires less time to produce a decision for each given observation of the side information. Supplemental Material: The e-companion is available at https://doi.org/10.1287/ijoo.2023.0088 .},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2023.0088},
  journal      = {INFORMS Journal on Optimization},
  number       = {3},
  pages        = {295-320},
  shortjournal = {INFORMS J. Optim.},
  title        = {Smart predict-then-optimize for two-stage linear programs with side information},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning for commodity procurement: Nonlinear
data-driven optimization of hedging decisions. <em>IJOO</em>,
<em>5</em>(3), 273–294. (<a
href="https://doi.org/10.1287/ijoo.2022.0086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the number of exchange-traded commodity contracts and their volatility increase, risk management through financial hedging gains importance for commodity-purchasing firms. Existing data-driven optimization approaches for hedging decisions include linear regression-based techniques. As such, they assume linear price–feature relationships and, thus, do not automatically detect nonlinear feature effects. We propose an alternative, nonlinear data-driven approach to commodity procurement based on deep learning. The prescriptive algorithm uses artificial neural networks to allow for universal approximation and requires no a priori knowledge regarding underlying price processes. We reformulate the periodic review procurement problem as a multilabel time series classification problem as the optimal bang-bang type procurement policy allows us to treat the hedging decision for each demand period as an individual subproblem that is independent of the other periods. Thereby, we are differentiating between optimal and suboptimal hedging decisions in each period and introduce a novel opportunity cost–sensitive loss function. We train maximum likelihood classifiers based on different deep learning architectures and test their performance in numerical experiments and case studies for natural gas, crude oil, nickel, and copper procurement. We show comparable performance to the state of the art for linear price–feature relationships and considerable advantages in the nonlinear case. Funding: Financial support received through the DFG as part of the AdONE GRK2201 [Grant 277991500] is gratefully acknowledged.},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2022.0086},
  journal      = {INFORMS Journal on Optimization},
  number       = {3},
  pages        = {273-294},
  shortjournal = {INFORMS J. Optim.},
  title        = {Deep learning for commodity procurement: Nonlinear data-driven optimization of hedging decisions},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stochastic zeroth-order functional constrained optimization:
Oracle complexity and applications. <em>IJOO</em>, <em>5</em>(3),
256–272. (<a href="https://doi.org/10.1287/ijoo.2022.0085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functionally constrained stochastic optimization problems, where neither the objective function nor the constraint functions are analytically available, arise frequently in machine learning applications. In this work, assuming we only have access to the noisy evaluations of the objective and constraint functions, we propose and analyze stochastic zeroth-order algorithms for solving this class of stochastic optimization problem. When the domain of the functions is R n , assuming there are m constraint functions, we establish oracle complexities of order O ( ( m + 1 ) n / ϵ 2 ) and O ( ( m + 1 ) n / ϵ 3 ) in the convex and nonconvex settings, respectively, where ϵ represents the accuracy of the solutions required in appropriately defined metrics. The established oracle complexities are, to our knowledge, the first such results in the literature for functionally constrained stochastic zeroth-order optimization problems. We demonstrate the applicability of our algorithms by illustrating their superior performance on the problem of hyperparameter tuning for sampling algorithms and neural network training. Funding: K. Balasubramanian was partially supported by a seed grant from the Center for Data Science and Artificial Intelligence Research, University of California–Davis, and the National Science Foundation [Grant DMS-2053918].},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2022.0085},
  journal      = {INFORMS Journal on Optimization},
  number       = {3},
  pages        = {256-272},
  shortjournal = {INFORMS J. Optim.},
  title        = {Stochastic zeroth-order functional constrained optimization: Oracle complexity and applications},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A bisection protocol for political redistricting.
<em>IJOO</em>, <em>5</em>(3), 233–255. (<a
href="https://doi.org/10.1287/ijoo.2022.0084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Political redistricting in the United States is the process of drawing congressional and state legislative district boundaries. This work introduces the bisection protocol , a two-player, zero-sum, extensive-form game motivated by political redistricting in which two players alternately divide pieces of a region in half (up to rounding) to obtain a district plan. A subgame perfect Nash equilibrium is presented for the protocol in a relaxed continuous nongeometric setting, and a recurrence is given for the optimal strategies. The bisection protocol is compared with the recently proposed I-cut-you-freeze protocol across a variety of standard fairness metrics. A hardness result is presented for the bisection protocol in the more realistic discrete geometric setting along with exact equilibrium strategies for small grid graphs. Because equilibrium computation is intractable for practical instances, heuristics are developed for both protocols that model players’ drawing strategies as mixed-integer linear programs. When the heuristics are applied to congressional redistricting in Iowa with counties preserved, both protocols produce district plans that are fairer (according to three popular metrics) than Iowa’s 115th congressional districts. Finally, the bisection heuristic is used to generate congressional district plans from census tracts for 18 states, demonstrating its potential for practical use. Funding: This work was supported by National Science Foundation Graduate Research Fellowship Program [Grant DGE-1746047] and the fourth author is supported in part by the Air Force Office of Scientific Research [Grant FA9550-19-1-0106]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/ijoo.2022.0084 .},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2022.0084},
  journal      = {INFORMS Journal on Optimization},
  number       = {3},
  pages        = {233-255},
  shortjournal = {INFORMS J. Optim.},
  title        = {A bisection protocol for political redistricting},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Strong formulations for distributionally robust
chance-constrained programs with left-hand side uncertainty under
wasserstein ambiguity. <em>IJOO</em>, <em>5</em>(2), 211–232. (<a
href="https://doi.org/10.1287/ijoo.2022.0083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributionally robust chance-constrained programs (DR-CCPs) over Wasserstein ambiguity sets exhibit attractive out-of-sample performance and admit big- M– based mixed-integer programming reformulations with conic constraints. However, the resulting formulations often suffer from scalability issues as problem size increases. To address this shortcoming, we derive stronger formulations that scale well with respect to the problem size. Our focus is on ambiguity sets under the so-called left-hand side uncertainty, where the uncertain parameters affect the coefficients of the decision variables in the linear inequalities defining the safety sets. The interaction between the uncertain parameters and the variable coefficients in the safety set definition causes challenges in strengthening the original big- M formulations. By exploiting the connection between nominal chance-constrained programs and DR-CCP, we obtain strong formulations with significant enhancements. In particular, through this connection, we derive a linear number of valid inequalities, which can be immediately added to the formulations to obtain improved formulations in the original space of variables. In addition, we suggest a quantile-based strengthening procedure that allows us to reduce the big- M coefficients drastically. Furthermore, based on this procedure, we propose an exponential class of inequalities that can be separated efficiently within a branch-and-cut framework. The quantile-based strengthening procedure can be expensive. Therefore, for the special case of covering and packing type problems, we identify an efficient scheme to carry out this procedure. We demonstrate the computational efficacy of our proposed formulations on two classes of problems, namely stochastic portfolio optimization and resource planning. Funding: This work was supported by the DARPA Lagrange Program [Grant N660011824020], the National Science Foundation [Grant 1740707], the Office of Naval Research [Grant N00014-19-1-2321], and the Institute for Basic Science [Grants IBS-R029-C1 and IBS-R029-Y2].},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2022.0083},
  journal      = {INFORMS Journal on Optimization},
  number       = {2},
  pages        = {211-232},
  shortjournal = {INFORMS J. Optim.},
  title        = {Strong formulations for distributionally robust chance-constrained programs with left-hand side uncertainty under wasserstein ambiguity},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine-learning–based arc selection for constrained
shortest path problems in column generation. <em>IJOO</em>,
<em>5</em>(2), 191–210. (<a
href="https://doi.org/10.1287/ijoo.2022.0082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Column generation is an iterative method used to solve a variety of optimization problems. It decomposes the problem into two parts: a master problem and one or more pricing problems (PP). The total computing time taken by the method is divided between these two parts. In routing or scheduling applications, the problems are mostly defined on a network, and the PP is usually an NP-hard shortest path problem with resource constraints. In this work, we propose a new heuristic pricing algorithm based on machine learning. By taking advantage of the data collected during previous executions, the objective is to reduce the size of the network and accelerate the PP, keeping only the arcs that have a high chance to be part of the linear relaxation solution. The method has been applied to two specific problems: the vehicle and crew scheduling problem in public transit and the vehicle routing problem with time windows. Reductions in computational time of up to 40\% can be obtained. Funding: The authors thank Giro, Inc., and the Natural Sciences and Engineering Research Council of Canada for financial support [Grant CRDPJ 520349-17].},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2022.0082},
  journal      = {INFORMS Journal on Optimization},
  number       = {2},
  pages        = {191-210},
  shortjournal = {INFORMS J. Optim.},
  title        = {Machine-Learning–Based arc selection for constrained shortest path problems in column generation},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Holistic prescriptive analytics for continuous and
constrained optimization problems. <em>IJOO</em>, <em>5</em>(2),
155–171. (<a href="https://doi.org/10.1287/ijoo.2022.0080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a holistic framework for prescriptive analytics. Given side data x , decisions z , and uncertain quantities y that are functions of x and z , we propose a framework that simultaneously predicts y and prescribes the “should be” optimal decisions z ¯ . The algorithm can accommodate a large number of predictive machine learning models as well as continuous and discrete decisions of high cardinality. It also allows for constraints on these decision variables. We show wide applicability and strong computational performances on synthetic experiments and on two real-world case studies.},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2022.0080},
  journal      = {INFORMS Journal on Optimization},
  number       = {2},
  pages        = {155-171},
  shortjournal = {INFORMS J. Optim.},
  title        = {Holistic prescriptive analytics for continuous and constrained optimization problems},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Presolving for mixed-integer semidefinite optimization.
<em>IJOO</em>, <em>5</em>(2), 131–154. (<a
href="https://doi.org/10.1287/ijoo.2022.0079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides a discussion and evaluation of presolving methods for mixed-integer semidefinite programs. We generalize methods from the mixed-integer linear case and introduce new methods that depend on the semidefinite condition. The methods considered include adding linear constraints, deriving bounds relying on 2 × 2 minors of the semidefinite constraints, tightening of variable bounds based on solving a semidefinite program with one variable, and scaling of the matrices in the semidefinite constraints. Tightening the bounds of variables can also be used in a node presolving step. Along the way, we discuss how to solve semidefinite programs with one variable using a semismooth Newton method and the convergence of iteratively applying bound tightening. We then provide an extensive computational comparison of the different presolving methods, demonstrating their effectiveness with an improvement in running time of about 22\% on average. The impact depends on the instance type and varies across the methods. Funding: This work was supported by the EXPRESS II project within the German Research Foundation (Deutsche Forschungsgemeinschaft, DFG) priority program CoSIP (DFG-SPP 1798). It was also partly supported by the DFG within Project A4 in the SFB 805.},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2022.0079},
  journal      = {INFORMS Journal on Optimization},
  number       = {2},
  pages        = {131-154},
  shortjournal = {INFORMS J. Optim.},
  title        = {Presolving for mixed-integer semidefinite optimization},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The power and limits of predictive approaches to
observational data-driven optimization: The case of pricing.
<em>IJOO</em>, <em>5</em>(1), 110–129. (<a
href="https://doi.org/10.1287/ijoo.2022.0077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider data-driven decision making in which data on historical decisions and outcomes are endogenous and lack the necessary features for causal identification (e.g., unconfoundedness or instruments), focusing on data-driven pricing. We study approaches that, for lack of better alternative, optimize the prediction of objective (revenue) given decision (price). Whereas data-driven decision making is transforming modern operations, most large-scale data are observational, with which confounding is inevitable and the strong assumptions necessary for causal identification are dubious. Nonetheless, the inevitable statistical biases may be irrelevant if impact on downstream optimization performance is limited. This paper seeks to formalize and empirically study this question. First, to study the power of decision making with confounded data, by leveraging a special optimization structure, we develop bounds on the suboptimality of pricing using the (noncausal) prediction of historical demand given price. Second, to study the limits of decision making with confounded data, we develop a new hypothesis test for optimality with respect to the true average causal effect on the objective and apply it to interest rate–setting data to assesses whether performance can be distinguished from optimal to statistical significance in practice. Our empirical study demonstrates that predictive approaches can generally be powerful in practice with some limitations. Funding: This work was supported by the National Science Foundation [Grant 1846210]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/ijoo.2022.0077 .},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2022.0077},
  journal      = {INFORMS Journal on Optimization},
  number       = {1},
  pages        = {110-129},
  shortjournal = {INFORMS J. Optim.},
  title        = {The power and limits of predictive approaches to observational data-driven optimization: The case of pricing},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MILP sensitivity analysis for the objective function
coefficients. <em>IJOO</em>, <em>5</em>(1), 92–109. (<a
href="https://doi.org/10.1287/ijoo.2022.0078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new approach to sensitivity analysis of the objective function coefficients in mixed-integer linear programming (MILP). We determine the maximal region of the coefficients for which the current solution remains optimal. The region is maximal in the sense that, for variations beyond this region, the optimal solution changes. For variations in a single objective function coefficient, we show how to obtain the region by biobjective mixed-integer linear programming. In particular, we prove that it suffices to determine the two extreme nondominated points adjacent to the optimal solution of the MILP problem. Furthermore, we show how to extend the methodology to simultaneous changes to two or more coefficients by use of multiobjective analysis. Two examples illustrate the applicability of the approach. Supplemental Material: The online appendix is available at https://doi.org/10.1287/ijoo.2022.0078 .},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2022.0078},
  journal      = {INFORMS Journal on Optimization},
  number       = {1},
  pages        = {92-109},
  shortjournal = {INFORMS J. Optim.},
  title        = {MILP sensitivity analysis for the objective function coefficients},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributionally robust optimization based on kernel density
estimation and mean-entropic value-at-risk. <em>IJOO</em>,
<em>5</em>(1), 68–91. (<a
href="https://doi.org/10.1287/ijoo.2022.0076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a distributionally robust optimization model based on kernel density estimation (KDE) and mean entropic value-at-risk (EVaR) is proposed, where the ambiguity set is defined as a KDE- ϕ -divergence “ball” centered at the empirical distribution in the weighted KDE distribution function family, which is a finite-dimensional set. Instead of the joint probability distribution of the random vector, the one-dimensional probability distribution of the random loss function is approximated by the univariate weighted KDE for dimensionality reduction. Under the mild conditions of the kernel and ϕ -divergence function, the computationally tractable reformulation of the corresponding distributionally robust mean-EVaR optimization model is derived by Fenchel’s duality theory. Convergence of the optimal value and the solution set of the distributionally robust optimization problem based on KDE and mean-EVaR to those of the corresponding stochastic programming problem with the true distribution is proved. For some special cases, including portfolio selection, newsvendor problem, and linear two-stage stochastic programming problem, concrete tractable reformulations are given. Primary empirical test results for portfolio selection and project management problems show that the proposed model is promising. Funding: This work was funded by the National Natural Science Foundation of China [Grants 11971092 and 11571061] and the Fundamental Research Funds for the Central Universities [Grants DUT15RC(3)037 and DUT18RC(4)067].},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2022.0076},
  journal      = {INFORMS Journal on Optimization},
  number       = {1},
  pages        = {68-91},
  shortjournal = {INFORMS J. Optim.},
  title        = {Distributionally robust optimization based on kernel density estimation and mean-entropic value-at-risk},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Test score algorithms for budgeted stochastic utility
maximization. <em>IJOO</em>, <em>5</em>(1), 27–67. (<a
href="https://doi.org/10.1287/ijoo.2022.0075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by recent developments in designing algorithms based on individual item scores for solving utility maximization problems, we study the framework of using test scores, defined as a statistic of observed individual item performance data, for solving the budgeted stochastic utility maximization problem. We extend an existing scoring mechanism, namely, the replication test scores, to incorporate heterogeneous item costs as well as item values. We show that a natural greedy algorithm that selects items solely based on their replication test scores outputs solutions within a constant factor of the optimum for the class of functions satisfying an extended diminishing returns property. Our algorithms and approximation guarantees assume that test scores are noisy estimates of certain expected values with respect to marginal distributions of individual item values, thus making our algorithms practical and extending previous work that assumes noiseless estimates. Moreover, we show how our algorithm can be adapted to the setting in which items arrive in a streaming fashion while maintaining the same approximation guarantee. We present numerical results, using synthetic data and data sets from the Academia.StackExchange Q&amp;A forum, which show that our test score algorithm can achieve competitiveness and in some cases better performance than a benchmark algorithm that requires access to a value oracle to evaluate function values. Funding: This research was supported, in part, by the Institute for Basic Science [Grants IBS-R029-C1, IBS-R029-Y2].},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2022.0075},
  journal      = {INFORMS Journal on Optimization},
  number       = {1},
  pages        = {27-67},
  shortjournal = {INFORMS J. Optim.},
  title        = {Test score algorithms for budgeted stochastic utility maximization},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An algorithm for the separation-preserving transition of
clusterings. <em>IJOO</em>, <em>5</em>(1), 1–26. (<a
href="https://doi.org/10.1287/ijoo.2022.0074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The separability of clusters is one of the most desired properties in clustering. There is a wide range of settings in which different clusterings of the same data set appear. We are interested in applications for which there is a need for an explicit, gradual transition of one separable clustering into another one. This transition should be a sequence of simple, natural steps that upholds separability of the clusters throughout. We design an algorithm for such a transition. We exploit the intimate connection of separability and linear programming over bounded-shape partition and transportation polytopes: separable clusterings lie on the boundary of partition polytopes and form a subset of the vertices of the corresponding transportation polytopes, and circuits of both polytopes are readily interpreted as sequential or cyclical exchanges of items between clusters. This allows for a natural approach to achieve the desired transition through a combination of two walks: an edge walk between two so-called radial clusterings in a transportation polytope, computed through an adaptation of classical tools of sensitivity analysis and parametric programming, and a walk from a separable clustering to a corresponding radial clustering, computed through a tailored, iterative routine updating cluster sizes and reoptimizing the cluster assignment of items. Funding: Borgwardt gratefully acknowledges support of this work through National Science Foundation [Grant 2006183] Circuit Walks in Optimization , Algorithmic Foundations, Division of Computing and Communication Foundations; through Air Force Office of Scientific Research [Grant FA9550-21-1-0233] The Hirsch Conjecture for Totally-Unimodular Polyhedra ; and through Simons Collaboration [Grant 524210] Polyhedral Theory in Data Analytics . Happach has been supported by the Alexander von Humboldt Foundation with funds from the German Federal Ministry of Education and Research.},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2022.0074},
  journal      = {INFORMS Journal on Optimization},
  number       = {1},
  pages        = {1-26},
  shortjournal = {INFORMS J. Optim.},
  title        = {An algorithm for the separation-preserving transition of clusterings},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
