<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TMLR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tmlr---611">TMLR - 611</h2>
<ul>
<li><details>
<summary>
(2023). GIT-net: Generalized integral transform for operator
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=0WKTmrVkd2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces GIT-Net, a deep neural network architecture for approximating Partial Differential Equation (PDE) operators, inspired by integral transform operators. GIT-NET harnesses the fact that common differential operators commonly used for defining PDEs can often be represented parsimoniously when expressed in specialized functional bases (e.g., Fourier basis). Unlike rigid integral transforms, GIT-Net parametrizes adaptive generalized integral transforms with deep neural networks. When compared to several recently proposed alternatives, GIT-Net&#39;s computational and memory requirements scale gracefully with mesh discretizations, facilitating its application to PDE problems on complex geometries. Numerical experiments demonstrate that GIT-Net is a competitive neural network operator, exhibiting small test errors and low evaluations across a range of PDE problems. This stands in contrast to existing neural network operators, which typically excel in just one of these areas.},
  archive      = {J_TMLR},
  author       = {Chao Wang and Alexandre H. Thiery},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {GIT-net: Generalized integral transform for operator learning},
  url          = {https://openreview.net/forum?id=0WKTmrVkd2},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving native CNN robustness with filter frequency
regularization. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=2wecNCpZ7Y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks tend to overfit the training distribution and perform poorly on out-of-distribution data. A conceptually simple solution lies in adversarial training, which introduces worst-case perturbations into the training data and thus improves model generalization to some extent. However, it is only one ingredient towards generally more robust models and requires knowledge about the potential attacks or inference time data corruptions during model training. This paper focuses on the native robustness of models that can learn robust behavior directly from conventional training data without out-of-distribution examples. To this end, we study the frequencies in learned convolution filters. Clean-trained models often prioritize high-frequency information, whereas adversarial training enforces models to shift the focus to low-frequency details during training. By mimicking this behavior through frequency regularization in learned convolution weights, we achieve improved native robustness to adversarial attacks, common corruptions, and other out-of-distribution tests. Additionally, this method leads to more favorable shifts in decision-making towards low-frequency information, such as shapes, which inherently aligns more closely with human vision.},
  archive      = {J_TMLR},
  author       = {Jovita Lukasik and Paul Gavrikov and Janis Keuper and Margret Keuper},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Improving native CNN robustness with filter frequency regularization},
  url          = {https://openreview.net/forum?id=2wecNCpZ7Y},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards optimization-friendly binary neural network.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=4Hq816XDDG">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary neural networks (BNNs) are a promising approach for compressing and accelerating deep learning models, especially in resource-constrained environments. However, the optimization gap between BNNs and their full-precision counterparts has long been an open problem limiting their performance. In this work, we propose a novel optimization pipeline to enhance the performance of BNNs. The main approach includes three key components: (1) BNext, a strong binary baseline based on an optimization-friendly basic block design, (2) knowledge complexity, a simple yet effective teacher-selection metric taking the capacity gap between teachers and binary students under consideration, (3) consecutive knowledge distillation (CKD), a novel multi-round optimization technique to transfer high-confidence knowledge from strong teachers to low-capacity BNNs. We empirically validate the superiority of the method on several vision classification tasks CIFAR-10/100 &amp; ImageNet. For instance, the BNext family outperforms previous BNNs under different capacity levels and contributes the first binary neural network to reach the state-of-the-art 80.57\% Top-1 accuracy on ImageNet with 0.82 GOPS, which verifies the potential of BNNs and already contributes a strong baseline for future research on high-accuracy BNNs. The code will be publicly available at (blind URL, see supplementary material).},
  archive      = {J_TMLR},
  author       = {Nianhui Guo and Joseph Bethge and Hong Guo and Christoph Meinel and Haojin Yang},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards optimization-friendly binary neural network},
  url          = {https://openreview.net/forum?id=4Hq816XDDG},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). UnIVAL: Unified model for image, video, audio and language
tasks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=4uflhObpcp">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have made the ambitious quest for generalist agents significantly far from being a fantasy. A key hurdle for building such general models is the diversity and heterogeneity of tasks and modalities. A promising solution is unification, allowing the support of a myriad of tasks and modalities within one unified framework. While few large models (e.g., Flamingo (Alayrac et al. 2022)), trained on massive datasets, can support more than two modalities, current small to mid-scale unified models are still limited to 2 modalities, usually image-text or video-text. The question that we ask is: is it possible to build efficiently a unified model that can support all modalities? To answer this, we propose UnIVAL, a step further towards this ambitious goal. Without relying on fancy datasets sizes or models with billions of parameters, the ~ 0.25B parameter UnIVAL model goes beyond two modalities and unifies text, images, video, and audio into a single model. Our model is efficiently pretrained on many tasks, based on task balancing and multimodal curriculum learning. UnIVAL shows competitive performance to existing state-of-the-art approaches, across image and video-text tasks. The feature representations learned from image and video-text modalities, allows the model to achieve competitive performance when finetuned on audio-text tasks, despite not being pretrained on audio. Thanks to the unified model, we propose a novel study on multimodal model merging via weight interpolation of models trained on different multimodal tasks, showing their benefits in particular for out-of-distribution generalization. Finally, we motivate unification by showing the synergy between tasks. The model weights and code are available at: https://github.com/mshukor/UnIVAL.},
  archive      = {J_TMLR},
  author       = {Mustafa Shukor and Corentin Dancette and Alexandre Rame and Matthieu Cord},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {UnIVAL: Unified model for image, video, audio and language tasks},
  url          = {https://openreview.net/forum?id=4uflhObpcp},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Partial optimal transport for support subset selection.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=75CcopPxIr">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In probabilistic terms, optimal transport aims to find a joint distribution that couples two distributions and minimizes the cost of transforming one distribution to another. Any feasible coupling necessarily maintains the support of both distributions. However, maintaining the entire support is not ideal when only a subset of one of the distributions, namely the source, is assumed to align with the other target distribution. For these cases, which are common in machine learning applications, we study the semi-relaxed partial optimal transport problem that relaxes the constraints on the joint distribution allowing it to under-represent a subset of the source by over-representing other subsets of the source by a constant factor. In the discrete distribution case, such as in the case of two samples from continuous random variables, optimal transport with the relaxed constraints is a linear program. When sufficiently relaxed, the solution has a source marginal with only a subset of its original support. We investigate the scaling path of solutions, specifically the relaxed marginal distribution for the source, across different relaxations and show that it is distinct from the solutions from penalty-based semi-relaxed unbalanced optimal transport problems and fully-relaxed partial optimal transport, which have previously been explored. We demonstrate the usefulness of this support subset selection in applications such as color transfer, partial point cloud alignment, and semi-supervised machine learning, where a part of data is curated to have reliable labels and another part is unlabeled or has unreliable labels. Our experiments show that optimal transport under the relaxed constraint can improve the performance of these applications by allowing for more flexible alignment between distributions.},
  archive      = {J_TMLR},
  author       = {Bilal Riaz and Yuksel Karahan and Austin J. Brockmeier},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Partial optimal transport for support subset selection},
  url          = {https://openreview.net/forum?id=75CcopPxIr},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Early stopping for deep image prior. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=231ZzrLC8X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep image prior (DIP) and its variants have shown remarkable potential to solve inverse problems in computational imaging (CI), needing no separate training data. Practical DIP models are often substantially overparameterized. During the learning process, these models first learn the desired visual content and then pick up potential modeling and observational noise, i.e., performing early learning then overfitting. Thus, the practicality of DIP hinges on early stopping (ES) that can capture the transition period. In this regard, most previous DIP works for CI tasks only demonstrate the potential of the models, reporting the peak performance against the ground truth but providing no clue about how to operationally obtain near-peak performance without access to the ground truth. In this paper, we set to break this practicality barrier of DIP, and propose an effective ES strategy that consistently detects near-peak performance across several CI tasks and DIP variants. Simply based on the running variance of DIP intermediate reconstructions, our ES method not only outpaces the existing ones---which only work in very narrow regimes, but also remains effective when combined with methods that try to mitigate overfitting.},
  archive      = {J_TMLR},
  author       = {Hengkang Wang and Taihui Li and Zhong Zhuang and Tiancong Chen and Hengyue Liang and Ju Sun},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Early stopping for deep image prior},
  url          = {https://openreview.net/forum?id=231ZzrLC8X},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on the possibilities &amp; impossibilities of
AI-generated text detection. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=AXtFeYjboj">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have revolutionized the domain of natural language processing (NLP) with remarkable capabilities of generating human-like text responses. However, despite these advancements, several works in the existing literature have raised serious concerns about the potential misuse of LLMs such as spreading misinformation, generating fake news, plagiarism in academia, and contaminating the web. To address these concerns, a consensus among the research community is to develop algorithmic solutions to detect AI-generated text. The basic idea is that whenever we can tell if the given text is either written by a human or an AI, we can utilize this information to address the above-mentioned concerns. To that end, a plethora of detection frameworks have been proposed, highlighting the possibilities of AI-generated text detection. But in parallel to the development of detection frameworks, researchers have also concentrated on designing strategies to elude detection, i.e., focusing on the impossibilities of AI-generated text detection. This is a crucial step in order to make sure the detection frameworks are robust enough and it is not too easy to fool a detector. Despite the huge interest and the flurry of research in this domain, the community currently lacks a comprehensive analysis of recent developments. In this survey, we aim to provide a concise categorization and overview of current work encompassing both the prospects and the limitations of AI-generated text detection. To enrich the collective knowledge, we engage in an exhaustive discussion on critical and challenging open questions related to ongoing research on AI-generated text detection.},
  archive      = {J_TMLR},
  author       = {Soumya Suvra Ghosal and Souradip Chakraborty and Jonas Geiping and Furong Huang and Dinesh Manocha and Amrit Bedi},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A survey on the possibilities &amp; impossibilities of AI-generated text detection},
  url          = {https://openreview.net/forum?id=AXtFeYjboj},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Smoothed differential privacy. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=CviCLt44Em">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential privacy (DP) is a widely-accepted and widely-applied notion of privacy based on worst-case analysis. Often, DP classifies most mechanisms without additive noise as non-private (Dwork et al., 2014). Thus, additive noises are added to improve privacy (to achieve DP). However, in many real-world applications, adding additive noise is undesirable (Bagdasaryan et al., 2019) and sometimes prohibited (Liu et al., 2020). In this paper, we propose a natural extension of DP following the worst average-case idea behind the celebrated smoothed analysis (Spielman &amp; Teng, May 2004). Our notion, smoothed DP, can effectively measure the privacy leakage of mechanisms without additive noises under realistic settings. We prove that any discrete mechanism with sampling procedures is more private than what DP predicts, while many continuous mechanisms with sampling procedures are still non-private under smoothed DP. In addition, we prove several desirable properties of smoothed DP, including composition, robustness to post-processing, and distribution reduction. Based on those properties, we propose an efficient algorithm to calculate the privacy parameters for smoothed DP. Experimentally, we verify that, according to smoothed DP, the discrete sampling mechanisms are private in real-world elections, and some discrete neural networks can be private without adding any additive noise. We believe that these results contribute to the theoretical foundation of realistic privacy measures beyond worst-case analysis.},
  archive      = {J_TMLR},
  author       = {Ao Liu and Yu-Xiang Wang and Lirong Xia},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Smoothed differential privacy},
  url          = {https://openreview.net/forum?id=CviCLt44Em},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Equivariant MuZero. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ExbGarTbLE">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning has shown lots of success in closed, well-defined domains such as games (Chess, Go, StarCraft). The next frontier is real-world scenarios, where setups are numerous and varied. For this, agents need to learn the underlying environment dynamics, so as to robustly generalise to conditions that differ from those they were trained on. Model-based reinforcement learning algorithms, such as MuZero or Dreamer, aim to accomplish this by learning a world model. However, leveraging a world model has not yet consistently shown greater generalisation capabilities compared to model-free alternatives. In this work, we propose improving the data efficiency and generalisation capabilities of MuZero by explicitly incorporating the \emph{symmetries} of the environment in its world-model architecture. We prove that, so long as the neural networks used by MuZero are equivariant to a particular symmetry group acting on the environment, the entirety of MuZero&#39;s action-selection algorithm will also be equivariant to that group. As such, Equivariant MuZero is guaranteed to behave symmetrically in symmetrically-transformed states, and will hence be more data-efficient when learning its world models. We evaluate Equivariant MuZero on procedurally-generated MiniPacman and on Chaser from the ProcGen suite: training on a set of mazes, and then testing on unseen rotated versions, demonstrating the benefits of equivariance. We verify that our improvements hold even when only some of the components of Equivariant MuZero obey strict equivariance, which highlights the robustness of our construction.},
  archive      = {J_TMLR},
  author       = {Andreea Deac and Theophane Weber and George Papamakarios},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Equivariant MuZero},
  url          = {https://openreview.net/forum?id=ExbGarTbLE},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Uncertainty estimation for computed tomography with a
linearised deep image prior. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=FWyabz82fH">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing deep-learning based tomographic image reconstruction methods do not provide accurate uncertainty estimates of their reconstructions, hindering their real-world deployment. This paper develops a method, termed as linearised deep image prior (DIP), to estimate the uncertainty associated with reconstructions produced by the DIP with total variation (TV) regularisation. We endow the DIP with conjugate Gaussian-linear model type error-bars computed from a local linearisation of the neural network around its optimised parameters. To preserve conjugacy, we approximate the TV regulariser with a Gaussian surrogate. This approach provides pixel-wise uncertainty estimates and a marginal likelihood objective for hyperparameter optimisation. We demonstrate the method on synthetic data and real-measured high-resolution 2D $\mu$CT data, and show that it provides superior calibration of uncertainty estimates relative to previous probabilistic formulations of the~DIP. Our code is available at https://github.com/educating-dip/bayes_dip.},
  archive      = {J_TMLR},
  author       = {Javier Antoran and Riccardo Barbano and Johannes Leuschner and José Miguel Hernández-Lobato and Bangti Jin},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Uncertainty estimation for computed tomography with a linearised deep image prior},
  url          = {https://openreview.net/forum?id=FWyabz82fH},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ProtoCaps: A fast and non-iterative capsule network routing
method. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Id10mlBjcx">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capsule Networks have emerged as a powerful class of deep learning architectures, known for robust performance with relatively few parameters compared to Convolutional Neural Networks (CNNs). However, their inherent efficiency is often overshadowed by their slow, iterative routing mechanisms which establish connections between Capsule layers, posing computational challenges resulting in an inability to scale. In this paper, we introduce a novel, non-iterative routing mechanism, inspired by trainable prototype clustering. This innovative approach aims to mitigate computational complexity, while retaining, if not enhancing, performance efficacy. Furthermore, we harness a shared Capsule subspace, negating the need to project each lower-level Capsule to each higher-level Capsule, thereby significantly reducing memory requisites during training. Our approach demonstrates superior results compared to the current best non-iterative Capsule Network and tests on the Imagewoof dataset, which is too computationally demanding to handle efficiently by iterative approaches. Our findings underscore the potential of our proposed methodology in enhancing the operational efficiency and performance of Capsule Networks, paving the way for their application in increasingly complex computational scenarios. Code is available at https://github.com/mileseverett/ProtoCaps.},
  archive      = {J_TMLR},
  author       = {Miles Everett and Mingjun Zhong and Georgios Leontidis},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ProtoCaps: A fast and non-iterative capsule network routing method},
  url          = {https://openreview.net/forum?id=Id10mlBjcx},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). StarCoder: May the source be with you! <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=KoFOg41haE">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The BigCode community, an open-scientific collaboration working on the responsible development of Large Language Models for Code (Code LLMs), introduces StarCoder and StarCoderBase: 15.5B parameter models with 8K context length, infilling capabilities and fast large-batch inference enabled by multi-query attention. StarCoderBase is trained on 1 trillion tokens sourced from The Stack, a large collection of permissively licensed GitHub repositories with inspection tools and an opt-out process. We fine-tuned StarCoderBase on 35B Python tokens, resulting in the creation of StarCoder. We perform the most comprehensive evaluation of Code LLMs to date and show that StarCoderBase outperforms every open Code LLM that supports multiple programming languages and matches or outperforms the OpenAI code-cushman-001 model. Furthermore, StarCoder outperforms every model that is fine-tuned on Python and still retains its performance on other programming languages. We take several important steps towards a safe open-access model release, including an improved PII redaction pipeline and a novel attribution tracing tool, and make the StarCoder models publicly available under a more commercially viable version of the Open Responsible AI Model license.},
  archive      = {J_TMLR},
  author       = {Raymond Li and Loubna Ben allal and Yangtian Zi and Niklas Muennighoff and Denis Kocetkov and Chenghao Mou and Marc Marone and Christopher Akiki and Jia LI and Jenny Chim and Qian Liu and Evgenii Zheltonozhskii and Terry Yue Zhuo and Thomas Wang and Olivier Dehaene and Joel Lamy-Poirier and Joao Monteiro and Nicolas Gontier and Ming-Ho Yee and Logesh Kumar Umapathi and Jian Zhu and Ben Lipkin and Muhtasham Oblokulov and Zhiruo Wang and Rudra Murthy and Jason T Stillerman and Siva Sankalp Patel and Dmitry Abulkhanov and Marco Zocca and Manan Dey and Zhihan Zhang and Urvashi Bhattacharyya and Wenhao Yu and Sasha Luccioni and Paulo Villegas and Fedor Zhdanov and Tony Lee and Nadav Timor and Jennifer Ding and Claire S Schlesinger and Hailey Schoelkopf and Jan Ebert and Tri Dao and Mayank Mishra and Alex Gu and Carolyn Jane Anderson and Brendan Dolan-Gavitt and Danish Contractor and Siva Reddy and Daniel Fried and Dzmitry Bahdanau and Yacine Jernite and Carlos Muñoz Ferrandis and Sean Hughes and Thomas Wolf and Arjun Guha and Leandro Von Werra and Harm de Vries},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {StarCoder: May the source be with you!},
  url          = {https://openreview.net/forum?id=KoFOg41haE},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Wrapped <span
class="math inline"><em>β</em></span>-gaussians with compact support for
exact probabilistic modeling on manifolds. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=KrequDpWzt">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce wrapped $\beta$-Gaussians, a family of wrapped distributions on Riemannian manifolds, supporting efficient reparametrized sampling, as well as exact density estimation, effortlessly supporting high dimensions and anisotropic scale parameters. We extend Fenchel-Young losses for geometry-aware learning with wrapped $\beta$-Gaussians, and demonstrate the efficacy of our proposed family in a suite of experiments on hypersphere and rotation manifolds: data fitting, hierarchy encoding, generative modeling with variational autoencoders, and multilingual word embedding alignment.},
  archive      = {J_TMLR},
  author       = {Sergey Troshin and Vlad Niculae},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Wrapped $\beta$-gaussians with compact support for exact probabilistic modeling on manifolds},
  url          = {https://openreview.net/forum?id=KrequDpWzt},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Two-level actor-critic using multiple teachers.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=LfQ6uAVAEo">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning has successfully allowed agents to learn complex behaviors for many tasks. However, a key limitation of current learning approaches is the sample-inefficiency problem, which limits performance of the learning agent. This paper considers how agents can benefit from improved learning via teachers&#39; advice. In particular, we consider the setting with multiple sub-optimal teachers, as opposed to having a single near-optimal teacher. We propose a flexible two-level actor-critic algorithm where the high-level network learns to choose the best teacher in the current situation while the low-level network learns the control policy.},
  archive      = {J_TMLR},
  author       = {Su Zhang and Srijita Das and Sriram Ganapathi Subramanian and Matthew E. Taylor},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Two-level actor-critic using multiple teachers},
  url          = {https://openreview.net/forum?id=LfQ6uAVAEo},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). In search of projectively equivariant networks.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Ls1E16bTj8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Equivariance of linear neural network layers is well studied. In this work, we relax the equivariance condition to only be true in a projective sense. Hereby, we introduce the topic of projective equivariance to the machine learning audience. We theoretically study the relation of projectively and linearly equivariant linear layers. We find that in some important cases, surprisingly, the two types of layers coincide. We also propose a way to construct a projectively equivariant neural network, which boils down to building a standard equivariant network where the linear group representations acting on each intermediate feature space are lifts of projective group representations. Projective equivariance is showcased in two simple experiments. Code for the experiments is provided in the supplementary material.},
  archive      = {J_TMLR},
  author       = {Georg Bökman and Axel Flinth and Fredrik Kahl},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {In search of projectively equivariant networks},
  url          = {https://openreview.net/forum?id=Ls1E16bTj8},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transport with support: Data-conditional diffusion bridges.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Mbc58EzF5q">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamic Schrödinger bridge problem provides an appealing setting for solving constrained time-series data generation tasks posed as optimal transport problems. It consists of learning non-linear diffusion processes using efficient iterative solvers. Recent works have demonstrated state-of-the-art results (eg., in modelling single-cell embryo RNA sequences or sampling from complex posteriors) but are limited to learning bridges with only initial and terminal constraints. Our work extends this paradigm by proposing the Iterative Smoothing Bridge (ISB). We integrate Bayesian filtering and optimal control into learning the diffusion process, enabling the generation of constrained stochastic processes governed by sparse observations at intermediate stages and terminal constraints. We assess the effectiveness of our method on synthetic and real-world data generation tasks and we show that the ISB generalises well to high-dimensional data, is computationally efficient, and provides accurate estimates of the marginals at intermediate and terminal times.},
  archive      = {J_TMLR},
  author       = {Ella Tamir and Martin Trapp and Arno Solin},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Transport with support: Data-conditional diffusion bridges},
  url          = {https://openreview.net/forum?id=Mbc58EzF5q},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Federated minimax optimization with client heterogeneity.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=NnUmg1chLL">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimax optimization has seen a surge in interest with the advent of modern applications such as GANs, and it is inherently more challenging than simple minimization. The difficulty is exacerbated by the training data residing at multiple edge devices or \textit{clients}, especially when these clients can have heterogeneous datasets and heterogeneous local computation capabilities. We propose a general federated minimax optimization framework that subsumes such settings and several existing methods like Local SGDA. We show that naive aggregation of model updates made by clients running unequal number of local steps can result in optimizing a mismatched objective function -- a phenomenon previously observed in standard federated minimization. To fix this problem, we propose normalizing the client updates by the number of local steps. We analyze the convergence of the proposed algorithm for classes of nonconvex-concave and nonconvex-nonconcave functions and characterize the impact of heterogeneous client data, partial client participation, and heterogeneous local computations. For all the function classes considered, we significantly improve the existing computation and communication complexity results. Experimental results support our theoretical claims.},
  archive      = {J_TMLR},
  author       = {Pranay Sharma and Rohan Panda and Gauri Joshi},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Federated minimax optimization with client heterogeneity},
  url          = {https://openreview.net/forum?id=NnUmg1chLL},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DreamEdit: Subject-driven image editing. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=P9haooN9v2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subject-driven image generation aims at generating images containing customized subjects, which has recently drawn enormous attention from the research community. Nevertheless, the previous works cannot precisely control the background and position of the target subject. In this work, we aspire to fill the void of the existing subject-driven generation tasks. To this end, we propose two novel subject-driven editing sub-tasks, i.e., Subject Replacement and Subject Addition. The new tasks are challenging in multiple aspects: replacing a subject with a customized one can totally change its shape, texture, and color, while adding a target subject to a designated position in a provided scene necessitates a rational context-aware posture of the subject. To conquer these two novel tasks, we first manually curate a new dataset called DreamEditBench containing 22 different types of subjects, and 440 source images, which cover diverse scenarios with different difficulty levels. We plan to host DreamEditBench as a platform and hire trained evaluators for standardized human evaluation. We also devise an innovative method DreamEditor to resolve these tasks by performing iterative generation, which enables a smooth adaptation to the customized subject. In this project, we conduct automatic and human evaluations to understand the performance of our DreamEditor and baselines on DreamEditBench. We found that the new tasks are challenging for the existing models. For Subject Replacement, we found that the existing models are particularly sensitive to the shape and color of the original subject. When the original subject and the customized subject are highly different, the model failure rate will dramatically increase. For Subject Addition, we found that the existing models cannot easily blend the customized subjects into the background smoothly, which causes noticeable artifacts in the generated image. We hope that DreamEditBench can become a standardized platform to enable future investigations towards building more controllable subject-driven image editing. Our project and benchmark homepage is https://dreameditbenchteam.github.io/},
  archive      = {J_TMLR},
  author       = {Tianle Li and Max Ku and Cong Wei and Wenhu Chen},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DreamEdit: Subject-driven image editing},
  url          = {https://openreview.net/forum?id=P9haooN9v2},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Error bounds and dynamics of bootstrapping in actor-critic
reinforcement learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=QCjMJfSnYk">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Actor-critic algorithms such as DDPG, TD3, and SAC, which are built on Silver&#39;s deterministic policy gradient theorem, are among the most successful reinforcement-learning methods, but their mathematical basis is not entirely clear. In particular, the critic networks in these algorithms learn to estimate action-value functions by a “bootstrapping” technique based on Bellman error, and it is unclear why this approach works so well in practice, given that Bellman error is only very loosely related to value error, i.e. to the inaccuracy of the action-value estimate. Here we show that policy training in this class of actor-critic methods depends not on the accuracy of the critic&#39;s action-value estimate but on how well the critic estimates the gradient of the action-value, which is better assessed using what we call difference error. We show that this difference error is closely related to the Bellman error — a finding which helps to explain why Bellman-based bootstrapping leads to good policies. Further, we show that value error and difference error show different dynamics along on-policy trajectories through state-action space: value error is a low-pass anticausal (i.e., backward-in-time) filter of Bellman error, and therefore accumulates along trajectories, whereas difference error is a high-pass filter of Bellman error. It follows that techniques which reduce the high-frequency Fourier components of the Bellman error may improve policy training even if they increase the actual size of the Bellman errors. These findings help to explain certain aspects of actor-critic methods that are otherwise theoretically puzzling, such as the use of policy (as distinct from exploratory) noise, and they suggest other measures that may improve these methods.},
  archive      = {J_TMLR},
  author       = {Ahmed J Zerouali and Douglas Blair Tweed},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Error bounds and dynamics of bootstrapping in actor-critic reinforcement learning},
  url          = {https://openreview.net/forum?id=QCjMJfSnYk},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Privacy budget tailoring in private data analysis.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=SnPEhMyuYX">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of learning differentially private linear and logistic regression models that do not exhibit disparate performance for minority groups in the data. Small-sized datasets pose a challenging regime for differential privacy; that is, satisfying differential privacy while learning models from data can lead to models with worse accuracy for minority---in size---subgroups. To address this challenge, inspired by Abowd &amp; Schmutte (2018), we propose: (i) to systematically tailor the privacy budget to the different groups, (ii) use linear optimization oracles in a grid to optimize Lagrangian objectives that correspond to fair learning and optimization. We present efficient differentially private algorithms for linear and logistic regression subject to fairness constraints (e.g., bounded group loss) that allocate the privacy budget based on the private standard error of each subgroup in the data. Consequently, the formulation reduces the amount of noise added to these groups, which leads to more accurate models for such groups. We validate the proposed, group-aware budget allocation, method on synthetic and real-world datasets where we show significant reductions in prediction error for the smallest groups, while still preserving sufficient privacy to protect the minority group from re-identification attacks. In addition, we provide sample complexity lower bounds for our problem formulation.},
  archive      = {J_TMLR},
  author       = {Daniel Alabi and Chris Wiggins},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Privacy budget tailoring in private data analysis},
  url          = {https://openreview.net/forum?id=SnPEhMyuYX},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accelerating batch active learning using continual learning
techniques. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=T55dLSgsEf">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A major problem with Active Learning (AL) is high training costs since models are typically retrained from scratch after every query round. We start by demonstrating that standard AL on neural networks with warm starting fails, both to accelerate training and to avoid catastrophic forgetting when using fine-tuning over AL query rounds. We then develop a new class of techniques, circumventing this problem, by biasing further training towards previously labeled sets. We accomplish this by employing existing, and developing novel, replay-based Continual Learning (CL) algorithms that are effective at quickly learning the new without forgetting the old, especially when data comes from an evolving distribution. We call this paradigm \textit{&quot;Continual Active Learning&quot; (CAL)}. We show CAL achieves significant speedups using a plethora of replay schemes that use model distillation and that select diverse/uncertain points from the history. We conduct experiments across many data domains, including natural language, vision, medical imaging, and computational biology, each with different neural architectures and dataset sizes. CAL consistently provides a $\sim$3x reduction in training time, while retaining performance and out-of-distribution robustness, showing its wide applicability.},
  archive      = {J_TMLR},
  author       = {Arnav Mohanty Das and Gantavya Bhatt and Megh Manoj Bhalerao and Vianne R. Gao and Rui Yang and Jeff Bilmes},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Accelerating batch active learning using continual learning techniques},
  url          = {https://openreview.net/forum?id=T55dLSgsEf},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards fair video summarization. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Uj6MRfR1P5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated video summarization is a vision task that aims to generate concise summaries of lengthy videos. Recent advancements in deep learning have led to highly performant video summarization models; however, there has been a lack of attention given to fairness and unbiased representation in the generated summaries. To bridge this gap, we introduce and analytically define the fair video summarization problem, and demonstrate its connections to the well-established problem of fair clustering. To facilitate fair model development, we also introduce the FairVidSum dataset, which is similar in design to state-of-the-art video summarization datasets such as TVSum and SumMe, but also includes annotations for sensitive attributes and individuals alongside frame importance scores. Finally, we propose the SumBal metric for quantifying the fairness of an outputted video summary. We conduct extensive experiments to benchmark the fairness of various state-of-the-art video summarization models. Our results highlight the need for better models that balance accuracy and fairness to ensure equitable representation and inclusion in summaries. For completeness, we also provide a novel fair-only baseline, FVS-LP, to showcase the fairness-utility gap models can improve upon.},
  archive      = {J_TMLR},
  author       = {Anshuman Chhabra and Kartik Patwari and Chandana Kuntala and Sristi and Deepak Kumar Sharma and Prasant Mohapatra},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards fair video summarization},
  url          = {https://openreview.net/forum?id=Uj6MRfR1P5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ECG representation learning with multi-modal EHR data.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=UxmvCwuTMG">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electronic Health Records (EHRs) provide a rich source of medical information across different modalities such as electrocardiograms (ECG), structured EHRs (sEHR), and unstructured EHRs (text). Inspired by the fact that many cardiac and non-cardiac diseases influence the behavior of the ECG, we leverage structured EHRs and unstructured EHRs from multiple sources by pairing with ECGs and propose a set of three new multi-modal contrastive learning models that combine ECG, sEHR, and text modalities. The performance of these models is compared against different baseline models such as supervised learning models trained from scratch with random weights initialization, and self-supervised learning models trained only on ECGs. We pre-train the models on a large proprietary dataset of about 9 $million$ ECGs from around 2.4 $million$ patients and evaluate the pre-trained models on various downstream tasks such as classification, zero-shot retrieval, and out-of-distribution detection involving the prediction of various heart conditions using ECG waveforms as input, and demonstrate that the models presented in this work show significant improvements compared to all baseline modes.},
  archive      = {J_TMLR},
  author       = {Sravan Kumar Lalam and Hari Krishna Kunderu and Shayan Ghosh and Harish Kumar A and Samir Awasthi and Ashim Prasad and Francisco Lopez-Jimenez and Zachi I Attia and Samuel Asirvatham and Paul Friedman and Rakesh Barve and Melwin Babu},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ECG representation learning with multi-modal EHR data},
  url          = {https://openreview.net/forum?id=UxmvCwuTMG},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SHAP-XRT: The shapley value meets conditional independence
testing. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=WFtTpQ47A7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex nature of artificial neural networks raises concerns on their reliability, trustworthiness, and fairness in real-world scenarios. The Shapley value---a solution concept from game theory---is one of the most popular explanation methods for machine learning models. More traditionally, from a statistical perspective, feature importance is defined in terms of conditional independence. So far, these two approaches to interpretability and feature importance have been considered separate and distinct. In this work, we show that Shapley-based explanation methods and conditional independence testing are closely related. We introduce the \textbf{SHAP}ley E\textbf{X}planation \textbf{R}andomization \textbf{T}est (SHAP-XRT), a testing procedure inspired by the Conditional Randomization Test (CRT) for a specific notion of local (i.e., on a sample) conditional independence. With it, we prove that for binary classification problems, the marginal contributions in the Shapley value provide lower and upper bounds to the expected $p$-values of their respective tests. Furthermore, we show that the Shapley value itself provides an upper bound to the expected $p$-value of a global (i.e., overall) null hypothesis. As a result, we further our understanding of Shapley-based explanation methods from a novel perspective and characterize the conditions under which one can make statistically valid claims about feature importance via the Shapley value.},
  archive      = {J_TMLR},
  author       = {Jacopo Teneggi and Beepul Bharti and Yaniv Romano and Jeremias Sulam},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SHAP-XRT: The shapley value meets conditional independence testing},
  url          = {https://openreview.net/forum?id=WFtTpQ47A7},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FREED++: Improving RL agents for fragment-based molecule
generation by thorough reproduction. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=YVPb6tyRJu">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A rational design of new therapeutic drugs aims to find a molecular structure with desired biological functionality, e.g., an ability to activate or suppress a specific protein via binding to it. Molecular docking is a common technique for evaluating protein-molecule interactions. Recently, Reinforcement Learning (RL) has emerged as a promising approach to generating molecules with the docking score (DS) as a reward. In this work, we reproduce, scrutinize and improve the recent RL model for molecule generation called FREED (Yang et al., 2021). Extensive evaluation of the proposed method reveals several limitations and challenges despite the outstanding results reported for three target proteins. Our contributions include fixing numerous implementation bugs and simplifying the model while increasing its quality, significantly extending experiments, and conducting an accurate comparison with current state-of-the-art methods for protein-conditioned molecule generation. We show that the resulting fixed model is capable of producing molecules with superior docking scores compared to alternative approaches.},
  archive      = {J_TMLR},
  author       = {Alexander Telepov and Artem Tsypin and Kuzma Khrabrov and Sergey Yakukhnov and Pavel Strashnov and Petr Zhilyaev and Egor Rumiantsev and Daniel Ezhov and Manvel Avetisian and Olga Popova and Artur Kadurin},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FREED++: Improving RL agents for fragment-based molecule generation by thorough reproduction},
  url          = {https://openreview.net/forum?id=YVPb6tyRJu},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Open problems and fundamental limitations of reinforcement
learning from human feedback. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=bx24KpJ4Eb">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning from human feedback (RLHF) is a technique for training AI systems to align with human goals. RLHF has emerged as the central method used to finetune state-of-the-art large language models (LLMs). Despite this popularity, there has been relatively little public work systematizing its flaws. In this paper, we (1) survey open problems and fundamental limitations of RLHF and related methods; (2) overview techniques to understand, improve, and complement RLHF in practice; and (3) propose auditing and disclosure standards to improve societal oversight of RLHF systems. Our work emphasizes the limitations of RLHF and highlights the importance of a multi-layered approach to the development of safer AI systems.},
  archive      = {J_TMLR},
  author       = {Stephen Casper and Xander Davies and Claudia Shi and Thomas Krendl Gilbert and Jérémy Scheurer and Javier Rando and Rachel Freedman and Tomasz Korbak and David Lindner and Pedro Freire and Tony Tong Wang and Samuel Marks and Charbel-Raphael Segerie and Micah Carroll and Andi Peng and Phillip Christoffersen and Mehul Damani and Stewart Slocum and Usman Anwar and Anand Siththaranjan and Max Nadeau and Eric J Michaud and Jacob Pfau and Dmitrii Krasheninnikov and Xin Chen and Lauro Langosco and Peter Hase and Erdem Biyik and Anca Dragan and David Krueger and Dorsa Sadigh and Dylan Hadfield-Menell},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Open problems and fundamental limitations of reinforcement learning from human feedback},
  url          = {https://openreview.net/forum?id=bx24KpJ4Eb},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Benchmarks for physical reasoning AI. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=cHroS8VIyN">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physical reasoning is a crucial aspect in the development of general AI systems, given that human learning starts with interacting with the physical world before progressing to more complex concepts. Although researchers have studied and assessed the physical reasoning of AI approaches through various specific benchmarks, there is no comprehensive approach to evaluating and measuring progress. Therefore, we aim to offer an overview of existing benchmarks and their solution approaches and propose a unified perspective for measuring the physical reasoning capacity of AI systems. We select benchmarks that are designed to test algorithmic performance in physical reasoning tasks. While each of the selected benchmarks poses a unique challenge, their ensemble provides a comprehensive proving ground for an AI generalist agent with a measurable skill level for various physical reasoning concepts. This gives an advantage to such an ensemble of benchmarks over other holistic benchmarks that aim to simulate the real world by intertwining its complexity and many concepts. We group the presented set of physical reasoning benchmarks into subcategories so that more narrow generalist AI agents can be tested first on these groups.},
  archive      = {J_TMLR},
  author       = {Andrew Melnik and Robin Schiewer and Moritz Lange and Andrei Ioan Muresanu and mozhgan saeidi and Animesh Garg and Helge Ritter},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Benchmarks for physical reasoning AI},
  url          = {https://openreview.net/forum?id=cHroS8VIyN},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast slate policy optimization: Going beyond plackett-luce.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=f7a8XCRtUu">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An increasingly important building block of large scale machine learning systems is based on returning slates; an ordered lists of items given a query. Applications of this technology include: search, information retrieval and recommender systems. When the action space is large, decision systems are restricted to a particular structure to complete online queries quickly. This paper addresses the optimization of these large scale decision systems given an arbitrary reward function. We cast this learning problem in a policy optimization framework and propose a new class of policies, born from a novel relaxation of decision functions. This results in a simple, yet efficient learning algorithm that scales to massive action spaces. We compare our method to the commonly adopted Plackett-Luce policy class and demonstrate the effectiveness of our approach on problems with action space sizes in the order of millions.},
  archive      = {J_TMLR},
  author       = {Otmane Sakhi and David Rohde and Nicolas Chopin},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Fast slate policy optimization: Going beyond plackett-luce},
  url          = {https://openreview.net/forum?id=f7a8XCRtUu},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the efficacy of differentially private few-shot image
classification. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=hFsr59Imzm">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been significant recent progress in training differentially private (DP) models which achieve accuracy that approaches the best non-private models. These DP models are typically pretrained on large public datasets and then fine-tuned on private downstream datasets that are relatively large and similar in distribution to the pretraining data. However, in many applications including personalization and federated learning, it is crucial to perform well (i) in the few-shot setting, as obtaining large amounts of labeled data may be problematic; and (ii) on datasets from a wide variety of domains for use in various specialist settings. To understand under which conditions few-shot DP can be effective, we perform an exhaustive set of experiments that reveals how the accuracy and vulnerability to attack of few-shot DP image classification models are affected as the number of shots per class, privacy level, model architecture, downstream dataset, and subset of learnable parameters in the model vary. We show that to achieve DP accuracy on par with non-private models, the shots per class must be increased as the privacy level increases. We also show that learning parameter-efficient FiLM adapters under DP is competitive with learning just the final classifier layer or learning all of the network parameters. Finally, we evaluate DP federated learning systems and establish state-of-the-art performance on the challenging FLAIR benchmark.},
  archive      = {J_TMLR},
  author       = {Marlon Tobaben and Aliaksandra Shysheya and John F Bronskill and Andrew Paverd and Shruti Tople and Santiago Zanella-Beguelin and Richard E Turner and Antti Honkela},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the efficacy of differentially private few-shot image classification},
  url          = {https://openreview.net/forum?id=hFsr59Imzm},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Beyond boundaries: A novel data-augmentation discourse for
open domain generalization. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=jpZmhiIys1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of Open Domain Generalization (ODG) is multifaceted, encompassing shifts in domains and labels across all source and target domains. Existing approaches have encountered challenges such as style bias towards training domains, insufficient feature-space disentanglement to highlight semantic features, and discriminativeness of the latent space. Additionally, they rely on a confidence-based target outlier detection approach, which can lead to misclassifications when target open samples visually align with the source domain data. In response to these challenges, we present a solution named \textsc{ODG-Net}. We aim to create a direct open-set classifier within a \textit{discriminative}, \textit{unbiased}, and \textit{disentangled} semantic embedding space. To enrich data density and diversity, we introduce a generative augmentation framework that produces \textit{style-interpolated} novel domains for closed-set images and novel pseudo-open images by \textit{interpolating the contents of paired training images}. Our augmentation strategy skillfully utilizes \textit{disentangled style and content information} to synthesize images effectively. Furthermore, we tackle the issue of style bias by representing all images in relation to all source domain properties, which effectively accentuates complementary visual features. Consequently, we train a multi-class semantic object classifier, incorporating both closed and open class classification capabilities, along with a style classifier to identify style primitives. The joint use of style and semantic classifiers facilitates the disentanglement of the latent space, thereby enhancing the generalization performance of the semantic classifier. To ensure discriminativeness in both closed and open spaces, we optimize the semantic feature space using novel metric losses. The experimental results on six benchmark datasets convincingly demonstrate that \textsc{ODG-Net} surpasses the state-of-the-art by an impressive margin of $1-4\%$ in both open and closed-set DG scenarios.},
  archive      = {J_TMLR},
  author       = {Shirsha Bose and Ankit Jha and Hitesh Kandala and Biplab Banerjee},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Beyond boundaries: A novel data-augmentation discourse for open domain generalization},
  url          = {https://openreview.net/forum?id=jpZmhiIys1},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Revisiting topic-guided language models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=lXBEwFfxpA">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A recent line of work in natural language processing has aimed to combine language models and topic models. These \textit{topic-guided language models} augment neural language models with topic models, unsupervised learning methods that can discover document-level patterns of word use. This paper compares the effectiveness of these methods in a standardized setting. We study four topic-guided language models and two baselines, evaluating the held-out predictive performance of each model on four corpora. Surprisingly, we find that \textit{none of these methods outperform a standard LSTM language model baseline}, and most fail to learn good topics. Further, we train a probe of the neural language model that shows that the baseline&#39;s hidden states already encode topic information. We make public all code used for this study.},
  archive      = {J_TMLR},
  author       = {Carolina Zheng and Keyon Vafa and David Blei},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Revisiting topic-guided language models},
  url          = {https://openreview.net/forum?id=lXBEwFfxpA},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-supervised single domain generalization with label-free
adversarial data augmentation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=sUlbRfLijj">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain generalization (DG) has attracted increasing attention recently, as it seeks to improve the generalization ability of visual recognition models to unseen target domains. DG leverages multiple source domains for model training, while single domain generalization (SDG) further restricts such setting by exploiting only a single source domain. Nevertheless, both DG and SDG assume that the source domains are fully labeled, which might not be practical in many real world scenarios. In this paper, we present a new problem, i.e., semi-supervised single domain generalization (SS-SDG), which aims to train a model with a partially labeled single source domain to generalize to multiple unseen testing domains. We propose an effective framework to address this problem. In particular, we design a label-free adversarial data augmentation strategy to diversify the source domain, and propose a novel multi-pair FixMatch loss to generalize classifiers to unseen testing domains. Extensive experiments on OfficeHome, PACS and DomainNet20 datasets show that our method surpasses the latest SDG and semi-supervised methods. Moreover, on PACS and DomainNet20, our method approaches the fully supervised ERM upper bound within $5\%$ gap, but only uses less than $8\%$ of the labels.},
  archive      = {J_TMLR},
  author       = {Ronghang Zhu and Xiang Yu and Sheng Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Semi-supervised single domain generalization with label-free adversarial data augmentation},
  url          = {https://openreview.net/forum?id=sUlbRfLijj},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed architecture search over heterogeneous
distributions. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=sY75NqDRk1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is an efficient learning framework that assists distributed machine learning when data cannot be shared with a centralized server. Recent advancements in FL use predefined architecture-based learning for all clients. However, given that clients&#39; data are invisible to the server and data distributions are non-identical across clients, a predefined architecture discovered in a centralized setting may not be an optimal solution for all the clients in FL. Motivated by this challenge, we introduce SPIDER, an algorithmic framework that aims to Search PersonalIzed neural architecture for feDERated learning. SPIDER is designed based on two unique features: (1) alternately optimizing one architecture-homogeneous global model in a generic FL manner and architecture-heterogeneous local models that are connected to the global model by weight-sharing-based regularization, (2) achieving architecture-heterogeneous local models by a perturbation-based neural architecture search method. Experimental results demonstrate superior prediction performance compared with other state-of-the-art personalization methods.},
  archive      = {J_TMLR},
  author       = {Erum Mushtaq and Chaoyang He and Jie Ding and Salman Avestimehr},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Distributed architecture search over heterogeneous distributions},
  url          = {https://openreview.net/forum?id=sY75NqDRk1},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mixture of dynamical variational autoencoders for
multi-source trajectory modeling and separation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=sbkZKBVC31">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a latent-variable generative model called mixture of dynamical variational autoencoders (MixDVAE) to model the dynamics of a system composed of multiple moving sources. A DVAE model is pre-trained on a single-source dataset to capture the source dynamics. Then, multiple instances of the pre-trained DVAE model are integrated into a multi-source mixture model with a discrete observation-to-source assignment latent variable. The posterior distributions of both the discrete observation-to-source assignment variable and the continuous DVAE variables representing the sources content/position are estimated using the variational expectation-maximization algorithm, leading to multi-source trajectories estimation. We illustrate the versatility of the proposed MixDVAE model on two tasks: a computer vision task, namely multi-object tracking, and an audio processing task, namely single-channel audio source separation. Experimental results show that the proposed method works well on these two tasks, and outperforms several baseline methods.},
  archive      = {J_TMLR},
  author       = {Xiaoyu Lin and Laurent Girin and Xavier Alameda-Pineda},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Mixture of dynamical variational autoencoders for multi-source trajectory modeling and separation},
  url          = {https://openreview.net/forum?id=sbkZKBVC31},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detecting danger in gridworlds using gromov’s link
condition. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=t4p612DftO">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gridworlds have been long-utilised in AI research, particularly in reinforcement learning, as they provide simple yet scalable models for many real-world applications such as robot navigation, emergent behaviour, and operations research. We initiate a study of gridworlds using the mathematical framework of reconfigurable systems and state complexes due to Abrams, Ghrist &amp; Peterson. State complexes, a higher-dimensional analogue of state graphs, represent all possible configurations of a system as a single geometric space, thus making them conducive to study using geometric, topological, or combinatorial methods. The main contribution of this work is a modification to the original Abrams, Ghrist &amp; Peterson setup which we introduce to capture agent braiding and thereby more naturally represent the topology of gridworlds. With this modification, the state complexes may exhibit geometric defects (failure of Gromov&#39;s Link Condition). Serendipitously, we discover these failures for agent-only cases occur exactly where undesirable or dangerous states appear in the gridworld. Our results therefore provide a novel method for seeking guaranteed safety limitations in discrete task environments with single or multiple agents, and offer useful safety information (in geometric and topological forms) for incorporation in or analysis of machine learning systems. More broadly, our work introduces tools from geometric group theory and combinatorics to the AI community and demonstrates a proof-of-concept for this geometric viewpoint of the task domain through the example of simple environments.},
  archive      = {J_TMLR},
  author       = {Thomas F Burns and Robert Tang},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Detecting danger in gridworlds using gromov’s link condition},
  url          = {https://openreview.net/forum?id=t4p612DftO},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards a general transfer approach for policy-value
networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=vJcTm2v9Ku">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transferring trained policies and value functions from one task to another, such as one game to another with a different board size, board shape, or more substantial rule changes, is a challenging problem. Popular benchmarks for reinforcement learning (RL), such as Atari games and ProcGen, have limited variety especially in terms of action spaces. Due to a focus on such benchmarks, the development of transfer methods that can also handle changes in action spaces has received relatively little attention. Furthermore, we argue that progress towards more general methods should include benchmarks where new problem instances can be described by domain experts, rather than machine learning experts, using convenient, high-level domain specific languages (DSLs). In addition to enabling end users to more easily describe their problems, user-friendly DSLs also contain relevant task information which can be leveraged to make effective zero-shot transfer plausibly achievable. As an example, we use the Ludii general game system, which includes a highly varied set of over 1000 distinct games described in such a language. We propose a simple baseline approach for transferring fully convolutional policy-value networks, which are used to guide search agents similar to AlphaZero, between any pair of games modelled in this system. Extensive results---including various cases of highly successful zero-shot transfer---are provided for a wide variety of source and target games.},
  archive      = {J_TMLR},
  author       = {Dennis J. N. J. Soemers and Vegard Mella and Eric Piette and Matthew Stephenson and Cameron Browne and Olivier Teytaud},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards a general transfer approach for policy-value networks},
  url          = {https://openreview.net/forum?id=vJcTm2v9Ku},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IndicTrans2: Towards high-quality and accessible machine
translation models for all 22 scheduled indian languages. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=vfT4YuzAYA">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {India has a rich linguistic landscape, with languages from 4 major language families spoken by over a billion people. 22 of these languages listed in the Constitution of India (referred to as scheduled languages) are the focus of this work. Given the linguistic diversity, high-quality and accessible Machine Translation (MT) systems are essential in a country like India. Before this work, there was (i) no parallel training data spanning all 22 languages, (ii) no robust benchmarks covering all these languages and containing content relevant to India, and (iii) no existing translation models that support all 22 scheduled languages of India. In this work, we aim to address this gap by focusing on the missing pieces required for enabling wide, easy, and open access to good machine translation systems for all 22 scheduled Indian languages. We identify four key areas of improvement: curating and creating larger training datasets, creating diverse and high-quality benchmarks, training multilingual models, and releasing models with open access. Our first contribution is the release of the Bharat Parallel Corpus Collection (BPCC), the largest publicly available parallel corpora for Indic languages. BPCC contains a total of 230M bitext pairs, of which a total of 126M were newly added, including 644K manually translated sentence pairs created as part of this work. Our second contribution is the release of the first $n$-way parallel benchmark covering all 22 Indian languages, featuring diverse domains, Indian-origin content, and conversational test sets. Next, we present IndicTrans2, the first translation model to support all 22 languages, surpassing existing models in performance on multiple existing and new benchmarks created as a part of this work. Lastly, to promote accessibility and collaboration, we release our models and associated data with permissive licenses at https://github.com/AI4Bharat/IndicTrans2.},
  archive      = {J_TMLR},
  author       = {Jay Gala and Pranjal A Chitale and A K Raghavan and Varun Gumma and Sumanth Doddapaneni and Aswanth Kumar M and Janki Atul Nawale and Anupama Sujatha and Ratish Puduppully and Vivek Raghavan and Pratyush Kumar and Mitesh M Khapra and Raj Dabre and Anoop Kunchukuttan},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {IndicTrans2: Towards high-quality and accessible machine translation models for all 22 scheduled indian languages},
  url          = {https://openreview.net/forum?id=vfT4YuzAYA},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Local function complexity for active learning via mixture of
gaussian processes. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=w4MoQ39zmc">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inhomogeneities in real-world data, e.g., due to changes in the observation noise level or variations in the structural complexity of the source function, pose a unique set of challenges for statistical inference. Accounting for them can greatly improve predictive power when physical resources or computation time is limited. In this paper, we draw on recent theoretical results on the estimation of local function complexity (LFC), derived from the domain of local polynomial smoothing (LPS), to establish a notion of local structural complexity, which is used to develop a model-agnostic active learning (AL) framework. Due to its reliance on pointwise estimates, the LPS model class is not robust and scalable concerning large input space dimensions that typically come along with real-world problems. Here, we derive and estimate the Gaussian process regression (GPR)-based analog of the LPS-based LFC and use it as a substitute in the above framework to make it robust and scalable. We assess the effectiveness of our LFC estimate in an AL application on a prototypical low-dimensional synthetic dataset, before taking on the challenging real-world task of reconstructing a quantum chemical force field for a small organic molecule and demonstrating state-of-the-art performance with a significantly reduced training demand.},
  archive      = {J_TMLR},
  author       = {Danny Panknin and Stefan Chmiela and Klaus Robert Muller and Shinichi Nakajima},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Local function complexity for active learning via mixture of gaussian processes},
  url          = {https://openreview.net/forum?id=w4MoQ39zmc},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Resmax: An alternative soft-greedy operator for
reinforcement learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=wzzrs5QH5k">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft-greedy operators, namely $\varepsilon$-greedy and softmax, remain a common choice to induce a basic level of exploration for action-value methods in reinforcement learning. These operators, however, have a few critical limitations. In this work, we investigate a simple soft-greedy operator, which we call resmax, that takes actions proportionally to their max action gap: the residual to the estimated maximal value. It is simple to use and ensures coverage of the state-space like $\varepsilon$-greedy, but focuses exploration more on potentially promising actions like softmax. Further, it does not concentrate probability as quickly as softmax, and so better avoids overemphasizing sub-optimal actions that appear high-valued during learning. Additionally, we prove it is a non-expansion for any fixed exploration hyperparameter, unlike the softmax policy which requires a state-action specific temperature to obtain a non-expansion (called mellowmax). We empirically validate that resmax is comparable to or outperforms $\varepsilon$-greedy and softmax across a variety of environments in tabular and deep RL.},
  archive      = {J_TMLR},
  author       = {Erfan Miahi and Revan MacQueen and Alex Ayoub and Abbas Masoumzadeh and Martha White},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Resmax: An alternative soft-greedy operator for reinforcement learning},
  url          = {https://openreview.net/forum?id=wzzrs5QH5k},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Image retrieval outperforms diffusion models on data
augmentation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=xflYdGZMpv">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many approaches have been proposed to use diffusion models to augment training datasets for downstream tasks, such as classification. However, diffusion models are themselves trained on large datasets, often with noisy annotations, and it remains an open question to which extent these models contribute to downstream classification performance. In particular, it remains unclear if they generalize enough to improve over directly using the additional data of their pre-training process for augmentation. We systematically evaluate a range of existing methods to generate images from diffusion models and study new extensions to assess their benefit for data augmentation. Personalizing diffusion models towards the target data outperforms simpler prompting strategies. However, using the pre-training data of the diffusion model alone, via a simple nearest-neighbor retrieval procedure, leads to even stronger downstream performance. Our study explores the potential of diffusion models in generating new training data, and surprisingly finds that these sophisticated models are not yet able to beat a simple and strong image retrieval baseline on simple downstream vision tasks.},
  archive      = {J_TMLR},
  author       = {Max F Burg and Florian Wenzel and Dominik Zietlow and Max Horn and Osama Makansi and Francesco Locatello and Chris Russell},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Image retrieval outperforms diffusion models on data augmentation},
  url          = {https://openreview.net/forum?id=xflYdGZMpv},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modular deep learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=z9EkXfvxta">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning has recently become the dominant paradigm of machine learning. Pre-trained models fine-tuned for downstream tasks achieve better performance with fewer labelled examples. Nonetheless, it remains unclear how to develop models that specialise towards multiple tasks without incurring negative interference and that generalise systematically to non-identically distributed tasks. Modular deep learning has emerged as a promising solution to these challenges. In this framework, units of computation are often implemented as autonomous parameter-efficient modules. Information is conditionally routed to a subset of modules and subsequently aggregated. These properties enable positive transfer and systematic generalisation by separating computation from routing and updating modules locally. We offer a survey of modular architectures, providing a unified view over several threads of research that evolved independently in the scientific literature. Moreover, we explore various additional purposes of modularity, including scaling language models, causal inference and discovery, programme simulation, and hierarchical reinforcement learning. Finally, we report various concrete applications where modularity has been successfully deployed such as cross-lingual and cross-modal knowledge transfer.},
  archive      = {J_TMLR},
  author       = {Jonas Pfeiffer and Sebastian Ruder and Ivan Vulić and Edoardo Ponti},
  journal      = {Transactions on Machine Learning Research},
  month        = {12},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Modular deep learning},
  url          = {https://openreview.net/forum?id=z9EkXfvxta},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved identification accuracy in equation learning via
comprehensive <span
class="math inline"><strong>R</strong><sup><strong>2</strong></sup></span>-elimination
and bayesian model selection. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=0ck7hJ8EVC">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of equation learning, exhaustively considering all possible combinations derived from a basis function dictionary is infeasible. Sparse regression and greedy algorithms have emerged as popular approaches to tackle this challenge. However, the presence of strong collinearities poses difficulties for sparse regression techniques, and greedy steps may inadvertently exclude important components of the true equation, leading to reduced identification accuracy. In this article, we present a novel algorithm that strikes a balance between comprehensiveness and efficiency in equation learning. Inspired by stepwise regression, our approach combines the coefficient of determination, $R^2$, and the Bayesian model evidence, $p(y|\mathcal{M})$, in a novel way. Through three extensive numerical experiments involving random polynomials and dynamical systems, we compare our method against two standard approaches, four state-of-the-art methods, and bidirectional stepwise regression incorporating $p(y|\mathcal{M})$. The results demonstrate that our less greedy algorithm surpasses all other methods in terms of identification accuracy. Furthermore, we discover a heuristic approach to mitigate the overfitting penalty associated with $R^2$ and propose an equation learning procedure solely based on $R^2$, which achieves high rates of exact equation recovery.},
  archive      = {J_TMLR},
  author       = {Daniel Nickelsen and Bubacarr Bah},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Improved identification accuracy in equation learning via comprehensive $\boldsymbol{R^2}$-elimination and bayesian model selection},
  url          = {https://openreview.net/forum?id=0ck7hJ8EVC},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring transformer backbones for heterogeneous treatment
effect estimation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=1kl4YM2Q7P">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous works on Treatment Effect Estimation (TEE) are not in widespread use because they are predominantly theoretical, where strong parametric assumptions are made but untractable for practical application. Recent works use Multilayer Perceptron (MLP) for modeling casual relationships, however, MLPs lag far behind recent advances in ML methodology, which limits their applicability and generalizability. To extend beyond the single domain formulation and towards more realistic learning scenarios, we explore model design spaces beyond MLPs, i.e., transformer backbones, which provide flexibility where attention layers govern interactions among treatments and covariates to exploit structural similarities of potential outcomes for confounding control. Through careful model design, Transformers as Treatment Effect Estimators (TransTEE) is proposed. We show empirically that TransTEE can: (1) serve as a general-purpose treatment effect estimator which significantly outperforms competitive baselines on a variety of challenging TEE problems (e.g., discrete, continuous, structured, or dosage-associated treatments.) and is applicable to both when covariates are tabular and when they consist of structural data (e.g., texts, graphs); (2) yield multiple advantages: compatibility with propensity score modeling, parameter efficiency, robustness to continuous treatment value distribution shifts, explainable in covariate adjustment, and real-world utility in auditing pre-trained language models.},
  archive      = {J_TMLR},
  author       = {YiFan Zhang and Hanlin Zhang and Zachary Chase Lipton and Li Erran Li and Eric Xing},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Exploring transformer backbones for heterogeneous treatment effect estimation},
  url          = {https://openreview.net/forum?id=1kl4YM2Q7P},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Invertible hierarchical generative model for images.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=4rkKN4tM63">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Normalizing flows (NFs) as generative models enjoy desirable properties such as exact invertibility and exact likelihood evaluation, while being efficient to sample from. These properties, however, come at the cost of heavy restrictions on the architecture. Due to these limitations, modeling multi-modal probability distributions can yield poor results even with low-dimensional data. Additionally, typical flow architectures employed on real image datasets produce samples with visible aliasing artifacts and limited variation. The latent decomposition of flow-models also falls short on that of competing methods, with uneven contribution to a decoded image. In this work we build an invertible generative model using conditional normalizing flows in a hierarchical fashion to circumvent the aforementioned limitations. We show that we can achieve superior sample quality among flow-based models with fewer parameters compared to the state of the art. We demonstrate ability to control individual levels of detail via the latent decomposition of our model.},
  archive      = {J_TMLR},
  author       = {Heikki Timonen and Miika Aittala and Jaakko Lehtinen},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Invertible hierarchical generative model for images},
  url          = {https://openreview.net/forum?id=4rkKN4tM63},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Achieving risk control in online learning settings.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=5Y04GWvoJu">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To provide rigorous uncertainty quantification for online learning models, we develop a framework for constructing uncertainty sets that provably control risk---such as coverage of confidence intervals, false negative rate, or F1 score---in the online setting. This extends conformal prediction to apply to a larger class of online learning problems. Our method guarantees risk control at any user-specified level even when the underlying data distribution shifts drastically, even adversarially, over time in an unknown fashion. The technique we propose is highly flexible as it can be applied with any base online learning algorithm (e.g., a deep neural network trained online), requiring minimal implementation effort and essentially zero additional computational cost. We further extend our approach to control multiple risks simultaneously, so the prediction sets we generate are valid for all given risks. To demonstrate the utility of our method, we conduct experiments on real-world tabular time-series data sets showing that the proposed method rigorously controls various natural risks. Furthermore, we show how to construct valid intervals for an online image-depth estimation problem that previous sequential calibration schemes cannot handle.},
  archive      = {J_TMLR},
  author       = {Shai Feldman and Liran Ringel and Stephen Bates and Yaniv Romano},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Achieving risk control in online learning settings},
  url          = {https://openreview.net/forum?id=5Y04GWvoJu},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). One-round active learning through data utility learning and
proxy models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=8HQCOMRa7g">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While active learning (AL) techniques have demonstrated the potential to produce high-performance models with fewer labeled data, their application remains limited due to the necessity for multiple rounds of interaction with annotators. This paper studies the problem of one-round AL, which aims at selecting a subset of unlabeled points and querying their labels \emph{all at once}. A fundamental challenge is how to measure the utility of different choices of labeling queries for learning a target model. Our key idea is to learn such a utility metric from a small initial labeled set. We demonstrate that our approach leads to state-of-the-art performance on various AL benchmarks and is more robust to the lack of initial labeled data. In addition to algorithmic development and evaluation, we introduce a novel metric for quantifying `\emph{utility transferability}&#39; -- the degree of correlation between the performance changes of two learning algorithms due to variations in training data selection. Previous studies have often observed a notable utility transferability between models, even those with differing complexities. Such transferability enabled our approach, as well as other techniques such as coresets, hyperparameter tuning, and data valuation, to scale up to more sophisticated target models by substituting them with smaller proxy models. Nevertheless, utility transferability has not yet been rigorously defined within a formal mathematical framework, a gap that our work addresses innovatively. We further propose two Monte Carlo-based methods for efficiently comparing utility transferability for different proxy models, thereby facilitating a more informed selection of proxy models.},
  archive      = {J_TMLR},
  author       = {Jiachen T. Wang and Si Chen and Ruoxi Jia},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {One-round active learning through data utility learning and proxy models},
  url          = {https://openreview.net/forum?id=8HQCOMRa7g},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Meta continual learning on graphs with experience replay.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=8tnrh56P5W">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual learning is a machine learning approach where the challenge is that a constructed learning model executes incoming tasks while maintaining its performance over the earlier tasks. In order to address this issue, we devise a technique that combines two uniquely important concepts in machine learning, namely &quot;replay buffer&quot; and &quot;meta learning&quot;, aiming to exploit the best of two worlds. In this method, the model weights are initially computed by using the current task dataset. Next, the dataset of the current task is merged with the stored samples from the earlier tasks and the model weights are updated using the combined dataset. This aids in preventing the model weights converging to the optimal parameters of the current task and enables the preservation of information from earlier tasks. We choose to adapt our technique to graph data structure and the task of node classification on graphs. We introduce MetaCLGraph, which outperforms the baseline methods over various graph datasets including Citeseer, Corafull, Arxiv, and Reddit. This method illustrates the potential of combining replay buffer and meta learning in the field of continual learning on graphs.},
  archive      = {J_TMLR},
  author       = {Altay Unal and Abdullah Akgül and Melih Kandemir and Gozde Unal},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Meta continual learning on graphs with experience replay},
  url          = {https://openreview.net/forum?id=8tnrh56P5W},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online model selection by learning how compositional kernels
evolve. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=23WZFQBUh5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the need for efficient, personalized learning in health, we investigate the problem of online compositional kernel selection for multi-task Gaussian Process regression. Existing composition selection methods do not satisfy our strict criteria in health; selection must occur quickly, and the selected kernels must maintain the appropriate level of complexity, sparsity, and stability as data arrives online. We introduce the Kernel Evolution Model (KEM), a generative process on how to evolve kernel compositions in a way that manages the bias--variance trade-off as we observe more data about a user. Using pilot data, we learn a set of kernel evolutions that can be used to quickly select kernels for new test users. KEM reliably selects high-performing kernels for a range of synthetic and real data sets, including two health data sets.},
  archive      = {J_TMLR},
  author       = {Eura Shin and Predrag Klasnja and Susan Murphy and Finale Doshi-Velez},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Online model selection by learning how compositional kernels evolve},
  url          = {https://openreview.net/forum?id=23WZFQBUh5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stochastic mirror descent: Convergence analysis and adaptive
variants via the mirror stochastic polyak stepsize. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=28bQiPWxHl">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the convergence of stochastic mirror descent (SMD) under interpolation in relatively smooth and smooth convex optimization. In relatively smooth convex optimization we provide new convergence guarantees for SMD with a constant stepsize. For smooth convex optimization we propose a new adaptive stepsize scheme --- the mirror stochastic Polyak stepsize (mSPS). Notably, our convergence results in both settings do not make bounded gradient assumptions or bounded variance assumptions, and we show convergence to a neighborhood that vanishes under interpolation. Consequently, these results correspond to the first convergence guarantees under interpolation for the exponentiated gradient algorithm for fixed or adaptive stepsizes. mSPS generalizes the recently proposed stochastic Polyak stepsize (SPS) (Loizou et al. 2021) to mirror descent and remains both practical and efficient for modern machine learning applications while inheriting the benefits of mirror descent. We complement our results with experiments across various supervised learning tasks and different instances of SMD, demonstrating the effectiveness of mSPS.},
  archive      = {J_TMLR},
  author       = {Ryan D&#39;Orazio and Nicolas Loizou and Issam H. Laradji and Ioannis Mitliagkas},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Stochastic mirror descent: Convergence analysis and adaptive variants via the mirror stochastic polyak stepsize},
  url          = {https://openreview.net/forum?id=28bQiPWxHl},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Minorization-maximization for learning determinantal point
processes. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=65AzNvY73Q">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A determinantal point process (DPP) is a powerful probabilistic model that generates diverse random subsets from a ground set. Since a DPP is characterized by a positive definite kernel, a DPP on a finite ground set can be parameterized by a kernel matrix. Recently, DPPs have gained attention in the machine learning community and have been applied to various practical problems; however, there is still room for further research on the learning of DPPs. In this paper, we propose a simple learning rule for full-rank DPPs based on a minorization-maximization (MM) algorithm, which monotonically increases the likelihood in each iteration. We show that our minorizer of the MM algorithm provides a tighter lower-bound compared to an existing method locally. We also generalize the algorithm for further acceleration. In our experiments on both synthetic and real-world datasets, our method outperforms existing methods in most settings. Our code is available at https://github.com/ISMHinoLab/DPPMMEstimation.},
  archive      = {J_TMLR},
  author       = {Takahiro Kawashima and Hideitsu Hino},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Minorization-maximization for learning determinantal point processes},
  url          = {https://openreview.net/forum?id=65AzNvY73Q},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Replay-enhanced continual reinforcement learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=91hfMEUukm">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Replaying past experiences has proven to be a highly effective approach for averting catastrophic forgetting in supervised continual learning. However, some crucial factors are still largely ignored, making it vulnerable to serious failure, when used as a solution to forgetting in continual reinforcement learning, even in the context of perfect memory where all data of previous tasks are accessible in the current task. On the one hand, since most reinforcement learning algorithms are not invariant to the reward scale, the previously well-learned tasks (with high rewards) may appear to be more salient to the current learning process than the current task (with small initial rewards). This causes the agent to concentrate on those salient tasks at the expense of generality on the current task. On the other hand, offline learning on replayed tasks while learning a new task may induce a distributional shift between the dataset and the learned policy on old tasks, resulting in forgetting. In this paper, we introduce RECALL, a replay-enhanced method that greatly improves the plasticity of existing replay-based methods on new tasks while effectively avoiding the recurrence of catastrophic forgetting in continual reinforcement learning. RECALL leverages adaptive normalization on approximate targets and policy distillation on old tasks to enhance generality and stability, respectively. Extensive experiments on the Continual World benchmark show that RECALL performs significantly better than purely perfect memory replay, and achieves comparable or better overall performance against state-of-the-art continual learning methods.},
  archive      = {J_TMLR},
  author       = {Tiantian Zhang and Kevin Zehua Shen and Zichuan Lin and Bo Yuan and Xueqian Wang and Xiu Li and Deheng Ye},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Replay-enhanced continual reinforcement learning},
  url          = {https://openreview.net/forum?id=91hfMEUukm},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Invariant structure learning for better generalization and
causal explainability. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=A9yn7KTwsK">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning the causal structure behind data is invaluable for improving generalization and ob- taining high-quality explanations. Towards this end, we propose a novel framework, Invariant Structure Learning (ISL), that is designed to improve causal structure discovery by utilizing generalization as an indication in the process. ISL splits the data into different environments, and learns a structure that is invariant to the target across different environments by imposing a consistency constraint. The proposed aggregation mechanism then selects the classifier based on a graph structure that reflects the causal mechanisms in the data more accurately compared to the structures learnt from individual environments. Furthermore, we extend ISL to a self-supervised learning setting, where accurate causal structure discovery does not rely on any labels. Self-supervised ISL utilizes proposals for invariant causality, by iteratively setting different nodes as targets. On synthetic and real-world datasets, we demonstrate that ISL accurately discovers the causal structure, outperforms alternative methods, and yields superior generalization for datasets with significant distribution shifts.},
  archive      = {J_TMLR},
  author       = {Yunhao Ge and Sercan O Arik and Jinsung Yoon and Ao Xu and Laurent Itti and Tomas Pfister},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Invariant structure learning for better generalization and causal explainability},
  url          = {https://openreview.net/forum?id=A9yn7KTwsK},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Offline reinforcement learning with additional covering
distributions. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=AfXq3x3X16">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study learning optimal policies from a logged dataset, i.e., offline RL, with function general approximation. Despite the efforts devoted, existing algorithms with theoretic finite-sample guarantees typically assume exploratory data coverage or strong realizable function classes (e.g., Bellman-completeness), which is hard to be satisfied in reality. While there are recent works that successfully tackle these strong assumptions, they either require the gap assumptions that could only be satisfied by part of MDPs or use the behavior regularization that makes the optimality of learned policy even intractable. To solve this challenge, we provide finite-sample guarantees for a simple algorithm based on marginalized importance sampling (MIS), showing that sample-efficient offline RL for general MDPs is possible with only a partial coverage dataset (instead of assuming a dataset covering all possible policies) and weak realizable function classes (assuming function classes containing simply one function) given additional side information of a covering distribution. We demonstrate that the covering distribution trades off prior knowledge of the optimal trajectories against the coverage requirement of the dataset, revealing the effect of this inductive bias in the learning processes. Furthermore, when considering the exploratory dataset, our analysis shows that only realizable function classes are enough for learning near-optimal policies, even with no side information on the additional coverage distributions.},
  archive      = {J_TMLR},
  author       = {Chenjie Mao},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Offline reinforcement learning with additional covering distributions},
  url          = {https://openreview.net/forum?id=AfXq3x3X16},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Provably personalized and robust federated learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=B0uBSSUy0G">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering clients with similar objectives and learning a model per cluster is an intuitive and interpretable approach to personalization in federated learning. However, doing so with provable and optimal guarantees has remained an open challenge. In this work, we formalize personalized federated learning as a stochastic optimization problem. We propose simple clustering-based algorithms which iteratively identify and train within clusters, using local client gradients. Our algorithms have optimal convergence rates which asymptotically match those obtained if we knew the true underlying clustering of the clients, and are provably robust in the Byzantine setting where some fraction of the clients are malicious.},
  archive      = {J_TMLR},
  author       = {Mariel Werner and Lie He and Michael Jordan and Martin Jaggi and Sai Praneeth Karimireddy},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Provably personalized and robust federated learning},
  url          = {https://openreview.net/forum?id=B0uBSSUy0G},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using representation expressiveness and learnability to
evaluate self-supervised learning methods. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=BxdrpnRHNh">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of evaluating the quality of self-supervised learning (SSL) models without access to supervised labels, while being agnostic to the architecture, learning algorithm or data manipulation used during training. We argue that representations can be evaluated through the lens of expressiveness and learnability. We propose to use the Intrinsic Dimension (ID) to assess expressiveness and introduce Cluster Learnability (CL) to assess learnability. CL is measured in terms of the performance of a KNN classifier trained to predict labels obtained by clustering the representations with K-means. We thus combine CL and ID into a single predictor – CLID. Through a large-scale empirical study with a diverse family of SSL algorithms, we find that CLID better correlates with in-distribution model performance than other competing recent evaluation schemes. We also benchmark CLID on out-of-domain generalization, where CLID serves as a predictor of the transfer performance of SSL models on several visual classification tasks, yielding improvements with respect to the competing baselines.},
  archive      = {J_TMLR},
  author       = {Yuchen Lu and Zhen Liu and Aristide Baratin and Romain Laroche and Aaron Courville and Alessandro Sordoni},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Using representation expressiveness and learnability to evaluate self-supervised learning methods},
  url          = {https://openreview.net/forum?id=BxdrpnRHNh},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Training DNNs resilient to adversarial and random bit-flips
by learning quantization ranges. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=BxjHMPwZIH">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Promoting robustness in deep neural networks (DNNs) is crucial for their reliable deployment in uncertain environments, such as low-power settings or in the presence of adversarial attacks. In particular, bit-flip weight perturbations in quantized networks can significantly degrade performance, underscoring the need to improve DNN resilience. In this paper, we introduce a training mechanism to learn the quantization range of different DNN layers to enhance DNN robustness against bit-flip errors on the model parameters. The proposed approach, called weight clipping-aware training (WCAT), minimizes the quantization range while preserving performance, striking a balance between the two. Our experimental results on different models and datasets showcase that DNNs trained with WCAT can tolerate a high amount of noise while keeping the accuracy close to the baseline model. Moreover, we show that our method significantly enhances DNN robustness against adversarial bit-flip attacks. Finally, when considering the energy-reliability trade-off inherent in on-chip SRAM memories, we observe that WCAT consistently improves the Pareto frontier of test accuracy and energy consumption across diverse models.},
  archive      = {J_TMLR},
  author       = {Kamran Chitsaz and Goncalo Mordido and Jean-Pierre David and François Leduc-Primeau},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Training DNNs resilient to adversarial and random bit-flips by learning quantization ranges},
  url          = {https://openreview.net/forum?id=BxjHMPwZIH},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Synthetic data from diffusion models improves ImageNet
classification. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=DlRsoxjyPm">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep generative models are becoming increasingly powerful, now generating diverse, high fidelity, photo-realistic samples given text prompts. Nevertheless, samples from such models have not been shown to significantly improve model training for challenging and well-studied discriminative tasks like ImageNet classification. In this paper we show that augmenting the ImageNet training set with samples from a generative diffusion model can yield substantial improvements in ImageNet classification accuracy over strong ResNet and Vision Transformer baselines. To this end we explore the fine-tuning of large-scale text-to-image diffusion models, yielding class-conditional ImageNet models with state-of-the-art FID score (1.76 at 256×256 resolution) and Inception Score (239 at 256×256). The model also yields a new state-of-the-art in Classification Accuracy Scores, i.e., ImageNet test accuracy for a ResNet-50 architecture trained solely on synthetic data (64.96 top-1 accuracy for 256×256 samples, improving to 69.24 for 1024×1024 samples). Adding up to three times as many synthetic samples as real training samples consistently improves ImageNet classification accuracy across multiple architectures.},
  archive      = {J_TMLR},
  author       = {Shekoofeh Azizi and Simon Kornblith and Chitwan Saharia and Mohammad Norouzi and David J. Fleet},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Synthetic data from diffusion models improves ImageNet classification},
  url          = {https://openreview.net/forum?id=DlRsoxjyPm},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NOFLITE: Learning to predict individual treatment effect
distributions. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=EjqopDxLbG">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the effect of a treatment on an individual&#39;s outcome of interest is an important challenge in various fields, such as healthcare, economics, marketing, and education. Previous work in machine learning has focused on estimating the expected value of the treatment effect. However, effective personalized decision-making requires more than just the treatment expected effect; it requires knowing the entire treatment effect distribution. Knowing this distribution allows analyzing the treatment&#39;s expected utility or quantifying the uncertainty regarding a treatment&#39;s effect. This information is essential for prescribing optimal treatments. The ability of a model to predict accurate individual treatment effect distributions is captured by its likelihood. In light of this, we propose a novel neural architecture, NOFLITE, that uses normalizing flows to directly optimize this likelihood, while simultaneously learning flexible estimates of the individual treatment effect distribution. Experiments on various semi-synthetic data sets show that NOFLITE outperforms existing methods in terms of loglikelihood. Moreover, we illustrate how the predicted distributions can enable an in-depth analysis of the treatment effect and more accurate decision-making.},
  archive      = {J_TMLR},
  author       = {Toon Vanderschueren and Jeroen Berrevoets and Wouter Verbeke},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {NOFLITE: Learning to predict individual treatment effect distributions},
  url          = {https://openreview.net/forum?id=EjqopDxLbG},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RCT rejection sampling for causal estimation evaluation.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=F74ZZk5hPa">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Confounding is a significant obstacle to unbiased estimation of causal effects from observational data. For settings with high-dimensional covariates---such as text data, genomics, or the behavioral social sciences---researchers have proposed methods to adjust for confounding by adapting machine learning methods to the goal of causal estimation. However, empirical evaluation of these adjustment methods has been challenging and limited. In this work, we build on a promising empirical evaluation strategy that simplifies evaluation design and uses real data: subsampling randomized controlled trials (RCTs) to create confounded observational datasets while using the average causal effects from the RCTs as ground-truth. We contribute a new sampling algorithm, which we call RCT rejection sampling, and provide theoretical guarantees that causal identification holds in the observational data to allow for valid comparisons to the ground-truth RCT. Using synthetic data, we show our algorithm indeed results in low bias when oracle estimators are evaluated on the confounded samples, which is not always the case for a previously proposed algorithm. In addition to this identification result, we highlight several finite data considerations for evaluation designers who plan to use RCT rejection sampling on their own datasets. As a proof of concept, we implement an example evaluation pipeline and walk through these finite data considerations with a novel, real-world RCT---which we release publicly---consisting of approximately 70k observations and text data as high-dimensional covariates. Together, these contributions build towards a broader agenda of improved empirical evaluation for causal estimation.},
  archive      = {J_TMLR},
  author       = {Katherine A. Keith and Sergey Feldman and David Jurgens and Jonathan Bragg and Rohit Bhattacharya},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {RCT rejection sampling for causal estimation evaluation},
  url          = {https://openreview.net/forum?id=F74ZZk5hPa},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DP-LFlow: Differentially private latent flow for scalable
sensitive image generation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=GEcneTl9Mk">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy concerns grow with the success of modern deep learning models, especially when the training set contains sensitive data. Differentially private generative model (DPGM) can serve as a solution to circumvent such concerns by generating data that are distributionally similar to the original data yet with differential privacy (DP) guarantees. While GAN has attracted major attention, existing DPGMs based on flow generative models are limited and only developed on low-dimensional tabular datasets. The capability of exact density estimation makes the flow model exceptional when density estimation is of interest. In this work, we will first show that it is challenging (or even infeasible) to train a DP-flow via DP-SGD, i.e. the workhorse algorithm for private deep learning, on high-dimensional image sets with acceptable utility, and then we give an effective solution by reducing the generation from the pixel space to a lower dimensional latent space. We show the effectiveness and scalability of the proposed method via extensive experiments, where the proposed method achieves a significantly better privacy-utility trade-off compared to existing alternatives. Notably, our method is the first DPGM to scale to high-resolution image sets (up to 256 × 256). Our code is available at https://github.com/dihjiang/DP-LFlow.},
  archive      = {J_TMLR},
  author       = {Dihong Jiang and Sun Sun},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DP-LFlow: Differentially private latent flow for scalable sensitive image generation},
  url          = {https://openreview.net/forum?id=GEcneTl9Mk},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MERMAIDE: Learning to align learners using model-based
meta-learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=H5VRvCXCzf">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study how a principal can efficiently and effectively intervene on the rewards of a previously unseen learning agent in order to induce desirable outcomes. This is relevant to many real-world settings like auctions or taxation, where the principal may not know the learning behavior nor the rewards of real people. Moreover, the principal should be few-shot adaptable and minimize the number of interventions, because interventions are often costly. We introduce MERMAIDE, a model-based meta-learning framework to train a principal that can quickly adapt to out-of-distribution agents with different learning strategies and reward functions. We validate this approach step-by-step. First, in a Stackelberg setting with a best-response agent, we show that meta-learning enables quick convergence to the theoretically known Stackelberg equilibrium at test time, although noisy observations severely increase the sample complexity. We then show that our model-based meta-learning approach is cost-effective in intervening on bandit agents with unseen explore-exploit strategies. Finally, we outperform baselines that use either meta-learning or agent behavior modeling, in both $0$-shot and $1$-shot settings with partial agent information.},
  archive      = {J_TMLR},
  author       = {Arundhati Banerjee and Soham Rajesh Phade and Stefano Ermon and Stephan Zheng},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {MERMAIDE: Learning to align learners using model-based meta-learning},
  url          = {https://openreview.net/forum?id=H5VRvCXCzf},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Conditional sampling of variational autoencoders via
iterated approximate ancestral sampling. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=I5sJ6PU6JN">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional sampling of variational autoencoders (VAEs) is needed in various applications, such as missing data imputation, but is computationally intractable. A principled choice for asymptotically exact conditional sampling is Metropolis-within-Gibbs (MWG). However, we observe that the tendency of VAEs to learn a structured latent space, a commonly desired property, can cause the MWG sampler to get “stuck” far from the target distribution. This paper mitigates the limitations of MWG: we systematically outline the pitfalls in the context of VAEs, propose two original methods that address these pitfalls, and demonstrate an improved performance of the proposed methods on a set of sampling tasks.},
  archive      = {J_TMLR},
  author       = {Vaidotas Simkus and Michael U. Gutmann},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Conditional sampling of variational autoencoders via iterated approximate ancestral sampling},
  url          = {https://openreview.net/forum?id=I5sJ6PU6JN},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bridging the gap between offline and online reinforcement
learning evaluation methodologies. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=J3veZdVpts">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) has shown great promise with algorithms learning in environments with large state and action spaces purely from scalar reward signals. A crucial challenge for current deep RL algorithms is that they require a tremendous amount of environment interactions for learning. This can be infeasible in situations where such interactions are expensive, such as in robotics. Offline RL algorithms try to address this issue by bootstrapping the learning process from existing logged data without needing to interact with the environment from the very beginning. While online RL algorithms are typically evaluated as a function of the number of environment interactions, there isn&#39;t a single established protocol for evaluating offline RL methods. In this paper, we propose a sequential approach to evaluate offline RL algorithms as a function of the training set size and thus by their data efficiency. Sequential evaluation provides valuable insights into the data efficiency of the learning process and the robustness of algorithms to distribution changes in the dataset while also harmonizing the visualization of the offline and online learning phases. Our approach is generally applicable and easy to implement. We compare several existing offline RL algorithms using this approach and present insights from a variety of tasks and offline datasets.},
  archive      = {J_TMLR},
  author       = {Shivakanth Sujit and Pedro Braga and Jorg Bornschein and Samira Ebrahimi Kahou},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bridging the gap between offline and online reinforcement learning evaluation methodologies},
  url          = {https://openreview.net/forum?id=J3veZdVpts},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finding neurons in a haystack: Case studies with sparse
probing. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=JYs1R9IMJr">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite rapid adoption and deployment of large language models (LLMs), the internal computations of these models remain opaque and poorly understood. In this work, we seek to understand how high-level human-interpretable features are represented within the internal neuron activations of LLMs. We train $k$-sparse linear classifiers (probes) on these internal activations to predict the presence of features in the input; by varying the value of $k$ we study the sparsity of learned representations and how this varies with model scale. With $k=1$, we localize individual neurons that are highly relevant for a particular feature and perform a number of case studies to illustrate general properties of LLMs. In particular, we show that early layers make use of sparse combinations of neurons to represent many features in superposition, that middle layers have seemingly dedicated neurons to represent higher-level contextual features, and that increasing scale causes representational sparsity to increase on average, but there are multiple types of scaling dynamics. In all, we probe for over 100 unique features comprising 10 different categories in 7 different models spanning 70 million to 6.9 billion parameters.},
  archive      = {J_TMLR},
  author       = {Wes Gurnee and Neel Nanda and Matthew Pauly and Katherine Harvey and Dmitrii Troitskii and Dimitris Bertsimas},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Finding neurons in a haystack: Case studies with sparse probing},
  url          = {https://openreview.net/forum?id=JYs1R9IMJr},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The (un)scalability of informed heuristic function
estimation in NP-hard search problems. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=JllRdycmLk">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The A* algorithm is commonly used to solve NP-hard combinatorial optimization problems. When provided with a completely informed heuristic function, A* can solve such problems in time complexity that is polynomial in the solution cost and branching factor. In light of this fact, we examine a line of recent publications that propose fitting deep neural networks to the completely informed heuristic function. We assert that these works suffer from inherent scalability limitations since --- under the assumption of NP $\not \subseteq$ P/poly --- such approaches result in either (a) network sizes that scale super-polynomially in the instance sizes or (b) the accuracy of the fitted deep neural networks scales inversely with the instance sizes. Complementing our theoretical claims, we provide experimental results for three representative NP-hard search problems. The results suggest that fitting deep neural networks to informed heuristic functions requires network sizes that grow quickly with the problem instance size. We conclude by suggesting that the research community should focus on scalable methods for integrating heuristic search with machine learning, as opposed to methods relying on informed heuristic estimation.},
  archive      = {J_TMLR},
  author       = {Sumedh Pendurkar and Taoan Huang and Brendan Juba and Jiapeng Zhang and Sven Koenig and Guni Sharon},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The (Un)Scalability of informed heuristic function estimation in NP-hard search problems},
  url          = {https://openreview.net/forum?id=JllRdycmLk},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Uncovering unique concept vectors through latent space
decomposition. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=LT4DXqUJTD">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interpreting the inner workings of deep learning models is crucial for establishing trust and ensuring model safety. Concept-based explanations have emerged as a superior approach that is more interpretable than feature attribution estimates such as pixel saliency. However, defining the concepts for the interpretability analysis biases the explanations by the user’s expectations on the concepts. To address this, we propose a novel post-hoc unsupervised method that automatically uncovers the concepts learned by deep models during training. By decomposing the latent space of a layer in singular vectors and refining them by unsupervised clustering, we uncover concept vectors aligned with directions of high variance that are relevant to the model prediction, and that point to semantically distinct concepts. Our extensive experiments reveal that the majority of our concepts are readily understandable to humans, exhibit coherency, and bear relevance to the task at hand. Moreover, we showcase the practical utility of our method in dataset exploration, where our concept vectors successfully identify outlier training samples affected by various confounding factors. This novel exploration technique has remarkable versatility to data types and model architectures and it will facilitate the identification of biases and the discovery of sources of error within training data.},
  archive      = {J_TMLR},
  author       = {Mara Graziani and Laura O&#39;Mahony and An-phi Nguyen and Henning Müller and Vincent Andrearczyk},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Uncovering unique concept vectors through latent space decomposition},
  url          = {https://openreview.net/forum?id=LT4DXqUJTD},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SIESTA: Efficient online continual learning with sleep.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=MqDVlBWRRV">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In supervised continual learning, a deep neural network (DNN) is updated with an ever-growing data stream. Unlike the offline setting where data is shuffled, we cannot make any distributional assumptions about the data stream. Ideally, only one pass through the dataset is needed for computational efficiency. However, existing methods are inadequate and make many assumptions that cannot be made for real-world applications, while simultaneously failing to improve computational efficiency. In this paper, we propose a novel continual learning method, SIESTA based on wake/sleep framework for training, which is well aligned to the needs of on-device learning. The major goal of SIESTA is to advance compute efficient continual learning so that DNNs can be updated efficiently using far less time and energy. The principal innovations of SIESTA are: 1) rapid online updates using a rehearsal-free, backpropagation-free, and data-driven network update rule during its wake phase, and 2) expedited memory consolidation using a compute-restricted rehearsal policy during its sleep phase. For memory efficiency, SIESTA adapts latent rehearsal using memory indexing from REMIND. Compared to REMIND and prior arts, SIESTA is far more computationally efficient, enabling continual learning on ImageNet-1K in under 2 hours on a single GPU; moreover, in the augmentation-free setting it matches the performance of the offline learner, a milestone critical to driving adoption of continual learning in real-world applications.},
  archive      = {J_TMLR},
  author       = {Md Yousuf Harun and Jhair Gallardo and Tyler L. Hayes and Ronald Kemker and Christopher Kanan},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SIESTA: Efficient online continual learning with sleep},
  url          = {https://openreview.net/forum?id=MqDVlBWRRV},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Latent state models of training dynamics. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=NE2xXWo0LF">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The impact of randomness on model training is poorly understood. How do differences in data order and initialization actually manifest in the model, such that some training runs outperform others or converge faster? Furthermore, how can we interpret the resulting training dynamics and the phase transitions that characterize different trajectories? To understand the effect of randomness on the dynamics and outcomes of neural network training, we train models multiple times with different random seeds and compute a variety of metrics throughout training, such as the $L_2$ norm, mean, and variance of the neural network&#39;s weights. We then fit a hidden Markov model (HMM) over the resulting sequences of metrics. The HMM represents training as a stochastic process of transitions between latent states, providing an intuitive overview of significant changes during training. Using our method, we produce a low-dimensional, discrete representation of training dynamics on grokking tasks, image classification, and masked language modeling. We use the HMM representation to study phase transitions and identify latent &quot;detour&quot; states that slow down convergence.},
  archive      = {J_TMLR},
  author       = {Michael Y. Hu and Angelica Chen and Naomi Saphra and Kyunghyun Cho},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Latent state models of training dynamics},
  url          = {https://openreview.net/forum?id=NE2xXWo0LF},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-free diversity-based ensemble selection for one-shot
federated learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ORMlg4g3mG">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emerging availability of various machine learning models creates a great demand to harness the collective intelligence of many independently well-trained models to improve overall performance. Considering the privacy concern and non-negligible communication costs, one-shot federated learning and ensemble learning in a data-free manner attract significant attention. However, conventional ensemble selection approaches are neither training efficient nor applicable to federated learning due to the risk of privacy leakage from local clients; meanwhile, the &quot;many could be better than all&quot; principle under data-free constraints makes it even more challenging. Therefore, it becomes crucial to design an effective ensemble selection strategy to find a good subset of the base models as the ensemble team for the federated learning scenario. In this paper, we propose a novel data-free diversity-based framework, DeDES, to address the ensemble selection problem with diversity consideration for models under the one-shot federated learning setting. Experimental results show that our method can achieve both better performance and higher efficiency over 5 datasets, 4 different model structures, and both homogeneous and heterogeneous model groups under four different data-partition strategies.},
  archive      = {J_TMLR},
  author       = {Naibo Wang and Wenjie Feng and yuchen deng and Moming Duan and Fusheng Liu and See-Kiong Ng},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Data-free diversity-based ensemble selection for one-shot federated learning},
  url          = {https://openreview.net/forum?id=ORMlg4g3mG},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learn the time to learn: Replay scheduling in continual
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Q4aAITDgdP">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Replay methods are known to be successful at mitigating catastrophic forgetting in continual learning scenarios despite having limited access to historical data. However, storing historical data is cheap in many real-world settings, yet replaying all historical data is often prohibited due to processing time constraints. In such settings, we propose that continual learning systems should learn the time to learn and schedule which tasks to replay at different time steps. We first demonstrate the benefits of our proposal by using Monte Carlo tree search to find a proper replay schedule, and show that the found replay schedules can outperform fixed scheduling policies when combined with various replay methods in different continual learning settings. Additionally, we propose a framework for learning replay scheduling policies with reinforcement learning. We show that the learned policies can generalize better in new continual learning scenarios compared to equally replaying all seen tasks, without added computational cost. Our study reveals the importance of learning the time to learn in continual learning, which brings current research closer to real-world needs.},
  archive      = {J_TMLR},
  author       = {Marcus Klasson and Hedvig Kjellstrom and Cheng Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learn the time to learn: Replay scheduling in continual learning},
  url          = {https://openreview.net/forum?id=Q4aAITDgdP},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning multiscale non-stationary causal structures.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=SQnPE63jtA">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a gap in the current state of the art by providing a solution for modeling causal relationships that evolve over time and occur at different time scales. Specifically, we introduce the multiscale non-stationary directed acyclic graph (MN-DAG), a framework for modeling multivariate time series data. Our contribution is twofold. Firstly, we expose a probabilistic generative model by leveraging results from spectral and causality theories. Our model allows sampling an MN-DAG according to user-specified priors on the time-dependence and multiscale properties of the causal graph. Secondly, we devise a Bayesian method named Multiscale Non-stationary Causal Structure Learner (MN-CASTLE) that uses stochastic variational inference to estimate MN-DAGs. The method also exploits information from the local partial correlation between time series over different time resolutions. The data generated from an MN-DAG reproduces well-known features of time series in different domains, such as volatility clustering and serial correlation. Additionally, we show the superior performance of MN-CASTLE on synthetic data with different multiscale and non-stationary properties compared to baseline models. Finally, we apply MN-CASTLE to identify the drivers of the natural gas prices in the US market. Causal relationships have strengthened during the COVID-19 outbreak and the Russian invasion of Ukraine, a fact that baseline methods fail to capture. MN-CASTLE identifies the causal impact of critical economic drivers on natural gas prices, such as seasonal factors, economic uncertainty, oil prices, and gas storage deviations.},
  archive      = {J_TMLR},
  author       = {Gabriele D&#39;Acunto and Gianmarco De Francisci Morales and Paolo Bajardi and Francesco Bonchi},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning multiscale non-stationary causal structures},
  url          = {https://openreview.net/forum?id=SQnPE63jtA},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SANTA: Source anchoring network and target alignment for
continual test time adaptation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=V7guVYzvE4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adapting a trained model to perform satisfactorily on continually changing test environments is an important and challenging task. In this work, we propose a novel framework, SANTA, which aims to satisfy the following characteristics required for online adaptation: 1) can work effectively for different (even small) batch sizes; 2) should continue to work well on the source domain; 3) should have minimal tunable hyperparameters and storage requirements. Given a pre-trained network trained on source domain data, the proposed framework modifies the affine parameters of the batch normalization layers using source anchoring based self-distillation. This ensures that the model incorporates knowledge from the newly encountered domains, without catastrophically forgetting the previously seen domains. We also propose a source-prototype driven contrastive alignment to ensure natural grouping of the target samples, while maintaining the already learnt semantic information. Extensive evaluation on three benchmark datasets under challenging settings justify the effectiveness of SANTA for real-world applications. Code here: https://github.com/goirik-chakrabarty/SANTA},
  archive      = {J_TMLR},
  author       = {Goirik Chakrabarty and Manogna Sreenivas and Soma Biswas},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SANTA: Source anchoring network and target alignment for continual test time adaptation},
  url          = {https://openreview.net/forum?id=V7guVYzvE4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Variational causal dynamics: Discovering modular world
models from interventions. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=V9tQKYYNK1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Latent world models allow agents to reason about complex environments with high-dimensional observations. However, adapting to new environments and effectively leveraging previous knowledge remain significant challenges. We present Variational Causal Dynamics (VCD), a structured world model that exploits the invariance of causal mechanisms across environments to achieve fast and modular adaptation. By causally factorising a transition model, VCD is able to identify reusable components across different environments. This is achieved by combining causal discovery and variational inference to learn a latent representation and transition model jointly in an unsupervised manner. Specifically, we optimise the evidence lower bound jointly over a representation model and a transition model structured as a causal graphical model. In evaluations on simulated environments with state and image observations, we show that VCD is able to successfully identify causal variables, and to discover consistent causal structures across different environments. Moreover, given a small number of observations in a previously unseen, intervened environment, VCD is able to identify the sparse changes in the dynamics and to adapt efficiently. In doing so, VCD significantly extends the capabilities of the current state-of-the-art in latent world models while also comparing favourably in terms of prediction accuracy.},
  archive      = {J_TMLR},
  author       = {Anson Lei and Bernhard Schölkopf and Ingmar Posner},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Variational causal dynamics: Discovering modular world models from interventions},
  url          = {https://openreview.net/forum?id=V9tQKYYNK1},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Program of thoughts prompting: Disentangling computation
from reasoning for numerical reasoning tasks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=YfZ4ZPt8zd">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, there has been significant progress in teaching language models to perform step-by-step reasoning to solve complex numerical reasoning tasks. Chain-of-thoughts prompting (CoT) is the state-of-art method for many of these tasks. CoT uses language models to produce text describing reasoning, and computation, and finally the answer to a question. Here we propose `Program of Thoughts&#39; (PoT), which uses language models (mainly Codex) to generate text and programming language statements, and finally an answer. In PoT, the computation can be delegated to a program interpreter, which is used to execute the generated program, thus decoupling complex computation from reasoning and language understanding. We evaluate PoT on five math word problem datasets and three financial-QA datasets in both few-shot and zero-shot settings. We find that PoT has an average performance gain over CoT of around 12% across all datasets. By combining PoT with self-consistency decoding, we can achieve extremely strong performance on all the math datasets and financial datasets. All of our data and code will be released.},
  archive      = {J_TMLR},
  author       = {Wenhu Chen and Xueguang Ma and Xinyi Wang and William W. Cohen},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks},
  url          = {https://openreview.net/forum?id=YfZ4ZPt8zd},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Visualizing the diversity of representations learned by
bayesian neural networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ZSxvyWrX6k">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explainable Artificial Intelligence (XAI) aims to make learning machines less opaque, and offers researchers and practitioners various tools to reveal the decision-making strategies of neural networks. In this work, we investigate how XAI methods can be used for exploring and visualizing the diversity of feature representations learned by Bayesian Neural Networks (BNNs). Our goal is to provide a global understanding of BNNs by making their decision-making strategies a) visible and tangible through feature visualizations and b) quantitatively measurable with a distance measure learned by contrastive learning. Our work provides new insights into the posterior distribution in terms of human-understandable feature information with regard to the underlying decision-making strategies. The main findings of our work are the following: 1) global XAI methods can be applied to explain the diversity of decision-making strategies of BNN instances, 2) Monte Carlo dropout with commonly used Dropout rates exhibit increased diversity in feature representations compared to the multimodal posterior approximation of MultiSWAG, 3) the diversity of learned feature representations highly correlates with the uncertainty estimate for the output and 4) the inter-mode diversity of the multimodal posterior decreases as the network width increases, while the intra-mode diversity increases. These findings are consistent with the recent Deep Neural Networks theory, providing additional intuitions about what the theory implies in terms of humanly understandable concepts.},
  archive      = {J_TMLR},
  author       = {Dennis Grinwald and Kirill Bykov and Shinichi Nakajima and Marina MC Höhne},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Visualizing the diversity of representations learned by bayesian neural networks},
  url          = {https://openreview.net/forum?id=ZSxvyWrX6k},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving continual learning by accurate gradient
reconstructions of the past. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=b1fpfCjja1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weight-regularization and experience replay are two popular continual-learning strategies with complementary strengths: while weight-regularization requires less memory, replay can more accurately mimic batch training. How can we combine them to get better methods? Despite the simplicity of the question, little is known or done to optimally combine these approaches. In this paper, we present such a method by using a recently proposed principle of adaptation that relies on a faithful reconstruction of the gradients of the past data. Using this principle, we design a prior which combines two types of replay methods with a quadratic weight-regularizer and achieves better gradient reconstructions. The combination improves performance on standard task-incremental continual learning benchmarks such as Split-CIFAR, SplitTinyImageNet, and ImageNet-1000, achieving $&gt;\!80\%$ of the batch performance by simply utilizing a memory of $&lt;\!10\%$ of the past data. Our work shows that a good combination of the two strategies can be very effective in reducing forgetting.},
  archive      = {J_TMLR},
  author       = {Erik Daxberger and Siddharth Swaroop and Kazuki Osawa and Rio Yokota and Richard E Turner and José Miguel Hernández-Lobato and Mohammad Emtiyaz Khan},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Improving continual learning by accurate gradient reconstructions of the past},
  url          = {https://openreview.net/forum?id=b1fpfCjja1},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated detection of causal inference opportunities:
Regression discontinuity subgroup discovery. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=cdRYoTyHZh">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The gold standard for the identification of causal effects are randomized controlled trials (RCT), but RCTs may not always be feasible to conduct. When treatments depend on a threshold however, such as the blood sugar threshold for diabetes diagnosis, we can still sometimes estimate causal effects with regression discontinuities (RDs). RDs are valid when units just above and below the threshold have the same distribution of covariates and thus no confounding in the presence of noise, establishing an as-if randomization. In practice however, implementing RD studies can be difficult as identifying treatment thresholds require considerable domain expertise -- furthermore, the thresholds may differ across subgroups (e.g., the blood sugar threshold for diabetes may differ across demographics), and ignoring these differences can lower statistical power. Finding the thresholds and to whom they apply is an important problem currently solved manually by domain experts, and data-driven approaches are needed when domain expertise is not sufficient. Here, we introduce Regression Discontinuity SubGroup Discovery (RDSGD), a machine-learning method that identifies statistically powerful and interpretable subgroups for RD thresholds. Using a medical claims dataset with over 60 million patients, we apply RDSGD to multiple clinical contexts and identify subgroups with increased compliance to treatment assignment thresholds. As treatment thresholds matter for many diseases and policy decisions, RDSGD can be a powerful tool for discovering new avenues for causal estimation.},
  archive      = {J_TMLR},
  author       = {Tony Liu and Patrick Lawlor and Lyle Ungar and Konrad Kording and Rahul Ladhania},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Automated detection of causal inference opportunities: Regression discontinuity subgroup discovery},
  url          = {https://openreview.net/forum?id=cdRYoTyHZh},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reliable active learning via influence functions.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=dN9YICB6hN">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the high cost and time-consuming nature of collecting labeled data, having insufficient labeled data is a common challenge that can negatively impact the performance of deep learning models when applied to real-world applications. Active learning (AL) aims to reduce the cost and time required for obtaining labeled data by selecting valuable samples during model training. However, recent works have pointed out the performance unreliability of existing AL algorithms for deep learning (DL) architectures under different scenarios, which manifests as their performance being comparable (or worse) to that of basic random selection. This behavior compromises the applicability of these approaches. We address this problem by proposing a theoretically motivated AL framework for DL architectures. We demonstrate that the most valuable samples for the model are those that, unsurprisingly, improve its performance on the entire dataset, most of which is unlabeled, and present a framework to efficiently estimate such performance (or loss) via influence functions, pseudo labels and diversity selection. Experimental results show that the proposed reliable active learning via influence functions (RALIF) can consistently outperform the random selection baseline as well as other existing and state-of-the art active learning approaches.},
  archive      = {J_TMLR},
  author       = {Meng Xia and Ricardo Henao},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reliable active learning via influence functions},
  url          = {https://openreview.net/forum?id=dN9YICB6hN},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Personalized federated learning with communication
compression. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=dZugyhbNFY">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In contrast to training traditional machine learning~(ML) models in data centers, federated learning~(FL) trains ML models over local datasets contained on resource-constrained heterogeneous edge devices. Existing FL algorithms aim to learn a single global model for all participating devices, which may not be helpful to all devices participating in the training due to the heterogeneity of the data across the devices. Recently, Hanzely and Richt\&#39;{a}rik (2020) proposed a new formulation for training personalized FL models aimed at balancing the trade-off between the traditional global model and the local models that could be trained by individual devices using their private data only. They derived a new algorithm, called {\em loopless gradient descent}~(L2GD), to solve it and showed that this algorithms leads to improved communication complexity guarantees in regimes when more personalization is required. In this paper, we equip their L2GD algorithm with a {\em bidirectional} compression mechanism to further reduce the communication bottleneck between the local devices and the server. Unlike other compression-based algorithms used in the FL-setting, our compressed L2GD algorithm operates on a probabilistic communication protocol, where communication does not happen on a fixed schedule. Moreover, our compressed L2GD algorithm maintains a similar convergence rate as vanilla SGD without compression. To empirically validate the efficiency of our algorithm, we perform diverse numerical experiments on both convex and non-convex problems and using various compression techniques.},
  archive      = {J_TMLR},
  author       = {El houcine Bergou and Konstantin Pavlovich Burlachenko and Aritra Dutta and Peter Richtárik},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Personalized federated learning with communication compression},
  url          = {https://openreview.net/forum?id=dZugyhbNFY},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rewiring with positional encodings for graph neural
networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=dn3ZkqG2YV">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several recent works use positional encodings to extend the receptive fields of graph neural network (GNN) layers equipped with attention mechanisms. These techniques, however, extend receptive fields to the complete graph, at substantial computational cost and risking a change in the inductive biases of conventional GNNs, or require complex architecture adjustments. As a conservative alternative, we use positional encodings to expand receptive fields to r-hop neighborhoods. More specifically, our method augments the input graph with additional nodes/edges and uses positional encodings as node and/or edge features. We thus modify graphs before inputting them to a downstream GNN model, instead of modifying the model itself. This makes our method model-agnostic, i.e., compatible with any of the existing GNN architectures. We also provide examples of positional encodings that are lossless with a one-to-one map between the original and the modified graphs. We demonstrate that extending receptive fields via positional encodings and a virtual fully- connected node significantly improves GNN performance and alleviates over-squashing using small r. We obtain improvements on a variety of models and datasets and reach competitive performance using traditional GNNs or graph Transformers.},
  archive      = {J_TMLR},
  author       = {Rickard Brüel Gabrielsson and Mikhail Yurochkin and Justin Solomon},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Rewiring with positional encodings for graph neural networks},
  url          = {https://openreview.net/forum?id=dn3ZkqG2YV},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Understanding the robustness difference between stochastic
gradient descent and adaptive gradient methods. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ed8SkMdYFT">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic gradient descent (SGD) and adaptive gradient methods, such as Adam and RMSProp, have been widely used in training deep neural networks. We empirically show that while the difference between the standard generalization performance of models trained using these methods is small, those trained using SGD exhibit far greater robustness under input perturbations. Notably, our investigation demonstrates the presence of irrelevant frequencies in natural datasets, where alterations do not affect models&#39; generalization performance. However, models trained with adaptive methods show sensitivity to these changes, suggesting that their use of irrelevant frequencies can lead to solutions sensitive to perturbations. To better understand this difference, we study the learning dynamics of gradient descent (GD) and sign gradient descent (signGD) on a synthetic dataset that mirrors natural signals. With a three-dimensional input space, the models optimized with GD and signGD have standard risks close to zero but vary in their adversarial risks. Our result shows that linear models&#39; robustness to $\ell_2$-norm bounded changes is inversely proportional to the model parameters&#39; weight norm: a smaller weight norm implies better robustness. In the context of deep learning, our experiments show that SGD-trained neural networks have smaller Lipschitz constants, explaining the better robustness to input perturbations than those trained with adaptive gradient methods. Our source code is available at https://github.com/averyma/opt-robust.},
  archive      = {J_TMLR},
  author       = {Avery Ma and Yangchen Pan and Amir-massoud Farahmand},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Understanding the robustness difference between stochastic gradient descent and adaptive gradient methods},
  url          = {https://openreview.net/forum?id=ed8SkMdYFT},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ILPO-MP: Mode priors prevent mode collapse when imitating
latent policies from observations. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=f3JLnnZsAm">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imitation learning from observations (IfO) constrains the classic imitation learning setting to cases where expert observations are easy to obtain, but no expert actions are available. Most existing IfO methods require access to task-specific cost functions or many interactions with the target environment. Learning a forward dynamics model in combination with a latent policy has been shown to solve these issues. However, the limited supervision in the IfO scenario can lead to mode collapse when learning the generative forward dynamics model and the corresponding latent policy. In this paper, we analyze the mode collapse problem in this setting and show that it is caused by a combination of deterministic expert data and bad initialization of the models. Under the assumption of piecewise continuous system dynamics, we propose ILPO-MP, a method to prevent the mode collapse using clustering of expert transitions to impose a mode prior on the generative model and the latent policy. We show that ILPO-MP prevents mode collapse and improves performance in a variety of environments.},
  archive      = {J_TMLR},
  author       = {Oliver Struckmeier and Ville Kyrki},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ILPO-MP: Mode priors prevent mode collapse when imitating latent policies from observations},
  url          = {https://openreview.net/forum?id=f3JLnnZsAm},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Complementary sparsity: Accelerating sparse CNNs with high
accuracy on general-purpose computing platforms. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=g1B4qgOw79">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model sparsity is a promising approach to reducing parameters or FLOPs of convolutional neural networks (CNNs). Compared to unstructured or coarse-grained structured sparsity, fine-grained structured sparsity, e.g., N:M sparse pattern, can achieve a better balance between accuracy and efficiency on general computing platforms like CPUs and GPUs. In particular, the 2:4 sparsity can accelerate CNN inference by 2$\times$ speed and with negligible accuracy drop. However, N:M sparsity needs to be supported by GPU within specific hardware circuits and hardly achieves significant speedups on common GPUs. To accelerate CNNs with general-purposed computing resources and simultaneously retain the model accuracy as much as possible, this paper proposes complementary sparsity (CS). CS denotes that only one weight can be retained for weights spaced at the same distance. On the one hand, CS features high mask flexibility, which is naturally favorable to high model accuracy. Moreover, we propose a CS-specific sparse training method to improve CS-based CNNs&#39; accuracy under high parameter sparsities ($&gt;$75\%). On the other hand, CS itself is memory-access balanced and robust to pattern hyperparameters, which can be utilized to speedup CS-based convolution computation on CPUs and common GPUs. We thus propose a CS convolution parallel computing algorithm that adapts to common GPUs without sparse tensor cores. Experimental results show that compared to other sparsity patterns, the proposed CS can achieve the optimal trade-off in terms of accuracy and latency for CPUs and common GPUs, respectively. Codes will be available at https://gitee.com/mindspore/models/tree/master/research/cv/CS.},
  archive      = {J_TMLR},
  author       = {Kang Zhao and Yijun Tan and Kai Han and Ting Hu and Hanting Chen and Tao Yuan and Yunhe Wang and Jun Yao},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Complementary sparsity: Accelerating sparse CNNs with high accuracy on general-purpose computing platforms},
  url          = {https://openreview.net/forum?id=g1B4qgOw79},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Understanding curriculum learning in policy optimization for
online combinatorial optimization. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=gKEbBKRUjA">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the recent years, reinforcement learning (RL) starts to show promising results in tackling combinatorial optimization (CO) problems, in particular when coupled with curriculum learning to facilitate training. Despite emerging empirical evidence, theoretical study on why RL helps is still at its early stage. This paper presents the first systematic study on policy optimization methods for online CO problems. We show that online CO problems can be naturally formulated as latent Markov Decision Processes (LMDPs), and prove convergence bounds on natural policy gradient (NPG) for solving LMDPs. Furthermore, our theory explains the benefit of curriculum learning: it can find a strong sampling policy and reduce the distribution shift, a critical quantity that governs the convergence rate in our theorem. For a canonical online CO problem, the Best Choice Problem (BCP), we formally prove that distribution shift is reduced exponentially with curriculum learning even if the curriculum is a randomly generated BCP on a smaller scale. Our theory also shows we can simplify the curriculum learning scheme used in prior work from multi-step to single-step. Lastly, we provide extensive experiments on the Best Choice Problem, Online Knapsack, and AdWords to verify our findings.},
  archive      = {J_TMLR},
  author       = {Runlong Zhou and Zelin He and Yuandong Tian and Yi Wu and Simon Shaolei Du},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Understanding curriculum learning in policy optimization for online combinatorial optimization},
  url          = {https://openreview.net/forum?id=gKEbBKRUjA},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-client label propagation for transductive and
semi-supervised federated learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=gY04GX8R5k">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present Cross-Client Label Propagation (XCLP), a new method for transductive and semi-supervised federated learning. XCLP estimates a data graph jointly from the data of multiple clients and computes labels for the unlabeled data by propagating label information across the graph. To avoid clients having to share their data with anyone, XCLP employs two cryptographically secure protocols: secure Hamming distance computation and secure summation. We demonstrate two distinct applications of XCLP within federated learning. In the first, we use it in a one-shot way to predict labels for unseen test points. In the second, we use it to repeatedly pseudo-label unlabeled training data in a federated semi-supervised setting. Experiments on both real federated and standard benchmark datasets show that in both applications XCLP achieves higher classification accuracy than alternative approaches.},
  archive      = {J_TMLR},
  author       = {Jonathan Scott and Michelle Yeo and Christoph H Lampert},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Cross-client label propagation for transductive and semi-supervised federated learning},
  url          = {https://openreview.net/forum?id=gY04GX8R5k},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The analysis of the expected change in the classification
probability of the predicted label. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=gvqzvUVPiQ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a formalism for estimating the expected change in the probability distribution of the predicted label of an object, with respect to all small perturbations to the object. We first derive analytically an estimate of the expected probability change as a function of the input noise. We then conduct three empirical studies: in the first study, experimental results on image classification show that the proposed measure can be used to distinguish the not-robust label predictions from those that are robust, even when they are all predicted with high confidence. The second study shows that the proposed robustness measure is almost always higher for the predictions on the corrupted images, compared to the predictions on the original versions of them. The final study shows that the proposed measure is lower for models when they are trained using adversarial training approaches.},
  archive      = {J_TMLR},
  author       = {Ruo Yang and Ping Liu and Mustafa Bilgic},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The analysis of the expected change in the classification probability of the predicted label},
  url          = {https://openreview.net/forum?id=gvqzvUVPiQ},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RLTF: Reinforcement learning from unit test feedback.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=hjYmsV6nXZ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of program synthesis, or code generation, is to generate executable code based on given descriptions. Recently, there has been an increasing number of studies employing reinforcement learning (RL) to improve the performance of large language models (LLMs) for code. However, some of the current representative RL methods have only used offline frameworks, limiting the exploration of new sample spaces. Additionally, the utilization of unit test signals is limited, not accounting for specific error locations within the code. To address these issues, we proposed RLTF, i.e., Reinforcement Learning from Unit Test Feedback, a novel online RL framework with unit test feedback of multi-granularity for refining code LLMs. Our approach generates data in real-time during training and simultaneously utilizes fine-grained feedback signals to guide the model towards producing higher-quality code. Extensive experiments show that RLTF achieves state-of-the-art performance on the APPS and the MBPP benchmarks. Our code is available at: \url{https://github.com/Zyq-scut/RLTF}.},
  archive      = {J_TMLR},
  author       = {Jiate Liu and Yiqin Zhu and Kaiwen Xiao and QIANG FU and Xiao Han and Yang Wei and Deheng Ye},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {RLTF: Reinforcement learning from unit test feedback},
  url          = {https://openreview.net/forum?id=hjYmsV6nXZ},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data pruning and neural scaling laws: Fundamental
limitations of score-based algorithms. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=iRTL4pDavo">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data pruning algorithms are commonly used to reduce the memory and computational cost of the optimization process. Recent empirical results (Guo, B. Zhao, and Bai, 2022) reveal that random data pruning remains a strong baseline and outperforms most existing data pruning methods in the high compression regime, i.e., where a fraction of 30% or less of the data is kept. This regime has recently attracted a lot of interest as a result of the role of data pruning in improving the so-called neural scaling laws; see (Sorscher et al., 2022), where the authors showed the need for high-quality data pruning algorithms in order to beat the sample power law. In this work, we focus on score-based data pruning algorithms and show theoretically and empirically why such algorithms fail in the high compression regime. We demonstrate “No Free Lunch&quot; theorems for data pruning and discuss potential solutions to these limitations.},
  archive      = {J_TMLR},
  author       = {Fadhel Ayed and Soufiane Hayou},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Data pruning and neural scaling laws: Fundamental limitations of score-based algorithms},
  url          = {https://openreview.net/forum?id=iRTL4pDavo},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to reconstruct signals from binary measurements
alone. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ioFIAQOBOS">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in unsupervised learning have highlighted the possibility of learning to reconstruct signals from noisy and incomplete linear measurements alone. These methods play a key role in medical and scientific imaging and sensing, where ground truth data is often scarce or difficult to obtain. However, in practice measurements are not only noisy and incomplete but also quantized. Here we explore the extreme case of learning from binary observations and provide necessary and sufficient conditions on the number of measurements required for identifying a set of signals from incomplete binary data. Our results are complementary to existing bounds on signal recovery from binary measurements. Furthermore, we introduce a novel self-supervised learning approach, which we name SSBM, that only requires binary data for training. We demonstrate in a series of experiments with real datasets that SSBM performs on par with supervised learning and outperforms sparse reconstruction methods with a fixed wavelet basis by a large margin.},
  archive      = {J_TMLR},
  author       = {Julián Tachella and Laurent Jacques},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning to reconstruct signals from binary measurements alone},
  url          = {https://openreview.net/forum?id=ioFIAQOBOS},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature-attending recurrent modules for generalization in
reinforcement learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=j4y3gN7VtW">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many important tasks are defined in terms of object. To generalize across these tasks, a reinforcement learning (RL) agent needs to exploit the structure that the objects induce. Prior work has either hard-coded object-centric features, used complex object-centric generative models, or updated state using local spatial features. However, these approaches have had limited success in enabling general RL agents. Motivated by this, we introduce “Feature- Attending Recurrent Modules” (FARM), an architecture for learning state representations that relies on simple, broadly applicable inductive biases for capturing spatial and temporal regularities. FARM learns a state representation that is distributed across multiple modules that each attend to spatiotemporal features with an expressive feature attention mechanism. We show that this improves an RL agent’s ability to generalize across object-centric tasks. We study task suites in both 2D and 3D environments and find that FARM better generalizes compared to competing architectures that leverage attention or multiple modules.},
  archive      = {J_TMLR},
  author       = {Wilka Torrico Carvalho and Andrew Kyle Lampinen and Kyriacos Nikiforou and Felix Hill and Murray Shanahan},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Feature-attending recurrent modules for generalization in reinforcement learning},
  url          = {https://openreview.net/forum?id=j4y3gN7VtW},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Federated learning under partially disjoint data via
manifold reshaping. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=jLJTqJXAG7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Statistical heterogeneity severely limits the performance of federated learning (FL), motivating several explorations e.g., FedProx, MOON and FedDyn, to alleviate this problem. Despite effectiveness, their considered scenario generally requires samples from almost all classes during the local training of each client, although some covariate shifts may exist among clients. In fact, the natural case of partially class-disjoint data (PCDD), where each client contributes a few classes (instead of all classes) of samples, is practical yet underexplored. Specifically, the unique collapse and invasion characteristics of PCDD can induce the biased optimization direction in local training, which prevents the efficiency of federated learning. To address this dilemma, we propose a manifold reshaping approach called FedMR to calibrate the feature space of local training. Our FedMR adds two interplaying losses to the vanilla federated learning: one is the intra-class loss to decorrelate feature dimensions for anti-collapse; and the other one is the inter-class loss to guarantee the proper margin among categories in the feature expansion. We conduct extensive experiments on a range of datasets to demonstrate that our FedMR achieves much higher accuracy and better communication efficiency.},
  archive      = {J_TMLR},
  author       = {Ziqing Fan and Jiangchao Yao and Ruipeng Zhang and Lingjuan Lyu and Yanfeng Wang and Ya Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Federated learning under partially disjoint data via manifold reshaping},
  url          = {https://openreview.net/forum?id=jLJTqJXAG7},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A robust backpropagation-free framework for images.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=leqr0vQzeN">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While current deep learning algorithms have been successful for a wide variety of artificial intelligence (AI) tasks, including those involving structured image data, they present deep neurophysiological conceptual issues due to their reliance on the gradients that are computed by backpropagation of errors (backprop). Gradients are required to obtain synaptic weight adjustments but require knowledge of feed forward activities in order to conduct backward propagation, a biologically implausible process. This is known as the &quot;weight transport problem&#39;&#39;. Therefore, in this work, we present a more biologically plausible approach towards solving the weight transport problem for image data. This approach, which we name the error-kernel driven activation alignment (EKDAA) algorithm, accomplishes through the introduction of locally derived error transmission kernels and error maps. Like standard deep learning networks, EKDAA performs the standard forward process via weights and activation functions; however, its backward error computation involves adaptive error kernels that propagate local error signals through the network. The efficacy of EKDAA is demonstrated by performing visual-recognition tasks on the Fashion MNIST, CIFAR-10 and SVHN benchmarks, along with demonstrating its ability to extract visual features from natural color images. Furthermore, in order to demonstrate its non-reliance on gradient computations, results are presented for an EKDAA-trained CNN that employs a non-differentiable activation function.},
  archive      = {J_TMLR},
  author       = {Timothy Zee and Alex Ororbia and Ankur Mali and Ifeoma Nwogu},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A robust backpropagation-free framework for images},
  url          = {https://openreview.net/forum?id=leqr0vQzeN},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RAFT: Reward rAnked FineTuning for generative foundation
model alignment. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=m7p5O7zblY">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative foundation models are susceptible to implicit biases that can arise from extensive unsupervised training data. Such biases can produce suboptimal samples, skewed outcomes, and unfairness, with potentially serious consequences. Consequently, aligning these models with human ethics and preferences is an essential step toward ensuring their responsible and effective deployment in real-world applications. Prior research has primarily employed Reinforcement Learning from Human Feedback (RLHF) to address this problem, where generative models are fine-tuned with RL algorithms guided by a human-feedback-informed reward model. However, the inefficiencies and instabilities associated with RL algorithms frequently present substantial obstacles to the successful alignment, necessitating the development of a more robust and streamlined approach. To this end, we introduce a new framework, Reward rAnked FineTuning (RAFT), designed to align generative models effectively. Utilizing a reward model and a sufficient number of samples, our approach selects the high-quality samples, discarding those that exhibit undesired behavior, and subsequently enhancing the model by fine-tuning on these filtered samples. Our studies show that RAFT can effectively improve the model performance in both reward learning and other automated metrics in both large language models and diffusion models.},
  archive      = {J_TMLR},
  author       = {Hanze Dong and Wei Xiong and Deepanshu Goyal and Yihan Zhang and Winnie Chow and Rui Pan and Shizhe Diao and Jipeng Zhang and KaShun SHUM and Tong Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {RAFT: Reward rAnked FineTuning for generative foundation model alignment},
  url          = {https://openreview.net/forum?id=m7p5O7zblY},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inducing meaningful units from character sequences with
dynamic capacity slot attention. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=m8U9rSs6gU">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Characters do not convey meaning, but sequences of characters do. We propose an unsupervised distributional method to learn the abstract meaning-bearing units in a sequence of characters. Rather than segmenting the sequence, our Dynamic Capacity Slot Attention model discovers continuous representations of the objects in the sequence, extending an architecture for object discovery in images. We train our model on different languages and evaluate the quality of the obtained representations with forward and reverse probing classifiers. These experiments show that our model succeeds in discovering units which are similar to those proposed previously in form, content, and level of abstraction, and which show promise for capturing meaningful information at a higher level of abstraction.},
  archive      = {J_TMLR},
  author       = {Melika Behjati and James Henderson},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Inducing meaningful units from character sequences with dynamic capacity slot attention},
  url          = {https://openreview.net/forum?id=m8U9rSs6gU},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Provably safe reinforcement learning: Conceptual analysis,
survey, and benchmarking. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=mcN0ezbnzO">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring the safety of reinforcement learning (RL) algorithms is crucial to unlock their potential for many real-world tasks. However, vanilla RL and most safe RL approaches do not guarantee safety. In recent years, several methods have been proposed to provide hard safety guarantees for RL, which is essential for applications where unsafe actions could have disastrous consequences. Nevertheless, there is no comprehensive comparison of these provably safe RL methods. Therefore, we introduce a categorization of existing provably safe RL methods, present the conceptual foundations for both continuous and discrete action spaces, and empirically benchmark existing methods. We categorize the methods based on how they adapt the action: action replacement, action projection, and action masking. Our experiments on an inverted pendulum and a quadrotor stabilization task indicate that action replacement is the best-performing approach for these applications despite its comparatively simple realization. Furthermore, adding a reward penalty, every time the safety verification is engaged, improved training performance in our experiments. Finally, we provide practical guidance on selecting provably safe RL approaches depending on the safety specification, RL algorithm, and type of action space.},
  archive      = {J_TMLR},
  author       = {Hanna Krasowski and Jakob Thumm and Marlon Müller and Lukas Schäfer and Xiao Wang and Matthias Althoff},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Provably safe reinforcement learning: Conceptual analysis, survey, and benchmarking},
  url          = {https://openreview.net/forum?id=mcN0ezbnzO},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A combinatorial semi-bandit approach to charging station
selection for electric vehicles. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ndw90pkNM9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we address the problem of long-distance navigation for battery electric vehicles (BEVs), where one or more charging sessions are required to reach the intended destination. We consider the availability and performance of the charging stations to be unknown and stochastic, and develop a combinatorial semi-bandit framework for exploring the road network to learn the parameters of the queue time and charging power distributions. Within this framework, we first outline a method for transforming the road network graph into a graph of feasible paths between charging stations to handle the constrained combinatorial optimization problem in an efficient way. Then, for the feasibility graph, we use a Bayesian approach to model the stochastic edge weights, utilizing conjugate priors for the one-parameter exponential and two-parameter gamma distributions, the latter of which is novel to multi-armed bandit literature. Finally, we apply combinatorial versions of Thompson Sampling, BayesUCB and Epsilon-greedy to the problem. We demonstrate the performance of our framework on long-distance navigation problem instances in large-scale country-sized road networks, with simulation experiments in Norway, Sweden and Finland.},
  archive      = {J_TMLR},
  author       = {Niklas Åkerblom and Morteza Haghir Chehreghani},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A combinatorial semi-bandit approach to charging station selection for electric vehicles},
  url          = {https://openreview.net/forum?id=ndw90pkNM9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differentially private optimizers can learn adversarially
robust models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=o8VgRNYh6n">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models have shone in a variety of domains and attracted increasing attention from both the security and the privacy communities. One important yet worrying question is: Will training models under the differential privacy (DP) constraint have an unfavorable impact on their adversarial robustness? While previous works have postulated that privacy comes at the cost of worse robustness, we give the first theoretical analysis to show that DP models can indeed be robust and accurate, even sometimes more robust than their naturally-trained non-private counterparts. We observe three key factors that influence the privacy-robustness-accuracy tradeoff: (1) hyper-parameters for DP optimizers are critical; (2) pre-training on public data significantly mitigates the accuracy and robustness drop; (3) choice of DP optimizers makes a difference. With these factors set properly, we achieve 90\% natural accuracy, 72\% robust accuracy ($+9\%$ than the non-private model) under $l_2(0.5)$ attack, and 69\% robust accuracy ($+16\%$ than the non-private model) with pre-trained SimCLRv2 model under $l_\infty(4/255)$ attack on CIFAR10 with $\epsilon=2$. In fact, we show both theoretically and empirically that DP models are Pareto optimal on the accuracy-robustness tradeoff. Empirically, the robustness of DP models is consistently observed across various datasets and models. We believe our encouraging results are a significant step towards training models that are private as well as robust.},
  archive      = {J_TMLR},
  author       = {Zhiqi Bu and Yuan Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Differentially private optimizers can learn adversarially robust models},
  url          = {https://openreview.net/forum?id=o8VgRNYh6n},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GraphPNAS: Learning probabilistic graph generators for
neural architecture search. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ok18jj7cam">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural architectures can be naturally viewed as computational graphs. Motivated by this perspective, we, in this paper, study neural architecture search (NAS) through the lens of learning graph generative models. In contrast to existing NAS methods which largely focus on searching for a single best architecture, i.e, point estimation, we propose GraphPNAS a deep graph generative model that learns a distribution of well-performing architectures. Relying on graph neural networks (GNNs), our GraphPNAS can better capture topologies of good neural architectures and relations between operators therein. Moreover, our graph generator leads to a learnable probabilistic search method that is more flexible and efficient than the commonly used RNN generator and random search methods. Finally, we learn our generator via an efficient reinforcement learning formulation for NAS. To assess the effectiveness of our GraphPNAS, we conduct extensive experiments on four search spaces, including the challenging RandWire on TinyImageNet, ENAS on CIFAR10, and NAS-Bench-101/201. We show that our proposed graph generator consistently outperforms RNN-based one and achieves better or comparable performances than state-of-the-art NAS methods.},
  archive      = {J_TMLR},
  author       = {Muchen Li and Jeffrey Yunfan Liu and Leonid Sigal and Renjie Liao},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {GraphPNAS: Learning probabilistic graph generators for neural architecture search},
  url          = {https://openreview.net/forum?id=ok18jj7cam},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Addressing caveats of neural persistence with deep graph
persistence. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=oyfRWeoUJY">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Persistence is a prominent measure for quantifying neural network complexity, proposed in the emerging field of topological data analysis in deep learning. In this work, however, we find both theoretically and empirically that the variance of network weights and spatial concentration of large weights are the main factors that impact neural persistence. Whilst this captures useful information for linear classifiers, we find that no relevant spatial structure is present in later layers of deep neural networks, making neural persistence roughly equivalent to the variance of weights. Additionally, the proposed averaging procedure across layers for deep neural networks does not consider interaction between layers. Based on our analysis, we propose an extension of the filtration underlying neural persistence to the whole neural network instead of single layers, which is equivalent to calculating neural persistence on one particular matrix. This yields our deep graph persistence measure, which implicitly incorporates persistent paths through the network and alleviates variance-related issues through standardisation. Code is available at https://github.com/ExplainableML/Deep-Graph-Persistence.},
  archive      = {J_TMLR},
  author       = {Leander Girrbach and Anders Christensen and Ole Winther and Zeynep Akata and A. Sophia Koepke},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Addressing caveats of neural persistence with deep graph persistence},
  url          = {https://openreview.net/forum?id=oyfRWeoUJY},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tight conditions for when the NTK approximation is valid.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=qM7JPBYROr">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study when the neural tangent kernel (NTK) approximation is valid for training a model with the square loss. In the lazy training setting of Chizat et al. 2019, we show that rescaling the model by a factor of $\alpha = O(T)$ suffices for the NTK approximation to be valid until training time $T$. Our bound is tight and improves on the previous bound of Chizat et al. 2019, which required a larger rescaling factor of $\alpha = O(T^2)$.},
  archive      = {J_TMLR},
  author       = {Enric Boix-Adserà and Etai Littwin},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Tight conditions for when the NTK approximation is valid},
  url          = {https://openreview.net/forum?id=qM7JPBYROr},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Causal reinforcement learning: A survey. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=qqnttX9LPo">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning is an essential paradigm for solving sequential decision problems under uncertainty. Despite many remarkable achievements in recent decades, applying reinforcement learning methods in the real world remains challenging. One of the main obstacles is that reinforcement learning agents lack a fundamental understanding of the world and must therefore learn from scratch through numerous trial-and-error interactions. They may also face challenges in providing explanations for their decisions and generalizing the acquired knowledge. Causality, however, offers notable advantages by formalizing knowledge in a systematic manner and harnessing invariance for effective knowledge transfer. This has led to the emergence of causal reinforcement learning, a subfield of reinforcement learning that seeks to enhance existing algorithms by incorporating causal relationships into the learning process. In this survey, we provide a comprehensive review of the literature in this domain. We begin by introducing basic concepts in causality and reinforcement learning, and then explain how causality can help address key challenges faced by traditional reinforcement learning. We categorize and systematically evaluate existing causal reinforcement learning approaches, with a focus on their ability to enhance sample efficiency, advance generalizability, facilitate knowledge transfer, mitigate spurious correlations, and promote explainability, fairness, and safety. Lastly, we outline the limitations of current research and shed light on future directions in this rapidly evolving field.},
  archive      = {J_TMLR},
  author       = {Zhihong Deng and Jing Jiang and Guodong Long and Chengqi Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Causal reinforcement learning: A survey},
  url          = {https://openreview.net/forum?id=qqnttX9LPo},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bag of image patch embedding behind the success of
self-supervised learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=r06xREo3QG">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised learning (SSL) has recently achieved tremendous empirical advancements in learning image representation. However, our understanding of the principle behind learning such a representation is still limited. This work shows that joint-embedding SSL approaches learn a representation of image patches, which reflects their co-occurrence. Such a connection to co-occurrence modeling can be established formally, and it supplements the prevailing invariance perspective. We empirically show that learning a representation for fixed-scale patches and aggregating local patch representations as the image representation achieves similar or even better results than the baseline methods. We denote this process as {\it BagSSL}. Even with $32\times 32$ patch representation, BagSSL achieves $62\%$ top-1 linear probing accuracy on ImageNet. On the other hand, with a multi-scale pretrained model, we show that the whole image embedding is approximately the average of local patch embeddings. While the SSL representation is relatively invariant at the global scale, we show that locality is preserved when we zoom into local patch-level representation. Further, we show that patch representation aggregation can improve various SOTA baseline methods by a large margin. The patch representation is considerably easier to understand, and this work makes a step to demystify self-supervised representation learning.},
  archive      = {J_TMLR},
  author       = {Yubei Chen and Adrien Bardes and ZENGYI LI and Yann LeCun},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bag of image patch embedding behind the success of self-supervised learning},
  url          = {https://openreview.net/forum?id=r06xREo3QG},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pairwise learning with adaptive online gradient descent.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=rq1SaHQg2k">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an adaptive online gradient descent method with momentum for pairwise learning, in which the stepsize is determined by historical information. Due to the structure of pairwise learning, the sample pairs are dependent on the parameters, causing difficulties in the convergence analysis. To this end, we develop novel techniques for the convergence analysis of the proposed algorithm. We show that the proposed algorithm can output the desired solution in strongly convex, convex, and nonconvex cases. Furthermore, we present theoretical explanations for why our proposed algorithm can accelerate previous workhorses for online pairwise learning. All assumptions used in the theoretical analysis are mild and common, making our results applicable to various pairwise learning problems. To demonstrate the efficiency of our algorithm, we compare the proposed adaptive method with the non-adaptive counterpart on the benchmark online AUC maximization problem.},
  archive      = {J_TMLR},
  author       = {Tao Sun and Qingsong Wang and Yunwen Lei and Dongsheng Li and Bao Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Pairwise learning with adaptive online gradient descent},
  url          = {https://openreview.net/forum?id=rq1SaHQg2k},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Binary classification under local label differential privacy
using randomized response mechanisms. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=uKCGOw9bGG">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label differential privacy is a popular branch of $\epsilon$-differential privacy for protecting labels in training datasets with non-private features. In this paper, we study the generalization performance of a binary classifier trained on a dataset privatized under the label differential privacy achieved by the randomized response mechanism. Particularly, we establish minimax lower bounds for the excess risks of the deep neural network plug-in classifier, theoretically quantifying how privacy guarantee $\epsilon$ affects its generalization performance. Our theoretical result shows: (1) the randomized response mechanism slows down the convergence of excess risk by lessening the multiplicative constant term compared with the non-private case $(\epsilon=\infty)$; (2) as $\epsilon$ decreases, the optimal structure of the neural network should be smaller for better generalization performance; (3) the convergence of its excess risk is guaranteed even if $\epsilon$ is adaptive to the size of training sample $n$ at a rate slower than $O(n^{-1/2})$. Our theoretical results are validated by extensive simulated examples and two real applications.},
  archive      = {J_TMLR},
  author       = {Shirong Xu and Chendi Wang and Will Wei Sun and Guang Cheng},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Binary classification under local label differential privacy using randomized response mechanisms},
  url          = {https://openreview.net/forum?id=uKCGOw9bGG},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PAVI: Plate-amortized variational inference. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=vlY9GDCCA6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given observed data and a probabilistic generative model, Bayesian inference searches for the distribution of the model&#39;s parameters that could have yielded the data. Inference is challenging for large population studies where millions of measurements are performed over a cohort of hundreds of subjects, resulting in a massive parameter space. This large cardinality renders off-the-shelf Variational Inference (VI) computationally impractical. In this work, we design structured VI families that efficiently tackle large population studies. Our main idea is to share the parameterization and learning across the different i.i.d. variables in a generative model -symbolized by the model&#39;s $\textit{plates}$. We name this concept $\textit{plate amortization}$. Contrary to off-the-shelf stochastic VI --which slows down inference-- plate amortization results in orders of magnitude faster to train variational distributions. Applied to large-scale hierarchical problems, PAVI yields expressive, parsimoniously parameterized VI with an affordable training time --effectively unlocking inference in those regimes. We illustrate the practical utility of PAVI through a challenging Neuroimaging example featuring 400 million latent parameters, demonstrating a significant step towards scalable and expressive Variational Inference.},
  archive      = {J_TMLR},
  author       = {Louis Rouillard and Alexandre Le Bris and Thomas Moreau and Demian Wassermann},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {PAVI: Plate-amortized variational inference},
  url          = {https://openreview.net/forum?id=vlY9GDCCA6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Universal graph continual learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=wzRE5kTnl3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address catastrophic forgetting issues in graph learning as the arrival of new data from diverse task distributions often leads graph models to prioritize the current task, causing them to forget valuable insights from previous tasks. Whereas prior studies primarily tackle one setting of graph continual learning such as incremental node classification, we focus on a universal approach wherein each data point in a task can be a node or a graph, and the task varies from node to graph classification. We refer to this setting as Universal Graph Continual Learning (UGCL), which includes node-unit node classification (NUNC), graph-unit node classification (GUNC), and graph-unit graph classification (GUGC). Our novel method maintains a replay memory of nodes and neighbours to remind the model of past graph structures through distillation. Emphasizing the importance of preserving distinctive graph structures across tasks, we enforce that coarse-to-grain graph representations stay close to previous ones by minimizing our proposed global and local structure losses. We benchmark our method against various continual learning baselines in 8 real-world graph datasets and achieve significant improvement in average performance and forgetting across tasks.},
  archive      = {J_TMLR},
  author       = {Thanh Duc Hoang and Do Viet Tung and Duy-Hung Nguyen and Bao-Sinh Nguyen and Huy Hoang Nguyen and Hung Le},
  journal      = {Transactions on Machine Learning Research},
  month        = {11},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Universal graph continual learning},
  url          = {https://openreview.net/forum?id=wzRE5kTnl3},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Revisiting image classifier training for improved certified
robust defense against adversarial patches. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=2tdhQMLg36">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Certifiably robust defenses against adversarial patches for image classifiers ensure correct prediction against any changes to a constrained neighborhood of pixels. PatchCleanser, the state-of-the-art certified defense, uses a double-masking strategy for robust classification. The success of this strategy relies heavily on the model&#39;s invariance to image pixel masking. In this paper, we take a closer look at model training schemes to improve this invariance. Instead of using Random Cutout augmentations like PatchCleanser, we introduce the notion of worst-case masking, i.e., selecting masked images which maximize classification loss. However, finding worst-case masks requires an exhaustive search, which might be prohibitively expensive to do on-the-fly during training. To solve this problem, we propose a two-round greedy masking strategy (Greedy Cutout) which finds an approximate worst-case mask location with much less compute. We show that the models trained with our Greedy Cutout improves certified robust accuracy over Random Cutout in PatchCleanser across a range of datasets and architectures. Certified robust accuracy on ImageNet with a ViT-B16-224 model increases from 58.1% to 62.3% against a 3% square patch applied anywhere on the image.},
  archive      = {J_TMLR},
  author       = {Aniruddha Saha and Shuhua Yu and Mohammad Sadegh Norouzzadeh and Wan-Yi Lin and Chaithanya Kumar Mummadi},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Revisiting image classifier training for improved certified robust defense against adversarial patches},
  url          = {https://openreview.net/forum?id=2tdhQMLg36},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pareto actor-critic for equilibrium selection in multi-agent
reinforcement learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=3AzqYa18ah">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work focuses on equilibrium selection in no-conflict multi-agent games, where we specifically study the problem of selecting a Pareto-optimal Nash equilibrium among several existing equilibria. It has been shown that many state-of-the-art multi-agent reinforcement learning (MARL) algorithms are prone to converging to Pareto-dominated equilibria due to the uncertainty each agent has about the policy of the other agents during training. To address sub-optimal equilibrium selection, we propose Pareto Actor-Critic (Pareto-AC), which is an actor-critic algorithm that utilises a simple property of no-conflict games (a superset of cooperative games): the Pareto-optimal equilibrium in a no-conflict game maximises the returns of all agents and, therefore, is the preferred outcome for all agents. We evaluate Pareto-AC in a diverse set of multi-agent games and show that it converges to higher episodic returns compared to seven state-of-the-art MARL algorithms and that it successfully converges to a Pareto-optimal equilibrium in a range of matrix games. Finally, we propose PACDCG, a graph neural network extension of Pareto-AC, which is shown to efficiently scale in games with a large number of agents.},
  archive      = {J_TMLR},
  author       = {Filippos Christianos and Georgios Papoudakis and Stefano V Albrecht},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Pareto actor-critic for equilibrium selection in multi-agent reinforcement learning},
  url          = {https://openreview.net/forum?id=3AzqYa18ah},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Policy gradient algorithms implicitly optimize by
continuation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=3Ba6Hd3nZt">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Direct policy optimization in reinforcement learning is usually solved with policy-gradient algorithms, which optimize policy parameters via stochastic gradient ascent. This paper provides a new theoretical interpretation and justification of these algorithms. First, we formulate direct policy optimization in the optimization by continuation framework. The latter is a framework for optimizing nonconvex functions where a sequence of surrogate objective functions, called continuations, are locally optimized. Second, we show that optimizing affine Gaussian policies and performing entropy regularization can be interpreted as implicitly optimizing deterministic policies by continuation. Based on these theoretical results, we argue that exploration in policy-gradient algorithms consists in computing a continuation of the return of the policy at hand, and that the variance of policies should be history-dependent functions adapted to avoid local extrema rather than to maximize the return of the policy.},
  archive      = {J_TMLR},
  author       = {Adrien Bolland and Gilles Louppe and Damien Ernst},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Policy gradient algorithms implicitly optimize by continuation},
  url          = {https://openreview.net/forum?id=3Ba6Hd3nZt},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-attention in colors: Another take on encoding graph
structure in transformers. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=3dQCNqqv2d">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel self-attention mechanism, which we call CSA (Chromatic Self-Attention), which extends the notion of attention scores to attention _filters_, independently modulating the feature channels. We showcase CSA in a fully-attentional graph Transformer CGT (Chromatic Graph Transformer) which integrates both graph structural information and edge features, completely bypassing the need for local message-passing components. Our method flexibly encodes graph structure through node-node interactions, by enriching the original edge features with a relative positional encoding scheme. We propose a new scheme based on random walks that encodes both structural and positional information, and show how to incorporate higher-order topological information, such as rings in molecular graphs. Our approach achieves state-of-the-art results on the ZINC benchmark dataset, while providing a flexible framework for encoding graph structure and incorporating higher-order topology.},
  archive      = {J_TMLR},
  author       = {Romain Menegaux and Emmanuel Jehanno and Margot Selosse and Julien Mairal},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Self-attention in colors: Another take on encoding graph structure in transformers},
  url          = {https://openreview.net/forum?id=3dQCNqqv2d},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-domain long-tailed learning by augmenting disentangled
representations. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=4UXJhNSbwd">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is an inescapable long-tailed class-imbalance issue in many real-world classification problems. Current methods for addressing this problem only consider scenarios where all examples come from the same distribution. However, in many cases, there are multiple domains with distinct class imbalance. We study this multi-domain long-tailed learning problem and aim to produce a model that generalizes well across all classes and domains. Towards that goal, we introduce TALLY, a method that addresses this multi-domain long-tailed learning problem. Built upon a proposed selective balanced sampling strategy, TALLY achieves this by mixing the semantic representation of one example with the domain-associated nuisances of another, producing a new representation for use as data augmentation. To improve the disentanglement of semantic representations, TALLY further utilizes a domain-invariant class prototype that averages out domain-specific effects. We evaluate TALLY on several benchmarks and real-world datasets and find that it consistently outperforms other state-of-the-art methods in both subpopulation and domain shift.},
  archive      = {J_TMLR},
  author       = {Xinyu Yang and Huaxiu Yao and Allan Zhou and Chelsea Finn},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Multi-domain long-tailed learning by augmenting disentangled representations},
  url          = {https://openreview.net/forum?id=4UXJhNSbwd},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The kernel density integral transformation. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=6OEcDKZj5j">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature preprocessing continues to play a critical role when applying machine learning and statistical methods to tabular data. In this paper, we propose the use of the kernel density integral transformation as a feature preprocessing step. Our approach subsumes the two leading feature preprocessing methods as limiting cases: linear min-max scaling and quantile transformation. We demonstrate that, without hyperparameter tuning, the kernel density integral transformation can be used as a simple drop-in replacement for either method, offering robustness to the weaknesses of each. Alternatively, with tuning of a single continuous hyperparameter, we frequently outperform both of these methods. Finally, we show that the kernel density transformation can be profitably applied to statistical data analysis, particularly in correlation analysis and univariate clustering.},
  archive      = {J_TMLR},
  author       = {Calvin McCarter},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The kernel density integral transformation},
  url          = {https://openreview.net/forum?id=6OEcDKZj5j},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Zero-shot node classification with graph contrastive
embedding network. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=8wGXnjRLSy">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies zero-shot node classification, which aims to predict new classes (i.e., unseen classes) of nodes in a graph. This problem is challenging yet promising in a variety of real-world applications such as social analysis and bioinformatics. The key of zero-shot node classification is to enable the knowledge transfer of nodes from training classes to unseen classes. However, existing methods typically ignore the dependencies between nodes and classes, and fail to be organically integrated in a united way. In this paper, we present a novel framework called the Graph Contrastive Embedding Network (GraphCEN) for zero-shot node classification. Specifically, GraphCEN first constructs an affinity graph to model the relations between the classes. Then the node- and class-level contrastive learning (CL) are proposed to jointly learn node embeddings and class assignments in an end-to-end manner. The two-level CL can be optimized to mutually enhance each other. Extensive experiments indicate that our GraphCEN significantly outperforms the state-of-the-art approaches on multiple challenging benchmark datasets.},
  archive      = {J_TMLR},
  author       = {Wei Ju and Yifang Qin and Siyu Yi and Zhengyang Mao and Kangjie Zheng and Luchen Liu and Xiao Luo and Ming Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Zero-shot node classification with graph contrastive embedding network},
  url          = {https://openreview.net/forum?id=8wGXnjRLSy},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Private GANs, revisited. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=9sVCIngrhP">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that the canonical approach for training differentially private GANs -- updating the discriminator with differentially private stochastic gradient descent (DPSGD) -- can yield significantly improved results after modifications to training. Specifically, we propose that existing instantiations of this approach neglect to consider how adding noise only to discriminator updates inhibits discriminator training, disrupting the balance between the generator and discriminator necessary for successful GAN training. We show that a simple fix -- taking more discriminator steps between generator steps -- restores parity between the generator and discriminator and improves results. Additionally, with the goal of restoring parity, we experiment with other modifications -- namely, large batch sizes and adaptive discriminator update frequency -- to improve discriminator training and see further improvements in generation quality. Our results demonstrate that on standard image synthesis benchmarks, DPSGD outperforms all alternative GAN privatization schemes. Code: https://github.com/alexbie98/dpgan-revisit.},
  archive      = {J_TMLR},
  author       = {Alex Bie and Gautam Kamath and Guojun Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Private GANs, revisited},
  url          = {https://openreview.net/forum?id=9sVCIngrhP},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An optical control environment for benchmarking
reinforcement learning algorithms. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=61TKzU9B96">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning has the potential to address various scientific problems. In this paper, we implement an optics simulation environment for reinforcement learning based controllers. The environment captures the essence of nonconvexity, nonlinearity, and time-dependent noise inherent in optical systems, offering a more realistic setting. Subsequently, we provide the benchmark results of several reinforcement learning algorithms on the proposed simulation environment. The experimental findings demonstrate the superiority of off-policy reinforcement learning approaches over traditional control algorithms in navigating the intricacies of complex optical control environments.},
  archive      = {J_TMLR},
  author       = {ABULIKEMU ABUDUWEILI and Changliu Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {An optical control environment for benchmarking reinforcement learning algorithms},
  url          = {https://openreview.net/forum?id=61TKzU9B96},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Limitation of characterizing implicit regularization by
data-independent functions. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=140kSqm0uy">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, understanding the implicit regularization of neural networks (NNs) has become a central task in deep learning theory. However, implicit regularization is itself not completely defined and well understood. In this work, we attempt to mathematically define and study implicit regularization. Importantly, we explore the limitations of a common approach to characterizing implicit regularization using data-independent functions. We propose two dynamical mechanisms, i.e., Two-point and One-point Overlapping mechanisms, based on which we provide two recipes for producing classes of one-hidden-neuron NNs that provably cannot be fully characterized by a type of or all data-independent functions. Following the previous works, our results further emphasize the profound data dependency of implicit regularization in general, inspiring us to study in detail the data dependency of NN implicit regularization in the future.},
  archive      = {J_TMLR},
  author       = {Leyang Zhang and Zhi-Qin John Xu and Tao Luo and Yaoyu Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Limitation of characterizing implicit regularization by data-independent functions},
  url          = {https://openreview.net/forum?id=140kSqm0uy},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Conformal prediction under ambiguous ground truth.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=CAd6V2qXxc">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conformal Prediction (CP) allows to perform rigorous uncertainty quantification by constructing a prediction set $C(X)$ satisfying $\mathbb{P}(Y \in C(X))\geq 1-\alpha$ for a user-chosen $\alpha \in [0,1]$ by relying on calibration data $(X_1,Y_1),...,(X_n,Y_n)$ from $\mathbb{P}=\mathbb{P}^{X} \otimes \mathbb{P}^{Y|X}$. It is typically implicitly assumed that $\mathbb{P}^{Y|X}$ is the ``true&#39;&#39; posterior label distribution. However, in many real-world scenarios, the labels $Y_1,...,Y_n$ are obtained by aggregating expert opinions using a voting procedure, resulting in a one-hot distribution $\mathbb{P}_{\textup{vote}}^{Y|X}$. This is the case for most datasets, even well-known ones like ImageNet. For such ``voted&#39;&#39; labels, CP guarantees are thus w.r.t. $\mathbb{P}_{\textup{vote}}=\mathbb{P}^X \otimes \mathbb{P}_{\textup{vote}}^{Y|X}$ rather than the true distribution $\mathbb{P}$. In cases with unambiguous ground truth labels, the distinction between $\mathbb{P}_{\textup{vote}}$ and $\mathbb{P}$ is irrelevant. However, when experts do not agree because of ambiguous labels, approximating $\mathbb{P}^{Y|X}$ with a one-hot distribution $\mathbb{P}_{\textup{vote}}^{Y|X}$ ignores this uncertainty. In this paper, we propose to leverage expert opinions to approximate $\mathbb{P}^{Y|X}$ using a non-degenerate distribution $\mathbb{P}_{\textup{agg}}^{Y|X}$. We then develop \emph{Monte Carlo CP} procedures which provide guarantees w.r.t. $\mathbb{P}_{\textup{agg}}=\mathbb{P}^X \otimes \mathbb{P}_{\textup{agg}}^{Y|X}$ by sampling multiple synthetic pseudo-labels from $\mathbb{P}_{\textup{agg}}^{Y|X}$ for each calibration example $X_1,...,X_n$. In a case study of skin condition classification with significant disagreement among expert annotators, we show that applying CP w.r.t. $\mathbb{P}_{\textup{vote}}$ under-covers expert annotations: calibrated for $72\%$ coverage, it falls short by on average $10\%$; our Monte Carlo CP closes this gap both empirically and theoretically. We also extend Monte Carlo CP to multi-label classification and CP with calibration examples enriched through data augmentation.},
  archive      = {J_TMLR},
  author       = {David Stutz and Abhijit Guha Roy and Tatiana Matejovicova and Patricia Strachan and Ali Taylan Cemgil and Arnaud Doucet},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Conformal prediction under ambiguous ground truth},
  url          = {https://openreview.net/forum?id=CAd6V2qXxc},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Discretization invariant networks for learning maps between
neural fields. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=CpYBAqDgmz">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the emergence of powerful representations of continuous data in the form of neural fields, there is a need for discretization invariant learning: an approach for learning maps between functions on continuous domains without being sensitive to how the function is sampled. We present a new framework for understanding and designing discretization invariant neural networks (DI-Nets), which generalizes many discrete networks such as convolutional neural networks as well as continuous networks such as neural operators. Our analysis establishes upper bounds on the deviation in model outputs under different finite discretizations, and highlights the central role of point set discrepancy in characterizing such bounds. This insight leads to the design of a family of neural networks driven by numerical integration via quasi-Monte Carlo sampling with discretizations of low discrepancy. We prove by construction that DI-Nets universally approximate a large class of maps between integrable function spaces, and show that discretization invariance also describes backpropagation through such models. Applied to neural fields, convolutional DI-Nets can learn to classify and segment visual data under various discretizations, and sometimes generalize to new types of discretizations at test time.},
  archive      = {J_TMLR},
  author       = {Clinton Wang and Polina Golland},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Discretization invariant networks for learning maps between neural fields},
  url          = {https://openreview.net/forum?id=CpYBAqDgmz},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inverse scaling: When bigger isn’t better. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=DwgRm72GQF">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Work on scaling laws has found that large language models (LMs) show predictable improvements to overall loss with increased scale (model size, training data, and compute). Here, we present evidence for the claim that LMs may show inverse scaling, or worse task performance with increased scale, e.g., due to flaws in the training objective and data. We present empirical evidence of inverse scaling on 11 datasets collected by running a public contest, the Inverse Scaling Prize, with a substantial prize pool. Through analysis of the datasets, along with other examples found in the literature, we identify four potential causes of inverse scaling: (i) preference to repeat memorized sequences over following in-context instructions, (ii) imitation of undesirable patterns in the training data, (iii) tasks containing an easy distractor task which LMs could focus on, rather than the harder real task, and (iv) correct but misleading few-shot demonstrations of the task. We release the winning datasets at inversescaling.com/data to allow for further investigation of inverse scaling. Our tasks have helped drive the discovery of U-shaped and inverted-U scaling trends, where an initial trend reverses, suggesting that scaling trends are less reliable at predicting the behavior of larger-scale models than previously understood. Overall, our results suggest that there are tasks for which increased model scale alone may not lead to progress, and that more careful thought needs to go into the data and objectives for training language models.},
  archive      = {J_TMLR},
  author       = {Ian R. McKenzie and Alexander Lyzhov and Michael Martin Pieler and Alicia Parrish and Aaron Mueller and Ameya Prabhu and Euan McLean and Xudong Shen and Joe Cavanagh and Andrew George Gritsevskiy and Derik Kauffman and Aaron T. Kirtland and Zhengping Zhou and Yuhui Zhang and Sicong Huang and Daniel Wurgaft and Max Weiss and Alexis Ross and Gabriel Recchia and Alisa Liu and Jiacheng Liu and Tom Tseng and Tomasz Korbak and Najoung Kim and Samuel R. Bowman and Ethan Perez},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Inverse scaling: When bigger isn&#39;t better},
  url          = {https://openreview.net/forum?id=DwgRm72GQF},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-label node classification on graph-structured data.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=EZhkV2BjDP">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have shown state-of-the-art improvements in node classification tasks on graphs. While these improvements have been largely demonstrated in a multi-class classification scenario, a more general and realistic scenario in which each node could have multiple labels has so far received little attention. The first challenge in conducting focused studies on multi-label node classification is the limited number of publicly available multi-label graph datasets. Therefore, as our first contribution, we collect and release three real-world biological datasets and develop a multi-label graph generator to generate datasets with tunable properties. While high label similarity (high homophily) is usually attributed to the success of GNNs, we argue that a multi-label scenario does not follow the usual semantics of homophily and heterophily so far defined for a multi-class scenario. As our second contribution, we define homophily and Cross-Class Neighborhood Similarity for the multi-label scenario and provide a thorough analyses of the collected $9$ multi-label datasets. Finally, we perform a large-scale comparative study with $8$ methods and $9$ datasets and analyse the performances of the methods to assess the progress made by current state of the art in the multi-label node classification scenario. We release our benchmark at https://github.com/Tianqi-py/MLGNC.},
  archive      = {J_TMLR},
  author       = {Tianqi Zhao and Thi Ngan Dong and Alan Hanjalic and Megha Khosla},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Multi-label node classification on graph-structured data},
  url          = {https://openreview.net/forum?id=EZhkV2BjDP},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Projected randomized smoothing for certified adversarial
robustness. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=FObkvLwNSo">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Randomized smoothing is the current state-of-the-art method for producing provably robust classifiers. While randomized smoothing typically yields robust $\ell_2$-ball certificates, recent research has generalized provable robustness to different norm balls as well as anisotropic regions. This work considers a classifier architecture that first projects onto a low-dimensional approximation of the data manifold and then applies a standard classifier. By performing randomized smoothing in the low-dimensional projected space, we characterize the certified region of our smoothed composite classifier back in the high-dimensional input space and prove a tractable lower bound on its volume. We show experimentally on CIFAR-10 and SVHN that classifiers without the initial projection are vulnerable to perturbations that are normal to the data manifold and yet are captured by the certified regions of our method. We compare the volume of our certified regions against various baselines and show that our method improves on the state-of-the-art by many orders of magnitude.},
  archive      = {J_TMLR},
  author       = {Samuel Pfrommer and Brendon G. Anderson and Somayeh Sojoudi},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Projected randomized smoothing for certified adversarial robustness},
  url          = {https://openreview.net/forum?id=FObkvLwNSo},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). VoLTA: Vision-language transformer with weakly-supervised
local-feature alignment. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Kt2VJrCKo4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-language pre-training (VLP) has recently proven highly effective for various uni- and multi-modal downstream applications. However, most existing end-to-end VLP methods use high-resolution image-text-box data to perform well on fine-grained region-level tasks, such as object detection, segmentation, and referring expression comprehension. Unfortunately, such high-resolution images with accurate bounding box annotations are expensive to collect and use for supervision at scale. In this work, we propose VoLTA (Vision Language Transformer with weakly-supervised local-feature Alignment), a new VLP paradigm that only utilizes image-caption data but achieves fine-grained region-level image understanding, eliminating the need for expensive box annotations. VoLTA adopts graph optimal transport-based weakly-supervised alignment on local image patches and text tokens to germinate an explicit, self-normalized, and interpretable low-level matching criterion. In addition, VoLTA pushes multi-modal fusion deep into the uni-modal backbones during pre training and removes fusion-specific transformer layers, further reducing memory requirements. Extensive experiments on a wide range of vision- and vision-language downstream tasks demonstrate the effectiveness of VoLTA on fine-grained applications without compromising the coarse-grained downstream performance, often outperforming methods using significantly more caption and box annotations.},
  archive      = {J_TMLR},
  author       = {Shraman Pramanick and Li Jing and Sayan Nag and Jiachen Zhu and Hardik J Shah and Yann LeCun and Rama Chellappa},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {VoLTA: Vision-language transformer with weakly-supervised local-feature alignment},
  url          = {https://openreview.net/forum?id=Kt2VJrCKo4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive hyperparameter selection for differentially private
gradient descent. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=LLKI5Lq2YN">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an adaptive mechanism for hyperparameter selection in differentially private optimization that addresses the inherent trade-off between utility and privacy. The mechanism eliminates the often unstructured and time-consuming manual effort of selecting hyperparameters and avoids the additional privacy costs that hyperparameter selection otherwise incurs on top of that of the actual algorithm. We instantiate our mechanism for noisy gradient descent on non-convex, convex and strongly convex loss functions, respectively, to derive schedules for the noise variance and step size. These schedules account for the properties of the loss function and adapt to convergence metrics such as the gradient norm. When using these schedules, we show that noisy gradient descent converges at essentially the same rate as its noise-free counterpart. Numerical experiments show that the schedules consistently perform well across a range of datasets without manual tuning.},
  archive      = {J_TMLR},
  author       = {Dominik Fay and Sindri Magnússon and Jens Sjölund and Mikael Johansson},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Adaptive hyperparameter selection for differentially private gradient descent},
  url          = {https://openreview.net/forum?id=LLKI5Lq2YN},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fourier features in reinforcement learning with neural
networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=LWotmCKC6Y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In classic Reinforcement Learning (RL), the performance of algorithms depends critically on data representation, i.e., the way the states of the system are represented as features. Choosing appropriate features for a task is an important way of adding prior domain knowledge since cleverly distributing information into states facilitates appropriate generalization. For linear function approximations, the representation is usually hand-designed according to the task at hand and projected into a higher-dimensional space to facilitate linear separation. Among the feature encodings used in RL for linear function approximation, we can mention in a non-exhaustive way Polynomial Features or Tile Coding. However, the main bottleneck of such feature encodings is that they do not scale to high-dimensional inputs as they grow exponentially in size with the input dimension.},
  archive      = {J_TMLR},
  author       = {David Brellmann and David Filliat and Goran Frehse},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Fourier features in reinforcement learning with neural networks},
  url          = {https://openreview.net/forum?id=LWotmCKC6Y},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed newton-type methods with communication
compression and bernoulli aggregation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=NekBTCKJ1H">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite their high computation and communication costs, Newton-type methods remain an appealing option for distributed training due to their robustness against ill-conditioned convex problems. In this work, we study communication compression and aggregation mechanisms for curvature information in order to reduce these costs while preserving theoretically superior local convergence guarantees. We prove that the recently developed class of three point compressors (3PC) of [Richtarik et al., 2022] for gradient communication can be generalized to Hessian communication as well. This result opens up a wide variety of communication strategies, such as contractive compression and lazy aggregation, available to our disposal to compress prohibitively costly curvature information. Moreover, we discovered several new 3PC mechanisms, such as adaptive thresholding and Bernoulli aggregation, which require reduced communication and occasional Hessian computations. Furthermore, we extend and analyze our approach to bidirectional communication compression and partial device participation setups to cater to the practical considerations of applications in federated learning. For all our methods, we derive fast condition-number-independent local linear and/or superlinear convergence rates. Finally, with extensive numerical evaluations on convex optimization problems, we illustrate that our designed schemes achieve state-of-the-art communication complexity compared to several key baselines using second-order information.},
  archive      = {J_TMLR},
  author       = {Rustem Islamov and Xun Qian and Slavomir Hanzely and Mher Safaryan and Peter Richtárik},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Distributed newton-type methods with communication compression and bernoulli aggregation},
  url          = {https://openreview.net/forum?id=NekBTCKJ1H},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual cognitive architecture: Incorporating biases and
multi-memory systems for lifelong learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=PEyVq0hlO3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks (ANNs) exhibit a narrow scope of expertise on stationary independent data. However, the data in the real world is continuous and dynamic, and ANNs must adapt to novel scenarios while also retaining the learned knowledge to become lifelong learners. The ability of humans to excel at these tasks can be attributed to multiple factors ranging from cognitive computational structures, cognitive biases, and the multi-memory systems in the brain. We incorporate key concepts from each of these to design a novel framework, Dual Cognitive Architecture (DUCA), which includes multiple sub-systems, implicit and explicit knowledge representation dichotomy, inductive bias, and a multi-memory system. DUCA shows improvement across different settings and datasets, and it also exhibits reduced task recency bias, without the need for extra information. To further test the versatility of lifelong learning methods on a challenging distribution shift, we introduce a novel domain-incremental dataset DN4IL. In addition to improving performance on existing benchmarks, DUCA also demonstrates superior performance on this complex dataset.},
  archive      = {J_TMLR},
  author       = {Shruthi Gowda and Bahram Zonooz and Elahe Arani},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Dual cognitive architecture: Incorporating biases and multi-memory systems for lifelong learning},
  url          = {https://openreview.net/forum?id=PEyVq0hlO3},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identifying latent distances with finslerian geometry.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Q2Gi0TUAdS">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Riemannian geometry provides us with powerful tools to explore the latent space of generative models while preserving the underlying structure of the data. The latent space can be equipped it with a Riemannian metric, pulled back from the data manifold. With this metric, we can systematically navigate the space relying on geodesics defined as the shortest curves between two points. Generative models are often stochastic, causing the data space, the Riemannian metric, and the geodesics, to be stochastic as well. Stochastic objects are at best impractical, and at worst impossible, to manipulate. A common solution is to approximate the stochastic pullback metric by its expectation. But the geodesics derived from this expected Riemannian metric do not correspond to the expected length-minimising curves. In this work, we propose another metric whose geodesics explicitly minimise the expected length of the pullback metric. We show this metric defines a Finsler metric, and we compare it with the expected Riemannian metric. In high dimensions, we prove that both metrics converge to each other at a rate of $\mathcal{O}\left(\frac{1}{D}\right)$. This convergence implies that the established expected Riemannian metric is an accurate approximation of the theoretically more grounded Finsler metric. This provides justification for using the expected Riemannian metric for practical implementations.},
  archive      = {J_TMLR},
  author       = {Alison Pouplin and David Eklund and Carl Henrik Ek and Søren Hauberg},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Identifying latent distances with finslerian geometry},
  url          = {https://openreview.net/forum?id=Q2Gi0TUAdS},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Physics informed neural networks for elliptic equations with
oscillatory differential operators. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=QfyVqvpg7u">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics informed neural network (PINN) based solution methods for differential equations have recently shown success in a variety of scientific computing applications. Several authors have reported difficulties, however, when using PINNs to solve equations with multiscale features. The objective of the present work is to illustrate and explain the difficulty of using standard PINNs for the particular case of divergence-form elliptic partial differential equations (PDEs) with oscillatory coefficients present in the differential operator. We show that if the coefficient in the elliptic operator $a^{\epsilon}(x)$ is of the form $a(x/\epsilon)$ for a 1-periodic coercive function $a(\cdot)$, then the Frobenius norm of the neural tangent kernel (NTK) matrix associated to the loss function grows as $1/\epsilon^2$. This implies that as the separation of scales in the problem increases, training the neural network with gradient descent based methods to achieve an accurate approximation of the solution to the PDE becomes increasingly difficult. Numerical examples illustrate the stiffness of the optimization problem.},
  archive      = {J_TMLR},
  author       = {Arnav Gangal and Luis Kim and Sean Patrick Carney},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Physics informed neural networks for elliptic equations with oscillatory differential operators},
  url          = {https://openreview.net/forum?id=QfyVqvpg7u},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gradient masked averaging for federated learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=REAyrhRYAo">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is an emerging paradigm that permits a large number of clients with heterogeneous data to coordinate learning of a unified global model without the need to share data amongst each other. A major challenge in federated learning is the heterogeneity of data across client, which can degrade the performance of standard FL algorithms. Standard FL algorithms involve averaging of model parameters or gradient updates to approximate the global model at the server. However, we argue that in heterogeneous settings, averaging can result in information loss and lead to poor generalization due to the bias induced by dominant client gradients. We hypothesize that to generalize better across non-i.i.d datasets, the algorithms should focus on learning the invariant mechanism that is constant while ignoring spurious mechanisms that differ across clients. Inspired from recent works in Out-of-Distribution generalization, we propose a gradient masked averaging approach for FL as an alternative to the standard averaging of client updates. This aggregation technique for client updates can be adapted as a drop-in replacement in most existing federated algorithms. We perform extensive experiments on multiple FL algorithms with in-distribution, real-world, feature-skewed out-of-distribution, and quantity imbalanced datasets and show that it provides consistent improvements, particularly in the case of heterogeneous clients.},
  archive      = {J_TMLR},
  author       = {Irene Tenison and Sai Aravind Sreeramadas and Vaikkunth Mugunthan and Edouard Oyallon and Irina Rish and Eugene Belilovsky},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Gradient masked averaging for federated learning},
  url          = {https://openreview.net/forum?id=REAyrhRYAo},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards stability of autoregressive neural operators.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=RFfUUtKYOG">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural operators have proven to be a promising approach for modeling spatiotemporal systems in the physical sciences. However, training these models for large systems can be quite challenging as they incur significant computational and memory expense---these systems are often forced to rely on autoregressive time-stepping of the neural network to predict future temporal states. While this is effective in managing costs, it can lead to uncontrolled error growth over time and eventual instability. We analyze the sources of this autoregressive error growth using prototypical neural operator models for physical systems and explore ways to mitigate it. We introduce architectural and application-specific improvements that allow for careful control of instability-inducing operations within these models without inflating the compute/memory expense. We present results on several scientific systems that include Navier-Stokes fluid flow, rotating shallow water, and a high-resolution global weather forecasting system. We demonstrate that applying our design principles to neural operators leads to significantly lower errors for long-term forecasts as well as longer time horizons without qualitative signs of divergence compared to the original models for these systems. We open-source our code for reproducibility.},
  archive      = {J_TMLR},
  author       = {Michael McCabe and Peter Harrington and Shashank Subramanian and Jed Brown},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards stability of autoregressive neural operators},
  url          = {https://openreview.net/forum?id=RFfUUtKYOG},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Beyond distribution shift: Spurious features through the
lens of training dynamics. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Tkvmt9nDmB">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) are prone to learning spurious features that correlate with the label during training but are irrelevant to the learning problem. This hurts model generalization and poses problems when deploying them in safety-critical applications. This paper aims to better understand the effects of spurious features through the lens of the learning dynamics of the internal neurons during the training process. We make the following observations: (1) While previous works highlight the harmful effects of spurious features on the generalization ability of DNNs, we emphasize that not all spurious features are harmful. Spurious features can be &quot;benign&quot; or &quot;harmful&quot; depending on whether they are &quot;harder&quot; or &quot;easier&quot; to learn than the core features for a given model. This definition is model and dataset dependent. (2) We build upon this premise and use instance difficulty methods (like Prediction Depth) to quantify &quot;easiness&quot; for a given model and to identify this behavior during the training phase. (3) We empirically show that the harmful spurious features can be detected by observing the learning dynamics of the DNN&#39;s early layers. In other words, easy features learned by the initial layers of a DNN early during the training can (potentially) hurt model generalization. We verify our claims on medical and vision datasets, both simulated and real, and justify the empirical success of our hypothesis by showing the theoretical connections between Prediction Depth and information-theoretic concepts like $\mathcal{V}$-usable information. Lastly, our experiments show that monitoring only accuracy during training (as is common in machine learning pipelines) is insufficient to detect spurious features. We, therefore, highlight the need for monitoring early training dynamics using suitable instance difficulty metrics.},
  archive      = {J_TMLR},
  author       = {Nihal Murali and Aahlad Manas Puli and Ke Yu and Rajesh Ranganath and kayhan Batmanghelich},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Beyond distribution shift: Spurious features through the lens of training dynamics},
  url          = {https://openreview.net/forum?id=Tkvmt9nDmB},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiscale causal structure learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Ub6XILEF9x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal structure learning methods are vital for unveiling causal relationships embedded into observed data. However, the state of the art suffers a major limitation: it assumes that causal interactions occur only at the frequency at which data is observed. To address this limitation, this paper proposes a method that allows structural learning of linear causal relationships occurring at different time scales. Specifically, we explicitly take into account instantaneous and lagged inter-relations between multiple time series, represented at different scales, hinging on wavelet transform. We cast the problem as the learning of a multiscale causal graph having sparse structure and dagness constraints, enforcing causality through directed and acyclic topology. To solve the resulting (non-convex) formulation, we propose an algorithm termed MS-CASTLE, which exhibits consistent performance across different noise distributions and wavelet choices. We also propose a single-scale version of our algorithm, SS-CASTLE, which outperforms existing methods in computational efficiency, performance, and robustness on synthetic data. Finally, we apply the proposed approach to learn the multiscale causal structure of the risk of 15 global equity markets, during covid-19 pandemic, illustrating the importance of multiscale analysis to reveal useful interactions at different time resolutions. Financial investors can leverage our approach to manage risk within equity portfolios from a causal perspective, tailored to their investment horizon.},
  archive      = {J_TMLR},
  author       = {Gabriele D&#39;Acunto and Paolo Di Lorenzo and Sergio Barbarossa},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Multiscale causal structure learning},
  url          = {https://openreview.net/forum?id=Ub6XILEF9x},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diagnostic tool for out-of-sample model evaluation.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Ulf3QZG9DC">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessment of model fitness is a key part of machine learning. The standard paradigm of model evaluation is analysis of the average loss over future data. This is often explicit in model fitting, where we select models that minimize the average loss over training data as a surrogate, but comes with limited theoretical guarantees. In this paper, we consider the problem of characterizing a batch of out-of-sample losses of a model using a calibration data set. We provide finite-sample limits on the out-of-sample losses that are statistically valid under quite general conditions and propose a diagonistic tool that is simple to compute and interpret. Several numerical experiments are presented to show how the proposed method quantifies the impact of distribution shifts, aids the analysis of regression, and enables model selection as well as hyperparameter tuning.},
  archive      = {J_TMLR},
  author       = {Ludvig Hult and Dave Zachariah and Peter Stoica},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Diagnostic tool for out-of-sample model evaluation},
  url          = {https://openreview.net/forum?id=Ulf3QZG9DC},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-validation for geospatial data: Estimating
generalization performance in geostatistical problems. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=VgJhYu7FmQ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geostatistical learning problems are frequently characterized by spatial autocorrelation in the input features and/or the potential for covariate shift at test time. These realities violate the classical assumption of independent, identically distributed data, upon which most cross-validation algorithms rely in order to estimate the generalization performance of a model. In this paper, we present a theoretical criterion for unbiased cross-validation estimators in the geospatial setting. We also introduce a new cross-validation algorithm to evaluate models, inspired by the challenges of geospatial problems. We apply a framework for categorizing problems into different types of geospatial scenarios to help practitioners select an appropriate cross-validation strategy. Our empirical analyses compare cross-validation algorithms on both simulated and several real datasets to develop recommendations for a variety of geospatial settings. This paper aims to draw attention to some challenges that arise in model evaluation for geospatial problems and to provide guidance for users.},
  archive      = {J_TMLR},
  author       = {Jing Wang and Laurel Hopkins and Tyler Hallman and W. Douglas Robinson and Rebecca Hutchinson},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Cross-validation for geospatial data: Estimating generalization performance in geostatistical problems},
  url          = {https://openreview.net/forum?id=VgJhYu7FmQ},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An analysis of model-based reinforcement learning from
abstracted observations. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=YQWOzzSMPp">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many methods for Model-based Reinforcement learning (MBRL) in Markov decision processes (MDPs) provide guarantees for both the accuracy of the model they can deliver and the learning efficiency. At the same time, state abstraction techniques allow for a reduction of the size of an MDP while maintaining a bounded loss with respect to the original problem. Therefore, it may come as a surprise that no such guarantees are available when combining both techniques, i.e., where MBRL merely observes abstract states. Our theoretical analysis shows that abstraction can introduce a dependence between samples collected online (e.g., in the real world). That means that, without taking this dependence into account, results for MBRL do not directly extend to this setting. Our result shows that we can use concentration inequalities for martingales to overcome this problem. This result makes it possible to extend the guarantees of existing MBRL algorithms to the setting with abstraction. We illustrate this by combining R-MAX, a prototypical MBRL algorithm, with abstraction, thus producing the first performance guarantees for model-based ‘RL from Abstracted Observations’: model-based reinforcement learning with an abstract model.},
  archive      = {J_TMLR},
  author       = {Rolf A. N. Starre and Marco Loog and Elena Congeduti and Frans A Oliehoek},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {An analysis of model-based reinforcement learning from abstracted observations},
  url          = {https://openreview.net/forum?id=YQWOzzSMPp},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Benefits of max pooling in neural networks: Theoretical and
experimental evidence. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=YgeXqrH7gA">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When deep neural networks became state of the art image classifiers, numerous max pooling operations were an important component of the architecture. However, modern computer vision networks typically have few, if any, max pooling operations. To understand whether this trend is justified, we develop a mathematical framework analyzing ReLU based approximations of max pooling, and prove a sense in which max pooling cannot be replicated. We formulate and analyze a novel class of optimal approximations, and find that the residual can be made exponentially small in the kernel size, but only with an exponentially wide approximation. This work gives a theoretical basis for understanding the reduced use of max pooling in newer architectures. It also enables us to establish an empirical observation about natural images: since max pooling does not seem necessary, the inputs on which max pooling is distinct – those with a large difference between the max and other values – are not prevalent.},
  archive      = {J_TMLR},
  author       = {Kyle Matoba and Nikolaos Dimitriadis and François Fleuret},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Benefits of max pooling in neural networks: Theoretical and experimental evidence},
  url          = {https://openreview.net/forum?id=YgeXqrH7gA},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). <span class="math inline"><em>f</em></span>-MICL:
Understanding and generalizing InfoNCE-based contrastive learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ZD03VUZmRx">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In self-supervised contrastive learning, a widely-adopted objective function is InfoNCE, which uses the heuristic cosine similarity for the representation comparison, and is closely related to maximizing the Kullback-Leibler (KL)-based mutual information. In this paper, we aim at answering two intriguing questions: (1) Can we go beyond the KL-based objective? (2) Besides the popular cosine similarity, can we design a better similarity function? We provide answers to both questions by generalizing the KL-based mutual information to the $f$-Mutual Information in Contrastive Learning ($f$-MICL) using the $f$-divergences. To answer the first question, we provide a wide range of $f$-MICL objectives which share the nice properties of InfoNCE (e.g., alignment and uniformity), and meanwhile result in similar or even superior performance. For the second question, assuming that the joint feature distribution is proportional to the Gaussian kernel, we derive an $f$-Gaussian similarity with better interpretability and empirical performance. Finally, we identify close relationships between the $f$-MICL objective and several popular InfoNCE-based objectives. Using benchmark tasks from both vision and natural language, we empirically evaluate $f$-MICL with different $f$-divergences on various architectures (SimCLR, MoCo, and MoCo v3) and datasets. We observe that $f$-MICL generally outperforms the benchmarks and the best-performing $f$-divergence is task and dataset dependent.},
  archive      = {J_TMLR},
  author       = {Yiwei Lu and Guojun Zhang and Sun Sun and Hongyu Guo and Yaoliang Yu},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {$f$-MICL: Understanding and generalizing InfoNCE-based contrastive learning},
  url          = {https://openreview.net/forum?id=ZD03VUZmRx},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved baselines for vision-language pre-training.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=a7nvXxNmdV">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive learning has emerged as an efficient framework to learn multimodal representations. CLIP, a seminal work in this area, achieved impressive results by training on paired image-text data using the contrastive loss. Recent work claims improvements over CLIP using additional non-contrastive losses inspired from self-supervised learning. However, it is sometimes hard to disentangle the contribution of these additional losses from other implementation details, \eg, data augmentation or regularization techniques, used to train the model. To shed light on this matter, in this paper, we first propose, implement and evaluate several baselines obtained by combining contrastive learning with recent advances in self-supervised learning. In particular, we use the loss functions that were proven successful for visual self-supervised learning to align image and text modalities. We find that these baselines outperform a basic implementation of CLIP. However, when a stronger training recipe is employed, the advantage disappears. Indeed, we find that a simple CLIP baseline can also be improved substantially, up to a 25\% relative improvement on downstream zero-shot tasks, by using well-known training techniques that are popular in other subfields. Moreover, we discover that it is enough to apply image and text augmentations to make up for most of the improvement attained by prior works. With our improved training recipe for CLIP, we obtain state-of-the-art performance on four standard datasets, and consistently outperform prior work (up to +4\% on the largest dataset), while being substantially simpler.},
  archive      = {J_TMLR},
  author       = {Enrico Fini and Pietro Astolfi and Adriana Romero-Soriano and Jakob Verbeek and Michal Drozdzal},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Improved baselines for vision-language pre-training},
  url          = {https://openreview.net/forum?id=a7nvXxNmdV},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Local advantage networks for multi-agent reinforcement
learning in dec-POMDPs. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=adpKzWQunW">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many recent successful off-policy multi-agent reinforcement learning (MARL) algorithms for cooperative partially observable environments focus on finding factorized value functions, leading to convoluted network structures. Building on the structure of independent Q-learners, our LAN algorithm takes a radically different approach, leveraging a dueling architecture to learn for each agent a decentralized best-response policies via individual advantage functions. The learning is stabilized by a centralized critic whose primary objective is to reduce the moving target problem of the individual advantages. The critic, whose network&#39;s size is independent of the number of agents, is cast aside after learning. Evaluation on the StarCraft II multi-agent challenge benchmark shows that LAN reaches state-of-the-art performance and is highly scalable with respect to the number of agents, opening up a promising alternative direction for MARL research.},
  archive      = {J_TMLR},
  author       = {Raphaël Avalos and Mathieu Reymond and Ann Nowe and Diederik M Roijers},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Local advantage networks for multi-agent reinforcement learning in dec-POMDPs},
  url          = {https://openreview.net/forum?id=adpKzWQunW},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Convergence of SGD for training neural networks with sliced
wasserstein losses. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=aqqfB3p9ZA">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal Transport has sparked vivid interest in recent years, in particular thanks to the Wasserstein distance, which provides a geometrically sensible and intuitive way of comparing probability measures. For computational reasons, the Sliced Wasserstein (SW) distance was introduced as an alternative to the Wasserstein distance, and has seen uses for training generative Neural Networks (NNs). While convergence of Stochastic Gradient Descent (SGD) has been observed practically in such a setting, there is to our knowledge no theoretical guarantee for this observation. Leveraging recent works on convergence of SGD on non-smooth and non-convex functions by Bianchi et al. (2022), we aim to bridge that knowledge gap, and provide a realistic context under which fixed-step SGD trajectories for the SW loss on NN parameters converge. More precisely, we show that the trajectories approach the set of (sub)-gradient flow equations as the step decreases. Under stricter assumptions, we show a much stronger convergence result for noised and projected SGD schemes, namely that the long-run limits of the trajectories approach a set of generalised critical points of the loss function.},
  archive      = {J_TMLR},
  author       = {Eloi Tanguy},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Convergence of SGD for training neural networks with sliced wasserstein losses},
  url          = {https://openreview.net/forum?id=aqqfB3p9ZA},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multimodal language learning for object retrieval in low
data regimes in the face of missing modalities. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=cXa6Xdm0v7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our study is motivated by robotics, where when dealing with robots or other physical systems, we often need to balance competing concerns of relying on complex, multimodal data coming from a variety of sensors with a general lack of large representative datasets. Despite the complexity of modern robotic platforms and the need for multimodal interaction, there has been little research on integrating more than two modalities in a low data regime with the real-world constraint that sensors fail due to obstructions or adverse conditions. In this work, we consider a case in which natural language is used as a retrieval query against objects, represented across multiple modalities, in a physical environment. We introduce extended multimodal alignment (EMMA), a method that learns to select the appropriate object while jointly refining modality-specific embeddings through a geometric (distance-based) loss. In contrast to prior work, our approach is able to incorporate an arbitrary number of views (modalities) of a particular piece of data. We demonstrate the efficacy of our model on a grounded language object retrieval scenario. We show that our model outperforms state-of-the-art baselines when little training data is available. Our code is available at https://github.com/kasraprime/EMMA.},
  archive      = {J_TMLR},
  author       = {Kasra Darvish and Edward Raff and Francis Ferraro and Cynthia Matuszek},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Multimodal language learning for object retrieval in low data regimes in the face of missing modalities},
  url          = {https://openreview.net/forum?id=cXa6Xdm0v7},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Worst-case feature risk minimization for data-efficient
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=czev0exHXT">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models typically require massive amounts of annotated data to train a strong model for a task of interest. However, data annotation is time-consuming and costly. How to use labeled data from a related but distinct domain, or just a few samples to train a satisfactory model are thus important questions. To achieve this goal, models should resist overfitting to the specifics of the training data in order to generalize well to new data. This paper proposes a novel Worst-case Feature Risk Minimization (WFRM) method that helps improve model generalization. Specifically, we tackle a minimax optimization problem in feature space at each training iteration. Given the input features, we seek the feature perturbation that maximizes the current training loss and then minimizes the training loss of the worst-case features. By incorporating our WFRM during training, we significantly improve model generalization under distributional shift – Domain Generalization (DG) and in the low-data regime – Few-shot Learning (FSL). We theoretically analyze WFRM and find the key reason why it works better than ERM – it induces an empirical risk-based semi-adaptive $L_{2}$ regularization of the classifier weights, enabling a better risk-complexity trade-off. We evaluate WFRM on two data-efficient learning tasks, including three standard DG benchmarks of PACS, VLCS, OfficeHome and the most challenging FSL benchmark Meta-Dataset. Despite the simplicity, our method consistently improves various DG and FSL methods, leading to the new state-of-the-art performances in all settings. Codes &amp; models will be released at https://github.com/jslei/WFRM.},
  archive      = {J_TMLR},
  author       = {Jingshi Lei and Da Li and Chengming Xu and Liming Fang and Timothy Hospedales and Yanwei Fu},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Worst-case feature risk minimization for data-efficient learning},
  url          = {https://openreview.net/forum?id=czev0exHXT},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Greedier is better: Selecting multiple neighbors per
iteration for sparse subspace clustering. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=djD8IbSvgm">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse subspace clustering (SSC) using greedy-based neighbor selection, such as orthogonal matching pursuit (OMP), has been known as a popular computationally-efficient alternative to the standard $\ell_1$-minimization based methods. However, existing stopping rules of OMP to halt neighbor search needs additional offline work to estimate some ground truths, e.g., subspace dimension and/or noise strength. This paper proposes a new SSC scheme using generalized OMP (GOMP), a soup-up of OMP whereby multiple, say $p(\geq1)$, neighbors are identified per iteration to further speed up neighbor acquisition, along with a new stopping rule requiring nothing more than a knowledge of the ambient signal dimension and the number $p$ of identified neighbors in each iteration. Compared to conventional OMP (i.e., $p=1$), the proposed GOMP method involves fewer iterations, thereby enjoying lower algorithmic complexity. Under the semi-random model, analytic performance guarantees are provided. It is shown that, with a high probability, (i) GOMP can retrieve more true neighbors than OMP, consequently yielding higher data clustering accuracy, and (ii) the proposed stopping rule terminates neighbor search once the number of recovered neighbors is close to the subspace dimension. Issues about selecting $p$ for practical implementation are also discussed. Computer simulations using both synthetic and real data are provided to demonstrate the effectiveness of the proposed approach and validate our analytic study.},
  archive      = {J_TMLR},
  author       = {Jwo-Yuh Wu and Liang-Chi Huang and Wen Hsuan Li and Chun-Hung Liu and Rung-Hung Gau},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Greedier is better: Selecting multiple neighbors per iteration for sparse subspace clustering},
  url          = {https://openreview.net/forum?id=djD8IbSvgm},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CAE v2: Context autoencoder with CLIP latent alignment.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=f36LaK7M0F">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Masked image modeling (MIM) learns visual representations by predicting the masked patches on a pre-defined target. Inspired by MVP(Wei et al., 2022b) that displays impressive gains with CLIP, in this work, we also employ the semantically rich CLIP latent as target and further tap its potential by introducing a new MIM pipeline, CAE v2, to learn a high-quality encoder and facilitate model convergence on the pre-training task. CAE v2 is an improved variant of CAE (Chen et al., 2023), applying the CLIP latent on two pretraining tasks, i.e., visible latent alignment and masked latent alignment. Visible latent alignment directly mimics the visible latent representations from the encoder to the corresponding CLIP latent, which is beneficial for facilitating model convergence and improving the representative ability of the encoder. Masked latent alignment predicts the representations of masked patches within the feature space of CLIP latent as standard MIM task does, effectively aligning the representations computed from the encoder and the regressor into the same domain. We pretrain CAE v2 on ImageNet-1K images and evaluate on various downstream vision tasks, including image classification, semantic segmentation, object detection and instance segmentation. Experiments show that our CAE v2 achieves competitive performance and even outperforms the CLIP vision encoder, demonstrating the effectiveness of our method. Code is available at https://github.com/Atten4Vis/CAE.},
  archive      = {J_TMLR},
  author       = {Xinyu Zhang and Jiahui Chen and Junkun Yuan and Qiang Chen and Jian Wang and Xiaodi Wang and Shumin Han and Xiaokang Chen and Jimin Pi and Kun Yao and Junyu Han and Errui Ding and Jingdong Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {CAE v2: Context autoencoder with CLIP latent alignment},
  url          = {https://openreview.net/forum?id=f36LaK7M0F},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Non-stationary contextual pricing with safety constraints.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=fWIQ9Oaao0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a contextual pricing problem, a seller aims at maximizing the revenue over a sequence of sales sessions (described by feature vectors) using binary-censored feedback of &quot;sold&quot; or &quot;not sold&quot;. Existing methods often overlook two practical challenges (1) the best pricing strategy could change over time; (2) the prices and pricing policies must conform to hard constraints due to safety, ethical or legal restrictions. We address both challenges by solving a more general problem of &quot;universal dynamic regret&quot; minimization in proper online learning with exp-concave losses --- an open problem posed by Baby &amp; Wang (2021) that we partially resolve in this paper, with attention restricted to loss functions coming from a generalized linear model. Here &quot;dynamic regret&quot; measures the performance relative to a non-stationary sequence of policies, and &quot;proper&quot; means that the learner must choose feasible strategies within a pre-defined convex set, which we use to model the safety constraints. In this work, we consider a linear noisy valuation model for the customers. In the case of a known strictly log-concave market noise, our algorithm achieves $\tilde{O}(d^3T^{1/3}C_T^{2/3} \vee d^3)$ dynamic regret in comparison with the optimal policy series, where $T$, $d$ and $C_T$ stand for the time horizon, the feature dimension and the total variation (characterizing non-stationarity) respectively. This regret is near-optimal with respect to $T$ (within $O(\log T)$ gaps) and $C_T$, and our algorithm is adaptable to unknown $C_T$ and remains feasible throughout. However, the dependence on $d$ is suboptimal and the minimax rate is still open.},
  archive      = {J_TMLR},
  author       = {Dheeraj Baby and Jianyu Xu and Yu-Xiang Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Non-stationary contextual pricing with safety constraints},
  url          = {https://openreview.net/forum?id=fWIQ9Oaao0},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Population-based evaluation in repeated rock-paper-scissors
as a benchmark for multiagent reinforcement learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=gQnJ7ODIAx">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Progress in fields of machine learning and adversarial planning has benefited significantly from benchmark domains, from checkers and the classic UCI data sets to Go and Diplomacy. In sequential decision-making, agent evaluation has largely been restricted to few interactions against experts, with the aim to reach some desired level of performance (e.g. beating a human professional player). We propose a benchmark for multiagent learning based on repeated play of the simple game Rock, Paper, Scissors along with a population of forty-three tournament entries, some of which are intentionally sub-optimal. We describe metrics to measure the quality of agents based both on average returns and exploitability. We then show that several RL, online learning, and language model approaches can learn good counter-strategies and generalize well, but ultimately lose to the top-performing bots, creating an opportunity for research in multiagent learning.},
  archive      = {J_TMLR},
  author       = {Marc Lanctot and John Schultz and Neil Burch and Max Olan Smith and Daniel Hennes and Thomas Anthony and Julien Perolat},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Population-based evaluation in repeated rock-paper-scissors as a benchmark for multiagent reinforcement learning},
  url          = {https://openreview.net/forum?id=gQnJ7ODIAx},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Straggler-resilient personalized federated learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=gxEpUFxIgz">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning is an emerging learning paradigm that allows training models from samples distributed across a large network of clients while respecting privacy and communication restrictions. Despite its success, federated learning faces several challenges related to its decentralized nature. In this work, we develop a novel algorithmic procedure with theoretical speedup guarantees that simultaneously handles two of these hurdles, namely (i) data heterogeneity, i.e., data distributions can vary substantially across clients, and (ii) system heterogeneity, i.e., the computational power of the clients could differ significantly. By leveraging previous works in the realm of representation learning (Collins et al., 2021; Liang et al., 2020), our method constructs a global common representation utilizing the data from all clients. Additionally, it learns a user-specific set of parameters resulting in a personalized solution for each individual client. Furthermore, it mitigates the effects of stragglers by adaptively selecting clients based on their computational characteristics, thus achieving for the first time near optimal sample complexity and provable logarithmic speedup. Experimental results support our theoretical findings showing the superiority of our method over alternative personalized federated schemes in system and data heterogeneous environments.},
  archive      = {J_TMLR},
  author       = {Isidoros Tziotis and Zebang Shen and Ramtin Pedarsani and Hamed Hassani and Aryan Mokhtari},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Straggler-resilient personalized federated learning},
  url          = {https://openreview.net/forum?id=gxEpUFxIgz},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised learning for segmentation and quantification
of dopamine neurons in parkinson’s disease. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=izFnURFG3f">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s Disease (PD) is the second most common neurodegenerative disease in humans. PD is characterized by the gradual loss of dopaminergic neurons in the Substantia Nigra (SN, a part of the mid-brain). Counting the number of dopaminergic neurons in the SN is one of the most important indexes in evaluating drug efficacy in PD animal models. Currently, analyzing and quantifying dopaminergic neurons is conducted manually by experts through analysis of digital pathology images which is laborious, time-consuming, and highly subjective. As such, a reliable and unbiased automated system is demanded for the quantification of dopaminergic neurons in digital pathology images. Recent years have seen a surge in adopting deep learning solutions in medical image processing. However, developing high-performing deep learning models hinges on the availability of large-scale, high-quality annotated data, which can be expensive to acquire, especially in applications like digital pathology image analysis. To this end, we propose an end-to-end deep learning framework based on self-supervised learning for the segmentation and quantification of dopaminergic neurons in PD animal models. To the best of our knowledge, this is the first deep learning model that detects the cell body of dopaminergic neurons, counts the number of dopaminergic neurons, and provides characteristics of individual dopaminergic neurons as a numerical output. Extensive experiments demonstrate the effectiveness of our model in quantifying neurons with high precision, which can provide a faster turnaround for drug efficacy studies,better understanding of dopaminergic neuronal health status, and unbiased results in PD pre-clinical research. As part of our contributions, we also provide the first publicly available dataset of histology digital images along with expert annotations for the segmentation of TH-positive DA neuronal soma.},
  archive      = {J_TMLR},
  author       = {Fatemeh Haghighi and soumitra ghosh and Sarah Chu and Hai Ngu and Mohsen Hejrati and Han Hui Lin and Baris Bingol and Somaye Hashemifar},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Self-supervised learning for segmentation and quantification of dopamine neurons in parkinson’s disease},
  url          = {https://openreview.net/forum?id=izFnURFG3f},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bridging imitation and online reinforcement learning: An
optimistic tale. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=lanGfX0M6C">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the following problem: Given an offline demonstration dataset from an imperfect expert, what is the best way to leverage it to bootstrap online learning performance in MDPs. We first propose an Informed Posterior Sampling-based RL (iPSRL) algorithm that uses the offline dataset, and information about the expert&#39;s behavioral policy used to generate the offline dataset. Its cumulative Bayesian regret goes down to zero exponentially fast in $N$, the offline dataset size if the expert is competent enough. Since this algorithm is computationally impractical, we then propose the iRLSVI algorithm that can be seen as a combination of the RLSVI algorithm for online RL, and imitation learning. Our empirical results show that the proposed iRLSVI algorithm is able to achieve significant reduction in regret as compared to two baselines: no offline data, and offline dataset but used without suitably modeling the generative policy. Our algorithm can be seen as bridging online RL and imitation learning.},
  archive      = {J_TMLR},
  author       = {Botao Hao and Rahul Jain and Dengwang Tang and Zheng Wen},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bridging imitation and online reinforcement learning: An optimistic tale},
  url          = {https://openreview.net/forum?id=lanGfX0M6C},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Overcoming resource constraints in federated learning: Large
models can be trained with only weak clients. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=lx1WnkL9fk">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is emerging as a popular, promising decentralized learning framework that enables collaborative training among clients, with no need to share private data between them or to a centralized server. However, considering many edge clients do not have sufficient computing, memory, or communication capabilities, federated learning of large models still faces significant bottlenecks. To keep such weak but crucial clients in the loop, prior works either consider a heterogeneous-client setting where clients train models with different sizes; or offload training to the server. However, the heterogeneous-client setting requires some clients to train full model, which is not aligned with the resource-constrained setting; while the latter ones break privacy promises in FL when sharing intermediate representations or labels with the server. To overcome these limitations, in this work, we formulate a realistic, but much less explored, cross-device FL setting in which no client can train a full large model nor is willing to share any intermediate information with the remote server. Under such a formulation, we develop a principal sub-model (PriSM) training methodology to collaboratively train a full large model, while assigning each client a small sub-model that is a probabilistic low-rank approximation to the full server model. When creating sub-models, PriSM first performs a principal kernel analysis in the orthogonal kernel space to obtain importance of each kernel. Then, PriSM adopts a novel importance-aware sampling process to select a subset of kernels (i.e., a kernel with high importance is assigned with a higher sampling probability). This sampling process ensures each sub-model is still a low-rank approximation to the full model, while all sub-models together achieve nearly full coverage on the principal kernels. To further improve memory efficiency while still preserving accuracy, PriSM also exploits low-rank structure in intermediate representations and allows each sub-model to learn only a subset of them. Our evaluations on various datasets and models (CNNs, LSTMs, Transformers) under different resource-constrained settings demonstrate that PriSM yields an accuracy improvement of up to $10\%$ compared to existing works. More importantly, PriSM does not incur significant accuracy degradation compared to full-model training (e.g., only $\sim 2\%$ accuracy drops for ResNet-18/CIFAR-10 when clients train only $0.2\times$ sub-models).},
  archive      = {J_TMLR},
  author       = {Yue Niu and Saurav Prakash and Souvik Kundu and Sunwoo Lee and Salman Avestimehr},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Overcoming resource constraints in federated learning: Large models can be trained with only weak clients},
  url          = {https://openreview.net/forum?id=lx1WnkL9fk},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Homomorphic self-supervised learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=tEKqQgbwbf">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many state of the art self-supervised learning approaches fundamentally rely on transformations applied to the input in order to selectively extract task-relevant information. Recently, the field of equivariant deep learning has developed to introduce structure into the feature space of deep neural networks by designing them as homomorphisms with respect to input transformations. In this work, we observe that many existing self-supervised learning algorithms can be both unified and generalized when seen through the lens of equivariant representations. Specifically, we introduce a general framework we call Homomorphic Self-Supervised Learning, and theoretically show how it may subsume the use of input-augmentations provided an augmentation-homomorphic feature extractor. We validate this theory experimentally for simple augmentations, demonstrate the necessity of representational structure for feature-space SSL, and further empirically explore how the parameters of this framework relate to those of traditional augmentation-based self-supervised learning. We conclude with a discussion of the potential benefits afforded by this new perspective on self-supervised learning.},
  archive      = {J_TMLR},
  author       = {T. Anderson Keller and Xavier Suau and Luca Zappella},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Homomorphic self-supervised learning},
  url          = {https://openreview.net/forum?id=tEKqQgbwbf},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neighborhood gradient mean: An efficient decentralized
learning method for non-IID data. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=vkiKzK5G3e">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized learning algorithms enable the training of deep learning models over large distributed datasets, without the need for a central server. The current state-of-the-art decentralized algorithms mostly assume the data distributions to be Independent and Identically Distributed (IID). In practical scenarios, the distributed datasets can have significantly different data distributions across the agents. This paper focuses on improving decentralized learning on non-IID data with minimal compute and memory overheads. We propose Neighborhood Gradient Mean (NGM), a novel decentralized learning algorithm that modifies the local gradients of each agent using self- and cross-gradient information. In particular, the proposed method averages the local gradients with model-variant or data-variant cross-gradients based on the communication budget. Model-variant cross-gradients are derivatives of the received neighbors’ model parameters with respect to the local dataset. Data-variant cross-gradient derivatives of the local model with respect to its neighbors’ datasets. The data-variant cross-gradients are aggregated through an additional communication round. We theoretically analyze the convergence characteristics of NGM and demonstrate its efficiency on non-IID data sampled from various vision and language datasets. Our experiments demonstrate that the proposed method either remains competitive or outperforms (by 0-6%) the existing state-of-the-art (SoTA) decentralized learning algorithm on non-IID data with significantly less compute and memory requirements. Further, we show that the model-variant cross-gradient information available locally at each agent can improve the performance on non-IID data by 3-20% without additional communication costs.},
  archive      = {J_TMLR},
  author       = {Sai Aparna Aketi and Sangamesh Kodge and Kaushik Roy},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Neighborhood gradient mean: An efficient decentralized learning method for non-IID data},
  url          = {https://openreview.net/forum?id=vkiKzK5G3e},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Training vision-language transformers from captions.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=xLnbSpozWS">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-Language Transformers can be learned without low-level human labels (e.g. class labels, bounding boxes, etc). Existing work, whether explicitly utilizing bounding boxes (Chen et al., 2020b; Tan &amp; Bansal, 2019; Lu et al., 2019) or patches (Kim et al., 2021), assumes that the visual backbone must first be trained on ImageNet (Russakovsky et al., 2015) class prediction before being integrated into a multimodal linguistic pipeline. We show that this is not necessary and introduce a new model Vision-Language from Captions (VLC) built on top of Masked Auto-Encoders (He et al., 2022) that does not require this supervision. We seek to provide general advice on multimodal pretraining by examining the roles of (a) unimodal initialization, (b) unimodal architectural components and (c) data annotation in the pretraining corpus. Our extensive and carefully controlled studies suggest that none of the above factors is absolutely important in achieving versatile vision-language representations. We conclude our analysis with suggestions on the choices of initialization, architectural components, and annotation formats targeting a better balance between data efficiency and representation quality.},
  archive      = {J_TMLR},
  author       = {Liangke Gui and Yingshan Chang and Qiuyuan Huang and Subhojit Som and Alexander G Hauptmann and Jianfeng Gao and Yonatan Bisk},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Training vision-language transformers from captions},
  url          = {https://openreview.net/forum?id=xLnbSpozWS},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analysis of convolutions, non-linearity and depth in graph
neural networks using neural tangent kernel. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=xgYgDEof29">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fundamental principle of Graph Neural Networks (GNNs) is to exploit the structural information of the data by aggregating the neighboring nodes using a `graph convolution&#39; in conjunction with a suitable choice for the network architecture, such as depth and activation functions. Therefore, understanding the influence of each of the design choice on the network performance is crucial. Convolutions based on graph Laplacian have emerged as the dominant choice with the symmetric normalization of the adjacency matrix as the most widely adopted one. However, some empirical studies show that row normalization of the adjacency matrix outperforms it in node classification. Despite the widespread use of GNNs, there is no rigorous theoretical study on the representation power of these convolutions, that could explain this behavior. Similarly, the empirical observation of the linear GNNs performance being on par with non-linear ReLU GNNs lacks rigorous theory. In this work, we theoretically analyze the influence of different aspects of the GNN architecture using the Graph Neural Tangent Kernel in a semi-supervised node classification setting. Under the population Degree Corrected Stochastic Block Model, we prove that: (i) linear networks capture the class information as good as ReLU networks; (ii) row normalization preserves the underlying class structure better than other convolutions; (iii) performance degrades with network depth due to over-smoothing, but the loss in class information is the slowest in row normalization; (iv) skip connections retain the class information even at infinite depth, thereby eliminating over-smoothing. We finally validate our theoretical findings numerically and on real datasets such as Cora and Citeseer.},
  archive      = {J_TMLR},
  author       = {Mahalakshmi Sabanayagam and Pascal Esser and Debarghya Ghoshdastidar},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Analysis of convolutions, non-linearity and depth in graph neural networks using neural tangent kernel},
  url          = {https://openreview.net/forum?id=xgYgDEof29},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic regret analysis of safe distributed online
optimization for convex and non-convex problems. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=xiQXHvL1eN">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses safe distributed online optimization over an unknown set of linear safety constraints. A network of agents aims at jointly minimizing a global, time-varying function, which is only partially observable to each individual agent. Therefore, agents must engage in local communications to generate a safe sequence of actions competitive with the best minimizer sequence in hindsight, and the gap between the two sequences is quantified via dynamic regret. We propose distributed safe online gradient descent (D-Safe-OGD) with an exploration phase, where all agents estimate the constraint parameters collaboratively to build estimated feasible sets, ensuring the action selection safety during the optimization phase. We prove that for convex functions, D-Safe-OGD achieves a dynamic regret bound of $O(T^{2/3} \sqrt{\log T} + T^{1/3}C_T^*)$, where $C_T^*$ denotes the path-length of the best minimizer sequence. We further prove a dynamic regret bound of $O(T^{2/3}{\color{black} \sqrt{\log T}} + T^{2/3}C_T^*)$ for certain non-convex problems, which establishes the first dynamic regret bound for a safe distributed algorithm in the non-convex setting.},
  archive      = {J_TMLR},
  author       = {Ting-Jui Chang and Sapana Chaudhary and Dileep Kalathil and Shahin Shahrampour},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Dynamic regret analysis of safe distributed online optimization for convex and non-convex problems},
  url          = {https://openreview.net/forum?id=xiQXHvL1eN},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Not all causal inference is the same. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ySWQ6eXAKp">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurally-parameterized Structural Causal Models in the Pearlian notion to causality, referred to as NCM, were recently introduced as a step towards next-generation learning systems. However, said NCM are only concerned with the learning aspect of causal inference and totally miss out on the architecture aspect. That is, actual causal inference within NCM is intractable in that the NCM won’t return an answer to a query in polynomial time. This insight follows as corollary to the more general statement on the intractability of arbitrary structural causal model (SCM) parameterizations, which we prove in this work through classical 3-SAT reduction. Since future learning algorithms will be required to deal with both high dimensional data and highly complex mechanisms governing the data, we ultimately believe work on tractable inference for causality to be decisive. We also show that not all “causal” models are created equal. More specifically, there are models capable of answering causal queries that are not SCM, which we refer to as partially causal models (PCM). We provide a tabular taxonomy in terms of tractability properties for all of the different model families, namely correlation-based, PCM and SCM. To conclude our work, we also provide some initial ideas on how to overcome parts of the intractability of causal inference with SCM by showing an example of how parameterizing an SCM with SPN modules can at least allow for tractable mechanisms. With this work we hope that our insights can raise awareness for this novel research direction since achieving success with causality in real world downstream tasks will not only depend on learning correct models but also require having the practical ability to gain access to model inferences.},
  archive      = {J_TMLR},
  author       = {Matej Zečević and Devendra Singh Dhami and Kristian Kersting},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Not all causal inference is the same},
  url          = {https://openreview.net/forum?id=ySWQ6eXAKp},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sharper rates and flexible framework for nonconvex SGD with
client and data sampling. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=zKgJ6TWAFE">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We revisit the classical problem of finding an approximately stationary point of the average of $n$ smooth and possibly nonconvex functions. The optimal complexity of stochastic first-order methods in terms of the number of gradient evaluations of individual functions is $\mathcal{O}\left(n + n^{1/2}\varepsilon^{-1}\right)$, attained by the optimal SGD methods SPIDER (Fang et al., 2018) and PAGE (Li et al., 2021), for example, where $\varepsilon$ is the error tolerance. However, i) the big-$\mathcal{O}$ notation hides crucial dependencies on the smoothness constants associated with the functions, and ii) the rates and theory in these methods assume simplistic sampling mechanisms that do not offer any flexibility. In this work we remedy the situation. First, we generalize the PAGE (Li et al., 2021) algorithm so that it can provably work with virtually any (unbiased) sampling mechanism. This is particularly useful in federated learning, as it allows us to construct and better understand the impact of various combinations of client and data sampling strategies. Second, our analysis is sharper as we make explicit use of certain novel inequalities that capture the intricate interplay between the smoothness constants and the sampling procedure. Indeed, our analysis is better even for the simple sampling procedure analyzed in the PAGE (Li et al., 2021) paper. However, this already improved bound can be further sharpened by a different sampling scheme which we propose. In summary, we provide the most general and most accurate analysis of optimal SGD in the smooth nonconvex regime. Finally, our theoretical findings are supposed with carefully designed experiments.},
  archive      = {J_TMLR},
  author       = {Alexander Tyurin and Lukang Sun and Konstantin Pavlovich Burlachenko and Peter Richtárik},
  journal      = {Transactions on Machine Learning Research},
  month        = {10},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Sharper rates and flexible framework for nonconvex SGD with client and data sampling},
  url          = {https://openreview.net/forum?id=zKgJ6TWAFE},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HypUC: Hyperfine uncertainty calibration with gradient-
boosted corrections for reliable regression on imbalanced
electrocardiograms. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=0Xo9giEZWf">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automated analysis of medical time series, such as the electrocardiogram (ECG), electroencephalogram (EEG), pulse oximetry, etc, has the potential to serve as a valuable tool for diagnostic decisions, allowing for remote monitoring of patients and more efficient use of expensive and time-consuming medical procedures. Deep neural networks (DNNs) have been demonstrated to process such signals effectively. However, previous research has primarily focused on classifying medical time series rather than attempting to regress the continuous-valued physiological parameters central to diagnosis. One significant challenge in this regard is the imbalanced nature of the dataset, as a low prevalence of abnormal conditions can lead to heavily skewed data that results in inaccurate predictions and a lack of certainty in such predictions when deployed. To address these challenges, we propose HypUC, a framework for imbalanced probabilistic regression in medical time series, making several contributions. (i) We introduce a simple kernel density-based technique to tackle the imbalanced regression problem with medical time series. (ii) Moreover, we employ a probabilistic regression framework that allows uncertainty estimation for the predicted continuous values. (iii) We also present a new approach to calibrate the predicted uncertainty further. (iv) Finally, we demonstrate a technique to use calibrated uncertainty estimates to improve the predicted continuous value and show the efficacy of the calibrated uncertainty estimates to flag unreliable predictions. HypUC is evaluated on a large, diverse, real-world dataset of ECGs collected from millions of patients, outperforming several conventional baselines on various diagnostic tasks, suggesting potential use-case for the reliable clinical deployment of deep learning models and a prospective clinical trial. Consequently, a hyperkalemia diagnosis algorithm based on HypUC is going to be the subject of a real-world clinical prospective study.},
  archive      = {J_TMLR},
  author       = {Uddeshya Upadhyay and Sairam Bade and Arjun Puranik and Shahir Asfahan and Melwin Babu and Francisco Lopez-Jimenez and Samuel Asirvatham and Ashim Prasad and Ajit Rajasekharan and Samir Awasthi and Rakesh Barve},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {HypUC: Hyperfine uncertainty calibration with gradient- boosted corrections for reliable regression on imbalanced electrocardiograms},
  url          = {https://openreview.net/forum?id=0Xo9giEZWf},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning-to-defer for sequential medical decision-making
under uncertainty. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=0pn3KnbH5F">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning-to-defer is a framework to automatically defer decision-making to a human expert when ML-based decisions are deemed unreliable. Existing learning-to-defer frameworks are not designed for sequential settings. That is, they defer at every instance independently, based on immediate predictions, while ignoring the potential long-term impact of these interventions. As a result, existing frameworks are myopic. Further, they do not defer adaptively, which is crucial when human interventions are costly. In this work, we propose Sequential Learning-to-Defer (SLTD), a framework for learning-to-defer to a domain expert in sequential decision-making settings. Contrary to existing literature, we pose the problem of learning-to-defer as model-based reinforcement learning (RL) to i) account for long-term consequences of ML-based actions using RL and ii) adaptively defer based on the dynamics (model-based). Our proposed framework determines whether to defer (at each time step) by quantifying whether a deferral now will improve the value compared to delaying deferral to the next time step. To quantify the improvement, we account for potential future deferrals. As a result, we learn a pre-emptive deferral policy (i.e. a policy that defers early if using the ML-based policy could worsen long-term outcomes). Our deferral policy is adaptive to the non-stationarity in the dynamics. We demonstrate that adaptive deferral via SLTD provides an improved trade-off between long-term outcomes and deferral frequency on synthetic, semi-synthetic, and real-world data with non-stationary dynamics. Finally, we interpret the deferral decision by decomposing the propagated (long-term) uncertainty around the outcome, to justify the deferral decision.},
  archive      = {J_TMLR},
  author       = {Shalmali Joshi and Sonali Parbhoo and Finale Doshi-Velez},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning-to-defer for sequential medical decision-making under uncertainty},
  url          = {https://openreview.net/forum?id=0pn3KnbH5F},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Does “deep learning on a data diet” reproduce? Overall yes,
but GraNd at initialization does not. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=1dwXa9vmOI">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training deep neural networks on vast datasets often results in substantial computational demands, underscoring the need for efficient data pruning. In this context, we critically re-evaluate the data pruning metrics introduced in `Deep Learning on a Data Diet&#39; by Paul et al. (2021): the Gradient Norm (GraNd) (at initialization) and the Error L2 Norm (EL2N). Our analysis uncovers a strong correlation between the GraNd scores at initialization and a sample&#39;s input norm, suggesting the latter as a potential baseline for data pruning. However, comprehensive tests on CIFAR-10 show neither metric outperforming random pruning, contradicting one of the findings in Paul et al. (2021). We pinpoint the inconsistency in the GraNd at initialization results to a later-fixed bug in FLAX&#39;s checkpoint restoring mechanism (https://github.com/google/flax/commit/28fbd95500f4bf2f9924d2560062fa50e919b1a5). Altogether, our findings do not support using the input norm or GraNd scores at initialization for effective data pruning. Nevertheless, EL2N and GraNd scores at later training epochs do provide useful pruning signals, aligning with the expected performance.},
  archive      = {J_TMLR},
  author       = {Andreas Kirsch},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Does ‘Deep learning on a data diet’ reproduce? overall yes, but GraNd at initialization does not},
  url          = {https://openreview.net/forum?id=1dwXa9vmOI},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A probabilistic taylor expansion with gaussian processes.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=2TneniEIDB">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a class of Gaussian processes for which the posterior mean, for a particular choice of data, replicates a truncated Taylor expansion of any order. The data consist of derivative evaluations at the expansion point and the prior covariance kernel belongs to the class of Taylor kernels, which can be written in a certain power series form. We discuss and prove some results on maximum likelihood estimation of parameters of Taylor kernels. The proposed framework is a special case of Gaussian process regression based on data that is orthogonal in the reproducing kernel Hilbert space of the covariance kernel.},
  archive      = {J_TMLR},
  author       = {Toni Karvonen and Jon Cockayne and Filip Tronarp and Simo Särkkä},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A probabilistic taylor expansion with gaussian processes},
  url          = {https://openreview.net/forum?id=2TneniEIDB},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Benchmarking continuous time models for predicting multiple
sclerosis progression. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=2uMnAwWnRy">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple sclerosis is a disease that affects the brain and spinal cord, it can lead to severe disability and has no known cure. The majority of prior work in machine learning for multiple sclerosis has been centered around using Magnetic Resonance Imaging scans or laboratory tests; these modalities are both expensive to acquire and can be unreliable. In a recent paper it was shown that disease progression can be predicted effectively using performance outcome measures and demographic data. In our work we build on this to investigate the modeling side, using continuous time models to predict progression. We benchmark four continuous time models using a publicly available multiple sclerosis dataset. We find that the best continuous model is often able to outperform the best benchmarked discrete time model. We also carry out an extensive ablation to discover the sources of performance gains, we find that standardizing existing features leads to a larger performance increase than interpolating missing features.},
  archive      = {J_TMLR},
  author       = {Alexander Luke Ian Norcliffe and Lev Proleev and Diana Mincu and F Lee Hartsell and Katherine A Heller and Subhrajit Roy},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Benchmarking continuous time models for predicting multiple sclerosis progression},
  url          = {https://openreview.net/forum?id=2uMnAwWnRy},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Subgraph permutation equivariant networks. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=3agxS3aDUs">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we develop a new method, named Sub-graph Permutation Equivariant Networks (SPEN), which provides a framework for building graph neural networks that operate on sub-graphs, while using a base update function that is permutation equivariant, that are equivariant to a novel choice of automorphism group. Message passing neural networks have been shown to be limited in their expressive power and recent approaches to over come this either lack scalability or require structural information to be encoded into the feature space. The general framework presented here overcomes the scalability issues associated with global permutation equivariance by operating more locally on sub-graphs. In addition, through operating on sub-graphs the expressive power of higher-dimensional global permutation equivariant networks is improved; this is due to fact that two non-distinguishable graphs often contain distinguishable sub-graphs. Furthermore, the proposed framework only requires a choice of $k$-hops for creating ego-network sub-graphs and a choice of representation space to be used for each layer, which makes the method easily applicable across a range of graph based domains. We experimentally validate the method on a range of graph benchmark classification tasks, demonstrating statistically indistinguishable results from the state-of-the-art on six out of seven benchmarks. Further, we demonstrate that the use of local update functions offers a significant improvement in GPU memory over global methods.},
  archive      = {J_TMLR},
  author       = {Joshua Mitton and Roderick Murray-Smith},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Subgraph permutation equivariant networks},
  url          = {https://openreview.net/forum?id=3agxS3aDUs},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Label noise-robust learning using a confidence-based sieving
strategy. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=3taIQG4C7H">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In learning tasks with label noise, improving model robustness against overfitting is a pivotal challenge because the model eventually memorizes labels, including the noisy ones. Identifying the samples with noisy labels and preventing the model from learning them is a promising approach to address this challenge. When training with noisy labels, the per-class confidence scores of the model, represented by the class probabilities, can be reliable criteria for assessing whether the input label is the true label or the corrupted one. In this work, we exploit this observation and propose a novel discriminator metric called confidence error and a sieving strategy called CONFES to differentiate between the clean and noisy samples effectively. We provide theoretical guarantees on the probability of error for our proposed metric. Then, we experimentally illustrate the superior performance of our proposed approach compared to recent studies on various settings, such as synthetic and real-world label noise. Moreover, we show CONFES can be combined with other state-of-the-art approaches, such as Co-teaching and DivideMix to further improve model performance.},
  archive      = {J_TMLR},
  author       = {Reihaneh Torkzadehmahani and Reza Nasirigerdeh and Daniel Rueckert and Georgios Kaissis},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Label noise-robust learning using a confidence-based sieving strategy},
  url          = {https://openreview.net/forum?id=3taIQG4C7H},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HERMES: Hybrid error-corrector model with inclusion of
external signals for nonstationary fashion time series. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=4ofFo7D5GL">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing models and algorithms to predict nonstationary time series is a long standing statistical problem. It is crucial for many applications, in particular for fashion or retail industries, to make optimal inventory decisions and avoid massive wastes. By tracking thousands of fashion trends on social media with state-of-the-art computer vision approaches, we propose a new model for fashion time series forecasting. Our contribution is twofold. We first provide publicly a dataset gathering 10000 weekly fashion time series. As influence dynamics are the key of emerging trend detection, we associate with each time series an external weak signal representing behaviours of influencers. Secondly, to leverage such a dataset, we propose a new hybrid forecasting mode. Our approach combines per-time-series parametric models with seasonal components and a global recurrent neural network to include sporadic external signals. This hybrid model provides state-of-the-art results on the proposed fashion dataset, on the weekly time series of the M4 competition, and illustrates the benefit of the contribution of external weak signals.},
  archive      = {J_TMLR},
  author       = {Etienne David and Jean Bellot and Sylvain Le Corff},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {HERMES: Hybrid error-corrector model with inclusion of external signals for nonstationary fashion time series},
  url          = {https://openreview.net/forum?id=4ofFo7D5GL},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IBIA: An incremental build-infer-approximate framework for
approximate inference of partition function. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=8L7Rh6FIXt">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exact computation of the partition function is known to be intractable, necessitating approximate inference techniques. Existing methods for approximate inference are slow to converge for many benchmarks. The control of accuracy-complexity trade-off is also non-trivial in many of these methods. We propose a novel incremental build-infer-approximate (IBIA) framework for approximate inference that addresses these issues. In this framework, the probabilistic graphical model is converted into a sequence of clique tree forests (SCTF) with bounded clique sizes. We show that the SCTF can be used to efficiently compute the partition function. We propose two new algorithms which are used to construct the SCTF and prove the correctness of both. The first is an algorithm for incremental construction of CTFs that is guaranteed to give a valid CTF with bounded clique sizes and the second is an approximation algorithm that takes a calibrated CTF as input and yields a valid and calibrated CTF with reduced clique sizes as the output. We have evaluated our method using several benchmark sets from recent UAI competitions and our results show good accuracies with competitive runtimes.},
  archive      = {J_TMLR},
  author       = {Shivani Bathla and Vinita Vasudevan},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {IBIA: An incremental build-infer-approximate framework for approximate inference of partition function},
  url          = {https://openreview.net/forum?id=8L7Rh6FIXt},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Momentum tracking: Momentum acceleration for decentralized
deep learning on heterogeneous data. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=8koy8QuTZD">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {SGD with momentum is one of the key components for improving the performance of neural networks. For decentralized learning, a straightforward approach using momentum is Distributed SGD (DSGD) with momentum (DSGDm). However, DSGDm performs worse than DSGD when the data distributions are statistically heterogeneous. Recently, several studies have addressed this issue and proposed methods with momentum that are more robust to data heterogeneity than DSGDm, although their convergence rates remain dependent on data heterogeneity and deteriorate when the data distributions are heterogeneous. In this study, we propose Momentum Tracking, which is a method with momentum whose convergence rate is proven to be independent of data heterogeneity. More specifically, we analyze the convergence rate of Momentum Tracking in the setting where the objective function is non-convex and the stochastic gradient is used. Then, we identify that it is independent of data heterogeneity for any momentum coefficient $\beta \in [0, 1)$. Through experiments, we demonstrate that Momentum Tracking is more robust to data heterogeneity than the existing decentralized learning methods with momentum and can consistently outperform these existing methods when the data distributions are heterogeneous.},
  archive      = {J_TMLR},
  author       = {Yuki Takezawa and Han Bao and Kenta Niwa and Ryoma Sato and Makoto Yamada},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Momentum tracking: Momentum acceleration for decentralized deep learning on heterogeneous data},
  url          = {https://openreview.net/forum?id=8koy8QuTZD},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Single-pass contrastive learning can work for both
homophilic and heterophilic graph. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=244KePn09i">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing graph contrastive learning (GCL) techniques typically require two forward passes for a single instance to construct the contrastive loss, which is effective for capturing the low-frequency signals of node features. Such a dual-pass design has shown empirical success on homophilic graphs, but its effectiveness on heterophilic graphs, where directly connected nodes typically have different labels, is unknown. In addition, existing GCL approaches fail to provide strong performance guarantees. Coupled with the unpredictability of GCL approaches on heterophilic graphs, their applicability in real-world contexts is limited. Then, a natural question arises: Can we design a GCL method that works for both homophilic and heterophilic graphs with a performance guarantee? To answer this question, we theoretically study the concentration property of features obtained by neighborhood aggregation on homophilic and heterophilic graphs, introduce the single-pass graph contrastive learning loss based on the property, and provide performance guarantees for the minimizer of the loss on downstream tasks. As a direct consequence of our analysis, we implement the Single-Pass Graph Contrastive Learning method (SP-GCL). Empirically, on 14 benchmark datasets with varying degrees of homophily, the features learned by the SP-GCL can match or outperform existing strong baselines with significantly less computational overhead, which demonstrates the usefulness of our findings in real-world cases.},
  archive      = {J_TMLR},
  author       = {Haonan Wang and Jieyu Zhang and Qi Zhu and Wei Huang and Kenji Kawaguchi and Xiaokui Xiao},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Single-pass contrastive learning can work for both homophilic and heterophilic graph},
  url          = {https://openreview.net/forum?id=244KePn09i},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bridging the gap between target networks and functional
regularization. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=BFvoemrmqX">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bootstrapping is behind much of the successes of deep Reinforcement Learning. However, learning the value function via bootstrapping often leads to unstable training due to fast-changing target values. Target Networks are employed to stabilize training by using an additional set of lagging parameters to estimate the target values. Despite the popularity of Target Networks, their effect on the optimization is still misunderstood. In this work, we show that they act as an implicit regularizer which can be beneficial in some cases, but also have disadvantages such as being inflexible and can result in instabilities, even when vanilla TD(0) converges. To overcome these issues, we propose an explicit Functional Regularization alternative that is flexible and a convex regularizer in function space and we theoretically study its convergence. We conducted an experimental study across a range of environments, discount factors, and off-policiness data collections to investigate the effectiveness of the regularization induced by Target Networks and Functional Regularization in terms of performance, accuracy, and stability. Our findings emphasize that Functional Regularization can be used as a drop-in replacement for Target Networks and result in performance improvement. Furthermore, adjusting both the regularization weight and the network update period in Functional Regularization can result in further performance improvements compared to solely adjusting the network update period as typically done with Target Networks. Our approach also enhances the ability to networks to recover accurate $Q$-values.},
  archive      = {J_TMLR},
  author       = {Alexandre Piché and Valentin Thomas and Joseph Marino and Rafael Pardinas and Gian Maria Marconi and Christopher Pal and Mohammad Emtiyaz Khan},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bridging the gap between target networks and functional regularization},
  url          = {https://openreview.net/forum?id=BFvoemrmqX},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AP: Selective activation for de-sparsifying pruned networks.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=EGQSpkUDdD">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rectified linear unit (ReLU) is a highly successful activation function in neural networks as it allows networks to easily obtain sparse representations, which reduces overfitting in overparameterized networks. However, in the context of network pruning, we find that the sparsity introduced by ReLU, which we quantify by a term called dynamic dead neuron rate (DNR), is not beneficial for the pruned network. Interestingly, the more the network is pruned, the smaller the dynamic DNR becomes during and after optimization. This motivates us to propose a method to explicitly reduce the dynamic DNR for the pruned network, i.e., de-sparsify the network. We refer to our method as Activate-while-Pruning (AP). We note that AP does not function as a stand-alone method, as it does not evaluate the importance of weights. Instead, it works in tandem with existing pruning methods and aims to improve their performance by selective activation of nodes to reduce the dynamic DNR. We conduct extensive experiments using various popular networks (e.g., ResNet, VGG, DenseNet, MobileNet) via two classical and three state-of-the-art pruning methods. The experimental results on public datasets (e.g., CIFAR-10, CIFAR-100) suggest that AP works well with existing pruning methods and improves the performance by 3% - 4%. For larger scale datasets (e.g., ImageNet) and state-of-the-art networks (e.g., vision transformer), we observe an improvement of 2% - 3% with AP as opposed to without. Lastly, we conduct an ablation study to examine the effectiveness of the components comprising AP.},
  archive      = {J_TMLR},
  author       = {Shiyu Liu and Rohan Ghosh and Mehul Motani},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {AP: Selective activation for de-sparsifying pruned networks},
  url          = {https://openreview.net/forum?id=EGQSpkUDdD},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semantic representations of mathematical expressions in a
continuous vector space. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=EWPA9TZcUy">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mathematical notation makes up a large portion of STEM literature, yet finding semantic representations for formulae remains a challenging problem. Because mathematical notation is precise, and its meaning changes significantly with small character shifts, the methods that work for natural text do not necessarily work well for mathematical expressions. This work describes an approach for representing mathematical expressions in a continuous vector space. We use the encoder of a sequence-to-sequence architecture, trained on visually different but mathematically equivalent expressions, to generate vector representations (or embeddings). We compare this approach with a structural approach that considers visual layout to embed an expression and show that our proposed approach is better at capturing mathematical semantics. Finally, to expedite future research, we publish a corpus of equivalent transcendental and algebraic expression pairs.},
  archive      = {J_TMLR},
  author       = {Neeraj Gangwar and Nickvash Kani},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Semantic representations of mathematical expressions in a continuous vector space},
  url          = {https://openreview.net/forum?id=EWPA9TZcUy},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DPVIm: Differentially private variational inference
improved. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=GlhM6XX1wv">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differentially private (DP) release of multidimensional statistics typically considers an aggregate sensitivity, e.g. the vector norm of a high-dimensional vector. However, different dimensions of that vector might have widely different magnitudes and therefore DP perturbation disproportionately affects the signal across dimensions. We observe this problem in the gradient release of the DP-SGD algorithm when using it for variational inference (VI), where it manifests in poor convergence as well as high variance in outputs for certain variational parameters, and make the following contributions: (i) We mathematically isolate the cause for the difference in magnitudes between gradient parts corresponding to different variational parameters. Using this as prior knowledge we establish a link between the gradients of the variational parameters, and propose an efficient while simple fix for the problem to obtain a less noisy gradient estimator, which we call \emph{aligned} gradients. This approach allows us to obtain the updates for the covariance parameter of a Gaussian posterior approximation without a privacy cost. We compare this to alternative approaches for scaling the gradients using analytically derived preconditioning, e.g. natural gradients. (ii) We suggest using iterate averaging over the DP parameter traces recovered during the training, to reduce the DP-induced noise in parameter estimates at no additional cost in privacy. Finally, (iii) to accurately capture the additional uncertainty DP introduces to the model parameters, we infer the DP-induced noise from the parameter traces and include that in the learned posteriors to make them \emph{noise aware}. We demonstrate the efficacy of our proposed improvements through various experiments on real data.},
  archive      = {J_TMLR},
  author       = {Joonas Jälkö and Lukas Prediger and Antti Honkela and Samuel Kaski},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DPVIm: Differentially private variational inference improved},
  url          = {https://openreview.net/forum?id=GlhM6XX1wv},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On adaptivity in quantum testing. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Hf95zFnQ7H">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Can adaptive strategies outperform non-adaptive ones for quantum hypothesis selection? We exhibit problems where adaptive strategies provably reduce the number of required samples by a factor four in the worst case, and possibly more when the actual difficulty of the problem makes it possible. In addition, we exhibit specific hypotheses classes for which there is a provable polynomial separation between adaptive and non-adaptive strategies -- a specificity of the quantum framework that does not appear in classical testing.},
  archive      = {J_TMLR},
  author       = {Omar Fawzi and Nicolas Flammarion and Aurélien Garivier and Aadil Oufkir},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On adaptivity in quantum testing},
  url          = {https://openreview.net/forum?id=Hf95zFnQ7H},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning domain-specific causal discovery from time series.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=JFaZ94tT8M">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal discovery (CD) from time-varying data is important in neuroscience, medicine, and machine learning. Techniques for CD encompass randomized experiments, which are generally unbiased but expensive, and algorithms such as Granger causality, conditional-independence-based, structural-equation-based, and score-based methods that are only accurate under strong assumptions made by human designers. However, as demonstrated in other areas of machine learning, human expertise is often not entirely accurate and tends to be outperformed in domains with abundant data. In this study, we examine whether we can enhance domain-specific causal discovery for time series using a data-driven approach. Our findings indicate that this procedure significantly outperforms human-designed, domain-agnostic causal discovery methods, such as Mutual Information, VAR-LiNGAM, and Granger Causality on the MOS 6502 microprocessor, the NetSim fMRI dataset, and the Dream3 gene dataset. We argue that, when feasible, the causality field should consider a supervised approach in which domain-specific CD procedures are learned from extensive datasets with known causal relationships, rather than being designed by human specialists. Our findings promise a new approach toward improving CD in neural and medical data and for the broader machine learning community.},
  archive      = {J_TMLR},
  author       = {Xinyue Wang and Konrad Kording},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning domain-specific causal discovery from time series},
  url          = {https://openreview.net/forum?id=JFaZ94tT8M},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the special role of class-selective neurons in early
training. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=JaNlH6dZYk">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is commonly observed that deep networks trained for classification exhibit class-selective neurons in their early and intermediate layers. Intriguingly, recent studies have shown that these class-selective neurons can be ablated without deteriorating network function. But if class-selective neurons are not necessary, why do they exist? We attempt to answer this question in a series of experiments on ResNet-50s trained on ImageNet. We first show that class-selective neurons emerge during the first few epochs of training, before receding rapidly but not completely; this suggests that class-selective neurons found in trained networks are in fact vestigial remains of early training. With single-neuron ablation experiments, we then show that class-selective neurons are important for network function in this early phase of training. We also observe that the network is close to a linear regime in this early phase; we thus speculate that class-selective neurons appear early in training as quasi-linear shortcut solutions to the classification task. Finally, in causal experiments where we regularize against class selectivity at different points in training, we show that the presence of class-selective neurons early in training is critical to the successful training of the network; in contrast, class-selective neurons can be suppressed later in training with little effect on final accuracy. It remains to be understood by which mechanism the presence of class-selective neurons in the early phase of training contributes to the successful training of networks.},
  archive      = {J_TMLR},
  author       = {Omkar Ranadive and Nikhil Thakurdesai and Ari S. Morcos and Matthew L Leavitt and Stephane Deny},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the special role of class-selective neurons in early training},
  url          = {https://openreview.net/forum?id=JaNlH6dZYk},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SkillS: Adaptive skill sequencing for efficient
temporally-extended exploration. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=JwGKVpRfVD">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to effectively reuse prior knowledge is a key requirement when building general and flexible Reinforcement Learning (RL) agents. Skill reuse is one of the most common approaches, but current methods have considerable limitations. For example, fine-tuning an existing policy frequently fails, as the policy can degrade rapidly early in training. In a similar vein, distillation of expert behavior can lead to poor results when given sub-optimal experts. We compare several common approaches for skill transfer on multiple domains including changes in task and system dynamics. We identify how existing methods fail and introduce an alternative approach to mitigate these problems. Our approach learns to sequence temporally-extended skills for exploration but learns the final policy directly from the raw experience. This conceptual split enables rapid adaptation and thus efficient data collection but without constraining the final solution. It significantly outperforms many classical methods across a suite of evaluation tasks and we use a broad set of ablations to highlight the importance of different components of our method.},
  archive      = {J_TMLR},
  author       = {Giulia Vezzani and Dhruva Tirumala and Markus Wulfmeier and Dushyant Rao and Abbas Abdolmaleki and Ben Moran and Tuomas Haarnoja and Jan Humplik and Roland Hafner and Michael Neunert and Claudio Fantacci and Tim Hertweck and Thomas Lampe and Fereshteh Sadeghi and Nicolas Heess and Martin Riedmiller},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SkillS: Adaptive skill sequencing for efficient temporally-extended exploration},
  url          = {https://openreview.net/forum?id=JwGKVpRfVD},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimistic optimization of gaussian process samples.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=KQ5jI19kF3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian optimization is a popular formalism for global optimization, but its computational costs limit it to expensive-to-evaluate functions. A competing, computationally more effi- cient, global optimization framework is optimistic optimization, which exploits prior knowl- edge about the geometry of the search space in form of a dissimilarity function. We investi- gate to which degree the conceptual advantages of Bayesian Optimization can be combined with the computational efficiency of optimistic optimization. By mapping the kernel to a dissimilarity, we obtain an optimistic optimization algorithm for the Bayesian Optimization setting with a run-time of up to $O(N log N )$. As a high-level take-away we find that, when using stationary kernels on objectives of low evaluation cost, optimistic optimization can be preferable over Bayesian optimization, while for strongly coupled and parametric models, Bayesian optimization can perform much better, even at low evaluation cost. As a concep- tual takeaway, our results demonstrate that balancing exploration and exploitation under Gaussian process assumptions does not require computing a posterior.},
  archive      = {J_TMLR},
  author       = {Julia Grosse and Cheng Zhang and Philipp Hennig},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Optimistic optimization of gaussian process samples},
  url          = {https://openreview.net/forum?id=KQ5jI19kF3},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Approximating naive bayes on unlabelled categorical data.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=KpElM2S9pw">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the question of binary classification when no labels are available and the input features are categorical. The lack of labels means supervised approaches can&#39;t be used, and the lack of a natural distance measure means that most unsupervised methods do poorly. For such problems, where the alternatives might be a) do nothing or b) heuristic rules-based approaches, we offer a third alternative: a classifier that approximates Naive Bayes. Our primary scenarios are those that involve distinguishing scripted, or bot, web traffic from that of legitimate users. Our main assumption is the existence of some attribute $x_*$ more prevalent in the benign than the scripted traffic; i.e., $P(x_*|\overline{\mbox{bot}}) = K \cdot P(x_*|\mbox{bot}),$ for $K&gt;1.$ We show that any such disparity yields a lower bound on $P(\mbox{bot}|x_{j})$ even when we have no prior estimates of $P(x_*|\overline{\mbox{bot}}),$ $P(x_*|\mbox{bot})$ or $K$ (except that $K&gt;1$). We show that when at least one bin of at least one feature receives no attack traffic then we under-estimate the actual conditional probability by a factor of $1-1/K.$ Thus, any attribute with a large disparity between prevalence in benign and abuse traffic (i.e., $K$ is large), allows good approximation of the Naive Bayes classifier without the benefit of labels. The approach is particularly suited to problems where $K$ is high and thus the approximation is very accurate. Example problems (and relevant attributes) might be: password-guessing, if login attempts from legitimate users succeed at a much higher rate than those from password-guessing attackers; Credit Card Verification Value (CVV) guessing, if an attacker exhaustively tries all possible 3 or 4-digit values and fails at a higher rate than legitimate users; account registration, if legitimate users use email addresses from services that do not allow fee anonymous accounts (e.g., {\tt .edu}) at a much higher rate than attackers; click-fraud if legitimate users visit pages and services that contain no ads at a higher rate than click-fraud bots.},
  archive      = {J_TMLR},
  author       = {Cormac Herley},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Approximating naive bayes on unlabelled categorical data},
  url          = {https://openreview.net/forum?id=KpElM2S9pw},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-annotator deep learning: A probabilistic framework for
classification. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=MgdoxzImlK">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving complex classification tasks using deep neural networks typically requires large amounts of annotated data. However, corresponding class labels are noisy when provided by error-prone annotators, e.g., crowdworkers. Training standard deep neural networks leads to subpar performances in such multi-annotator supervised learning settings. We address this issue by presenting a probabilistic training framework named multi-annotator deep learning (MaDL). A downstream ground truth and an annotator performance model are jointly trained in an end-to-end learning approach. The ground truth model learns to predict instances&#39; true class labels, while the annotator performance model infers probabilistic estimates of annotators&#39; performances. A modular network architecture enables us to make varying assumptions regarding annotators&#39; performances, e.g., an optional class or instance dependency. Further, we learn annotator embeddings to estimate annotators&#39; densities within a latent space as proxies of their potentially correlated annotations. Together with a weighted loss function, we improve the learning from correlated annotation patterns. In a comprehensive evaluation, we examine three research questions about multi-annotator supervised learning. Our findings show MaDL&#39;s state-of-the-art performance and robustness against many correlated, spamming annotators.},
  archive      = {J_TMLR},
  author       = {Marek Herde and Denis Huseljic and Bernhard Sick},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Multi-annotator deep learning: A probabilistic framework for classification},
  url          = {https://openreview.net/forum?id=MgdoxzImlK},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to optimize quasi-newton methods. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=Ns2X7Azudy">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fast gradient-based optimization algorithms have become increasingly essential for the computationally efficient training of machine learning models. One technique is to multiply the gradient by a preconditioner matrix to produce a step, but it is unclear what the best preconditioner matrix is. This paper introduces a novel machine learning optimizer called LODO, which tries to online meta-learn the best preconditioner during optimization. Specifically, our optimizer merges Learning to Optimize (L2O) techniques with quasi-Newton methods to learn preconditioners parameterized as neural networks; they are more flexible than preconditioners in other quasi-Newton methods. Unlike other L2O methods, LODO does not require any meta-training on a training task distribution, and instead learns to optimize on the fly while optimizing on the test task, adapting to the local characteristics of the loss landscape while traversing it. Theoretically, we show that our optimizer approximates the inverse Hessian in noisy loss landscapes and is capable of representing a wide range of inverse Hessians. We experimentally verify that our algorithm can optimize in noisy settings, and show that simpler alternatives for representing the inverse Hessians worsen performance. Lastly, we use our optimizer to train a semi-realistic deep neural network with 95k parameters at speeds comparable to those of standard neural network optimizers.},
  archive      = {J_TMLR},
  author       = {Isaac Liao and Rumen Dangovski and Jakob Nicolaus Foerster and Marin Soljacic},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning to optimize quasi-newton methods},
  url          = {https://openreview.net/forum?id=Ns2X7Azudy},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mitigating confirmation bias in semi-supervised learning via
efficient bayesian model averaging. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=PRrKOaDQtQ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-of-the-art (SOTA) semi-supervised learning (SSL) methods have been highly successful in leveraging a mix of labeled and unlabeled data, often via self-training or pseudo-labeling. During pseudo-labeling, the model&#39;s predictions on unlabeled data are used for training and may result in confirmation bias where the model reinforces its own mistakes. In this work, we show that SOTA SSL methods often suffer from confirmation bias and demonstrate that this is often a result of using a poorly calibrated classifier for pseudo labeling. We introduce BaM-SSL, an efficient Bayesian Model averaging technique that improves uncertainty quantification in SSL methods with limited computational or memory overhead. We demonstrate that BaM-SSL mitigates confirmation bias in SOTA SSL methods across standard vision benchmarks of CIFAR-10, CIFAR-100, giving up to 16% improvement in test accuracy on the CIFAR-100 with 400 labels benchmark. Furthermore, we also demonstrate their effectiveness in additional realistic and challenging problems, such as class-imbalanced datasets and in photonics science.},
  archive      = {J_TMLR},
  author       = {Charlotte Loh and Rumen Dangovski and Shivchander Sudalairaj and Seungwook Han and Ligong Han and Leonid Karlinsky and Marin Soljacic and Akash Srivastava},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Mitigating confirmation bias in semi-supervised learning via efficient bayesian model averaging},
  url          = {https://openreview.net/forum?id=PRrKOaDQtQ},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detecting incidental correlation in multimodal learning via
latent variable modeling. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=QoRo9QmOAr">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal neural networks often fail to utilize all modalities. They subsequently generalize worse than their unimodal counterparts, or make predictions that only depend on a subset of modalities. We refer to this problem as \emph{modality underutilization}. Existing work has addressed this issue by ensuring that there are no systematic biases in dataset creation, or that our neural network architectures and optimization algorithms are capable of learning modality interactions. We demonstrate that even when these favorable conditions are met, modality underutilization can still occur in the small data regime. To explain this phenomenon, we put forth a concept that we call \emph{incidental correlation}. It is a spurious correlation that emerges in small datasets, despite not being a part of the underlying data generating process (DGP). We develop our argument using a DGP under which multimodal neural networks must utilize all modalities, since all paths between the inputs and target are causal. This represents an idealized scenario that often fails to materialize. Instead, due to incidental correlation, small datasets sampled from this DGP have higher likelihood under an alternative DGP with spurious paths between the inputs and target. Multimodal neural networks that use these spurious paths for prediction fail to utilize all modalities. Given its harmful effects, we propose to detect incidental correlation via latent variable modeling. We specify an identifiable variational autoencoder such that the latent posterior encodes the spurious correlations between the inputs and target. This allows us to interpret the Kullback-Leibler divergence between the latent posterior and prior as the severity of incidental correlation. We use an ablation study to show that identifiability is important in this context, since we derive our conclusions from the latent posterior. Using experiments with synthetic data, as well as with VQA v2.0 and NLVR2, we demonstrate that incidental correlation emerges in the small data regime, and leads to modality underutilization. Practitioners of multimodal learning can use our method to detect whether incidental correlation is present in their datasets, and determine whether they should collect additional data.},
  archive      = {J_TMLR},
  author       = {Taro Makino and Yixin Wang and Krzysztof J. Geras and Kyunghyun Cho},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Detecting incidental correlation in multimodal learning via latent variable modeling},
  url          = {https://openreview.net/forum?id=QoRo9QmOAr},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Task weighting in meta-learning with trajectory
optimisation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=SSkTBUyJip">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing meta-learning algorithms that are un-biased toward a subset of training tasks often requires hand-designed criteria to weight tasks, potentially resulting in sub-optimal solutions. In this paper, we introduce a new principled and fully-automated task-weighting algorithm for meta-learning methods. By considering the weights of tasks within the same mini-batch as an action, and the meta-parameter of interest as the system state, we cast the task-weighting meta-learning problem to a trajectory optimisation and employ the iterative linear quadratic regulator to determine the optimal action or weights of tasks. We theoretically show that the proposed algorithm converges to an $\epsilon_{0}$-stationary point, and empirically demonstrate that the proposed approach out-performs common hand-engineering weighting methods in two few-shot learning benchmarks.},
  archive      = {J_TMLR},
  author       = {Cuong C. Nguyen and Thanh-Toan Do and Gustavo Carneiro},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Task weighting in meta-learning with trajectory optimisation},
  url          = {https://openreview.net/forum?id=SSkTBUyJip},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Revisiting hidden representations in transfer learning for
medical imaging. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ScrEUZLxPr">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While a key component to the success of deep learning is the availability of massive amounts of training data, medical image datasets are often limited in diversity and size. Transfer learning has the potential to bridge the gap between related yet different domains. For medical applications, however, it remains unclear whether it is more beneficial to pre-train on natural or medical images. We aim to shed light on this problem by comparing initialization on ImageNet and RadImageNet on seven medical classification tasks. Our work includes a replication study, which yields results contrary to previously published findings. In our experiments, ResNet50 models pre-trained on ImageNet tend to outperform those trained on RadImageNet. To gain further insights, we investigate the learned representations using Canonical Correlation Analysis (CCA) and compare the predictions of the different models. Our results indicate that, contrary to intuition, ImageNet and RadImageNet may converge to distinct intermediate representations, which appear to diverge further during fine-tuning. Despite these distinct representations, the predictions of the models remain similar. Our findings show that the similarity between networks before and after fine-tuning does not correlate with performance gains, suggesting that the advantages of transfer learning might not solely originate from the reuse of features in the early layers of a convolutional neural network.},
  archive      = {J_TMLR},
  author       = {Dovile Juodelyte and Amelia Jiménez-Sánchez and Veronika Cheplygina},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Revisiting hidden representations in transfer learning for medical imaging},
  url          = {https://openreview.net/forum?id=ScrEUZLxPr},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic subgoal-based exploration via bayesian optimization.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ThJl4d5JRg">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning in sparse-reward navigation environments with expensive and limited interactions is challenging and poses a need for effective exploration. Motivated by complex navigation tasks that require real-world training (when cheap simulators are not available), we consider an agent that faces an unknown distribution of environments and must decide on an exploration strategy. It may leverage a series of training environments to improve its policy before it is evaluated in a test environment drawn from the same environment distribution. Most existing approaches focus on fixed exploration strategies, while the few that view exploration as a meta-optimization problem tend to ignore the need for _cost-efficient_ exploration. We propose a cost-aware Bayesian optimization approach that efficiently searches over a class of dynamic subgoal-based exploration strategies. The algorithm adjusts a variety of levers --- the locations of the subgoals, the length of each episode, and the number of replications per trial --- in order to overcome the challenges of sparse rewards, expensive interactions, and noise. An experimental evaluation demonstrates that the new approach outperforms existing baselines across a number of problem domains. We also provide a theoretical foundation and prove that the method asymptotically identifies a near-optimal subgoal design.},
  archive      = {J_TMLR},
  author       = {Yijia Wang and Matthias Poloczek and Daniel R. Jiang},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Dynamic subgoal-based exploration via bayesian optimization},
  url          = {https://openreview.net/forum?id=ThJl4d5JRg},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the sample complexity of lipschitz constant estimation.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=UIalYAHdBH">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the Lipschitz constant of a function, also known as Lipschitz learning, is a fundamental problem with broad applications in fields such as control and global optimization. In this paper, we study the Lipschitz learning problem with minimal parametric assumptions on the target function. As a first theoretical contribution, we derive novel lower bounds on the sample complexity of this problem for both noise-free and noisy settings under mild assumptions. Moreover, we propose a simple Lipschitz learning algorithm called $\textit{Lipschitz Constant Estimation by Least Squares Regression}$ (referred to as LCLS). We show that LCLS is asymptotically consistent for general noise assumptions and offers finite sample guarantees that can be translated to new upper bounds on the sample complexity of the Lipschitz learning problem. Our analysis shows that the sample complexity rates derived in this paper are optimal in both the noise-free setting and in the noisy setting when the noise is assumed to follow a Gaussian distribution and that LCLS is a sample-optimal algorithm in both cases. Finally, we show that by design, the LCLS algorithm is computationally faster than existing theoretically consistent methods, and can be readily adapted to various noise assumptions with little to no prior knowledge of the target function properties or noise distribution.},
  archive      = {J_TMLR},
  author       = {Julien Walden Huang and Stephen J. Roberts and Jan-Peter Calliess},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the sample complexity of lipschitz constant estimation},
  url          = {https://openreview.net/forum?id=UIalYAHdBH},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gated domain units for multi-source domain generalization.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=V7BvYJyTmM">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The phenomenon of distribution shift (DS) occurs when a dataset at test time differs from the dataset at training time, which can significantly impair the performance of a machine learning model in practical settings due to a lack of knowledge about the data&#39;s distribution at test time. To address this problem, we postulate that real-world distributions are composed of latent Invariant Elementary Distributions (I.E.D) across different domains. This assumption implies an invariant structure in the solution space that enables knowledge transfer to unseen domains. To exploit this property for domain generalization, we introduce a modular neural network layer consisting of Gated Domain Units (GDUs) that learn a representation for each latent elementary distribution. During inference, a weighted ensemble of learning machines can be created by comparing new observations with the representations of each elementary distribution. Our flexible framework also accommodates scenarios where explicit domain information is not present. Extensive experiments on image, text, and graph data show consistent performance improvement on out-of-training target domains. These findings support the practicality of the I.E.D assumption and the effectiveness of GDUs for domain generalisation.},
  archive      = {J_TMLR},
  author       = {Simon Föll and Alina Dubatovka and Eugen Ernst and Siu Lun Chau and Martin Maritsch and Patrik Okanovic and Gudrun Thaeter and Joachim M. Buhmann and Felix Wortmann and Krikamol Muandet},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Gated domain units for multi-source domain generalization},
  url          = {https://openreview.net/forum?id=V7BvYJyTmM},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A DNN optimizer that improves over AdaBelief by suppression
of the adaptive stepsize range. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=VI2JjIfU37">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We make contributions towards improving adaptive-optimizer performance. Our improvements are based on suppression of the range of adaptive stepsizes in the AdaBelief optimizer. Firstly, we show that the particular placement of the parameter $\epsilon$ within the update expressions of AdaBelief reduces the range of the adaptive stepsizes, making AdaBelief closer to SGD with momentum. Secondly, we extend AdaBelief by further suppressing the range of the adaptive stepsizes. To achieve the above goal, we perform mutual layerwise vector projections between the gradient $\boldsymbol{g}_t$ and its first momentum $\boldsymbol{m}_t$ before using them to estimate the second momentum. The new optimization method is referred to as \emph{Aida}. Thirdly, extensive experimental results show that Aida outperforms nine optimizers when training transformers and LSTMs for NLP, and VGG and ResNet for image classification over CIAF10 and CIFAR100 while matching the best performance of the nine methods when training WGAN-GP models for image generation tasks. Furthermore, Aida produces higher validation accuracies than AdaBelief for training ResNet18 over ImageNet.},
  archive      = {J_TMLR},
  author       = {Guoqiang Zhang and Kenta Niwa and W. Bastiaan Kleijn},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A DNN optimizer that improves over AdaBelief by suppression of the adaptive stepsize range},
  url          = {https://openreview.net/forum?id=VI2JjIfU37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An option-dependent analysis of regret minimization
algorithms in finite-horizon semi-MDP. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=VP9p4u9jAo">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A large variety of real-world Reinforcement Learning (RL) tasks is characterized by a complex and heterogeneous structure that makes end-to-end (or flat) approaches hardly applicable or even infeasible. Hierarchical Reinforcement Learning (HRL) provides general solutions to address these problems thanks to a convenient multi-level decomposition of the tasks, making their solution accessible. Although often used in practice, few works provide theoretical guarantees to justify this outcome effectively. Thus, it is not yet clear when to prefer such approaches compared to standard flat ones. In this work, we provide an option-dependent upper bound to the regret suffered by regret minimization algorithms in finite-horizon problems. We illustrate that the performance improvement derives from the planning horizon reduction induced by the temporal abstraction enforced by the hierarchical structure. Then, focusing on a sub-setting of HRL approaches, the options framework, we highlight how the average duration of the available options affects the planning horizon and, consequently, the regret itself. Finally, we relax the assumption of having pre-trained options to show how, in particular situations, is still preferable a hierarchical approach over a standard one.},
  archive      = {J_TMLR},
  author       = {Gianluca Drappo and Alberto Maria Metelli and Marcello Restelli},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {An option-dependent analysis of regret minimization algorithms in finite-horizon semi-MDP},
  url          = {https://openreview.net/forum?id=VP9p4u9jAo},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The geometry of mixability. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=VrvGHDSzZ7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixable loss functions are of fundamental importance in the context of prediction with expert advice in the online setting since they characterize fast learning rates. By re-interpreting properness from the point of view of differential geometry, we provide a simple geometric characterization of mixability for the binary and multi-class cases: a proper loss function $\ell$ is $\eta$-mixable if and only if the superprediction set $\textrm{spr}(\eta \ell)$ of the scaled loss function $\eta \ell$ slides freely inside the superprediction set $\textrm{spr}(\ell_{\log})$ of the log loss $\ell_{\log}$, under fairly general assumptions on the differentiability of $\ell$. Our approach provides a way to treat some concepts concerning loss functions (like properness) in a &#39;&#39;coordinate-free&#39;&#39; manner and reconciles previous results obtained for mixable loss functions for the binary and the multi-class cases.},
  archive      = {J_TMLR},
  author       = {Armando J Cabrera Pacheco and Robert Williamson},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The geometry of mixability},
  url          = {https://openreview.net/forum?id=VrvGHDSzZ7},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). How reliable is your regression model’s uncertainty under
real-world distribution shifts? <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=WJt2Pc3qtI">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many important computer vision applications are naturally formulated as regression problems. Within medical imaging, accurate regression models have the potential to automate various tasks, helping to lower costs and improve patient outcomes. Such safety-critical deployment does however require reliable estimation of model uncertainty, also under the wide variety of distribution shifts that might be encountered in practice. Motivated by this, we set out to investigate the reliability of regression uncertainty estimation methods under various real-world distribution shifts. To that end, we propose an extensive benchmark of 8 image-based regression datasets with different types of challenging distribution shifts. We then employ our benchmark to evaluate many of the most common uncertainty estimation methods, as well as two state-of-the-art uncertainty scores from the task of out-of-distribution detection. We find that while methods are well calibrated when there is no distribution shift, they all become highly overconfident on many of the benchmark datasets. This uncovers important limitations of current uncertainty estimation methods, and the proposed benchmark therefore serves as a challenge to the research community. We hope that our benchmark will spur more work on how to develop truly reliable regression uncertainty estimation methods.},
  archive      = {J_TMLR},
  author       = {Fredrik K. Gustafsson and Martin Danelljan and Thomas B. Schön},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {How reliable is your regression model&#39;s uncertainty under real-world distribution shifts?},
  url          = {https://openreview.net/forum?id=WJt2Pc3qtI},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Achieving the pareto frontier of regret minimization and
best arm identification in multi-armed bandits. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=XXfEmIMJDm">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the Pareto frontier of two archetypal objectives in multi-armed bandits, namely, regret minimization (RM) and best arm identification (BAI) with a fixed horizon. It is folklore that the balance between exploitation and exploration is crucial for both RM and BAI, but exploration is more critical in achieving the optimal performance for the latter objective. To this end, we design and analyze the BoBW-lil’UCB($\gamma$) algorithm. Complementarily, by establishing lower bounds on the regret achievable by any algorithm with a given BAI failure probability, we show that (i) no algorithm can simultaneously perform optimally for both the RM and BAI objectives, and (ii) BoBW-lil’UCB($\gamma$) achieves order-wise optimal performance for RM or BAI under different values of $\gamma$. Our work elucidates the trade-off more precisely by showing how the constants in previous works depend on certain hardness parameters. Finally, we show that BoBW-lil’UCB outperforms a close competitor UCB$_\alpha$ (Degenne et al., 2019) in terms of the time complexity and the regret on diverse datasets such as MovieLens and Published Kinase Inhibitor Set.},
  archive      = {J_TMLR},
  author       = {Zixin Zhong and Wang Chi Cheung and Vincent Tan},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Achieving the pareto frontier of regret minimization and best arm identification in multi-armed bandits},
  url          = {https://openreview.net/forum?id=XXfEmIMJDm},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Turning a curse into a blessing: Enabling
in-distribution-data-free backdoor removal via stabilized model
inversion. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=XuOE99cmST">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effectiveness of many existing techniques for removing backdoors from machine learning models relies on access to clean in-distribution data. However, given that these models are often trained on proprietary datasets, it may not be practical to assume that in-distribution samples will always be available. On the other hand, model inversion techniques, which are typically viewed as privacy threats, can reconstruct realistic training samples from a given model, potentially eliminating the need for in-distribution data. To date, the only prior attempt to integrate backdoor removal and model inversion involves a simple combination that produced very limited results. This work represents a first step toward a more thorough understanding of how model inversion techniques could be leveraged for effective backdoor removal. Specifically, we seek to answer several key questions: What properties must reconstructed samples possess to enable successful defense? Is perceptual similarity to clean samples enough, or are additional characteristics necessary? Is it possible for reconstructed samples to contain backdoor triggers? We demonstrate that relying solely on perceptual similarity is insufficient for effective defenses. The stability of model predictions in response to input and parameter perturbations also plays a critical role. To address this, we propose a new bi-level optimization based framework for model inversion that promotes stability in addition to visual quality. Interestingly, we also find that reconstructed samples from a pre-trained generator&#39;s latent space do not contain backdoors, even when signals from a backdoored model are utilized for reconstruction. We provide a theoretical analysis to explain this observation. Our evaluation shows that our stabilized model inversion technique achieves state-of-the-art backdoor removal performance without requiring access to clean in-distribution data. Furthermore, its performance is on par with or even better than using the same amount of clean samples.},
  archive      = {J_TMLR},
  author       = {Si Chen and Yi Zeng and Won Park and Jiachen T. Wang and Xun Chen and Lingjuan Lyu and Zhuoqing Mao and Ruoxi Jia},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Turning a curse into a blessing: Enabling in-distribution-data-free backdoor removal via stabilized model inversion},
  url          = {https://openreview.net/forum?id=XuOE99cmST},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Relating graph auto-encoders to linear models.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Y1eYplvxrE">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph auto-encoders are widely used to construct graph representations in Euclidean vector spaces. However, it has already been pointed out empirically that linear models on many tasks can outperform graph auto-encoders. In our work, we prove that the solution space induced by graph auto-encoders is a subset of the solution space of a linear map. This demonstrates that linear embedding models have at least the representational power of graph auto-encoders based on graph convolutional networks. So why are we still using nonlinear graph auto-encoders? One reason could be that actively restricting the linear solution space might introduce an inductive bias that helps improve learning and generalization. While many researchers believe that the nonlinearity of the encoder is the critical ingredient towards this end, we instead identify the node features of the graph as a more powerful inductive bias. We give theoretical insights by introducing a corresponding bias in a linear model and analyzing the change in the solution space. Our experiments are aligned with other empirical work on this question and show that the linear encoder can outperform the nonlinear encoder when using feature information.},
  archive      = {J_TMLR},
  author       = {Solveig Klepper and Ulrike von Luxburg},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Relating graph auto-encoders to linear models},
  url          = {https://openreview.net/forum?id=Y1eYplvxrE},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on causal discovery methods for i.i.d. And time
series data. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=YdMrdhGx9y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to understand causality from data is one of the major milestones of human-level intelligence. Causal Discovery (CD) algorithms can identify the cause-effect relationships among the variables of a system from related observational data with certain assumptions. Over the years, several methods have been developed primarily based on the statistical properties of data to uncover the underlying causal mechanism. In this study, we present an extensive discussion on the methods designed to perform causal discovery from both independent and identically distributed (I.I.D.) data and time series data. For this purpose, we first introduce the common terminologies used in causal discovery literature and then provide a comprehensive discussion of the algorithms designed to identify causal relations in different settings. We further discuss some of the benchmark datasets available for evaluating the algorithmic performance, off-the-shelf tools or software packages to perform causal discovery readily, and the common metrics used to evaluate these methods. We also evaluate some widely used causal discovery algorithms on multiple benchmark datasets and compare their performances. Finally, we conclude by discussing the research challenges and the applications of causal discovery algorithms in multiple areas of interest.},
  archive      = {J_TMLR},
  author       = {Uzma Hasan and Emam Hossain and Md Osman Gani},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A survey on causal discovery methods for I.I.D. and time series data},
  url          = {https://openreview.net/forum?id=YdMrdhGx9y},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differentially private diffusion models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ZPpQk7FJXF">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While modern machine learning models rely on increasingly large training datasets, data is often limited in privacy-sensitive domains. Generative models trained with differential privacy (DP) on sensitive data can sidestep this challenge, providing access to synthetic data instead. We build on the recent success of diffusion models (DMs) and introduce Differentially Private Diffusion Models (DPDMs), which enforce privacy using differentially private stochastic gradient descent (DP-SGD). We investigate the DM parameterization and the sampling algorithm, which turn out to be crucial ingredients in DPDMs, and propose noise multiplicity, a powerful modification of DP-SGD tailored to the training of DMs. We validate our novel DPDMs on image generation benchmarks and achieve state-of-the-art performance in all experiments. Moreover, on standard benchmarks, classifiers trained on DPDM-generated synthetic data perform on par with task-specific DP-SGD-trained classifiers, which has not been demonstrated before for DP generative models. Project page and code: https://nv-tlabs.github.io/DPDM.},
  archive      = {J_TMLR},
  author       = {Tim Dockhorn and Tianshi Cao and Arash Vahdat and Karsten Kreis},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Differentially private diffusion models},
  url          = {https://openreview.net/forum?id=ZPpQk7FJXF},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimating differential equations from temporal point
processes. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=cJgHzw8Qhq">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ordinary differential equations (ODEs) allow interpretation of phenomena in various scientific fields. They have mostly been applied to numerical data observed at regular intervals, but not to irregularly observed discrete events, also known as point processes. In this study, we introduce an ODE modeling of such events by combining ODEs with log-Gaussian Cox processes (Møller et al., 1998). In the experiments with different types of ODEs regarding infectious disease, predator-prey interaction, and competition among participants, our method outperformed existing baseline methods assuming regularly observed continuous data with respect to the accuracy of recovering the latent parameters of ODEs. Through both synthetic and actual examples, we also showed the ability of our method to extrapolate, model latent events that cannot be observed, and offer interpretability of phenomena from the viewpoint of the estimated parameters of ODE.},
  archive      = {J_TMLR},
  author       = {Shuichi Miyazawa and Daichi Mochihashi},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Estimating differential equations from temporal point processes},
  url          = {https://openreview.net/forum?id=cJgHzw8Qhq},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Teaching smaller language models to generalise to unseen
compositional questions. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=d4Vr6E0jjm">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We equip a smaller Language Model to generalise to answering challenging compositional questions that have not been seen in training. To do so we propose a combination of multitask supervised pretraining on up to 93 tasks designed to instill diverse reasoning abilities, and a dense retrieval system that aims to retrieve a set of evidential paragraph fragments. Recent progress in question-answering has been achieved either through prompting methods against very large pretrained Language Models in zero or few-shot fashion, or by fine-tuning smaller models, sometimes in conjunction with information retrieval. We focus on the less explored question of the extent to which zero-shot generalisation can be enabled in smaller models with retrieval against a corpus within which sufficient information to answer a particular question may not exist. We establish strong baselines in this setting for diverse evaluation datasets (StrategyQA, CommonsenseQA, IIRC, DROP, Musique and ARC-DA), and show that performance can be significantly improved by adding retrieval-augmented training datasets which are designed to expose our models to a variety of heuristic reasoning strategies such as weighing partial evidence or ignoring an irrelevant context.},
  archive      = {J_TMLR},
  author       = {Tim Hartill and Neset TAN and Michael Witbrock and Patricia J. Riddle},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Teaching smaller language models to generalise to unseen compositional questions},
  url          = {https://openreview.net/forum?id=d4Vr6E0jjm},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Variational elliptical processes. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=djN3TaqbdA">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present elliptical processes—a family of non-parametric probabilistic models that subsumes Gaussian processes and Student&#39;s t processes. This generalization includes a range of new heavy-tailed behaviors while retaining computational tractability. Elliptical processes are based on a representation of elliptical distributions as a continuous mixture of Gaussian distributions. We parameterize this mixture distribution as a spline normalizing flow, which we train using variational inference. The proposed form of the variational posterior enables a sparse variational elliptical process applicable to large-scale problems. We highlight advantages compared to Gaussian processes through regression and classification experiments. Elliptical processes can supersede Gaussian processes in several settings, including cases where the likelihood is non-Gaussian or when accurate tail modeling is essential.},
  archive      = {J_TMLR},
  author       = {Maria Margareta Bånkestad and Jens Sjölund and Jalil Taghia and Thomas B. Schön},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Variational elliptical processes},
  url          = {https://openreview.net/forum?id=djN3TaqbdA},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Faster training of neural ODEs using gauß–legendre
quadrature. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=f0FSDAy1bU">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural ODEs demonstrate strong performance in generative and time-series modelling. However, training them via the adjoint method is slow compared to discrete models due to the requirement of numerically solving ODEs. To speed neural ODEs up, a common approach is to regularise the solutions. However, this approach may affect the expressivity of the model; when the trajectory itself matters, this is particularly important. In this paper, we propose an alternative way to speed up the training of neural ODEs. The key idea is to speed up the adjoint method by using Gauß-Legendre quadrature to solve integrals faster than ODE-based methods while remaining memory efficient. We also extend the idea to training SDEs using the Wong-Zakai theorem, by training a corresponding ODE and transferring the parameters. Our approach leads to faster training of neural ODEs, especially for large models. It also presents a new way to train SDE-based models.},
  archive      = {J_TMLR},
  author       = {Alexander Luke Ian Norcliffe and Marc Peter Deisenroth},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Faster training of neural ODEs using Gauß–Legendre quadrature},
  url          = {https://openreview.net/forum?id=f0FSDAy1bU},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluating human-language model interaction. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=hjDYJUn9l1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world applications of language models (LMs), such as writing assistance and code autocomplete, involve human-LM interaction. However, most benchmarks are non-interactive in that a model produces output without human involvement. To evaluate human-LM interaction, we develop a new framework, Human-AI Language-based Interaction Evaluation (HALIE), that defines the components of interactive systems and dimensions to consider when designing evaluation metrics. Compared to standard, non-interactive evaluation, HALIE captures (i) the interactive process, not only the final output; (ii) the first-person subjective experience, not just a third-party assessment; and (iii) notions of preference beyond quality (e.g., enjoyment and ownership). We then design five tasks to cover different forms of interaction: social dialogue, question answering, crossword puzzles, summarization, and metaphor generation. With four state-of-the-art LMs (three variants of OpenAI&#39;s GPT-3 and AI21 Labs&#39; Jurassic-1), we find that better non-interactive performance does not always translate to better human-LM interaction. In particular, we highlight three cases where the results from non-interactive and interactive metrics diverge and underscore the importance of human-LM interaction for LM evaluation.},
  archive      = {J_TMLR},
  author       = {Mina Lee and Megha Srivastava and Amelia Hardy and John Thickstun and Esin Durmus and Ashwin Paranjape and Ines Gerard-Ursin and Xiang Lisa Li and Faisal Ladhak and Frieda Rong and Rose E Wang and Minae Kwon and Joon Sung Park and Hancheng Cao and Tony Lee and Rishi Bommasani and Michael S. Bernstein and Percy Liang},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Evaluating human-language model interaction},
  url          = {https://openreview.net/forum?id=hjDYJUn9l1},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Revisiting sparsity hunting in federated learning: Why does
sparsity consensus matter? <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=iHyhdpsnyi">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge devices can benefit remarkably from federated learning due to their distributed nature; however, their limited resource and computing power poses limitations in deployment. A possible solution to this problem is to utilize off-the-shelf sparse learning algorithms at the clients to meet their resource budget. However, such naive deployment in the clients causes significant accuracy degradation, especially for highly resource-constrained clients. In particular, our investigations reveal that the lack of consensus in the sparsity masks among the clients may potentially slow down the convergence of the global model and cause a substantial accuracy drop. With these observations, we present \textit{federated lottery aware sparsity hunting} (FLASH), a unified sparse learning framework for training a sparse sub-model that maintains the performance under ultra-low parameter density while yielding proportional communication benefits. Moreover, given that different clients may have different resource budgets, we present \textit{hetero-FLASH} where clients can take different density budgets based on their device resource limitations instead of supporting only one target parameter density. Experimental analysis on diverse models and datasets shows the superiority of FLASH in closing the gap with an unpruned baseline while yielding up to $\mathord{\sim}10.1\%$ improved accuracy with $\mathord{\sim}10.26\times$ fewer communication, compared to existing alternatives, at similar hyperparameter settings.},
  archive      = {J_TMLR},
  author       = {Sara Babakniya and Souvik Kundu and Saurav Prakash and Yue Niu and Salman Avestimehr},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Revisiting sparsity hunting in federated learning: Why does sparsity consensus matter?},
  url          = {https://openreview.net/forum?id=iHyhdpsnyi},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On perfect clustering for gaussian processes. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=igDOV2KBwM">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a data based transformation for infinite-dimensional Gaussian processes and derive its limit theorem. For a clustering problem using mixture models, an appropriate modification of this transformation asymptotically leads to perfect separation of the populations under rather general conditions, except the scenario in which differences between clusters depend only on the locations; in which case our procedure is useless. Theoretical properties related to label consistency are studied for the k-means clustering algorithm when used on this transformed data. Good empirical performance of the proposed methodology is demonstrated using simulated as well as benchmark data sets, when compared with some popular parametric and nonparametric methods for such functional data.},
  archive      = {J_TMLR},
  author       = {Juan Cuesta-Albertos and Subhajit Dutta},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On perfect clustering for gaussian processes},
  url          = {https://openreview.net/forum?id=igDOV2KBwM},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). High fidelity neural audio compression. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ivCd8z8zR2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a state-of-the-art real-time, high-fidelity, audio codec leveraging neural networks. It consists in a streaming encoder-decoder architecture with quantized latent space trained in an end-to-end fashion. We simplify and speed-up the training by using a single multiscale spectrogram adversary that efficiently reduces artifacts and produce high-quality samples. We introduce a novel loss balancer mechanism to stabilize training: the weight of a loss now defines the fraction of the overall gradient it should represent, thus decoupling the choice of this hyper-parameter from the typical scale of the loss. Finally, we study how lightweight Transformer models can be used to further compress the obtained representation by up to 40%, while staying faster than real time. We provide a detailed description of the key design choices of the proposed model including: training objective, architectural changes and a study of various perceptual loss functions. We present an extensive subjective evaluation (MUSHRA tests) together with an ablation study for a range of bandwidths and audio domains, including speech, noisy-reverberant speech, and music. Our approach is superior to the baselines methods across all evaluated settings, considering both 24 kHz monophonic and 48 kHz stereophonic audio. Code and samples are available under github.com/facebookresearch/encodec.},
  archive      = {J_TMLR},
  author       = {Alexandre Défossez and Jade Copet and Gabriel Synnaeve and Yossi Adi},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {High fidelity neural audio compression},
  url          = {https://openreview.net/forum?id=ivCd8z8zR2},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Individual privacy accounting for differentially private
stochastic gradient descent. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=l4Jcxs0fpC">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differentially private stochastic gradient descent (DP-SGD) is the workhorse algorithm for recent advances in private deep learning. It provides a single privacy guarantee to all datapoints in the dataset. We propose \emph{output-specific} $(\varepsilon,\delta)$-DP to characterize privacy guarantees for individual examples when releasing models trained by DP-SGD. We also design an efficient algorithm to investigate individual privacy across a number of datasets. We find that most examples enjoy stronger privacy guarantees than the worst-case bound. We further discover that the training loss and the privacy parameter of an example are well-correlated. This implies groups that are underserved in terms of model utility simultaneously experience weaker privacy guarantees. For example, on CIFAR-10, the average $\varepsilon$ of the class with the lowest test accuracy is 44.2\% higher than that of the class with the highest accuracy.},
  archive      = {J_TMLR},
  author       = {Da Yu and Gautam Kamath and Janardhan Kulkarni and Tie-Yan Liu and Jian Yin and Huishuai Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Individual privacy accounting for differentially private stochastic gradient descent},
  url          = {https://openreview.net/forum?id=l4Jcxs0fpC},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bridging the Sim2Real gap with CARE: Supervised detection
adaptation with conditional alignment and reweighting. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=lAQQx7hlku">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sim2Real domain adaptation (DA) research focuses on the constrained setting of adapting from a labeled synthetic source domain to an unlabeled or sparsely labeled real target domain. However, for high-stakes applications (e.g. autonomous driving), it is common to have a modest amount of human-labeled real data in addition to plentiful auto-labeled source data (e.g. from a driving simulator). We study this setting of supervised sim2real DA applied to 2D object detection. We propose Domain Translation via Conditional Alignment and Reweighting (CARE) a novel algorithm that systematically exploits target labels to explicitly close the sim2real appearance and content gaps. We present an analytical justification of our algorithm and demonstrate strong gains over competing methods on standard benchmarks.},
  archive      = {J_TMLR},
  author       = {Viraj Uday Prabhu and David Acuna and Rafid Mahmood and Marc T. Law and Yuan-Hong Liao and Judy Hoffman and Sanja Fidler and James Lucas},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bridging the Sim2Real gap with CARE: Supervised detection adaptation with conditional alignment and reweighting},
  url          = {https://openreview.net/forum?id=lAQQx7hlku},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cyclic and randomized stepsizes invoke heavier tails in SGD
than constant stepsize. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=lNB5EHx8uC">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyclic and randomized stepsizes are widely used in the deep learning practice and can often outperform standard stepsize choices such as constant stepsize in SGD. Despite their empirical success, not much is currently known about when and why they can theoretically improve the generalization performance. We consider a general class of Markovian stepsizes for learning, which contain i.i.d. random stepsize, cyclic stepsize as well as the constant stepsize as special cases, and motivated by the literature which shows that heaviness of the tails (measured by the so-called ``tail-index”) in the SGD iterates is correlated with generalization, we study tail-index and provide a number of theoretical results that demonstrate how the tail-index varies on the stepsize scheduling. Our results bring a new understanding of the benefits of cyclic and randomized stepsizes compared to constant stepsize in terms of the tail behavior. We illustrate our theory on linear regression experiments and show through deep learning experiments that Markovian stepsizes can achieve even a heavier tail and be a viable alternative to cyclic and i.i.d. randomized stepsize rules.},
  archive      = {J_TMLR},
  author       = {Mert Gurbuzbalaban and Yuanhan Hu and Umut Simsekli and Lingjiong Zhu},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Cyclic and randomized stepsizes invoke heavier tails in SGD than constant stepsize},
  url          = {https://openreview.net/forum?id=lNB5EHx8uC},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). <span class="math inline"><em>k</em></span>-mixup
regularization for deep learning via optimal transport. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=lOegPKSu04">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixup is a popular regularization technique for training deep neural networks that improves generalization and increases robustness to certain distribution shifts. It perturbs input training data in the direction of other randomly-chosen instances in the training set. To better leverage the structure of the data, we extend mixup in a simple, broadly applicable way to $k$-mixup, which perturbs $k$-batches of training points in the direction of other $k$-batches. The perturbation is done with displacement interpolation, i.e. interpolation under the Wasserstein metric. We demonstrate theoretically and in simulations that $k$-mixup preserves cluster and manifold structures, and we extend theory studying the efficacy of standard mixup to the $k$-mixup case. Our empirical results show that training with $k$-mixup further improves generalization and robustness across several network architectures and benchmark datasets of differing modalities. For the wide variety of real datasets considered, the performance gains of $k$-mixup over standard mixup are similar to or larger than the gains of mixup itself over standard ERM after hyperparameter optimization. In several instances, in fact, $k$-mixup achieves gains in settings where standard mixup has negligible to zero improvement over ERM.},
  archive      = {J_TMLR},
  author       = {Kristjan Greenewald and Anming Gu and Mikhail Yurochkin and Justin Solomon and Edward Chien},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {$k$-mixup regularization for deep learning via optimal transport},
  url          = {https://openreview.net/forum?id=lOegPKSu04},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantization robust federated learning for efficient
inference on heterogeneous devices. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=lvevdX6bxm">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is a machine learning paradigm to distributively learn machine learning models from decentralized data that remains on-device. Despite the success of standard Federated optimization methods, such as Federated Averaging (FedAvg) in FL, the energy demands and hardware induced constraints for on-device learning have not been considered sufficiently in the literature. Specifically, an essential demand for on-device learning is to enable trained models to be quantized to various bit-widths based on the energy needs and heterogeneous hardware designs across the federation. In this work, we introduce multiple variants of federated averaging algorithm that train neural networks robust to quantization. Such networks can be quantized to various bit-widths with only limited reduction in full precision model accuracy. We perform extensive experiments on standard FL benchmarks to evaluate our proposed FedAvg variants for quantization robustness and provide a convergence analysis for our Quantization-Aware variants in FL. Our results demonstrate that integrating quantization robustness results in FL models that are significantly more robust to different bit-widths during quantized on-device inference.},
  archive      = {J_TMLR},
  author       = {Kartik Gupta and Marios Fournarakis and Matthias Reisser and Christos Louizos and Markus Nagel},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Quantization robust federated learning for efficient inference on heterogeneous devices},
  url          = {https://openreview.net/forum?id=lvevdX6bxm},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). WOODS: Benchmarks for out-of-distribution generalization in
time series. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=mvftzofTYQ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models often fail to generalize well under distribution shifts. Understanding and overcoming these failures have led to a new research field on Out-of-Distribution (OOD) generalization. Despite being extensively studied for static computer vision tasks, OOD generalization has been severely underexplored for time series tasks. To shine a light on this gap, we present WOODS: 10 challenging time series benchmarks covering a diverse range of data modalities, such as videos, brain recordings, and smart device sensory signals. We revise the existing OOD generalization algorithms for time series tasks and evaluate them using our systematic framework. Our experiments show a large room for improvement for empirical risk minimization and OOD generalization algorithms on our datasets, thus underscoring the new challenges posed by time series tasks.},
  archive      = {J_TMLR},
  author       = {Jean-Christophe Gagnon-Audet and Kartik Ahuja and Mohammad Javad Darvishi Bayazi and Pooneh Mousavi and Guillaume Dumas and Irina Rish},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {WOODS: Benchmarks for out-of-distribution generalization in time series},
  url          = {https://openreview.net/forum?id=mvftzofTYQ},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Representations and computations in transformers that
support generalization on structured tasks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=oFC2LAqS6Z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformers have shown remarkable success in natural language processing and computer vision, serving as the foundation of large language and multimodal models. These networks can capture nuanced context sensitivity across high-dimensional language tokens or image pixels, but it remains unclear how highly structured behavior and systematic generalization can arise in these systems. Here, we explore the solution process a causal transformer discovers as it learns to solve a set of algorithmic tasks involving copying, sorting, and hierarchical compositions of these operations. We search for the minimal layer and head configuration sufficient to solve these tasks and unpack the roles of the attention heads, as well as how token representations are reweighted across layers to complement these roles. Our results provide new insights into how attention layers in transformers support structured computation within and across tasks: 1) Replacing fixed position labels with labels sampled from a larger set enables strong length generalization and faster learning. The learnable embeddings of these labels develop different representations, capturing sequence order if necessary, depending on task demand. 2) Two-layer transformers can learn reliable solutions to the multi-level problems we explore. The first layer tends to transform the input representation to allow the second layer to share computation across repeated components within a task or across related tasks. 3) We introduce an analysis pipeline that quantifies how the representation space in a given layer prioritizes different aspects of each item. We show that these representations prioritize information needed to guide attention relative to information that only requires downstream readout.},
  archive      = {J_TMLR},
  author       = {Yuxuan Li and James McClelland},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Representations and computations in transformers that support generalization on structured tasks},
  url          = {https://openreview.net/forum?id=oFC2LAqS6Z},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient inference with model cascades. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=obB415rg8q">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-of-the-art deep learning models are becoming ever larger. However, many practical applications are constrained by the cost of inference. Cascades of pretrained models with conditional execution address these requirements based on the intuition that some inputs are easy enough that they can be processed correctly by a smaller model allowing for an early exit. If the smaller model is not sufficiently confident in its prediction, the input is passed on to a larger model. The selection of the confidence threshold allows to trade off computational cost against accuracy. In this work we explore the effective design of model cascades, thoroughly evaluate the impact on the accuracy-efficiency trade-off, and provide a reproducible state-of-the-art baseline that is currently missing for related research. We demonstrate that model cascades dominate the ImageNet Pareto front already with 2-model cascades, achieving an average reduction in compute effort at equal accuracy of almost 3.1x above 86% and more than 1.9x between 80% and 86% top-1 accuracy, while 3-model cascades achieve 4.4x above 87% accuracy. We confirm wider applicability and effectiveness of the method on the GLUE benchmark. We release the code to reproduce our experiments in the supplementary material and use only publicly available pretrained models and datasets.},
  archive      = {J_TMLR},
  author       = {Luzian Lebovitz and Lukas Cavigelli and Michele Magno and Lorenz K Muller},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Efficient inference with model cascades},
  url          = {https://openreview.net/forum?id=obB415rg8q},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RIFLE: Imputation and robust inference from low order
marginals. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=oud7Ny0KQy">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ubiquity of missing values in real-world datasets poses a challenge for statistical inference and can prevent similar datasets from being analyzed in the same study, precluding many existing datasets from being used for new analyses. While an extensive collection of packages and algorithms have been developed for data imputation, the overwhelming majority perform poorly if there are many missing values and low sample sizes, which are unfortunately common characteristics in empirical data. Such low-accuracy estimations adversely affect the performance of downstream statistical models. We develop a statistical inference framework for predicting the target variable in the presence of missing data without imputation. Our framework, RIFLE (Robust InFerence via Low-order moment Estimations), estimates low-order moments of the underlying data distribution with corresponding confidence intervals to learn a distributionally robust model. We specialize our framework to linear regression and normal discriminant analysis, and we provide convergence and performance guarantees. This framework can also be adapted to impute missing data. We compare RIFLE with state-of-the-art approaches (including MICE, Amelia, MissForest, KNN-imputer, MIDA, and Mean Imputer) in numerical experiments. Our experiments demonstrate that RIFLE outperforms other benchmark algorithms when the percentage of missing values is high and/or when the number of data points is relatively small. RIFLE is publicly available},
  archive      = {J_TMLR},
  author       = {Sina Baharlouei and Sze-Chuan Suen and Meisam Razaviyayn},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {RIFLE: Imputation and robust inference from low order marginals},
  url          = {https://openreview.net/forum?id=oud7Ny0KQy},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RIGNN: A rationale perspective for semi-supervised
open-world graph classification. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=qcCE4mC2jI">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph classification has gained growing attention in the graph machine learning community and a variety of semi-supervised methods have been developed to reduce the high cost of annotation. They usually combine graph neural networks (GNNs) and extensive semi-supervised techniques such as knowledge distillation. However, they adhere to the close-set assumption that unlabeled graphs all belong to known classes, limiting their applications in the real world. This paper goes further, investigating a practical problem of semi-supervised open-world graph classification where these unlabeled graph data could come from unseen classes. A novel approach named Rationale-Informed GNN (RIGNN) is proposed, which takes a rationale view to detect components containing the most information related to the label space and classify unlabeled graphs into a known class or an unseen class. In particular, RIGNN contains a relational detector and a feature extractor to produce effective rationale features, which maximize the mutual information with label information and exhibit sufficient disentanglement with non-rationale elements. Furthermore, we construct a graph-of-graph based on geometrical relationships, which gives instructions on enhancing rationale representations. In virtue of effective rationale representations, we can provide accurate and balanced predictions for unlabeled graphs. An extension is also made to accomplish effective open-set graph classification. We verify our proposed methods on four benchmark datasets in various settings and experimental results reveal the effectiveness of our proposed RIGNN compared with state-of-the-art methods.},
  archive      = {J_TMLR},
  author       = {Xiao Luo and Yusheng Zhao and Zhengyang Mao and Yifang Qin and Wei Ju and Ming Zhang and Yizhou Sun},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {RIGNN: A rationale perspective for semi-supervised open-world graph classification},
  url          = {https://openreview.net/forum?id=qcCE4mC2jI},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on transformers in reinforcement learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=r30yuDPvf2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer has been considered the dominating neural architecture in NLP and CV, mostly under supervised settings. Recently, a similar surge of using Transformers has appeared in the domain of reinforcement learning (RL), but it is faced with unique design choices and challenges brought by the nature of RL. However, the evolution of Transformers in RL has not yet been well unraveled. In this paper, we seek to systematically review motivations and progress on using Transformers in RL, provide a taxonomy on existing works, discuss each sub-field, and summarize future prospects.},
  archive      = {J_TMLR},
  author       = {Wenzhe Li and Hao Luo and Zichuan Lin and Chongjie Zhang and Zongqing Lu and Deheng Ye},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A survey on transformers in reinforcement learning},
  url          = {https://openreview.net/forum?id=r30yuDPvf2},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural causal structure discovery from interventions.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=rdHVPPVuXa">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent promising results have generated a surge of interest in continuous optimization methods for causal discovery from observational data. However, there are theoretical limitations on the identifiability of underlying structures obtained solely from observational data. Interventional data, on the other hand, provides richer information about the underlying data-generating process. Nevertheless, extending and applying methods designed for observational data to include interventions is a challenging problem. To address this issue, we propose a general framework based on neural networks to develop models that incorporate both observational and interventional data. Notably, our method can handle the challenging and realistic scenario where the identity of the intervened upon variable is unknown. We evaluate our proposed approach in the context of graph recovery, both de novo and from a partially-known edge set. Our method achieves strong benchmark results on various structure learning tasks, including structure recovery of synthetic graphs as well as standard graphs from the Bayesian Network Repository.},
  archive      = {J_TMLR},
  author       = {Nan Rosemary Ke and Olexa Bilaniuk and Anirudh Goyal and Stefan Bauer and Hugo Larochelle and Bernhard Schölkopf and Michael Curtis Mozer and Christopher Pal and Yoshua Bengio},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Neural causal structure discovery from interventions},
  url          = {https://openreview.net/forum?id=rdHVPPVuXa},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast kernel methods for generic lipschitz losses via <span
class="math inline"><em>p</em></span>-sparsified sketches.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ry2qgRqTOw">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel methods are learning algorithms that enjoy solid theoretical foundations while suffering from important computational limitations. Sketching, which consists in looking for solutions among a subspace of reduced dimension, is a well-studied approach to alleviate these computational burdens. However, statistically-accurate sketches, such as the Gaussian one, usually contain few null entries, such that their application to kernel methods and their non-sparse Gram matrices remains slow in practice. In this paper, we show that sparsified Gaussian (and Rademacher) sketches still produce theoretically-valid approximations while allowing for important time and space savings thanks to an efficient \emph{decomposition trick}. To support our method, we derive excess risk bounds for both single and multiple output kernel problems, with generic Lipschitz losses, hereby providing new guarantees for a wide range of applications, from robust regression to multiple quantile regression. Our theoretical results are complemented with experiments showing the empirical superiority of our approach over state-of-the-art sketching methods.},
  archive      = {J_TMLR},
  author       = {Tamim El Ahmad and Pierre Laforgue and Florence d&#39;Alché-Buc},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Fast kernel methods for generic lipschitz losses via $p$-sparsified sketches},
  url          = {https://openreview.net/forum?id=ry2qgRqTOw},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Causal parrots: Large language models may talk causality but
are not causal. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=tv46tCzs83">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some argue scale is all what is needed to achieve AI, covering even causal models. We make it clear that large language models (LLMs) cannot be causal and give reason onto why sometimes we might feel otherwise. To this end, we define and exemplify a new subgroup of Structural Causal Model (SCM) that we call meta SCM which encode causal facts about other SCM within their variables. We conjecture that in the cases where LLM succeed in doing causal inference, underlying was a respective meta SCM that exposed correlations between causal facts in natural language on whose data the LLM was ultimately trained. If our hypothesis holds true, then this would imply that LLMs are like parrots in that they simply recite the causal knowledge embedded in the data. Our empirical analysis provides favoring evidence that current LLMs are even weak `causal parrots.&#39;},
  archive      = {J_TMLR},
  author       = {Matej Zečević and Moritz Willig and Devendra Singh Dhami and Kristian Kersting},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Causal parrots: Large language models may talk causality but are not causal},
  url          = {https://openreview.net/forum?id=tv46tCzs83},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weight-balancing fixes and flows for deep learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=uaHyXxyp2r">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feedforward neural networks with homogeneous activation functions possess an internal symmetry: the functions they compute do not change when the incoming and outgoing weights at any hidden unit are rescaled by reciprocal positive values. This paper makes two contributions to our understanding of these networks. The first is to describe a simple procedure, or {\it fix}, for balancing the weights in these networks: this procedure computes multiplicative rescaling factors---one at each hidden unit---that rebalance the weights of these networks without changing the end-to-end functions that they compute. Specifically, given an initial network with arbitrary weights, the procedure determines the functionally equivalent network whose weight matrix is of minimal $\ell_{p,q}$-norm; the weights at each hidden unit are said to be balanced when this norm is stationary with respect to rescaling transformations. The optimal rescaling factors are computed in an iterative fashion via simple multiplicative updates, and the updates are notable in that (a) they do not require the tuning of learning rates, (b) they operate in parallel on the rescaling factors at all hidden units, and (c) they converge monotonically to a global minimizer of the $\ell_{p,q}$-norm. The paper&#39;s second contribution is to analyze the optimization landscape for learning in these networks. We suppose that the network&#39;s loss function consists of two terms---one that is invariant to rescaling transformations, measuring predictive accuracy, and another (a regularizer) that breaks this invariance, penalizing large weights. We show how to derive a weight-balancing {\it flow} such that the regularizer remains minimal with respect to rescaling transformations as the weights descend in the loss function. These dynamics reduce to an ordinary gradient flow for $\ell_2$-norm regularization, but not otherwise. In this way our analysis suggests a canonical pairing of alternative flows and regularizers.},
  archive      = {J_TMLR},
  author       = {Lawrence K. Saul},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Weight-balancing fixes and flows for deep learning},
  url          = {https://openreview.net/forum?id=uaHyXxyp2r},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stochastic batch acquisition: A simple baseline for deep
active learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=vcHwQyNBjW">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine a simple stochastic strategy for adapting well-known single-point acquisition functions to allow batch active learning. Unlike acquiring the top-K points from the pool set, score- or rank-based sampling takes into account that acquisition scores change as new data are acquired. This simple strategy for adapting standard single-sample acquisition strategies can even perform just as well as compute-intensive state-of-the-art batch acquisition functions, like BatchBALD or BADGE while using orders of magnitude less compute. In addition to providing a practical option for machine learning practitioners, the surprising success of the proposed method in a wide range of experimental settings raises a difficult question for the field: when are these expensive batch acquisition methods pulling their weight?},
  archive      = {J_TMLR},
  author       = {Andreas Kirsch and Sebastian Farquhar and Parmida Atighehchian and Andrew Jesson and Frédéric Branchaud-Charron and Yarin Gal},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Stochastic batch acquisition: A simple baseline for deep active learning},
  url          = {https://openreview.net/forum?id=vcHwQyNBjW},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Walking out of the weisfeiler leman hierarchy: Graph
learning beyond message passing. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=vgXnEyeWVY">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose CRaWl, a novel neural network architecture for graph learning. Like graph neural networks, CRaWl layers update node features on a graph and thus can freely be combined or interleaved with GNN layers. Yet CRaWl operates fundamentally different from message passing graph neural networks. CRaWl layers extract and aggregate information on subgraphs appearing along random walks through a graph using 1D Convolutions. Thereby it detects long range interactions and computes non-local features. As the theoretical basis for our approach, we prove a theorem stating that the expressiveness of CRaWl is incomparable with that of the Weisfeiler Leman algorithm and hence with graph neural networks. That is, there are functions expressible by CRaWl, but not by GNNs and vice versa. This result extends to higher levels of the Weisfeiler Leman hierarchy and thus to higher-order GNNs. Empirically, we show that CRaWl matches state-of-the-art GNN architectures across a multitude of benchmark datasets for classification and regression on graphs.},
  archive      = {J_TMLR},
  author       = {Jan Tönshoff and Martin Ritzert and Hinrikus Wolf and Martin Grohe},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Walking out of the weisfeiler leman hierarchy: Graph learning beyond message passing},
  url          = {https://openreview.net/forum?id=vgXnEyeWVY},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fair and useful cohort selection. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=wRepWp1KC7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A challenge in fair algorithm design is that, while there are compelling notions of individual fairness, these notions typically do not satisfy desirable composition properties, and downstream applications based on fair classifiers might not preserve fairness. To study fairness under composition, Dwork &amp; Ilvento (2019) introduced an archetypal problem called fair-cohort-selection problem, where a single fair classifier is composed with itself to select a group of candidates of a given size, and proposed a solution to this problem. In this work we design algorithms for selecting cohorts that not only preserve fairness, but also maximize the utility of the selected cohort under two notions of utility that we introduce and motivate. We give optimal (or approximately optimal) polynomial-time algorithms for this problem in both an offline setting, and an online setting where candidates arrive one at a time and are classified as they arrive.},
  archive      = {J_TMLR},
  author       = {Konstantina Bairaktari and Paul Tsela Langton and Huy Nguyen and Niklas Smedemark-Margulies and Jonathan Ullman},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Fair and useful cohort selection},
  url          = {https://openreview.net/forum?id=wRepWp1KC7},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TSMixer: An all-MLP architecture for time series
forecast-ing. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=wbpxTuXgm0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world time-series datasets are often multivariate with complex dynamics. To capture this complexity, high capacity architectures like recurrent- or attention-based sequential deep learning models have become popular. However, recent work demonstrates that simple univariate linear models can outperform such deep learning models on several commonly used academic benchmarks. Extending them, in this paper, we investigate the capabilities of linear models for time-series forecasting and present Time-Series Mixer (TSMixer), a novel architecture designed by stacking multi-layer perceptrons (MLPs). TSMixer is based on mixing operations along both the time and feature dimensions to extract information efficiently. On popular academic benchmarks, the simple-to-implement TSMixer is comparable to specialized state-of-the-art models that leverage the inductive biases of specific benchmarks. On the challenging and large scale M5 benchmark, a real-world retail dataset, TSMixer demonstrates superior performance compared to the state-of-the-art alternatives. Our results underline the importance of efficiently utilizing cross-variate and auxiliary information for improving the performance of time series forecasting. We present various analyses to shed light into the capabilities of TSMixer. The design paradigms utilized in TSMixer are expected to open new horizons for deep learning-based time series forecasting.},
  archive      = {J_TMLR},
  author       = {Si-An Chen and Chun-Liang Li and Sercan O Arik and Nathanael Christian Yoder and Tomas Pfister},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {TSMixer: An all-MLP architecture for time series forecast-ing},
  url          = {https://openreview.net/forum?id=wbpxTuXgm0},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global contrastive learning for long-tailed classification.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=xWrtiJwJj5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the long-tailed classification problem in which a few classes in the training data dominate the majority of the other classes. For concreteness, we focus on the visual domain in this paper. Most current methods employ contrastive learning to learn a representation for long-tailed data. In this paper, first, we investigate $k$-positive sampling, a popular baseline method widely used to build contrastive learning models for imbalanced data. Previous works show that $k$-positive learning, which only chooses $k$ positive samples (instead of all positive images) for each query image, suffers from inferior performance in long-tailed data. In this work, we further point out that k-positive learning limits the learning capability of both head and tail classes. Based on this perspective, we propose a novel contrastive learning framework that improves the limitation in k-positive learning by enlarging its positive selection space, so it can help the model learn more semantic discrimination features. Second, we analyze how the temperature (the hyperparameter used for tuning a concentration of samples on feature space) affects the gradients of each class in long-tailed learning, and propose a new method that can mitigate inadequate gradients between classes, which can help model learning easier. We name this framework as CoGloAT. Finally, we go on to introduce a new prototype learning framework namely ProCo based on coreset selection, which creates a global prototype for each cluster while keeping the computation cost within a reasonable time and show that combining CoGloAT with ProCo can further enhance the model learning ability on long-tailed data.},
  archive      = {J_TMLR},
  author       = {Thong Bach and Anh Tong and Truong Son Hy and Vu Nguyen and Thanh Nguyen-Tang},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Global contrastive learning for long-tailed classification},
  url          = {https://openreview.net/forum?id=xWrtiJwJj5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Linearized relative positional encoding. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=xoLyps2qWc">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relative positional encoding is widely used in vanilla and linear transformers to represent positional information. However, existing encoding methods of a vanilla transformer are not always directly applicable to a linear transformer, because the latter requires a decomposition of the query and key representations into separate kernel functions. Nevertheless, principles for designing encoding methods suitable for linear transformers remain understudied. In this work, we put together a variety of existing linear relative positional encoding approaches under a canonical form and further propose a family of linear relative positional encoding algorithms via unitary transformation. Our formulation leads to a principled framework that can be used to develop new relative positional encoding methods that preserve linear space-time complexity. Equipped with different models, the proposed linearized relative positional encoding (LRPE) family derives effective encoding for various applications. Experiments show that compared with existing methods, LRPE achieves state-of-the-art performance in language modeling, text classification, and image classification. Meanwhile, it emphasizes a general paradigm for designing broadly more relative positional encoding methods that are applicable to linear transformers.},
  archive      = {J_TMLR},
  author       = {Zhen Qin and Weixuan Sun and Kaiyue Lu and Hui Deng and Dongxu Li and Xiaodong Han and Yuchao Dai and Lingpeng Kong and Yiran Zhong},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Linearized relative positional encoding},
  url          = {https://openreview.net/forum?id=xoLyps2qWc},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Offline reinforcement learning with mixture of deterministic
policies. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=zkRCp4RmAF">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline reinforcement learning (RL) has recently attracted considerable attention as an approach for utilizing past experiences to learn a policy. Recent studies have reported the challenges of offline RL, such as estimating the values of actions that are outside the data distribution. To mitigate offline RL issues, we propose an algorithm that leverages a mixture of deterministic policies. When the data distribution is multimodal, fitting a policy modeled with a unimodal distribution, such as Gaussian distribution, may lead to interpolation between separate modes, thereby resulting in the value estimation of actions that are outside the data distribution. In our framework, the state-action space is divided by learning discrete latent variables, and the sub-policies corresponding to each region are trained. The proposed algorithm was derived by considering the variational lower bound of the offline RL objective function. We show empirically that the use of the proposed mixture policy can reduce the accumulation of the critic loss in offline RL, which was reported in previous studies. Experimental results also indicate that using a mixture of deterministic policies in offline RL improves the performance with the D4RL benchmarking datasets.},
  archive      = {J_TMLR},
  author       = {Takayuki Osa and Akinobu Hayashi and Pranav Deo and Naoki Morihira and Takahide Yoshiike},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Offline reinforcement learning with mixture of deterministic policies},
  url          = {https://openreview.net/forum?id=zkRCp4RmAF},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep operator learning lessens the curse of dimensionality
for PDEs. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=zmBFzuT2DN">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have achieved remarkable success in numerous domains, and their application to PDE-related problems has been rapidly advancing. This paper provides an estimate for the generalization error of learning Lipschitz operators over Banach spaces using DNNs with applications to various PDE solution operators. The goal is to specify DNN width, depth, and the number of training samples needed to guarantee a certain testing error. Under mild assumptions on data distributions or operator structures, our analysis shows that deep operator learning can have a relaxed dependence on the discretization resolution of PDEs and, hence, lessen the curse of dimensionality in many PDE-related problems including elliptic equations, parabolic equations, and Burgers equations. Our results are also applied to give insights about discretization-invariant in operator learning.},
  archive      = {J_TMLR},
  author       = {Ke Chen and Chunmei Wang and Haizhao Yang},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Deep operator learning lessens the curse of dimensionality for PDEs},
  url          = {https://openreview.net/forum?id=zmBFzuT2DN},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FairGrad: Fairness aware gradient descent. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=0f8tU3QwWD">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of group fairness in classification, where the objective is to learn models that do not unjustly discriminate against subgroups of the population. Most existing approaches are limited to simple binary tasks or involve difficult to implement training mechanisms which reduces their practical applicability. In this paper, we propose FairGrad, a method to enforce fairness based on a re-weighting scheme that iteratively learns group specific weights based on whether they are advantaged or not. FairGrad is easy to implement, accommodates various standard fairness definitions, and comes with minimal overhead. Furthermore, we show that it is competitive with standard baselines over various datasets including ones used in natural language processing and computer vision. FairGrad is available as a PyPI package at - https://pypi.org/project/fairgrad},
  archive      = {J_TMLR},
  author       = {Gaurav Maheshwari and Michaël Perrot},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FairGrad: Fairness aware gradient descent},
  url          = {https://openreview.net/forum?id=0f8tU3QwWD},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Meta-learning via classifier(-free) diffusion guidance.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=1irVjE7A3w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce meta-learning algorithms that perform zero-shot weight-space adaptation of neural network models to unseen tasks. Our methods repurpose the popular generative image synthesis techniques of natural language guidance and diffusion models to generate neural network weights adapted for tasks. We first train an unconditional generative hypernetwork model to produce neural network weights; then we train a second &quot;guidance&quot; model that, given a natural language task description, traverses the hypernetwork latent space to find high-performance task-adapted weights in a zero-shot manner. We explore two alternative approaches for latent space guidance: &quot;HyperCLIP&quot;-based classifier guidance and a conditional Hypernetwork Latent Diffusion Model (&quot;HyperLDM&quot;), which we show to benefit from the classifier-free guidance technique common in image generation. Finally, we demonstrate that our approaches outperform existing multi-task and meta-learning methods in a series of zero-shot learning experiments on our Meta-VQA dataset.},
  archive      = {J_TMLR},
  author       = {Elvis Nava and Seijin Kobayashi and Yifei Yin and Robert K. Katzschmann and Benjamin F Grewe},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Meta-learning via classifier(-free) diffusion guidance},
  url          = {https://openreview.net/forum?id=1irVjE7A3w},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transport score climbing: Variational inference using
forward KL and adaptive neural transport. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=7KW7zvKd7J">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational inference often minimizes the ``reverse&#39;&#39; Kullbeck-Leibler (KL) $D_{KL}(q||p)$ from the approximate distribution $q$ to the posterior $p$. Recent work studies the ``forward&#39;&#39; KL $D_{KL}(p||q)$, which unlike reverse KL does not lead to variational approximations that underestimate uncertainty. Markov chain Monte Carlo (MCMC) methods were used to evaluate the expectation in computing the forward KL. This paper introduces Transport Score Climbing (TSC), a method that optimizes $D_{KL}(p||q)$ by using Hamiltonian Monte Carlo (HMC) but running the HMC chain on a transformed, or warped, space. A function called the transport map performs the transformation by acting as a change-of-variable from the latent variable space. TSC uses HMC samples to dynamically train the transport map while optimizing $D_{KL}(p||q)$. TSC leverages synergies, where better transport maps lead to better HMC sampling, which then leads to better transport maps. We demonstrate TSC on synthetic and real data, including using TSC to train variational auto-encoders. We find that TSC achieves competitive performance on the experiments.},
  archive      = {J_TMLR},
  author       = {Liyi Zhang and David Blei and Christian A Naesseth},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Transport score climbing: Variational inference using forward KL and adaptive neural transport},
  url          = {https://openreview.net/forum?id=7KW7zvKd7J},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Logistic-normal likelihoods for heteroscedastic label noise.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=7wA65zL3B3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A natural way of estimating heteroscedastic label noise in regression is to model the observed (potentially noisy) target as a sample from a normal distribution, whose parameters can be learned by minimizing the negative log-likelihood. This formulation has desirable loss attenuation properties, as it reduces the contribution of high-error examples. Intuitively, this behavior can improve robustness against label noise by reducing overfitting. We propose an extension of this simple and probabilistic approach to classification that has the same desirable loss attenuation properties. Furthermore, we discuss and address some practical challenges of this extension. We evaluate the effectiveness of the method by measuring its robustness against label noise in classification. We perform enlightening experiments exploring the inner workings of the method, including sensitivity to hyperparameters, ablation studies, and other insightful analyses.},
  archive      = {J_TMLR},
  author       = {Erik Englesson and Amir Mehrpanah and Hossein Azizpour},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Logistic-normal likelihoods for heteroscedastic label noise},
  url          = {https://openreview.net/forum?id=7wA65zL3B3},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The ConceptARC benchmark: Evaluating understanding and
generalization in the ARC domain. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=8ykyGbtt2q">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The abilities to form and abstract concepts is key to human intelligence, but such abilities remain lacking in state-of-the-art AI systems. There has been substantial research on conceptual abstraction in AI, particularly using idealized domains such as Raven’s Progressive Matrices and Bongard problems, but even when AI systems succeed on such problems, the systems are rarely evaluated in depth to see if they have actually grasped the concepts they are meant to capture. In this paper we describe an in-depth evaluation benchmark for the Abstraction and Reasoning Corpus (ARC), a collection of few-shot abstraction and analogy problems developed by Chollet (2019). In particular, we describe ConceptARC, a new, publicly available bench- mark in the ARC domain that systematically assesses abstraction and generalization abilities on a number of basic spatial and semantic concepts. ConceptARC differs from the original ARC dataset in that it is specifically organized around “concept groups”—sets of problems that focus on specific concepts and that are vary in complexity and level of abstraction. We report results on testing humans on this benchmark as well as three machine solvers: the top two programs from a 2021 ARC competition and OpenAI’s GPT-4. Our results show that humans substantially outperform the machine solvers on this benchmark, showing abilities to abstract and generalize concepts that are not yet captured by AI systems. We believe that this benchmark will spur improvements in the development of AI systems for conceptual abstraction and in the effective evaluation of such systems.},
  archive      = {J_TMLR},
  author       = {Arsenii Kirillovich Moskvichev and Victor Vikram Odouard and Melanie Mitchell},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The ConceptARC benchmark: Evaluating understanding and generalization in the ARC domain},
  url          = {https://openreview.net/forum?id=8ykyGbtt2q},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ML-BFGS: A momentum-based l-BFGS for distributed large-scale
neural network optimization. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=9jnsPp8DP3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quasi-Newton methods still face significant challenges in training large-scale neural networks due to additional compute costs in the Hessian related computations and instability issues in stochastic training. A well-known method, L-BFGS that efficiently approximates the Hessian using history parameter and gradient changes, suffers convergence instability in stochastic training. So far, attempts that adapt L-BFGS to large-scale stochastic training incur considerable extra overhead, which offsets its convergence benefits in wall-clock time. In this paper, we propose mL-BFGS, a lightweight momentum-based L-BFGS algorithm that paves the way for quasi-Newton (QN) methods in large-scale distributed deep neural network (DNN) optimization. mL-BFGS introduces a nearly cost-free momentum scheme into L-BFGS update and greatly reduces stochastic noise in the Hessian, therefore stabilizing convergence during stochastic optimization. For model training at a large scale, mL-BFGS approximates a block-wise Hessian, thus enabling distributing compute and memory costs across all computing nodes. We provide a supporting convergence analysis for mL-BFGS in stochastic settings. To investigate mL-BFGS&#39;s potential in large-scale DNN training, we train benchmark neural models using mL-BFGS and compare performance with baselines (SGD, Adam, and other quasi-Newton methods). Results show that mL-BFGS achieves both noticeable iteration-wise and wall-clock speedup.},
  archive      = {J_TMLR},
  author       = {Yue Niu and Zalan Fabian and Sunwoo Lee and Mahdi Soltanolkotabi and Salman Avestimehr},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ML-BFGS: A momentum-based L-BFGS for distributed large-scale neural network optimization},
  url          = {https://openreview.net/forum?id=9jnsPp8DP3},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cyclophobic reinforcement learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=83rgSFPpws">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In environments with sparse rewards, finding a good inductive bias for exploration is crucial to the agent&#39;s success. However, there are two competing goals: novelty search and systematic exploration. While existing approaches such as curiosity-driven exploration find novelty, they sometimes do not systematically explore the whole state space, akin to depth-first-search vs breadth-first-search. In this paper, we propose a new intrinsic reward that is cyclophobic, i.e., it does not reward novelty, but punishes redundancy by avoiding cycles. Augmenting the cyclophobic intrinsic reward with a sequence of hierarchical representations based on the agent&#39;s cropped observations we are able to achieve excellent results in the MiniGrid and MiniHack environments. Both are particularly hard, as they require complex interactions with different objects in order to be solved. Detailed comparisons with previous approaches and thorough ablation studies show that our newly proposed cyclophobic reinforcement learning is more sample efficient than other state of the art methods in a variety of tasks.},
  archive      = {J_TMLR},
  author       = {Stefan Sylvius Wagner and Peter Arndt and Jan Robine and Stefan Harmeling},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Cyclophobic reinforcement learning},
  url          = {https://openreview.net/forum?id=83rgSFPpws},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic approach to universal random features in graph
neural networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=AXUtAIX0Fn">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Universal random features (URF) are state of the art regarding practical graph neural networks that are provably universal. There is great diversity regarding terminology, methodology, benchmarks, and evaluation metrics used among existing URF. Not only does this make it increasingly difficult for practitioners to decide which technique to apply to a given problem, but it also stands in the way of systematic improvements. We propose a new comprehensive framework that captures all previous URF techniques. On the theoretical side, among other results, we formally prove that under natural conditions all instantiations of our framework are universal. The framework thus provides a new simple technique to prove universality results. On the practical side, we develop a method to systematically and automatically train URF. This in turn enables us to impartially and objectively compare all existing URF. New URF naturally emerge from our approach, and our experiments demonstrate that they improve the state of the art.},
  archive      = {J_TMLR},
  author       = {Billy Joe Franks and Markus Anders and Marius Kloft and Pascal Schweitzer},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A systematic approach to universal random features in graph neural networks},
  url          = {https://openreview.net/forum?id=AXUtAIX0Fn},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributionally robust classification on a data budget.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=D5Z2E8CNsD">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real world uses of deep learning require predictable model behavior under distribution shifts. Models such as CLIP show emergent natural distributional robustness comparable to humans, but may require hundreds of millions of training samples. Can we train robust learners in a domain where data is limited? To rigorously address this question, we introduce JANuS (Joint Annotations and Names Set), a collection of four new training datasets with images, labels, and corresponding captions, and perform a series of carefully controlled investigations of factors contributing to robustness in image classification, then compare those results to findings derived from a large-scale meta-analysis. Using this approach, we show that standard ResNet-50 trained with the cross-entropy loss on 2.4 million image samples can attain comparable robustness to a CLIP ResNet-50 trained on 400 million samples. To our knowledge, this is the first result showing (near) state-of-the-art distributional robustness on limited data budgets.},
  archive      = {J_TMLR},
  author       = {Benjamin Feuer and Ameya Joshi and Minh Pham and Chinmay Hegde},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Distributionally robust classification on a data budget},
  url          = {https://openreview.net/forum?id=D5Z2E8CNsD},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nonconvex-nonconcave min-max optimization on riemannian
manifolds. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=EDVIHPZhFo">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work studies nonconvex-nonconcave min-max problems on Riemannian manifolds. We first characterize the local optimality of nonconvex-nonconcave problems on manifolds with a generalized notion of local minimax points. We then define the stability and convergence criteria of dynamical systems on manifolds and provide necessary and sufficient conditions of strictly stable equilibrium points for both continuous and discrete dynamics. Additionally, we propose several novel second-order methods on manifolds that provably converge to local minimax points asymptotically. We validate the empirical benefits of the proposed methods with extensive experiments.},
  archive      = {J_TMLR},
  author       = {Andi Han and Bamdev Mishra and Pratik Jawanpuria and Junbin Gao},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Nonconvex-nonconcave min-max optimization on riemannian manifolds},
  url          = {https://openreview.net/forum?id=EDVIHPZhFo},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Chasing better deep image priors between over- and
under-parameterization. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=EwJJks2cSa">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) are well-known to act as \textbf{over-parameterized} deep image priors (DIP) that regularize various image inverse problems. Meanwhile, researchers also proposed extremely compact, \textbf{under-parameterized} image priors (e.g., deep decoder) that are strikingly competent for image restoration too, despite a loss of accuracy. These two extremes push us to think whether there exists a better solution in the middle: \textit{between over- and under-parameterized image priors, can one identify ``intermediate&quot; parameterized image priors that achieve better trade-offs between performance, efficiency, and even preserving strong transferability?} Drawing inspirations from the lottery ticket hypothesis (LTH), we conjecture and study a novel ``lottery image prior&quot; (\textbf{LIP}) by exploiting DNN inherent sparsity, stated as: \textit{given an over-parameterized DNN-based image prior, it will contain a sparse subnetwork that can be trained in isolation, to match the original DNN&#39;s performance when being applied as a prior to various image inverse problems}. Our results validate the superiority of LIPs: we can successfully locate the LIP subnetworks from over-parameterized DIPs at substantial sparsity ranges. Those LIP subnetworks significantly outperform deep decoders under comparably compact model sizes (by often fully preserving the effectiveness of their over-parameterized counterparts), and they also possess high transferability across different images as well as restoration task types. Besides, we also extend LIP to compressive sensing image reconstruction, where a \textit{pre-trained} GAN generator is used as the prior (in contrast to \textit{untrained} DIP or deep decoder), and confirm its validity in this setting too. To our best knowledge, this is the first time that LTH is demonstrated to be relevant in the context of inverse problems or image priors. Codes are available at https://github.com/VITA-Group/Chasing-Better-DIPs.},
  archive      = {J_TMLR},
  author       = {Qiming Wu and Xiaohan Chen and Yifan Jiang and Zhangyang Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Chasing better deep image priors between over- and under-parameterization},
  url          = {https://openreview.net/forum?id=EwJJks2cSa},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MaMMUT: A simple architecture for joint learning for
MultiModal tasks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=FqOG4osY7C">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of language models have moved from encoder-decoder to decoder-only designs. In addition, we observe that the two most popular multimodal tasks, the generative and contrastive tasks, are nontrivial to accommodate in one architecture, and further need adaptations for downstream tasks. We propose a novel paradigm of training with a decoder-only model for multimodal tasks, which is surprisingly effective in jointly learning of these disparate vision-language tasks. This is done with a simple model, called MaMMUT. It consists of a single vision encoder and a text decoder, and is able to accommodate contrastive and generative learning by a novel two-pass approach on the text decoder. We demonstrate that joint learning of these diverse objectives is simple, effective, and maximizes the weight-sharing of the model across these tasks. Furthermore, the same architecture enables straightforward extensions to open-vocabulary object detection and video-language tasks. The model tackles a diverse range of tasks, while being modest in capacity. Our model achieves the state of the art on image-text and text-image retrieval, video question answering and open-vocabulary detection tasks, outperforming much larger and more extensively trained foundational models. It shows very competitive results on VQA and Video Captioning, especially considering its capacity. Ablations confirm the flexibility and advantages of our approach.},
  archive      = {J_TMLR},
  author       = {Weicheng Kuo and AJ Piergiovanni and Dahun Kim and xiyang luo and Benjamin Caine and Wei Li and Abhijit Ogale and Luowei Zhou and Andrew M. Dai and Zhifeng Chen and Claire Cui and Anelia Angelova},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {MaMMUT: A simple architecture for joint learning for MultiModal tasks},
  url          = {https://openreview.net/forum?id=FqOG4osY7C},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Expected worst case regret via stochastic sequential
covering. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=H1SekypXKA">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of sequential prediction and online minimax regret with stochastically generated features under a general loss function. In an online learning setting, Nature selects features and associates a true label with these features. A learner uses features to predict a label, which is compared to the true label, and a loss is incurred. The total loss over $T$ rounds, when compared to a loss incurred by a set of experts, is known as a regret. We introduce the notion of *expected worst case minimax regret* that generalizes and encompasses prior known minimax regrets. For such minimax regrets, we establish tight upper bounds via a novel concept of *stochastic global sequential covering*. We show that for a hypothesis class of VC-dimension $\mathsf{VC}$ and $i.i.d.$ generated features over $T$ rounds, the cardinality of stochastic global sequential covering can be upper bounded with high probability (w.h.p.) by $e^{O(\mathsf{VC} \cdot \log^2 T)}$. We then improve this bound by introducing a new complexity measure called the *Star-Littlestone* dimension, and show that classes with Star-Littlestone dimension $\mathsf{SL}$ admit a stochastic global sequential covering of order $e^{O(\mathsf{SL} \cdot \log T)}$. We further establish upper bounds for real valued classes with finite fat-shattering numbers. Finally, by applying information-theoretic tools for the fixed design minimax regrets, we provide lower bounds for expected worst case minimax regret. We demonstrate the effectiveness of our approach by establishing tight bounds on the expected worst case minimax regrets for logarithmic loss and general mixable losses.},
  archive      = {J_TMLR},
  author       = {Changlong Wu and Mohsen Heidari and Ananth Grama and Wojciech Szpankowski},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Expected worst case regret via stochastic sequential covering},
  url          = {https://openreview.net/forum?id=H1SekypXKA},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust alzheimer’s progression modeling using cross-domain
self-supervised deep learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=HVAeM6sNo8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing successful artificial intelligence systems in practice depends on both robust deep learning models and large, high-quality data. However, acquiring and labeling data can be prohibitively expensive and time-consuming in many real-world applications, such as clinical disease models. Self-supervised learning has demonstrated great potential in increasing model accuracy and robustness in small data regimes. In addition, many clinical imaging and disease modeling applications rely heavily on regression of continuous quantities. However, the applicability of self-supervised learning for these medical-imaging regression tasks has not been extensively studied. In this study, we develop a cross-domain self-supervised learning approach for disease prognostic modeling as a regression problem using medical images as input. We demonstrate that self-supervised pretraining can improve the prediction of Alzheimer&#39;s Disease progression from brain MRI. We also show that pretraining on extended (but not labeled) brain MRI data outperforms pretraining on natural images. We further observe that the highest performance is achieved when both natural images and extended brain-MRI data are used for pretraining.},
  archive      = {J_TMLR},
  author       = {Saba Dadsetan and Mohsen Hejrati and Shandong Wu and Somaye Hashemifar},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Robust alzheimer&#39;s progression modeling using cross-domain self-supervised deep learning},
  url          = {https://openreview.net/forum?id=HVAeM6sNo8},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards a defense against federated backdoor attacks under
continuous training. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=HwcB5elyuG">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Backdoor attacks are dangerous and difficult to prevent in federated learning (FL), where training data is sourced from untrusted clients over long periods of time. These difficulties arise because: (a) defenders in FL do not have access to raw training data, and (b) a phenomenon we identify called backdoor leakage causes models trained continuously to eventually suffer from backdoors due to cumulative errors in defense mechanisms. We propose a framework called shadow learning for defending against backdoor attacks in the FL setting under long-range training. Shadow learning trains two models in parallel: a backbone model and a shadow model. The backbone is trained without any defense mechanism to obtain good performance on the main task. The shadow model combines filtering of malicious clients with early-stopping to control the attack success rate even as the data distribution changes. We theoretically motivate our design and show experimentally that our framework significantly improves upon existing defenses against backdoor attacks.},
  archive      = {J_TMLR},
  author       = {Shuaiqi Wang and Jonathan Hayase and Giulia Fanti and Sewoong Oh},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards a defense against federated backdoor attacks under continuous training},
  url          = {https://openreview.net/forum?id=HwcB5elyuG},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning augmentation distributions using transformed risk
minimization. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=LRYtNj8Xw0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new \emph{Transformed Risk Minimization} (TRM) framework as an extension of classical risk minimization. In TRM, we optimize not only over predictive models, but also over data transformations; specifically over distributions thereof. As a key application, we focus on learning augmentations; for instance appropriate rotations of images, to improve classification performance with a given class of predictors. Our TRM method (1) jointly learns transformations and models in a \emph{single training loop}, (2) works with any training algorithm applicable to standard risk minimization, and (3) handles any transforms, such as discrete and continuous classes of augmentations. To avoid overfitting when implementing empirical transformed risk minimization, we propose a novel regularizer based on PAC-Bayes theory. For learning augmentations of images, we propose a new parametrization of the space of augmentations via a stochastic composition of blocks of geometric transforms. This leads to the new \emph{Stochastic Compositional Augmentation Learning} (SCALE) algorithm. The performance of TRM with SCALE compares favorably to prior methods on CIFAR10/100. Additionally, we show empirically that SCALE can correctly learn certain symmetries in the data distribution (recovering rotations on rotated MNIST) and can also improve calibration of the learned model.},
  archive      = {J_TMLR},
  author       = {Evangelos Chatzipantazis and Stefanos Pertigkiozoglou and Kostas Daniilidis and Edgar Dobriban},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning augmentation distributions using transformed risk minimization},
  url          = {https://openreview.net/forum?id=LRYtNj8Xw0},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). You only transfer what you share: Intersection-induced graph
transfer learning for link prediction. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Nn71AdKyYH">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction is central to many real-world applications, but its performance may be hampered when the graph of interest is sparse. To alleviate issues caused by sparsity, we investigate a previously overlooked phenomenon: in many cases, a densely connected, complementary graph can be found for the original graph. The denser graph may share nodes with the original graph, which offers a natural bridge for transferring selective, meaningful knowledge. We identify this setting as Graph Intersection-induced Transfer Learning (GITL), which is motivated by practical applications in e-commerce or academic co-authorship predictions. We develop a framework to effectively leverage the structural prior in this setting. We first create an intersection subgraph using the shared nodes between the two graphs, then transfer knowledge from the source-enriched intersection subgraph to the full target graph. In the second step, we consider two approaches: a modified label propagation, and a multi-layer perceptron (MLP) model in a teacher-student regime. Experimental results on proprietary e-commerce datasets and open-source citation graphs show that the proposed workflow outperforms existing transfer learning baselines that do not explicitly utilize the intersection structure.},
  archive      = {J_TMLR},
  author       = {Wenqing Zheng and Edward W Huang and Nikhil Rao and Zhangyang Wang and Karthik Subbian},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {You only transfer what you share: Intersection-induced graph transfer learning for link prediction},
  url          = {https://openreview.net/forum?id=Nn71AdKyYH},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual representation learning for out-of-distribution
detection. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=PHAr3q49h6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To classify in-distribution samples, deep neural networks explore strongly label-related information and discard weakly label-related information according to the information bottleneck. Out-of-distribution samples drawn from distributions differing from that of in-distribution samples could be assigned with unexpected high-confidence predictions because they could obtain minimum strongly label-related information. To distinguish in- and out-of-distribution samples, Dual Representation Learning (DRL) makes out-of-distribution samples harder to have high-confidence predictions by exploring both strongly and weakly label-related information from in-distribution samples. For a pretrained network exploring strongly label-related information to learn label-discriminative representations, DRL trains its auxiliary network exploring the remaining weakly label-related information to learn distribution-discriminative representations. Specifically, for a label-discriminative representation, DRL constructs its complementary distribution-discriminative representation by integrating diverse representations less similar to the label-discriminative representation. Accordingly, DRL combines label- and distribution-discriminative representations to detect out-of-distribution samples. Experiments show that DRL outperforms the state-of-the-art methods for out-of-distribution detection.},
  archive      = {J_TMLR},
  author       = {Zhilin Zhao and Longbing Cao},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Dual representation learning for out-of-distribution detection},
  url          = {https://openreview.net/forum?id=PHAr3q49h6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Regret bounds for satisficing in multi-armed bandit
problems. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=QnT41ZGNh9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the objective of \textit{satisficing} in multi-armed bandit problems. Instead of aiming to find an optimal arm, the learner is content with an arm whose reward is above a given satisfaction level. We provide algorithms and analysis for the realizable case when such a satisficing arm exists as well as for the general case when this may not be the case. Introducing the notion of \textit{satisficing regret}, our main result shows that in the general case it is possible to obtain constant satisficing regret when there is a satisficing arm (thereby correcting a contrary claim in the literature), while standard logarithmic regret bounds can be re-established otherwise. Experiments illustrate that our algorithm is not only superior to standard algorithms in the satisficing setting, but also works well in the classic bandit setting.},
  archive      = {J_TMLR},
  author       = {Thomas Michel and Hossein Hajiabolhassan and Ronald Ortner},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Regret bounds for satisficing in multi-armed bandit problems},
  url          = {https://openreview.net/forum?id=QnT41ZGNh9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Meta-calibration: Learning of model calibration using
differentiable expected calibration error. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=R2hUure38l">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Calibration of neural networks is a topical problem that is becoming more and more important as neural networks increasingly underpin real-world applications. The problem is especially noticeable when using modern neural networks, for which there is a significant difference between the confidence of the model and the probability of correct prediction. Various strategies have been proposed to improve calibration, yet accurate calibration remains challenging. We propose a novel framework with two contributions: introducing a new differentiable surrogate for expected calibration error (DECE) that allows calibration quality to be directly optimised, and a meta-learning framework that uses DECE to optimise for validation set calibration with respect to model hyper-parameters. The results show that we achieve competitive performance with existing calibration approaches. Our framework opens up a new avenue and toolset for tackling calibration, which we believe will inspire further work on this important challenge.},
  archive      = {J_TMLR},
  author       = {Ondrej Bohdal and Yongxin Yang and Timothy Hospedales},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Meta-calibration: Learning of model calibration using differentiable expected calibration error},
  url          = {https://openreview.net/forum?id=R2hUure38l},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Some remarks on identifiability of independent component
analysis in restricted function classes. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=REtKapdkyI">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this short note, we comment on recent results on identifiability of independent component analysis. We point out an error in earlier works and clarify that this error cannot be fixed as the chosen approach is not sufficiently powerful to prove identifiability results. In addition, we explain the necessary ingredients to prove stronger identifiability results. Finally, we discuss and extend the flow-based technique to construct spurious solutions for independent component analysis problems and provide a counterexample to an earlier identifiability result.},
  archive      = {J_TMLR},
  author       = {Simon Buchholz},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Some remarks on identifiability of independent component analysis in restricted function classes},
  url          = {https://openreview.net/forum?id=REtKapdkyI},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive compression for communication-efficient distributed
training. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Rb6VDOHebB">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose Adaptive Compressed Gradient Descent (AdaCGD) -- a novel optimization algorithm for communication-efficient training of supervised machine learning models with adaptive compression level. Our approach is inspired by the recently proposed three point compressor (3PC) framework of Richtarik et al. (2022) , which includes error feedback (EF21), lazily aggregated gradient (LAG), and their combination as special cases, and offers the current state-of-the-art rates for these methods under weak assumptions. While the above mechanisms offer a fixed compression level or adapt between two extreme compression levels, we propose a much finer adaptation. In particular, we allow users to choose between selected contractive compression mechanisms, such as Top-$K$ sparsification with a user-defined selection of sparsification levels $K$, or quantization with a user-defined selection of quantization levels, or their combination. AdaCGD chooses the appropriate compressor and compression level adaptively during the optimization process. Besides i) proposing a theoretically-grounded multi-adaptive communication compression mechanism, we further ii) extend the 3PC framework to bidirectional compression, i.e., allow the server to compress as well, and iii) provide sharp convergence bounds in the strongly convex, convex, and nonconvex settings. The convex regime results are new even for several key special cases of our general mechanism, including 3PC and EF21. In all regimes, our rates are superior compared to all existing adaptive compression methods.},
  archive      = {J_TMLR},
  author       = {Maksim Makarenko and Elnur Gasanov and Abdurakhmon Sadiev and Rustem Islamov and Peter Richtárik},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Adaptive compression for communication-efficient distributed training},
  url          = {https://openreview.net/forum?id=Rb6VDOHebB},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Federated high-dimensional online decision making.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=TjaMO63fc9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We resolve the main challenge of federated bandit policy design via exploration-exploitation trade-off delineation under data decentralization with a local privacy protection argument. Such a challenge is practical in domain-specific applications and admits another layer of complexity in applications of medical decision-making and web marketing, where high- dimensional decision contexts are sensitive but important to inform decision-making. Exist- ing (low dimensional) federated bandits suffer super-linear theoretical regret upper bound in high-dimensional scenarios and are at risk of client information leakage due to their in- ability to separate exploration from exploitation. This paper proposes a class of bandit policy design, termed Fedego Lasso, to complete the task of federated high-dimensional online decision-making with sub-linear theoretical regret and local client privacy argument. Fedego Lasso relies on a novel multi-client teamwork-selfish bandit policy design to per- form decentralized collaborative exploration and federated egocentric exploration with log- arithmic communication costs. Experiments demonstrate the effectiveness of the proposed algorithms on both synthetic and real-world datasets.},
  archive      = {J_TMLR},
  author       = {Chi-Hua Wang and Wenjie Li and Guang Lin},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Federated high-dimensional online decision making},
  url          = {https://openreview.net/forum?id=TjaMO63fc9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Asymptotic analysis of conditioned stochastic gradient
descent. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=U4XgzRjfF1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate a general class of stochastic gradient descent (SGD) algorithms, called $\textit{conditioned}$ SGD, based on a preconditioning of the gradient direction. Using a discrete-time approach with martingale tools, we establish under mild assumptions the weak convergence of the rescaled sequence of iterates for a broad class of conditioning matrices including stochastic first-order and second-order methods. Almost sure convergence results, which may be of independent interest, are also presented. Interestingly, the asymptotic normality result consists in a stochastic equicontinuity property so when the conditioning matrix is an estimate of the inverse Hessian, the algorithm is asymptotically optimal.},
  archive      = {J_TMLR},
  author       = {Rémi Leluc and François Portier},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Asymptotic analysis of conditioned stochastic gradient descent},
  url          = {https://openreview.net/forum?id=U4XgzRjfF1},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). RECLIP: Resource-efficient CLIP by training with small
images. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Ufc5cWhHko">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present RECLIP (Resource-efficient CLIP), a simple method that minimizes computational resource footprint for CLIP (Contrastive Language Image Pretraining). Inspired by the notion of coarse-to-fine in computer vision, we leverage small images to learn from large-scale language supervision efficiently, and finetune the model with high-resolution data in the end. Since the complexity of the vision transformer heavily depends on input image size, our approach significantly reduces the training resource requirements both in theory and in practice. Using the same batch size and training epoch, RECLIP achieves highly competitive zero-shot classification and image-text retrieval accuracy with 6 to 8× less computational resources and 7 to 9× fewer FLOPs than the base- line. Compared to the state-of-the-art contrastive learning methods, RECLIP demonstrates 5 to 59× training resource savings while maintaining highly competitive zero-shot classification and retrieval performance. Finally, RECLIP matches the state of the art in transfer learning to open-vocabulary detection tasks, achieving 32 APr on LVIS. We hope this work will pave the path for the broader research community to explore language supervised pretraining in resource-friendly settings.},
  archive      = {J_TMLR},
  author       = {Runze Li and Dahun Kim and Bir Bhanu and Weicheng Kuo},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {RECLIP: Resource-efficient CLIP by training with small images},
  url          = {https://openreview.net/forum?id=Ufc5cWhHko},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DoCoM: Compressed decentralized optimization with
near-optimal sample complexity. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=W0ehjkl9x7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes the Doubly Compressed Momentum-assisted stochastic gradient tracking algorithm (DoCoM) for communication-efficient decentralized optimization. The algorithm features two main ingredients to achieve a near-optimal sample complexity while allowing for communication compression. First, the algorithm tracks both the averaged iterate and stochastic gradient using compressed gossiping consensus. Second, a momentum step is incorporated for adaptive variance reduction with the local gradient estimates. We show that DoCoM finds a near-stationary solution at all participating agents satisfying $\mathbb{E}[ \| \nabla f( \theta ) \|^2 ] = {\cal O}( 1 / T^{2/3} )$ in $T$ iterations, where $f(\theta)$ is a smooth (possibly non-convex) objective function. Notice that the proof is achieved via analytically designing a new potential function that tightly tracks the one-iteration progress of DoCoM. As a corollary, our analysis also established the linear convergence of DoCoM to a global optimal solution for objective functions with the Polyak-Łojasiewicz condition. Numerical experiments demonstrate that our algorithm outperforms several state-of-the-art algorithms in practice.},
  archive      = {J_TMLR},
  author       = {Chung-Yiu Yau and Hoi To Wai},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DoCoM: Compressed decentralized optimization with near-optimal sample complexity},
  url          = {https://openreview.net/forum?id=W0ehjkl9x7},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learned thresholds token merging and pruning for vision
transformers. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=WYKTCKpImz">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision transformers have demonstrated remarkable success in a wide range of computer vision tasks over the last years, however, their high computational costs remains a significant barrier to their practical deployment. In particular, the complexity of transformer models is quadratic with respect to the number of input tokens. Therefore techniques that reduce the number of input tokens that need to be processed have been proposed. This paper introduces Learned Thresholds token Merging and Pruning (LTMP), a novel approach that leverages the strengths of both token merging and token pruning. LTMP uses learned threshold masking modules that dynamically determine which tokens to merge and which to prune. We demonstrate our approach with extensive experiments on vision transformers on the ImageNet classification task. Our results demonstrate that LTMP achieves state-of-the-art accuracy across reduction rates while requiring only a single fine-tuning epoch, which is an order of magnitude faster than previous methods.},
  archive      = {J_TMLR},
  author       = {Maxim Bonnaerens and Joni Dambre},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learned thresholds token merging and pruning for vision transformers},
  url          = {https://openreview.net/forum?id=WYKTCKpImz},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Empirical limitations of the NTK for understanding scaling
laws in deep learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Y3saBb7mCE">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ``Neural Tangent Kernel&#39;&#39; (NTK) (Jacot et al 2018), and its empirical variants have been proposed as a proxy to capture certain behaviors of real neural networks. In this work, we study NTKs through the lens of scaling laws, and demonstrate that they fall short of explaining important aspects of neural network generalization. In particular, we demonstrate realistic settings where finite-width neural networks have significantly better data scaling exponents as compared to their corresponding empirical and infinite NTKs at initialization. This reveals a more fundamental difference between the real networks and NTKs, beyond just a few percentage points of test accuracy. Further, we show that even if the empirical NTK is allowed to be pre-trained on a constant number of samples, the kernel scaling does not catch up to the neural network scaling. Finally, we show that the empirical NTK continues to evolve throughout most of the training, in contrast with prior work which suggests that it stabilizes after a few epochs of training. Altogether, our work establishes concrete limitations of the NTK approach in understanding scaling laws of real networks on natural datasets.},
  archive      = {J_TMLR},
  author       = {Nikhil Vyas and Yamini Bansal and Preetum Nakkiran},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Empirical limitations of the NTK for understanding scaling laws in deep learning},
  url          = {https://openreview.net/forum?id=Y3saBb7mCE},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). One-step distributional reinforcement learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ZPMf53vE1L">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) allows an agent interacting sequentially with an environment to maximize its long-term expected return. In the distributional RL (DistrRL) paradigm, the agent goes beyond the limit of the expected value, to capture the underlying probability distribution of the return across all time steps. The set of DistrRL algorithms has led to improved empirical performance. Nevertheless, the theory of DistrRL is still not fully understood, especially in the control case. In this paper, we present the simpler one-step distributional reinforcement learning (OS-DistrRL) framework encompassing only the randomness induced by the one-step dynamics of the environment. Contrary to DistrRL, we show that our approach comes with a unified theory for both policy evaluation and control. Indeed, we propose two OS-DistrRL algorithms for which we provide an almost sure convergence analysis. The proposed approach compares favorably with categorical DistrRL on various environments.},
  archive      = {J_TMLR},
  author       = {Mastane Achab and Reda ALAMI and YASSER ABDELAZIZ DAHOU DJILALI and Kirill Fedyanin and Eric Moulines},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {One-step distributional reinforcement learning},
  url          = {https://openreview.net/forum?id=ZPMf53vE1L},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards multi-spatiotemporal-scale generalized PDE modeling.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=dPSTDbGtBY">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {{Partial differential equations (PDEs) are central to describing complex physical system simulations. Their expensive solution techniques have led to an increased interest in deep neural network based surrogates. However, the practical utility of training such surrogates is contingent on their ability to model complex multi-scale spatio-temporal phenomena. {In recent years}, various neural network architectures have been proposed to target such phenomena, most notably Fourier Neural Operators (FNOs), which give a natural handle over local \&amp; global spatial information via parameterization of different Fourier modes, and U-Nets which treat local and global information via downsampling and upsampling paths. However, large-scale comparisons between these convolution-based approaches are notoriously sparse. In this work, we make such comprehensive comparisons regarding performance, runtime complexity, memory requirements, and generalization capabilities. Concretely, we stress-test various FNO, (Dilated) ResNet, and U-Net like approaches to fluid mechanics problems in both vorticity-stream and velocity function form. For U-Nets, we transfer recent architectural improvements from computer vision, most notably from object segmentation and generative modeling. Next, we use our insights on design considerations, and introduce U-FNets, i.e., modern U-Nets that are augmented with FNO downsampling layers. Those architectures further improve performance without major degradation of computational cost. Finally, we ablate and discuss various choices for parameter conditioning}, and show promising results on generalization to different PDE parameters and time-scales with a single surrogate model. Source code for our PyTorch benchmark framework is available at https://anonymous.4open.science/r/tmlr-pdemulti-6677/.},
  archive      = {J_TMLR},
  author       = {Jayesh K Gupta and Johannes Brandstetter},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards multi-spatiotemporal-scale generalized PDE modeling},
  url          = {https://openreview.net/forum?id=dPSTDbGtBY},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scalable stochastic gradient riemannian langevin dynamics in
non-diagonal metrics. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=dXAuvo6CGI">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic-gradient sampling methods are often used to perform Bayesian inference on neural networks. It has been observed that the methods in which notions of differential geometry are included tend to have better performances, with the Riemannian metric improving posterior exploration by accounting for the local curvature. However, the existing methods often resort to simple diagonal metrics to remain computationally efficient. This loses some of the gains. We propose two non-diagonal metrics that can be used in stochastic-gradient samplers to improve convergence and exploration but have only a minor computational overhead over diagonal metrics. We show that for fully connected neural networks (NNs) with sparsity-inducing priors and convolutional NNs with correlated priors, using these metrics can provide improvements. For some other choices the posterior is sufficiently easy also for the simpler metrics.},
  archive      = {J_TMLR},
  author       = {Hanlin Yu and Marcelo Hartmann and Bernardo Williams and Arto Klami},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Scalable stochastic gradient riemannian langevin dynamics in non-diagonal metrics},
  url          = {https://openreview.net/forum?id=dXAuvo6CGI},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Novel class discovery for long-tailed recognition.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ey5b7kODvK">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the novel class discovery has recently made great progress, existing methods typically focus on improving algorithms on class-balanced benchmarks. However, in real-world recognition tasks, the class distributions of their corresponding datasets are often imbalanced, which leads to serious performance degeneration of those methods. In this paper, we consider a more realistic setting for novel class discovery where the distributions of novel and known classes are long-tailed. One main challenge of this new problem is to discover imbalanced novel classes with the help of long-tailed known classes. To tackle this problem, we propose an adaptive self-labeling strategy based on an equiangular prototype representation of classes. Our method infers high-quality pseudo-labels for the novel classes by solving a relaxed optimal transport problem and effectively mitigates the class biases in learning the known and novel classes. We perform extensive experiments on CIFAR100, ImageNet100, Herbarium19 and large-scale iNaturalist18 datasets, and the results demonstrate the superiority of our method. Our code is available at \url{https://github.com/kleinzcy/NCDLR}.},
  archive      = {J_TMLR},
  author       = {Chuyu Zhang and Ruijie Xu and Xuming He},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Novel class discovery for long-tailed recognition},
  url          = {https://openreview.net/forum?id=ey5b7kODvK},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Holistic evaluation of language models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=iO4LZibEqW">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language models (LMs) are becoming the foundation for almost all major language technologies, but their capabilities, limitations, and risks are not well understood. We present Holistic Evaluation of Language Models (HELM) to improve the transparency of language models. First, we taxonomize the vast space of potential scenarios (i.e. use cases) and metrics (i.e. desiderata) that are of interest for LMs. Then we select a broad subset based on coverage and feasibility, noting what’s missing or underrepresented (e.g. question answering for neglected English dialects, metrics for trustworthiness). Second, we adopt a multi-metric approach: We measure 7 metrics (accuracy, calibration, robustness, fairness, bias, toxicity, and efficiency) for each of 16 core scenarios to the extent possible (87.5% of the time), ensuring that metrics beyond accuracy don’t fall to the wayside, and that trade-offs across models and metrics are clearly exposed. We also perform 7 targeted evaluations, based on 26 targeted scenarios, to more deeply analyze specific aspects (e.g. knowledge, reasoning, memorization/copyright, disinformation). Third, we conduct a large-scale evaluation of 30 prominent language models (spanning open, limited-access, and closed models) on all 42 scenarios, including 21 scenarios that were not previously used in mainstream LM evaluation. Prior to HELM, models on average were evaluated on just 17.9% of the core HELM scenarios, with some prominent models not sharing a single scenario in common. We improve this to 96.0%: now all 30 models have been densely benchmarked on a set of core scenarios and metrics under standardized conditions. Our evaluation surfaces 25 top-level findings concerning the interplay between different scenarios, metrics, and models. For full transparency, we release all raw model prompts and completions publicly for further analysis, as well as a general modular toolkit for easily adding new scenarios, models, metrics, and prompting strategies. We intend for HELM to be a living benchmark for the community, continuously updated with new scenarios, metrics, and models.},
  archive      = {J_TMLR},
  author       = {Percy Liang and Rishi Bommasani and Tony Lee and Dimitris Tsipras and Dilara Soylu and Michihiro Yasunaga and Yian Zhang and Deepak Narayanan and Yuhuai Wu and Ananya Kumar and Benjamin Newman and Binhang Yuan and Bobby Yan and Ce Zhang and Christian Alexander Cosgrove and Christopher D Manning and Christopher Re and Diana Acosta-Navas and Drew Arad Hudson and Eric Zelikman and Esin Durmus and Faisal Ladhak and Frieda Rong and Hongyu Ren and Huaxiu Yao and Jue WANG and Keshav Santhanam and Laurel Orr and Lucia Zheng and Mert Yuksekgonul and Mirac Suzgun and Nathan Kim and Neel Guha and Niladri S. Chatterji and Omar Khattab and Peter Henderson and Qian Huang and Ryan Andrew Chi and Sang Michael Xie and Shibani Santurkar and Surya Ganguli and Tatsunori Hashimoto and Thomas Icard and Tianyi Zhang and Vishrav Chaudhary and William Wang and Xuechen Li and Yifan Mai and Yuhui Zhang and Yuta Koreeda},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Holistic evaluation of language models},
  url          = {https://openreview.net/forum?id=iO4LZibEqW},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning from time-dependent streaming data with online
stochastic algorithms. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=kdfiEu1ul6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses stochastic optimization in a streaming setting with time-dependent and biased gradient estimates. We analyze several first-order methods, including Stochastic Gradient Descent (SGD), mini-batch SGD, and time-varying mini-batch SGD, along with their Polyak-Ruppert averages. Our non-asymptotic analysis establishes novel heuristics that link dependence, biases, and convexity levels, enabling accelerated convergence. Specifically, our findings demonstrate that (i) time-varying mini-batch SGD methods have the capability to break long- and short-range dependence structures, (ii) biased SGD methods can achieve comparable performance to their unbiased counterparts, and (iii) incorporating Polyak-Ruppert averaging can accelerate the convergence of the stochastic optimization algorithms. To validate our theoretical findings, we conduct a series of experiments using both simulated and real-life time-dependent data.},
  archive      = {J_TMLR},
  author       = {Antoine Godichon-Baggioni and Nicklas Werge and Olivier Wintenberger},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning from time-dependent streaming data with online stochastic algorithms},
  url          = {https://openreview.net/forum?id=kdfiEu1ul6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mitigating real-world distribution shifts in the fourier
domain. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=lu4oAq55iK">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While machine learning systems can be highly accurate in their training environments, their performance in real-world deployments can suffer significantly due to distribution shifts. Real-world distribution shifts involve various input distortions due to noise, weather, device and other variations. Many real-world distribution shifts are not represented in standard domain adaptation datasets and prior empirical work has shown that domain adaptation methods developed using these standard datasets may not generalize well to real-world distribution shifts. Furthermore, motivated by observations of the sensitivity of deep neural networks (DNN) to the spectral statistics of data, which can vary in real-world scenarios, we propose Fourier Moment Matching (FMM), a model-agnostic input transformation that matches the Fourier-amplitude statistics of source to target data using unlabeled samples. We demonstrate through extensive empirical evaluations across time-series, image classification and semantic segmentation tasks that FMM is effective both individually and when combined with a variety of existing methods to overcome real-world distribution shifts.},
  archive      = {J_TMLR},
  author       = {Kiran Krishnamachari and See-Kiong Ng and Chuan-Sheng Foo},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Mitigating real-world distribution shifts in the fourier domain},
  url          = {https://openreview.net/forum?id=lu4oAq55iK},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to boost resilience of complex networks via neural
edge rewiring. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=moZvOx5cxe">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The resilience of complex networks refers to their ability to maintain functionality in the face of structural attacks. This ability can be improved by performing minimal modifications to the network structure via degree-preserving edge rewiring-based methods. Existing learning-free edge rewiring methods, although effective, are limited in their ability to generalize to different graphs. Such a limitation cannot be trivially addressed by existing graph neural networks (GNNs)-based learning approaches since there is no rich initial node features for GNNs to learn meaningful representations. In this work, inspired by persistent homology, we specifically design a variant of GNN called FireGNN to learn meaningful node representations solely from graph structures. We then develop an end-to-end inductive method called ResiNet, which aims to discover resilient network topologies while balancing network utility. ResiNet reformulates the optimization of network resilience as a Markov decision process equipped with edge rewiring action space. It learns to sequentially select the appropriate edges to rewire for maximizing resilience. Extensive experiments demonstrate that ResiNet outperforms existing approaches and achieves near-optimal resilience gains on various graphs while balancing network utility.},
  archive      = {J_TMLR},
  author       = {Shanchao Yang and MA KAILI and Baoxiang Wang and Tianshu Yu and Hongyuan Zha},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning to boost resilience of complex networks via neural edge rewiring},
  url          = {https://openreview.net/forum?id=moZvOx5cxe},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using confounded data in latent model-based reinforcement
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=nFWRuJXPkU">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the presence of confounding, naively using off-the-shelf offline reinforcement learning (RL) algorithms leads to sub-optimal behaviour. In this work, we propose a safe method to exploit confounded offline data in model-based RL, which improves the sample-efficiency of an interactive agent that also collects online, unconfounded data. First, we import ideas from the well-established framework of $do$-calculus to express model-based RL as a causal inference problem, thus bridging the gap between the fields of RL and causality. Then, we propose a generic method for learning a causal transition model from offline and online data, which captures and corrects the confounding effect using a hidden latent variable. We prove that our method is correct and efficient, in the sense that it attains better generalization guarantees thanks to the confounded offline data (in the asymptotic case), regardless of the confounding effect (the offline expert&#39;s behaviour). We showcase our method on a series of synthetic experiments, which demonstrate that a) using confounded offline data naively degrades the sample-efficiency of an RL agent; b) using confounded offline data correctly improves sample-efficiency.},
  archive      = {J_TMLR},
  author       = {Maxime Gasse and Damien GRASSET and Guillaume Gaudron and Pierre-Yves Oudeyer},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Using confounded data in latent model-based reinforcement learning},
  url          = {https://openreview.net/forum?id=nFWRuJXPkU},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimizing learning rate schedules for iterative pruning of
deep neural networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=nGW2Hotpq3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The importance of learning rate (LR) schedules on network pruning has been observed in a few recent works. As an example, Frankle and Carbin (2019) highlighted that winning tickets (i.e., accuracy preserving subnetworks) can not be found without applying a LR warmup schedule. Renda, Frankle and Carbin (2020) also demonstrated that rewinding the LR to its initial state at the end of each pruning cycle can improve pruning performance. In this paper, we go one step further by first providing a theoretical justification for the surprising effect of LR schedules. Next, we propose a LR schedule for network pruning called SILO, which stands for S-shaped Improved Learning rate Optimization. The advantages of SILO over existing LR schedules are two-fold: (i) SILO has a strong theoretical motivation and dynamically adjusts the LR during pruning to improve generalization. Specifically, SILO increases the LR upper bound (max_lr) in an S-shape. This leads to an improvement of 2% - 4% in extensive experiments with various types of networks (e.g., Vision Transformers, ResNet) on popular datasets such as ImageNet, CIFAR-10/100. (ii) In addition to the strong theoretical motivation, SILO is empirically optimal in the sense of matching an Oracle, which exhaustively searches for the optimal value of max_lr via grid search. We find that SILO is able to precisely adjust the value of max_lr to be within the Oracle optimized interval, resulting in performance competitive with the Oracle with significantly lower complexity.},
  archive      = {J_TMLR},
  author       = {Shiyu Liu and Rohan Ghosh and John Chong Min Tan and Mehul Motani},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Optimizing learning rate schedules for iterative pruning of deep neural networks},
  url          = {https://openreview.net/forum?id=nGW2Hotpq3},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rotation-invariant random features provide a strong baseline
for machine learning on 3D point clouds. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=nYzhlFyjjd">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rotational invariance is a popular inductive bias used by many fields in machine learning, such as computer vision and machine learning for quantum chemistry. Rotation-invariant machine learning methods set the state of the art for many tasks, including molecular property prediction and 3D shape classification. These methods generally either rely on task-specific rotation-invariant features, or they use general-purpose deep neural networks which are complicated to design and train. However, it is unclear whether the success of these methods is primarily due to the rotation invariance or the deep neural networks. To address this question, we suggest a simple and general-purpose method for learning rotation-invariant functions of three-dimensional point cloud data using a random features approach. Specifically, we extend the random features method of Rahimi &amp; Recht (2007) by deriving a version that is invariant to three-dimensional rotations and showing that it is fast to evaluate on point cloud data. We show through experiments that our method matches or outperforms the performance of general-purpose rotation-invariant neural networks on standard molecular property prediction benchmark datasets QM7 and QM9. We also show that our method is general-purpose and provides a rotation-invariant baseline on the ModelNet40 shape classification task. Finally, we show that our method has an order of magnitude smaller prediction latency than competing kernel methods.},
  archive      = {J_TMLR},
  author       = {Owen Melia and Eric M Jonas and Rebecca Willett},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Rotation-invariant random features provide a strong baseline for machine learning on 3D point clouds},
  url          = {https://openreview.net/forum?id=nYzhlFyjjd},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning representations that are closed-form monge mapping
optimal with application to domain adaptation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=nOIGfQnFZm">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal transport (OT) is a powerful geometric tool used to compare and align probability measures following the least effort principle. Despite its widespread use in machine learning (ML), OT problem still bears its computational burden, while at the same time suffering from the curse of dimensionality for measures supported on general high-dimensional spaces. In this paper, we propose to tackle these challenges using representation learning. In particular, we seek to learn an embedding space such that the samples of the two input measures become alignable in it with a simple affine mapping that can be calculated efficiently in closed-form. We then show that such approach leads to results that are comparable to solving the original OT problem when applied to the transfer learning task on which many OT baselines where previously evaluated in both homogeneous and heterogeneous DA settings.},
  archive      = {J_TMLR},
  author       = {Oliver Struckmeier and Ievgen Redko and Anton Mallasto and Karol Arndt and Markus Heinonen and Ville Kyrki},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning representations that are closed-form monge mapping optimal with application to domain adaptation},
  url          = {https://openreview.net/forum?id=nOIGfQnFZm},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Long-term forecasting with TiDE: Time-series dense encoder.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=pCbC3aQB5W">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent work has shown that simple linear models can outperform several Transformer based approaches in long term time-series forecasting. Motivated by this, we propose a Multi-layer Perceptron (MLP) based encoder-decoder model, \underline{Ti}me-series \underline{D}ense \underline{E}ncoder (TiDE), for long-term time-series forecasting that enjoys the simplicity and speed of linear models while also being able to handle covariates and non-linear dependencies. Theoretically, we prove that the simplest linear analogue of our model can achieve near optimal error rate for linear dynamical systems (LDS) under some assumptions. Empirically, we show that our method can match or outperform prior approaches on popular long-term time-series forecasting benchmarks while being 5-10x faster than the best Transformer based model.},
  archive      = {J_TMLR},
  author       = {Abhimanyu Das and Weihao Kong and Andrew Leach and Shaan K Mathur and Rajat Sen and Rose Yu},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Long-term forecasting with TiDE: Time-series dense encoder},
  url          = {https://openreview.net/forum?id=pCbC3aQB5W},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph neural networks for temporal graphs: State of the art,
open challenges, and opportunities. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=pHCdMat0gI">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have become the leading paradigm for learning on (static) graph-structured data. However, many real-world systems are dynamic in nature, since the graph and node/edge attributes change over time. In recent years, GNN-based models for temporal graphs have emerged as a promising area of research to extend the capabilities of GNNs. In this work, we provide the first comprehensive overview of the current state-of-the-art of temporal GNN, introducing a rigorous formalization of learning settings and tasks and a novel taxonomy categorizing existing approaches in terms of how the temporal aspect is represented and processed. We conclude the survey with a discussion of the most relevant open challenges for the field, from both research and application perspectives.},
  archive      = {J_TMLR},
  author       = {Antonio Longa and Veronica Lachi and Gabriele Santin and Monica Bianchini and Bruno Lepri and Pietro Lio and franco scarselli and Andrea Passerini},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Graph neural networks for temporal graphs: State of the art, open challenges, and opportunities},
  url          = {https://openreview.net/forum?id=pHCdMat0gI},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). V1T: Large-scale mouse v1 response prediction using a vision
transformer. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=qHZs2p4ZD4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate predictive models of the visual cortex neural response to natural visual stimuli remain a challenge in computational neuroscience. In this work, we introduce $V{\small 1}T$, a novel Vision Transformer based architecture that learns a shared visual and behavioral representation across animals. We evaluate our model on two large datasets recorded from mouse primary visual cortex and outperform previous convolution-based models by more than 12.7% in prediction performance. Moreover, we show that the self-attention weights learned by the Transformer correlate with the population receptive fields. Our model thus sets a new benchmark for neural response prediction and can be used jointly with behavioral and neural recordings to reveal meaningful characteristic features of the visual cortex.},
  archive      = {J_TMLR},
  author       = {Bryan M. Li and Isabel Maria Cornacchia and Nathalie Rochefort and Arno Onken},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {V1T: Large-scale mouse v1 response prediction using a vision transformer},
  url          = {https://openreview.net/forum?id=qHZs2p4ZD4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Structured low-rank tensors for generalized linear models.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=qUxBs3Ln41">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent works have shown that imposing tensor structures on the coefficient tensor in regression problems can lead to more reliable parameter estimation and lower sample complexity compared to vector-based methods. This work investigates a new low-rank tensor model, called Low Separation Rank (LSR), in Generalized Linear Model (GLM) problems. The LSR model – which generalizes the well-known Tucker and CANDECOMP/PARAFAC (CP) models, and is a special case of the Block Tensor Decomposition (BTD) model – is imposed onto the coefficient tensor in the GLM model. This work proposes a block coordinate descent algorithm for parameter estimation in LSR-structured tensor GLMs. Most importantly, it derives a minimax lower bound on the error threshold on estimating the coefficient tensor in LSR tensor GLM problems. The minimax bound is proportional to the intrinsic degrees of freedom in the LSR tensor GLM problem, suggesting that its sample complexity may be significantly lower than that of vectorized GLMs. This result can also be specialised to lower bound the estimation error in CP and Tucker-structured GLMs. The derived bounds are comparable to tight bounds in the literature for Tucker linear regression, and the tightness of the minimax lower bound is further assessed numerically. Finally, numerical experiments on synthetic datasets demonstrate the efficacy of the proposed LSR tensor model for three regression types (linear, logistic and Poisson). Experiments on a collection of medical imaging datasets demonstrate the usefulness of the LSR model over other tensor models (Tucker and CP) on real, imbalanced data with limited available samples.},
  archive      = {J_TMLR},
  author       = {Batoul Ahmad Taki and Anand Sarwate and Waheed U. Bajwa},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Structured low-rank tensors for generalized linear models},
  url          = {https://openreview.net/forum?id=qUxBs3Ln41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reinforcement learning with delayed, composite, and
partially anonymous reward. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ubCoTAynPp">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate an infinite-horizon average reward Markov Decision Process (MDP) with delayed, composite, and partially anonymous reward feedback. The delay and compositeness of rewards mean that rewards generated as a result of taking an action at a given state are fragmented into different components, and they are sequentially realized at delayed time instances. The partial anonymity attribute implies that a learner, for each state, only observes the aggregate of past reward components generated as a result of different actions taken at that state, but realized at the observation instance. We propose an algorithm named $\mathrm{DUCRL2}$ to obtain a near-optimal policy for this setting and show that it achieves a regret bound of $\tilde{\mathcal{O}}\left(DS\sqrt{AT} + d (SA)^3\right)$ where $S$ and $A$ are the sizes of the state and action spaces, respectively, $D$ is the diameter of the MDP, $d$ is a parameter upper bounded by the maximum reward delay, and $T$ denotes the time horizon. This demonstrates the optimality of the bound in the order of $T$, and an additive impact of the delay.},
  archive      = {J_TMLR},
  author       = {Washim Uddin Mondal and Vaneet Aggarwal},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reinforcement learning with delayed, composite, and partially anonymous reward},
  url          = {https://openreview.net/forum?id=ubCoTAynPp},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). About the cost of central privacy in density estimation.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=uq29MIWvIV">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study non-parametric density estimation for densities in Lipschitz and Sobolev spaces, and under central privacy. In particular, we investigate regimes where the privacy budget is not supposed to be constant. We consider the classical definition of central differential privacy, but also the more recent notion of central concentrated differential privacy. We recover the result of Barber &amp; Duchi (2014) stating that histogram estimators are optimal against Lipschitz distributions for the L2 risk and, under regular differential privacy, we extend it to other norms and notions of privacy. Then, we investigate higher degrees of smoothness, drawing two conclusions: First, and contrary to what happens with constant privacy budget (Wasserman &amp; Zhou, 2010), there are regimes where imposing privacy degrades the regular minimax risk of estimation on Sobolev densities. Second, so-called projection estimators are near-optimal against the same classes of densities in this new setup with pure differential privacy, but contrary to the constant privacy budget case, it comes at the cost of relaxation. With zero concentrated differential privacy, there is no need for relaxation, and we prove that the estimation is optimal.},
  archive      = {J_TMLR},
  author       = {Clément Lalanne and Aurélien Garivier and Rémi Gribonval},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {About the cost of central privacy in density estimation},
  url          = {https://openreview.net/forum?id=uq29MIWvIV},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Understanding convolution on graphs via energies.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=v5ew3FPTgb">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) typically operate by message-passing, where the state of a node is updated based on the information received from its neighbours. Most message-passing models act as graph convolutions, where features are mixed by a shared, linear transformation before being propagated over the edges. On node-classification tasks, graph convolutions have been shown to suffer from two limitations: poor performance on heterophilic graphs, and over-smoothing. It is common belief that both phenomena occur because such models behave as low-pass filters, meaning that the Dirichlet energy of the features decreases along the layers incurring a smoothing effect that ultimately makes features no longer distinguishable. In this work, we rigorously prove that simple graph-convolutional models can actually enhance high frequencies and even lead to an asymptotic behaviour we refer to as over-sharpening, opposite to over-smoothing. We do so by showing that linear graph convolutions with symmetric weights minimize a multi-particle energy that generalizes the Dirichlet energy; in this setting, the weight matrices induce edge-wise attraction (repulsion) through their positive (negative) eigenvalues, thereby controlling whether the features are being smoothed or sharpened. We also extend the analysis to non-linear GNNs, and demonstrate that some existing time-continuous GNNs are instead always dominated by the low frequencies. Finally, we validate our theoretical findings through ablations and real-world experiments.},
  archive      = {J_TMLR},
  author       = {Francesco Di Giovanni and James Rowbottom and Benjamin Paul Chamberlain and Thomas Markovich and Michael M. Bronstein},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Understanding convolution on graphs via energies},
  url          = {https://openreview.net/forum?id=v5ew3FPTgb},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Foiling explanations in deep neural networks. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=wvLQMHtyLk">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have greatly impacted numerous fields over the past decade. Yet despite exhibiting superb performance over many problems, their black-box nature still poses a significant challenge with respect to explainability. Indeed, explainable artificial intelligence (XAI) is crucial in several fields, wherein the answer alone---sans a reasoning of how said answer was derived---is of little value. This paper uncovers a troubling property of explanation methods for image-based DNNs: by making small visual changes to the input image---hardly influencing the network&#39;s output---we demonstrate how explanations may be arbitrarily manipulated through the use of evolution strategies. Our novel algorithm, AttaXAI, a model-and-data XAI-agnostic, adversarial attack on XAI algorithms, only requires access to the output logits of a classifier and to the explanation map; these weak assumptions render our approach highly useful where real-world models and data are concerned. We compare our method&#39;s performance on two benchmark datasets---CIFAR100 and ImageNet---using four different pretrained deep-learning models: VGG16-CIFAR100, VGG16-ImageNet, MobileNet-CIFAR100, and Inception-v3-ImageNet. We find that the XAI methods can be manipulated without the use of gradients or other model internals. Our novel algorithm is successfully able to manipulate an image in a manner imperceptible to the human eye, such that the XAI method outputs a specific explanation map. To our knowledge, this is the first such method in a black-box setting, and we believe it has significant value where explainability is desired, required, or legally mandatory.},
  archive      = {J_TMLR},
  author       = {Snir Vitrack Tamam and Raz Lapid and Moshe Sipper},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Foiling explanations in deep neural networks},
  url          = {https://openreview.net/forum?id=wvLQMHtyLk},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diffusion models for constrained domains. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=xuWTFQ4VGO">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Denoising diffusion models are a novel class of generative algorithms that achieve state-of-the-art performance across a range of domains, including image generation and text-to-image tasks. Building on this success, diffusion models have recently been extended to the Riemannian manifold setting, broadening their applicability to a range of problems from the natural and engineering sciences. However, these Riemannian diffusion models are built on the assumption that their forward and backward processes are well-defined for all times, preventing them from being applied to an important set of tasks that consider manifolds defined via a set of inequality constraints. In this work, we introduce a principled framework to bridge this gap. We present two distinct noising processes based on (i) the logarithmic barrier metric and (ii) the reflected Brownian motion induced by the constraints. As existing diffusion model techniques cannot be applied in this setting, we proceed to derive new tools to define such models in our framework. We then empirically demonstrate the scalability and flexibility of our methods on a number of synthetic and real-world tasks, including applications from robotics and protein design.},
  archive      = {J_TMLR},
  author       = {Nic Fishman and Leo Klarner and Valentin De Bortoli and Emile Mathieu and Michael John Hutchinson},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Diffusion models for constrained domains},
  url          = {https://openreview.net/forum?id=xuWTFQ4VGO},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simulate time-integrated coarse-grained molecular dynamics
with multi-scale graph networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=y8RZoPjEUl">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Molecular dynamics (MD) simulation is essential for various scientific domains but computationally expensive. Learning-based force fields have made significant progress in accelerating ab-initio MD simulation but are not fast enough for many real-world applications due to slow inference for large systems and small time steps (femtosecond-level). We aim to address these challenges by learning a multi-scale graph neural network that directly simulates coarse-grained MD with a very large time step (nanosecond-level) and a novel refinement module based on diffusion models to mitigate simulation instability. The effectiveness of our method is demonstrated in two complex systems: single-chain coarse-grained polymers and multi-component Li-ion polymer electrolytes. For evaluation, we simulate trajectories much longer than the training trajectories for systems with different chemical compositions that the model is not trained on. Structural and dynamical properties can be accurately recovered at several orders of magnitude higher speed than classical force fields by getting out of the femtosecond regime.},
  archive      = {J_TMLR},
  author       = {Xiang Fu and Tian Xie and Nathan J. Rebello and Bradley Olsen and Tommi S. Jaakkola},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Simulate time-integrated coarse-grained molecular dynamics with multi-scale graph networks},
  url          = {https://openreview.net/forum?id=y8RZoPjEUl},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural ordinary differential equations for modeling epidemic
spreading. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=yrkJGne0vN">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mathematical models of infectious diseases have long been used for studying the mechanisms by which diseases spread, for predicting the spread of epidemics, and also for controlling their outbreaks. These models are based on some assumptions and different assumptions give rise to different models. Models on social networks of individuals which capture contact patterns are usually more realistic and can more accurately model contagion dynamics. Unfortunately, computing the output of realistic models is often hard. Thus, modeling the evolution of contagion dynamics over large complex networks constitutes a challenging task. In this paper, we present a computational approach to model the contagion dynamics underlying infectious diseases. Specifically, we focus on the susceptible-infectious-recovered (SIR) epidemic model on networks. Given that this model can be expressed by an intractable system of ordinary differential equations, we devise a simpler system that approximates the output of the model. Then, we capitalize on recent advances in neural ordinary differential equations and propose a neural architecture that can effectively predict the course of an epidemic on the network. We apply the proposed architecture on several network datasets and compare it against state-of-the-art methods under different experimental settings. Our results indicate that the proposed method improves predictions in various spreading scenarios, paving the way for the extensive application of interpretable neural networks in the field of epidemic spreading. At the same time, the proposed model is highly efficient even when trained on very large networks where traditional algorithms become significantly slower.},
  archive      = {J_TMLR},
  author       = {Chrysoula Kosma and Giannis Nikolentzos and George Panagopoulos and Jean-Marc Steyaert and Michalis Vazirgiannis},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Neural ordinary differential equations for modeling epidemic spreading},
  url          = {https://openreview.net/forum?id=yrkJGne0vN},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The multiquadric kernel for moment-matching distributional
reinforcement learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=z49eaB8kiH">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributional reinforcement learning has gained significant attention in recent years due to its ability to handle uncertainty and variability in the returns an agent will receive for each action it takes. A key challenge in distributional reinforcement learning is finding a measure of the difference between two distributions that is well-suited for use with the distributional Bellman operator, a function that takes in a value distribution and produces a modified distribution based on the agent&#39;s current state and action. In this paper, we address this challenge by introducing the multiquadric kernel to moment-matching distributional reinforcement learning. We show that this kernel is both theoretically sound and empirically effective. Our contribution is mainly of a theoretical nature, presenting the first formally sound kernel for moment-matching distributional reinforcement learning with good practical performance. We also provide insights into why the RBF kernel has been shown to provide good practical results despite its theoretical problems. Finally, we evaluate the performance of our kernel on a number of standard benchmarks, obtaining results comparable to the state-of-the-art.},
  archive      = {J_TMLR},
  author       = {Ludvig Killingberg and Helge Langseth},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The multiquadric kernel for moment-matching distributional reinforcement learning},
  url          = {https://openreview.net/forum?id=z49eaB8kiH},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Execution-based code generation using deep reinforcement
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=0XBuaxqEcG">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The utilization of programming language (PL) models, pre-trained on large-scale code corpora, as a means of automating software engineering processes has demonstrated considerable potential in streamlining various code generation tasks such as code completion, code translation, and program synthesis. However, current approaches mainly rely on supervised fine-tuning objectives borrowed from text generation, neglecting unique sequence-level characteristics of code, including but not limited to compilability as well as syntactic and functional correctness. To address this limitation, we propose PPOCoder, a new framework for code generation that synergistically combines pre-trained PL models with Proximal Policy Optimization (PPO) which is a widely used deep reinforcement learning technique. By utilizing non-differentiable feedback from code execution and structure alignment, PPOCoder seamlessly integrates external code-specific knowledge into the model optimization process. It&#39;s important to note that PPOCoder is a task-agnostic and model-agnostic framework that can be used across different code generation tasks and PLs. Extensive experiments on three code generation tasks demonstrate the effectiveness of our proposed approach compared to SOTA methods, achieving significant improvements in compilation success rates and functional correctness across different PLs.},
  archive      = {J_TMLR},
  author       = {Parshin Shojaee and Aneesh Jain and Sindhu Tipirneni and Chandan K. Reddy},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Execution-based code generation using deep reinforcement learning},
  url          = {https://openreview.net/forum?id=0XBuaxqEcG},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Challenges and opportunities in offline reinforcement
learning from visual observations. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=1QqIfGZOWu">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline reinforcement learning has shown great promise in leveraging large pre-collected datasets for policy learning, allowing agents to forgo often-expensive online data collection. However, offline reinforcement learning from visual observations with continuous action spaces remains under-explored, with a limited understanding of the key challenges in this complex domain. In this paper, we establish simple baselines for continuous control in the visual domain and introduce a suite of benchmarking tasks for offline reinforcement learning from visual observations designed to better represent the data distributions present in real-world offline RL problems and guided by a set of desiderata for offline RL from visual observations, including robustness to visual distractions and visually identifiable changes in dynamics. Using this suite of benchmarking tasks, we show that simple modifications to two popular vision-based online reinforcement learning algorithms, DreamerV2 and DrQ-v2, suffice to outperform existing offline RL methods and establish competitive baselines for continuous control in the visual domain. We rigorously evaluate these algorithms and perform an empirical evaluation of the differences between state-of-the-art model-based and model-free offline RL methods for continuous control from visual observations. All code and data used in this evaluation are open-sourced to facilitate progress in this domain.},
  archive      = {J_TMLR},
  author       = {Cong Lu and Philip J. Ball and Tim G. J. Rudner and Jack Parker-Holder and Michael A Osborne and Yee Whye Teh},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Challenges and opportunities in offline reinforcement learning from visual observations},
  url          = {https://openreview.net/forum?id=1QqIfGZOWu},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural monge map estimation and its applications.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=2mZSlQscj3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monge map refers to the optimal transport map between two probability distributions and provides a principled approach to transform one distribution to another. Neural network-based optimal transport map solver has gained great attention in recent years. Along this line, we present a scalable algorithm for computing the neural Monge map between two probability distributions. Our algorithm is based on a weak form of the optimal transport problem, thus it only requires samples from the marginals instead of their analytic expressions, and can be applied in large-scale settings. Furthermore, using the duality gap we prove rigorously \textit{a posteriori} error analysis for the method. Our algorithm is suitable for general cost functions, compared with other existing methods for estimating Monge maps using samples, which are usually for quadratic costs. The performance of our algorithms is demonstrated through a series of experiments with both synthetic and realistic data, including text-to-image generation, class-preserving map, and image inpainting tasks.},
  archive      = {J_TMLR},
  author       = {Jiaojiao Fan and Shu Liu and Shaojun Ma and Hao-Min Zhou and Yongxin Chen},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Neural monge map estimation and its applications},
  url          = {https://openreview.net/forum?id=2mZSlQscj3},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tackling provably hard representative selection via graph
neural networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=3LzgOQ3eOb">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representative Selection (RS) is the problem of finding a small subset of exemplars from a dataset that is representative of the dataset. In this paper, we study RS for attributed graphs, and focus on finding representative nodes that optimize the accuracy of a model trained on the selected representatives. Theoretically, we establish a new hardness result for RS (in the absence of a graph structure) by proving that a particular, highly practical variant of it (RS for Learning) is hard to approximate in polynomial time within any reasonable factor, which implies a significant potential gap between the optimum solution of widely-used surrogate functions and the actual accuracy of the model. We then study the setting where a (homophilous) graph structure is available, or can be constructed, between the data points. We show that with an appropriate modeling approach, the presence of such a structure can turn a hard RS (for learning) problem into one that can be effectively solved. To this end, we develop RS-GNN, a representation learning-based RS model based on Graph Neural Networks. Empirically, we demonstrate the effectiveness of RS-GNN on problems with predefined graph structures as well as problems with graphs induced from node feature similarities, by showing that RS-GNN achieves significant improvements over established baselines on a suite of eight benchmarks.},
  archive      = {J_TMLR},
  author       = {Mehran Kazemi and Anton Tsitsulin and Hossein Esfandiari and Mohammadhossein Bateni and Deepak Ramachandran and Bryan Perozzi and Vahab Mirrokni},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Tackling provably hard representative selection via graph neural networks},
  url          = {https://openreview.net/forum?id=3LzgOQ3eOb},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the predictive accuracy of neural temporal point process
models for continuous-time event data. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=3OSISBQPrM">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal Point Processes (TPPs) serve as the standard mathematical framework for modeling asynchronous event sequences in continuous time. However, classical TPP models are often constrained by strong assumptions, limiting their ability to capture complex real-world event dynamics. To overcome this limitation, researchers have proposed Neural TPPs, which leverage neural network parametrizations to offer more flexible and efficient modeling. While recent studies demonstrate the effectiveness of Neural TPPs, they often lack a unified setup, relying on different baselines, datasets, and experimental configurations. This makes it challenging to identify the key factors driving improvements in predictive accuracy, hindering research progress. To bridge this gap, we present a comprehensive large-scale experimental study that systematically evaluates the predictive accuracy of state-of-the-art neural TPP models. Our study encompasses multiple real-world and synthetic event sequence datasets, following a carefully designed unified setup. We thoroughly investigate the influence of major architectural components such as event encoding, history encoder, and decoder parametrization on both time and mark prediction tasks. Additionally, we delve into the less explored area of probabilistic calibration for neural TPP models. By analyzing our results, we draw insightful conclusions regarding the significance of history size and the impact of architectural components on predictive accuracy. Furthermore, we shed light on the miscalibration of mark distributions in neural TPP models. Our study aims to provide valuable insights into the performance and characteristics of neural TPP models, contributing to a better understanding of their strengths and limitations.},
  archive      = {J_TMLR},
  author       = {Tanguy Bosser and Souhaib Ben Taieb},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the predictive accuracy of neural temporal point process models for continuous-time event data},
  url          = {https://openreview.net/forum?id=3OSISBQPrM},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Assisting human decisions in document matching.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=5rq8iRzHAQ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many practical applications, ranging from paper-reviewer assignment in peer review to job-applicant matching for hiring, require human decision makers to identify relevant matches by combining their expertise with predictions from machine learning models. In many such model-assisted document matching tasks, the decision makers have stressed the need for assistive information about the model outputs (or the data) to facilitate their decisions. In this paper, we devise a proxy matching task that allows us to evaluate which kinds of assistive information improve decision makers’ performance (in terms of accuracy and time). Through a crowdsourced (N = 271 participants) study, we find that providing black-box model explanations reduces users’ accuracy on the matching task, contrary to the commonly-held belief that they can be helpful by allowing better understanding of the model. On the other hand, custom methods that are designed to closely attend to some task-specific desiderata are found to be effective in improving user performance. Surprisingly, we also find that the users’ perceived utility of assistive information is misaligned with their objective utility (measured through their task performance).},
  archive      = {J_TMLR},
  author       = {Joon Sik Kim and Valerie Chen and Danish Pruthi and Nihar B Shah and Ameet Talwalkar},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Assisting human decisions in document matching},
  url          = {https://openreview.net/forum?id=5rq8iRzHAQ},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Catastrophic overfitting can be induced with discriminative
non-robust features. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=10hCbu70Sr">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial training (AT) is the de facto method for building robust neural networks, but it can be computationally expensive. To mitigate this, fast single-step attacks can be used, but this may lead to catastrophic overfitting (CO). This phenomenon appears when networks gain non-trivial robustness during the first stages of AT, but then reach a breaking point where they become vulnerable in just a few iterations. The mechanisms that lead to this failure mode are still poorly understood. In this work, we study the onset of CO in single-step AT methods through controlled modifications of typical datasets of natural images. In particular, we show that CO can be induced at much smaller $\epsilon$ values than it was observed before just by injecting images with seemingly innocuous features. These features aid non-robust classification but are not enough to achieve robustness on their own. Through extensive experiments we analyze this novel phenomenon and discover that the presence of these easy features induces a learning shortcut that leads to CO. Our findings provide new insights into the mechanisms of CO and improve our understanding of the dynamics of AT.},
  archive      = {J_TMLR},
  author       = {Guillermo Ortiz-Jimenez and Pau de Jorge and Amartya Sanyal and Adel Bibi and Puneet K. Dokania and Pascal Frossard and Grégory Rogez and Philip Torr},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Catastrophic overfitting can be induced with discriminative non-robust features},
  url          = {https://openreview.net/forum?id=10hCbu70Sr},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient reward poisoning attacks on online deep
reinforcement learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=25G63lDHV2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study reward poisoning attacks on online deep reinforcement learning (DRL), where the attacker is oblivious to the learning algorithm used by the agent and the dynamics of the environment. We demonstrate the intrinsic vulnerability of state-of-the-art DRL algorithms by designing a general, black-box reward poisoning framework called adversarial MDP attacks. We instantiate our framework to construct two new attacks which only corrupt the rewards for a small fraction of the total training timesteps and make the agent learn a low-performing policy. We provide a theoretical analysis of the efficiency of our attack and perform an extensive empirical evaluation. Our results show that our attacks efficiently poison agents learning in several popular classical control and MuJoCo environments with a variety of state-of-the-art DRL algorithms, such as DQN, PPO, SAC, etc.},
  archive      = {J_TMLR},
  author       = {Yinglun Xu and Qi Zeng and Gagandeep Singh},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Efficient reward poisoning attacks on online deep reinforcement learning},
  url          = {https://openreview.net/forum?id=25G63lDHV2},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A proximal algorithm for sampling. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=CkXOwlhf27">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study sampling problems associated with potentials that lack smoothness. The potentials can be either convex or non-convex. Departing from the standard smooth setting, the potentials are only assumed to be weakly smooth or non-smooth, or the summation of multiple such functions. We develop a sampling algorithm that resembles proximal algorithms in optimization for this challenging sampling task. Our algorithm is based on a special case of Gibbs sampling known as the alternating sampling framework (ASF). The key contribution of this work is a practical realization of the ASF based on rejection sampling for both non-convex and convex potentials that are not necessarily smooth. In almost all the cases of sampling considered in this work, our proximal sampling algorithm achieves a better complexity than all existing methods.},
  archive      = {J_TMLR},
  author       = {Jiaming Liang and Yongxin Chen},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A proximal algorithm for sampling},
  url          = {https://openreview.net/forum?id=CkXOwlhf27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards better generalization with flexible representation
of multi-module graph neural networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=EYjfLeJL4l">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have become compelling models designed to perform learning and inference on graph-structured data. However, little work has been done to understand the fundamental limitations of GNNs for scaling to larger graphs and generalizing to out-of-distribution (OOD) inputs. In this paper, we use a random graph generator to systematically investigate how the graph size and structural properties affect the predictive performance of GNNs. We present specific evidence that the average node degree is a key feature in determining whether GNNs can generalize to unseen graphs, and that the use of multiple node update functions can improve the generalization performance of GNNs when dealing with graphs of multimodal degree distributions. Accordingly, we propose a multi-module GNN framework that allows the network to adapt flexibly to new graphs by generalizing a single canonical nonlinear transformation over aggregated inputs. Our results show that the multi-module GNNs improve the OOD generalization on a variety of inference tasks in the direction of diverse structural features.},
  archive      = {J_TMLR},
  author       = {HyunGeun Lee and Kijung Yoon},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards better generalization with flexible representation of multi-module graph neural networks},
  url          = {https://openreview.net/forum?id=EYjfLeJL4l},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the gradient formula for learning generative models with
regularized optimal transport costs. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=FbztvhdCX9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning a Wasserstein Generative Adversarial Networks (WGAN) requires the differentiation of the optimal transport cost with respect to the parameters of the generative model. In this work, we provide sufficient conditions for the existence of a gradient formula in two different frameworks: the case of semi-discrete optimal transport (i.e. with a discrete target distribution) and the case of regularized optimal transport (i.e. with an entropic penalty). In both cases the gradient formula involves a solution of the semi-dual formulation of the optimal transport cost. Our study makes a connection between the gradient of the WGAN loss function and the Laguerre diagrams associated to semi-discrete transport maps. The learning problem is addressed with an alternating algorithm, which is in general not convergent. However, in most cases, it stabilizes close to a relevant solution for the generative learning problem. We also show that entropic regularization can improve the convergence speed but noticeably changes the shape of the learned generative model.},
  archive      = {J_TMLR},
  author       = {Antoine Houdard and Arthur Leclaire and Nicolas Papadakis and Julien Rabin},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the gradient formula for learning generative models with regularized optimal transport costs},
  url          = {https://openreview.net/forum?id=FbztvhdCX9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Active acquisition for multimodal temporal data: A
challenging decision-making task. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Gbu1bHQhEL">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a challenging decision-making task that we call active acquisition for multimodal temporal data (A2MT). In many real-world scenarios, input features are not readily available at test time and must instead be acquired at significant cost. With A2MT, we aim to learn agents that actively select which modalities of an input to acquire, trading off acquisition cost and predictive performance. A2MT extends a previous task called active feature acquisition to temporal decision making about high-dimensional inputs. We propose a method based on the Perceiver IO architecture to address A2MT in practice. Our agents are able to solve a novel synthetic scenario requiring practically relevant cross-modal reasoning skills. On two large-scale, real-world datasets, Kinetics-700 and AudioSet, our agents successfully learn cost-reactive acquisition behavior. However, an ablation reveals they are unable to learn adaptive acquisition strategies, emphasizing the difficulty of the task even for state-of-the-art models. Applications of A2MT may be impactful in domains like medicine, robotics, or finance, where modalities differ in acquisition cost and informativeness.},
  archive      = {J_TMLR},
  author       = {Jannik Kossen and Cătălina Cangea and Eszter Vértes and Andrew Jaegle and Viorica Patraucean and Ira Ktena and Nenad Tomasev and Danielle Belgrave},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Active acquisition for multimodal temporal data: A challenging decision-making task},
  url          = {https://openreview.net/forum?id=Gbu1bHQhEL},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Understanding self-supervised pretraining with part-aware
representation learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=HP7Qpui5YE">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we are interested in understanding self-supervised pretraining through studying the capability that self-supervised methods learn part-aware representations. The study is mainly motivated by that random views, used in contrastive learning, and random masked (visible) patches, used in masked image modeling, are often about object parts. We explain that contrastive learning is a part-to-whole task: the projection layer hallucinates the whole object representation from the object part representation learned from the encoder, and that masked image modeling is a part-to-part task: the masked patches of the object are hallucinated from the visible patches. The explanation suggests that the self-supervised pretrained encoder leans toward understanding the object part. We empirically compare the off-the-shelf encoders pretrained with several representative methods on object-level recognition and part-level recognition. The results show that the fully-supervised model outperforms self-supervised models for object-level recognition, and most self-supervised contrastive learning and masked image modeling methods outperform the fully-supervised method for part-level recognition. It is observed that the combination of contrastive learning and masked image modeling further improves the performance.},
  archive      = {J_TMLR},
  author       = {Jie Zhu and Jiyang Qi and Mingyu Ding and Xiaokang Chen and Ping Luo and Xinggang Wang and Wenyu Liu and Leye Wang and Jingdong Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Understanding self-supervised pretraining with part-aware representation learning},
  url          = {https://openreview.net/forum?id=HP7Qpui5YE},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Consistent collaborative filtering via tensor decomposition.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=HqIuAzBxbh">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative filtering is the de facto standard for analyzing users’ activities and building recommendation systems for items. In this work we develop Sliced Anti-symmetric Decomposition (SAD), a new model for collaborative filtering based on implicit feedback. In contrast to traditional techniques where a latent representation of users (user vectors) and items (item vectors) are estimated, SAD introduces one additional latent vector to each item, using a novel three-way tensor view of user-item interactions. This new vector extends user-item preferences calculated by standard dot products to general inner products, producing interactions between items when evaluating their relative preferences. SAD reduces to state-of-the-art (SOTA) collaborative filtering models when the vector collapses to 1, while in this paper we allow its value to be estimated from data. Allowing the values of the new item vector to be different from 1 has profound implications. It suggests users may have nonlinear mental models when evaluating items, allowing the existence of cycles in pairwise comparisons. We demonstrate the efficiency of SAD in both simulated and real world datasets containing over 1M user-item interactions. By comparing with seven SOTA collaborative filtering models with implicit feedbacks, SAD produces the most consistent personalized preferences, in the meanwhile maintaining top-level of accuracy in personalized recommendations. We release the model and inference algorithms in a Python library https://github.com/apple/ml-sad.},
  archive      = {J_TMLR},
  author       = {Shiwen Zhao and Guillermo Sapiro},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Consistent collaborative filtering via tensor decomposition},
  url          = {https://openreview.net/forum?id=HqIuAzBxbh},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data augmentation is a hyperparameter: Cherry-picked
self-supervision for unsupervised anomaly detection is creating the
illusion of success. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=HyzCuCV1jH">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised learning (SSL) has emerged as a promising alternative to create supervisory signals to real-world problems, avoiding the extensive cost of manual labeling. SSL is particularly attractive for unsupervised tasks such as anomaly detection (AD), where labeled anomalies are rare or often nonexistent. A large catalog of augmentation functions has been used for SSL-based AD (SSAD) on image data, and recent works have reported that the type of augmentation has a significant impact on accuracy. Motivated by those, this work sets out to put image-based SSAD under a larger lens and investigate the role of data augmentation in SSAD. Through extensive experiments on 3 different detector models and across 420 AD tasks, we provide comprehensive numerical and visual evidences that the alignment between data augmentation and anomaly-generating mechanism is the key to the success of SSAD, and in the lack thereof, SSL may even impair accuracy. To the best of our knowledge, this is the first meta-analysis on the role of data augmentation in SSAD.},
  archive      = {J_TMLR},
  author       = {Jaemin Yoo and Tiancheng Zhao and Leman Akoglu},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Data augmentation is a hyperparameter: Cherry-picked self-supervision for unsupervised anomaly detection is creating the illusion of success},
  url          = {https://openreview.net/forum?id=HyzCuCV1jH},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semantic self-adaptation: Enhancing generalization with a
single sample. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ILNqQhGbLx">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The lack of out-of-domain generalization is a critical weakness of deep networks for semantic segmentation. Previous studies relied on the assumption of a static model, i. e., once the training process is complete, model parameters remain fixed at test time. In this work, we challenge this premise with a self-adaptive approach for semantic segmentation that adjusts the inference process to each input sample. Self-adaptation operates on two levels. First, it fine-tunes the parameters of convolutional layers to the input image using consistency regularization. Second, in Batch Normalization layers, self-adaptation interpolates between the training and the reference distribution derived from a single test sample. Despite both techniques being well known in the literature, their combination sets new state-of-the-art accuracy on synthetic-to-real generalization benchmarks. Our empirical study suggests that self-adaptation may complement the established practice of model regularization at training time for improving deep network generalization to out-of-domain data. Our code and pre-trained models are available at https://github.com/visinf/self-adaptive.},
  archive      = {J_TMLR},
  author       = {Sherwin Bahmani and Oliver Hahn and Eduard Zamfir and Nikita Araslanov and Daniel Cremers and Stefan Roth},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Semantic self-adaptation: Enhancing generalization with a single sample},
  url          = {https://openreview.net/forum?id=ILNqQhGbLx},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On average-case error bounds for kernel-based bayesian
quadrature. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=JJrKbq35l4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study error bounds for Bayesian quadrature (BQ), with an emphasis on noisy settings, randomized algorithms, and average-case performance measures. We seek to approximate the integral of functions in a Reproducing Kernel Hilbert Space (RKHS), particularly focusing on the Mat\&#39;ern-$\nu$ and squared exponential (SE) kernels, with samples from the function potentially being corrupted by Gaussian noise. We provide a two-step meta-algorithm that serves as a general tool for relating the average-case quadrature error with the $L^2$-function approximation error. When specialized to the Mat\&#39;ern kernel, we recover an existing near-optimal error rate while avoiding the existing method of repeatedly sampling points. When specialized to other settings, we obtain new average-case results for settings including the SE kernel with noise and the Mat\&#39;ern kernel with misspecification. Finally, we present algorithm-independent lower bounds that have greater generality and/or give distinct proofs compared to existing ones.},
  archive      = {J_TMLR},
  author       = {Xu Cai and Thanh Lam and Jonathan Scarlett},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On average-case error bounds for kernel-based bayesian quadrature},
  url          = {https://openreview.net/forum?id=JJrKbq35l4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mind the gap: Mitigating the distribution gap in graph
few-shot learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=LEVbhNrLEL">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prevailing supervised deep graph learning models often suffer from the issue of label scarcity, leading to performance degradation in the face of limited annotated data. Although numerous graph few-shot learning (GFL) methods have been developed to mitigate this problem, they tend to rely excessively on labeled data. This over-reliance on labeled data can result in impaired generalization ability in the test phase due to the existence of a distribution gap. Moreover, existing GFL methods lack a general purpose as their designs are coupled with task or data-specific characteristics. To address these shortcomings, we propose a novel Self-Distilled Graph Few-shot Learning framework (SDGFL) that is both general and effective. SDGFL leverages a self-distilled contrastive learning procedure to boost GFL. Specifically, our model first pre-trains a graph encoder with contrastive learning using unlabeled data. Later, the trained encoder is frozen as a teacher model to distill a student model with a contrastive loss. The distilled model is then fed to GFL. By learning data representation in a self-supervised manner, SDGFL effectively mitigates the distribution gap and enhances generalization ability. Furthermore, our proposed framework is task and data-independent, making it a versatile tool for general graph mining purposes. To evaluate the effectiveness of our proposed framework, we introduce an information-based measurement that quantifies its capability. Through comprehensive experiments, we demonstrate that SDGFL outperforms state-of-the-art baselines on various graph mining tasks across multiple datasets in the few-shot scenario. We also provide a quantitative measurement of SDGFL’s superior performance in comparison to existing methods.},
  archive      = {J_TMLR},
  author       = {Chunhui Zhang and Hongfu Liu and Jundong Li and Yanfang Ye and Chuxu Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Mind the gap: Mitigating the distribution gap in graph few-shot learning},
  url          = {https://openreview.net/forum?id=LEVbhNrLEL},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Calibrating and improving graph contrastive learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=LdSP6cvTS4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive learning algorithms have demonstrated remarkable success in various applications such as node classification, link prediction, and graph clustering. However, in unsupervised graph contrastive learning, some contrastive pairs may contradict the truths in downstream tasks and thus the decrease of losses on these pairs undesirably harms the performance in the downstream tasks. To assess the discrepancy between the prediction and the ground-truth in the downstream tasks for these contrastive pairs, we adapt expected calibration error (ECE) to graph contrastive learning. The analysis of ECE motivates us to propose a novel regularization method, Contrast-Reg, to ensure that decreasing the contrastive loss leads to better performance in the downstream tasks. As a plug-in regularizer, Contrast-Reg effectively improves the performance of existing graph contrastive learning algorithms. We provide both theoretical and empirical results to demonstrate the effectiveness of Contrast-Reg in enhancing the generalizability of the Graph Neural Network (GNN) model and improving the performance of graph contrastive algorithms with different similarity definitions and encoder backbones across various downstream tasks.},
  archive      = {J_TMLR},
  author       = {MA KAILI and Garry YANG and Han Yang and Yongqiang Chen and James Cheng},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Calibrating and improving graph contrastive learning},
  url          = {https://openreview.net/forum?id=LdSP6cvTS4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). JiangJun: Mastering xiangqi by tackling non-transitivity in
two-player zero-sum games. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=MMsyqXIJuk">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an empirical exploration of non-transitivity in perfect-information games, specifically focusing on Xiangqi, a traditional Chinese board game comparable in game-tree complexity to chess and shogi. By analyzing over 10,000 records of human Xiangqi play, we highlight the existence of both transitive and non-transitive elements within the game’s strategic structure. To address non-transitivity, we introduce the JiangJun algorithm, an innovative combination of Monte-Carlo Tree Search (MCTS) and Policy Space Response Oracles (PSRO) designed to approximate a Nash equilibrium. We evaluate the algorithm empirically using a WeChat mini program and achieve a Master level with a 99.41% win rate against human players. The algorithm’s effectiveness in overcoming non-transitivity is confirmed by a plethora of metrics, such as relative population performance and visualization results. Our project site is available at https://sites.google.com/view/jiangjun-site/.},
  archive      = {J_TMLR},
  author       = {Yang Li and Kun Xiong and Yingping Zhang and Jiangcheng Zhu and Stephen Marcus McAleer and Wei Pan and Jun Wang and Zonghong Dai and Yaodong Yang},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {JiangJun: Mastering xiangqi by tackling non-transitivity in two-player zero-sum games},
  url          = {https://openreview.net/forum?id=MMsyqXIJuk},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards a more rigorous science of blindspot discovery in
image classification models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=MaDvbLaBiF">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A growing body of work studies Blindspot Discovery Methods (&quot;BDM&quot;s): methods that use an image embedding to find semantically meaningful (i.e., united by a human-understandable concept) subsets of the data where an image classifier performs significantly worse. Motivated by observed gaps in prior work, we introduce a new framework for evaluating BDMs, SpotCheck, that uses synthetic image datasets to train models with known blindspots and a new BDM, PlaneSpot, that uses a 2D image representation. We use SpotCheck to run controlled experiments that identify factors that influence BDM performance (e.g., the number of blindspots in a model, or features used to define the blindspot) and show that PlaneSpot is competitive with and in many cases outperforms existing BDMs. Importantly, we validate these findings by designing additional experiments that use real image data from MS-COCO, a large image benchmark dataset. Our findings suggest several promising directions for future work on BDM design and evaluation. Overall, we hope that the methodology and analyses presented in this work will help facilitate a more rigorous science of blindspot discovery.},
  archive      = {J_TMLR},
  author       = {Gregory Plumb and Nari Johnson and Angel Cabrera and Ameet Talwalkar},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards a more rigorous science of blindspot discovery in image classification models},
  url          = {https://openreview.net/forum?id=MaDvbLaBiF},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fair kernel regression through cross-covariance operators.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=MyQ1e1VQQ3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring fairness in machine learning models is a difficult problem from both a formulation and implementation perspective. One sensible criterion for achieving fairness is Equalised Odds, which requires that subjects in protected and unprotected groups have equal true and false positive rates. However, practical implementation is challenging. This work proposes two ways to address this issue through the conditional independence operator. First, given the output values, it is used as a fairness measure of independence between model predictions and sensitive variables. Second, it is used as a regularisation term in the problem formulation, which seeks optimal models that balance performance and fairness concerning the sensitive variables. To illustrate the potential of our approach, we consider different scenarios. First, we use the Gaussian model to provide new insights into the problem formulation and numerical results on its convergence. Second, we present the formulation using the conditional cross-covariance operator. We anticipate that a closed-form solution is possible in the general problem formulation, including in the case of a kernel formulation setting. Third, we introduce a normalised criterion of the conditional independence operator. All formulations are posed under the risk minimisation principle, which leads to theoretical results on the performance. Additionally, insights are provided into using these operators under a Gaussian Process setting. Our methods are compared to state-of-the-art methods in terms of performance and fairness metrics on a representative set of real problems. The results obtained with our proposed methodology show promising performance-fairness curves. Furthermore, we discuss the usefulness of linear weights in the fair model to describe the behaviour of the features when enforcing fairness over a particular set of input features.},
  archive      = {J_TMLR},
  author       = {Adrian Perez-Suay and Paula Gordaliza and Jean-Michel Loubes and Dino Sejdinovic and Gustau Camps-Valls},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Fair kernel regression through cross-covariance operators},
  url          = {https://openreview.net/forum?id=MyQ1e1VQQ3},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contextual combinatorial multi-output GP bandits with group
constraints. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=OqbGu3hdQb">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In federated multi-armed bandit problems, maximizing global reward while satisfying minimum privacy requirements to protect clients is the main goal. To formulate such problems, we consider a combinatorial contextual bandit setting with groups and changing action sets, where similar base arms arrive in groups and a set of base arms, called a super arm, must be chosen in each round to maximize super arm reward while satisfying the constraints of the rewards of groups from which base arms were chosen. To allow for greater flexibility, we let each base arm have two outcomes, modeled as the output of a two-output Gaussian process (GP), where one outcome is used to compute super arm reward and the other for group reward. We then propose a novel double-UCB GP-bandit algorithm, called Thresholded Combinatorial Gaussian Process Upper Confidence Bounds (TCGP-UCB), which balances between maximizing cumulative super arm reward and satisfying group reward constraints and can be tuned to prefer one over the other. We also define a new notion of regret that combines super arm regret with group reward constraint satisfaction and prove that TCGP-UCB incurs $\tilde{O}(\sqrt{KT\overline{\gamma}_{T}} )$ regret with high probability, where $\overline{\gamma}_{T}$ is the maximum information gain associated with the set of base arm contexts that appeared in the first $T$ rounds and $K$ is the maximum super arm cardinality over all rounds. We lastly show in experiments using synthetic and real-world data and based on a federated learning setup as well as a content-recommendation one that our algorithm performs better then the current non-GP state-of-the-art combinatorial bandit algorithm, while satisfying group constraints.},
  archive      = {J_TMLR},
  author       = {Sepehr Elahi and Baran Atalar and Sevda Öğüt and Cem Tekin},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Contextual combinatorial multi-output GP bandits with group constraints},
  url          = {https://openreview.net/forum?id=OqbGu3hdQb},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adjusting machine learning decisions for equal opportunity
and counterfactual fairness. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=P6NcRPb13w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) methods have the potential to automate high-stakes decisions, such as bail admissions or credit lending, by analyzing and learning from historical data. But these algorithmic decisions may be unfair: in learning from historical data, they may replicate discriminatory practices from the past. In this paper, we propose two algorithms that adjust fitted ML predictors to produce decisions that are fair. Our methods provide post-hoc adjustments to the predictors, without requiring that they be retrained. We consider a causal model of the ML decisions, define fairness through counterfactual decisions within the model, and then form algorithmic decisions that capture the historical data as well as possible but are provably fair. In particular, we consider two definitions of fairness. The first is ``equal counterfactual opportunity,&#39;&#39; where the counterfactual distribution of the decision is the same regardless of the protected attribute; the second is counterfactual fairness. We evaluate the algorithms, and the trade-off between accuracy and fairness, on datasets about admissions, income, credit, and recidivism.},
  archive      = {J_TMLR},
  author       = {Yixin Wang and Dhanya Sridhar and David Blei},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Adjusting machine learning decisions for equal opportunity and counterfactual fairness},
  url          = {https://openreview.net/forum?id=P6NcRPb13w},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The open MatSci ML toolkit: A flexible framework for machine
learning in materials science. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=QBMyDZsPMd">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the Open MatSci ML Toolkit: a flexible, self-contained, and scalable Python-based framework to apply deep learning models and methods on scientific data with a specific focus on materials science and the OpenCatalyst Dataset. Our toolkit provides: 1. A scalable machine learning workflow for materials science leveraging PyTorch Lightning, which enables seamless scaling across different computation capabilities (laptop, server, cluster) and hardware platforms (CPU, GPU, XPU). 2. Deep Graph Library (DGL) support for rapid graph neural network prototyping and development. By publishing and sharing this toolkit with the research community via open-source release, we hope to: 1. Lower the entry barrier for new machine learning researchers and practitioners that want to get started with the OpenCatalyst dataset, which presently comprises the largest computational materials science dataset. 2. Enable the scientific community to apply advanced machine learning tools to high-impact scientific challenges, such as modeling of materials behavior for clean energy applications. We demonstrate the capabilities of our framework by enabling three new equivariant neural network models for multiple OpenCatalyst tasks and arrive at promising results for compute scaling and model performance. The code of the framework and experiments presented in this is paper are publicly available at https://github.com/IntelLabs/matsciml.},
  archive      = {J_TMLR},
  author       = {Santiago Miret and Kin Long Kelvin Lee and Carmelo Gonzales and Marcel Nassar and Matthew Spellings},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The open MatSci ML toolkit: A flexible framework for machine learning in materials science},
  url          = {https://openreview.net/forum?id=QBMyDZsPMd},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved group robustness via classifier retraining on
independent splits. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Qlvgq9eC63">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks trained by minimizing the average risk can achieve strong average performance. Still, their performance for a subgroup may degrade if the subgroup is underrepresented in the overall data population. Group distributionally robust optimization (Sagawa et al., 2020a), or group DRO in short, is a widely used baseline for learning models with strong worst-group performance. We note that this method requires group labels for every example at training time and can overfit to small groups, requiring strong regularization. Given a limited amount of group labels at training time, Just Train Twice (Liu et al., 2021), or JTT in short, is a two-stage method that infers a pseudo group label for every unlabeled example first, then applies group DRO based on the inferred group labels. The inference process is also sensitive to overfitting, sometimes involving additional hyperparameters. This paper designs a simple method based on the idea of classifier retraining on independent splits of the training data. We find that using a novel sample-splitting procedure achieves robust worst-group performance in the fine-tuning step. When evaluated on benchmark image and text classification tasks, our approach consistently performs favorably to group DRO, JTT, and other strong baselines when either group labels are available during training or are only given in validation sets. Importantly, our method only relies on a single hyperparameter, which adjusts the fraction of labels used for training feature extractors vs. training classification layers. We justify the rationale of our splitting scheme with a generalization-bound analysis of the worst-group loss.},
  archive      = {J_TMLR},
  author       = {Thien Hang Nguyen and Hongyang R. Zhang and Huy Nguyen},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Improved group robustness via classifier retraining on independent splits},
  url          = {https://openreview.net/forum?id=Qlvgq9eC63},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DSpar: An embarrassingly simple strategy for efficient GNN
training and inference via degree-based sparsification. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=SaVEXFuozg">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Running Graph Neural Networks (GNNs) on large graphs suffers from notoriously inefficiency. This is attributed to the sparse graph-based operations, which is hard to be accelerated by community hardware, e.g., GPUs and CPUs. One potential solution is to ``sketch&#39;&#39; the original graph by removing unimportant edges, then both the training and inference process are executed on the sparsified graph with improved efficiency. Traditional graph sparsification work calculates the edge importance score, i.e., effective resistance, from graph topology with theoretical guarantee. However, estimating effective resistance is even more expensive than training GNNs itself. Later, learning-based sparsification methods propose to learn the edge importance from data, but with significant overhead due to the extra learning process. Thus, both of them introduce significant ahead-of-training overhead. In this paper, we experimentally and theoretically prove that effective resistance can be approximated using only the node degree information and achieve similar node presentations on graph with/without sparsification. Based on this finding, we propose DSpar, to sparsify the graph once before training based on only the node degree information with negligible ahead-of-training overhead. In practice, for the training phase, DSpar achieves up to $5.9\times$ faster than baseline with almost no accuracy drop. For the inference phase, DSpar reduces up to $90\%$ latency.},
  archive      = {J_TMLR},
  author       = {Zirui Liu and Kaixiong Zhou and Zhimeng Jiang and Li Li and Rui Chen and Soo-Hyun Choi and Xia Hu},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DSpar: An embarrassingly simple strategy for efficient GNN training and inference via degree-based sparsification},
  url          = {https://openreview.net/forum?id=SaVEXFuozg},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bayesian quadrature for neural ensemble search.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=T5sXdAO3EQ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensembling can improve the performance of Neural Networks, but existing approaches struggle when the architecture likelihood surface has dispersed, narrow peaks. Furthermore, existing methods construct equally weighted ensembles, and this is likely to be vulnerable to the failure modes of the weaker architectures. By viewing ensembling as approximately marginalising over architectures we construct ensembles using the tools of Bayesian Quadrature -- tools which are well suited to the exploration of likelihood surfaces with dispersed, narrow peaks. Additionally, the resulting ensembles consist of architectures weighted commensurate with their performance. We show empirically -- in terms of test likelihood, accuracy, and expected calibration error -- that our method outperforms state-of-the-art baselines, and verify via ablation studies that its components do so independently.},
  archive      = {J_TMLR},
  author       = {Saad Hamid and Xingchen Wan and Martin Jørgensen and Binxin Ru and Michael A Osborne},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bayesian quadrature for neural ensemble search},
  url          = {https://openreview.net/forum?id=T5sXdAO3EQ},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TabCBM: Concept-based interpretable neural networks for
tabular data. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=TIsrnWpjQ0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concept-based interpretability addresses the opacity of deep neural networks by constructing an explanation for a model&#39;s prediction using high-level units of information referred to as concepts. Research in this area, however, has been mainly focused on image and graph-structured data, leaving high-stakes tasks whose data is tabular out of reach of existing methods. In this paper, we address this gap by introducing the first definition of what a high-level concept may entail in tabular data. We use this definition to propose Tabular Concept Bottleneck Models (TabCBMs), a family of interpretable self-explaining neural architectures capable of learning high-level concept explanations for tabular tasks. As our method produces concept-based explanations both when partial concept supervision or no concept supervision is available at training time, it is adaptable to settings where concept annotations are missing. We evaluate our method in both synthetic and real-world tabular tasks and show that TabCBM outperforms or performs competitively compared to state-of-the-art methods, while providing a high level of interpretability as measured by its ability to discover known high-level concepts. Finally, we show that TabCBM can discover important high-level concepts in synthetic datasets inspired by critical tabular tasks (e.g., single-cell RNAseq) and allows for human-in-the-loop concept interventions in which an expert can identify and correct mispredicted concepts to boost the model&#39;s performance.},
  archive      = {J_TMLR},
  author       = {Mateo Espinosa Zarlenga and Zohreh Shams and Michael Edward Nelson and Been Kim and Mateja Jamnik},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {TabCBM: Concept-based interpretable neural networks for tabular data},
  url          = {https://openreview.net/forum?id=TIsrnWpjQ0},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised graph representation learning for neuronal
morphologies. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ThhMzfrd6r">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised graph representation learning has recently gained interest in several application domains such as neuroscience, where modeling the diverse morphology of cell types in the brain is one of the key challenges. It is currently unknown how many excitatory cortical cell types exist and what their defining morphological features are. Here we present GraphDINO, a purely data-driven approach to learn low-dimensional representations of 3D neuronal morphologies from unlabeled large-scale datasets. GraphDINO is a novel transformer-based representation learning method for spatially-embedded graphs. To enable self-supervised learning on transformers, we (1) developed data augmentation strategies for spatially-embedded graphs, (2) adapted the positional encoding and (3) introduced a novel attention mechanism, AC-Attention, which combines attention-based global interaction between nodes and classic graph convolutional processing. We show, in two different species and across multiple brain areas, that this method yields morphological cell type clusterings that are on par with manual feature-based classification by experts, but without using prior knowledge about the structural features of neurons. Moreover, it outperforms previous approaches on quantitative benchmarks predicting expert labels. Our method could potentially enable data-driven discovery of novel morphological features and cell types in large-scale datasets. It is applicable beyond neuroscience in settings where samples in a dataset are graphs and graph-level embeddings are desired.},
  archive      = {J_TMLR},
  author       = {Marissa A. Weis and Laura Pede and Timo Lüddecke and Alexander S Ecker},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Self-supervised graph representation learning for neuronal morphologies},
  url          = {https://openreview.net/forum?id=ThhMzfrd6r},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lifelong reinforcement learning with modulating masks.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=V7tahqGrOq">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lifelong learning aims to create AI systems that continuously and incrementally learn during a lifetime, similar to biological learning. Attempts so far have met problems, including catastrophic forgetting, interference among tasks, and the inability to exploit previous knowledge. While considerable research has focused on learning multiple supervised classification tasks that involve changes in the input distribution, lifelong reinforcement learning (LRL) must deal with variations in the state and transition distributions, and in the reward functions. Modulating masks with a fixed backbone network, recently developed for classification, are particularly suitable to deal with such a large spectrum of task variations. In this paper, we adapted modulating masks to work with deep LRL, specifically PPO and IMPALA agents. The comparison with LRL baselines in both discrete and continuous RL tasks shows superior performance. We further investigated the use of a linear combination of previously learned masks to exploit previous knowledge when learning new tasks: not only is learning faster, the algorithm solves tasks that we could not otherwise solve from scratch due to extremely sparse rewards. The results suggest that RL with modulating masks is a promising approach to lifelong learning, to the composition of knowledge to learn increasingly complex tasks, and to knowledge reuse for efficient and faster learning.},
  archive      = {J_TMLR},
  author       = {Eseoghene Ben-Iwhiwhu and Saptarshi Nath and Praveen Kumar Pilly and Soheil Kolouri and Andrea Soltoggio},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Lifelong reinforcement learning with modulating masks},
  url          = {https://openreview.net/forum?id=V7tahqGrOq},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Breaking the spurious causality of conditional generation
via fairness intervention with corrective sampling. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=VV4zJwLwI7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trying to capture the sample-label relationship, conditional generative models often end up inheriting the spurious correlation in the training dataset, giving label-conditional distributions that are severely imbalanced in another latent attribute. To mitigate such undesirable correlations engraved into generative models, which we call spurious causality, we propose a general two-step strategy. (a) Fairness Intervention (FI): Emphasize the minority samples that are hard to be generated due to the spurious correlation in the training dataset. (b) Corrective Sampling (CS): Filter the generated samples explicitly to follow the desired label-conditional latent attribute distribution. We design the fairness intervention for various degrees of supervision on the spurious attribute, including unsupervised, weakly-supervised, and semi-supervised scenarios. Our experimental results show that the proposed FICS can successfully resolve the spurious correlation in generated samples on various datasets.},
  archive      = {J_TMLR},
  author       = {Junhyun Nam and Sangwoo Mo and Jaeho Lee and Jinwoo Shin},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Breaking the spurious causality of conditional generation via fairness intervention with corrective sampling},
  url          = {https://openreview.net/forum?id=VV4zJwLwI7},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stochastic constrained DRO with a complexity independent of
sample size. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=VpaXrBFYZ9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributionally Robust Optimization (DRO), as a popular method to train robust models against distribution shift between training and test sets, has received tremendous attention in recent years. In this paper, we propose and analyze stochastic algorithms that apply to both non-convex and convex losses for solving Kullback–Leibler divergence constrained DRO problem. Compared with existing methods solving this problem, our stochastic algorithms not only enjoy competitive if not better complexity independent of sample size but also just require a constant batch size at every iteration, which is more practical for broad applications. We establish a nearly optimal complexity bound for finding an $\epsilon$-stationary solution for non-convex losses and an optimal complexity for finding an $\epsilon$-optimal solution for convex losses. Empirical studies demonstrate the effectiveness of the proposed algorithms for solving non-convex and convex constrained DRO problems.},
  archive      = {J_TMLR},
  author       = {Qi Qi and Jiameng Lyu and Kung-Sik Chan and Er-Wei Bai and Tianbao Yang},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Stochastic constrained DRO with a complexity independent of sample size},
  url          = {https://openreview.net/forum?id=VpaXrBFYZ9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Conditional generative models are provably robust: Pointwise
guarantees for bayesian inverse problems. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Wcui061fxr">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional generative models became a very powerful tool to sample from Bayesian inverse problem posteriors. It is well-known in classical Bayesian literature that posterior measures are quite robust with respect to perturbations of both the prior measure and the negative log-likelihood, which includes perturbations of the observations. However, to the best of our knowledge, the robustness of conditional generative models with respect to perturbations of the observations has not been investigated yet. In this paper, we prove for the first time that appropriately learned conditional generative models provide robust results for single observations.},
  archive      = {J_TMLR},
  author       = {Fabian Altekrüger and Paul Hagemann and Gabriele Steidl},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Conditional generative models are provably robust: Pointwise guarantees for bayesian inverse problems},
  url          = {https://openreview.net/forum?id=Wcui061fxr},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Off-policy evaluation with out-of-sample guarantees.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=XnYtGPgG9p">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of evaluating the performance of a decision policy using past observational data. The outcome of a policy is measured in terms of a loss (aka. disutility or negative reward) and the main problem is making valid inferences about its out-of-sample loss when the past data was observed under a different and possibly unknown policy. Using a sample-splitting method, we show that it is possible to draw such inferences with finite-sample coverage guarantees about the entire loss distribution, rather than just its mean. Importantly, the method takes into account model misspecifications of the past policy - including unmeasured confounding. The evaluation method can be used to certify the performance of a policy using observational data under a specified range of credible model assumptions.},
  archive      = {J_TMLR},
  author       = {Sofia Ek and Dave Zachariah and Fredrik D. Johansson and Peter Stoica},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Off-policy evaluation with out-of-sample guarantees},
  url          = {https://openreview.net/forum?id=XnYtGPgG9p},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervision is all you need for solving rubik’s cube.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=bnBeNFB27b">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing combinatorial search methods are often complex and require some level of expertise. This work introduces a simple and efficient deep learning method for solving combinatorial problems with a predefined goal, represented by Rubik&#39;s Cube. We demonstrate that, for such problems, training a deep neural network on random scrambles branching from the goal state is sufficient to achieve near-optimal solutions. When tested on Rubik&#39;s Cube, 15 Puzzle, and 7$\times$7 Lights Out, our method outperformed the previous state-of-the-art method DeepCubeA, improving the trade-off between solution optimality and computational cost, despite significantly less training data. Furthermore, we investigate the scaling law of our Rubik&#39;s Cube solver with respect to model size and training data volume.},
  archive      = {J_TMLR},
  author       = {Kyo Takano},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Self-supervision is all you need for solving rubik’s cube},
  url          = {https://openreview.net/forum?id=bnBeNFB27b},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). POMRL: No-regret learning-to-plan with increasing horizons.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=brGgOAXYtr">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of planning under model uncertainty in an online meta-reinforcement learning (RL) setting where an agent is presented with a sequence of related tasks with limited interactions per task. The agent can use its experience in each task and across tasks to estimate both the transition model and the distribution over tasks. We propose an algorithm to meta-learn the underlying relatedness across tasks, utilize it to plan in each task, and upper-bound the regret of the planning loss. Our bound suggests that the average regret over tasks decreases as the number of tasks increases and as the tasks are more similar. In the classical single-task setting, it is known that the planning horizon should depend on the estimated model&#39;s accuracy, that is, on the number of samples within task. We generalize this finding to meta-RL and study this dependence of planning horizons on the number of tasks. Based on our theoretical findings, we derive heuristics for selecting slowly increasing discount factors, and we validate its significance empirically.},
  archive      = {J_TMLR},
  author       = {Khimya Khetarpal and Claire Vernade and Brendan O&#39;Donoghue and Satinder Singh and Tom Zahavy},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {POMRL: No-regret learning-to-plan with increasing horizons},
  url          = {https://openreview.net/forum?id=brGgOAXYtr},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The score-difference flow for implicit generative modeling.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=dpGSNLUCzu">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implicit generative modeling (IGM) aims to produce samples of synthetic data matching the characteristics of a target data distribution. Recent work (e.g. score-matching networks, diffusion models) has approached the IGM problem from the perspective of pushing synthetic source data toward the target distribution via dynamical perturbations or flows in the ambient space. In this direction, we present the score difference (SD) between arbitrary target and source distributions as a flow that optimally reduces the Kullback-Leibler divergence between them while also solving the Schrödinger bridge problem. We apply the SD flow to convenient proxy distributions, which are aligned if and only if the original distributions are aligned. We demonstrate the formal equivalence of this formulation to denoising diffusion models under certain conditions. We also show that the training of generative adversarial networks includes a hidden data-optimization sub-problem, which induces the SD flow under certain choices of loss function when the discriminator is optimal. As a result, the SD flow provides a theoretical link between model classes that individually address the three challenges of the &quot;generative modeling trilemma&quot;—high sample quality, mode coverage, and fast sampling—thereby setting the stage for a unified approach.},
  archive      = {J_TMLR},
  author       = {Romann M. Weber},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The score-difference flow for implicit generative modeling},
  url          = {https://openreview.net/forum?id=dpGSNLUCzu},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A characteristic function for shapley-value-based
attribution of anomaly scores. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=eLX5XrajXh">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In anomaly detection, the degree of irregularity is often summarized as a real-valued anomaly score. We address the problem of attributing such anomaly scores to input features for interpreting the results of anomaly detection. We particularly investigate the use of the Shapley value for attributing anomaly scores of semi-supervised detection methods. We propose a characteristic function specifically designed for attributing anomaly scores. The idea is to approximate the absence of some features by locally minimizing the anomaly score with regard to the to-be-absent features. We examine the applicability of the proposed characteristic function and other general approaches for interpreting anomaly scores on multiple datasets and multiple anomaly detection methods. The results indicate the potential utility of the attribution methods including the proposed one.},
  archive      = {J_TMLR},
  author       = {Naoya Takeishi and Yoshinobu Kawahara},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A characteristic function for shapley-value-based attribution of anomaly scores},
  url          = {https://openreview.net/forum?id=eLX5XrajXh},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contrastive attraction and contrastive repulsion for
representation learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=f39UIDkwwc">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive learning (CL) methods effectively learn data representations in a self-supervision manner, where the encoder contrasts each positive sample over multiple negative samples via a one-vs-many softmax cross-entropy loss. By leveraging large amounts of unlabeled image data, recent CL methods have achieved promising results when pretrained on large-scale datasets, such as ImageNet. However, most of them consider the augmented views from the same instance are positive pairs, while views from other instances are negative ones. Such binary partition insufficiently considers the relation between samples and tends to yield worse performance when generalized on images in the wild. In this paper, to further improve the performance of CL and enhance its robustness on various datasets, we propose a doubly CL strategy that contrasts positive samples and negative ones within themselves separately. We realize this strategy with contrastive attraction and contrastive repulsion (CACR), which makes the query not only exert a greater force to attract more distant positive samples but also do so to repel closer negative samples. Theoretical analysis reveals that CACR generalizes CL&#39;s behavior by positive attraction and negative repulsion. It further considers the intra-contrastive relation within the positive and negative pairs to narrow the gap between the sampled and true distribution, which is important when datasets are less curated. Extensive large-scale experiments on standard vision tasks show that CACR not only consistently outperforms existing CL methods on benchmark datasets, but also shows better robustness when generalized on imbalanced image datasets.},
  archive      = {J_TMLR},
  author       = {Huangjie Zheng and Xu Chen and Jiangchao Yao and Hongxia Yang and Chunyuan Li and Ya Zhang and Hao Zhang and Ivor Tsang and Jingren Zhou and Mingyuan Zhou},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Contrastive attraction and contrastive repulsion for representation learning},
  url          = {https://openreview.net/forum?id=f39UIDkwwc},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Black-box batch active learning for regression.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=fvEvDlKko6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Batch active learning is a popular approach for efficiently training machine learning models on large, initially unlabelled datasets by repeatedly acquiring labels for batches of data points. However, many recent batch active learning methods are white-box approaches and are often limited to differentiable parametric models: they score unlabeled points using acquisition functions based on model embeddings or first- and second-order derivatives. In this paper, we propose black-box batch active learning for regression tasks as an extension of white-box approaches. Crucially, our method only relies on model predictions. This approach is compatible with a wide range of machine learning models, including regular and Bayesian deep learning models and non-differentiable models such as random forests. It is rooted in Bayesian principles and utilizes recent kernel-based approaches. This allows us to extend a wide range of existing state-of-the-art white-box batch active learning methods (BADGE, BAIT, LCMD) to black-box models. We demonstrate the effectiveness of our approach through extensive experimental evaluations on regression datasets, achieving surprisingly strong performance compared to white-box approaches for deep learning models.},
  archive      = {J_TMLR},
  author       = {Andreas Kirsch},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Black-box batch active learning for regression},
  url          = {https://openreview.net/forum?id=fvEvDlKko6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The vendi score: A diversity evaluation metric for machine
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=g97OHbQyk1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diversity is an important criterion for many areas of machine learning (ML), including generative modeling and dataset curation. However, existing metrics for measuring diversity are often domain-specific and limited in flexibility. In this paper we address the diversity evaluation problem by proposing the Vendi Score, which connects and extends ideas from ecology and quantum statistical mechanics to ml. The Vendi Score is defined as the exponential of the Shannon entropy of the eigenvalues of a similarity matrix. This matrix is induced by a user-defined similarity function applied to the sample to be evaluated for diversity. In taking a similarity function as input, the Vendi Score enables its user to specify any desired form of diversity. Importantly, unlike many existing metrics in ML, the Vendi Score does not require a reference dataset or distribution over samples or labels, it is therefore general and applicable to any generative model, decoding algorithm, and dataset from any domain where similarity can be defined. We showcase the Vendi Score on molecular generative modeling where we found it addresses shortcomings of the current diversity metric of choice in that domain. We also applied the Vendi Score to generative models of images and decoding algorithms of text where we found it confirms known results about diversity in those domains. Furthermore, we used the Vendi Score to measure mode collapse, a known shortcoming of generative adversarial networks (GANs). In particular, the Vendi Score revealed that even GANs that capture all the modes of a labelled dataset can be less diverse than the original dataset. Finally, the interpretability of the Vendi Score allowed us to diagnose several benchmark ML datasets for diversity, opening the door for diversity-informed data augmentation.},
  archive      = {J_TMLR},
  author       = {Dan Friedman and Adji Bousso Dieng},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The vendi score: A diversity evaluation metric for machine learning},
  url          = {https://openreview.net/forum?id=g97OHbQyk1},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spectral learning of bernoulli linear dynamical systems
models for decision-making. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=giw2vcAhiH">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Latent linear dynamical systems with Bernoulli observations provide a powerful modeling framework for identifying the temporal dynamics underlying binary time series data, which arise in a variety of contexts such as binary decision-making and discrete stochastic processes such as binned neural spike trains. Here we develop a spectral learning method for fast, efficient fitting of probit-Bernoulli latent linear dynamical system (LDS) models. Our approach extends traditional subspace identification methods to the Bernoulli setting via a transformation of the first and second sample moments. This results in a robust, fixed-cost estimator that avoids the hazards of local optima and the long computation time of iterative fitting procedures like the expectation-maximization (EM) algorithm. In regimes where data is limited or assumptions about the statistical structure of the data are not met, we demonstrate that the spectral estimate provides a good initialization for Laplace-EM fitting. Finally, we show that the estimator provides substantial benefits to real world settings by analyzing data from mice performing a sensory decision-making task.},
  archive      = {J_TMLR},
  author       = {Iris R Stone and Yotam Sagiv and Il Memming Park and Jonathan W. Pillow},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Spectral learning of bernoulli linear dynamical systems models for decision-making},
  url          = {https://openreview.net/forum?id=giw2vcAhiH},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finding and only finding differential nash equilibria by
both pretending to be a follower. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=igdWKxK5RZ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding Nash equilibria in two-player differentiable games is a classical problem in game theory with important relevance in machine learning. We propose double Follow-the-Ridge (double-FTR), an algorithm that locally converges to and only to differential Nash equilibria in general-sum two-player differentiable games. To our knowledge, double-FTR is the first algorithm with such guarantees for general-sum games. Furthermore, we show that by varying its preconditioner, double-FTR leads to a broader family of algorithms with the same convergence guarantee. In addition, double-FTR avoids oscillation near equilibria due to the real-eigenvalues of its Jacobian at fixed points. Empirically, we validate the double-FTR algorithm on a range of simple zero-sum and general sum games, as well as simple Generative Adversarial Network (GAN) tasks.},
  archive      = {J_TMLR},
  author       = {Xuchan Bao and Guodong Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Finding and only finding differential nash equilibria by both pretending to be a follower},
  url          = {https://openreview.net/forum?id=igdWKxK5RZ},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The meta-evaluation problem in explainable AI: Identifying
reliable estimators with MetaQuantus. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=j3FK00HyfU">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the unsolved challenges in the field of Explainable AI (XAI) is determining how to most reliably estimate the quality of an explanation method in the absence of ground truth explanation labels. Resolving this issue is of utmost importance as the evaluation outcomes generated by competing evaluation methods (or ``quality estimators&#39;&#39;), which aim at measuring the same property of an explanation method, frequently present conflicting rankings. Such disagreements can be challenging for practitioners to interpret, thereby complicating their ability to select the best-performing explanation method. We address this problem through a meta-evaluation of different quality estimators in XAI, which we define as ``the process of evaluating the evaluation method&#39;&#39;. Our novel framework, MetaQuantus, analyses two complementary performance characteristics of a quality estimator: its resilience to noise and reactivity to randomness, thus circumventing the need for ground truth labels. We demonstrate the effectiveness of our framework through a series of experiments, targeting various open questions in XAI such as the selection and hyperparameter optimisation of quality estimators. Our work is released under an open-source license (https://github.com/annahedstroem/MetaQuantus) to serve as a development tool for XAI- and Machine Learning (ML) practitioners to verify and benchmark newly constructed quality estimators in a given explainability context. With this work, we provide the community with clear and theoretically-grounded guidance for identifying reliable evaluation methods, thus facilitating reproducibility in the field.},
  archive      = {J_TMLR},
  author       = {Anna Hedström and Philine Lou Bommer and Kristoffer Knutsen Wickstrøm and Wojciech Samek and Sebastian Lapuschkin and Marina MC Höhne},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The meta-evaluation problem in explainable AI: Identifying reliable estimators with MetaQuantus},
  url          = {https://openreview.net/forum?id=j3FK00HyfU},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Augmented language models: A survey. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=jh7wH2AzKK">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This survey reviews works in which language models (LMs) are augmented with reasoning skills and the ability to use tools. The former is defined as decomposing a potentially complex task into simpler subtasks while the latter consists in calling external modules such as a code interpreter. LMs can leverage these augmentations separately or in combination via heuristics, or learn to do so from demonstrations. While adhering to a standard missing tokens prediction objective, such augmented LMs can use various, possibly non-parametric external modules to expand their context processing ability, thus departing from the pure language modeling paradigm. We therefore refer to them as Augmented Language Models (ALMs). The missing token objective allows ALMs to learn to reason, use tools, and even act, while still performing standard natural language tasks and even outperforming most regular LMs on several benchmarks. In this work, after reviewing current advance in ALMs, we conclude that this new research direction has the potential to address common limitations of traditional LMs such as interpretability, consistency, and scalability issues.},
  archive      = {J_TMLR},
  author       = {Grégoire Mialon and Roberto Dessi and Maria Lomeli and Christoforos Nalmpantis and Ramakanth Pasunuru and Roberta Raileanu and Baptiste Roziere and Timo Schick and Jane Dwivedi-Yu and Asli Celikyilmaz and Edouard Grave and Yann LeCun and Thomas Scialom},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Augmented language models: A survey},
  url          = {https://openreview.net/forum?id=jh7wH2AzKK},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Provably convergent policy optimization via metric-aware
trust region methods. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=jkTqJJOGMS">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trust-region methods based on Kullback-Leibler divergence are pervasively used to stabilize policy optimization in reinforcement learning. In this paper, we exploit more flexible metrics and examine two natural extensions of policy optimization with Wasserstein and Sinkhorn trust regions, namely Wasserstein policy optimization (WPO) and Sinkhorn policy optimization (SPO). Instead of restricting the policy to a parametric distribution class, we directly optimize the policy distribution and derive their close-form policy updates based on the Lagrangian duality. Theoretically, we show that WPO guarantees a monotonic performance improvement, and SPO provably converges to WPO as the entropic regularizer diminishes. Moreover, we prove that with a decaying Lagrangian multiplier to the trust region constraint, both methods converge to global optimality. Experiments across tabular domains, robotic locomotion, and continuous control tasks further demonstrate the performance improvement of both approaches, more robustness of WPO to sample insufficiency, and faster convergence of SPO, over state-of-art policy gradient methods.},
  archive      = {J_TMLR},
  author       = {Jun Song and Niao He and Lijun Ding and Chaoyue Zhao},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Provably convergent policy optimization via metric-aware trust region methods},
  url          = {https://openreview.net/forum?id=jkTqJJOGMS},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vulnerability-aware instance reweighting for adversarial
training. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=kdPcLdJbt1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial Training (AT) has been found to substantially improve the robustness of deep learning classifiers against adversarial attacks. AT involves obtaining robustness by including adversarial examples in training a classifier. Most variants of AT algorithms treat every training example equally. However, recent works have shown that better performance is achievable by treating them unequally. In addition, it has been observed that AT exerts an uneven influence on different classes in a training set and unfairly hurts examples corresponding to classes that are inherently harder to classify. Consequently, various reweighting schemes have been proposed that assign unequal weights to robust losses of individual examples in a training set. In this work, we propose a novel instance-wise reweighting scheme. It considers the vulnerability of each natural example and the resulting information loss on its adversarial counterpart occasioned by adversarial attacks. Through extensive experiments, we show that our proposed method significantly improves over existing reweighting schemes, especially against strong white and black-box attacks.},
  archive      = {J_TMLR},
  author       = {Olukorede Fakorede and Ashutosh Kumar Nirala and Modeste Atsague and Jin Tian},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Vulnerability-aware instance reweighting for adversarial training},
  url          = {https://openreview.net/forum?id=kdPcLdJbt1},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data distillation: A survey. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=lmXMXP74TO">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The popularity of deep learning has led to the curation of a vast number of massive and multifarious datasets. Despite having close-to-human performance on individual tasks, training parameter-hungry models on large datasets poses multi-faceted problems such as (a) high model-training time; (b) slow research iteration; and (c) poor eco-sustainability. As an alternative, data distillation approaches aim to synthesize terse data summaries, which can serve as effective drop-in replacements of the original dataset for scenarios like model training, inference, architecture search, etc. In this survey, we present a formal framework for data distillation, along with providing a detailed taxonomy of existing approaches. Additionally, we cover data distillation approaches for different data modalities, namely images, graphs, and user-item interactions (recommender systems), while also identifying current challenges and future research directions.},
  archive      = {J_TMLR},
  author       = {Noveen Sachdeva and Julian McAuley},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Data distillation: A survey},
  url          = {https://openreview.net/forum?id=lmXMXP74TO},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differentiable logic machines. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=mXfkKtu5JA">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of reasoning, learning, and decision-making is key to build more general artificial intelligence systems. As a step in this direction, we propose a novel neural-logic architecture, called differentiable logic machine (DLM), that can solve both inductive logic programming (ILP) and reinforcement learning (RL) problems, where the solution can be interpreted as a first-order logic program. Our proposition includes several innovations. Firstly, our architecture defines a restricted but expressive continuous relaxation of the space of first-order logic programs by assigning weights to predicates instead of rules, in contrast to most previous neural-logic approaches. Secondly, with this differentiable architecture, we propose several (supervised and RL) training procedures, based on gradient descent, which can recover a fully-interpretable solution (i.e., logic formula). Thirdly, to accelerate RL training, we also design a novel critic architecture that enables actor-critic algorithms. Fourthly, to solve hard problems, we propose an incremental training procedure that can learn a logic program progressively. Compared to state-of-the-art (SOTA) differentiable ILP methods, DLM successfully solves all the considered ILP problems with a higher percentage of successful seeds (up to 3.5x). On RL problems, without requiring an interpretable solution, DLM outperforms other non-interpretable neural-logic RL approaches in terms of rewards (up to 3.9%). When enforcing interpretability, DLM can solve harder RL problems (e.g., Sorting, Path) than other interpretable RL methods. Moreover, we show that deep logic programs can be learned via incremental supervised training. In addition to this excellent performance, DLM can scale well in terms of memory and computational time, especially during the testing phase where it can deal with much more constants (&gt;2x) than SOTA.},
  archive      = {J_TMLR},
  author       = {Matthieu Zimmer and Xuening Feng and Claire Glanois and Zhaohui JIANG and Jianyi Zhang and Paul Weng and Dong Li and Jianye HAO and Wulong Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Differentiable logic machines},
  url          = {https://openreview.net/forum?id=mXfkKtu5JA},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GPS++: Reviving the art of message passing for molecular
property prediction. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=moVEUgJaHO">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present GPS++, a hybrid Message Passing Neural Network / Graph Transformer model for molecular property prediction. Our model integrates a well-tuned local message passing component and biased global attention with other key ideas from prior literature to achieve state-of-the-art results on large-scale molecular dataset PCQM4Mv2. Through a thorough ablation study we highlight the impact of individual components and find that nearly all of the model’s performance can be maintained without any use of global self-attention, showing that message passing is still a competitive approach for 3D molecular property prediction despite the recent dominance of graph transformers. We also find that our approach is significantly more accurate than prior art when 3D positional information is not available.},
  archive      = {J_TMLR},
  author       = {Dominic Masters and Josef Dean and Kerstin Klaeser and Zhiyi Li and Samuel Maddrell-Mander and Adam Sanders and Hatem Helal and Deniz Beker and Andrew W Fitzgibbon and Shenyang Huang and Ladislav Rampášek and Dominique Beaini},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {GPS++: Reviving the art of message passing for molecular property prediction},
  url          = {https://openreview.net/forum?id=moVEUgJaHO},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural networks beyond explainability: Selective inference
for sequence motifs. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=nddEHTSnqg">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, neural networks have been successful at making predictions from biological sequences, especially in the context of regulatory genomics. As in other fields of deep learning, tools have been devised to extract features such as sequence motifs that can explain the predictions made by a trained network. Here we intend to go beyond explainable machine learning and introduce SEISM, a selective inference procedure to test the association between these extracted features and the predicted phenotype. In particular, we discuss how training a one-layer convolutional network is formally equivalent to selecting motifs maximizing some association score. We adapt existing sampling-based selective inference procedures by quantizing this selection over an infinite set to a large but finite grid. Finally,we show that sampling under a specific choice of parameters is sufficient to characterize the composite null hypothesis typically used for selective inference - a result that goes well beyond our particular framework. We illustrate the behavior of our method in terms of calibration, power and speed and discuss its power/speed trade-off with a simpler data-split strategy. SEISM paves the way to an easier analysis of neural networks used in regulatory genomics, and to more powerful methods for genome wide association studies (GWAS).},
  archive      = {J_TMLR},
  author       = {Antoine Villié and Philippe Veber and Yohann De Castro and Laurent Jacob},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Neural networks beyond explainability: Selective inference for sequence motifs},
  url          = {https://openreview.net/forum?id=nddEHTSnqg},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DORA: Exploring outlier representations in deep neural
networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=nfYwRIezvg">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) excel at learning complex abstractions within their internal representations. However, the concepts they learn remain opaque, a problem that becomes particularly acute when models unintentionally learn spurious correlations. In this work, we present DORA (Data-agnOstic Representation Analysis), the first data-agnostic framework for analyzing the representational space of DNNs. Central to our framework is the proposed Extreme-Activation (EA) distance measure, which assesses similarities between representations by analyzing their activation patterns on data points that cause the highest level of activation. As spurious correlations often manifest in features of data that are anomalous to the desired task, such as watermarks or artifacts, we demonstrate that internal representations capable of detecting such artifactual concepts can be found by analyzing relationships within neural representations. We validate the EA metric quantitatively, demonstrating its effectiveness both in controlled scenarios and real-world applications. Finally, we provide practical examples from popular Computer Vision models to illustrate that representations identified as outliers using the EA metric often correspond to undesired and spurious concepts.},
  archive      = {J_TMLR},
  author       = {Kirill Bykov and Mayukh Deb and Dennis Grinwald and Klaus Robert Muller and Marina MC Höhne},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DORA: Exploring outlier representations in deep neural networks},
  url          = {https://openreview.net/forum?id=nfYwRIezvg},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Supervised knowledge may hurt novel class discovery
performance. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=oqOBTo5uWD">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Novel class discovery (NCD) aims to infer novel categories in an unlabeled dataset by leveraging prior knowledge of a labeled set comprising disjoint but related classes. Given that most existing literature focuses primarily on utilizing supervised knowledge from a labeled set at the methodology level, this paper considers the question: Is supervised knowledge always helpful at different levels of semantic relevance? To proceed, we first establish a novel metric, so-called transfer leakage, to measure the semantic similarity between labeled/unlabeled datasets. To show the validity of the proposed metric, we build up a large-scale benchmark with various degrees of semantic similarities between labeled/unlabeled datasets on ImageNet by leveraging its hierarachical class structure. The results based on the proposed benchmark show that the proposed transfer leakage is in line with the hierarachical class structure; and that NCD performance is consistent with the semantic similarities (measured by the proposed metric). Next, by using the proposed transfer leakage, we conduct various empirical experiments with different levels of semantic similarity, yielding that supervised knowledge may hurt NCD performance. Specifically, using supervised information from a low-similarity labeled set may lead to a suboptimal result as compared to using pure self-supervised knowledge. These results reveal the inadequacy of the existing NCD literature which usually assumes that supervised knowledge is beneficial. Finally, we develop a pseudo-version of the transfer leakage as a practical reference to decide if supervised knowledge should be used in NCD. Its effectiveness is supported by our empirical studies, which show that the pseudo transfer leakage (with or without supervised knowledge) is consistent with the corresponding accuracy based on various datasets.},
  archive      = {J_TMLR},
  author       = {ZIYUN LI and Jona Otholt and Ben Dai and Di Hu and Christoph Meinel and Haojin Yang},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Supervised knowledge may hurt novel class discovery performance},
  url          = {https://openreview.net/forum?id=oqOBTo5uWD},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stochastic gradient updates yield deep equilibrium kernels.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=p7UTv2hWgM">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implicit deep learning allows one to compute with implicitly defined features, for example features that solve optimisation problems. We consider the problem of computing with implicitly defined features in a kernel regime. We call such a kernel a deep equilibrium kernel (DEKer). Specialising on a stochastic gradient descent (SGD) update rule applied to features (not weights) in a latent variable model, we find an exact deterministic update rule for the (DEKer) in a high dimensional limit. This derived update rule resembles previously introduced infinitely wide neural network kernels. To perform our analysis, we describe an alternative parameterisation of the link function of exponential families, a result that may be of independent interest. This new parameterisation allows us to draw new connections between a statistician&#39;s inverse link function and a machine learner&#39;s activation function. We describe an interesting property of SGD in this high dimensional limit: even though individual iterates are random vectors, inner products of any two iterates are deterministic, and can converge to a unique fixed point as the number of iterates increases. We find that the (DEKer) empirically outperforms related neural network kernels on a series of benchmarks.},
  archive      = {J_TMLR},
  author       = {Russell Tsuchida and Cheng Soon Ong},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Stochastic gradient updates yield deep equilibrium kernels},
  url          = {https://openreview.net/forum?id=p7UTv2hWgM},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A unified perspective on natural gradient variational
inference with gaussian mixture models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=tLBjsX4tjs">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational inference with Gaussian mixture models (GMMs) enables learning of highly tractable yet multi-modal approximations of intractable target distributions with up to a few hundred dimensions. The two currently most effective methods for GMM-based variational inference, VIPS and iBayes-GMM, both employ independent natural gradient updates for the individual components and their weights. We show for the first time, that their derived updates are equivalent, although their practical implementations and theoretical guarantees differ. We identify several design choices that distinguish both approaches, namely with respect to sample selection, natural gradient estimation, stepsize adaptation, and whether trust regions are enforced or the number of components adapted. We argue that for both approaches, the quality of the learned approximations can heavily suffer from the respective design choices: By updating the individual components using samples from the mixture model, iBayes-GMM often fails to produce meaningful updates to low-weight components, and by using a zero-order method for estimating the natural gradient, VIPS scales badly to higher-dimensional problems. Furthermore, we show that information-geometric trust-regions (used by VIPS) are effective even when using first-order natural gradient estimates, and often outperform the improved Bayesian learning rule (iBLR) update used by iBayes-GMM. We systematically evaluate the effects of design choices and show that a hybrid approach significantly outperforms both prior works. Along with this work, we publish our highly modular and efficient implementation for natural gradient variational inference with Gaussian mixture models, which supports $432$ different combinations of design choices, facilitates the reproduction of all our experiments, and may prove valuable for the practitioner.},
  archive      = {J_TMLR},
  author       = {Oleg Arenz and Philipp Dahlinger and Zihan Ye and Michael Volpp and Gerhard Neumann},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A unified perspective on natural gradient variational inference with gaussian mixture models},
  url          = {https://openreview.net/forum?id=tLBjsX4tjs},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamics adapted imitation learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=w36pqfaJ4t">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider Imitation Learning with dynamics variation between the expert demonstration (source domain) and the environment (target domain). Based on the popular framework of Adversarial Imitation Learning, we propose a novel algorithm – Dynamics Adapted Imitation Learning (DYNAIL), which incorporates the dynamics variation into the state-action occupancy measure matching as a regularization term. The dynamics variation is modeled by a pair of classifiers to distinguish between source dynamics and target dynamics. Theoretically, we provide an upper bound on the divergence between the learned policy and expert demonstrations in the source domain. Our error bound only depends on the expectation of the discrepancy between the source and target dynamics for the optimal policy in the target domain. The experiment evaluation validates that our method achieves superior results on high dimensional continuous control tasks, compared to existing imitation learning methods},
  archive      = {J_TMLR},
  author       = {Zixuan Liu and Liu Liu and Bingzhe Wu and Lanqing Li and Xueqian Wang and Bo Yuan and Peilin Zhao},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Dynamics adapted imitation learning},
  url          = {https://openreview.net/forum?id=w36pqfaJ4t},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An explicit expansion of the kullback-leibler divergence
along its fisher-rao gradient flow. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=9pWjgQ3y85">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let $V_* : \mathbb{R}^d \to \mathbb{R}$ be some (possibly non-convex) potential function, and consider the probability measure $\pi \propto e^{-V_*}$. When $\pi$ exhibits multiple modes, it is known that sampling techniques based on Wasserstein gradient flows of the Kullback-Leibler (KL) divergence (e.g. Langevin Monte Carlo) suffer poorly in the rate of convergence, where the dynamics are unable to easily traverse between modes. In stark contrast, the work of Lu et al. (2019; 2022) has shown that the gradient flow of the KL with respect to the Fisher-Rao (FR) geometry exhibits a convergence rate to $\pi$ is that \textit{independent} of the potential function. In this short note, we complement these existing results in the literature by providing an explicit expansion of $\text{KL}(\rho_t^{\text{FR}}\|\pi)$ in terms of $e^{-t}$, where $(\rho_t^{\text{FR}})_{t\geq 0}$ is the FR gradient flow of the KL divergence. In turn, we are able to provide a clean asymptotic convergence rate, where the burn-in time is guaranteed to be finite. Our proof is based on observing a similarity between FR gradient flows and simulated annealing with linear scaling, and facts about cumulant generating functions. We conclude with simple synthetic experiments that demonstrate our theoretical findings are indeed tight. Based on our numerical findings, we conjecture that the asymptotic rates of convergence for Wasserstein-Fisher-Rao gradient flows are possibly related to this expansion in some cases.},
  archive      = {J_TMLR},
  author       = {Carles Domingo-Enrich and Aram-Alexandre Pooladian},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {An explicit expansion of the kullback-leibler divergence along its fisher-rao gradient flow},
  url          = {https://openreview.net/forum?id=9pWjgQ3y85},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bandwidth enables generalization in quantum kernel models.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=A1N2qp4yAq">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computers are known to provide speedups over classical state-of-the-art machine learning methods in some specialized settings. For example, quantum kernel methods have been shown to provide an exponential speedup on a learning version of the discrete logarithm problem. Understanding the generalization of quantum models is essential to realizing similar speedups on problems of practical interest. Recent results demonstrate that generalization is hindered by the exponential size of the quantum feature space. Although these results suggest that quantum models cannot generalize when the number of qubits is large, in this paper we show that these results rely on overly restrictive assumptions. We consider a wider class of models by varying a hyperparameter that we call quantum kernel bandwidth. We analyze the large-qubit limit and provide explicit formulas for the generalization of a quantum model that can be solved in closed form. Specifically, we show that changing the value of the bandwidth can take a model from provably not being able to generalize to any target function to good generalization for well-aligned targets. Our analysis shows how the bandwidth controls the spectrum of the kernel integral operator and thereby the inductive bias of the model. We demonstrate empirically that our theory correctly predicts how varying the bandwidth affects generalization of quantum models on challenging datasets, including those far outside our theoretical assumptions. We discuss the implications of our results for quantum advantage in machine learning.},
  archive      = {J_TMLR},
  author       = {Abdulkadir Canatar and Evan Peters and Cengiz Pehlevan and Stefan M. Wild and Ruslan Shaydulin},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bandwidth enables generalization in quantum kernel models},
  url          = {https://openreview.net/forum?id=A1N2qp4yAq},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attentional-biased stochastic gradient descent.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=B0WYWvVA2r">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a simple yet effective provable method (named ABSGD) for addressing the data imbalance or label noise problem in deep learning. Our method is a simple modification to momentum SGD where we assign an individual importance weight to each sample in the mini-batch. The individual-level weight of a sampled data is systematically proportional to the exponential of a scaled loss value of the data, where the scaling factor is interpreted as the regularization parameter in the framework of distributionally robust optimization (DRO). Depending on whether the scaling factor is positive or negative, ABSGD is guaranteed to converge to a stationary point of an information-regularized min-max or min-min DRO problem, respectively. Compared with existing class-level weighting schemes, our method can capture the diversity between individual examples within each class. Compared with existing individual-level weighting methods using meta-learning that require three backward propagations for computing mini-batch stochastic gradients, our method is more efficient with only one backward propagation at each iteration as in standard deep learning methods. ABSGD is flexible enough to combine with other robust losses without any additional cost. Our empirical studies on several benchmark datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_TMLR},
  author       = {Qi Qi and Yi Xu and Wotao Yin and Rong Jin and Tianbao Yang},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Attentional-biased stochastic gradient descent},
  url          = {https://openreview.net/forum?id=B0WYWvVA2r},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised discovery and composition of object light
fields. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=B7PFZtm8DA">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural scene representations, both continuous and discrete, have recently emerged as a powerful new paradigm for 3D scene understanding. Recent efforts have tackled unsupervised discovery of object-centric neural scene representations. However, the high cost of ray-marching, exacerbated by the fact that each object representation has to be ray-marched separately, leads to insufficiently sampled radiance fields and thus, noisy renderings, poor framerates, and high memory and time complexity during training and rendering. Here, we propose to represent objects in an object-centric, compositional scene representation as light fields. We propose a novel light field compositor module that enables reconstructing the global light field from a set of object-centric light fields. Dubbed Compositional Object Light Fields (COLF), our method enables unsupervised learning of object-centric neural scene representations, state-of-the-art reconstruction and novel view synthesis performance on standard datasets, and rendering and training speeds at orders of magnitude faster than existing 3D approaches.},
  archive      = {J_TMLR},
  author       = {Cameron Omid Smith and Hong-Xing Yu and Sergey Zakharov and Fredo Durand and Joshua B. Tenenbaum and Jiajun Wu and Vincent Sitzmann},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unsupervised discovery and composition of object light fields},
  url          = {https://openreview.net/forum?id=B7PFZtm8DA},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimum-statistical collaboration towards general and
efficient black-box optimization. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ClIcmwdlxn">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we make the key delineation on the roles of resolution and statistical uncertainty in hierarchical bandits-based black-box optimization algorithms, guiding a more general analysis and a more efficient algorithm design. We introduce the optimum-statistical collaboration, an algorithm framework of managing the interaction between optimization error flux and statistical error flux evolving in the optimization process. We provide a general analysis of this framework without specifying the forms of statistical error and uncertainty quantifier. Our framework and its analysis, due to their generality, can be applied to a large family of functions and partitions that satisfy different local smoothness assumptions and have different numbers of local optimums, which is much richer than the class of functions studied in prior works. Our framework also inspires us to propose a better measure of the statistical uncertainty and consequently a variance-adaptive algorithm VHCT. In theory, we prove the algorithm enjoys rate-optimal regret bounds under different local smoothness assumptions; in experiments, we show the algorithm outperforms prior efforts in different settings.},
  archive      = {J_TMLR},
  author       = {Wenjie Li and Chi-Hua Wang and Guang Cheng and Qifan Song},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Optimum-statistical collaboration towards general and efficient black-box optimization},
  url          = {https://openreview.net/forum?id=ClIcmwdlxn},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust multi-agent reinforcement learning with state
uncertainty. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=CqTkapZ6H9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world multi-agent reinforcement learning (MARL) applications, agents may not have perfect state information (e.g., due to inaccurate measurement or malicious attacks), which challenges the robustness of agents&#39; policies. Though robustness is getting important in MARL deployment, little prior work has studied state uncertainties in MARL, neither in problem formulation nor algorithm design. Motivated by this robustness issue and the lack of corresponding studies, we study the problem of MARL with state uncertainty in this work. We provide the first attempt to the theoretical and empirical analysis of this challenging problem. We first model the problem as a Markov Game with state perturbation adversaries (MG-SPA) by introducing a set of state perturbation adversaries into a Markov Game. We then introduce robust equilibrium (RE) as the solution concept of an MG-SPA. We conduct a fundamental analysis regarding MG-SPA such as giving conditions under which such a robust equilibrium exists. Then we propose a robust multi-agent Q-learning (RMAQ) algorithm to find such an equilibrium, with convergence guarantees. To handle high-dimensional state-action space, we design a robust multi-agent actor-critic (RMAAC) algorithm based on an analytical expression of the policy gradient derived in the paper. Our experiments show that the proposed RMAQ algorithm converges to the optimal value function; our RMAAC algorithm outperforms several MARL and robust MARL methods in multiple multi-agent environments when state uncertainty is present. The source code is public on https://github.com/sihongho/robust_marl_with_state_uncertainty.},
  archive      = {J_TMLR},
  author       = {Sihong He and Songyang Han and Sanbao Su and Shuo Han and Shaofeng Zou and Fei Miao},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Robust multi-agent reinforcement learning with state uncertainty},
  url          = {https://openreview.net/forum?id=CqTkapZ6H9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sequential query encoding for complex query answering on
knowledge graphs. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ERqGqZzSu5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex Query Answering (CQA) is an important and fundamental task for knowledge graph (KG) reasoning. Query encoding (QE) is proposed as a fast and robust solution to CQA. In the encoding process, most existing QE methods first parse the logical query into an executable computational direct-acyclic graph (DAG), then use neural networks to parameterize the operators, and finally, recursively execute these neuralized operators. However, the parameterization-and-execution paradigm may be potentially over-complicated, as it can be structurally simplified by a single neural network encoder. Meanwhile, sequence encoders, like LSTM and Transformer, proved to be effective for encoding semantic graphs in related tasks. Motivated by this, we propose sequential query encoding (SQE) as an alternative to encode queries for CQA. Instead of parameterizing and executing the computational graph, SQE first uses a search-based algorithm to linearize the computational graph to a sequence of tokens and then uses a sequence encoder to compute its vector representation. Then this vector representation is used as a query embedding to retrieve answers from the embedding space according to similarity scores. Despite its simplicity, SQE demonstrates state-of-the-art neural query encoding performance on FB15k, FB15k-237, and NELL on an extended benchmark including twenty-nine types of in-distribution queries. Further experiment shows that SQE also demonstrates comparable knowledge inference capability on out-of-distribution queries, whose query types are not observed during the training process.},
  archive      = {J_TMLR},
  author       = {Jiaxin Bai and Tianshi Zheng and Yangqiu Song},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Sequential query encoding for complex query answering on knowledge graphs},
  url          = {https://openreview.net/forum?id=ERqGqZzSu5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On averaging ROC curves. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=FByH3qL87G">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Receiver operating characteristic (ROC) curves are a popular method of summarising the performance of classifiers. The ROC curve describes the separability of the distributions of predictions from a two-class classifier. There are a variety of situations in which an analyst seeks to aggregate multiple ROC curves into a single representative example. A number of methods of doing so are available; however, there is a degree of subtlety that is often overlooked when selecting the appropriate one. An important component of this relates to the interpretation of the decision process for which the classifier will be used. This paper summarises a number of methods of aggregation and carefully delineates the interpretations of each in order to inform their correct usage. A toy example is provided that highlights how an injudicious choice of aggregation method can lead to erroneous conclusions.},
  archive      = {J_TMLR},
  author       = {Jack Hogan and Niall M. Adams},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On averaging ROC curves},
  url          = {https://openreview.net/forum?id=FByH3qL87G},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The eigenlearning framework: A conservation law perspective
on kernel ridge regression and wide neural networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=FDbQGCAViI">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We derive simple closed-form estimates for the test risk and other generalization metrics of kernel ridge regression (KRR). Relative to prior work, our derivations are greatly simplified and our final expressions are more readily interpreted. In particular, we show that KRR can be interpreted as an explicit competition among kernel eigenmodes for a fixed supply of a quantity we term &quot;learnability.&#39;&#39; These improvements are enabled by a sharp conservation law which limits the ability of KRR to learn any orthonormal basis of functions. Test risk and other objects of interest are expressed transparently in terms of our conserved quantity evaluated in the kernel eigenbasis. We use our improved framework to: i) provide a theoretical explanation for the &quot;deep bootstrap&quot; of Nakkiran et al (2020), ii) generalize a previous result regarding the hardness of the classic parity problem, iii) fashion a theoretical tool for the study of adversarial robustness, and iv) draw a tight analogy between KRR and a well-studied system in statistical physics.},
  archive      = {J_TMLR},
  author       = {James B Simon and Madeline Dickens and Dhruva Karkada and Michael Deweese},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The eigenlearning framework: A conservation law perspective on kernel ridge regression and wide neural networks},
  url          = {https://openreview.net/forum?id=FDbQGCAViI},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reinforcement teaching. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=G2GKiicaJI">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning algorithms learn to solve a task, but are unable to improve their ability to learn. Meta-learning methods learn about machine learning algorithms and improve them so that they learn more quickly. However, existing meta-learning methods are either hand-crafted to improve one specific component of an algorithm or only work with differentiable algorithms. We develop a unifying meta-learning framework, called \textit{Reinforcement Teaching}, to improve the learning process of \emph{any} algorithm. Under Reinforcement Teaching, a teaching policy is learned, through reinforcement, to improve a student&#39;s learning algorithm. To learn an effective teaching policy, we introduce the \textit{parametric-behavior embedder} that learns a representation of the student&#39;s learnable parameters from its input/output behavior. We further use \textit{learning progress} to shape the teacher&#39;s reward, allowing it to more quickly maximize the student&#39;s performance. To demonstrate the generality of Reinforcement Teaching, we conduct experiments in which a teacher learns to significantly improve both reinforcement and supervised learning algorithms. Reinforcement Teaching outperforms previous work using heuristic reward functions and state representations, as well as other parameter representations.},
  archive      = {J_TMLR},
  author       = {Calarina Muslimani and Alex Lewandowski and Dale Schuurmans and Matthew E. Taylor and Jun Luo},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reinforcement teaching},
  url          = {https://openreview.net/forum?id=G2GKiicaJI},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the convergence and calibration of deep learning with
differential privacy. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=K0CAGgjYS1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differentially private (DP) training preserves the data privacy usually at the cost of slower convergence (and thus lower accuracy), as well as more severe mis-calibration than its non-private counterpart. To analyze the convergence of DP training, we formulate a continuous time analysis through the lens of neural tangent kernel (NTK), which characterizes the per-sample gradient clipping and the noise addition in DP training, for arbitrary network architectures and loss functions. Interestingly, we show that the noise addition only affects the privacy risk but not the convergence or calibration, whereas the per-sample gradient clipping (under both flat and layerwise clipping styles) only affects the convergence and calibration. Furthermore, we observe that while DP models trained with small clipping norm usually achieve the best accurate, but are poorly calibrated and thus unreliable. In sharp contrast, DP models trained with large clipping norm enjoy the same privacy guarantee and similar accuracy, but are significantly more \textit{calibrated}. Our code can be found at https://github.com/woodyx218/opacus_global_clipping.},
  archive      = {J_TMLR},
  author       = {Zhiqi Bu and Hua Wang and Zongyu Dai and Qi Long},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the convergence and calibration of deep learning with differential privacy},
  url          = {https://openreview.net/forum?id=K0CAGgjYS1},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive half-space projection method for stochastic
optimization problems with group sparse regularization. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=KBhSyBBeeO">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization problems with group sparse regularization are ubiquitous in various popular downstream applications, such as feature selection and compression for Deep Neural Networks (DNNs). Nonetheless, the existing methods in the literature do not perform particularly well when such regularization is used in combination with a stochastic loss function. In particular, it is challenging to design a computationally efficient algorithm with a convergence guarantee and can compute group-sparse solutions. Recently, a half-space stochastic projected gradient (HSPG) method was proposed that partly addressed these challenges. This paper presents a substantially enhanced version of HSPG that we call AdaHSPG+ that makes two noticeable advances. First, AdaHSPG+ is shown to have a stronger convergence result under significantly looser assumptions than those required by HSPG. This improvement in convergence is achieved by integrating variance reduction techniques with a new adaptive strategy for iteratively predicting the support of a solution. Second, AdaHSPG+ requires significantly less parameter tuning compared to HSPG, thus making it more practical and user-friendly. This advance is achieved by designing automatic and adaptive strategies for choosing the type of step employed at each iteration and for updating key hyperparameters. The numerical effectiveness of our proposed AdaHSPG+ algorithm is demonstrated on both convex and non-convex benchmark problems. The source code is available at https://github.com/tianyic/adahspg.},
  archive      = {J_TMLR},
  author       = {Yutong Dai and Tianyi Chen and Guanyi Wang and Daniel Robinson},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {An adaptive half-space projection method for stochastic optimization problems with group sparse regularization},
  url          = {https://openreview.net/forum?id=KBhSyBBeeO},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Numerical data imputation for multimodal data sets: A
probabilistic nearest-neighbor kernel density approach. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=KqR3rgooXb">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerical data imputation algorithms replace missing values by estimates to leverage incomplete data sets. Current imputation methods seek to minimize the error between the unobserved ground truth and the imputed values. But this strategy can create artifacts leading to poor imputation in the presence of multimodal or complex distributions. To tackle this problem, we introduce the $k$NN$\times$KDE algorithm: a data imputation method combining nearest neighbor estimation ($k$NN) and density estimation with Gaussian kernels (KDE). We compare our method with previous data imputation methods using artificial and real-world data with different data missing scenarios and various data missing rates, and show that our method can cope with complex original data structure, yields lower data imputation errors, and provides probabilistic estimates with higher likelihood than current methods. We release the code in open-source for the community.},
  archive      = {J_TMLR},
  author       = {Florian Lalande and Kenji Doya},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Numerical data imputation for multimodal data sets: A probabilistic nearest-neighbor kernel density approach},
  url          = {https://openreview.net/forum?id=KqR3rgooXb},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-dimensional concept discovery (MCD): A unifying
framework with completeness guarantees. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=KxBQPz7HKh">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The completeness axiom renders the explanation of a post-hoc eXplainable AI (XAI) method only locally faithful to the model, i.e. for a single decision. For the trustworthy application of XAI, in particular for high-stake decisions, a more global model understanding is required. To this end, concept-based methods have been proposed, which are however not guaranteed to be bound to the actual model reasoning. To circumvent this problem, we propose Multi-dimensional Concept Discovery (MCD) as an extension of previous approaches that fulfills a completeness relation on the level of concepts. Our method starts from general linear subspaces as concepts and does neither require reinforcing concept interpretability nor re-training of model parts. We propose sparse subspace clustering to discover improved concepts and fully leverage the potential of multi-dimensional subspaces. MCD offers two complementary analysis tools for concepts in input space: (1) concept activation maps, that show where a concept is expressed within a sample, allowing for concept characterization through prototypical samples, and (2) concept relevance heatmaps, that decompose the model decision into concept contributions. Both tools together enable a detailed global understanding of the model reasoning, which is guaranteed to relate to the model via a completeness relation. Thus, MCD paves the way towards more trustworthy concept-based XAI. We empirically demonstrate the superiority of MCD against more constrained concept definitions.},
  archive      = {J_TMLR},
  author       = {Johanna Vielhaben and Stefan Bluecher and Nils Strodthoff},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Multi-dimensional concept discovery (MCD): A unifying framework with completeness guarantees},
  url          = {https://openreview.net/forum?id=KxBQPz7HKh},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the robustness of dataset inference. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=LKz5SqIXPJ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) models are costly to train as they can require a significant amount of data, computational resources and technical expertise. Thus, they constitute valuable intellectual property that needs protection from adversaries wanting to steal them. Ownership verification techniques allow the victims of model stealing attacks to demonstrate that a suspect model was in fact stolen from theirs. Although a number of ownership verification techniques based on watermarking or fingerprinting have been proposed, most of them fall short either in terms of security guarantees (well-equipped adversaries can evade verification) or computational cost. A fingerprinting technique, Dataset Inference (DI) has been shown to offer better robustness and efficiency than prior methods. The authors of DI provided a correctness proof for linear (suspect) models. However, in a subspace of the same setting, we prove that DI suffers from high false positives (FPs) -- it can incorrectly identify an independent model trained with non-overlapping data from the same distribution as stolen. We further prove that DI also triggers FPs in realistic, non-linear suspect models. We then confirm empirically that DI in the black-box setting leads to FPs, with high confidence. Second, we show that DI also suffers from false negatives (FNs) -- an adversary can fool DI by regularising a stolen model&#39;s decision boundaries using adversarial training, thereby leading to an FN. To this end, we demonstrate that black-box DI fails to identify a model adversarially trained from a stolen dataset -- the setting where DI is the hardest to evade. Finally, we discuss the implications of our findings, the viability of fingerprinting-based ownership verification in general, and suggest directions for future work.},
  archive      = {J_TMLR},
  author       = {Sebastian Szyller and Rui Zhang and Jian Liu and N Asokan},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the robustness of dataset inference},
  url          = {https://openreview.net/forum?id=LKz5SqIXPJ},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Federated learning under covariate shifts with
generalization guarantees. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=N7lCDaeNiS">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses intra-client and inter-client covariate shifts in federated learning (FL) with a focus on the overall generalization performance. To handle covariate shifts, we formulate a new global model training paradigm and propose Federated Importance-Weighted Empirical Risk Minimization (FTW-ERM) along with improving density ratio matching methods without requiring perfect knowledge of the supremum over true ratios. We also propose the communication-efficient variant FITW-ERM with the same level of privacy guarantees as those of classical ERM in FL. We theoretically show that FTW-ERM achieves smaller generalization error than classical ERM under certain settings. Experimental results demonstrate the superiority of FTW-ERM over existing FL baselines in challenging imbalanced federated settings in terms of data distribution shifts across clients.},
  archive      = {J_TMLR},
  author       = {Ali Ramezani-Kebrya and Fanghui Liu and Thomas Pethick and Grigorios Chrysos and Volkan Cevher},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Federated learning under covariate shifts with generalization guarantees},
  url          = {https://openreview.net/forum?id=N7lCDaeNiS},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning object-centric neural scattering functions for
free-viewpoint relighting and scene composition. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=NrfSRtTpN5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photorealistic object appearance modeling from 2D images is a constant topic in vision and graphics. While neural implicit methods (such as Neural Radiance Fields) have shown high-fidelity view synthesis results, they cannot relight the captured objects. More recent neural inverse rendering approaches have enabled object relighting, but they represent surface properties as simple BRDFs, and therefore cannot handle translucent objects. We propose Object-Centric Neural Scattering Functions (OSFs) for learning to reconstruct object appearance from only images. OSFs not only support free-viewpoint object relighting, but also can model both opaque and translucent objects. While accurately modeling subsurface light transport for translucent objects can be highly complex and even intractable for neural methods, OSFs learn to approximate the radiance transfer from a distant light to an outgoing direction at any spatial location. This approximation avoids explicitly modeling complex subsurface scattering, making learning a neural implicit model tractable. Experiments on real and synthetic data show that OSFs accurately reconstruct appearances for both opaque and translucent objects, allowing faithful free-viewpoint relighting as well as scene composition. In our supplementary material, we include a video for an overview. Project website with video results: https://kovenyu.com/OSF/},
  archive      = {J_TMLR},
  author       = {Hong-Xing Yu and Michelle Guo and Alireza Fathi and Yen-Yu Chang and Eric Ryan Chan and Ruohan Gao and Thomas Funkhouser and Jiajun Wu},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning object-centric neural scattering functions for free-viewpoint relighting and scene composition},
  url          = {https://openreview.net/forum?id=NrfSRtTpN5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning graph structure from convolutional mixtures.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=OILbP0WErR">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning frameworks such as graph neural networks typically rely on a given, fixed graph to exploit relational inductive biases and thus effectively learn from network data. However, when said graphs are (partially) unobserved, noisy, or dynamic, the problem of inferring graph structure from data becomes relevant. In this paper, we postulate a graph convolutional relationship between the observed and latent graphs, and formulate the graph structure learning task as a network inverse (deconvolution) problem. In lieu of eigendecomposition-based spectral methods or iterative optimization solutions, we unroll and truncate proximal gradient iterations to arrive at a parameterized neural network architecture that we call a Graph Deconvolution Network (GDN). GDNs can learn a distribution of graphs in a supervised fashion, perform link prediction or edge-weight regression tasks by adapting the loss function, and they are inherently inductive as well as node permutation equivariant. We corroborate GDN&#39;s superior graph learning performance and its generalization to larger graphs using synthetic data in supervised settings. Moreover, we demonstrate the robustness and representation power of GDNs on real world neuroimaging and social network datasets.},
  archive      = {J_TMLR},
  author       = {Max Wasserman and Saurabh Sihag and Gonzalo Mateos and Alejandro Ribeiro},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning graph structure from convolutional mixtures},
  url          = {https://openreview.net/forum?id=OILbP0WErR},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The robustness limits of SoTA vision models to natural
variation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=QhHLwn3D0Y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent state-of-the-art vision models have introduced new architectures, learning paradigms, and larger pretraining data, leading to impressive performance on tasks such as classification. While previous generations of vision models were shown to lack robustness to factors such as pose, the extent to which this next generation of models are more robust remains unclear. To study this question, we develop a dataset of more than 7 million images with controlled changes in pose, position background, lighting color, and size. We study not only how robust recent state-of- the-art models are, but also the extent to which models can generalize to variation in each of these factors. We consider a catalog of recent vision models, including vision transformers (ViT), self-supervised models such as masked autoencoders (MAE), and models trained on larger datasets such as CLIP. We find that even today’s best models are not robust to common changes in pose, size, and background. When some samples varied during training, we found models required a significant portion of instances seen varying to generalize—though eventually robustness did improve. When variability is only witnessed for some classes however, we found that models did not generalize to other classes unless the classes were very similar to those seen varying during training. We hope our work will shed further light on the blind spots of SoTA models and spur the development of more robust vision models.},
  archive      = {J_TMLR},
  author       = {Mark Ibrahim and Quentin Garrido and Ari S. Morcos and Diane Bouchacourt},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The robustness limits of SoTA vision models to natural variation},
  url          = {https://openreview.net/forum?id=QhHLwn3D0Y},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 3D-aware video generation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=SwlfyDq6B3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative models have emerged as an essential building block for many image synthesis and editing tasks. Recent advances in this field have also enabled high-quality 3D or video content to be generated that exhibits either multi-view or temporal consistency. With our work, we explore 4D generative adversarial networks (GANs) that learn unconditional generation of 3D-aware videos. By combining neural implicit representations with time-aware discriminator, we develop a GAN framework that synthesizes 3D video supervised only with monocular videos. We show that our method learns a rich embedding of decomposable 3D structures and motions that enables new visual effects of spatio-temporal renderings while producing imagery with quality comparable to that of existing 3D or video GANs.},
  archive      = {J_TMLR},
  author       = {Sherwin Bahmani and Jeong Joon Park and Despoina Paschalidou and Hao Tang and Gordon Wetzstein and Leonidas Guibas and Luc Van Gool and Radu Timofte},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {3D-aware video generation},
  url          = {https://openreview.net/forum?id=SwlfyDq6B3},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finding competence regions in domain generalization.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=TSy0vuwQFN">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate a &quot;learning to reject&quot; framework to address the problem of silent failures in Domain Generalization (DG), where the test distribution differs from the training distribution. Assuming a mild distribution shift, we wish to accept out-of-distribution (OOD) data from a new domain whenever a model&#39;s estimated competence foresees trustworthy responses, instead of rejecting OOD data outright. Trustworthiness is then predicted via a proxy incompetence score that is tightly linked to the performance of a classifier. We present a comprehensive experimental evaluation of existing proxy scores as incompetence scores for classification and highlight the resulting trade-offs between rejection rate and accuracy gain. For comparability with prior work, we focus on standard DG benchmarks and consider the effect of measuring incompetence via different learned representations in a closed versus an open world setting. Our results suggest that increasing incompetence scores are indeed predictive of reduced accuracy, leading to significant improvements of the average accuracy below a suitable incompetence threshold. However, the scores are not yet good enough to allow for a favorable accuracy/rejection trade-off in all tested domains. Surprisingly, our results also indicate that classifiers optimized for DG robustness do not outperform a naive Empirical Risk Minimization (ERM) baseline in the competence region, that is, where test samples elicit low incompetence scores.},
  archive      = {J_TMLR},
  author       = {Jens Müller and Stefan T. Radev and Robert Schmier and Felix Draxler and Carsten Rother and Ullrich Koethe},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Finding competence regions in domain generalization},
  url          = {https://openreview.net/forum?id=TSy0vuwQFN},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online min-max problems with non-convexity and
non-stationarity. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=TdzQtbLeVw">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online min-max optimization has recently gained considerable interest due to its rich applications to game theory, multi-agent reinforcement learning, online robust learning, etc. Theoretical understanding in this field has been mainly focused on convex-concave settings. Online min-max optimization with nonconvex geometries, which captures various online deep learning problems, has yet been studied so far. In this paper, we make the first effort and investigate online nonconvex-strongly-concave min-max optimization in the nonstationary environment. We first introduce a natural notion of local Nash equilibrium (NE)-regret, and then propose a novel algorithm coined TSODA to achieve the optimal regret. We further generalize our study to the setting with stochastic first-order feedback, and show that a variation of TSODA can also achieve the same optimal regret in expectation. Our theoretical results and the superior performance of the proposed method are further validated by empirical experiments. To our best knowledge, this is the first exploration of efficient online nonconvex min-max optimization.},
  archive      = {J_TMLR},
  author       = {Yu Huang and Yuan Cheng and Yingbin Liang and Longbo Huang},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Online min-max problems with non-convexity and non-stationarity},
  url          = {https://openreview.net/forum?id=TdzQtbLeVw},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dr-fairness: Dynamic data ratio adjustment for fair training
on real and generated data. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=TyBd56VK7z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fair visual recognition has become critical for preventing demographic disparity. A major cause of model unfairness is the imbalanced representation of different groups in training data. Recently, several works aim to alleviate this issue using generated data. However, these approaches often use generated data to obtain similar amounts of data across groups, which is not optimal for achieving high fairness due to different learning difficulties and generated data qualities across groups. To address this issue, we propose a novel adaptive sampling approach that leverages both real and generated data for fairness. We design a bilevel optimization that finds the optimal data sampling ratios among groups and between real and generated data while training a model. The ratios are dynamically adjusted considering both the model&#39;s accuracy as well as its fairness. To efficiently solve our non-convex bilevel optimization, we propose a simple approximation to the solution given by the implicit function theorem. Extensive experiments show that our framework achieves state-of-the-art fairness and accuracy on the CelebA and ImageNet People Subtree datasets. We also observe that our method adaptively relies less on the generated data when it has poor quality. Our work shows the importance of using generated data together with real data for improving model fairness.},
  archive      = {J_TMLR},
  author       = {Yuji Roh and Weili Nie and De-An Huang and Steven Euijong Whang and Arash Vahdat and Anima Anandkumar},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Dr-fairness: Dynamic data ratio adjustment for fair training on real and generated data},
  url          = {https://openreview.net/forum?id=TyBd56VK7z},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inversion by direct iteration: An alternative to denoising
diffusion for image restoration. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=VmyFF5lL3F">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inversion by Direct Iteration (InDI) is a new formulation for supervised image restoration that avoids the so-called ``regression to the mean&#39;&#39; effect and produces more realistic and detailed images than existing regression-based methods. It does this by gradually improving image quality in small steps, similar to generative denoising diffusion models. Image restoration is an ill-posed problem where multiple high-quality images are plausible reconstructions of a given low-quality input. Therefore, the outcome of a single step regression model is typically an aggregate of all possible explanations, therefore lacking details and realism. The main advantage of InDI is that it does not try to predict the clean target image in a single step but instead gradually improves the image in small steps, resulting in better perceptual quality. While generative denoising diffusion models also work in small steps, our formulation is distinct in that it does not require knowledge of any analytic form of the degradation process. Instead, we directly learn an iterative restoration process from low-quality and high-quality paired examples. InDI can be applied to virtually any image degradation, given paired training data. In conditional denoising diffusion image restoration the denoising network generates the restored image by repeatedly denoising an initial image of pure noise, conditioned on the degraded input. Contrary to conditional denoising formulations, InDI directly proceeds by iteratively restoring the input low-quality image, producing high-quality results on a variety of image restoration tasks, including motion and out-of-focus deblurring, super-resolution, compression artifact removal, and denoising.},
  archive      = {J_TMLR},
  author       = {Mauricio Delbracio and Peyman Milanfar},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Inversion by direct iteration: An alternative to denoising diffusion for image restoration},
  url          = {https://openreview.net/forum?id=VmyFF5lL3F},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). How to reuse and compose knowledge for a lifetime of tasks:
A survey on continual learning and functional composition.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=VynY6Bk03b">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A major goal of artificial intelligence (AI) is to create an agent capable of acquiring a general understanding of the world. Such an agent would require the ability to continually accumulate and build upon its knowledge as it encounters new experiences. Lifelong or continual learning addresses this setting, whereby an agent faces a continual stream of problems and must strive to capture the knowledge necessary for solving each new task it encounters. If the agent is capable of accumulating knowledge in some form of compositional representation, it could then selectively reuse and combine relevant pieces of knowledge to construct novel solutions. Despite the intuitive appeal of this simple idea, the literatures on lifelong learning and compositional learning have proceeded largely separately. In an effort to promote developments that bridge between the two fields, this article surveys their respective research landscapes and discusses existing and future connections between them.},
  archive      = {J_TMLR},
  author       = {Jorge A Mendez and ERIC EATON},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {How to reuse and compose knowledge for a lifetime of tasks: A survey on continual learning and functional composition},
  url          = {https://openreview.net/forum?id=VynY6Bk03b},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to incentivize improvements from strategic agents.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=W98AEKQ38Y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning systems are often used in settings where individuals adapt their features to obtain a desired outcome. In such settings, strategic behavior leads to a sharp loss in model performance in deployment. In this work, we aim to address this problem by learning classifiers that encourage decision subjects to change their features in a way that leads to improvement in both predicted and true outcome. We frame the dynamics of prediction and adaptation as a two-stage game, and characterize optimal strategies for the model designer and its decision subjects. In benchmarks on simulated and real-world datasets, we find that classifiers trained using our method maintain the accuracy of existing approaches while inducing higher levels of improvement and less manipulation.},
  archive      = {J_TMLR},
  author       = {Yatong Chen and Jialu Wang and Yang Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning to incentivize improvements from strategic agents},
  url          = {https://openreview.net/forum?id=W98AEKQ38Y},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CoCoFL: Communication- and computation-aware federated
learning via partial NN freezing and quantization. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=XJIg4kQbkv">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Devices participating in federated learning (FL) typically have heterogeneous communication, computation, and memory resources. However, in synchronous FL, all devices need to finish training by the same deadline dictated by the server. Our results show that training a smaller subset of the neural network (NN) at constrained devices, i.e., dropping neurons/filters as proposed by state of the art, is inefficient, preventing these devices to make an effective contribution to the model. This causes unfairness w.r.t the achievable accuracies of constrained devices, especially in cases with a skewed distribution of class labels across devices. We present a novel FL technique, CoCoFL, which maintains the full NN structure on all devices. To adapt to the devices’ heterogeneous resources, CoCoFL freezes and quantizes selected layers, reducing communication, computation, and memory requirements, whereas other layers are still trained in full precision, enabling to reach a high accuracy. Thereby, CoCoFL efficiently utilizes the available resources on devices and allows constrained devices to make a significant contribution to the FL system, preserving fairness among participants (accuracy parity) and significantly improving final accuracy.},
  archive      = {J_TMLR},
  author       = {Kilian Pfeiffer and Martin Rapp and Ramin Khalili and Joerg Henkel},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {CoCoFL: Communication- and computation-aware federated learning via partial NN freezing and quantization},
  url          = {https://openreview.net/forum?id=XJIg4kQbkv},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A reproducible and realistic evaluation of partial domain
adaptation methods. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=XcVzIBXeRn">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised Domain Adaptation (UDA) aims at classifying unlabeled target images leveraging source labeled ones. In the case of an extreme label shift scenario between the source and target domains, where we have extra source classes not present in the target domain, the UDA problem becomes a harder problem called Partial Domain Adaptation (PDA). While different methods have been developed to solve the PDA problem, most successful algorithms use model selection strategies that rely on target labels to find the best hyper-parameters and/or models along training. These strategies violate the main assumption in PDA: only unlabeled target domain samples are available. In addition, there are also experimental inconsistencies between developed methods - different architectures, hyper-parameter tuning, number of runs - yielding unfair comparisons. The main goal of this work is to provide a realistic evaluation of PDA methods under different model selection strategies and a consistent evaluation protocol. We evaluate 6 state-of-the-art PDA algorithms on 2 different real-world datasets using 7 different model selection strategies. Our two main findings are: (i) without target labels for model selection, the accuracy of the methods decreases up to 30 percentage points; (ii) only one method and model selection pair performs well on both datasets. Experiments were performed with our PyTorch framework, BenchmarkPDA, which we open source.},
  archive      = {J_TMLR},
  author       = {Tiago Salvador and Kilian FATRAS and Ioannis Mitliagkas and Adam M Oberman},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A reproducible and realistic evaluation of partial domain adaptation methods},
  url          = {https://openreview.net/forum?id=XcVzIBXeRn},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contextualize me – the case for context in reinforcement
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Y42xVBQusn">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While Reinforcement Learning ( RL) has made great strides towards solving increasingly complicated problems, many algorithms are still brittle to even slight environmental changes. Contextual Reinforcement Learning (cRL) provides a framework to model such changes in a principled manner, thereby enabling flexible, precise and interpretable task specification and generation. Our goal is to show how the framework of cRL contributes to improving zero-shot generalization in RL through meaningful benchmarks and structured reasoning about generalization tasks. We confirm the insight that optimal behavior in cRL requires context information, as in other related areas of partial observability. To empirically validate this in the cRL framework, we provide various context-extended versions of common RL environments. They are part of the first benchmark library, CARL, designed for generalization based on cRL extensions of popular benchmarks, which we propose as a testbed to further study general agents. We show that in the contextual setting, even simple RL environments become challenging - and that naive solutions are not enough to generalize across complex context spaces.},
  archive      = {J_TMLR},
  author       = {Carolin Benjamins and Theresa Eimer and Frederik Schubert and Aditya Mohan and Sebastian Döhler and André Biedenkapp and Bodo Rosenhahn and Frank Hutter and Marius Lindauer},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Contextualize me – the case for context in reinforcement learning},
  url          = {https://openreview.net/forum?id=Y42xVBQusn},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Training with mixed-precision floating-point assignments.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ZoXi7n54OB">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When training deep neural networks, keeping all tensors in high precision (e.g., 32-bit or even 16-bit floats) is often wasteful. However, keeping all tensors in low precision (e.g., 8-bit floats) can lead to unacceptable accuracy loss. Hence, it is important to use a precision assignment—a mapping from all tensors (arising in training) to precision levels (high or low)—that keeps most of the tensors in low precision and leads to sufficiently accurate models. We provide a technique that explores this memory-accuracy tradeoff by generating precision assignments for convolutional neural networks that (i) use less memory and (ii) lead to more accurate convolutional networks at the same time, compared to the precision assignments considered by prior work in low-precision floating-point training. We evaluate our technique on image classiﬁcation tasks by training convolutional networks on CIFAR-10, CIFAR-100, and ImageNet. Our method typically provides &gt; 2× memory reduction over a baseline precision assignment while preserving training accuracy, and gives further reductions by trading off accuracy. Compared to other baselines which sometimes cause training to diverge, our method provides similar or better memory reduction while avoiding divergence.},
  archive      = {J_TMLR},
  author       = {Wonyeol Lee and Rahul Sharma and Alex Aiken},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Training with mixed-precision floating-point assignments},
  url          = {https://openreview.net/forum?id=ZoXi7n54OB},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Instance-adaptive video compression: Improving neural codecs
by training on the test set. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=akg6kdx0Pk">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a video compression algorithm based on instance-adaptive learning. On each video sequence to be transmitted, we finetune a pretrained compression model. The optimal parameters are transmitted to the receiver along with the latent code. By entropy-coding the parameter updates under a suitable mixture model prior, we ensure that the network parameters can be encoded efficiently. This instance-adaptive compression algorithm is agnostic about the choice of base model and has the potential to improve any neural video codec. On UVG, HEVC, and Xiph datasets, our codec improves the performance of a scale-space flow model by between 21% and 27% BD-rate savings, and that of a state-of-the-art B-frame model by 17 to 20% BD-rate savings. We also demonstrate that instance-adaptive finetuning improves the robustness to domain shift. Finally, our approach reduces the capacity requirements of compression models. We show that it enables a competitive performance even after reducing the network size by 70%.},
  archive      = {J_TMLR},
  author       = {Ties van Rozendaal and Johann Brehmer and Yunfan Zhang and Reza Pourreza and Auke J. Wiggers and Taco Cohen},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Instance-adaptive video compression: Improving neural codecs by training on the test set},
  url          = {https://openreview.net/forum?id=akg6kdx0Pk},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pareto optimization for active learning under
out-of-distribution data scenarios. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=dXnccpSSYF">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pool-based Active Learning (AL) has proven successful in minimizing labeling costs by sequentially selecting the most informative unlabeled data from large pool and querying their labels from an oracle or annotators. However, existing AL sampling schemes may not perform well in out-of-distribution (OOD) data scenarios, where the unlabeled data pool contains samples that do not belong to the pre-defined categories of the target task. Achieving strong AL performance under OOD data scenarios presents a challenge due to the inherent conflict between AL sampling strategies and OOD data detection. For instance, both more informative in-distribution (ID) data and OOD data in an unlabeled data pool would be assigned high informativeness scores (e.g., high entropy) during AL processes. To address this dilemma, we propose a Monte-Carlo Pareto Optimization for Active Learning (POAL) sampling scheme, which selects optimal subsets of unlabeled samples with fixed batch size from the unlabeled data pool. We formulate the AL sampling task as a multi-objective optimization problem and employ Pareto optimization based on two conflicting objectives: (1) the conventional AL sampling scheme (e.g., maximum entropy) and (2) the confidence of excluding OOD data samples. Experimental results demonstrate the effectiveness of our POAL approach on classical Machine Learning (ML) and Deep Learning (DL) tasks.},
  archive      = {J_TMLR},
  author       = {Xueying Zhan and Zeyu Dai and Qingzhong Wang and Qing Li and Haoyi Xiong and Dejing Dou and Antoni B. Chan},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Pareto optimization for active learning under out-of-distribution data scenarios},
  url          = {https://openreview.net/forum?id=dXnccpSSYF},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning symbolic rules for reasoning in quasi-natural
language. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=gwRwHUZUgz">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symbolic reasoning, rule-based symbol manipulation, is a hallmark of human intelligence. However, rule-based systems have had limited success competing with learning-based systems outside formalized domains such as automated theorem proving. We hypothesize that this is due to the manual construction of rules in past attempts. In this work, we take initial steps towards rule-based systems that can reason with natural language but without manually constructing rules. We propose MetaQNL, a &quot;Quasi-Natural Language&quot; that can express both formal logic and natural language sentences, and MetaInduce, a learning algorithm that induces MetaQNL rules from training data consisting of questions and answers, with or without intermediate reasoning steps. In addition, we introduce soft matching—a flexible mechanism for applying rules without rigid matching, overcoming a typical source of brittleness in symbolic reasoning. Our approach achieves state-of-the-art accuracies on multiple reasoning benchmarks; it learns compact models with much less data and produces not only answers but also checkable proofs. Further, experiments on two simple real-world datasets demonstrate the possibility for our method to handle noise and ambiguity.},
  archive      = {J_TMLR},
  author       = {Kaiyu Yang and Jia Deng},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning symbolic rules for reasoning in quasi-natural language},
  url          = {https://openreview.net/forum?id=gwRwHUZUgz},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Causally-guided regularization of graph attention improves
generalizability. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=iDNMZgjJuJ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph attention networks estimate the relational importance of node neighbors to aggregate relevant information over local neighborhoods for a prediction task. However, the inferred attentions are vulnerable to spurious correlations and connectivity in the training data, hampering the generalizability of models. We introduce CAR, a general-purpose regularization framework for graph attention networks. Embodying a causal inference approach based on invariance prediction, CAR aligns the attention mechanism with the causal effects of active interventions on graph connectivity in a scalable manner. CAR is compatible with a variety of graph attention architectures, and we show that it systematically improves generalizability on various node classification tasks. Our ablation studies indicate that CAR hones in on the aspects of graph structure most pertinent to the prediction (e.g., homophily), and does so more effectively than alternative approaches. Finally, we also show that \methodname enhances interpretability of attention coefficients by accentuating node-neighbor relations that point to causal hypotheses.},
  archive      = {J_TMLR},
  author       = {Alexander P Wu and Thomas Markovich and Bonnie Berger and Nils Yannick Hammerla and Rohit Singh},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Causally-guided regularization of graph attention improves generalizability},
  url          = {https://openreview.net/forum?id=iDNMZgjJuJ},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Empirical study on optimizer selection for
out-of-distribution generalization. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ipe0IMglFF">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern deep learning systems do not generalize well when the test data distribution is slightly different to the training data distribution. While much promising work has been accomplished to address this fragility, a systematic study of the role of optimizers and their out-of-distribution generalization performance has not been undertaken. In this study, we examine the performance of popular first-order optimizers for different classes of distributional shift under empirical risk minimization and invariant risk minimization. We address this question for image and text classification using DomainBed, WILDS, and Backgrounds Challenge as testbeds for studying different types of shifts---namely correlation and diversity shift. We search over a wide range of hyperparameters and examine classification accuracy (in-distribution and out-of-distribution) for over 20,000 models. We arrive at the following findings, which we expect to be helpful for practitioners: i) adaptive optimizers (e.g., Adam) perform worse than non-adaptive optimizers (e.g., SGD, momentum SGD) on out-of-distribution performance. In particular, even though there is no significant difference in in-distribution performance, we show a measurable difference in out-of-distribution performance. ii) in-distribution performance and out-of-distribution performance exhibit three types of behavior depending on the dataset---linear returns, increasing returns, and diminishing returns. For example, in the training of natural language data using Adam, fine-tuning the performance of in-distribution performance does not significantly contribute to the out-of-distribution generalization performance.},
  archive      = {J_TMLR},
  author       = {Hiroki Naganuma and Kartik Ahuja and Shiro Takagi and Tetsuya Motokawa and Rio Yokota and Kohta Ishikawa and Ikuro Sato and Ioannis Mitliagkas},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Empirical study on optimizer selection for out-of-distribution generalization},
  url          = {https://openreview.net/forum?id=ipe0IMglFF},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inherent limits on topology-based link prediction.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=izL3B8dPx1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction systems (e.g. recommender systems) typically use graph topology as one of their main sources of information. However, automorphisms and related properties of graphs beget inherent limits in predictability. We calculate hard upper bounds on how well graph topology alone enables link prediction for a wide variety of real-world graphs. We find that in the sparsest of these graphs the upper bounds are surprisingly low, thereby demonstrating that prediction systems on sparse graph data are inherently limited and require information in addition to the graph topology.},
  archive      = {J_TMLR},
  author       = {Justus Isaiah Hibshman and Tim Weninger},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Inherent limits on topology-based link prediction},
  url          = {https://openreview.net/forum?id=izL3B8dPx1},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predicting out-of-domain generalization with neighborhood
invariance. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=jYkWdJzTwn">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing and deploying machine learning models safely depends on the ability to char- acterize and compare their abilities to generalize to new environments. Although recent work has proposed a variety of methods that can directly predict or theoretically bound the generalization capacity of a model, they rely on strong assumptions such as matching train/test distributions and access to model gradients. In order to characterize generalization when these assumptions are not satisfied, we propose neighborhood invariance, a measure of a classifier’s output invariance in a local transformation neighborhood. Specifically, we sample a set of transformations and given an input test point, calculate the invariance as the largest fraction of transformed points classified into the same class. Crucially, our measure is simple to calculate, does not depend on the test point’s true label, makes no assumptions about the data distribution or model, and can be applied even in out-of-domain (OOD) settings where existing methods cannot, requiring only selecting a set of appropriate data transformations. In experiments on robustness benchmarks in image classification, sentiment analysis, and natural language inference, we demonstrate a strong and robust correlation between our neighborhood invariance measure and actual OOD generalization on over 4,600 models evaluated on over 100 train/test domain pairs.},
  archive      = {J_TMLR},
  author       = {Nathan Hoyen Ng and Neha Hulkund and Kyunghyun Cho and Marzyeh Ghassemi},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Predicting out-of-domain generalization with neighborhood invariance},
  url          = {https://openreview.net/forum?id=jYkWdJzTwn},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised domain adaptation via minimized joint error.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=kiPsMct7vL">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation transfers knowledge from a fully labeled source domain to a different target domain, where no labeled data are available. Some researchers have proposed upper bounds for the target error when transferring knowledge. For example, Ben-David et al. (2010) established a theory based on minimizing the source error and distance between marginal distributions simultaneously. However, in most research, the joint error is ignored because of its intractability. In this research, we argue that joint errors are essential for domain adaptation problems, particularly when the domain gap is large. To address this problem, we propose a novel objective related to the upper bound of the joint error. Moreover, we adopt a source/pseudo-target label-induced hypothesis space that can reduce the search space to further tighten this bound. To measure the dissimilarity between hypotheses, we define a novel cross-margin discrepancy to alleviate instability during adversarial learning. In addition, we present extensive empirical evidence showing that the proposed method boosts the performance of image classification accuracy on standard domain adaptation benchmarks.},
  archive      = {J_TMLR},
  author       = {Dexuan Zhang and Thomas Westfechtel and Tatsuya Harada},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unsupervised domain adaptation via minimized joint error},
  url          = {https://openreview.net/forum?id=kiPsMct7vL},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A kernel perspective on behavioural metrics for markov
decision processes. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=nHfPXl1ly7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel perspective on behavioural metrics for Markov decision processes via the use of positive definite kernels. We define a new metric under this lens that is provably equivalent to the recently introduced MICo distance (Castro et al., 2021). The kernel perspective enables us to provide new theoretical results, including value-function bounds and low-distortion finite-dimensional Euclidean embeddings, which are crucial when using behavioural metrics for reinforcement learning representations. We complement our theory with strong empirical results that demonstrate the effectiveness of these methods in practice.},
  archive      = {J_TMLR},
  author       = {Pablo Samuel Castro and Tyler Kastner and Prakash Panangaden and Mark Rowland},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A kernel perspective on behavioural metrics for markov decision processes},
  url          = {https://openreview.net/forum?id=nHfPXl1ly7},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Assuming locally equal calibration errors for non-parametric
multiclass calibration. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=na5sHG69rI">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A probabilistic classifier is considered calibrated if it outputs probabilities equal to the expected class distribution given the classifier&#39;s output. Calibration is essential in safety-critical tasks where small deviations between the predicted probabilities and the actually observed class proportions can incur high costs. A common approach to improve the calibration of a classifier is to use a hold-out data set and a post-hoc calibration method to learn a correcting transformation for the classifier&#39;s output. This work explores the field of post-hoc calibration methods for multi-class classifiers and formulates two assumptions about the probability simplex which have been used by many existing non-parametric calibration methods, but despite this, have never been explicitly stated: assuming locally equal label distributions or assuming locally equal calibration errors. Based on the latter assumption, an intuitive non-parametric post-hoc calibration method is proposed, which is shown to offer improvements to the state-of-the-art according to the expected calibration error metric on CIFAR-10 and CIFAR-100 data sets.},
  archive      = {J_TMLR},
  author       = {Kaspar Valk and Meelis Kull},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Assuming locally equal calibration errors for non-parametric multiclass calibration},
  url          = {https://openreview.net/forum?id=na5sHG69rI},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SC2 benchmark: Supervised compression for split computing.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=p28wv4G65d">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing demand for deep learning models on mobile devices, splitting neural network computation between the device and a more powerful edge server has become an attractive solution. However, existing split computing approaches often underperform compared to a naive baseline of remote computation on compressed data. Recent studies propose learning compressed representations that contain more relevant information for supervised downstream tasks, showing improved tradeoffs between compressed data size and supervised performance. However, existing evaluation metrics only provide an incomplete picture of split computing. This study introduces supervised compression for split computing (SC2) and proposes new evaluation criteria: minimizing computation on the mobile device, minimizing transmitted data size, and maximizing model accuracy. We conduct a comprehensive benchmark study using 10 baseline methods, three computer vision tasks, and over 180 trained models, and discuss various aspects of SC2. We also release our code and sc2bench, a Python package for future research on SC2. Our proposed metrics and package will help researchers better understand the tradeoffs of supervised compression in split computing.},
  archive      = {J_TMLR},
  author       = {Yoshitomo Matsubara and Ruihan Yang and Marco Levorato and Stephan Mandt},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SC2 benchmark: Supervised compression for split computing},
  url          = {https://openreview.net/forum?id=p28wv4G65d},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). When does uncertainty matter?: Understanding the impact of
predictive uncertainty in ML assisted decision making. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=pbs22kJmEO">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As machine learning (ML) models are increasingly being employed to assist human decision makers, it becomes critical to provide these decision makers with relevant inputs which can help them decide if and how to incorporate model predictions into their decision making. For instance, communicating the uncertainty associated with model predictions could potentially be helpful in this regard. In this work, we carry out user studies (1,330 responses from 190 participants) to systematically assess how people with differing levels of expertise respond to different types of predictive uncertainty (i.e., posterior predictive distributions with different shapes and variances) in the context of ML assisted decision making for predicting apartment rental prices. We found that showing posterior predictive distributions led to smaller disagreements with the ML model&#39;s predictions, regardless of the shapes and variances of the posterior predictive distributions we considered, and that these effects may be sensitive to expertise in both ML and the domain. This suggests that posterior predictive distributions can potentially serve as useful decision aids which should be used with caution and take into account the type of distribution and the expertise of the human.},
  archive      = {J_TMLR},
  author       = {Sean McGrath and Parth Mehta and Alexandra Zytek and Isaac Lage and Himabindu Lakkaraju},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {When does uncertainty matter?: Understanding the impact of predictive uncertainty in ML assisted decision making},
  url          = {https://openreview.net/forum?id=pbs22kJmEO},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The stack: 3 TB of permissively licensed source code.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=pxpbTdUEpD">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) play an ever-increasing role in the field of Artificial Intelligence (AI)--not only for natural language processing but also for code understanding and generation. To stimulate open and responsible research on LLMs for code, we introduce The Stack, a 3.1 TB dataset consisting of permissively licensed source code in 30 programming languages. We describe how we collect the full dataset, construct a permissively licensed subset, present a data governance plan, discuss limitations, and show promising results on text2code benchmarks by training 350M-parameter decoders on different Python subsets. We find that (1) near-deduplicating the data significantly boosts performance across all experiments, and (2) it is possible to match previously reported HumanEval and MBPP performance using only permissively licensed data. We make the dataset available at https://hf.co/BigCode, provide a tool called &quot;Am I in The Stack&quot; for developers to search The Stack for copies of their code (https://hf.co/spaces/bigcode/in-the-stack), and provide a process for code to be removed from the dataset.},
  archive      = {J_TMLR},
  author       = {Denis Kocetkov and Raymond Li and Loubna Ben allal and Jia LI and Chenghao Mou and Yacine Jernite and Margaret Mitchell and Carlos Muñoz Ferrandis and Sean Hughes and Thomas Wolf and Dzmitry Bahdanau and Leandro Von Werra and Harm de Vries},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The stack: 3 TB of permissively licensed source code},
  url          = {https://openreview.net/forum?id=pxpbTdUEpD},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Undersampling is a minimax optimal robustness intervention
in nonparametric classification. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=r6oHDYOZ6p">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While a broad range of techniques have been proposed to tackle distribution shift, the simple baseline of training on an undersampled balanced dataset often achieves close to state-of-the-art-accuracy across several popular benchmarks. This is rather surprising, since undersampling algorithms discard excess majority group data. To understand this phenomenon, we ask if learning is fundamentally constrained by a lack of minority group samples. We prove that this is indeed the case in the setting of nonparametric binary classification. Our results show that in the worst case, an algorithm cannot outperform undersampling unless there is a high degree of overlap between the train and test distributions (which is unlikely to be the case in real-world datasets), or if the algorithm leverages additional structure about the distribution shift. In particular, in the case of label shift we show that there is always an undersampling algorithm that is minimax optimal. In the case of group-covariate shift we show that there is an undersampling algorithm that is minimax optimal when the overlap between the group distributions is small. We also perform an experimental case study on a label shift dataset and find that in line with our theory, the test accuracy of robust neural network classifiers is constrained by the number of minority samples.},
  archive      = {J_TMLR},
  author       = {Niladri S. Chatterji and Saminul Haque and Tatsunori Hashimoto},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Undersampling is a minimax optimal robustness intervention in nonparametric classification},
  url          = {https://openreview.net/forum?id=r6oHDYOZ6p},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Noise-robust graph learning by estimating and leveraging
pairwise interactions. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=r7imkFEAQb">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Teaching Graph Neural Networks (GNNs) to accurately classify nodes under severely noisy labels is an important problem in real-world graph learning applications, but is currently underexplored. Although pairwise training methods have demonstrated promise in supervised metric learning and unsupervised contrastive learning, they remain less studied on noisy graphs, where the structural pairwise interactions (PI) between nodes are abundant and thus might benefit label noise learning rather than the pointwise methods. This paper bridges the gap by proposing a pairwise framework for noisy node classification on graphs, which relies on the PI as a primary learning proxy in addition to the pointwise learning from the noisy node class labels. Our proposed framework PI-GNN contributes two novel components: (1) a confidence-aware PI estimation model that adaptively estimates the PI labels, which are defined as whether the two nodes share the same node labels, and (2) a decoupled training approach that leverages the estimated PI labels to regularize a node classification model for robust node classification. Extensive experiments on different datasets and GNN architectures demonstrate the effectiveness of PI-GNN, yielding a promising improvement over the state-of-the-art methods. Code is publicly available at https://github.com/TianBian95/pi-gnn.},
  archive      = {J_TMLR},
  author       = {Xuefeng Du and Tian Bian and Yu Rong and Bo Han and Tongliang Liu and Tingyang Xu and Wenbing Huang and Yixuan Li and Junzhou Huang},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Noise-robust graph learning by estimating and leveraging pairwise interactions},
  url          = {https://openreview.net/forum?id=r7imkFEAQb},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TransFool: An adversarial attack against neural machine
translation models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=sFk3aBNb81">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have been shown to be vulnerable to small perturbations of their inputs, known as adversarial attacks. In this paper, we investigate the vulnerability of Neural Machine Translation (NMT) models to adversarial attacks and propose a new attack algorithm called TransFool. To fool NMT models, TransFool builds on a multi-term optimization problem and a gradient projection step. By integrating the embedding representation of a language model, we generate fluent adversarial examples in the source language that maintain a high level of semantic similarity with the clean samples. Experimental results demonstrate that, for different translation tasks and NMT architectures, our white-box attack can severely degrade the translation quality while the semantic similarity between the original and the adversarial sentences stays high. Moreover, we show that TransFool is transferable to unknown target models. Finally, based on automatic and human evaluations, TransFool leads to improvement in terms of success rate, semantic similarity, and fluency compared to the existing attacks both in white-box and black-box settings. Thus, TransFool permits us to better characterize the vulnerability of NMT models and outlines the necessity to design strong defense mechanisms and more robust NMT systems for real-life applications.},
  archive      = {J_TMLR},
  author       = {Sahar Sadrizadeh and Ljiljana Dolamic and Pascal Frossard},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {TransFool: An adversarial attack against neural machine translation models},
  url          = {https://openreview.net/forum?id=sFk3aBNb81},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring the approximation capabilities of multiplicative
neural networks for smooth functions. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=sWQJfb2GSk">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiplication layers are a key component in various influential neural network modules, including self-attention and hypernetwork layers. In this paper, we investigate the approximation capabilities of deep neural networks with intermediate neurons connected by simple multiplication operations. We consider two classes of target functions: generalized bandlimited functions, which are frequently used to model real-world signals with finite bandwidth, and Sobolev-Type balls, which are embedded in the Sobolev Space $\mathcal{W}^{r,2}$. Our results demonstrate that multiplicative neural networks can approximate these functions with significantly fewer layers and neurons compared to standard ReLU neural networks, with respect to both input dimension and approximation error. These findings suggest that multiplicative gates can outperform standard feed-forward layers and have potential for improving neural network design.},
  archive      = {J_TMLR},
  author       = {Ido Ben-Shaul and Tomer Galanti and Shai Dekel},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Exploring the approximation capabilities of multiplicative neural networks for smooth functions},
  url          = {https://openreview.net/forum?id=sWQJfb2GSk},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving differentially private SGD via randomly sparsified
gradients. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=sY35BAiIf4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differentially private stochastic gradient descent (DP-SGD) has been widely adopted in deep learning to provide rigorously defined privacy, which requires gradient clipping to bound the maximum norm of individual gradients and additive isotropic Gaussian noise. With analysis of the convergence rate of DP-SGD in a non-convex setting, we identify that randomly sparsifying gradients before clipping and noisification adjusts a trade-off between internal components of the convergence bound and leads to a smaller upper bound when the noise is dominant. Additionally, our theoretical analysis and empirical evaluations show that the trade-off is not trivial but possibly a unique property of DP-SGD, as either canceling noisification or gradient clipping eliminates the trade-off in the bound. This observation is indicative, as it implies DP-SGD has special inherent room for (even simply random) gradient compression. To verify the observation an utilize it, we propose an efficient and lightweight extension using random sparsification (RS) to strengthen DP-SGD. Experiments with various DP-SGD frameworks show that RS can improve performance. Additionally, the produced sparse gradients of RS exhibit advantages in reducing communication cost and strengthening privacy against reconstruction attacks, which are also key problems in private machine learning.},
  archive      = {J_TMLR},
  author       = {Junyi Zhu and Matthew B. Blaschko},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Improving differentially private SGD via randomly sparsified gradients},
  url          = {https://openreview.net/forum?id=sY35BAiIf4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bounded space differentially private quantiles.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=sixOD8YVvM">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the quantiles of a large dataset is a fundamental problem in both the streaming algorithms literature and the differential privacy literature. However, all existing private mechanisms for distribution-independent quantile computation require space at least linear in the input size $n$. In this work, we devise a differentially private algorithm for the quantile estimation problem, with strongly sublinear space complexity, in the one-shot and continual observation settings. Our basic mechanism estimates any $\alpha$-approximate quantile of a length-$n$ stream over a data universe $\mathcal{X}$ with probability $1-\beta$ using $O\left( \frac{\log (|\mathcal{X}|/\beta) \log (\alpha \epsilon n)}{\alpha \epsilon} \right)$ space while satisfying $\epsilon$-differential privacy at a single time point. Our approach builds upon deterministic streaming algorithms for non-private quantile estimation instantiating the exponential mechanism using a utility function defined on sketch items, while (privately) sampling from intervals defined by the sketch. We also present another algorithm based on histograms that is especially well-suited to the multiple quantiles case. We implement our algorithms and experimentally evaluate them on synthetic and real-world datasets.},
  archive      = {J_TMLR},
  author       = {Daniel Alabi and Omri Ben-Eliezer and Anamay Chaturvedi},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bounded space differentially private quantiles},
  url          = {https://openreview.net/forum?id=sixOD8YVvM},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Invariant feature coding using tensor product
representation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=uv32JOdQuh">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a novel feature coding method that exploits invariance for transformations represented by a finite group of orthogonal matrices is proposed. We prove that the group-invariant feature vector contains sufficient discriminative information when learning a linear classifier using convex loss minimization. Based on this result, a novel feature model that explicitly considers group action is proposed for principal component analysis and k-means clustering, which are commonly used in most feature coding methods, and global feature functions. Although the global feature functions are in general complex nonlinear functions, the group action on this space can be easily calculated by constructing these functions as tensor-product representations of basic representations, resulting in an explicit form of invariant feature functions. The effectiveness of our method is demonstrated on several image datasets.},
  archive      = {J_TMLR},
  author       = {YUSUKE Mukuta and Tatsuya Harada},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Invariant feature coding using tensor product representation},
  url          = {https://openreview.net/forum?id=uv32JOdQuh},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Privacy-preserving energy-based generative models for
marginal distribution protection. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=vTsfup5ll6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider learning generative models for sensitive financial and healthcare data. While previous work incorporates Differential Privacy (DP) into GAN training to protect the privacy of individual training instances, we consider a different privacy context where the primary objective is protecting the privacy of sensitive marginal distributions of the true generative process. We propose and motivate a new notion of privacy: \emph{$\alpha$-Level Marginal Distribution Privacy} ($\alpha$-LMDP), which provides a statistical guarantee that the sensitive generative marginal distributions are different from the observed real data. We then propose \emph{Privacy-Preserving Energy Models (PPEMs)}, a novel energy-based generative model formulation where the representations for these attributes are isolated from other attributes. This structured formulation motivates a learning procedure where a penalty based on a statistical goodness of fit test, the \emph{Kernel Stein Discrepancy}, can be applied to only the attributes requiring privacy so that $\alpha$-LMDP may be satisfied without affecting the other attributes. We evaluate this approach using financial and healthcare datasets and demonstrate that the resulting learnt generative models produce high fidelity synthetic data while preserving privacy. We also show that PPEMs can incorporate both $\alpha$-LMDP \emph{and} DP in contexts where both forms of privacy are required.},
  archive      = {J_TMLR},
  author       = {Robert E. Tillman and Tucker Balch and Manuela Veloso},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Privacy-preserving energy-based generative models for marginal distribution protection},
  url          = {https://openreview.net/forum?id=vTsfup5ll6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LEAD: Min-max optimization from a physical perspective.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=vXSsTYs6ZB">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial formulations such as generative adversarial networks (GANs) have rekindled interest in two-player min-max games. A central obstacle in the optimization of such games is the rotational dynamics that hinder their convergence. In this paper, we show that game optimization shares dynamic properties with particle systems subject to multiple forces, and one can leverage tools from physics to improve optimization dynamics. Inspired by the physical framework, we propose LEAD, an optimizer for min-max games. Next, using Lyapunov stability theory and spectral analysis, we study LEAD’s convergence properties in continuous and discrete time settings for a class of quadratic min-max games to demonstrate linear convergence to the Nash equilibrium. Finally, we empirically evaluate our method on synthetic setups and CIFAR-10 image generation to demonstrate improvements in GAN training.},
  archive      = {J_TMLR},
  author       = {Reyhane Askari Hemmat and Amartya Mitra and Guillaume Lajoie and Ioannis Mitliagkas},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {LEAD: Min-max optimization from a physical perspective},
  url          = {https://openreview.net/forum?id=vXSsTYs6ZB},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Releasing graph neural networks with differential privacy
guarantees. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=wk8oXR0kFA">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing popularity of graph neural networks (GNNs) in several sensitive applications like healthcare and medicine, concerns have been raised over the privacy aspects of trained GNNs. More notably, GNNs are vulnerable to privacy attacks, such as membership inference attacks, even if only black-box access to the trained model is granted. We propose PRIVGNN, a privacy-preserving framework for releasing GNN models in a centralized setting. Assuming an access to a public unlabeled graph, PRIVGNN provides a framework to release GNN models trained explicitly on public data along with knowledge obtained from the private data in a privacy preserving manner. PRIVGNN combines the knowledge-distillation framework with the two noise mechanisms, random subsampling, and noisy labeling, to ensure rigorous privacy guarantees. We theoretically analyze our approach in the Rènyi differential privacy framework. Besides, we show the solid experimental performance of our method compared to several baselines adapted for graph-structured data. Our code is available at https://github.com/iyempissy/privGnn.},
  archive      = {J_TMLR},
  author       = {Iyiola Emmanuel Olatunji and Thorben Funke and Megha Khosla},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Releasing graph neural networks with differential privacy guarantees},
  url          = {https://openreview.net/forum?id=wk8oXR0kFA},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Test-time adaptation for visual document understanding.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=zshemTAa6U">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For visual document understanding (VDU), self-supervised pretraining has been shown to successfully generate transferable representations, yet, effective adaptation of such representations to distribution shifts at test-time remains to be an unexplored area. We propose DocTTA, a novel test-time adaptation method for documents, that does source-free domain adaptation using unlabeled target document data. DocTTA leverages cross-modality self-supervised learning via masked visual language modeling, as well as pseudo labeling to adapt models learned on a \textit{source} domain to an unlabeled \textit{target} domain at test time. We introduce new benchmarks using existing public datasets for various VDU tasks, including entity recognition, key-value extraction, and document visual question answering. DocTTA shows significant improvements on these compared to the source model performance, up to 1.89\% in (F1 score), 3.43\% (F1 score), and 17.68\% (ANLS score), respectively.},
  archive      = {J_TMLR},
  author       = {Sayna Ebrahimi and Sercan O Arik and Tomas Pfister},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Test-time adaptation for visual document understanding},
  url          = {https://openreview.net/forum?id=zshemTAa6U},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-source transfer learning for deep model-based
reinforcement learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=1nhTDzxxMA">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A crucial challenge in reinforcement learning is to reduce the number of interactions with the environment that an agent requires to master a given task. Transfer learning proposes to address this issue by re-using knowledge from previously learned tasks. However, determining which source task qualifies as the most appropriate for knowledge extraction, as well as the choice regarding which algorithm components to transfer, represent severe obstacles to its application in reinforcement learning. The goal of this paper is to address these issues with modular multi-source transfer learning techniques. The proposed techniques automatically learn how to extract useful information from source tasks, regardless of the difference in state-action space and reward function. We support our claims with extensive and challenging cross-domain experiments for visual control.},
  archive      = {J_TMLR},
  author       = {Remo Sasso and Matthia Sabatelli and Marco A. Wiering},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Multi-source transfer learning for deep model-based reinforcement learning},
  url          = {https://openreview.net/forum?id=1nhTDzxxMA},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generating adversarial examples with task oriented
multi-objective optimization. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=2f81Q622ww">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models, even the-state-of-the-art ones, are highly vulnerable to adversarial examples. Adversarial training is one of the most efficient methods to improve the model&#39;s robustness. The key factor for the success of adversarial training is the capability to generate qualified and divergent adversarial examples which satisfy some objectives/goals (e.g., finding adversarial examples that maximize the model losses for simultaneously attacking multiple models). Therefore, multi-objective optimization (MOO) is a natural tool for adversarial example generation to achieve multiple objectives/goals simultaneously. However, we observe that a naive application of MOO tends to maximize all objectives/goals equally, without caring if an objective/goal has been achieved yet. This leads to useless effort to further improve the goal-achieved tasks, while putting less focus on the goal-unachieved tasks. In this paper, we propose \emph{Task Oriented MOO} to address this issue, in the context where we can explicitly define the goal achievement for a task. Our principle is to only maintain the goal-achieved tasks, while letting the optimizer spend more effort on improving the goal-unachieved tasks. We conduct comprehensive experiments for our Task Oriented MOO on various adversarial example generation schemes. The experimental results firmly demonstrate the merit of our proposed approach.},
  archive      = {J_TMLR},
  author       = {Anh Tuan Bui and Trung Le and He Zhao and Quan Hung Tran and Paul Montague and Dinh Phung},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Generating adversarial examples with task oriented multi-objective optimization},
  url          = {https://openreview.net/forum?id=2f81Q622ww},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep plug-and-play clustering with unknown number of
clusters. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=6rbcq0qacA">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is an essential task for the purpose that data points can be classified in an unsupervised manner. Most deep clustering algorithms are very effective when given the number of clusters K. However, when K is unknown, finding the appropriate K for these algorithms can be computationally expensive via model-selection criteria, and applying algorithms with an inaccurate K can hardly achieve the state-of-the-art performance. This paper proposes a plug-and-play clustering module to automatically adjust the number of clusters, which can be easily embedded into existing deep parametric clustering methods. By analyzing the goal of clustering, a split-and-merge framework is introduced to reduce the intra-class diversity and increase the inter-class difference, which leverages the entropy between different clusters. Specifically, given an initial clustering number, clusters can be split into sub-clusters or merged into super-clusters and converge to a stable number of K clusters at the end of training. Experiments on benchmark datasets demonstrate that the proposed method can achieve comparable performance with the state-of-the-art works without requiring the number of clusters.},
  archive      = {J_TMLR},
  author       = {An Xiao and Hanting Chen and Tianyu Guo and QINGHUA ZHANG and Yunhe Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Deep plug-and-play clustering with unknown number of clusters},
  url          = {https://openreview.net/forum?id=6rbcq0qacA},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modelling sequential branching dynamics with a multivariate
branching gaussian process. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=9KoBOlstTq">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Branching Gaussian Process (BGP) model is a modification of the Overlapping Mixture of Gaussian Processes (OMGP) where latent functions branch in time. The BGP model was introduced as a method to model bifurcations in single-cell gene expression data and order genes by inferring their branching time parameter. A limitation of the current BGP model is that the assignment of observations to latent functions is inferred independently for each output dimension (gene). This leads to inconsistent assignments across outputs and reduces the accuracy of branching time inference. Here, we propose a multivariate branching Gaussian process (MBGP) model to perform joint branch assignment inference across multiple output dimensions. This ensures that branch assignments are consistent and leverages more data for branching time inference. Model inference is more challenging than for the original BGP or OMGP models because assignment labels can switch from trunk to branch lineages as branching times change during inference. To scale up inference to large datasets we use sparse variational Bayesian inference. We examine the effectiveness of our approach on synthetic data and a single-cell RNA-Seq dataset from mouse haematopoietic stem cells (HSCs). Our approach ensures assignment consistency by design and achieves improved accuracy in branching time inference and assignment accuracy.},
  archive      = {J_TMLR},
  author       = {Elvijs Sarkans and Sumon Ahmed and Magnus Rattray and Alexis Boukouvalas},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Modelling sequential branching dynamics with a multivariate branching gaussian process},
  url          = {https://openreview.net/forum?id=9KoBOlstTq},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to look by self-prediction. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=9aXKUJEKwV">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a method for learning active vision skills, to move the camera to observe a robot&#39;s sensors from informative points of view, without external rewards or labels. We do this by jointly training a visual predictor network, which predicts future returns of the sensors using pixels, and a camera control agent, which we reward using the negative error of the predictor. The agent thus moves the camera to points of view that are most predictive for a chosen sensor, which we select using a conditioning input to the agent. We observe that despite this noisy learned reward function, the learned policies a exhibit competence by reliably framing the sensor in a specific location in the view, an emergent location which we call a behavioral fovea. We find that replacing the conventional camera with a foveal camera further increases the policies&#39; precision.},
  archive      = {J_TMLR},
  author       = {Matthew Koichi Grimes and Joseph Varughese Modayil and Piotr W Mirowski and Dushyant Rao and Raia Hadsell},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning to look by self-prediction},
  url          = {https://openreview.net/forum?id=9aXKUJEKwV},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comparative generalization bounds for deep neural networks.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=162TqkUNPO">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we investigate the generalization capabilities of deep neural networks. We introduce a novel measure of the effective depth of neural networks, defined as the first layer at which sample embeddings are separable using the nearest-class center classifier. Our empirical results demonstrate that, in standard classification settings, neural networks trained using Stochastic Gradient Descent (SGD) tend to have small effective depths. We also explore the relationship between effective depth, the complexity of the training dataset, and generalization. For instance, we find that the effective depth of a trained neural network increases as the proportion of random labels in the data rises. Finally, we derive a generalization bound by comparing the effective depth of a network with the minimal depth required to fit the same dataset with partially corrupted labels. This bound provides non-vacuous predictions of test performance and is found to be empirically independent of the actual depth of the network.},
  archive      = {J_TMLR},
  author       = {Tomer Galanti and Liane Galanti and Ido Ben-Shaul},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Comparative generalization bounds for deep neural networks},
  url          = {https://openreview.net/forum?id=162TqkUNPO},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Forces are not enough: Benchmark and critical evaluation for
machine learning force fields with molecular simulations. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=A8pqQipwkt">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Molecular dynamics (MD) simulation techniques are widely used for various natural science applications. Increasingly, machine learning (ML) force field (FF) models begin to replace ab-initio simulations by predicting forces directly from atomic structures. Despite significant progress in this area, such techniques are primarily benchmarked by their force/energy prediction errors, even though the practical use case would be to produce realistic MD trajectories. We aim to fill this gap by introducing a novel benchmark suite for ML MD simulation. We curate representative MD systems, including water, organic molecules, peptide, and materials, and design evaluation metrics corresponding to the scientific objectives of respective systems. We benchmark a collection of state-of-the-art (SOTA) ML FF models and illustrate, in particular, how the commonly benchmarked force accuracy is not well aligned with relevant simulation metrics. We demonstrate when and how selected SOTA methods fail, along with offering directions for further improvement. Specifically, we identify stability as a key metric for ML models to improve. Our benchmark suite comes with a comprehensive open-source codebase for training and simulation with ML FFs to facilitate future work.},
  archive      = {J_TMLR},
  author       = {Xiang Fu and Zhenghao Wu and Wujie Wang and Tian Xie and Sinan Keten and Rafael Gomez-Bombarelli and Tommi S. Jaakkola},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Forces are not enough: Benchmark and critical evaluation for machine learning force fields with molecular simulations},
  url          = {https://openreview.net/forum?id=A8pqQipwkt},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Denise: Deep robust principal component analysis for
positive semidefinite matrices. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=D45gGvUZp2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The robust PCA of covariance matrices plays an essential role when isolating key explanatory features. The currently available methods for performing such a low-rank plus sparse decomposition are matrix specific, meaning, those algorithms must re-run for every new matrix. Since these algorithms are computationally expensive, it is preferable to learn and store a function that nearly instantaneously performs this decomposition when evaluated. Therefore, we introduce Denise, a deep learning-based algorithm for robust PCA of covariance matrices, or more generally, of symmetric positive semidefinite matrices, which learns precisely such a function. Theoretical guarantees for Denise are provided. These include a novel universal approximation theorem adapted to our geometric deep learning problem and convergence to an optimal solution to the learning problem. Our experiments show that Denise matches state-of-the-art performance in terms of decomposition quality, while being approximately $2000\times$ faster than the state-of-the-art, principal component pursuit (PCP), and $200 \times$ faster than the current speed-optimized method, fast PCP.},
  archive      = {J_TMLR},
  author       = {Calypso Herrera and Florian Krach and Anastasis Kratsios and Pierre Ruyssen and Josef Teichmann},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Denise: Deep robust principal component analysis for positive semidefinite matrices},
  url          = {https://openreview.net/forum?id=D45gGvUZp2},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Conditional permutation invariant flows. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=DUsgPi3oCC">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a conditional generative probabilistic model of set-valued data with a tractable log density. This model is a continuous normalizing flow governed by permutation equivariant dynamics. These dynamics are driven by a learnable per-set-element term and pairwise interactions, both parametrized by deep neural networks. We illustrate the utility of this model via applications including (1) complex traffic scene generation conditioned on visually specified map information, and (2) object bounding box generation conditioned directly on images. We train our model by maximizing the expected likelihood of labeled conditional data under our flow, with the aid of a penalty that ensures the dynamics are smooth and hence efficiently solvable. Our method significantly outperforms non-permutation invariant baselines in terms of log likelihood and domain-specific metrics (offroad, collision, and combined infractions), yielding realistic samples that are difficult to distinguish from data.},
  archive      = {J_TMLR},
  author       = {Berend Zwartsenberg and Adam Scibior and Matthew Niedoba and Vasileios Lioutas and Justice Sefas and Yunpeng Liu and Setareh Dabiri and Jonathan Wilder Lavington and Trevor Campbell and Frank Wood},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Conditional permutation invariant flows},
  url          = {https://openreview.net/forum?id=DUsgPi3oCC},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpretable mixture of experts. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=DdZoPUPm0a">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need for reliable model explanations is prominent for many machine learning applications, particularly for tabular and time-series data as their use cases often involve high-stakes decision making. Towards this goal, we introduce a novel interpretable modeling framework, Interpretable Mixture of Experts (IME), that yields high accuracy, comparable to `black-box&#39; Deep Neural Networks (DNNs) in many cases, along with useful interpretability capabilities. IME consists of an assignment module and a mixture of experts, with each sample being assigned to a single expert for prediction. We introduce multiple options for IME based on the assignment and experts being interpretable. When the experts are chosen to be interpretable such as linear models, IME yields an inherently-interpretable architecture where the explanations produced by IME are the exact descriptions of how the prediction is computed. In addition to constituting a standalone inherently-interpretable architecture, IME has the premise of being integrated with existing DNNs to offer interpretability to a subset of samples while maintaining the accuracy of the DNNs. Through extensive experiments on 15 tabular and time-series datasets, IME is demonstrated to be more accurate than single interpretable models and perform comparably with existing state-of-the-art DNNs in accuracy. On most datasets, IME even outperforms DNNs, while providing faithful explanations. Lastly, IME&#39;s explanations are compared to commonly-used post-hoc explanations methods through a user study -- participants are able to better predict the model behavior when given IME explanations, while finding IME&#39;s explanations more faithful and trustworthy.},
  archive      = {J_TMLR},
  author       = {Aya Abdelsalam Ismail and Sercan O Arik and Jinsung Yoon and Ankur Taly and Soheil Feizi and Tomas Pfister},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Interpretable mixture of experts},
  url          = {https://openreview.net/forum?id=DdZoPUPm0a},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transformer for partial differential equations’ operator
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=EPPqt3uERT">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven learning of partial differential equations&#39; solution operators has recently emerged as a promising paradigm for approximating the underlying solutions. The solution operators are usually parameterized by deep learning models that are built upon problem-specific inductive biases. An example is a convolutional or a graph neural network that exploits the local grid structure where functions&#39; values are sampled. The attention mechanism, on the other hand, provides a flexible way to implicitly exploit the patterns within inputs, and furthermore, relationship between arbitrary query locations and inputs. In this work, we present an attention-based framework for data-driven operator learning, which we term Operator Transformer (OFormer). Our framework is built upon self-attention, cross-attention, and a set of point-wise multilayer perceptrons (MLPs), and thus it makes few assumptions on the sampling pattern of the input function or query locations. We show that the proposed framework is competitive on standard PDE benchmark problems and can flexibly be adapted to different types of grids.},
  archive      = {J_TMLR},
  author       = {Zijie Li and Kazem Meidani and Amir Barati Farimani},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Transformer for partial differential equations’ operator learning},
  url          = {https://openreview.net/forum?id=EPPqt3uERT},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data models for dataset drift controls in machine learning
with optical images. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=I4IkGmgFJz">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camera images are ubiquitous in machine learning research. They also play a central role in the delivery of important public services spanning medicine or environmental surveying. However, the application of machine learning models in these domains has been limited because of robustness concerns. A primary failure mode are performance drops due to differences between the training and deployment data. While there are methods to prospectively validate the robustness of machine learning models to such dataset drifts, existing approaches do not account for explicit models of machine learning&#39;s primary object of interest: the data. This limits our ability to study and understand the relationship between data generation and downstream machine learning model performance in a physically accurate manner. In this study, we demonstrate how to overcome this limitation by pairing traditional machine learning with physical optics to obtain explicit and differentiable data models. We demonstrate how such data models can be constructed for image data and used to control downstream machine learning model performance related to dataset drift. The findings are distilled into three applications. First, drift synthesis enables the controlled generation of physically faithful drift test cases to power model selection and targeted generalization. Second, the gradient connection between machine learning task model and data model allows advanced, precise tolerancing of task model sensitivity to changes in the data generation. These drift forensics can be used to precisely specify the acceptable data environments in which a task model may be run. Third, drift optimization opens up the possibility to create drifts that can help the task model learn better faster, effectively optimizing the data generating process itself to support the downstream machine vision task. This is an interesting upgrade to existing imaging pipelines which traditionally have been optimized to be consumed by human users but not machine learning models. Alongside the data model code we release two datasets to the public that we collected as part of this work. In total, the two datasets, Raw-Microscopy and Raw-Drone, comprise 1,488 scientifically calibrated reference raw sensor measurements, 8,928 raw intensity variations as well as 17,856 images processed through twelve data models with different configurations. A guide to access the open code and datasets is available at https://github.com/aiaudit-org/raw2logit.},
  archive      = {J_TMLR},
  author       = {Luis Oala and Marco Aversa and Gabriel Nobis and Kurt Willis and Yoan Neuenschwander and Michèle Buck and Christian Matek and Jerome Extermann and Enrico Pomarico and Wojciech Samek and Roderick Murray-Smith and Christoph Clausen and Bruno Sanguinetti},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Data models for dataset drift controls in machine learning with optical images},
  url          = {https://openreview.net/forum?id=I4IkGmgFJz},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ensembles for uncertainty estimation: Benefits of prior
functions and bootstrapping. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=IqJsyulDUX">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In machine learning, an agent needs to estimate uncertainty to efficiently explore and adapt and to make effective decisions. A common approach to uncertainty estimation maintains an ensemble of models. In recent years, several approaches have been proposed for training ensembles, and conflicting views prevail with regards to the importance of various ingredients of these approaches. In this paper, we aim to address the benefits of two ingredients -- prior functions and bootstrapping -- which have come into question. We show that prior functions can significantly improve an ensemble agent&#39;s joint predictions across inputs and that bootstrapping affords additional benefits if the signal-to-noise ratio varies across inputs. Our claims are justified by both theoretical and experimental results.},
  archive      = {J_TMLR},
  author       = {Vikranth Dwaracherla and Zheng Wen and Ian Osband and Xiuyuan Lu and Seyed Mohammad Asghari and Benjamin Van Roy},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Ensembles for uncertainty estimation: Benefits of prior functions and bootstrapping},
  url          = {https://openreview.net/forum?id=IqJsyulDUX},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lightweight learner for shared knowledge lifelong learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Jjl2c8kWUc">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Lifelong Learning (LL), agents continually learn as they encounter new conditions and tasks. Most current LL is limited to a single agent that learns tasks sequentially. Dedicated LL machinery is then deployed to mitigate the forgetting of old tasks as new tasks are learned. This is inherently slow. We propose a new Shared Knowledge Lifelong Learning (SKILL) challenge, which deploys a decentralized population of LL agents that each sequentially learn different tasks, with all agents operating independently and in parallel. After learning their respective tasks, agents share and consolidate their knowledge over a decentralized communication network, so that, in the end, all agents can master all tasks. We present one solution to SKILL which uses Lightweight Lifelong Learning (LLL) agents, where the goal is to facilitate efficient sharing by minimizing the fraction of the agent that is specialized for any given task. Each LLL agent thus consists of a common task-agnostic immutable part, where most parameters are, and individual task-specific modules that contain fewer parameters but are adapted to each task. Agents share their task-specific modules, plus summary information (&quot;task anchors&quot;) representing their tasks in the common task-agnostic latent space of all agents. Receiving agents register each received task-specific module using the corresponding anchor. Thus, every agent improves its ability to solve new tasks each time new task-specific modules and anchors are received. If all agents can communicate with all others, eventually all agents become identical and can solve all tasks. On a new, very challenging SKILL-102 dataset with 102 image classification tasks (5,033 classes in total, 2,041,225 training, 243,464 validation, and 243,464 test images), we achieve much higher (and SOTA) accuracy over 8 LL baselines, while also achieving near perfect parallelization. Code and data can be found at https://github.com/gyhandy/Shared-Knowledge-Lifelong-Learning},
  archive      = {J_TMLR},
  author       = {Yunhao Ge and Yuecheng Li and Di Wu and Ao Xu and Adam M. Jones and Amanda Sofie Rios and Iordanis Fostiropoulos and shixian wen and Po-Hsuan Huang and Zachary William Murdock and Gozde Sahin and Shuo Ni and Kiran Lekkala and Sumedh Anand Sontakke and Laurent Itti},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Lightweight learner for shared knowledge lifelong learning},
  url          = {https://openreview.net/forum?id=Jjl2c8kWUc},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A simulation environment and reinforcement learning method
for waste reduction. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=KSvr8A62MD">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In retail (e.g., grocery stores, apparel shops, online retailers), inventory managers have to balance short-term risk (no items to sell) with long-term-risk (over ordering leading to product waste). This balancing task is made especially hard due to the lack of information about future customer purchases. In this paper, we study the problem of restocking a grocery store’s inventory with perishable items over time, from a distributional point of view. The objective is to maximize sales while minimizing waste, with uncertainty about the actual consumption by costumers. This problem is of a high relevance today, given the growing demand for food and the impact of food waste on the environment, the economy, and purchasing power. We frame inventory restocking as a new reinforcement learning task that exhibits stochastic behavior conditioned on the agent’s actions, making the environment partially observable. We make two main contributions. First, we introduce a new reinforcement learning environment, RetaiL, based on real grocery store data and expert knowledge. This environment is highly stochastic, and presents a unique challenge for reinforcement learning practitioners. We show that uncertainty about the future behavior of the environment is not handled well by classical supply chain algorithms, and that distributional approaches are a good way to account for the uncertainty. Second, we introduce GTDQN, a distributional reinforcement learning algorithm that learns a generalized lambda distribution over the reward space. GTDQN provides a strong baseline for our environment. It outperforms other distributional reinforcement learning approaches in this partially observable setting, in both overall reward and generated waste.},
  archive      = {J_TMLR},
  author       = {Sami Jullien and Mozhdeh Ariannezhad and Paul Groth and Maarten de Rijke},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A simulation environment and reinforcement learning method for waste reduction},
  url          = {https://openreview.net/forum?id=KSvr8A62MD},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retiring <span class="math inline"><em>Δ</em>DP</span>: New
distribution-level metrics for demographic parity. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=LjDFIWWVVa">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Demographic parity is the most widely recognized measure of group fairness in machine learning, which ensures equal treatment of different demographic groups. Numerous works aim to achieve demographic parity by pursuing the commonly used metric $\Delta DP$. Unfortunately, in this paper, we reveal that the fairness metric $\Delta DP$ can not precisely measure the violation of demographic parity, because it inherently has the following drawbacks: i) zero-value $\Delta DP$ does not guarantee zero violation of demographic parity, ii) $\Delta DP$ values can vary with different classification thresholds. To this end, we propose two new fairness metrics, Area Between Probability density function Curves (ABPC) and Area Between Cumulative density function Curves (ABCC), to precisely measure the violation of demographic parity at the distribution level. The new fairness metrics directly measure the difference between the distributions of the prediction probability for different demographic groups. Thus our proposed new metrics enjoy: i) zero-value ABCC/ABPC guarantees zero violation of demographic parity; ii) ABCC/ABPC guarantees demographic parity while the classification thresholds are adjusted. We further re-evaluate the existing fair models with our proposed fairness metrics and observe different fairness behaviors of those models under the new metrics.},
  archive      = {J_TMLR},
  author       = {Xiaotian Han and Zhimeng Jiang and Hongye Jin and Zirui Liu and Na Zou and Qifan Wang and Xia Hu},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Retiring $\Delta \text{DP}$: New distribution-level metrics for demographic parity},
  url          = {https://openreview.net/forum?id=LjDFIWWVVa},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Trip-ROMA: Self-supervised learning with triplets and random
mappings. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=MR4glug5GU">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive self-supervised learning (SSL) methods, such as MoCo and SimCLR, have achieved great success in unsupervised visual representation learning. They rely on a large number of negative pairs and thus require either large memory banks or large batches. Some recent non-contrastive SSL methods, such as BYOL and SimSiam, attempt to discard negative pairs and have also shown remarkable performance. To avoid collapsed solutions caused by not using negative pairs, these methods require non-trivial asymmetry designs. However, in small data regimes, we can not obtain a sufficient number of negative pairs or effectively avoid the over-fitting problem when negatives are not used at all. To address this situation, we argue that negative pairs are still important but one is generally sufficient for each positive pair. We show that a simple Triplet-based loss (Trip) can achieve surprisingly good performance without requiring large batches or asymmetry designs. Moreover, to alleviate the over-fitting problem in small data regimes and further enhance the effect of Trip, we propose a simple plug-and-play RandOm MApping (ROMA) strategy by randomly mapping samples into other spaces and requiring these randomly projected samples to satisfy the same relationship indicated by the triplets. Integrating the triplet-based loss with random mapping, we obtain the proposed method Trip-ROMA. Extensive experiments, including unsupervised representation learning and unsupervised few-shot learning, have been conducted on ImageNet-1K and seven small datasets. They successfully demonstrate the effectiveness of Trip-ROMA and consistently show that ROMA can further effectively boost other SSL methods. Code is available at https://github.com/WenbinLee/Trip-ROMA.},
  archive      = {J_TMLR},
  author       = {Wenbin Li and Xuesong Yang and Meihao Kong and Lei Wang and Jing Huo and Yang Gao and Jiebo Luo},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Trip-ROMA: Self-supervised learning with triplets and random mappings},
  url          = {https://openreview.net/forum?id=MR4glug5GU},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Successor feature representations. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=MTFf1rDDEI">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer in Reinforcement Learning aims to improve learning performance on target tasks using knowledge from experienced source tasks. Successor Representations (SR) and their extension Successor Features (SF) are prominent transfer mechanisms in domains where reward functions change between tasks. They reevaluate the expected return of previously learned policies in a new target task to transfer their knowledge. The SF framework extended SR by linearly decomposing rewards into successor features and a reward weight vector allowing their application in high-dimensional tasks. But this came with the cost of having a linear relationship between reward functions and successor features, limiting its application to tasks where such a linear relationship exists. We propose a novel formulation of SR based on learning the cumulative discounted probability of successor features, called Successor Feature Representations (SFR). Crucially, SFR allows to reevaluate the expected return of policies for general reward functions. We introduce different SFR variations, prove its convergence, and provide a guarantee on its transfer performance. Experimental evaluations based on SFR with function approximation demonstrate its advantage over SF not only for general reward functions, but also in the case of linearly decomposable reward functions.},
  archive      = {J_TMLR},
  author       = {Chris Reinke and Xavier Alameda-Pineda},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Successor feature representations},
  url          = {https://openreview.net/forum?id=MTFf1rDDEI},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Know your self-supervised learning: A survey on image-based
generative and discriminative training. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Ma25S4ludQ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although supervised learning has been highly successful in improving the state-of-the-art in the domain of image-based computer vision in the past, the margin of improvement has diminished significantly in recent years, indicating that a plateau is in sight. Meanwhile, the use of self-supervised learning (SSL) for the purpose of natural language processing (NLP) has seen tremendous successes during the past couple of years, with this new learning paradigm yielding powerful language models. Inspired by the excellent results obtained in the field of NLP, self-supervised methods that rely on clustering, contrastive learning, distillation, and information-maximization, which all fall under the banner of discriminative SSL, have experienced a swift uptake in the area of computer vision. Shortly afterwards, generative SSL frameworks that are mostly based on masked image modeling, complemented and surpassed the results obtained with discriminative SSL. Consequently, within a span of three years, over $100$ unique general-purpose frameworks for generative and discriminative SSL, with a focus on imaging, were proposed. In this survey, we review a plethora of research efforts conducted on image-oriented SSL, providing a historic view and paying attention to best practices as well as useful software packages. While doing so, we discuss pretext tasks for image-based SSL, as well as techniques that are commonly used in image-based SSL. Lastly, to aid researchers who aim at contributing to image-focused SSL, we outline a number of promising research directions.},
  archive      = {J_TMLR},
  author       = {Utku Ozbulak and Hyun Jung Lee and Beril Boga and Esla Timothy Anzaku and Ho-min Park and Arnout Van Messem and Wesley De Neve and Joris Vankerschaver},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Know your self-supervised learning: A survey on image-based generative and discriminative training},
  url          = {https://openreview.net/forum?id=Ma25S4ludQ},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast treatment personalization with latent bandits in
fixed-confidence pure exploration. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=NNRIGE8bvF">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalizing treatments for patients often involves a period of trial-and-error search until an optimal choice is found. To minimize suffering and other costs, it is critical to make this process as short as possible. When treatments have primarily short-term effects, search can be performed with multi-armed bandits (MAB), but these typically require long exploration periods to guarantee optimality. In this work, we design MAB algorithms which provably identify optimal treatments quickly by leveraging prior knowledge of the types of decision processes (patients) we can encounter, in the form of a latent variable model. We present two algorithms, the Latent LP-based Track and Stop (LLPT) explorer and the Divergence Explorer for this setting: fixed-confidence pure-exploration latent bandits. We give a lower bound on the stopping time of any algorithm which is correct at a given certainty level, and prove that the expected stopping time of the LLPT Explorer matches the lower bound in the high-certainty limit. Finally, we present results from an experimental study based on realistic simulation data for Alzheimer&#39;s disease, demonstrating that our formulation and algorithms lead to a significantly reduced stopping time.},
  archive      = {J_TMLR},
  author       = {Newton Mwai Kinyanjui and Emil Carlsson and Fredrik D. Johansson},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Fast treatment personalization with latent bandits in fixed-confidence pure exploration},
  url          = {https://openreview.net/forum?id=NNRIGE8bvF},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph-based multi-ODE neural networks for spatio-temporal
traffic forecasting. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Oq5XKRVYpQ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a recent surge in the development of spatio-temporal forecasting models in the transportation domain. Long-range traffic forecasting, however, remains a challenging task due to the intricate and extensive spatio-temporal correlations observed in traffic networks. Current works primarily rely on road networks with graph structures and learn representations using graph neural networks (GNNs), but this approach suffers from over-smoothing problem in deep architectures. To tackle this problem, recent methods introduced the combination of GNNs with residual connections or neural ordinary differential equations (ODE). However, current graph ODE models face two key limitations in feature extraction: (1) they lean towards global temporal patterns, overlooking local patterns that are important for unexpected events; and (2) they lack dynamic semantic edges in their architectural design. In this paper, we propose a novel architecture called Graph-based Multi-ODE Neural Networks (GRAM-ODE) which is designed with multiple connective ODE-GNN modules to learn better representations by capturing different views of complex local and global dynamic spatio-temporal dependencies. We also add some techniques like shared weights and divergence constraints into the intermediate layers of distinct ODE-GNN modules to further improve their communication towards the forecasting task. Our extensive set of experiments conducted on six real-world datasets demonstrate the superior performance of GRAM-ODE compared with state-of-the-art baselines as well as the contribution of different components to the overall performance.},
  archive      = {J_TMLR},
  author       = {Zibo Liu and Parshin Shojaee and Chandan K. Reddy},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Graph-based multi-ODE neural networks for spatio-temporal traffic forecasting},
  url          = {https://openreview.net/forum?id=Oq5XKRVYpQ},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A measure of the complexity of neural representations based
on partial information decomposition. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=R8TU3pfzFr">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In neural networks, task-relevant information is represented jointly by groups of neurons. However, the specific way in which this mutual information about the classification label is distributed among the individual neurons is not well understood: While parts of it may only be obtainable from specific single neurons, other parts are carried redundantly or synergistically by multiple neurons. We show how Partial Information Decomposition (PID), a recent extension of information theory, can disentangle these different contributions. From this, we introduce the measure of ``Representational Complexity&#39;&#39;, which quantifies the difficulty of accessing information spread across multiple neurons. We show how this complexity is directly computable for smaller layers. For larger layers, we propose subsampling and coarse-graining procedures and prove corresponding bounds on the latter. Empirically, for quantized deep neural networks solving the MNIST and CIFAR10 tasks, we observe that representational complexity decreases both through successive hidden layers and over training, and compare the results to related measures. Overall, we propose representational complexity as a principled and interpretable summary statistic for analyzing the structure and evolution of neural representations and complex systems in general.},
  archive      = {J_TMLR},
  author       = {David Alexander Ehrlich and Andreas Christian Schneider and Viola Priesemann and Michael Wibral and Abdullah Makkeh},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A measure of the complexity of neural representations based on partial information decomposition},
  url          = {https://openreview.net/forum?id=R8TU3pfzFr},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Aux-drop: Handling haphazard inputs in online learning using
auxiliary dropouts. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=R9CgBkeZ6Z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world applications based on online learning produce streaming data that is haphazard in nature, i.e., contains missing features, features becoming obsolete in time, the appearance of new features at later points in time and a lack of clarity on the total number of input features. These challenges make it hard to build a learnable system for such applications, and almost no work exists in deep learning that addresses this issue. In this paper, we present Aux-Drop, an auxiliary dropout regularization strategy for online learning that handles the haphazard input features in an effective manner. Aux-Drop adapts the conventional dropout regularization scheme for the haphazard input feature space ensuring that the final output is minimally impacted by the chaotic appearance of such features. It helps to prevent the co-adaptation of especially the auxiliary and base features, as well as reduces the strong dependence of the output on any of the auxiliary inputs of the model. This helps in better learning for scenarios where certain features disappear in time or when new features are to be modeled. The efficacy of Aux-Drop has been demonstrated through extensive numerical experiments on SOTA benchmarking datasets that include Italy Power Demand, HIGGS, SUSY and multiple UCI datasets. The code is available at https://github.com/Rohit102497/Aux-Drop.},
  archive      = {J_TMLR},
  author       = {Rohit Agarwal and Deepak Gupta and Alexander Horsch and Dilip K. Prasad},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Aux-drop: Handling haphazard inputs in online learning using auxiliary dropouts},
  url          = {https://openreview.net/forum?id=R9CgBkeZ6Z},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Agent-state construction with auxiliary inputs.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=RLYkyucU6k">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many, if not every realistic sequential decision-making task, the decision-making agent is not able to model the full complexity of the world. The environment is often much larger and more complex than the agent, a setting also known as partial observability. In such settings, the agent must leverage more than just the current sensory inputs; it must construct an agent state that summarizes previous interactions with the world. Currently, a popular approach for tackling this problem is to learn the agent-state function via a recurrent network from the agent&#39;s sensory stream as input. Many impressive reinforcement learning applications have instead relied on environment-specific functions to aid the agent&#39;s inputs for history summarization. These augmentations are done in multiple ways, from simple approaches like concatenating observations to more complex ones such as uncertainty estimates. Although ubiquitous in the field, these additional inputs, which we term auxiliary inputs, are rarely emphasized, and it is not clear what their role or impact is. In this work we explore this idea further, and relate these auxiliary inputs to prior classic approaches to state construction. We present a series of examples illustrating the different ways of using auxiliary inputs for reinforcement learning. We show that these auxiliary inputs can be used to discriminate between observations that would otherwise be aliased, leading to more expressive features that smoothly interpolate between different states. Finally, we show that this approach is complementary to state-of-the-art methods such as recurrent neural networks and truncated back-propagation through time, and acts as a heuristic that facilitates longer temporal credit assignment, leading to better performance.},
  archive      = {J_TMLR},
  author       = {Ruo Yu Tao and Adam White and Marlos C. Machado},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Agent-state construction with auxiliary inputs},
  url          = {https://openreview.net/forum?id=RLYkyucU6k},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Assisted learning for organizations with limited imbalanced
data. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=SEDWlhcFWA">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of big data, many big organizations are integrating machine learning into their work pipelines to facilitate data analysis. However, the performance of their trained models is often restricted by limited and imbalanced data available to them. In this work, we develop an assisted learning framework for assisting organizations to improve their learning performance. The organizations have sufficient computation resources but are subject to stringent data-sharing and collaboration policies. Their limited imbalanced data often cause biased inference and sub-optimal decision-making. In assisted learning, an organizational learner purchases assistance service from an external service provider and aims to enhance its model performance within only a few assistance rounds. We develop effective stochastic training algorithms for both assisted deep learning and assisted reinforcement learning. Different from existing distributed algorithms that need to frequently transmit gradients or models, our framework allows the learner to only occasionally share information with the service provider, but still obtain a model that achieves near-oracle performance as if all the data were centralized.},
  archive      = {J_TMLR},
  author       = {Cheng Chen and Jiaying Zhou and Jie Ding and Yi Zhou},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Assisted learning for organizations with limited imbalanced data},
  url          = {https://openreview.net/forum?id=SEDWlhcFWA},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning interpolations between boltzmann densities.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=TH6YrEcbth">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a training objective for continuous normalizing flows that can be used in the absence of samples but in the presence of an energy function. Our method relies on either a prescribed or a learnt interpolation $f_t$ of energy functions between the target energy $f_1$ and the energy function of a generalized Gaussian $f_0(x) = ||x/\sigma||_p^p$. The interpolation of energy functions induces an interpolation of Boltzmann densities $p_t \propto e^{-f_t}$ and we aim to find a time-dependent vector field $V_t$ that transports samples along the family $p_t$ of densities. The condition of transporting samples along the family $p_t$ is equivalent to satisfying the continuity equation with $V_t$ and $p_t = Z_t^{-1}e^{-f_t}$. Consequently, we optimize $V_t$ and $f_t$ to satisfy this partial differential equation. We experimentally compare the proposed training objective to the reverse KL-divergence on Gaussian mixtures and on the Boltzmann density of a quantum mechanical particle in a double-well potential.},
  archive      = {J_TMLR},
  author       = {Bálint Máté and François Fleuret},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning interpolations between boltzmann densities},
  url          = {https://openreview.net/forum?id=TH6YrEcbth},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Soft diffusion: Score matching with general corruptions.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=W98rebBxlQ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We define a broader family of corruption processes that generalizes previously known diffusion models. To reverse these general diffusions, we propose a new objective called Soft Score Matching. Soft Score Matching incorporates the degradation process in the network and provably learns the score function for any linear corruption process. Our new loss trains the model to predict a clean image, that after corruption, matches the diffused observation. This objective learns the gradient of the likelihood under suitable regularity conditions for the family of linear corruption processes. We further develop an algorithm to select the corruption levels for general diffusion processes and a novel sampling method that we call Momentum Sampler. We show experimentally that our framework works for general linear corruption processes, such as Gaussian blur and masking. Our method outperforms all linear diffusion models on CelebA-64 achieving FID score 1.85. We also show computational benefits compared to vanilla denoising diffusion.},
  archive      = {J_TMLR},
  author       = {Giannis Daras and Mauricio Delbracio and Hossein Talebi and Alex Dimakis and Peyman Milanfar},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Soft diffusion: Score matching with general corruptions},
  url          = {https://openreview.net/forum?id=W98rebBxlQ},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalizability of adversarial robustness under
distribution shifts. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=XNFo3dQiCJ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent progress in empirical and certified robustness promises to deliver reliable and deployable Deep Neural Networks (DNNs). Despite that success, most existing evaluations of DNN robustness have been done on images sampled from the same distribution on which the model was trained on. However, in the real world, DNNs may be deployed in dynamic environments that exhibit significant distribution shifts. In this work, we take a first step towards thoroughly investigating the interplay between empirical and certified adversarial robustness on one hand and domain generalization on another. To do so, we train robust models on multiple domains and evaluate their accuracy and robustness on an unseen domain. We observe that: (1) both empirical and certified robustness generalize to unseen domains, and (2) the level of generalizability does not correlate well with input visual similarity, measured by the FID between source and target domains. We also extend our study to cover a real-world medical application, in which adversarial augmentation significantly boosts the generalization of robustness with minimal effect on clean data accuracy.},
  archive      = {J_TMLR},
  author       = {Kumail Alhamoud and Hasan Abed Al Kader Hammoud and Motasem Alfarra and Bernard Ghanem},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Generalizability of adversarial robustness under distribution shifts},
  url          = {https://openreview.net/forum?id=XNFo3dQiCJ},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Event tables for efficient experience replay. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=XejzjAjKjv">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experience replay (ER) is a crucial component of many deep reinforcement learning (RL) systems. However, uniform sampling from an ER buffer can lead to slow convergence and unstable asymptotic behaviors. This paper introduces Stratified Sampling from Event Tables (SSET), which partitions an ER buffer into Event Tables, each capturing important subsequences of optimal behavior. We prove a theoretical advantage over the traditional monolithic buffer approach and combine SSET with an existing prioritized sampling strategy to further improve learning speed and stability. Empirical results in challenging MiniGrid domains, benchmark RL environments, and a high-fidelity car racing simulator demonstrate the advantages and versatility of SSET over existing ER buffer sampling},
  archive      = {J_TMLR},
  author       = {Varun Raj Kompella and Thomas Walsh and Samuel Barrett and Peter R. Wurman and Peter Stone},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Event tables for efficient experience replay},
  url          = {https://openreview.net/forum?id=XejzjAjKjv},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Do vision-language pretrained models learn composable
primitive concepts? <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=YwNrPLjHSL">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-language (VL) pretrained models have achieved impressive performance on multimodal reasoning and zero-shot recognition tasks. Many of these VL models are pretrained on unlabeled image and caption pairs from the internet. In this paper, we study whether representations of primitive concepts–such as colors, shapes, or the attributes of object parts–emerge automatically within these pretrained VL models. We propose a two-step framework, Compositional Concept Mapping (CompMap), to investigate this. CompMap first asks a VL model to generate concept activations with text prompts from a predefined list of primitive concepts, and then learns to construct an explicit composition model that maps the primitive concept activations (e.g. the likelihood of black tail or red wing) to com- posite concepts (e.g. a red-winged blackbird). We demonstrate that a composition model can be designed as a set operation, and show that a composition model is straightforward for machines to learn from ground truth primitive concepts (as a linear classifier). We thus hypothesize that if primitive concepts indeed emerge in a VL pretrained model, its primitive concept activations can be used to learn a composition model similar to the one designed by experts. We propose a quantitative metric to measure the degree of similarity, and refer to the metric as the interpretability of the VL models’ learned primitive concept representations. We also measure the classification accuracy when using the primitive concept activations and the learned composition model to predict the composite concepts, and refer to it as the usefulness metric. Our study reveals that state-of-the-art VL pretrained models learn primitive concepts that are highly useful for fine-grained visual recognition on the CUB dataset, and compositional generalization tasks on the MIT-States dataset. However, we observe that the learned composition models have low interpretability in our qualitative analyses. Our results reveal the limitations of existing VL models, and the necessity of pretraining objectives that encourage the acquisition of primitive concepts.},
  archive      = {J_TMLR},
  author       = {Tian Yun and Usha Bhalla and Ellie Pavlick and Chen Sun},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Do vision-language pretrained models learn composable primitive concepts?},
  url          = {https://openreview.net/forum?id=YwNrPLjHSL},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mean-field control based approximation of multi-agent
reinforcement learning in presence of a non-decomposable shared global
state. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ZME2nZMTvY">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mean Field Control (MFC) is a powerful approximation tool to solve large-scale Multi-Agent Reinforcement Learning (MARL) problems. However, the success of MFC relies on the presumption that given the local states and actions of all the agents, the next (local) states of the agents evolve conditionally independent of each other. Here we demonstrate that even in a MARL setting where agents share a common global state in addition to their local states evolving conditionally independently (thus introducing a correlation between the state transition processes of individual agents), the MFC can still be applied as a good approximation tool. The global state is assumed to be non-decomposable i.e., it cannot be expressed as a collection of local states of the agents. We compute the approximation error as $\mathcal{O}(e)$ where $e=\frac{1}{\sqrt{N}}\left[\sqrt{|\mathcal{X}|} +\sqrt{|\mathcal{U}|}\right]$. The size of the agent population is denoted by the term $N$, and $|\mathcal{X}|, |\mathcal{U}|$ respectively indicate the sizes of (local) state and action spaces of individual agents. The approximation error is found to be independent of the size of the shared global state space. We further demonstrate that in a special case if the reward and state transition functions are independent of the action distribution of the population, then the error can be improved to $e=\frac{\sqrt{|\mathcal{X}|}}{\sqrt{N}}$. Finally, we devise a Natural Policy Gradient based algorithm that solves the MFC problem with $\mathcal{O}(\epsilon^{-3})$ sample complexity and obtains a policy that is within $\mathcal{O}(\max\{e,\epsilon\})$ error of the optimal MARL policy for any $\epsilon&gt;0$.},
  archive      = {J_TMLR},
  author       = {Washim Uddin Mondal and Vaneet Aggarwal and Satish Ukkusuri},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Mean-field control based approximation of multi-agent reinforcement learning in presence of a non-decomposable shared global state},
  url          = {https://openreview.net/forum?id=ZME2nZMTvY},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Guillotine regularization: Why removing layers is needed to
improve generalization in self-supervised learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ZgXfXSz51n">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One unexpected technique that emerged in recent years consists in training a Deep Network (DN) with a Self-Supervised Learning (SSL) method, and using this network on downstream tasks but with its last few layers entirely removed. This usually skimmed-over trick of throwing away the entire projector is actually critical for SSL methods to display competitive performances. For example, on ImageNet classification, more than 30 points of percentage can be gained that way. This is a little vexing, as one would hope that the network layer at which invariance is explicitly enforced by the SSL criterion during training (the last layer) should be the one to use for best generalization performance downstream. But it seems not to be, and this study sheds some light on why. This trick, which we name Guillotine Regularization (GR), is in fact a generically applicable method that has been used to improve generalization performance in transfer learning scenarios. In this work, we identify the underlying reasons behind its success and challenge the preconceived idea that we should through away the entire projector in SSL. In fact, the optimal layer to use might change significantly depending on the training setup, the data or the downstream task. Lastly, we give some insights on how to reduce the need for a projector in SSL by aligning the pretext SSL task and the downstream task.},
  archive      = {J_TMLR},
  author       = {Florian Bordes and Randall Balestriero and Quentin Garrido and Adrien Bardes and Pascal Vincent},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Guillotine regularization: Why removing layers is needed to improve generalization in self-supervised learning},
  url          = {https://openreview.net/forum?id=ZgXfXSz51n},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fairness via in-processing in the over-parameterized regime:
A cautionary tale with MinDiff loss. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=f4VyYhkRvi">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prior work has observed that the test error of state-of-the-art deep neural networks often continues to decrease with increasing over-parameterization, a phenomenon referred to as double descent. This allows deep learning engineers to instantiate large models without having to worry about over-fitting. Despite its benefits, however, prior work has shown that over-parameterization can exacerbate bias against minority subgroups. Several fairness-constrained DNN training methods have been proposed to address this concern. Here, we critically examine MinDiff, a fairness-constrained training procedure implemented within TensorFlow&#39;s Responsible AI Toolkit, that aims to achieve Equality of Opportunity. We show that although MinDiff improves fairness for under-parameterized models, it is likely to be ineffective in the over-parameterized regime. This is because an overfit model with zero training loss is trivially group-wise fair on training data, creating an “illusion of fairness,” thus turning off the MinDiff optimization (this will apply to any disparity-based measures which care about errors or accuracy; while it won’t apply to demographic parity). We find that within specified fairness constraints, under-parameterized MinDiff models can even have lower error compared to their over-parameterized counterparts (despite baseline over-parameterized models having lower error compared to their under-parameterized counterparts). We further show that MinDiff optimization is very sensitive to choice of batch size in the under-parameterized regime. Thus, fair model training using MinDiff requires time-consuming hyper-parameter searches. Finally, we suggest using previously proposed regularization techniques, viz. L2, early stopping and flooding in conjunction with MinDiff to train fair over-parameterized models. In our results, over-parameterized models trained using MinDiff+regularization with standard batch sizes are fairer than their under-parameterized counterparts, suggesting that at the very least, regularizers should be integrated into fair deep learning flows, like MinDiff.},
  archive      = {J_TMLR},
  author       = {Akshaj Kumar Veldanda and Ivan Brugere and Jiahao Chen and Sanghamitra Dutta and Alan Mishler and Siddharth Garg},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Fairness via in-processing in the over-parameterized regime: A cautionary tale with MinDiff loss},
  url          = {https://openreview.net/forum?id=f4VyYhkRvi},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient model-based multi-agent mean-field reinforcement
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=gvcDSDYUZx">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning in multi-agent systems is highly challenging due to several factors including the non-stationarity introduced by agents&#39; interactions and the combinatorial nature of their state and action spaces. In particular, we consider the Mean-Field Control (MFC) problem which assumes an asymptotically infinite population of identical agents that aim to collaboratively maximize the collective reward. In many cases, solutions of an MFC problem are good approximations for large systems, hence, efficient learning for MFC is valuable for the analogous discrete agent setting with many agents. Specifically, we focus on the case of unknown system dynamics where the goal is to simultaneously optimize for the rewards and learn from experience. We propose an efficient model-based reinforcement learning algorithm, $\text{M}^3$--UCRL, that runs in episodes, balances between exploration and exploitation during policy learning, and provably solves this problem. Our main theoretical contributions are the first general regret bounds for model-based reinforcement learning for MFC, obtained via a novel mean-field type analysis. To learn the system’s dynamics, $\text{M}^3$--UCRL can be instantiated with various statistical models, e.g., neural networks or Gaussian Processes. Moreover, we provide a practical parametrization of the core optimization problem that facilitates gradient-based optimization techniques when combined with differentiable dynamics approximation methods such as neural networks.},
  archive      = {J_TMLR},
  author       = {Barna Pásztor and Andreas Krause and Ilija Bogunovic},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Efficient model-based multi-agent mean-field reinforcement learning},
  url          = {https://openreview.net/forum?id=gvcDSDYUZx},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TimeSeAD: Benchmarking deep multivariate time-series anomaly
detection. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=iMmsCI0JsS">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing new methods for detecting anomalies in time series is of great practical significance, but progress is hindered by the difficulty of assessing the benefit of new methods, for the following reasons. (1) Public benchmarks are flawed (e.g., due to potentially erroneous anomaly labels), (2) there is no widely accepted standard evaluation metric, and (3) evaluation protocols are mostly inconsistent. In this work, we address all three issues: (1) We critically analyze several of the most widely-used multivariate datasets, identify a number of significant issues, and select the best candidates for evaluation. (2) We introduce a new evaluation metric for time-series anomaly detection, which—in contrast to previous metrics—is recall consistent and takes temporal correlations into account. (3) We analyze and overhaul existing evaluation protocols and provide the largest benchmark of deep multivariate time-series anomaly detection methods to date. We focus on deep-learning based methods and multivariate data, a common setting in modern anomaly detection. We provide all implementations and analysis tools in a new comprehensive library for Time Series Anomaly Detection, called TimeSeAD.},
  archive      = {J_TMLR},
  author       = {Dennis Wagner and Tobias Michels and Florian C.F. Schulz and Arjun Nair and Maja Rudolph and Marius Kloft},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {TimeSeAD: Benchmarking deep multivariate time-series anomaly detection},
  url          = {https://openreview.net/forum?id=iMmsCI0JsS},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Personalized federated learning: A unified framework and
universal optimization techniques. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ilHM31lXC4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the optimization aspects of personalized Federated Learning (FL). We propose general optimizers that can be applied to numerous existing personalized FL objectives, specifically a tailored variant of Local SGD and variants of accelerated coordinate descent/accelerated SVRCD. By examining a general personalized objective capable of recovering many existing personalized FL objectives as special cases, we develop a comprehensive optimization theory applicable to a wide range of strongly convex personalized FL models in the literature. We showcase the practicality and/or optimality of our methods in terms of communication and local computation. Remarkably, our general optimization solvers and theory can recover the best-known communication and computation guarantees for addressing specific personalized FL objectives. Consequently, our proposed methods can serve as universal optimizers, rendering the design of task-specific optimizers unnecessary in many instances.},
  archive      = {J_TMLR},
  author       = {Filip Hanzely and Boxin Zhao and mladen kolar},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Personalized federated learning: A unified framework and universal optimization techniques},
  url          = {https://openreview.net/forum?id=ilHM31lXC4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). U-NO: U-shaped neural operators. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=j3oQF9coJd">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural operators generalize classical neural networks to maps between infinite-dimensional spaces, e.g., function spaces. Prior works on neural operators proposed a series of novel methods to learn such maps and demonstrated unprecedented success in learning solution operators of partial differential equations. Due to their close proximity to fully connected architectures, these models mainly suffer from high memory usage and are generally limited to shallow deep learning models. In this paper, we propose U-shaped Neural Operator (U-NO), a U-shaped memory enhanced architecture that allows for deeper neural operators. U-NOs exploit the problem structures in function predictions and demonstrate fast training, data efficiency, and robustness with respect to hyperparameters choices. We study the performance of U-NO on PDE benchmarks, namely, Darcy’s flow law and the Navier-Stokes equations. We show that U-NO results in an average of 26% and 44% prediction improvement on Darcy’s flow and turbulent Navier-Stokes equations, respectively, over the state of the art. On Navier-Stokes 3D spatiotemporal operator learning task, we show U-NO provides 37% improvement over the state of art methods.},
  archive      = {J_TMLR},
  author       = {Md Ashiqur Rahman and Zachary E Ross and Kamyar Azizzadenesheli},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {U-NO: U-shaped neural operators},
  url          = {https://openreview.net/forum?id=j3oQF9coJd},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A cubic regularization approach for finding local minimax
points in nonconvex minimax optimization. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=jVMMdg31De">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gradient descent-ascent (GDA) is a widely used algorithm for minimax optimization. However, GDA has been proved to converge to stationary points for nonconvex minimax optimization, which are suboptimal compared with local minimax points. In this work, we develop cubic regularization (CR) type algorithms that globally converge to local minimax points in nonconvex-strongly-concave minimax optimization. We first show that local minimax points are equivalent to second-order stationary points of a certain envelope function. Then, inspired by the classic cubic regularization algorithm, we propose an algorithm named Cubic-LocalMinimax for finding local minimax points, and provide a comprehensive convergence analysis by leveraging its intrinsic potential function. Specifically, we establish the global convergence of Cubic-LocalMinimax to a local minimax point at a sublinear convergence rate and characterize its iteration complexity. Also, we propose a GDA-based solver for solving the cubic subproblem involved in Cubic-LocalMinimax up to certain pre-defined accuracy, and analyze the overall gradient and Hessian-vector product computation complexities of such an inexact Cubic-LocalMinimax algorithm. Moreover, we propose a stochastic variant of Cubic-LocalMinimax for large-scale minimax optimization, and characterize its sample complexity under stochastic sub-sampling. Experimental results demonstrate faster or comparable convergence speed of our stochastic Cubic-LocalMinimax than the state-of-the-art algorithms such as GDA and Minimax Cubic-Newton. In particular, our stochastic Cubic-LocalMinimax was also faster as compared to several other algorithms for minimax optimization on a particular adversarial loss for training a convolutional neural network on MNIST.},
  archive      = {J_TMLR},
  author       = {Ziyi Chen and Zhengyang Hu and Qunwei Li and Zhe Wang and Yi Zhou},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A cubic regularization approach for finding local minimax points in nonconvex minimax optimization},
  url          = {https://openreview.net/forum?id=jVMMdg31De},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A stochastic proximal polyak step size. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=jWr41htaB3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the stochastic Polyak step size (SPS) has emerged as a competitive adaptive step size scheme for stochastic gradient descent. Here we develop ProxSPS, a proximal variant of SPS that can handle regularization terms. Developing a proximal variant of SPS is particularly important, since SPS requires a lower bound of the objective function to work well. When the objective function is the sum of a loss and a regularizer, available estimates of a lower bound of the sum can be loose. In contrast, ProxSPS only requires a lower bound for the loss which is often readily available. As a consequence, we show that ProxSPS is easier to tune and more stable in the presence of regularization. Furthermore for image classification tasks, ProxSPS performs as well as AdamW with little to no tuning, and results in a network with smaller weight parameters. We also provide an extensive convergence analysis for ProxSPS that includes the non-smooth, smooth, weakly convex and strongly convex setting.},
  archive      = {J_TMLR},
  author       = {Fabian Schaipp and Robert M. Gower and Michael Ulbrich},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A stochastic proximal polyak step size},
  url          = {https://openreview.net/forum?id=jWr41htaB3},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual PatchNorm. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=jgMqve6Qhw">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose Dual PatchNorm: two Layer Normalization layers (LayerNorms), before and after the patch embedding layer in Vision Transformers. We demonstrate that Dual PatchNorm outperforms the result of exhaustive search for alternative LayerNorm placement strategies in the Transformer block itself. In our experiments on image classification and contrastive learning, incorporating this trivial modification, often leads to improved accuracy over well-tuned vanilla Vision Transformers and never hurts.},
  archive      = {J_TMLR},
  author       = {Manoj Kumar and Mostafa Dehghani and Neil Houlsby},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Dual PatchNorm},
  url          = {https://openreview.net/forum?id=jgMqve6Qhw},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generating teammates for training robust ad hoc teamwork
agents via best-response diversity. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=l5BzfQhROl">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ad hoc teamwork (AHT) is the challenge of designing a robust learner agent that effectively collaborates with unknown teammates without prior coordination mechanisms. Early approaches address the AHT challenge by training the learner with a diverse set of handcrafted teammate policies, usually designed based on an expert&#39;s domain knowledge about the policies the learner may encounter. However, implementing teammate policies for training based on domain knowledge is not always feasible. In such cases, recent approaches attempted to improve the robustness of the learner by training it with teammate policies generated by optimising information-theoretic diversity metrics. The problem with optimising existing information-theoretic diversity metrics for teammate policy generation is the emergence of superficially different teammates. When used for AHT training, superficially different teammate behaviours may not improve a learner&#39;s robustness during collaboration with unknown teammates. In this paper, we present an automated teammate policy generation method optimising the Best-Response Diversity (BRDiv) metric, which measures diversity based on the compatibility of teammate policies in terms of returns. We evaluate our approach in environments with multiple valid coordination strategies, comparing against methods optimising information-theoretic diversity metrics and an ablation not optimising any diversity metric. Our experiments indicate that optimising BRDiv yields a diverse set of training teammate policies that improve the learner&#39;s performance relative to previous teammate generation approaches when collaborating with near-optimal previously unseen teammate policies.},
  archive      = {J_TMLR},
  author       = {Arrasy Rahman and Elliot Fosong and Ignacio Carlucho and Stefano V Albrecht},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Generating teammates for training robust ad hoc teamwork agents via best-response diversity},
  url          = {https://openreview.net/forum?id=l5BzfQhROl},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spectral regularization allows data-frugal learning over
combinatorial spaces. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=mySiFHCeAl">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven machine learning models are being increasingly employed in several important inference problems in biology, chemistry, and physics, which require learning over combinatorial spaces. Recent empirical evidence (see, e.g., ~\cite{tseng2020fourier,aghazadeh2021epistatic,ha2021adaptive}) suggests that regularizing the spectral representation of such models improves their generalization power when labeled data is scarce. However, despite these empirical studies, the theoretical underpinning of when and how spectral regularization enables improved generalization is poorly understood. In this paper, we focus on learning pseudo-Boolean functions and demonstrate that regularizing the empirical mean squared error by the $L_1$ norm of the spectral transform of the learned function reshapes the loss landscape and allows for data-frugal learning under a restricted secant condition on the learner&#39;s empirical error measured against the ground truth function. Under a weaker quadratic growth condition, we show that stationary points, which also approximately interpolate the training data points achieve statistically optimal generalization performance. Complementing our theory, we empirically demonstrate that running gradient descent on the regularized loss results in a better generalization performance compared to baseline algorithms in several data-scarce real-world problems.},
  archive      = {J_TMLR},
  author       = {Amirali Aghazadeh and Nived Rajaraman and Tony Tu and Kannan Ramchandran},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Spectral regularization allows data-frugal learning over combinatorial spaces},
  url          = {https://openreview.net/forum?id=mySiFHCeAl},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analyzing deep PAC-bayesian learning with neural tangent
kernel: Convergence, analytic generalization bound, and efficient
hyperparameter selection. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=nEX2q5B2RQ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PAC-Bayes is a well-established framework for analyzing generalization performance in machine learning models. This framework provides a bound on the expected population error by considering the sum of training error and the divergence between posterior and prior distributions. In addition to being a successful generalization bound analysis tool, the PAC-Bayesian bound can also be incorporated into an objective function for training probabilistic neural networks, which we refer to simply as {\it Deep PAC-Bayesian Learning}. Deep PAC-Bayesian learning has been shown to achieve competitive expected test set error and provide a tight generalization bound in practice at the same time through gradient descent training. Despite its empirical success, theoretical analysis of deep PAC-Bayesian learning for neural networks is rarely explored. To this end, this paper proposes a theoretical convergence and generalization analysis for Deep PAC-Bayesian learning. For a deep and wide probabilistic neural network, our analysis shows that PAC-Bayesian learning corresponds to solving a kernel ridge regression when the probabilistic neural tangent kernel (PNTK) is used as the kernel. We utilize this outcome in conjunction with the PAC-Bayes $\mathcal{C}$-bound, enabling us to derive an analytical and guaranteed PAC-Bayesian generalization bound for the first time. Finally, drawing insight from our theoretical results, we propose a proxy measure for efficient hyperparameter selection, which is proven to be time-saving on various benchmarks. Our work not only provides a better understanding of the theoretical underpinnings of Deep PAC-Bayesian learning, but also offers practical tools for improving the training and generalization performance of these models.},
  archive      = {J_TMLR},
  author       = {Wei Huang and Chunrui Liu and Yilan Chen and Richard Yi Da Xu and Miao Zhang and Tsui-Wei Weng},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Analyzing deep PAC-bayesian learning with neural tangent kernel: Convergence, analytic generalization bound, and efficient hyperparameter selection},
  url          = {https://openreview.net/forum?id=nEX2q5B2RQ},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast&amp;fair: Training acceleration and bias mitigation for
GNNs. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=nOk4XEB7Ke">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have been demonstrated to achieve state-of-the-art performance for a number of graph-based learning tasks, which leads to a rise in their employment in various domains. However, it has been shown that GNNs may inherit and even amplify bias within training data, which leads to unfair results towards certain sensitive groups. Meanwhile, training of GNNs introduces additional challenges, such as slow convergence and possible instability. Faced with these limitations, this work proposes FairNorm, a unified normalization-based framework that reduces the bias in GNN-based learning while also providing provably faster convergence. Specifically, FairNorm presents individual normalization operators over different sensitive groups and introduces fairness regularizers on the learnable parameters of normalization layers to reduce the bias in GNNs. The design of the proposed regularizers is built upon analyses that illuminate the sources of bias in graph-based learning. Experiments on node classification over real-world networks demonstrate the efficiency of the proposed scheme in improving fairness in terms of statistical parity and equal opportunity compared to fairness-aware baselines. In addition, it is empirically shown that the proposed framework leads to faster convergence compared to the naive baseline where no normalization is employed.},
  archive      = {J_TMLR},
  author       = {Oyku Deniz Kose and Yanning Shen},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Fast&amp;Fair: Training acceleration and bias mitigation for GNNs},
  url          = {https://openreview.net/forum?id=nOk4XEB7Ke},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attacking perceptual similarity metrics. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=r9vGSpbbRO">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Perceptual similarity metrics have progressively become more correlated with human judgments on perceptual similarity; however, despite recent advances, the addition of an imperceptible distortion can still compromise these metrics. In our study, we systematically examine the robustness of these metrics to imperceptible adversarial perturbations. Following the two-alternative forced-choice experimental design with two distorted images and one reference image, we perturb the distorted image closer to the reference via an adversarial attack until the metric flips its judgment. We first show that all metrics in our study are susceptible to perturbations generated via common adversarial attacks such as FGSM, PGD, and the One-pixel attack. Next, we attack the widely adopted LPIPS metric using spatial-transformation-based adversarial perturbations (stAdv) in a white-box setting to craft adversarial examples that can effectively transfer to other similarity metrics in a black-box setting. We also combine the spatial attack stAdv with PGD ($\ell_\infty$-bounded) attack to increase transferability and use these adversarial examples to benchmark the robustness of both traditional and recently developed metrics. Our benchmark provides a good starting point for discussion and further research on the robustness of metrics to imperceptible adversarial perturbations.},
  archive      = {J_TMLR},
  author       = {Abhijay Ghildyal and Feng Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Attacking perceptual similarity metrics},
  url          = {https://openreview.net/forum?id=r9vGSpbbRO},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computationally-efficient initialisation of GPs: The
generalised variogram method. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=slsAQHpS7n">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a computationally-efficient strategy to initialise the hyperparameters of a Gaussian process (GP) avoiding the computation of the likelihood function. Our strategy can be used as a pretraining stage to find initial conditions for maximum-likelihood (ML) training, or as a standalone method to compute hyperparameters values to be plugged in directly into the GP model. Motivated by the fact that training a GP via ML is equivalent (on average) to minimising the KL-divergence between the true and learnt model, we set to explore different metrics/divergences among GPs that are computationally inexpensive and provide hyperparameter values that are close to those found via ML. In practice, we identify the GP hyperparameters by projecting the empirical covariance or (Fourier) power spectrum onto a parametric family, thus proposing and studying various measures of discrepancy operating on the temporal and frequency domains. Our contribution extends the variogram method developed by the geostatistics literature and, accordingly, it is referred to as the generalised variogram method (GVM). In addition to the theoretical presentation of GVM, we provide experimental validation in terms of accuracy, consistency with ML and computational complexity for different kernels using synthetic and real-world data.},
  archive      = {J_TMLR},
  author       = {Felipe Tobar and Elsa Cazelles and Taco de Wolff},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Computationally-efficient initialisation of GPs: The generalised variogram method},
  url          = {https://openreview.net/forum?id=slsAQHpS7n},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). High-modality multimodal transformer: Quantifying modality
&amp; interaction heterogeneity for high-modality representation
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ttzypy3kT7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world problems are inherently multimodal, from the communicative modalities humans use to express social and emotional states such as spoken language, gestures, and paralinguistics to the force, proprioception, and visual sensors ubiquitous on robots. While there has been an explosion of interest in multimodal representation learning, these methods are still largely focused on a small set of modalities, primarily in the language, vision, and audio space. In order to accelerate generalization towards diverse and understudied modalities, this paper studies efficient representation learning for high-modality scenarios involving a large set of diverse modalities. Since adding new models for every new modality or task becomes prohibitively expensive, a critical technical challenge is heterogeneity quantification: how can we measure which modalities encode similar information and interactions in order to permit parameter sharing with previous modalities? This paper proposes two new information theoretic metrics for heterogeneity quantification: (1) modality heterogeneity studies how similar $2$ modalities $\{X_1,X_2\}$ are by measuring how much information can be transferred from $X_1$ to $X_2$, while (2) interaction heterogeneity studies how similarly pairs of modalities $\{X_1,X_2\}, \{X_3,X_4\}$ interact by measuring how much interaction information can be transferred from $\{X_1,X_2\}$ to $\{X_3,X_4\}$. We show the importance of these $2$ proposed metrics in high-modality scenarios as a way to automatically prioritize the fusion of modalities that contain unique information or unique interactions. The result is a single model, HighMMT, that scales up to $10$ modalities (text, image, audio, video, sensors, proprioception, speech, time-series, sets, and tables) and $15$ tasks from $5$ different research areas. Not only does HighMMT outperform prior methods on the tradeoff between performance and efficiency, it also demonstrates a crucial scaling behavior: performance continues to improve with each modality added, and it transfers to entirely new modalities and tasks during fine-tuning. We release our code and benchmarks, which we hope will present a unified platform for subsequent theoretical and empirical analysis.},
  archive      = {J_TMLR},
  author       = {Paul Pu Liang and Yiwei Lyu and Xiang Fan and Jeffrey Tsaw and Yudong Liu and Shentong Mo and Dani Yogatama and Louis-Philippe Morency and Russ Salakhutdinov},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {High-modality multimodal transformer: Quantifying modality &amp; interaction heterogeneity for high-modality representation learning},
  url          = {https://openreview.net/forum?id=ttzypy3kT7},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Beyond the imitation game: Quantifying and extrapolating the
capabilities of language models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=uyTL5Bvosj">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language models demonstrate both quantitative improvement and new qualitative capabilities with increasing scale. Despite their potentially transformative impact, these new capabilities are as yet poorly characterized. In order to inform future research, prepare for disruptive new model capabilities, and ameliorate socially harmful effects, it is vital that we understand the present and near-future capabilities and limitations of language models. To address this challenge, we introduce the Beyond the Imitation Game benchmark (BIG- bench). BIG-bench currently consists of 204 tasks, contributed by 450 authors across 132 institutions. Task topics are diverse, drawing problems from linguistics, childhood develop- ment, math, common-sense reasoning, biology, physics, social bias, software development, and beyond. BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models. We evaluate the behavior of OpenAI&#39;s GPT models, Google- internal dense transformer architectures, and Switch-style sparse transformers on BIG-bench, across model sizes spanning millions to hundreds of billions of parameters. In addition, a team of human expert raters performed all tasks in order to provide a strong baseline. Findings include: model performance and calibration both improve with scale, but are poor in absolute terms (and when compared with rater performance); performance is remarkably similar across model classes, though with benefits from sparsity; tasks that improve gradually and predictably commonly involve a large knowledge or memorization component, whereas tasks that exhibit &quot;breakthrough&quot; behavior at a critical scale often involve multiple steps or components, or brittle metrics; social bias typically increases with scale in settings with ambiguous context, but this can be improved with prompting.},
  archive      = {J_TMLR},
  author       = {Aarohi Srivastava and Abhinav Rastogi and Abhishek Rao and Abu Awal Md Shoeb and Abubakar Abid and Adam Fisch and Adam R. Brown and Adam Santoro and Aditya Gupta and Adrià Garriga-Alonso and Agnieszka Kluska and Aitor Lewkowycz and Akshat Agarwal and Alethea Power and Alex Ray and Alex Warstadt and Alexander W. Kocurek and Ali Safaya and Ali Tazarv and Alice Xiang and Alicia Parrish and Allen Nie and Aman Hussain and Amanda Askell and Amanda Dsouza and Ambrose Slone and Ameet Rahane and Anantharaman S. Iyer and Anders Johan Andreassen and Andrea Madotto and Andrea Santilli and Andreas Stuhlmüller and Andrew M. Dai and Andrew La and Andrew Lampinen and Andy Zou and Angela Jiang and Angelica Chen and Anh Vuong and Animesh Gupta and Anna Gottardi and Antonio Norelli and Anu Venkatesh and Arash Gholamidavoodi and Arfa Tabassum and Arul Menezes and Arun Kirubarajan and Asher Mullokandov and Ashish Sabharwal and Austin Herrick and Avia Efrat and Aykut Erdem and Ayla Karakaş and B. Ryan Roberts and Bao Sheng Loe and Barret Zoph and Bartłomiej Bojanowski and Batuhan Özyurt and Behnam Hedayatnia and Behnam Neyshabur and Benjamin Inden and Benno Stein and Berk Ekmekci and Bill Yuchen Lin and Blake Howald and Bryan Orinion and Cameron Diao and Cameron Dour and Catherine Stinson and Cedrick Argueta and Cesar Ferri and Chandan Singh and Charles Rathkopf and Chenlin Meng and Chitta Baral and Chiyu Wu and Chris Callison-Burch and Christopher Waites and Christian Voigt and Christopher D Manning and Christopher Potts and Cindy Ramirez and Clara E. Rivera and Clemencia Siro and Colin Raffel and Courtney Ashcraft and Cristina Garbacea and Damien Sileo and Dan Garrette and Dan Hendrycks and Dan Kilman and Dan Roth and C. Daniel Freeman and Daniel Khashabi and Daniel Levy and Daniel Moseguí González and Danielle Perszyk and Danny Hernandez and Danqi Chen and Daphne Ippolito and Dar Gilboa and David Dohan and David Drakard and David Jurgens and Debajyoti Datta and Deep Ganguli and Denis Emelin and Denis Kleyko and Deniz Yuret and Derek Chen and Derek Tam and Dieuwke Hupkes and Diganta Misra and Dilyar Buzan and Dimitri Coelho Mollo and Diyi Yang and Dong-Ho Lee and Dylan Schrader and Ekaterina Shutova and Ekin Dogus Cubuk and Elad Segal and Eleanor Hagerman and Elizabeth Barnes and Elizabeth Donoway and Ellie Pavlick and Emanuele Rodolà and Emma Lam and Eric Chu and Eric Tang and Erkut Erdem and Ernie Chang and Ethan A Chi and Ethan Dyer and Ethan Jerzak and Ethan Kim and Eunice Engefu Manyasi and Evgenii Zheltonozhskii and Fanyue Xia and Fatemeh Siar and Fernando Martínez-Plumed and Francesca Happé and Francois Chollet and Frieda Rong and Gaurav Mishra and Genta Indra Winata and Gerard de Melo and Germán Kruszewski and Giambattista Parascandolo and Giorgio Mariani and Gloria Xinyue Wang and Gonzalo Jaimovitch-Lopez and Gregor Betz and Guy Gur-Ari and Hana Galijasevic and Hannah Kim and Hannah Rashkin and Hannaneh Hajishirzi and Harsh Mehta and Hayden Bogar and Henry Francis Anthony Shevlin and Hinrich Schuetze and Hiromu Yakura and Hongming Zhang and Hugh Mee Wong and Ian Ng and Isaac Noble and Jaap Jumelet and Jack Geissinger and Jackson Kernion and Jacob Hilton and Jaehoon Lee and Jaime Fernández Fisac and James B Simon and James Koppel and James Zheng and James Zou and Jan Kocon and Jana Thompson and Janelle Wingfield and Jared Kaplan and Jarema Radom and Jascha Sohl-Dickstein and Jason Phang and Jason Wei and Jason Yosinski and Jekaterina Novikova and Jelle Bosscher and Jennifer Marsh and Jeremy Kim and Jeroen Taal and Jesse Engel and Jesujoba Alabi and Jiacheng Xu and Jiaming Song and Jillian Tang and Joan Waweru and John Burden and John Miller and John U. Balis and Jonathan Batchelder and Jonathan Berant and Jörg Frohberg and Jos Rozen and Jose Hernandez-Orallo and Joseph Boudeman and Joseph Guerr and Joseph Jones and Joshua B. Tenenbaum and Joshua S. Rule and Joyce Chua and Kamil Kanclerz and Karen Livescu and Karl Krauth and Karthik Gopalakrishnan and Katerina Ignatyeva and Katja Markert and Kaustubh Dhole and Kevin Gimpel and Kevin Omondi and Kory Wallace Mathewson and Kristen Chiafullo and Ksenia Shkaruta and Kumar Shridhar and Kyle McDonell and Kyle Richardson and Laria Reynolds and Leo Gao and Li Zhang and Liam Dugan and Lianhui Qin and Lidia Contreras-Ochando and Louis-Philippe Morency and Luca Moschella and Lucas Lam and Lucy Noble and Ludwig Schmidt and Luheng He and Luis Oliveros-Colón and Luke Metz and Lütfi Kerem Senel and Maarten Bosma and Maarten Sap and Maartje Ter Hoeve and Maheen Farooqi and Manaal Faruqui and Mantas Mazeika and Marco Baturan and Marco Marelli and Marco Maru and Maria Jose Ramirez-Quintana and Marie Tolkiehn and Mario Giulianelli and Martha Lewis and Martin Potthast and Matthew L Leavitt and Matthias Hagen and Mátyás Schubert and Medina Orduna Baitemirova and Melody Arnaud and Melvin McElrath and Michael Andrew Yee and Michael Cohen and Michael Gu and Michael Ivanitskiy and Michael Starritt and Michael Strube and Michał Swędrowski and Michele Bevilacqua and Michihiro Yasunaga and Mihir Kale and Mike Cain and Mimee Xu and Mirac Suzgun and Mitch Walker and Mo Tiwari and Mohit Bansal and Moin Aminnaseri and Mor Geva and Mozhdeh Gheini and Mukund Varma T and Nanyun Peng and Nathan Andrew Chi and Nayeon Lee and Neta Gur-Ari Krakover and Nicholas Cameron and Nicholas Roberts and Nick Doiron and Nicole Martinez and Nikita Nangia and Niklas Deckers and Niklas Muennighoff and Nitish Shirish Keskar and Niveditha S. Iyer and Noah Constant and Noah Fiedel and Nuan Wen and Oliver Zhang and Omar Agha and Omar Elbaghdadi and Omer Levy and Owain Evans and Pablo Antonio Moreno Casares and Parth Doshi and Pascale Fung and Paul Pu Liang and Paul Vicol and Pegah Alipoormolabashi and Peiyuan Liao and Percy Liang and Peter W Chang and Peter Eckersley and Phu Mon Htut and Pinyu Hwang and Piotr Miłkowski and Piyush Patil and Pouya Pezeshkpour and Priti Oli and Qiaozhu Mei and Qing Lyu and Qinlang Chen and Rabin Banjade and Rachel Etta Rudolph and Raefer Gabriel and Rahel Habacker and Ramon Risco and Raphaël Millière and Rhythm Garg and Richard Barnes and Rif A. Saurous and Riku Arakawa and Robbe Raymaekers and Robert Frank and Rohan Sikand and Roman Novak and Roman Sitelew and Ronan Le Bras and Rosanne Liu and Rowan Jacobs and Rui Zhang and Russ Salakhutdinov and Ryan Andrew Chi and Seungjae Ryan Lee and Ryan Stovall and Ryan Teehan and Rylan Yang and Sahib Singh and Saif M. Mohammad and Sajant Anand and Sam Dillavou and Sam Shleifer and Sam Wiseman and Samuel Gruetter and Samuel R. Bowman and Samuel Stern Schoenholz and Sanghyun Han and Sanjeev Kwatra and Sarah A. Rous and Sarik Ghazarian and Sayan Ghosh and Sean Casey and Sebastian Bischoff and Sebastian Gehrmann and Sebastian Schuster and Sepideh Sadeghi and Shadi Hamdan and Sharon Zhou and Shashank Srivastava and Sherry Shi and Shikhar Singh and Shima Asaadi and Shixiang Shane Gu and Shubh Pachchigar and Shubham Toshniwal and Shyam Upadhyay and Shyamolima Shammie Debnath and Siamak Shakeri and Simon Thormeyer and Simone Melzi and Siva Reddy and Sneha Priscilla Makini and Soo-Hwan Lee and Spencer Torene and Sriharsha Hatwar and Stanislas Dehaene and Stefan Divic and Stefano Ermon and Stella Biderman and Stephanie Lin and Stephen Prasad and Steven Piantadosi and Stuart Shieber and Summer Misherghi and Svetlana Kiritchenko and Swaroop Mishra and Tal Linzen and Tal Schuster and Tao Li and Tao Yu and Tariq Ali and Tatsunori Hashimoto and Te-Lin Wu and Théo Desbordes and Theodore Rothschild and Thomas Phan and Tianle Wang and Tiberius Nkinyili and Timo Schick and Timofei Kornev and Titus Tunduny and Tobias Gerstenberg and Trenton Chang and Trishala Neeraj and Tushar Khot and Tyler Shultz and Uri Shaham and Vedant Misra and Vera Demberg and Victoria Nyamai and Vikas Raunak and Vinay Venkatesh Ramasesh and vinay uday prabhu and Vishakh Padmakumar and Vivek Srikumar and William Fedus and William Saunders and William Zhang and Wout Vossen and Xiang Ren and Xiaoyu Tong and Xinran Zhao and Xinyi Wu and Xudong Shen and Yadollah Yaghoobzadeh and Yair Lakretz and Yangqiu Song and Yasaman Bahri and Yejin Choi and Yichi Yang and Yiding Hao and Yifu Chen and Yonatan Belinkov and Yu Hou and Yufang Hou and Yuntao Bai and Zachary Seid and Zhuoye Zhao and Zijian Wang and Zijie J. Wang and Zirui Wang and Ziyi Wu},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Beyond the imitation game: Quantifying and extrapolating the capabilities of language models},
  url          = {https://openreview.net/forum?id=uyTL5Bvosj},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). When to trust aggregated gradients: Addressing negative
client sampling in federated learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=v73h3bYE2Z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning has become a widely-used framework which allows learning a global model on decentralized local datasets under the condition of protecting local data privacy. However, federated learning faces severe optimization difficulty when training samples are not independently and identically distributed (non-i.i.d.). In this paper, we point out that the client sampling practice plays a decisive role in the aforementioned optimization difficulty. We find that the negative client sampling will cause the merged data distribution of currently sampled clients heavily inconsistent with that of all available clients, and further make the aggregated gradient unreliable. To address this issue, we propose a novel learning rate adaptation mechanism to adaptively adjust the server learning rate for the aggregated gradient in each round, according to the consistency between the merged data distribution of currently sampled clients and that of all available clients. Specifically, we make theoretical deductions to find a meaningful and robust indicator that is positively related to the optimal server learning rate, which is supposed to minimize the Euclidean distance between the aggregated gradient given currently sampled clients and that if all clients could participate in the current round. We show that our proposed indicator can effectively reflect the merged data distribution of sampled clients, thus we utilize it for the server learning rate adaptation. Extensive experiments on multiple image and text classification tasks validate the great effectiveness of our method in various settings. Our code is available at https://github.com/lancopku/FedGLAD.},
  archive      = {J_TMLR},
  author       = {Wenkai Yang and Yankai Lin and Guangxiang Zhao and Peng Li and Jie Zhou and Xu Sun},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {When to trust aggregated gradients: Addressing negative client sampling in federated learning},
  url          = {https://openreview.net/forum?id=v73h3bYE2Z},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to correct spectral methods for simulating
turbulent flows. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=wNBARGxoJn">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite their ubiquity throughout science and engineering, only a handful of partial differential equations (PDEs) have analytical, or closed-form solutions. This motivates a vast amount of classical work on numerical simulation of PDEs and more recently, a whirlwind of research into data-driven techniques leveraging machine learning (ML). A recent line of work indicates that a hybrid of classical numerical techniques and machine learning can offer significant improvements over either approach alone. In this work, we show that the choice of the numerical scheme is crucial when incorporating physics-based priors. We build upon Fourier-based spectral methods, which are known to be more efficient than other numerical schemes for simulating PDEs with smooth and periodic solutions. Specifically, we develop ML-augmented spectral solvers for three common PDEs of fluid dynamics. Our models are more accurate (2-4x) than standard spectral solvers at the same resolution but have longer overall runtimes (~2x), due to the additional runtime cost of the neural network component. We also demonstrate a handful of key design principles for combining machine learning and numerical methods for solving PDEs.},
  archive      = {J_TMLR},
  author       = {Gideon Dresdner and Dmitrii Kochkov and Peter Christian Norgaard and Leonardo Zepeda-Nunez and Jamie Smith and Michael Brenner and Stephan Hoyer},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning to correct spectral methods for simulating turbulent flows},
  url          = {https://openreview.net/forum?id=wNBARGxoJn},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cox-hawkes: Doubly stochastic spatiotemporal poisson
processes. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=xzCDD9i4IZ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hawkes processes are point process models that have been used to capture self-excitatory behaviour in social interactions, neural activity, earthquakes and viral epidemics. They can model the occurrence of the times and locations of events. Here we develop a new class of spatiotemporal Hawkes processes that can capture both triggering and clustering behaviour and we provide an efficient method for performing inference. We use a log-Gaussian Cox process (LGCP) as prior for the background rate of the Hawkes process which gives arbitrary flexibility to capture a wide range of underlying background effects (for infectious diseases these are called endemic effects). The Hawkes process and LGCP are computationally expensive due to the former having a likelihood with quadratic complexity in the number of observations and the latter involving inversion of the precision matrix which is cubic in observations. Here we propose a novel approach to perform MCMC sampling for our Hawkes process with LGCP background, using pre-trained Gaussian Process generators which provide direct and cheap access to samples during inference. We show the efficacy and flexibility of our approach in experiments on simulated data and use our methods to uncover the trends in a dataset of reported crimes in the US.},
  archive      = {J_TMLR},
  author       = {Xenia Miscouridou and Samir Bhatt and George Mohler and Seth Flaxman and Swapnil Mishra},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Cox-hawkes: Doubly stochastic spatiotemporal poisson processes},
  url          = {https://openreview.net/forum?id=xzCDD9i4IZ},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine explanations and human understanding. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=y4CGF1A8VG">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explanations are hypothesized to improve human understanding of machine learning models and achieve a variety of desirable outcomes, ranging from model debugging to enhancing human decision making. However, empirical studies have found mixed and even negative results. An open question, therefore, is under what conditions explanations can improve human understanding and in what way. To address this question, we first identify three core concepts that cover most existing quantitative measures of understanding: task decision boundary, model decision boundary, and model error. Using adapted causal diagrams, we provide a formal characterization of the relationship between these concepts and human approximations (i.e., understanding) of them. The relationship varies by the level of human intuition in different task types, such as emulation and discovery, which are often ignored when building or evaluating explanation methods. Our key result is that human intuitions are necessary for generating and evaluating machine explanations in human-AI decision making: without assumptions about human intuitions, explanations may improve human understanding of model decision boundary, but cannot improve human understanding of task decision boundary or model error. To validate our theoretical claims, we conduct human subject studies to show the importance of human intuitions. Together with our theoretical contributions, we provide a new paradigm for designing behavioral studies towards a rigorous view of the role of machine explanations across different tasks of human-AI decision making.},
  archive      = {J_TMLR},
  author       = {Chacha Chen and Shi Feng and Amit Sharma and Chenhao Tan},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Machine explanations and human understanding},
  url          = {https://openreview.net/forum?id=y4CGF1A8VG},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FASTRAIN-GNN: Fast and accurate self-training for graph
neural networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=1IYJfwJtjQ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning with Graph Neural Networks (GNNs) is an important challenge in expanding the remarkable success that GNNs have achieved. In the transductive node classification scenario, conventional supervised training methods for GNNs fail when only few labeled nodes are available. Self-training, wherein the GNN is trained in stages by augmenting the training data with a subset of the unlabeled data and the predictions of the GNN on this data (pseudolabels), has emerged as a promising approach to few-shot transductive learning. However, multi-stage self-training significantly increases the computational demands of GNN training. In addition, while the training set evolves considerably across the stages of self-training, the GNN architecture, graph topology and training hyperparameters are kept constant, adversely affecting the accuracy of the resulting model as well as the computational efficiency of training. To address this challenge, we propose FASTRAIN-GNN, a framework for efficient and accurate self-training of GNNs with few labeled nodes. FASTRAIN-GNN performs four main optimizations in each stage of self-training: (1) Sampling-based Pseudolabel Filtering removes nodes whose pseudolabels are likely to be incorrect from the enlarged training set. (2,3) Dynamic Sizing and Dynamic Regularization find the optimal network architecture and amount of training regularization in each stage of self-training, respectively, and (4) Progressive Graph Pruning removes selected edges between nodes in the training set to reduce the impact of over-smoothing. On few-shot node classification tasks using different GNN architectures, FASTRAIN-GNN produces models that are consistently more accurate (by up to 4.4%), while also substantially reducing the self-training time (by up to 2.1X) over the current state-of-the-art methods. Code is available at https://github.com/amrnag/FASTRAIN-GNN.},
  archive      = {J_TMLR},
  author       = {Amrit Nagarajan and Anand Raghunathan},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FASTRAIN-GNN: Fast and accurate self-training for graph neural networks},
  url          = {https://openreview.net/forum?id=1IYJfwJtjQ},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Jacobian-based causal discovery with nonlinear ICA.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=2Yo9xqR6Ab">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today&#39;s methods for uncovering causal relationships from observational data either constrain functional assignments (linearity/additive noise assumptions) or the data generating process (e.g., non-i.i.d. assumptions). Unlike previous works, which use conditional independence tests, we rely on the inference function&#39;s Jacobian to determine nonlinear cause-effect relationships. We prove that, under strong identifiability, the inference function&#39;s Jacobian captures the sparsity structure of the causal graph; thus, generalizing the classic LiNGAM method to the nonlinear case. We use nonlinear Independent Component Analysis (ICA) to infer the underlying sources from the observed variables and show how nonlinear ICA is compatible with causal discovery via non-i.i.d data. Our approach avoids the cost of exponentially many independence tests and makes our method end-to-end differentiable. We demonstrate that the proposed method can infer the causal graph on multiple synthetic data sets, and in most scenarios outperforms previous work.},
  archive      = {J_TMLR},
  author       = {Patrik Reizinger and Yash Sharma and Matthias Bethge and Bernhard Schölkopf and Ferenc Huszár and Wieland Brendel},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Jacobian-based causal discovery with nonlinear ICA},
  url          = {https://openreview.net/forum?id=2Yo9xqR6Ab},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NovelCraft: A dataset for novelty detection and discovery in
open worlds. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=4eL6z9ziw7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order for artificial agents to successfully perform tasks in changing environments, they must be able to both detect and adapt to novelty. However, visual novelty detection research often only evaluates on repurposed datasets such as CIFAR-10 originally intended for object classification, where images focus on one distinct, well-centered object. New benchmarks are needed to represent the challenges of navigating the complex scenes of an open world. Our new NovelCraft dataset contains multimodal episodic data of the images and symbolic world-states seen by an agent completing a pogo stick assembly task within a modified Minecraft environment. In some episodes, we insert novel objects of varying size within the complex 3D scene that may impact gameplay. Our visual novelty detection benchmark finds that methods that rank best on popular area-under-the-curve metrics may be outperformed by simpler alternatives when controlling false positives matters most. Further multimodal novelty detection experiments suggest that methods that fuse both visual and symbolic information can improve time until detection as well as overall discrimination. Finally, our evaluation of recent generalized category discovery methods suggests that adapting to new imbalanced categories in complex scenes remains an exciting open problem.},
  archive      = {J_TMLR},
  author       = {Patrick Feeney and Sarah Schneider and Panagiotis Lymperopoulos and Liping Liu and Matthias Scheutz and Michael C Hughes},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {NovelCraft: A dataset for novelty detection and discovery in open worlds},
  url          = {https://openreview.net/forum?id=4eL6z9ziw7},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bayesian transformed gaussian processes. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=4zCgjqjzAv">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Bayesian transformed Gaussian (BTG) model, proposed by Kedem and Oliviera in 1997, was developed as a Bayesian approach to trans-Kriging in the spatial statistics community. In this paper, we revisit BTG in the context of modern Gaussian process literature by framing it as a fully Bayesian counterpart to the Warped Gaussian process that marginalizes out a joint prior over input warping and kernel hyperparameters. As with any other fully Bayesian approach, this treatment introduces prohibitively expensive computational overhead; unsurprisingly, the BTG posterior predictive distribution, itself estimated through high-dimensional integration, must be inverted in order to perform model prediction. To address these challenges, we introduce principled numerical techniques for computing with BTG efficiently using a combination of doubly sparse quadrature rules, tight quantile bounds, and rank-one matrix algebra to enable both fast model prediction and model selection. These efficient methods allow us to compute with higher-dimensional datasets and apply BTG with layered transformations that greatly improve its expressibility. We demonstrate that BTG achieves superior empirical performance over MLE-based models in the low-data regime ---situations in which MLE tends to overfit.},
  archive      = {J_TMLR},
  author       = {Xinran Zhu and Leo Huang and Eric Hans Lee and Cameron Alexander Ibrahim and David Bindel},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bayesian transformed gaussian processes},
  url          = {https://openreview.net/forum?id=4zCgjqjzAv},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MASIF: Meta-learned algorithm selection using implicit
fidelity information. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=5aYGXxByI6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selecting a well-performing algorithm for a given task or dataset can be time-consuming and tedious, but is crucial for the successful day-to-day business of developing new AI &amp; ML applications. Algorithm Selection (AS) mitigates this through a meta-model leveraging meta-information about previous tasks. However, most of the available AS methods are error-prone because they characterize a task by either cheap-to-compute properties of the dataset or evaluations of cheap proxy algorithms, called landmarks. In this work, we extend the classical AS data setup to include multi-fidelity information and empirically demonstrate how meta-learning on algorithms’ learning behaviour allows us to exploit cheap test-time evidence effectively and combat myopia significantly. We further postulate a budget-regret trade-off w.r.t. the selection process. Our new selector MASIF is able to jointly interpret online evidence on a task in form of varying-length learning curves without any parametric assumption by leveraging a transformer-based encoder. This opens up new possibilities for guided rapid prototyping in data science on cheaply observed partial learning curves.},
  archive      = {J_TMLR},
  author       = {Tim Ruhkopf and Aditya Mohan and Difan Deng and Alexander Tornede and Frank Hutter and Marius Lindauer},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {MASIF: Meta-learned algorithm selection using implicit fidelity information},
  url          = {https://openreview.net/forum?id=5aYGXxByI6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online optimal tracking of linear systems with adversarial
disturbances. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=5nVJlKgmxp">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a memory-augmented control solution to the optimal reference tracking problem for linear systems subject to adversarial disturbances. We assume that the dynamics of the linear system are known and that the reference signal is generated by a linear system with unknown dynamics. Under these assumptions, finding the optimal tracking controller is formalized as an online convex optimization problem that leverages memory of past disturbance and reference values to capture their temporal effects on the performance. That is, a (disturbance, reference)-action control policy is formalized, which selects the control actions as a linear map of the past disturbance and reference values. The online convex optimization is then formulated over the parameters of the policy on its past disturbance and reference values to optimize general convex costs. It is shown that our approach outperforms robust control methods and achieves a tight regret bound O(√T) where in our regret analysis, we have benchmarked against the best linear policy.},
  archive      = {J_TMLR},
  author       = {Farnaz Adib Yaghmaie and Hamidreza Modares},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Online optimal tracking of linear systems with adversarial disturbances},
  url          = {https://openreview.net/forum?id=5nVJlKgmxp},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Can pruning improve certified robustness of neural networks?
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=6IFi2soduD">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of deep learning, the sizes of deep neural networks are getting larger beyond the affordability of hardware platforms. Given the fact that neural networks are often over-parameterized, one effective way to reduce such computational overhead is neural network pruning, by removing redundant parameters from trained neural networks. It has been recently observed that pruning can not only reduce computational overhead but also can improve empirical robustness of deep neural networks (NNs), potentially owing to removing spurious correlations while preserving the predictive accuracies. This paper for the first time demonstrates that pruning can generally improve $L_\infty$ certified robustness for ReLU-based NNs under the \textit{complete verification} setting. Using the popular Branch-and-Bound (BaB) framework, we find that pruning can enhance the estimated bound tightness of certified robustness verification, by alleviating linear relaxation and sub-domain split problems. We empirically verify our findings with off-the-shelf pruning methods and further present a new stability-based pruning method tailored for reducing neuron instability, that outperforms existing pruning methods in enhancing certified robustness. Our experiments show that by appropriately pruning an NN, its certified accuracy can be boosted up to \textbf{8.2\%} under standard training, and up to \textbf{24.5\%} under adversarial training on the CIFAR10 dataset. We additionally observe the possible existence of {\it certified lottery tickets} in our experiments that can match both standard and certified robust accuracies of the original dense models across different datasets. Our findings offer a new angle to study the intriguing interaction between sparsity and robustness, i.e. interpreting the interaction of sparsity and certified robustness via neuron stability. Codes will be fully released.},
  archive      = {J_TMLR},
  author       = {Zhangheng LI and Tianlong Chen and Linyi Li and Bo Li and Zhangyang Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Can pruning improve certified robustness of neural networks?},
  url          = {https://openreview.net/forum?id=6IFi2soduD},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Proximal curriculum for reinforcement learning agents.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=8WUyeeMxMH">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of curriculum design for reinforcement learning (RL) agents in contextual multi-task settings. Existing techniques on automatic curriculum design typically require domain-specific hyperparameter tuning or have limited theoretical underpinnings. To tackle these limitations, we design our curriculum strategy, ProCuRL, inspired by the pedagogical concept of Zone of Proximal Development (ZPD). ProCuRL captures the intuition that learning progress is maximized when picking tasks that are neither too hard nor too easy for the learner. We mathematically derive ProCuRL by analyzing two simple learning settings. We also present a practical variant of ProCuRL that can be directly integrated with deep RL frameworks with minimal hyperparameter tuning. Experimental results on a variety of domains demonstrate the effectiveness of our curriculum strategy over state-of-the-art baselines in accelerating the training process of deep RL agents.},
  archive      = {J_TMLR},
  author       = {Georgios Tzannetos and Bárbara Gomes Ribeiro and Parameswaran Kamalaruban and Adish Singla},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Proximal curriculum for reinforcement learning agents},
  url          = {https://openreview.net/forum?id=8WUyeeMxMH},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scalable deep compressive sensing. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=10JdgrzNOk">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been used to image compressive sensing (CS) for enhanced reconstruction performance. However, most existing deep learning methods train different models for different subsampling ratios, which brings an additional hardware burden. In this paper, we develop a general framework named scalable deep compressive sensing (SDCS) for the scalable sampling and reconstruction (SSR) of all existing end-to-end-trained models. In the proposed way, images are measured and initialized linearly. Two sampling matrix masks are introduced to flexibly control the subsampling ratios used in sampling and reconstruction, respectively. To achieve a reconstruction model with flexible subsampling ratios, a training strategy dubbed scalable training is developed. In scalable training, the model is trained with the sampling matrix and the initialization matrix at various subsampling ratios by integrating different sampling matrix masks. Experimental results show that models with SDCS can achieve SSR without changing their structure while maintaining good performance, and SDCS outperforms other SSR methods.},
  archive      = {J_TMLR},
  author       = {Zhonghao Zhang and Yipeng Liu and Xingyu Cao and Fei Wen and Ce Zhu},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Scalable deep compressive sensing},
  url          = {https://openreview.net/forum?id=10JdgrzNOk},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differentially private partitioned variational inference.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=55BcghgicI">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning a privacy-preserving model from sensitive data which are distributed across multiple devices is an increasingly important problem. The problem is often formulated in the federated learning context, with the aim of learning a single global model while keeping the data distributed. Moreover, Bayesian learning is a popular approach for modelling, since it naturally supports reliable uncertainty estimates. However, Bayesian learning is generally intractable even with centralised non-private data and so approximation techniques such as variational inference are a necessity. Variational inference has recently been extended to the non-private federated learning setting via the partitioned variational inference algorithm. For privacy protection, the current gold standard is called differential privacy. Differential privacy guarantees privacy in a strong, mathematically clearly defined sense. In this paper, we present differentially private partitioned variational inference, the first general framework for learning a variational approximation to a Bayesian posterior distribution in the federated learning setting while minimising the number of communication rounds and providing differential privacy guarantees for data subjects. We propose three alternative implementations in the general framework, one based on perturbing local optimisation runs done by individual parties, and two based on perturbing updates to the global model (one using a version of federated averaging, the second one adding virtual parties to the protocol), and compare their properties both theoretically and empirically. We show that perturbing the local optimisation works well with simple and complex models as long as each party has enough local data. However, the privacy is always guaranteed independently by each party. In contrast, perturbing the global updates works best with relatively simple models. Given access to suitable secure primitives, such as secure aggregation or secure shuffling, the performance can be improved by all parties guaranteeing privacy jointly.},
  archive      = {J_TMLR},
  author       = {Mikko A. Heikkilä and Matthew Ashman and Siddharth Swaroop and Richard E Turner and Antti Honkela},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Differentially private partitioned variational inference},
  url          = {https://openreview.net/forum?id=55BcghgicI},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sobolev spaces, kernels and discrepancies over hyperspheres.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=82hRiAbnnm">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work extends analytical foundations for kernel methods beyond the usual Euclidean manifold. Specifically, we characterise the smoothness of the native spaces (reproducing kernel Hilbert spaces) that are reproduced by geodesically isotropic kernels in the hyperspherical context. Our results are relevant to several areas of machine learning; we focus on their consequences for kernel cubature, determining the rate of convergence of the worst case error, and expanding the applicability of cubature algorithms based on Stein&#39;s method. First, we introduce a characterisation of Sobolev spaces on the $d$-dimensional sphere based on the Fourier--Schoenberg sequences associated with a given kernel. Such sequences are hard (if not impossible) to compute analytically on $d$-dimensional spheres, but often feasible over Hilbert spheres, where $d = \infty$. Second, we circumvent this problem by finding a projection operator that allows us to map from Hilbert spheres to finite-dimensional spheres. Our findings are illustrated for selected parametric families of kernel.},
  archive      = {J_TMLR},
  author       = {Simon Hubbert and Emilio Porcu and Chris J. Oates and Mark Girolami},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Sobolev spaces, kernels and discrepancies over hyperspheres},
  url          = {https://openreview.net/forum?id=82hRiAbnnm},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A variational perspective on generative flow networks.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=AZ4GobeSLq">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative flow networks (GFNs) are a class of probabilistic models for sequential sampling of composite objects, proportional to a target distribution that is defined in terms of an energy function or a reward. GFNs are typically trained using a flow matching or trajectory balance objective, which matches forward and backward transition models over trajectories. In this work we introduce a variational objective for training GFNs, which is a convex combination of the reverse- and forward KL divergences, and compare it to the trajectory balance objective when sampling from the forward- and backward model, respectively. We show that, in certain settings, variational inference for GFNs is equivalent to minimizing the trajectory balance objective, in the sense that both methods compute the same score-function gradient. This insight suggests that in these settings, control variates, which are commonly used to reduce the variance of score-function gradient estimates, can also be used with the trajectory balance objective. We evaluate our findings and the performance of the proposed variational objective numerically by comparing it to the trajectory balance objective on two synthetic tasks.},
  archive      = {J_TMLR},
  author       = {Heiko Zimmermann and Fredrik Lindsten and Jan-Willem van de Meent and Christian A Naesseth},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A variational perspective on generative flow networks},
  url          = {https://openreview.net/forum?id=AZ4GobeSLq},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Positive difference distribution for image outlier detection
using normalizing flows and contrastive data. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=B4J40x7NjA">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting test data deviating from training data is a central problem for safe and robust machine learning. Likelihoods learned by a generative model, e.g., a normalizing flow via standard log-likelihood training, perform poorly as an outlier score. We propose to use an unlabelled auxiliary dataset and a probabilistic outlier score for outlier detection. We use a self-supervised feature extractor trained on the auxiliary dataset and train a normalizing flow on the extracted features by maximizing the likelihood on in-distribution data and minimizing the likelihood on the contrastive dataset. We show that this is equivalent to learning the normalized positive difference between the in-distribution and the contrastive feature density. We conduct experiments on benchmark datasets and compare to the likelihood, the likelihood ratio and state-of-the-art anomaly detection methods.},
  archive      = {J_TMLR},
  author       = {Robert Schmier and Ullrich Koethe and Christoph-Nikolas Straehle},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Positive difference distribution for image outlier detection using normalizing flows and contrastive data},
  url          = {https://openreview.net/forum?id=B4J40x7NjA},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ChemSpacE: Interpretable and interactive chemical space
exploration. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=C1Xl8dYCBn">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discovering meaningful molecules in the vast combinatorial chemical space has been a long-standing challenge in many fields, from materials science to drug design. Recent progress in machine learning, especially with generative models, shows great promise for automated molecule synthesis. Nevertheless, most molecule generative models remain black-boxes, whose utilities are limited by a lack of interpretability and human participation in the generation process. In this work, we propose \textbf{Chem}ical \textbf{Spac}e \textbf{E}xplorer (ChemSpacE), a simple yet effective method for exploring the chemical space with pre-trained deep generative models. Our method enables users to interact with existing generative models and steer the molecule generation process. We demonstrate the efficacy of ChemSpacE on the molecule optimization task and the latent molecule manipulation task in single-property and multi-property settings. On the molecule optimization task, the performance of ChemSpacE is on par with previous black-box optimization methods yet is considerably faster and more sample efficient. Furthermore, the interface from ChemSpacE facilitates human-in-the-loop chemical space exploration and interactive molecule design. Code and demo are available at \url{https://github.com/yuanqidu/ChemSpacE}.},
  archive      = {J_TMLR},
  author       = {Yuanqi Du and Xian Liu and Nilay Mahesh Shah and Shengchao Liu and Jieyu Zhang and Bolei Zhou},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ChemSpacE: Interpretable and interactive chemical space exploration},
  url          = {https://openreview.net/forum?id=C1Xl8dYCBn},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differentially private image classification from features.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Cj6pLclmwT">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In deep learning, leveraging transfer learning has recently been shown to be an effective strategy for training large high performance models with Differential Privacy (DP). Moreover, somewhat surprisingly, recent works have found that privately training just the last layer of a pre-trained model provides the best utility with DP. While past studies largely rely on using first-order differentially private training algorithms like DP-SGD for training large models, in the specific case of privately learning from features, we observe that computational burden is often low enough to allow for more sophisticated optimization schemes, including second-order methods. To that end, we systematically explore the effect of design parameters such as loss function and optimization algorithm. We find that, while commonly used logistic regression performs better than linear regression in the non-private setting, the situation is reversed in the private setting. We find that least-squares linear regression is much more effective than logistic regression from both privacy and computational standpoint, especially at stricter epsilon values ($\epsilon &lt; 1$). On the optimization side, we also explore using Newton&#39;s method, and find that second-order information is quite helpful even with privacy, although the benefit significantly diminishes with stricter privacy guarantees. While both methods use second-order information, least squares is more effective at lower epsilon values while Newton&#39;s method is more effective at larger epsilon values. To combine the benefits of both methods, we propose a novel optimization algorithm called DP-FC, which leverages feature covariance instead of the Hessian of the logistic regression loss and performs well across all $\epsilon$ values we tried. With this, we obtain new SOTA results on ImageNet-1k, CIFAR-100 and CIFAR-10 across all values of $\epsilon$ typically considered. Most remarkably, on ImageNet-1K, we obtain top-1 accuracy of 88\% under DP guarantee of (8, $8 * 10^{-7}$) and 84.3\% under (0.1, $8 * 10^{-7}$).},
  archive      = {J_TMLR},
  author       = {Harsh Mehta and Walid Krichene and Abhradeep Guha Thakurta and Alexey Kurakin and Ashok Cutkosky},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Differentially private image classification from features},
  url          = {https://openreview.net/forum?id=Cj6pLclmwT},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A study of biologically plausible neural network: The role
and interactions of brain-inspired mechanisms in continual learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=DJr6zorJM2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans excel at continually acquiring, consolidating, and retaining information from an ever-changing environment, whereas artificial neural networks (ANNs) exhibit catastrophic forgetting. There are considerable differences in the complexity of synapses, the processing of information, and the learning mechanisms in biological neural networks and their artificial counterparts, which may explain the mismatch in performance. We consider a biologically plausible framework that constitutes separate populations of exclusively excitatory and inhibitory neurons that adhere to Dale&#39;s principle, and the excitatory pyramidal neurons are augmented with dendritic-like structures for context-dependent processing of stimuli. We then conduct a comprehensive study on the role and interactions of different mechanisms inspired by the brain, including sparse non-overlapping representations, Hebbian learning, synaptic consolidation, and replay of past activations that accompanied the learning event. Our study suggests that the employing of multiple complementary mechanisms in a biologically plausible architecture, similar to the brain, may be effective in enabling continual learning in ANNs. \footnote{We will make the code available upon acceptance.}},
  archive      = {J_TMLR},
  author       = {Fahad Sarfraz and Elahe Arani and Bahram Zonooz},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A study of biologically plausible neural network: The role and interactions of brain-inspired mechanisms in continual learning},
  url          = {https://openreview.net/forum?id=DJr6zorJM2},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Training data size induced double descent for denoising
feedforward neural networks and the role of training noise.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=FdMWtpVT1I">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When training an unregularized denoising feedforward neural network, we show that the generalization error versus the number of training data points is a double descent curve. We formalize the question of how many training data points should be used by looking at the generalization error for denoising noisy test data. Prior work on computing the generalization error focuses on adding noise to target outputs. However, adding noise to the input is more in line with current pre-training practices. In the linear (in the inputs) regime, we provide an asymptotically exact formula for the generalization error for rank 1 data and an approximation for the generalization error for rank $r$ data. From this, we derive a formula for the amount of noise that needs to be added to the training data to minimize the denoising error. This results in the emergence of a shrinkage phenomenon for improving the performance of denoising DNNs by making the training SNR smaller than the test SNR. Further, we see that the amount of shrinkage (ratio of the train to test SNR) also follows a double descent curve.},
  archive      = {J_TMLR},
  author       = {Rishi Sonthalia and Raj Rao Nadakuditi},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Training data size induced double descent for denoising feedforward neural networks and the role of training noise},
  url          = {https://openreview.net/forum?id=FdMWtpVT1I},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). POLTER: Policy trajectory ensemble regularization for
unsupervised reinforcement learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Hnr23knZfY">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of Unsupervised Reinforcement Learning (URL) is to find a reward-agnostic prior policy on a task domain, such that the sample-efficiency on supervised downstream tasks is improved. Although agents initialized with such a prior policy can achieve a significantly higher reward with fewer samples when finetuned on the downstream task, it is still an open question how an optimal pretrained prior policy can be achieved in practice. In this work, we present POLTER (Policy Trajectory Ensemble Regularization) – a general method to regularize the pretraining that can be applied to any URL algorithm and is especially useful on data- and knowledge-based URL algorithms. It utilizes an ensemble of policies that are discovered during pretraining and moves the policy of the URL algorithm closer to its optimal prior. Our method is based on a theoretical framework, and we analyze its practical effects on a white-box benchmark, allowing us to study POLTER with full control. In our main experiments, we evaluate POLTER on the Unsupervised Reinforcement Learning Benchmark (URLB), which consists of 12 tasks in 3 domains. We demonstrate the generality of our approach by improving the performance of a diverse set of data- and knowledge-based URL algorithms by 19% on average and up to 40% in the best case. Under a fair comparison with tuned baselines and tuned POLTER, we establish a new state-of-the-art for model-free methods on the URLB.},
  archive      = {J_TMLR},
  author       = {Frederik Schubert and Carolin Benjamins and Sebastian Döhler and Bodo Rosenhahn and Marius Lindauer},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {POLTER: Policy trajectory ensemble regularization for unsupervised reinforcement learning},
  url          = {https://openreview.net/forum?id=Hnr23knZfY},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Group fairness in reinforcement learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=JkIH4MeOc3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We pose and study the problem of satisfying fairness in the online Reinforcement Learning (RL) setting. We focus on the group notions of fairness, according to which agents belonging to different groups should have similar performance based on some given measure. We consider the setting of maximizing return in an unknown environment (unknown transition and reward function) and show that it is possible to have RL algorithms that learn the best fair policies without violating the fairness requirements at any point in time during the learning process. In the tabular finite-horizon episodic setting, we provide an algorithm that combines the principle of optimism and pessimism under uncertainty to achieve zero fairness violation with arbitrarily high probability while also maintaining sub-linear regret guarantees. For the high-dimensional Deep-RL setting, we present algorithms based on the performance-difference style approximate policy improvement update step and we report encouraging empirical results on various traditional RL-inspired benchmarks showing that our algorithms display the desired behavior of learning the optimal policy while performing a fair learning process.},
  archive      = {J_TMLR},
  author       = {Harsh Satija and Alessandro Lazaric and Matteo Pirotta and Joelle Pineau},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Group fairness in reinforcement learning},
  url          = {https://openreview.net/forum?id=JkIH4MeOc3},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A modulation layer to increase neural network robustness
against data quality issues. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=MRLHN4MSmA">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data missingness and quality are common problems in machine learning, especially for high-stakes applications such as healthcare. Developers often train machine learning models on carefully curated datasets using only high-quality data; however, this reduces the utility of such models in production environments. We propose a novel neural network modification to mitigate the impacts of low-quality and missing data which involves replacing the fixed weights of a fully-connected layer with a function of additional input. This is inspired by neuromodulation in biological neural networks where the cortex can up- and down-regulate inputs based on their reliability and the presence of other data. In testing, with reliability scores as a modulating signal, models with modulating layers were found to be more robust against data quality degradation, including additional missingness. These models are superior to imputation as they save on training time by entirely skipping the imputation process and further allow the introduction of other data quality measures that imputation cannot handle. Our results suggest that explicitly accounting for reduced information quality with a modulating fully connected layer can enable the deployment of artificial intelligence systems in real-time applications.},
  archive      = {J_TMLR},
  author       = {Mohamed Abdelhack and Jiaming Zhang and Sandhya Tripathi and Bradley A Fritz and Daniel Felsky and Michael Avidan and Yixin Chen and Christopher Ryan King},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A modulation layer to increase neural network robustness against data quality issues},
  url          = {https://openreview.net/forum?id=MRLHN4MSmA},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transframer: Arbitrary frame prediction with generative
models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=OJtYpdiHNo">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a general-purpose framework for image modelling and vision tasks based on probabilistic frame prediction. Our approach unifies a broad range of tasks, from image segmentation, to novel view synthesis and video interpolation. We pair this framework with an architecture we term \modelname, which uses U-Net and Transformer components to condition on annotated context frames, and outputs sequences of sparse, compressed image features. Transframer is the state-of-the-art on a variety of video generation benchmarks, is competitive with the strongest models on few-shot view synthesis, and can generate coherent 30 second videos from a single image without any explicit geometric information. A single generalist Transframer simultaneously produces promising results on 8 tasks, including semantic segmentation, image classification and optical flow prediction with no task-specific architectural components, demonstrating that multi-task computer vision can be tackled using probabilistic image models. Our approach can in principle be applied to a wide range of applications that require learning the conditional structure of annotated image-formatted data.},
  archive      = {J_TMLR},
  author       = {Charlie Nash and Joao Carreira and Jacob C Walker and Iain Barr and Andrew Jaegle and Mateusz Malinowski and Peter Battaglia},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Transframer: Arbitrary frame prediction with generative models},
  url          = {https://openreview.net/forum?id=OJtYpdiHNo},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). On the statistical complexity of estimation and testing
under privacy constraints. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=OarsigVib0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The challenge of producing accurate statistics while respecting the privacy of the individuals in a sample is an important area of research. We study minimax lower bounds for classes of differentially private estimators. In particular, we show how to characterize the power of a statistical test under differential privacy in a plug-and-play fashion by solving an appropriate transport problem. With specific coupling constructions, this observation allows us to derive Le Cam-type and Fano-type inequalities not only for regular definitions of differential privacy but also for those based on Renyi divergence. We then proceed to illustrate our results on three simple, fully worked out examples. In particular, we show that the problem class has a huge importance on the provable degradation of utility due to privacy. In certain scenarios, we show that maintaining privacy results in a noticeable reduction in performance only when the level of privacy protection is very high. Conversely, for other problems, even a modest level of privacy protection can lead to a significant decrease in performance. Finally, we demonstrate that the DP-SGLD algorithm, a private convex solver, can be employed for maximum likelihood estimation with a high degree of confidence, as it provides near-optimal results with respect to both the size of the sample and the level of privacy protection. This algorithm is applicable to a broad range of parametric estimation procedures, including exponential families.},
  archive      = {J_TMLR},
  author       = {Clément Lalanne and Aurélien Garivier and Rémi Gribonval},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the statistical complexity of estimation and testing under privacy constraints},
  url          = {https://openreview.net/forum?id=OarsigVib0},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integrating bayesian network structure into residual flows
and variational autoencoders. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=OsKXlWamTQ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep generative models have become more popular in recent years due to their scalability and representation capacity. Unlike probabilistic graphical models, they typically do not incorporate specific domain knowledge. As such, this work explores incorporating arbitrary dependency structures, as specified by Bayesian networks, into variational autoencoders (VAEs). This is achieved by developing a new type of graphical normalizing flow, which extends residual flows by encoding conditional independence through masking of the flow’s residual block weight matrices, and using these to extend both the prior and inference network of the VAE. We show that the proposed graphical VAE provides a more interpretable model that generalizes better in data-sparse settings, when practitioners know or can hypothesize about certain latent factors in their domain. Furthermore, we show that graphical residual flows provide not only density estimation and inference performance competitive with existing graphical flows, but also more stable and accurate inversion in practice as a byproduct of the flow’s Lipschitz bounds.},
  archive      = {J_TMLR},
  author       = {Jacobie Mouton and Rodney Stephen Kroon},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Integrating bayesian network structure into residual flows and variational autoencoders},
  url          = {https://openreview.net/forum?id=OsKXlWamTQ},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural collapse: A review on modelling principles and
generalization. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=QTXocpAP9p">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep classifier neural networks enter the terminal phase of training (TPT) when training error reaches zero and tend to exhibit intriguing Neural Collapse (NC) properties. Neural collapse essentially represents a state at which the within-class variability of final hidden layer outputs is infinitesimally small and their class means form a simplex equiangular tight frame. This simplifies the last layer behaviour to that of a nearest-class center decision rule. Despite the simplicity of this state, the dynamics and implications of reaching it are yet to be fully understood. In this work, we review the principles which aid in modelling neural collapse, followed by the implications of this state on generalization and transfer learning capabilities of neural networks. Finally, we conclude by discussing potential avenues and directions for future research.},
  archive      = {J_TMLR},
  author       = {Vignesh Kothapalli},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Neural collapse: A review on modelling principles and generalization},
  url          = {https://openreview.net/forum?id=QTXocpAP9p},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A revenue function for comparison-based hierarchical
clustering. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=QzWr4w8PXx">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Comparison-based learning addresses the problem of learning when, instead of explicit features or pairwise similarities, one only has access to comparisons of the form: \emph{Object $A$ is more similar to $B$ than to $C$.} Recently, it has been shown that, in Hierarchical Clustering, single and complete linkage can be directly implemented using only such comparisons while several algorithms have been proposed to emulate the behaviour of average linkage. Hence, finding hierarchies (or dendrograms) using only comparisons is a well understood problem. However, evaluating their meaningfulness when no ground-truth nor explicit similarities are available remains an open question. In this paper, we bridge this gap by proposing a new revenue function that allows one to measure the goodness of dendrograms using only comparisons. We show that this function is closely related to Dasgupta&#39;s cost for hierarchical clustering that uses pairwise similarities. On the theoretical side, we use the proposed revenue function to resolve the open problem of whether one can approximately recover a latent hierarchy using few triplet comparisons. On the practical side, we present principled algorithms for comparison-based hierarchical clustering based on the maximisation of the revenue and we empirically compare them with existing methods.},
  archive      = {J_TMLR},
  author       = {Aishik Mandal and Michaël Perrot and Debarghya Ghoshdastidar},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A revenue function for comparison-based hierarchical clustering},
  url          = {https://openreview.net/forum?id=QzWr4w8PXx},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pre-trained perceptual features improve differentially
private image generation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=R6W7zkMz0P">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training even moderately-sized generative models with differentially-private stochastic gradient descent (DP-SGD) is difficult: the required level of noise for reasonable levels of privacy is simply too large. We advocate instead building off a good, relevant representation on an informative public dataset, then learning to model the private data with that representation. In particular, we minimize the maximum mean discrepancy (MMD) between private target data and a generator&#39;s distribution, using a kernel based on perceptual features learned from a public dataset. With the MMD, we can simply privatize the data-dependent term once and for all, rather than introducing noise at each step of optimization as in DP-SGD. Our algorithm allows us to generate CIFAR10-level images with $\epsilon \approx 2$ which capture distinctive features in the distribution, far surpassing the current state of the art, which mostly focuses on datasets such as MNIST and FashionMNIST at a large $\epsilon \approx 10$. Our work introduces simple yet powerful foundations for reducing the gap between private and non-private deep generative models. Our code is available at https://github.com/ParkLabML/DP-MEPF.},
  archive      = {J_TMLR},
  author       = {Frederik Harder and Milad Jalali and Danica J. Sutherland and Mijung Park},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Pre-trained perceptual features improve differentially private image generation},
  url          = {https://openreview.net/forum?id=R6W7zkMz0P},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explaining visual counterfactual explainers. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=RYeRNwRjNE">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explainability methods have been widely used to provide insight into the decisions made by statistical models, thus facilitating their adoption in various domains within the industry. Counterfactual explanation methods aim to improve our understanding of a model by perturbing samples in a way that would alter its response in an unexpected manner. This information is helpful for users and for machine learning practitioners to understand and improve their models. Given the value provided by counterfactual explanations, there is a growing interest in the research community to investigate and propose new methods. However, we identify two issues that could hinder the progress in this field. (1) Existing metrics do not accurately reflect the value of an explainability method for the users. (2) Comparisons between methods are usually performed with datasets like CelebA, where images are annotated with attributes that do not fully describe them and with subjective attributes such as ``Attractive&#39;&#39;. In this work, we address these problems by proposing an evaluation method with a principled metric to evaluate and compare different counterfactual explanation methods. The evaluation is based on a synthetic dataset where images are fully described by their annotated attributes. As a result, we are able to perform a fair comparison of multiple explainability methods in the recent literature, obtaining insights about their performance. We make the code and data public to the research community.},
  archive      = {J_TMLR},
  author       = {Diego Velazquez and Pau Rodriguez and Alexandre Lacoste and Issam H. Laradji and Xavier Roca and Jordi Gonzàlez},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Explaining visual counterfactual explainers},
  url          = {https://openreview.net/forum?id=RYeRNwRjNE},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bridging performance gap between minimal and maximal SVM
models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=SM1BkjGePI">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-class support vector machine (SVM) models are typically built using all possible pairs of binary SVM in a one-against-one fashion. This requires too much computation for datasets with hundreds or thousands of classes, which motivates the search for multi-class models that do not use all pairwise SVM. Our models correspond to the choice of the model graph, whose vertices correspond to classes and edges represent which pairwise SVMs are trained. We conduct experiments to uncover metrical and topological properties that impact the accuracy of a multi-class SVM model. Based on their results we propose a way to construct intermediate multi-class SVM models. The key insight is that for model graphs of diameter two, we can estimate missing pairwise probabilities from the known ones thus transforming the computation of posteriors to the usual complete (maximal) case. Our proposed algorithm allows one to reduce computational effort by 50-80% while keeping accuracy near, or even above that of a softmax classifier. In our work we use convolutional data sets, which have multiple advantages for benchmarking multi-class SVM models.},
  archive      = {J_TMLR},
  author       = {Ondrej Such and René Fabricius},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bridging performance gap between minimal and maximal SVM models},
  url          = {https://openreview.net/forum?id=SM1BkjGePI},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalization as dynamical robustness–the role of
riemannian contraction in supervised learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Sb6p5mcefw">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key property of successful learning algorithms is generalization. In classical supervised learning, generalization can be achieved by ensuring that the empirical error converges to the expected error as the number of training samples goes to infinity. Within this classical setting, we analyze the generalization properties of iterative optimizers such as stochastic gradient descent and natural gradient flow through the lens of dynamical systems and control theory. Specifically, we use contraction analysis to show that generalization and dynamical robustness are intimately related through the notion of algorithmic stability. In particular, we prove that Riemannian contraction in a supervised learning setting implies generalization. We show that if a learning algorithm is contracting in some Riemannian metric with rate $\lambda &gt; 0$, it is uniformly algorithmically stable with rate $\mathcal{O}(1/\lambda n)$, where $n$ is the number of examples in the training set. The results hold for stochastic and deterministic optimization, in both continuous and discrete-time, for convex and non-convex loss surfaces. The associated generalization bounds reduce to well-known results in the particular case of gradient descent over convex or strongly convex loss surfaces. They can be shown to be optimal in certain linear settings, such as kernel ridge regression under gradient flow. Finally, we demonstrate that the well-known Polyak-Lojasiewicz condition is intimately related to the contraction of a model&#39;s outputs as they evolve under gradient descent. This correspondence allows us to derive uniform algorithmic stability bounds for nonlinear function classes such as wide neural networks.},
  archive      = {J_TMLR},
  author       = {Leo Kozachkov and Patrick Wensing and Jean-Jacques Slotine},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Generalization as dynamical robustness--the role of riemannian contraction in supervised learning},
  url          = {https://openreview.net/forum?id=Sb6p5mcefw},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Monotone deep boltzmann machines. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=SgTKk6ryPr">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Boltzmann machines (DBMs), one of the first ``deep&#39;&#39; learning methods ever studied, are multi-layered probabilistic models governed by a pairwise energy function that describes the likelihood of all variables/nodes in the network. In practice, DBMs are often constrained, i.e., via the \emph{restricted} Boltzmann machine (RBM) architecture (which does not permit intra-layer connections), in order to allow for more efficient inference. In this work, we revisit the generic DBM approach, and ask the question: are there other possible restrictions to their design that would enable efficient (approximate) inference? In particular, we develop a new class of restricted model, the monotone DBM, which allows for arbitrary self-connection in each layer, but restricts the \emph{weights} in a manner that guarantees the existence and global uniqueness of a mean-field fixed point. To do this, we leverage tools from the recently-proposed monotone Deep Equilibrium model and show that a particular choice of activation results in a fixed-point iteration that gives a variational mean-field solution. While this approach is still largely conceptual, it is the first architecture that allows for efficient approximate inference in fully-general weight structures for DBMs. We apply this approach to simple deep convolutional Boltzmann architectures and demonstrate that it allows for tasks such as the joint completion and classification of images, within a single deep probabilistic setting, while avoiding the pitfalls of mean-field inference in traditional RBMs.},
  archive      = {J_TMLR},
  author       = {Zhili Feng and Ezra Winston and J Zico Kolter},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Monotone deep boltzmann machines},
  url          = {https://openreview.net/forum?id=SgTKk6ryPr},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reducing predictive feature suppression in
resource-constrained contrastive image-caption retrieval. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=T1XtOqrVKn">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To train image-caption retrieval (ICR) methods, contrastive loss functions are a common choice for optimization functions. Unfortunately, contrastive ICR methods are vulnerable to predictive feature suppression. Predictive features are features that correctly indicate the similarity between a query and a candidate item. However, in the presence of multiple predictive features during training, encoder models tend to suppress redundant predictive features, since these features are not needed to learn to discriminate between positive and negative pairs. We introduce an approach to reduce predictive feature suppression for resource-constrained ICR methods: latent target decoding (LTD). We add an additional decoder to the contrastive ICR framework, to reconstruct the input caption in a latent space of a general-purpose sentence encoder, which prevents the image and caption encoder from suppressing predictive features. We implement the LTD objective as an optimization constraint, to ensure that the reconstruction loss is below a bound value while primarily optimizing for the contrastive loss. Importantly, LTD does not depend on additional training data or expensive (hard) negative mining strategies. Our experiments show that, unlike reconstructing the input caption in the input space, LTD reduces predictive feature suppression, measured by obtaining higher recall@k, r-precision, and nDCG scores than a contrastive ICR baseline. Moreover, we show that LTD should be implemented as an optimization constraint instead of a dual optimization objective. Finally, we show that LTD can be used with different contrastive learning losses and a wide variety of resource-constrained ICR methods.},
  archive      = {J_TMLR},
  author       = {Maurits Bleeker and Andrew Yates and Maarten de Rijke},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reducing predictive feature suppression in resource-constrained contrastive image-caption retrieval},
  url          = {https://openreview.net/forum?id=T1XtOqrVKn},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Clustering using approximate nearest neighbour oracles.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=TzRXyO3CzX">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of clustering data points in a streaming setting when one has access to the geometry of the space only via approximate nearest neighbour (ANN) oracles. In this setting, we present algorithms for streaming $O(1)$-approximate $k$-median clustering and its (streaming) coreset construction. In certain domains of interest, such as spaces with constant expansion, our algorithms improve upon the best-known runtime of both these problems. Furthermore, our results extend to cost functions satisfying the approximate triangle inequality, which subsumes $k$-means clustering and $M$-estimators. Finally, we run experiments on Census1990 dataset wherein the results empirically support our theory.},
  archive      = {J_TMLR},
  author       = {Enayat Ullah and Harry Lang and Raman Arora and Vladimir Braverman},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Clustering using approximate nearest neighbour oracles},
  url          = {https://openreview.net/forum?id=TzRXyO3CzX},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weisfeiler and leman go infinite: Spectral and combinatorial
pre-colorings. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=YJDqQSAuB6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The limit in the expressivity of Message Passing Graph Neural Networks (MPGNNs) has recently led to the development of end-to-end learning GNN architectures. These advanced GNNs usually generalize existing notions in the GNN architecture or suggest new ones that break the limit of the existing, relatively simple MPGNNs. In this paper, we focus on a different solution, the two-phase approach (or pre-coloring), which enables to use of the same simple MPGNNs while improving their expressivity. We prove that using pre-colorings could strictly increase the expressivity of MPGNNs ad infinitum. We also suggest new pre-coloring based on the spectral decomposition of the graph Laplacian and prove that it strictly improves the expressivity of standard MPGNNs. An extensive evaluation of the proposed method with different MPGNN models on various graph classification and node property prediction datasets consistently outperforms previous pre-coloring strategies. The code to reproduce our experiments is available at \url{https://github.com/TPFI22/Spectral-and-Combinatorial}.},
  archive      = {J_TMLR},
  author       = {Or Feldman and Amit Boyarski and Shai Feldman and Dani Kogan and Avi Mendelson and Chaim Baskin},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Weisfeiler and leman go infinite: Spectral and combinatorial pre-colorings},
  url          = {https://openreview.net/forum?id=YJDqQSAuB6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unifying physical systems’ inductive biases in neural ODE
using dynamics constraints. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ZOAb497iaY">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conservation of energy is at the core of many physical phenomena and dynamical systems. There have been a significant number of works in the past few years aimed at predicting the trajectory of motion of dynamical systems using neural networks while adhering to the law of conservation of energy. Most of these works are inspired by classical mechanics such as Hamiltonian and Lagrangian mechanics as well as Neural Ordinary Differential Equations. While these works have been shown to work well in specific domains respectively, there is a lack of a unifying method that is more generally applicable without requiring significant changes to the neural network architectures. In this work, we aim to address this issue by providing a simple method that could be applied to not just energy-conserving systems, but also dissipative systems, by including a different inductive bias in different cases in the form of a regularisation term in the loss function. The proposed method does not require changing the neural network architecture and could form the basis to validate a novel idea, therefore showing promises to accelerate research in this direction.},
  archive      = {J_TMLR},
  author       = {Yi Heng Lim and Muhammad Firmansyah Kasim},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unifying physical systems’ inductive biases in neural ODE using dynamics constraints},
  url          = {https://openreview.net/forum?id=ZOAb497iaY},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive patch foraging in deep reinforcement learning
agents. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=a0T3nOP9sB">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patch foraging is one of the most heavily studied behavioral optimization challenges in biology. However, despite its importance to biological intelligence, this behavioral optimization problem is understudied in artificial intelligence research. Patch foraging is especially amenable to study given that it has a known optimal solution, which may be difficult to discover given current techniques in deep reinforcement learning. Here, we investigate deep reinforcement learning agents in an ecological patch foraging task. For the first time, we show that machine learning agents can learn to patch forage adaptively in patterns similar to biological foragers, and approach optimal patch foraging behavior when accounting for temporal discounting. Finally, we show emergent internal dynamics in these agents that resemble single-cell recordings from foraging non-human primates, which complements experimental and theoretical work on the neural mechanisms of biological foraging. This work suggests that agents interacting in complex environments with ecologically valid pressures arrive at common solutions, suggesting the emergence of foundational computations behind adaptive, intelligent behavior in both biological and artificial agents.},
  archive      = {J_TMLR},
  author       = {Nathan Wispinski and Andrew Butcher and Kory Wallace Mathewson and Craig S Chapman and Matthew Botvinick and Patrick M. Pilarski},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Adaptive patch foraging in deep reinforcement learning agents},
  url          = {https://openreview.net/forum?id=a0T3nOP9sB},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A free lunch with influence functions? An empirical
evaluation of influence functions for average treatment effect
estimation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=dQxBRqCjLr">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The applications of causal inference may be life-critical, including the evaluation of vaccinations, medicine, and social policy. However, when undertaking estimation for causal inference, practitioners rarely have access to what might be called `ground-truth&#39; in a supervised learning setting, meaning the chosen estimation methods cannot be evaluated and must be assumed to be reliable. It is therefore crucial that we have a good understanding of the performance consistency of typical methods available to practitioners. In this work we provide a comprehensive evaluation of recent semiparametric methods (including neural network approaches) for average treatment effect estimation. Such methods have been proposed as a means to derive unbiased causal effect estimates and statistically valid confidence intervals, even when using otherwise non-parametric, data-adaptive machine learning techniques. We also propose a new estimator `MultiNet&#39;, and a variation on the semiparametric update step `MultiStep&#39;, which we evaluate alongside existing approaches. The performance of both semiparametric and `regular&#39; methods are found to be dataset dependent, indicating an interaction between the methods used, the sample size, and nature of the data generating process. Our experiments highlight the need for practitioners to check the consistency of their findings, potentially by undertaking multiple analyses with different combinations of estimators.},
  archive      = {J_TMLR},
  author       = {Matthew James Vowels and Sina Akbari and Necati Cihan Camgoz and Richard Bowden},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A free lunch with influence functions? an empirical evaluation of influence functions for average treatment effect estimation},
  url          = {https://openreview.net/forum?id=dQxBRqCjLr},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Partition-based active learning for graph neural networks.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=e0xaRylNuT">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of semi-supervised learning with Graph Neural Networks (GNNs) in an active learning setup. We propose GraphPart, a novel partition-based active learning approach for GNNs. GraphPart first splits the graph into disjoint partitions and then selects representative nodes within each partition to query. The proposed method is motivated by a novel analysis of the classification error under realistic smoothness assumptions over the graph and the node features. Extensive experiments on multiple benchmark datasets demonstrate that the proposed method outperforms existing active learning methods for GNNs under a wide range of annotation budget constraints. In addition, the proposed method does not introduce additional hyperparameters, which is crucial for model training, especially in the active learning setting where a labeled validation set may not be available.},
  archive      = {J_TMLR},
  author       = {Jiaqi Ma and Ziqiao Ma and Joyce Chai and Qiaozhu Mei},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Partition-based active learning for graph neural networks},
  url          = {https://openreview.net/forum?id=e0xaRylNuT},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep double descent via smooth interpolation. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=fempQstMbV">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability of overparameterized deep networks to interpolate noisy data, while at the same time showing good generalization performance, has been recently characterized in terms of the double descent curve for the test error. Common intuition from polynomial regression suggests that overparameterized networks are able to sharply interpolate noisy data, without considerably deviating from the ground-truth signal, thus preserving generalization ability. At present, a precise characterization of the relationship between interpolation and generalization for deep networks is missing. In this work, we quantify sharpness of fit of the training data interpolated by neural network functions, by studying the loss landscape w.r.t. to the input variable locally to each training point, over volumes around cleanly- and noisily-labelled training samples, as we systematically increase the number of model parameters and training epochs. Our findings show that loss sharpness in the input space follows both model- and epoch-wise double descent, with worse peaks observed around noisy labels. While small interpolating models sharply fit both clean and noisy data, large interpolating models express a smooth loss landscape, where noisy targets are predicted over large volumes around training data points, in contrast to existing intuition.},
  archive      = {J_TMLR},
  author       = {Matteo Gamba and Erik Englesson and Mårten Björkman and Hossein Azizpour},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Deep double descent via smooth interpolation},
  url          = {https://openreview.net/forum?id=fempQstMbV},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Understanding noise-augmented training for randomized
smoothing. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=fvyh6mDWFr">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Randomized smoothing is a technique for providing provable robustness guarantees against adversarial attacks while making minimal assumptions about a classifier. This method relies on taking a majority vote of any base classifier over multiple noise-perturbed inputs to obtain a smoothed classifier, and it remains the tool of choice to certify deep and complex neural network models. Nonetheless, non-trivial performance of such smoothed classifier crucially depends on the base model being trained on noise-augmented data, i.e., on a smoothed input distribution. While widely adopted in practice, it is still unclear how this noisy training of the base classifier precisely affects the risk of the robust smoothed classifier, leading to heuristics and tricks that are poorly understood. In this work we analyze these trade-offs theoretically in a binary classification setting, proving that these common observations are not universal. We show that, without making stronger distributional assumptions, no benefit can be expected from predictors trained with noise-augmentation, and we further characterize distributions where such benefit is obtained. Our analysis has direct implications to the practical deployment of randomized smoothing, and we illustrate some of these via experiments on CIFAR-10 and MNIST, as well as on synthetic datasets.},
  archive      = {J_TMLR},
  author       = {Ambar Pal and Jeremias Sulam},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Understanding noise-augmented training for randomized smoothing},
  url          = {https://openreview.net/forum?id=fvyh6mDWFr},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural shape compiler: A unified framework for transforming
between text, point cloud, and program. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=gR9UVgH8PZ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D shapes have complementary abstractions from low-level geometry to part-based hierarchies to languages, which convey different levels of information. This paper presents a unified framework to translate between pairs of shape abstractions: $\textit{Text}$ $\Longleftrightarrow$ $\textit{Point Cloud}$ $\Longleftrightarrow$ $\textit{Program}$. We propose $\textbf{\textit{Neural Shape Compiler}}$ to model the abstraction transformation as a conditional generation process. It converts 3D shapes of three abstract types into unified discrete shape code, transforms each shape code into code of other abstract types through the proposed $\textit{ShapeCode Transformer}$, and decodes them to output the target shape abstraction. Point Cloud code is obtained in a class-agnostic way by the proposed $\textit{Point}$VQVAE. On Text2Shape, ShapeGlot, ABO, Genre, and Program Synthetic datasets, Neural Shape Compiler shows strengths in $\textit{Text}$ $\Longrightarrow$ $\textit{Point Cloud}$, $\textit{Point Cloud}$ $\Longrightarrow$ $\textit{Text}$, $\textit{Point Cloud}$ $\Longrightarrow$ $\textit{Program}$, and Point Cloud Completion tasks. Additionally, Neural Shape Compiler benefits from jointly training on all heterogeneous data and tasks.},
  archive      = {J_TMLR},
  author       = {Tiange Luo and Honglak Lee and Justin Johnson},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Neural shape compiler: A unified framework for transforming between text, point cloud, and program},
  url          = {https://openreview.net/forum?id=gR9UVgH8PZ},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimating the density ratio between distributions with high
discrepancy using multinomial logistic regression. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=jM8nzUzBWr">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functions of the ratio of the densities $p/q$ are widely used in machine learning to quantify the discrepancy between the two distributions $p$ and $q$. For high-dimensional distributions, binary classification-based density ratio estimators have shown great promise. However, when densities are well-separated, estimating the density ratio with a binary classifier is challenging. In this work, we show that the state-of-the-art density ratio estimators do perform poorly on well-separated cases and demonstrate that this is due to distribution shifts between training and evaluation time. We present an alternative method that leverages multi-class classification for density ratio estimation and does not suffer from distribution shift issues. The method uses a set of auxiliary densities $\{m_k\}_{k=1}^K$ and trains a multi-class logistic regression to classify the samples from $p, q$ and $\{m_k\}_{k=1}^K$ into $K+2$ classes. We show that if these auxiliary densities are constructed such that they overlap with $p$ and $q$, then a multi-class logistic regression allows for estimating $\log p/q$ on the domain of any of the $K+2$ distributions and resolves the distribution shift problems of the current state-of-the-art methods. We compare our method to state-of-the-art density ratio estimators on both synthetic and real datasets and demonstrate its superior performance on the tasks of density ratio estimation, mutual information estimation, and representation learning.},
  archive      = {J_TMLR},
  author       = {Akash Srivastava and Seungwook Han and Kai Xu and Benjamin Rhodes and Michael U. Gutmann},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Estimating the density ratio between distributions with high discrepancy using multinomial logistic regression},
  url          = {https://openreview.net/forum?id=jM8nzUzBWr},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). UncertaINR: Uncertainty quantification of end-to-end
implicit neural representations for computed tomography. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=jdGMBgYvfX">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implicit neural representations (INRs) have achieved impressive results for scene reconstruction and computer graphics, where their performance has primarily been assessed on reconstruction accuracy. As INRs make their way into other domains, where model predictions inform high-stakes decision-making, uncertainty quantification of INR inference is becoming critical. To that end, we study a Bayesian reformulation of INRs, UncertaINR, in the context of computed tomography, and evaluate several Bayesian deep learning implementations in terms of accuracy and calibration. We find that they achieve well-calibrated uncertainty, while retaining accuracy competitive with other classical, INR-based, and CNN-based reconstruction techniques. Contrary to common intuition in the Bayesian deep learning literature, we find that INRs obtain the best calibration with computationally efficient Monte Carlo dropout, outperforming Hamiltonian Monte Carlo and deep ensembles. Moreover, in contrast to the best-performing prior approaches, UncertaINR does not require a large training dataset, but only a handful of validation images.},
  archive      = {J_TMLR},
  author       = {Francisca Vasconcelos and Bobby He and Nalini M Singh and Yee Whye Teh},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {UncertaINR: Uncertainty quantification of end-to-end implicit neural representations for computed tomography},
  url          = {https://openreview.net/forum?id=jdGMBgYvfX},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Private multi-task learning: Formulation and applications to
federated learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=onufdyHvqN">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many problems in machine learning rely on multi-task learning (MTL), in which the goal is to solve multiple related machine learning tasks simultaneously. MTL is particularly relevant for privacy-sensitive applications in areas such as healthcare, finance, and IoT computing, where sensitive data from multiple, varied sources are shared for the purpose of learning. In this work, we formalize notions of client-level privacy for MTL via billboard privacy (BP), a relaxation of differential privacy for mechanism design and distributed optimization. We then propose an algorithm for mean-regularized MTL, an objective commonly used for applications in personalized federated learning, subject to BP. We analyze our objective and solver, providing certifiable guarantees on both privacy and utility. Empirically, we find that our method provides improved privacy/utility trade-offs relative to global baselines across common federated learning benchmarks.},
  archive      = {J_TMLR},
  author       = {Shengyuan Hu and Steven Wu and Virginia Smith},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Private multi-task learning: Formulation and applications to federated learning},
  url          = {https://openreview.net/forum?id=onufdyHvqN},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Active learning of ordinal embeddings: A user study on
football data. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=oq3tx5kinu">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans innately measure distance between instances in an unlabeled dataset using an unknown similarity function. Distance metrics can only serve as proxy for similarity in information retrieval of similar instances. Learning a good similarity function from human annotations improves the quality of retrievals. This work uses deep metric learning to learn these user-defined similarity functions from few annotations for a large football trajectory dataset. We adapt an entropy-based active learning method with recent work from triplet mining to collect easy-to-answer but still informative annotations from human participants and use them to train a deep convolutional network that generalizes to unseen samples. Our user study shows that our approach improves the quality of the information retrieval compared to a previous deep metric learning approach that relies on a Siamese network. Specifically, we shed light on the strengths and weaknesses of passive sampling heuristics and active learners alike by analyzing the participants&#39; response efficacy. To this end, we collect accuracy, algorithmic time complexity, the participants&#39; fatigue and time-to-response, qualitative self-assessment and statements, as well as the effects of mixed-expertise annotators and their consistency on model performance and transfer-learning.},
  archive      = {J_TMLR},
  author       = {Christoffer Löffler and Kion Fallah and Stefano Fenu and Dario Zanca and Bjoern Eskofier and Christopher John Rozell and Christopher Mutschler},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Active learning of ordinal embeddings: A user study on football data},
  url          = {https://openreview.net/forum?id=oq3tx5kinu},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PAC-bayes generalisation bounds for heavy-tailed losses
through supermartingales. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=qxrwt6F3sf">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While PAC-Bayes is now an established learning framework for light-tailed losses (\emph{e.g.}, subgaussian or subexponential), its extension to the case of heavy-tailed losses remains largely uncharted and has attracted a growing interest in recent years. We contribute PAC-Bayes generalisation bounds for heavy-tailed losses under the sole assumption of bounded variance of the loss function. Under that assumption, we extend previous results from \citet{kuzborskij2019efron}. Our key technical contribution is exploiting an extention of Markov&#39;s inequality for supermartingales. Our proof technique unifies and extends different PAC-Bayesian frameworks by providing bounds for unbounded martingales as well as bounds for batch and online learning with heavy-tailed losses.},
  archive      = {J_TMLR},
  author       = {Maxime Haddouche and Benjamin Guedj},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {PAC-bayes generalisation bounds for heavy-tailed losses through supermartingales},
  url          = {https://openreview.net/forum?id=qxrwt6F3sf},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Uncovering the representation of spiking neural networks
trained with surrogate gradient. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=s9efQF3QW1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs) are recognized as the candidate for the next-generation neural networks due to their bio-plausibility and energy efficiency. Recently, researchers have demonstrated that SNNs are able to achieve nearly state-of-the-art performance in image recognition tasks using surrogate gradient training. However, some essential questions exist pertaining to SNNs that are little studied: Do SNNs trained with surrogate gradient learn different representations from traditional Artificial Neural Networks (ANNs)? Does the time dimension in SNNs provide unique representation power? In this paper, we aim to answer these questions by conducting a representation similarity analysis between SNNs and ANNs using Centered Kernel Alignment (CKA). We start by analyzing the spatial dimension of the networks, including both the width and the depth. Furthermore, our analysis of residual connections shows that SNNs learn a periodic pattern, which rectifies the representations in SNNs to be ANN-like. We additionally investigate the effect of the time dimension on SNN representation, finding that deeper layers encourage more dynamics along the time dimension. We also investigate the impact of input data such as event-stream data and adversarial attacks. Our work uncovers a host of new findings of representations in SNNs. We hope this work will inspire future research to fully comprehend the representation power of SNNs. Code is released at https://github.com/Intelligent-Computing-Lab-Yale/SNNCKA.},
  archive      = {J_TMLR},
  author       = {Yuhang Li and Youngeun Kim and Hyoungseob Park and Priyadarshini Panda},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Uncovering the representation of spiking neural networks trained with surrogate gradient},
  url          = {https://openreview.net/forum?id=s9efQF3QW1},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bridging graph position encodings for transformers with
weighted graph-walking automata. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=tE2NiMGd07">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A current goal in the graph neural network literature is to enable transformers to operate on graph-structured data, given their success on language and vision tasks. Since the transformer&#39;s original sinusoidal positional encodings (PEs) are not applicable to graphs, recent work has focused on developing graph PEs, rooted in spectral graph theory or various spatial features of a graph. In this work, we introduce a new graph PE, Graph Automaton PE (GAPE), based on weighted graph-walking automata (a novel extension of graph-walking automata). We compare the performance of GAPE with other PE schemes on both machine translation and graph-structured tasks, and we show that it generalizes several other PEs. An additional contribution of this study is a theoretical and controlled experimental comparison of many recent PEs in graph transformers, independent of the use of edge features.},
  archive      = {J_TMLR},
  author       = {Patrick Soga and David Chiang},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bridging graph position encodings for transformers with weighted graph-walking automata},
  url          = {https://openreview.net/forum?id=tE2NiMGd07},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Extended agriculture-vision: An extension of a large aerial
image dataset for agricultural pattern analysis. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=v5jwDLqfQo">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key challenge for much of the machine learning work on remote sensing and earth observation data is the difficulty in acquiring large amounts of accurately labeled data. This is particularly true for semantic segmentation tasks, which are much less common in the remote sensing domain because of the incredible difficulty in collecting precise, accurate, pixel-level annotations at scale. Recent efforts have addressed these challenges both through the creation of supervised datasets as well as the application of self-supervised methods. We continue these efforts on both fronts. First, we generate and release an improved version of the Agriculture-Vision dataset (Chiu et al., 2020b) to include raw, full-field imagery for greater experimental flexibility. Second, we extend this dataset with the release of 3600 large, high-resolution (10cm/pixel), full-field, red-green-blue and near-infrared images for pre-training. Third, we incorporate the Pixel-to-Propagation Module Xie et al. (2021b) originally built on the SimCLR framework into the framework of MoCo-V2 Chen et al.(2020b). Finally, we demonstrate the usefulness of this data by benchmarking different contrastive learning approaches on both downstream classification and semantic segmentation tasks. We explore both CNN and Swin Transformer Liu et al. (2021a) architectures within different frameworks based on MoCo-V2. Together, these approaches enable us to better detect key agricultural patterns of interest across a field from aerial imagery so that farmers may be alerted to problematic areas in a timely fashion to inform their management decisions. Furthermore, the release of these datasets will support numerous avenues of research for computer vision in remote sensing for agriculture.},
  archive      = {J_TMLR},
  author       = {Jing Wu and David Pichler and Daniel Marley and Naira Hovakimyan and David A Wilson and Jennifer Hobbs},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Extended agriculture-vision: An extension of a large aerial image dataset for agricultural pattern analysis},
  url          = {https://openreview.net/forum?id=v5jwDLqfQo},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prior and posterior networks: A survey on evidential deep
learning methods for uncertainty estimation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=xqS8k9E75c">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Popular approaches for quantifying predictive uncertainty in deep neural networks often involve distributions over weights or multiple models, for instance via Markov Chain sampling, ensembling, or Monte Carlo dropout. These techniques usually incur overhead by having to train multiple model instances or do not produce very diverse predictions. This comprehensive and extensive survey aims to familiarize the reader with an alternative class of models based on the concept of Evidential Deep Learning: For unfamiliar data, they admit &quot;what they don&#39;t know&quot; and fall back onto a prior belief. Furthermore, they allow uncertainty estimation in a single model and forward pass by parameterizing distributions over distributions. This survey recapitulates existing works, focusing on the implementation in a classification setting, before surveying the application of the same paradigm to regression. We also reflect on the strengths and weaknesses compared to other existing methods and provide the most fundamental derivations using a unified notation to aid future research.},
  archive      = {J_TMLR},
  author       = {Dennis Thomas Ulmer and Christian Hardmeier and Jes Frellsen},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Prior and posterior networks: A survey on evidential deep learning methods for uncertainty estimation},
  url          = {https://openreview.net/forum?id=xqS8k9E75c},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Memory-efficient reinforcement learning with value-based
knowledge consolidation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=zSDCvlaVBn">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks are promising for general function approximation but challenging to train on non-independent or non-identically distributed data due to catastrophic forgetting. The experience replay buffer, a standard component in deep reinforcement learning, is often used to reduce forgetting and improve sample efficiency by storing experiences in a large buffer and using them for training later. However, a large replay buffer results in a heavy memory burden, especially for onboard and edge devices with limited memory capacities. We propose memory-efficient reinforcement learning algorithms based on the deep Q-network algorithm to alleviate this problem. Our algorithms reduce forgetting and maintain high sample efficiency by consolidating knowledge from the target Q-network to the current Q-network. Compared to baseline methods, our algorithms achieve comparable or better performance in both feature-based and image-based tasks while easing the burden of large experience replay buffers.},
  archive      = {J_TMLR},
  author       = {Qingfeng Lan and Yangchen Pan and Jun Luo and A. Rupam Mahmood},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Memory-efficient reinforcement learning with value-based knowledge consolidation},
  url          = {https://openreview.net/forum?id=zSDCvlaVBn},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Turning normalizing flows into monge maps with geodesic
gaussian preserving flows. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=2UQv8L1Cv9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Normalizing Flows (NF) are powerful likelihood-based generative models that are able to trade off between expressivity and tractability to model complex densities. A now well established research avenue leverages optimal transport (OT) and looks for Monge maps, i.e. models with minimal effort between the source and target distributions. This paper introduces a method based on Brenier&#39;s polar factorization theorem to transform any trained NF into a more OT-efficient version without changing the final density. We do so by learning a rearrangement of the source (Gaussian) distribution that minimizes the OT cost between the source and the final density. The Gaussian preserving transformation is implemented with the construction of high dimensional divergence free functions and the path leading to the estimated Monge map is further constrained to lie on a geodesic in the space of volume-preserving diffeomorphisms thanks to Euler&#39;s equations. The proposed method leads to smooth flows with reduced OT costs for several existing models without affecting the model performance.},
  archive      = {J_TMLR},
  author       = {Guillaume Morel and Lucas Drumetz and Simon Benaïchouche and Nicolas Courty and François Rousseau},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Turning normalizing flows into monge maps with geodesic gaussian preserving flows},
  url          = {https://openreview.net/forum?id=2UQv8L1Cv9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Extreme masking for learning instance and distributed visual
representations. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=3epEbhdgbv">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents a scalable approach for learning spatially distributed visual representations over individual tokens and a holistic instance representation simultaneously. We use self-attention blocks to represent spatially distributed tokens, followed by cross-attention blocks to aggregate the holistic instance. The core of the approach is the use of extremely large token masking (75\%-90\%) as the data augmentation for supervision. Our model, named ExtreMA, follows the plain BYOL approach where the instance representation from the unmasked subset is trained to predict that from the intact input. Instead of encouraging invariance across inputs, learning requires the model to capture informative variations in an image. The paper makes three contributions: 1) It presents random masking as a strong and computationally efficient data augmentation for siamese representation learning. 2) With multiple sampling per instance, extreme masking greatly speeds up learning and improves performance with more data. 3) ExtreMA obtains stronger linear probing performance than masked modeling methods, and better transfer performance than prior contrastive models.},
  archive      = {J_TMLR},
  author       = {Zhirong Wu and Zihang Lai and Xiao Sun and Stephen Lin},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Extreme masking for learning instance and distributed visual representations},
  url          = {https://openreview.net/forum?id=3epEbhdgbv},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). L-SVRG and l-katyusha with adaptive sampling. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=9lyqt3rbDc">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic gradient-based optimization methods, such as L-SVRG and its accelerated variant L-Katyusha (Kovalev et al., 2020), are widely used to train machine learning models. Theoretical and empirical performance of L-SVRG and L-Katyusha can be improved by sampling the observations from a non-uniform distribution Qian et al. (2021). However, to design a desired sampling distribution, Qian et al. (2021) rely on prior knowledge of smoothness constants that can be computationally intractable to obtain in practice when the dimension of the model parameter is high. We propose an adaptive sampling strategy for L-SVRG and L-Katyusha that learns the sampling distribution with little computational overhead, while allowing it to change with iterates, and at the same time does not require any prior knowledge on the problem parameters. We prove convergence guarantees for L-SVRG and L-Katyusha for convex objectives when the sampling distribution changes with iterates. These results show that even without prior information, the proposed adaptive sampling strategy matches, and in some cases even surpasses, the performance of the sampling scheme in Qian et al. (2021). Extensive simulations support our theory and the practical utility of the proposed sampling scheme on real data.},
  archive      = {J_TMLR},
  author       = {Boxin Zhao and Boxiang Lyu and mladen kolar},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {L-SVRG and L-katyusha with adaptive sampling},
  url          = {https://openreview.net/forum?id=9lyqt3rbDc},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Numerical accounting in the shuffle model of differential
privacy. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=11osftjEbF">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shuffle model of differential privacy is a novel distributed privacy model based on a combination of local privacy mechanisms and a secure shuffler. It has been shown that the additional randomisation provided by the shuffler improves privacy bounds compared to the purely local mechanisms. Accounting tight bounds, however, is complicated by the complexity brought by the shuffler. The recently proposed numerical techniques for evaluating $(\varepsilon,\delta)$-differential privacy guarantees have been shown to give tighter bounds than commonly used methods for compositions of various complex mechanisms. In this paper, we show how to utilise these numerical accountants for adaptive compositions of general $\varepsilon$-LDP shufflers and for shufflers of $k$-randomised response mechanisms, including their subsampled variants. This is enabled by an approximation that speeds up the evaluation of the corresponding privacy loss distribution from $\mathcal{O}(n^2)$ to $\mathcal{O}(n)$, where $n$ is the number of users, without noticeable change in the resulting $\delta(\varepsilon)$-upper bounds. We also demonstrate looseness of the existing bounds and methods found in the literature, improving previous composition results for shufflers significantly.},
  archive      = {J_TMLR},
  author       = {Antti Koskela and Mikko A. Heikkilä and Antti Honkela},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Numerical accounting in the shuffle model of differential privacy},
  url          = {https://openreview.net/forum?id=11osftjEbF},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). How robust is your fairness? Evaluating and sustaining
fairness under unseen distribution shifts. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=11pGlecTz2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increasing concerns have been raised on deep learning fairness in recent years. Existing fairness-aware machine learning methods mainly focus on the fairness of in-distribution data. However, in real-world applications, it is common to have distribution shift between the training and test data. In this paper, we first show that the fairness achieved by existing methods can be easily broken by slight distribution shifts. To solve this problem, we propose a novel fairness learning method termed CUrvature MAtching (CUMA), which can achieve robust fairness generalizable to unseen domains with unknown distributional shifts. Specifically, CUMA enforces the model to have similar generalization ability on the majority and minority groups, by matching the loss curvature distributions of the two groups. We evaluate our method on three popular fairness datasets. Compared with existing methods, CUMA achieves superior fairness under unseen distribution shifts, without sacrificing either the overall accuracy or the in-distribution fairness.},
  archive      = {J_TMLR},
  author       = {Haotao Wang and Junyuan Hong and Jiayu Zhou and Zhangyang Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {How robust is your fairness? evaluating and sustaining fairness under unseen distribution shifts},
  url          = {https://openreview.net/forum?id=11pGlecTz2},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Better theory for SGD in the nonconvex world. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=AU4qHN2VkS">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale nonconvex optimization problems are ubiquitous in modern machine learning, and among practitioners interested in solving them, Stochastic Gradient Descent (SGD) reigns supreme. We revisit the analysis of SGD in the nonconvex setting and propose a new variant of the recently introduced \emph{expected smoothness} assumption which governs the behavior of the second moment of the stochastic gradient. We show that our assumption is both more general and more reasonable than assumptions made in all prior work. Moreover, our results yield the optimal $\mathcal{O}(\epsilon^{-4})$ rate for finding a stationary point of nonconvex smooth functions, and recover the optimal $\mathcal{O}(\epsilon^{-1})$ rate for finding a global solution if the Polyak-Łojasiewicz condition is satisfied. We compare against convergence rates under convexity and prove a theorem on the convergence of SGD under Quadratic Functional Growth and convexity, which might be of independent interest. Moreover, we perform our analysis in a framework which allows for a detailed study of the effects of a wide array of sampling strategies and minibatch sizes for finite-sum optimization problems. We corroborate our theoretical results with experiments on real and synthetic data.},
  archive      = {J_TMLR},
  author       = {Ahmed Khaled and Peter Richtárik},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Better theory for SGD in the nonconvex world},
  url          = {https://openreview.net/forum?id=AU4qHN2VkS},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning energy conserving dynamics efficiently with
hamiltonian gaussian processes. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=DHEZuKStzH">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hamiltonian mechanics is one of the cornerstones of the natural sciences. Recently there has been significant interest in learning Hamiltonian systems in a free-form way directly from trajectory data. Previous methods have tackled the problem of learning from many short, low-noise trajectories, but learning from a small number of long, noisy trajectories, whilst accounting for model uncertainty has not been addressed. In this work, we present a Gaussian process model for Hamiltonian systems with efficient decoupled parameterisation, and introduce an energy-conserving shooting method that allows robust inference from both short and long trajectories. We demonstrate the method&#39;s success in learning Hamiltonian systems in various data settings.},
  archive      = {J_TMLR},
  author       = {Magnus Ross and Markus Heinonen},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning energy conserving dynamics efficiently with hamiltonian gaussian processes},
  url          = {https://openreview.net/forum?id=DHEZuKStzH},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving nonconvex-nonconcave min-max problems exhibiting
weak minty solutions. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Gp0pHyUyrb">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate a structured class of nonconvex-nonconcave min-max problems exhibiting so-called \emph{weak Minty} solutions, a notion which was only recently introduced, but is able to simultaneously capture different generalizations of monotonicity. We prove novel convergence results for a generalized version of the optimistic gradient method (OGDA) in this setting, matching the $1/k$ rate for the best iterate in terms of the squared operator norm recently shown for the extragradient method (EG). In addition we propose an adaptive step size version of EG, which does not require knowledge of the problem parameters.},
  archive      = {J_TMLR},
  author       = {Axel Böhm},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Solving nonconvex-nonconcave min-max problems exhibiting weak minty solutions},
  url          = {https://openreview.net/forum?id=Gp0pHyUyrb},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantum policy iteration via amplitude estimation and grover
search – towards quantum advantage for reinforcement learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=HG11PAmwQ6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a full implementation and simulation of a novel quantum reinforcement learning method. Our work is a detailed and formal proof of concept for how quantum algorithms can be used to solve reinforcement learning problems and shows that, given access to error- free, efficient quantum realizations of the agent and environment, quantum methods can yield provable improvements over classical Monte-Carlo based methods in terms of sample complexity. Our approach shows in detail how to combine amplitude estimation and Grover search into a policy evaluation and improvement scheme. We first develop quantum policy evaluation (QPE) which is quadratically more efficient compared to an analogous classi- cal Monte Carlo estimation and is based on a quantum mechanical realization of a finite Markov decision process (MDP). Building on QPE, we derive a quantum policy iteration that repeatedly improves an initial policy using Grover search until the optimum is reached. Finally, we present an implementation of our algorithm for a two-armed bandit MDP which we then simulate.},
  archive      = {J_TMLR},
  author       = {Simon Wiedemann and Daniel Hein and Steffen Udluft and Christian B. Mendl},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Quantum policy iteration via amplitude estimation and grover search – towards quantum advantage for reinforcement learning},
  url          = {https://openreview.net/forum?id=HG11PAmwQ6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Black-box prompt learning for pre-trained language models.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=IvsGP7xRvm">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing scale of general-purpose Pre-trained Language Models (\textbf{PLMs}) necessitates the study of more efficient adaptation across different downstream tasks. In this paper, we establish a Black-box Discrete Prompt Learning (\textbf{BDPL}) to resonate with pragmatic interactions between the cloud infrastructure and edge devices. Particularly, instead of fine-tuning the model in the cloud, we adapt PLMs by prompt learning, which efficiently optimizes only a few parameters of the discrete prompts. Moreover, we consider the scenario that we do not have access to the parameters and gradients of the pre-trained models, except for its outputs given inputs. This black-box setting secures the cloud infrastructure from potential attack and misuse to cause a single-point failure, which is preferable to the white-box counterpart by current infrastructures. Under this black-box constraint, we apply a variance-reduced policy gradient algorithm to estimate the gradients of parameters in the categorical distribution of each discrete prompt. In light of our method, the user devices can efficiently tune their tasks by querying the PLMs bounded by a range of API calls. Our experiments on RoBERTa and GPT-3 demonstrate that the proposed algorithm achieves significant improvement on eight benchmarks in a cloud-device collaboration manner. Finally, we conduct in-depth case studies to comprehensively analyze our method in terms of various data sizes, prompt lengths, training budgets, optimization objectives, prompt transferability, and explanations of the learned prompts.},
  archive      = {J_TMLR},
  author       = {Shizhe Diao and Zhichao Huang and Ruijia Xu and Xuechun Li and LIN Yong and Xiao Zhou and Tong Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Black-box prompt learning for pre-trained language models},
  url          = {https://openreview.net/forum?id=IvsGP7xRvm},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PRUDEX-compass: Towards systematic evaluation of
reinforcement learning in financial markets. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=JjbsIYOuNi">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The financial markets, which involve more than $90 trillion market capitals, attract the attention of innumerable investors around the world. Recently, reinforcement learning in financial markets (FinRL) has emerged as a promising direction to train agents for making profitable investment decisions. However, the evaluation of most FinRL methods only focuses on profit-related measures and ignores many critical axes, which are far from satisfactory for financial practitioners to deploy these methods into real-world financial markets. Therefore, we introduce PRUDEX-Compass, which has 6 axes, i.e., Profitability, Risk-control, Universality, Diversity, rEliability, and eXplainability, with a total of 17 measures for a systematic evaluation. Specifically, i) we propose AlphaMix+ as a strong FinRL baseline, which leverages mixture-of-experts (MoE) and risk-sensitive approaches to make diversified risk-aware investment decisions, ii) we evaluate 8 FinRL methods in 4 long-term real-world datasets of influential financial markets to demonstrate the usage of our PRUDEX-Compass, iii) PRUDEX-Compass together with 4 real-world datasets, standard implementation of 8 FinRL methods and a portfolio management environment is released as public resources to facilitate the design and comparison of new FinRL methods. We hope that PRUDEX-Compass can not only shed light on future FinRL research to prevent untrustworthy results from stagnating FinRL into successful industry deployment but also provide a new challenging algorithm evaluation scenario for the reinforcement learning (RL) community.},
  archive      = {J_TMLR},
  author       = {Shuo Sun and Molei Qin and Xinrun Wang and Bo An},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {PRUDEX-compass: Towards systematic evaluation of reinforcement learning in financial markets},
  url          = {https://openreview.net/forum?id=JjbsIYOuNi},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bayesian optimization with informative covariance.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=JwgVBv18RG">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian optimization is a methodology for global optimization of unknown and expensive objectives. It combines a surrogate Bayesian regression model with an acquisition function to decide where to evaluate the objective. Typical regression models are given by Gaussian processes with stationary covariance functions. However, these functions are unable to express prior input-dependent information, including possible locations of the optimum. The ubiquity of stationary models has led to the common practice of exploiting prior information via informative mean functions. In this paper, we highlight that these models can perform poorly, especially in high dimensions. We propose novel informative covariance functions for optimization, leveraging nonstationarity to encode preferences for certain regions of the search space and adaptively promote local exploration during optimization. We demonstrate that the proposed functions can increase the sample efficiency of Bayesian optimization in high dimensions, even under weak prior information.},
  archive      = {J_TMLR},
  author       = {Afonso Eduardo and Michael U. Gutmann},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bayesian optimization with informative covariance},
  url          = {https://openreview.net/forum?id=JwgVBv18RG},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identification of negative transfers in multitask learning
using surrogate models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=KgfFAI9f3E">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multitask learning is widely used in practice to train a low-resource target task by augmenting it with multiple related source tasks. Yet, naively combining all the source tasks with a target task does not always improve the prediction performance for the target task due to negative transfers. Thus, a critical problem in multitask learning is identifying subsets of source tasks that would benefit the target task. This problem is computationally challenging since the number of subsets grows exponentially with the number of source tasks; efficient heuristics for subset selection does not always capture the relationship between task subsets and multitask learning performances. In this paper, we introduce an efficient procedure to address this problem via surrogate modeling. In surrogate modeling, we sample (random) subsets of source tasks and precompute their multitask learning performances; Then, we approximate the precomputed performances with a linear regression model that can also be used to predict the multitask performance of unseen task subsets. We show theoretically and empirically that fitting this model only requires sampling linearly many subsets in the number of source tasks. The fitted model provides a relevance score between each source task and the target task; We use the relevance scores to perform subset selection for multitask learning by thresholding. Through extensive experiments, we show that our approach predicts negative transfers from multiple source tasks to target tasks much more accurately than existing task affinity measures. Additionally, we demonstrate that for five weak supervision datasets, our approach consistently improves upon existing optimization methods for multi-task learning.},
  archive      = {J_TMLR},
  author       = {Dongyue Li and Huy Nguyen and Hongyang Ryan Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Identification of negative transfers in multitask learning using surrogate models},
  url          = {https://openreview.net/forum?id=KgfFAI9f3E},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalization bounds for kernel canonical correlation
analysis. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=KwWKB9Bqam">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of multiview representation learning using kernel canonical correlation analysis (KCCA) and establish non-asymptotic bounds on generalization error for regularized empirical risk minimization. In particular, we give fine-grained high-probability bounds on generalization error ranging from $O(n^{-1/6})$ to $O(n^{-1/5})$ depending on underlying distributional properties, where $n$ is the number of data samples. For the special case of finite-dimensional Hilbert spaces (such as linear CCA), our rates improve, ranging from $O(n^{-1/2})$ to $O(n^{-1})$. Finally, our results generalize to the problem of functional canonical correlation analysis over abstract Hilbert spaces.},
  archive      = {J_TMLR},
  author       = {Enayat Ullah and Raman Arora},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Generalization bounds for kernel canonical correlation analysis},
  url          = {https://openreview.net/forum?id=KwWKB9Bqam},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Temperature check: Theory and practice for training models
with softmax-cross-entropy losses. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=LBA2Jj5Gqn">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The softmax function combined with a cross-entropy loss is a principled approach to modeling probability distributions that has become ubiquitous in deep learning. The softmax function is defined by a lone hyperparameter, the temperature, that is commonly set to one or regarded as a way to tune model confidence after training; however, less is known about how the temperature impacts training dynamics or generalization performance. In this work we develop a theory of early learning for models trained with softmax-cross-entropy loss and show that the learning dynamics depend crucially on the inverse-temperature $\beta$ as well as the magnitude of the logits at initialization, $||\beta\textbf{z}||_{2}$. We follow up these analytic results with a large-scale empirical study of a variety of model architectures trained on CIFAR10, ImageNet, and IMDB sentiment analysis. We find that generalization performance depends strongly on the temperature, but only weakly on the initial logit magnitude. We provide evidence that the dependence of generalization on $\beta$ is not due to changes in model confidence, but is a dynamical phenomenon. It follows that the addition of $\beta$ as a tunable hyperparameter is key to maximizing model performance. Although we find the optimal $\beta$ to be sensitive to the architecture, experimental results suggest that tuning $\beta$ over the range $10^{-2}$ to $10^1$ improves performance over all architectures studied. We find that smaller $\beta$ may lead to better peak performance at the cost of sensitivity to the random seed.},
  archive      = {J_TMLR},
  author       = {Atish Agarwala and Samuel Stern Schoenholz and Jeffrey Pennington and Yann Dauphin},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Temperature check: Theory and practice for training models with softmax-cross-entropy losses},
  url          = {https://openreview.net/forum?id=LBA2Jj5Gqn},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parameter efficient node classification on homophilic
graphs. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=LIT8tjs6rJ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning on Graphs was recently made possible with the introduction of Graph Neural Networks (GNNs). GNNs use learnable diffusion processes to propagate information through the graph and improve performance on downstream tasks. However, learning this diffusion process can be expensive in terms of memory and computation. While a lot of research has gone into making these models more expressive and able to capture more complex patterns, in practice, edges in common benchmarking datasets often encode similarity of nodes with respect to the downstream task. This property is called homophily. We argue that for these homophilic graphs, learnable diffusion processes and large receptive fields are not required to achieve competitive performance. We propose Graph Non-Parametric Diffusion (GNPD) a method that outperforms traditional GNNs using only 2 linear models and non-parameteric diffusion. Our method takes ideas from Correct &amp; Smooth (C&amp;S) and the Scalable Inception Graph Network (SIGN) and combines them to create a simpler model that outperforms both of them on several datasets. Our method achieves an unmatched parameter efficiency, competing with models with two orders of magnitude more parameters. Additionally GNPD can also forego spectral embeddings which are the computational bottleneck of the C&amp;S method.},
  archive      = {J_TMLR},
  author       = {Lucas Prieto and Jeroen Den Boef and Paul Groth and Joran Cornelisse},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Parameter efficient node classification on homophilic graphs},
  url          = {https://openreview.net/forum?id=LIT8tjs6rJ},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving generalization with approximate factored value
functions. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=LwEWrrKyja">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning in general unstructured MDPs presents a challenging learning problem. However, certain MDP structures, such as factorization, are known to simplify the learning problem. This fact is often not useful in complex tasks with high-dimensional state spaces which do not usually exhibit such structure, and even if the structure is present, it is typically unknown. In this work, we instead turn this observation on its head. Instead of developing algorithms for structured MDPs, we propose a representation learning algorithm that approximates an unstructured MDP with one that has factorized structure. We then use these factors as a more convenient representation of the state for downstream learning. The particular structure that we leverage is reward factorization, which defines a more compact class of MDPs that admit factorized value functions. We empirically verify the effectiveness of our approach in terms of faster training (better sample complexity) and robust zero-shot transfer (better generalization) on the ProcGen benchmark and the MiniGrid environments.},
  archive      = {J_TMLR},
  author       = {Shagun Sodhani and Sergey Levine and Amy Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Improving generalization with approximate factored value functions},
  url          = {https://openreview.net/forum?id=LwEWrrKyja},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mixed effects in machine learning – a flexible mixedML
framework to add random effects to supervised machine learning
regression. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=MKZyHtmfwH">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustered data can frequently be found not only in social and behavioral sciences (e.g., multiple measurements of individuals) but also in typical machine learning problems (e.g., weather forecast in different cities, house prices in different regions). This implies dependencis for observations within one cluster, leading to violations of i.i.d. assumptions, biased estimates, and false inference. A typical approach to address this issue is to include random effects instead of fixed effects. We introduce the general mixedML framework, which includes random effects in supervised regression machine learning models, and present different estimation procedures. A segmentation of the problem allows to include random effects as an additional correction to the standard machine learning regression problem. Thus, the framework can be applied on top of the machine learning task, without the need to change the model or architecture, which distinguishes mixedML from other models in this field. With a simulation study and empirical data sets, we show that the framework produces comparable estimates to typical mixed effects frameworks in the linear case and increases the prediction quality and the gained information of the standard machine learning models in both the linear and non-linear case. Furthermore, the presented estimation procedures significantly decrease estimation time. Compared to other approaches in this area, the framework does not restrict the choice of machine learning algorithms and still includes random effects.},
  archive      = {J_TMLR},
  author       = {Pascal Kilian and Sangbeak Ye and Augustin Kelava},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Mixed effects in machine learning – a flexible mixedML framework to add random effects to supervised machine learning regression},
  url          = {https://openreview.net/forum?id=MKZyHtmfwH},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Leveraging demonstrations with latent space priors.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=OzGIu4T4Cz">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Demonstrations provide insight into relevant state or action space regions, bearing great potential to boost the efficiency and practicality of reinforcement learning agents. In this work, we propose to leverage demonstration datasets by combining skill learning and sequence modeling. Starting with a learned joint latent space, we separately train a generative model of demonstration sequences and an accompanying low-level policy. The sequence model forms a latent space prior over plausible demonstration behaviors to accelerate learning of high-level policies. We show how to acquire such priors from state-only motion capture demonstrations and explore several methods for integrating them into policy learning on transfer tasks. Our experimental results confirm that latent space priors provide significant gains in learning speed and final performance. We benchmark our approach on a set of challenging sparse-reward environments with a complex, simulated humanoid, and on offline RL benchmarks for navigation and object manipulation.},
  archive      = {J_TMLR},
  author       = {Jonas Gehring and Deepak Gopinath and Jungdam Won and Andreas Krause and Gabriel Synnaeve and Nicolas Usunier},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Leveraging demonstrations with latent space priors},
  url          = {https://openreview.net/forum?id=OzGIu4T4Cz},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-objective bayesian optimization with heuristic
objectives for biomedical and molecular data analysis workflows.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=QspAcsAyis">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many practical applications require optimization of multiple, computationally expensive, and possibly competing objectives that are well-suited for multi-objective Bayesian optimization (MOBO). However, for many types of biomedical data, measures of data analysis workflow success are often heuristic and therefore it is not known a priori which objectives are useful. Thus, MOBO methods that return the full Pareto front may be suboptimal in these cases. Here we propose a novel MOBO method that adaptively updates the scalarization function using properties of the posterior of a multi-output Gaussian process surrogate function. This approach selects useful objectives based on a flexible set of desirable criteria, allowing the functional form of each objective to guide optimization. We demonstrate the qualitative behaviour of our method on toy data and perform proof-of-concept analyses of single-cell RNA sequencing and highly multiplexed imaging datasets for univariate input optimization.},
  archive      = {J_TMLR},
  author       = {Alina Selega and Kieran R. Campbell},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Multi-objective bayesian optimization with heuristic objectives for biomedical and molecular data analysis workflows},
  url          = {https://openreview.net/forum?id=QspAcsAyis},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fusion of global and local knowledge for personalized
federated learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=QtrjqVIZna">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized federated learning, as a variant of federated learning, trains customized models for clients using their heterogeneously distributed data. However, it is still inconclusive about how to design personalized models with better representation of shared global knowledge and personalized pattern. To bridge the gap, we in this paper explore personalized models with low-rank and sparse decomposition. Specifically, we employ proper regularization to  extract a low-rank global knowledge representation (GKR), so as to distill global knowledge into a compact representation. Subsequently, we employ a sparse component over the obtained GKR to fuse the personalized pattern into the global knowledge. As a solution, we propose a two-stage proximal-based algorithm named \textbf{Fed}erated learning with mixed \textbf{S}parse and \textbf{L}ow-\textbf{R}ank representation (FedSLR) to efficiently search for the mixed models. Theoretically, under proper assumptions, we show that the GKR trained by FedSLR can at least sub-linearly converge to a stationary point of the regularized problem, and that the sparse component being fused can converge to its stationary point under proper settings. Extensive experiments also demonstrate the superior empirical performance of FedSLR. Moreover, FedSLR reduces the number of parameters, and lowers the down-link communication complexity, which are all desirable for federated learning algorithms. Source code is available in \url{https://github.com/huangtiansheng/fedslr}.},
  archive      = {J_TMLR},
  author       = {Tiansheng Huang and Li Shen and Yan Sun and Weiwei Lin and Dacheng Tao},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Fusion of global and local knowledge for personalized federated learning},
  url          = {https://openreview.net/forum?id=QtrjqVIZna},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved overparametrization bounds for global convergence
of SGD for shallow neural networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=RjZq6W6FoE">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the overparametrization bounds required for the global convergence of stochastic gradient descent algorithm for a class of one hidden layer feed-forward neural networks equipped with ReLU activation function. We improve the existing state-of-the-art results in terms of the required hidden layer width. We introduce a new proof technique combining nonlinear analysis with properties of random initializations of the network.},
  archive      = {J_TMLR},
  author       = {Bartłomiej Polaczyk and Jacek Cyranka},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Improved overparametrization bounds for global convergence of SGD for shallow neural networks},
  url          = {https://openreview.net/forum?id=RjZq6W6FoE},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FLUID: A unified evaluation framework for flexible
sequential data. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=UvJBKWaSSH">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern machine learning methods excel when training data is IID, large-scale, and well labeled. Learning in less ideal conditions remains an open challenge. The sub-fields of few-shot, continual, transfer, and representation learning have made substantial strides in learning under adverse conditions, each affording distinct advantages through methods and insights. These methods address different challenges such as data arriving sequentially or scarce training examples, however often the difficult conditions an ML system will face over its lifetime cannot be anticipated prior to deployment. Therefore, general ML systems which can handle the many challenges of learning in practical settings are needed. To foster research towards the goal of general ML methods, we introduce a new unified evaluation framework – FLUID (Flexible Sequential Data). FLUID integrates the objectives of few-shot, continual, transfer, and representation learning while enabling comparison and integration of techniques across these subfields. In FLUID, a learner faces a stream of data and must make sequential predictions while choosing how to update itself, adapt quickly to novel classes, and deal with changing data distributions; while accounting for the total amount of compute. We conduct experiments on a broad set of methods which shed new insight on the advantages and limitations of current techniques and indicate new research problems to solve. As a starting point towards more general methods, we present two new baselines which outperform other evaluated methods on FLUID.},
  archive      = {J_TMLR},
  author       = {Matthew Wallingford and Aditya Kusupati and Keivan Alizadeh-Vahid and Aaron Walsman and Aniruddha Kembhavi and Ali Farhadi},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FLUID: A unified evaluation framework for flexible sequential data},
  url          = {https://openreview.net/forum?id=UvJBKWaSSH},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bidirectional view based consistency regularization for
semi-supervised domain adaptation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=WVwnccBJLz">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distinguished from unsupervised domain adaptation (UDA), semi-supervised domain adaptation (SSDA) could access a few labeled target samples during learning additionally. Although achieving remarkable progress, target supervised information is easily overwhelmed by massive source supervised information, as there are many more labeled source samples than those in the target domain. In this work, we propose a novel method BVCR that better utilizes the supervised information by three schemes, i.e., modeling, exploration, and interaction. In the modeling scheme, BVCR models the source supervision and target supervision separately to avoid target supervised information being overwhelmed by source supervised information and better utilize the target supervision. Besides, as both supervised information naturally offer distinct views for the target domain, the exploration scheme performs intra-domain consistency regularization to better explore target information with bidirectional views. Moreover, as both views are complementary to each other, the interaction scheme introduces inter-domain consistency regularization to activate information interaction bidirectionally. Thus, the proposed method is elegantly symmetrical by design and easy to implement. Extensive experiments are conducted, and the results show the effectiveness of the proposed method.},
  archive      = {J_TMLR},
  author       = {Yuntao Du and 娟 江 and Hongtao Luo and Haiyang Yang and MingCai Chen and Chongjun Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bidirectional view based consistency regularization for semi-supervised domain adaptation},
  url          = {https://openreview.net/forum?id=WVwnccBJLz},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A halfspace-mass depth-based method for adversarial attack
detection. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=YtU0nDb5e8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the widespread use of deep learning algorithms, vulnerability to adversarial attacks is still an issue limiting their use in critical applications. Detecting these attacks is thus crucial to build reliable algorithms and has received increasing attention in the last few years. In this paper, we introduce the HalfspAce Mass dePth dEtectoR (HAMPER), a new method to detect adversarial examples by leveraging the concept of data depths, a statistical notion that provides center-outward ordering of points with respect to (w.r.t.) a probability distribution. In particular, the halfspace-mass (HM) depth exhibits attractive properties such as computational efficiency, which makes it a natural candidate for adversarial attack detection in high-dimensional spaces. Additionally, HM is non differentiable making it harder for attackers to directly attack HAMPER via gradient based-methods. We evaluate HAMPER in the context of supervised adversarial attacks detection across four benchmark datasets. Overall, we empirically show that HAMPER consistently outperforms SOTA methods. In particular, the gains are 13.1% (29.0%) in terms of AUROC (resp. FPR) on SVHN, 14.6% (25.7%) on CIFAR10 and 22.6% (49.0%) on CIFAR100 compared to the best performing method.},
  archive      = {J_TMLR},
  author       = {Marine Picot and Federica Granese and Guillaume Staerman and Marco Romanelli and Francisco Messina and Pablo Piantanida and Pierre Colombo},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A halfspace-mass depth-based method for adversarial attack detection},
  url          = {https://openreview.net/forum?id=YtU0nDb5e8},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Image compression with product quantized masked image
modeling. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Z2L5d9ay4B">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent neural compression methods have been based on the popular hyperprior framework. It relies on Scalar Quantization and offers a very strong compression performance. This contrasts from recent advances in image generation and representation learning, where Vector Quantization is more commonly employed. In this work, we attempt to bring these lines of research closer by revisiting vector quantization for image compression. We build upon the VQ-VAE framework and introduce several modifications. First, we replace the vanilla vector quantizer by a product quantizer. This intermediate solution between vector and scalar quantization allows for a much wider set of rate-distortion points: It implicitly defines high-quality quantizers that would otherwise require intractably large codebooks. Second, inspired by the success of Masked Image Modeling (MIM) in the context of self-supervised learning and generative image models, we propose a novel conditional entropy model which improves entropy coding by modelling the co-dependencies of the quantized latent codes. The resulting PQ-MIM model is surprisingly effective: its compression performance on par with recent hyperprior methods. It also outperforms HiFiC in terms of FID and KID metrics when optimized with perceptual losses (e.g. adversarial). Finally, since PQ-MIM is compatible with image generation frameworks, we show qualitatively that it can operate under a hybrid mode between compression and generation, with no further training or finetuning. As a result, we explore the extreme compression regime where an image is compressed into 200 bytes, i.e., less than a tweet.},
  archive      = {J_TMLR},
  author       = {Alaaeldin El-Nouby and Matthew J. Muckley and Karen Ullrich and Ivan Laptev and Jakob Verbeek and Herve Jegou},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Image compression with product quantized masked image modeling},
  url          = {https://openreview.net/forum?id=Z2L5d9ay4B},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The low-rank simplicity bias in deep networks.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=bCiNWDmlY2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern deep neural networks are highly over-parameterized compared to the data on which they are trained, yet they often generalize remarkably well. A flurry of recent work has asked: why do deep networks not overfit to their training data? In this work, we make a series of empirical observations that investigate and extend the hypothesis that deeper networks are inductively biased to find solutions with lower effective rank embeddings. We conjecture that this bias exists because the volume of functions that maps to low effective rank embedding increases with depth. We show empirically that our claim holds true on finite width linear and non-linear models on practical learning paradigms and show that on natural data, these are often the solutions that generalize well. We then show that the simplicity bias exists at both initialization and after training and is resilient to hyper-parameters and learning methods. We further demonstrate how linear over-parameterization of deep non-linear models can be used to induce low-rank bias, improving generalization performance on CIFAR and ImageNet without changing the modeling capacity.},
  archive      = {J_TMLR},
  author       = {Minyoung Huh and Hossein Mobahi and Richard Zhang and Brian Cheung and Pulkit Agrawal and Phillip Isola},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The low-rank simplicity bias in deep networks},
  url          = {https://openreview.net/forum?id=bCiNWDmlY2},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transductive decoupled variational inference for few-shot
classification. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=bomdTc9HyL">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The versatility to learn from a handful of samples is the hallmark of human intelligence. Few-shot learning is an endeavour to transcend this capability down to machines. Inspired by the promise and power of probabilistic deep learning, we propose a novel variational inference network for few-shot classification (coined as TRIDENT) to decouple the representation of an image into semantic and label latent variables, and simultaneously infer them in an intertwined fashion. To induce task-awareness, as part of the inference mechanics of TRIDENT, we exploit information across both query and support images of a few-shot task using a novel built-in attention-based transductive feature extraction module (we call AttFEX). Our extensive experimental results corroborate the efficacy of TRIDENT and demonstrate that, using the simplest of backbones, it sets a new state-of-the-art in the most commonly adopted datasets miniImageNet and tieredImageNet (offering up to 4% and 5% improvements, respectively), as well as for the recent challenging cross-domain miniImagenet --&gt; CUB scenario offering a significant margin (up to 20% improvement) beyond the best existing baselines.},
  archive      = {J_TMLR},
  author       = {Anuj Rajeeva Singh and Hadi Jamali-Rad},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Transductive decoupled variational inference for few-shot classification},
  url          = {https://openreview.net/forum?id=bomdTc9HyL},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cheap and deterministic inference for deep state-space
models of interacting dynamical systems. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=dqgdBy4Uv5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks are often used to model interacting dynamical systems since they gracefully scale to systems with a varying and high number of agents. While there has been much progress made for deterministic interacting systems, modeling is much more challenging for stochastic systems in which one is interested in obtaining a predictive distribution over future trajectories. Existing methods are either computationally slow since they rely on Monte Carlo sampling or make simplifying assumptions such that the predictive distribution is unimodal. In this work, we present a deep state-space model which employs graph neural networks in order to model the underlying interacting dynamical system. The predictive distribution is multimodal and has the form of a Gaussian mixture model, where the moments of the Gaussian components can be computed via deterministic moment matching rules. Our moment matching scheme can be exploited for sample-free inference leading to more efficient and stable training compared to Monte Carlo alternatives. Furthermore, we propose structured approximations to the covariance matrices of the Gaussian components in order to scale up to systems with many agents. We benchmark our novel framework on two challenging autonomous driving datasets. Both confirm the benefits of our method compared to state-of-the-art methods. We further demonstrate the usefulness of our individual contributions in a carefully designed ablation study and provide a detailed empirical runtime analysis of our proposed covariance approximations.},
  archive      = {J_TMLR},
  author       = {Andreas Look and Barbara Rakitsch and Melih Kandemir and Jan Peters},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Cheap and deterministic inference for deep state-space models of interacting dynamical systems},
  url          = {https://openreview.net/forum?id=dqgdBy4Uv5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Probing predictions on OOD images via nearest categories.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=fTNorIvVXG">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study out-of-distribution (OOD) prediction behavior of neural networks when they classify images from unseen classes or corrupted images. To probe the OOD behavior, we introduce a new measure, nearest category generalization (NCG), where we compute the fraction of OOD inputs that are classified with the same label as their nearest neighbor in the training set. Our motivation stems from understanding the prediction patterns of adversarially robust networks, since previous work has identified unexpected consequences of training to be robust to norm-bounded perturbations. We find that robust networks have consistently higher NCG accuracy than natural training, even when the OOD data is much farther away than the robustness radius. This implies that the local regularization of robust training has a significant impact on the network’s decision regions. We replicate our findings using many datasets, comparing new and existing training methods. Overall, adversarially robust networks resemble a nearest neighbor classifier when it comes to OOD data.},
  archive      = {J_TMLR},
  author       = {Yao-Yuan Yang and Cyrus Rashtchian and Ruslan Salakhutdinov and Kamalika Chaudhuri},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Probing predictions on OOD images via nearest categories},
  url          = {https://openreview.net/forum?id=fTNorIvVXG},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Defense against reward poisoning attacks in reinforcement
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=goPsLn3RVo">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study defense strategies against reward poisoning attacks in reinforcement learning. As a threat model, we consider cost-effective targeted attacks---these attacks minimally alter rewards to make the attacker&#39;s target policy uniquely optimal under the poisoned rewards, with the optimality gap specified by an attack parameter. Our goal is to design agents that are robust against such attacks in terms of the worst-case utility w.r.t. the true, unpoisoned, rewards while computing their policies under the poisoned rewards. We propose an optimization framework for deriving optimal defense policies, both when the attack parameter is known and unknown. For this optimization framework, we first provide characterization results for generic attack cost functions. These results show that the functional form of the attack cost function and the agent&#39;s knowledge about it are critical for establishing lower bounds on the agent&#39;s performance, as well as for the computational tractability of the defense problem. We then focus on a cost function based on $\ell_2$ norm, for which we show that the defense problem can be efficiently solved and yields defense policies whose expected returns under the true rewards are lower bounded by their expected returns under the poison rewards. Using simulation-based experiments, we demonstrate the effectiveness and robustness of our defense approach.},
  archive      = {J_TMLR},
  author       = {Kiarash Banihashem and Adish Singla and Goran Radanovic},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Defense against reward poisoning attacks in reinforcement learning},
  url          = {https://openreview.net/forum?id=goPsLn3RVo},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning identity-preserving transformations on data
manifolds. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=gyhiZYrk5y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many machine learning techniques incorporate identity-preserving transformations into their models to generalize their performance to previously unseen data. These transformations are typically selected from a set of functions that are known to maintain the identity of an input when applied (e.g., rotation, translation, flipping, and scaling). However, there are many natural variations that cannot be labeled for supervision or defined through examination of the data. As suggested by the manifold hypothesis, many of these natural variations live on or near a low-dimensional, nonlinear manifold. Several techniques represent manifold variations through a set of learned Lie group operators that define directions of motion on the manifold. However, these approaches are limited because they require transformation labels when training their models and they lack a method for determining which regions of the manifold are appropriate for applying each specific operator. We address these limitations by introducing a learning strategy that does not require transformation labels and developing a method that learns the local regions where each operator is likely to be used while preserving the identity of inputs. Experiments on MNIST and Fashion MNIST highlight our model&#39;s ability to learn identity-preserving transformations on multi-class datasets. Additionally, we train on CelebA to showcase our model&#39;s ability to learn semantically meaningful transformations on complex datasets in an unsupervised manner.},
  archive      = {J_TMLR},
  author       = {Marissa Catherine Connor and Kion Fallah and Christopher John Rozell},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning identity-preserving transformations on data manifolds},
  url          = {https://openreview.net/forum?id=gyhiZYrk5y},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph neural networks designed for different graph types: A
survey. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=h4BYtZ79uy">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs are ubiquitous in nature and can therefore serve as models for many practical but also theoretical problems. For this purpose, they can be defined as many different types which suitably reflect the individual contexts of the represented problem. To address cutting-edge problems based on graph data, the research field of Graph Neural Networks (GNNs) has emerged. Despite the field’s youth and the speed at which new models are developed, many recent surveys have been published to keep track of them. Nevertheless, it has not yet been gathered which GNN can process what kind of graph types. In this survey, we give a detailed overview of already existing GNNs and, unlike previous surveys, categorize them according to their ability to handle different graph types and properties. We consider GNNs operating on static and dynamic graphs of different structural constitutions, with or without node or edge attributes. Moreover, we distinguish between GNN models for discrete-time or continuous-time dynamic graphs and group the models according to their architecture. We find that there are still graph types that are not or only rarely covered by existing GNN models. We point out where models are missing and give potential reasons for their absence.},
  archive      = {J_TMLR},
  author       = {Josephine Thomas and Alice Moallemy-Oureh and Silvia Beddar-Wiesing and Clara Holzhüter},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Graph neural networks designed for different graph types: A survey},
  url          = {https://openreview.net/forum?id=h4BYtZ79uy},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continual learning by modeling intra-class variation.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=iDxfGaMYVr">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been observed that neural networks perform poorly when the data or tasks are presented sequentially. Unlike humans, neural networks suffer greatly from catastrophic forgetting, making it impossible to perform life-long learning. To address this issue, memory-based continual learning has been actively studied and stands out as one of the best-performing methods. We examine memory-based continual learning and identify that large variation in the representation space is crucial for avoiding catastrophic forgetting. Motivated by this, we propose to diversify representations by using two types of perturbations: model-agnostic variation (i.e., the variation is generated without the knowledge of the learned neural network) and model-based variation (i.e., the variation is conditioned on the learned neural network). We demonstrate that enlarging representational variation serves as a general principle to improve continual learning. Finally, we perform empirical studies which demonstrate that our method, as a simple plug-and-play component, can consistently improve a number of memory-based continual learning methods by a large margin.},
  archive      = {J_TMLR},
  author       = {Longhui Yu and Tianyang Hu and Lanqing HONG and Zhen Liu and Adrian Weller and Weiyang Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Continual learning by modeling intra-class variation},
  url          = {https://openreview.net/forum?id=iDxfGaMYVr},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving a special type of optimal transport problem by a
modified hungarian algorithm. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=k5m8xXTOrC">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computing the empirical Wasserstein distance in the Wasserstein-distance-based independence test is an optimal transport (OT) problem with a special structure. This observation inspires us to study a special type of OT problem and propose {\it a modified Hungarian algorithm} to solve it {\it exactly}. For the OT problem involving two marginals with $m$ and $n$ atoms ($m\geq n$), respectively, the computational complexity of the proposed algorithm is $\mathcal{O}(m^2n)$. Computing the empirical Wasserstein distance in the independence test requires solving this special type of OT problem, where $m=n^2$. The associated computational complexity of the proposed algorithm is $\mathcal{O}(n^5)$, while the order of applying the classic Hungarian algorithm is $\mathcal{O}(n^6)$. In addition to the aforementioned special type of OT problem, it is shown that the modified Hungarian algorithm could be adopted to solve a wider range of OT problems. Broader applications of the proposed algorithm are discussed---solving the one-to-many assignment problem and the many-to-many assignment problem. We conduct numerical experiments to validate our theoretical results. The experiment results demonstrate that the proposed modified Hungarian algorithm compares favorably with the Hungarian algorithm and the well-known Sinkhorn algorithm, and the network simplex algorithm.},
  archive      = {J_TMLR},
  author       = {Yiling Xie and Yiling Luo and Xiaoming Huo},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Solving a special type of optimal transport problem by a modified hungarian algorithm},
  url          = {https://openreview.net/forum?id=k5m8xXTOrC},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transfer entropy bottleneck: Learning sequence to sequence
information transfer. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=kJcwlP7BRs">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When presented with a data stream of two statistically dependent variables, predicting the future of one of the variables (the target stream) can benefit from information about both its history and the history of the other variable (the source stream). For example, fluctuations in temperature at a weather station can be predicted using both temperatures and barometric readings. However, a challenge when modelling such data is that it is easy for a neural network to rely on the greatest joint correlations within the target stream, which may ignore a crucial but small information transfer from the source to the target stream. As well, there are often situations where the target stream may have previously been modelled independently and it would be useful to use that model to inform a new joint model. Here, we develop an information bottleneck approach for conditional learning on two dependent streams of data. Our method, which we call Transfer Entropy Bottleneck (TEB), allows one to learn a model that bottlenecks the directed information transferred from the source variable to the target variable, while quantifying this information transfer within the model. As such, TEB provides a useful new information bottleneck approach for modelling two statistically dependent streams of data in order to make predictions about one of them.},
  archive      = {J_TMLR},
  author       = {Damjan Kalajdzievski and Ximeng Mao and Pascal Fortier-Poisson and Guillaume Lajoie and Blake Aaron Richards},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Transfer entropy bottleneck: Learning sequence to sequence information transfer},
  url          = {https://openreview.net/forum?id=kJcwlP7BRs},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reusable options through gradient-based meta learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=qdDmxzGuzu">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical methods in reinforcement learning have the potential to reduce the amount of decisions that the agent needs to perform when learning new tasks. However, finding a reusable useful temporal abstractions that facilitate fast learning remains a challenging problem. Recently, several deep learning approaches were proposed to learn such temporal abstractions in the form of options in an end-to-end manner. In this work, we point out several shortcomings of these methods and discuss their potential negative consequences. Subsequently, we formulate the desiderata for reusable options and use these to frame the problem of learning options as a gradient-based meta-learning problem. This allows us to formulate an objective that explicitly incentivizes options which allow a higher-level decision maker to adjust in few steps to different tasks. Experimentally, we show that our method is able to learn transferable components which accelerate learning and performs better than existing prior methods developed for this setting. Additionally, we perform ablations to quantify the impact of using gradient-based meta-learning as well as other proposed changes.},
  archive      = {J_TMLR},
  author       = {David Kuric and Herke van Hoof},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reusable options through gradient-based meta learning},
  url          = {https://openreview.net/forum?id=qdDmxzGuzu},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Containing a spread through sequential learning: To exploit
or to explore? <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=qvRWcDXBam">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spread of an undesirable contact process, such as an infectious disease (e.g. COVID-19), is contained through testing and isolation of infected nodes. The temporal and spatial evolution of the process (along with containment through isolation) render such detection as fundamentally different from active search detection strategies. In this work, through an active learning approach, we design testing and isolation strategies to contain the spread and minimize the cumulative infections under a given test budget. We prove that the objective can be optimized, with performance guarantees, by greedily selecting the nodes to test. We further design reward-based methodologies that effectively minimize an upper bound on the cumulative infections and are computationally more tractable in large networks. These policies, however, need knowledge about the nodes&#39; infection probabilities which are dynamically changing and have to be learned by sequential testing. We develop a message-passing framework for this purpose and, building on that, show novel tradeoffs between exploitation of knowledge through reward-based heuristics and exploration of the unknown through a carefully designed probabilistic testing. The tradeoffs are fundamentally distinct from the classical counterparts under active search or multi-armed bandit problems (MABs). We provably show the necessity of exploration in a stylized network and show through simulations that exploration can outperform exploitation in various synthetic and real-data networks depending on the parameters of the network and the spread.},
  archive      = {J_TMLR},
  author       = {Xingran Chen and Hesam Nikpey and Jungyeol Kim and Saswati Sarkar and Shirin Saeedi Bidokhti},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Containing a spread through sequential learning: To exploit or to explore?},
  url          = {https://openreview.net/forum?id=qvRWcDXBam},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Patches are all you need? <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=rAnB7JSMXL">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although convolutional neural networks have been the dominant architecture for computer vision for many years, Vision Transformers (ViTs) have recently shown promise as an alternative. Subsequently, many new models have been proposed which replace the self-attention layer within the ViT architecture with novel operations (such as MLPs), all of which have also been relatively performant. We note that these architectures all share a common component--the patch embedding layer--which enables the use of a simple isotropic template with alternating steps of channel- and spatial-dimension mixing. This raises a question: is the success of ViT-style models due to novel, highly-expressive operations like self-attention, or is it at least in part due to using patches? In this paper, we present some evidence for the latter: specifically, we propose the ConvMixer, an extremely simple and parameter-efficient fully-convolutional model in which we replace the self-attention and MLP layers within the ViT with less-expressive depthwise and pointwise convolutional layers, respectively. Despite its unusual simplicity, ConvMixer outperforms the ViT, MLP-Mixer, and their variants for similar data set sizes and parameter counts, in addition to outperforming classical vision models like ResNet. We argue that this contributes to the evidence that patches are sufficient for designing simple and effective vision models. Our code is available at https://github.com/locuslab/convmixer.},
  archive      = {J_TMLR},
  author       = {Asher Trockman and J Zico Kolter},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Patches are all you need?},
  url          = {https://openreview.net/forum?id=rAnB7JSMXL},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing diffusion-based image synthesis with robust
classifier guidance. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=tEVpz2xJWX">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Denoising diffusion probabilistic models (DDPMs) are a recent family of generative models that achieve state-of-the-art results. In order to obtain class-conditional generation, it was suggested to guide the diffusion process by gradients from a time-dependent classifier. While the idea is theoretically sound, deep learning-based classifiers are infamously susceptible to gradient-based adversarial attacks. Therefore, while traditional classifiers may achieve good accuracy scores, their gradients are possibly unreliable and might hinder the improvement of the generation results. Recent work discovered that adversarially robust classifiers exhibit gradients that are aligned with human perception, and these could better guide a generative process towards semantically meaningful images. We utilize this observation by defining and training a time-dependent adversarially robust classifier and use it as guidance for a generative diffusion model. In experiments on the highly challenging and diverse ImageNet dataset, our scheme introduces significantly more intelligible intermediate gradients, better alignment with theoretical findings, as well as improved generation results under several evaluation metrics. Furthermore, we conduct an opinion survey whose findings indicate that human raters prefer our method&#39;s results.},
  archive      = {J_TMLR},
  author       = {Bahjat Kawar and Roy Ganz and Michael Elad},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Enhancing diffusion-based image synthesis with robust classifier guidance},
  url          = {https://openreview.net/forum?id=tEVpz2xJWX},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Costs and benefits of fair regression. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=v6anjyEDVW">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world applications of machine learning tools in high-stakes domains are often regulated to be fair, in the sense that the predicted target should satisfy some quantitative notion of parity with respect to a protected attribute. However, the exact tradeoff between fairness and accuracy with a real-valued target is not entirely clear. In this paper, we characterize the inherent tradeoff between statistical parity and accuracy in the regression setting by providing a lower bound on the error of any attribute-blind fair regressor. Our lower bound is sharp, algorithm-independent, and admits a simple interpretation: when the moments of the target differ between groups, any fair algorithm has to make an error on at least one of the groups. We further extend this result to give a lower bound on the joint error of any (approximately) fair algorithm, using the Wasserstein distance to measure the quality of the approximation. With our novel lower bound, we also show that the price paid by a fair regressor that does not take the protected attribute as input is less than that of a fair regressor with explicit access to the protected attribute. On the upside, we establish the first connection between individual fairness, accuracy parity, and the Wasserstein distance by showing that if a regressor is individually fair, it also approximately verifies the accuracy parity, where the gap is again given by the Wasserstein distance between the two groups. Inspired by our theoretical results, we develop a practical algorithm for fair regression through the lens of representation learning, and conduct experiments on a real-world dataset to corroborate our findings.},
  archive      = {J_TMLR},
  author       = {Han Zhao},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Costs and benefits of fair regression},
  url          = {https://openreview.net/forum?id=v6anjyEDVW},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A unified view of masked image modeling. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=wmGlMhaBe0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Masked image modeling has demonstrated great potential to eliminate the label-hungry problem of training large-scale vision Transformers, achieving impressive performance on various downstream tasks. In this work, we propose a unified view of masked image modeling after revisiting existing methods. Under the unified view, we introduce a simple yet effective method, termed as MaskDistill, which reconstructs normalized semantic features from teacher models at the masked positions, conditioning on corrupted input images. Experimental results on image classification and semantic segmentation show that MaskDistill achieves comparable or superior performance than state-of-the-art methods. When using the huge vision Transformer and pretraining 300 epochs, MaskDistill obtains 88.3% fine-tuning top-1 accuracy on ImageNet-1k (224 size) and 58.8 semantic segmentation mIoU metric on ADE20k (512 size). Code is enclosed in the supplementary materials.},
  archive      = {J_TMLR},
  author       = {Zhiliang Peng and Li Dong and Hangbo Bao and Furu Wei and Qixiang Ye},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A unified view of masked image modeling},
  url          = {https://openreview.net/forum?id=wmGlMhaBe0},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards better out-of-distribution generalization of neural
algorithmic reasoning tasks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=xkrtvHlp3P">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the OOD generalization of neural algorithmic reasoning tasks, where the goal is to learn an algorithm (e.g., sorting, breadth-first search, and depth-first search) from input-output pairs using deep neural networks. First, we argue that OOD generalization in this setting is significantly different than common OOD settings. For example, some phenomena in OOD generalization of image classifications such as \emph{accuracy on the line} are not observed here, and techniques such as data augmentation methods do not help as assumptions underlying many augmentation techniques are often violated. Second, we analyze the main challenges (e.g., input distribution shift, non-representative data generation, and uninformative validation metrics) of the current leading benchmark, i.e., CLRS \citep{deepmind2021clrs}, which contains 30 algorithmic reasoning tasks. We propose several solutions, including a simple-yet-effective fix to the input distribution shift and improved data generation. Finally, we propose an attention-based 2WL-graph neural network (GNN) processor which complements message-passing GNNs so their combination outperforms the state-of-the-art model by a $3\%$ margin averaged over all algorithms.},
  archive      = {J_TMLR},
  author       = {Sadegh Mahdavi and Kevin Swersky and Thomas Kipf and Milad Hashemi and Christos Thrampoulidis and Renjie Liao},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards better out-of-distribution generalization of neural algorithmic reasoning tasks},
  url          = {https://openreview.net/forum?id=xkrtvHlp3P},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Action poisoning attacks on linear contextual bandits.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=yhGCKUsKJS">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contextual bandit algorithms have many applicants in a variety of scenarios. In order to develop trustworthy contextual bandit systems, understanding the impacts of various adversarial attacks on contextual bandit algorithms is essential. In this paper, we propose a new class of attacks: action poisoning attacks, where an adversary can change the action signal selected by the agent. We design action poisoning attack schemes against disjoint linear contextual bandit algorithms in both white-box and black-box settings. We further analyze the cost of the proposed attack strategies for a very popular and widely used bandit algorithm: LinUCB. We show that, in both white-box and black-box settings, the proposed attack schemes can force the LinUCB agent to pull a target arm very frequently by spending only logarithm cost. We also extend the proposed attack strategies to generalized linear models and show the effectiveness of the proposed strategies.},
  archive      = {J_TMLR},
  author       = {Guanlin Liu and Lifeng Lai},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Action poisoning attacks on linear contextual bandits},
  url          = {https://openreview.net/forum?id=yhGCKUsKJS},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Understanding and simplifying architecture search in
spatio-temporal graph neural networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=4jEuiMPKSF">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compiling together spatial and temporal modules via a unified framework, Spatio-Temporal Graph Neural Networks (STGNNs) have been popularly used in the multivariate spatio-temporal forecasting task, e.g. traffic prediction. After the numerous propositions of manually designed architectures, researchers show interest in the Neural Architecture Search (NAS) of STGNNs. Existing methods suffer from two issues: (1) hyperparameters like learning rate, channel size cannot be integrated into the NAS framework, which makes the model evaluation less accurate, potentially misleading the architecture search (2) the current search space, which basically mimics Darts-like methods, is too large for the search algorithm to find a sufficiently good candidate. In this work, we deal with both issues at the same time. We first re-examine the importance and transferability of the training hyperparameters to ensure a fair and fast comparison. Next, we set up a framework that disentangles architecture design into three disjoint angles according to how spatio-temporal representations flow and transform in architectures, which allows us to understand the behavior of architectures from a distributional perspective. This way, we can obtain good guidelines to reduce the STGNN search space and find state-of-the-art architectures by simple random search. As an illustrative example, we combine these principles with random search which already significantly outperforms both state-of-the-art hand-designed models and recently automatically searched ones.},
  archive      = {J_TMLR},
  author       = {Zhen Xu and quanming yao and Yong Li and Qiang Yang},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Understanding and simplifying architecture search in spatio-temporal graph neural networks},
  url          = {https://openreview.net/forum?id=4jEuiMPKSF},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). KRADA: Known-region-aware domain alignment for open-set
domain adaptation in semantic segmentation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=5II12ypVQo">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In semantic segmentation, we aim to train a pixel-level classifier to assign category labels to all pixels in an image, where labeled training images and unlabeled test images are from the same distribution and share the same label set. However, in an open world, the unlabeled test images probably contain unknown categories and have different distributions from the labeled images. Hence, in this paper, we consider a new, more realistic, and more challenging problem setting where the pixel-level classifier has to be trained with labeled images and unlabeled open-world images—we name it open world semantic segmentation (OSS). In OSS, the trained classifier is expected to identify unknown-class pixels and classify known-class pixels well. To solve OSS, we first investigate which distribution that unknown-class pixels obey. Then, motivated by the goodness-of-fit test, we use statistical measurements to show how a pixel fits the distribution of an unknown class and select highly-fitted pixels to form the unknown region in each test image. Eventually, we propose an end-to-end learning framework, known-region-aware domain alignment (KRADA), to distinguish unknown classes while aligning the distributions of known classes in labeled and unlabeled open-world images. The effectiveness of KRADA has been verified on two synthetic tasks and one COVID-19 segmentation task.},
  archive      = {J_TMLR},
  author       = {Chenhong Zhou and Feng Liu and Chen Gong and Rongfei Zeng and Tongliang Liu and William Cheung and Bo Han},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {KRADA: Known-region-aware domain alignment for open-set domain adaptation in semantic segmentation},
  url          = {https://openreview.net/forum?id=5II12ypVQo},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Layerwise bregman representation learning of neural networks
with applications to knowledge distillation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=6dsvH7pQHH">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new method for layerwise representation learning of a trained neural network that conforms to the non-linearity of the layer&#39;s transfer function. In particular, we form a Bregman divergence based on the convex function induced by the layer&#39;s transfer function and construct an extension of the original Bregman PCA formulation by incorporating a mean vector and revising the normalization constraint on the principal directions. These modifications allow exporting the learned representation as a fixed layer with a non-linearity. As an application to knowledge distillation, we cast the learning problem for the student network as predicting the compression coefficients of the teacher&#39;s representations, which is then passed as the input to the imported layer. Our empirical findings indicate that our approach is substantially more effective for transferring information between networks than typical teacher-student training that uses the teacher&#39;s soft labels.},
  archive      = {J_TMLR},
  author       = {Ehsan Amid and Rohan Anil and Christopher Fifty and Manfred K Warmuth},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Layerwise bregman representation learning of neural networks with applications to knowledge distillation},
  url          = {https://openreview.net/forum?id=6dsvH7pQHH},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). OADAT: Experimental and synthetic clinical optoacoustic data
for standardized image processing. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=BVi6MhKO0G">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optoacoustic (OA) imaging is based on excitation of biological tissues with nanosecond-duration laser pulses followed by subsequent detection of ultrasound waves generated via light-absorption-mediated thermoelastic expansion. OA imaging features a powerful combination between rich optical contrast and high resolution in deep tissues. This enabled the exploration of a number of attractive new applications both in clinical and laboratory settings. However, no standardized datasets generated with different types of experimental set-up and associated processing methods are available to facilitate advances in broader applications of OA in clinical settings. This complicates an objective comparison between new and established data processing methods, often leading to qualitative results and arbitrary interpretations of the data. In this paper, we provide both experimental and synthetic OA raw signals and reconstructed image domain datasets rendered with different experimental parameters and tomographic acquisition geometries. We further provide trained neural networks to tackle three important challenges related to OA image processing, namely accurate reconstruction under limited view tomographic conditions, removal of spatial undersampling artifacts and anatomical segmentation for improved image reconstruction. Specifically, we define 44 experiments corresponding to the aforementioned challenges as benchmarks to be used as a reference for the development of more advanced processing methods.},
  archive      = {J_TMLR},
  author       = {Firat Ozdemir and Berkan Lafci and Xose Luis Dean-Ben and Daniel Razansky and Fernando Perez-Cruz},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {OADAT: Experimental and synthetic clinical optoacoustic data for standardized image processing},
  url          = {https://openreview.net/forum?id=BVi6MhKO0G},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contrastive search is what you need for neural text
generation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=GbkWw3jwL9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating text with autoregressive language models (LMs) is of great importance to many natural language processing (NLP) applications. Previous solutions for this task often produce text that contains degenerative expressions (Welleck et al., 2020) or lacks semantic consistency (Basu et al., 2021). Recently, Su et al. (2022b) introduced a new decoding method, contrastive search, based on the isotropic representation space of the language model and obtained new state of the art on various benchmarks. Additionally, Su et al. (2022b) argued that the representations of autoregressive LMs (e.g. GPT-2) are intrinsically anisotropic which is also shared by previous studies (Ethayarajh, 2019). Therefore, to ensure the language model follows an isotropic distribution, Su et al. (2022b) proposed a contrastive learning scheme, SimCTG, which calibrates the language model’s representations through additional training. In this study, we first answer the question: “Are autoregressive LMs really anisotropic?”. To this end, we extensively evaluate the isotropy of LMs across 16 major languages. Surprisingly, we find that the anisotropic problem only exists in the two specific English GPT-2-small/medium models. On the other hand, all other evaluated LMs are naturally isotropic which is in contrast to the conclusion drawn by previous studies (Ethayarajh, 2019; Su et al., 2022b). Based on our findings, we further assess the contrastive search decoding method using off-the-shelf LMs on four generation tasks across 16 languages. Our experimental results demonstrate that contrastive search significantly outperforms previous decoding methods without any additional training. More notably, on 12 out of the 16 evaluated languages, contrastive search performs comparably with human-level performances as judged by human evaluations.},
  archive      = {J_TMLR},
  author       = {Yixuan Su and Nigel Collier},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Contrastive search is what you need for neural text generation},
  url          = {https://openreview.net/forum?id=GbkWw3jwL9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Supervised feature selection with neuron evolution in sparse
neural networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=GcO6ugrLKp">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection that selects an informative subset of variables from data not only enhances the model interpretability and performance but also alleviates the resource demands. Recently, there has been growing attention in feature selection using neural networks. However, existing methods usually suffer from high computational costs when applied to high-dimensional datasets. In this paper, inspired by evolution processes, we propose a novel resource-efficient supervised feature selection method using sparse neural networks, named &quot;NeuroFS&quot;. By gradually pruning the uninformative features from the input layer of a sparse neural network trained from scratch, NeuroFS derives an informative subset of features efficiently. By performing several experiments on $11$ low and high-dimensional real-world benchmarks of different types, we demonstrate that NeuroFS achieves the highest ranking-based score among the considered state-of-the-art supervised feature selection models. We will make the code publicly available on GitHub after acceptance of the paper.},
  archive      = {J_TMLR},
  author       = {Zahra Atashgahi and Xuhao Zhang and Neil Kichler and Shiwei Liu and Lu Yin and Mykola Pechenizkiy and Raymond Veldhuis and Decebal Constantin Mocanu},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Supervised feature selection with neuron evolution in sparse neural networks},
  url          = {https://openreview.net/forum?id=GcO6ugrLKp},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Controlling neural network smoothness for neural algorithmic
reasoning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=JnsGy9uWtI">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The modelling framework of neural algorithmic reasoning (Veličković &amp; Blundell, 2021) postulates that a continuous neural network may learn to emulate the discrete reasoning steps of a symbolic algorithm. We investigate the underlying hypothesis in the most simple conceivable scenario – the addition of real numbers. Our results show that two layer neural networks fail to learn the structure of the task, despite containing multiple solutions of the true function within their hypothesis class. Growing the network’s width leads to highly complex error regions in the input space. Moreover, we find that the network fails to generalise with increasing severity i) in the training domain, ii) outside of the training domain but within its convex hull, and iii) outside the training domain’s convex hull. This behaviour can be emulated with Gaussian process regressors that use radial basis function kernels of decreasing length scale. Classical results establish an equivalence between Gaussian processes and infinitely wide neural networks. We demonstrate a tight linkage between the scaling of a network weights’ standard deviation and its effective length scale on a sinusoidal regression problem, suggesting simple modifications to control the length scale of the function learned by a neural network and, thus, its smoothness. This has important applications for the different generalisation scenarios suggested above, but it also suggests a partial remedy to the brittleness of neural network predictions as exposed by adversarial examples. We demonstrate the gains in adversarial robustness that our modification achieves on a standard classification problem of handwritten digit recognition. In conclusion, this work shows inherent problems of neural networks even for the simplest algorithmic tasks which, however, may be partially remedied through links to Gaussian processes.},
  archive      = {J_TMLR},
  author       = {David A. Klindt},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Controlling neural network smoothness for neural algorithmic reasoning},
  url          = {https://openreview.net/forum?id=JnsGy9uWtI},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SPADE: Semi-supervised anomaly detection under distribution
mismatch. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=JwDpZSv3yz">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised anomaly detection is a common problem, as often the datasets containing anomalies are partially labeled. We propose a canonical framework: Semi-supervised Pseudo-labeler Anomaly Detection with Ensembling (SPADE) that isn&#39;t limited by the assumption that labeled and unlabeled data come from the same distribution. Indeed, the assumption is often violated in many applications -- for example, the labeled data may contain only anomalies unlike unlabeled data, or unlabeled data may contain different types of anomalies, or labeled data may contain only `easy-to-label&#39; samples. SPADE utilizes an ensemble of one class classifiers as the pseudo-labeler to improve the robustness of pseudo-labeling with distribution mismatch. Partial matching is proposed to automatically select the critical hyper-parameters for pseudo-labeling without validation data, which is crucial with limited labeled data. SPADE shows state-of-the-art semi-supervised anomaly detection performance across a wide range of scenarios with distribution mismatch in both tabular and image domains. In some common real-world settings such as model facing new types of unlabeled anomalies, SPADE outperforms the state-of-the-art alternatives by 5% AUC in average.},
  archive      = {J_TMLR},
  author       = {Jinsung Yoon and Kihyuk Sohn and Chun-Liang Li and Sercan O Arik and Tomas Pfister},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SPADE: Semi-supervised anomaly detection under distribution mismatch},
  url          = {https://openreview.net/forum?id=JwDpZSv3yz},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finite-time analysis of decentralized single-timescale
actor-critic. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=KQRv0O8iW4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized Actor-Critic (AC) algorithms have been widely utilized for multi-agent reinforcement learning (MARL) and have achieved remarkable success. Apart from its empirical success, the theoretical convergence property of decentralized AC algorithms is largely unexplored. Most of the existing finite-time convergence results are derived based on either double-loop update or two-timescale step sizes rule, and this is the case even for centralized AC algorithm under a single-agent setting. In practice, the *single-timescale* update is widely utilized, where actor and critic are updated in an alternating manner with step sizes being of the same order. In this work, we study a decentralized *single-timescale* AC algorithm. Theoretically, using linear approximation for value and reward estimation, we show that the algorithm has sample complexity of $\tilde{\mathcal{O}}(\varepsilon^{-2})$ under Markovian sampling, which matches the optimal complexity with a double-loop implementation (here, $\tilde{\mathcal{O}}$ hides a logarithmic term). When we reduce to the single-agent setting, our result yields new sample complexity for centralized AC using a single-timescale update scheme. The central to establishing our complexity results is *the hidden smoothness of the optimal critic variable* we revealed. We also provide a local action privacy-preserving version of our algorithm and its analysis. Finally, we conduct experiments to show the superiority of our algorithm over the existing decentralized AC algorithms.},
  archive      = {J_TMLR},
  author       = {qijun luo and Xiao Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Finite-time analysis of decentralized single-timescale actor-critic},
  url          = {https://openreview.net/forum?id=KQRv0O8iW4},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Workflow discovery from dialogues in the low data regime.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=L9othQvPks">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-based dialogues are now widely used to solve real-world problems. In cases where solution strategies are already known, they can sometimes be codified into workflows and used to guide humans or artificial agents through the task of helping clients. We introduce a new problem formulation that we call Workflow Discovery (WD) in which we are interested in the situation where a formal workflow may not yet exist. Still, we wish to discover the set of actions that have been taken to resolve a particular problem. We also examine a sequence-to-sequence (Seq2Seq) approach for this novel task. We present experiments where we extract workflows from dialogues in the Action-Based Conversations Dataset (ABCD). Since the ABCD dialogues follow known workflows to guide agents, we can evaluate our ability to extract such workflows using ground truth sequences of actions. We propose and evaluate an approach that conditions models on the set of possible actions, and we show that using this strategy, we can improve WD performance. Our conditioning approach also improves zero-shot and few-shot WD performance when transferring learned models to unseen domains within and across datasets. Further, on ABCD a modified variant of our Seq2Seq method achieves state-of-the-art performance on related but different problems of Action State Tracking (AST) and Cascading Dialogue Success (CDS) across many evaluation metrics.},
  archive      = {J_TMLR},
  author       = {Amine El hattami and Issam H. Laradji and Stefania Raimondo and David Vazquez and Pau Rodriguez and Christopher Pal},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Workflow discovery from dialogues in the low data regime},
  url          = {https://openreview.net/forum?id=L9othQvPks},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Signed graph neural networks: A frequency perspective.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=RZveYHgZbu">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCNs) and its variants are designed for unsigned graphs containing only positive links. Many existing GCNs have been derived from the spectral domain analysis of signals lying over (unsigned) graphs and in each convolution layer they perform low-pass filtering of the input features followed by a learnable linear transformation. Their extension to signed graphs with positive as well as negative links imposes multiple issues including computational irregularities and ambiguous frequency interpretation, making the design of computationally efficient low pass filters challenging. In this paper, we address these issues via spectral analysis of signed graphs and propose two different signed graph neural networks, one keeps only low-frequency information and one also retains high-frequency information. We further introduce magnetic signed Laplacian and use its eigendecomposition for spectral analysis of directed signed graphs. We test our methods for node classification and link sign prediction tasks on signed graphs and achieve state-of-the-art performances.},
  archive      = {J_TMLR},
  author       = {Rahul Singh and Yongxin Chen},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Signed graph neural networks: A frequency perspective},
  url          = {https://openreview.net/forum?id=RZveYHgZbu},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Guaranteed discovery of control-endogenous latent states
with multi-step inverse models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=TNocbXm5MZ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many sequential decision-making tasks, the agent is not able to model the full complexity of the world, which consists of multitudes of relevant and irrelevant information. For example, a person walking along a city street who tries to model all aspects of the world would quickly be overwhelmed by a multitude of shops, cars, and people moving in and out of view, each following their own complex and inscrutable dynamics. Is it possible to turn the agent&#39;s firehose of sensory information into a minimal latent state that is both necessary and sufficient for an agent to successfully act in the world? We formulate this question concretely, and propose the Agent Control-Endogenous State Discovery algorithm (AC-State), which has theoretical guarantees and is practically demonstrated to discover the minimal control-endogenous latent state which contains all of the information necessary for controlling the agent, while fully discarding all irrelevant information. This algorithm consists of a multi-step inverse model (predicting actions from distant observations) with an information bottleneck. AC-State enables localization, exploration, and navigation without reward or demonstrations. We demonstrate the discovery of the control-endogenous latent state in three domains: localizing a robot arm with distractions (e.g., changing lighting conditions and background), exploring a maze alongside other agents, and navigating in the Matterport house simulator.},
  archive      = {J_TMLR},
  author       = {Alex Lamb and Riashat Islam and Yonathan Efroni and Aniket Rajiv Didolkar and Dipendra Misra and Dylan J Foster and Lekan P Molu and Rajan Chari and Akshay Krishnamurthy and John Langford},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Guaranteed discovery of control-endogenous latent states with multi-step inverse models},
  url          = {https://openreview.net/forum?id=TNocbXm5MZ},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tailoring to the tails: Risk measures for fine-grained tail
sensitivity. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=UntUoeLwwu">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expected risk minimization (ERM) is at the core of many machine learning systems. This means that the risk inherent in a loss distribution is summarized using a single number - its average. In this paper, we propose a general approach to construct risk measures which exhibit a desired tail sensitivity and may replace the expectation operator in ERM. Our method relies on the specification of a reference distribution with a desired tail behaviour, which is in a one-to-one correspondence to a coherent upper probability. Any risk measure, which is compatible with this upper probability, displays a tail sensitivity which is finely tuned to the reference distribution. As a concrete example, we focus on divergence risk measures based on f-divergence ambiguity sets, which are a widespread tool used to foster distributional robustness of machine learning systems. For instance, we show how ambiguity sets based on the Kullback-Leibler divergence are intricately tied to the class of subexponential random variables. We elaborate the connection of divergence risk measures and rearrangement invariant Banach norms.},
  archive      = {J_TMLR},
  author       = {Christian Fröhlich and Robert Williamson},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Tailoring to the tails: Risk measures for fine-grained tail sensitivity},
  url          = {https://openreview.net/forum?id=UntUoeLwwu},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learn, unlearn and relearn: An online learning paradigm for
deep neural networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=WN1O2MJDST">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) are often trained on the premise that the complete training data set is provided ahead of time. However, in real-world scenarios, data often arrive in chunks over time. This leads to important considerations about the optimal strategy for training DNNs, such as whether to fine-tune them with each chunk of incoming data (warm-start) or to retrain them from scratch with the entire corpus of data whenever a new chunk is available. While employing the latter for training can be resource-intensive, recent work has pointed out the lack of generalization in warm-start models. Therefore, to strike a balance between efficiency and generalization, we introduce &quot;Learn, Unlearn, and Relearn (LURE)&quot; an online learning paradigm for DNNs. LURE interchanges between the unlearning phase, which selectively forgets the undesirable information in the model through weight reinitialization in a data-dependent manner, and the relearning phase, which emphasizes learning on generalizable features. We show that our training paradigm provides consistent performance gains across datasets in both classification and few-shot settings. We further show that it leads to more robust and well-calibrated models.},
  archive      = {J_TMLR},
  author       = {Vijaya Raghavan T Ramkumar and Elahe Arani and Bahram Zonooz},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learn, unlearn and relearn: An online learning paradigm for deep neural networks},
  url          = {https://openreview.net/forum?id=WN1O2MJDST},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AI-SARAH: Adaptive and implicit stochastic recursive
gradient methods. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=WoXJFsJ6Zw">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present AI-SARAH, a practical variant of SARAH. As a variant of SARAH, this algorithm employs the stochastic recursive gradient yet adjusts step-size based on local geometry. AI-SARAH implicitly computes step-size and efficiently estimates local Lipschitz smoothness of stochastic functions. It is fully adaptive, tune-free, straightforward to implement, and computationally efficient. We provide technical insight and intuitive illustrations on its design and convergence. We conduct extensive empirical analysis and demonstrate its strong performance compared with its classical counterparts and other state-of-the-art first-order methods in solving convex machine learning problems.},
  archive      = {J_TMLR},
  author       = {Zheng Shi and Abdurakhmon Sadiev and Nicolas Loizou and Peter Richtárik and Martin Takáč},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {AI-SARAH: Adaptive and implicit stochastic recursive gradient methods},
  url          = {https://openreview.net/forum?id=WoXJFsJ6Zw},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SolidGen: An autoregressive model for direct b-rep
synthesis. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ZR2CDgADRo">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Boundary representation (B-rep) format is the de-facto shape representation in computer-aided design (CAD) to model solid and sheet objects. Recent approaches to generating CAD models have focused on learning sketch-and-extrude modeling sequences that are executed by a solid modeling kernel in postprocess to recover a B-rep. In this paper we present a new approach that enables learning from and synthesizing B-reps without the need for supervision through CAD modeling sequence data. Our method SolidGen, is an autoregressive neural network that models the B-rep directly by predicting the vertices, edges, and faces using Transformer-based and pointer neural networks. Key to achieving this is our Indexed Boundary Representation that references B-rep vertices, edges and faces in a well-defined hierarchy to capture the geometric and topological relations suitable for use with machine learning. SolidGen can be easily conditioned on contexts e.g., class labels, images, and voxels thanks to its probabilistic modeling of the B-rep distribution. We demonstrate qualitatively, quantitatively, and through perceptual evaluation by human subjects that SolidGen can produce high quality, realistic CAD models.},
  archive      = {J_TMLR},
  author       = {Pradeep Kumar Jayaraman and Joseph George Lambourne and Nishkrit Desai and Karl Willis and Aditya Sanghi and Nigel J. W. Morris},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SolidGen: An autoregressive model for direct B-rep synthesis},
  url          = {https://openreview.net/forum?id=ZR2CDgADRo},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Regularized training of intermediate layers for generative
models for inverse problems. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=cKsKXR28cG">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) have been shown to be powerful and flexible priors when solving inverse problems. One challenge of using them is overcoming representation error, the fundamental limitation of the network in representing any particular signal. Recently, multiple proposed inversion algorithms reduce representation error by optimizing over intermediate layer representations. These methods are typically applied to generative models that were trained agnostic of the downstream inversion algorithm. In our work, we introduce a principle that if a generative model is intended for inversion using an algorithm based on optimization of intermediate layers, it should be trained in a way that regularizes those intermediate layers. We instantiate this principle for two notable recent inversion algorithms: Intermediate Layer Optimization and the Multi-Code GAN prior. For both of these inversion algorithms, we introduce a new regularized GAN training algorithm and demonstrate that the learned generative model results in lower reconstruction errors across a wide range of under sampling ratios when solving compressed sensing, inpainting, and super-resolution problems.},
  archive      = {J_TMLR},
  author       = {Sean Gunn and Jorio Cocola and PAul HAnd},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Regularized training of intermediate layers for generative models for inverse problems},
  url          = {https://openreview.net/forum?id=cKsKXR28cG},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DEUP: Direct epistemic uncertainty prediction.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=eGLdVRvvfQ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epistemic Uncertainty is a measure of the lack of knowledge of a learner which diminishes with more evidence. While existing work focuses on using the variance of the Bayesian posterior due to parameter uncertainty as a measure of epistemic uncertainty, we argue that this does not capture the part of lack of knowledge induced by model misspecification. We discuss how the excess risk, which is the gap between the generalization error of a predictor and the Bayes predictor, is a sound measure of epistemic uncertainty which captures the effect of model misspecification. We thus propose a principled framework for directly estimating the excess risk by learning a secondary predictor for the generalization error and subtracting an estimate of aleatoric uncertainty, i.e., intrinsic unpredictability. We discuss the merits of this novel measure of epistemic uncertainty, and highlight how it differs from variance-based measures of epistemic uncertainty and addresses its major pitfall. Our framework, Direct Epistemic Uncertainty Prediction (DEUP) is particularly interesting in interactive learning environments, where the learner is allowed to acquire novel examples in each round. Through a wide set of experiments, we illustrate how existing methods in sequential model optimization can be improved with epistemic uncertainty estimates from DEUP, and how DEUP can be used to drive exploration in reinforcement learning. We also evaluate the quality of uncertainty estimates from DEUP for probabilistic image classification and predicting synergies of drug combinations.},
  archive      = {J_TMLR},
  author       = {Salem Lahlou and Moksh Jain and Hadi Nekoei and Victor I Butoi and Paul Bertin and Jarrid Rector-Brooks and Maksym Korablyov and Yoshua Bengio},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DEUP: Direct epistemic uncertainty prediction},
  url          = {https://openreview.net/forum?id=eGLdVRvvfQ},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mean-field analysis for heavy ball methods:
Dropout-stability, connectivity, and global convergence. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=gZna3IiGfl">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stochastic heavy ball method (SHB), also known as stochastic gradient descent (SGD) with Polyak&#39;s momentum, is widely used in training neural networks. However, despite the remarkable success of such algorithm in practice, its theoretical characterization remains limited. In this paper, we focus on neural networks with two and three layers and provide a rigorous understanding of the properties of the solutions found by SHB: \emph{(i)} stability after dropping out part of the neurons, \emph{(ii)} connectivity along a low-loss path, and \emph{(iii)} convergence to the global optimum. To achieve this goal, we take a mean-field view and relate the SHB dynamics to a certain partial differential equation in the limit of large network widths. This mean-field perspective has inspired a recent line of work focusing on SGD while, in contrast, our paper considers an algorithm with momentum. More specifically, after proving existence and uniqueness of the limit differential equations, we show convergence to the global optimum and give a quantitative bound between the mean-field limit and the SHB dynamics of a finite-width network. Armed with this last bound, we are able to establish the dropout-stability and connectivity of SHB solutions.},
  archive      = {J_TMLR},
  author       = {Diyuan Wu and Vyacheslav Kungurtsev and Marco Mondelli},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Mean-field analysis for heavy ball methods: Dropout-stability, connectivity, and global convergence},
  url          = {https://openreview.net/forum?id=gZna3IiGfl},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diffusion-based time series imputation and forecasting with
structured state space models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=hHiIbk7ApW">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The imputation of missing values represents a significant obstacle for many real-world data analysis pipelines. Here, we focus on time series data and put forward SSSD, an imputation model that relies on two emerging technologies, (conditional) diffusion models as state-ofthe-art generative models and structured state space models as internal model architecture, which are particularly suited to capture long-term dependencies in time series data. We demonstrate that SSSD matches or even exceeds state-of-the-art probabilistic imputation and forecasting performance on a broad range of data sets and different missingness scenarios, including the challenging blackout-missing scenarios, where prior approaches failed to provide meaningful results.},
  archive      = {J_TMLR},
  author       = {Juan Lopez Alcaraz and Nils Strodthoff},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Diffusion-based time series imputation and forecasting with structured state space models},
  url          = {https://openreview.net/forum?id=hHiIbk7ApW},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A flexible nadaraya-watson head can offer explainable and
calibrated classification. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=iEq6lhG4O3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we empirically analyze a simple, non-learnable, and nonparametric Nadaraya-Watson (NW) prediction head that can be used with any neural network architecture. In the NW head, the prediction is a weighted average of labels from a support set. The weights are computed from distances between the query feature and support features. This is in contrast to the dominant approach of using a learnable classification head (e.g., a fully-connected layer) on the features, which can be challenging to interpret and can yield poorly calibrated predictions. Our empirical results on an array of computer vision tasks demonstrate that the NW head can yield better calibration with comparable accuracy compared to its parametric counterpart, particularly in data-limited settings. To further increase inference-time efficiency, we propose a simple approach that involves a clustering step run on the training set to create a relatively small distilled support set. Furthermore, we explore two means of interpretability/explainability that fall naturally from the NW head. The first is the label weights, and the second is our novel concept of the ``support influence function,&#39;&#39; which is an easy-to-compute metric that quantifies the influence of a support element on the prediction for a given query. As we demonstrate in our experiments, the influence function can allow the user to debug a trained model. We believe that the NW head is a flexible, interpretable, and highly useful building block that can be used in a range of applications.},
  archive      = {J_TMLR},
  author       = {Alan Q. Wang and Mert R. Sabuncu},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A flexible nadaraya-watson head can offer explainable and calibrated classification},
  url          = {https://openreview.net/forum?id=iEq6lhG4O3},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dirichlet mechanism for differentially private KL divergence
minimization. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=lmr2WwlaFc">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given an empirical distribution $f(x)$ of sensitive data $x$, we consider the task of minimizing $F(y) = D_{\text{KL}} (f(x)\Vert y)$ over a probability simplex, while protecting the privacy of $x$. We observe that, if we take the exponential mechanism and use the KL divergence as the loss function, then the resulting algorithm is the $Dirichlet\text{ }mechanism$ that outputs a single draw from a Dirichlet distribution. Motivated by this, we propose a Rényi differentially private (RDP) algorithm that employs the Dirichlet mechanism to solve the KL divergence minimization task. In addition, given $f(x)$ as above and $\hat{y}$ an output of the Dirichlet mechanism, we prove a probability tail bound on $D_{\text{KL}} (f(x)\Vert \hat{y})$, which is then used to derive a lower bound for the sample complexity of our RDP algorithm. Experiments on real-world datasets demonstrate advantages of our algorithm over Gaussian and Laplace mechanisms in supervised classification and maximum likelihood estimation.},
  archive      = {J_TMLR},
  author       = {Donlapark Ponnoprat},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Dirichlet mechanism for differentially private KL divergence minimization},
  url          = {https://openreview.net/forum?id=lmr2WwlaFc},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differentially private fréchet mean on the manifold of
symmetric positive definite (SPD) matrices with log-euclidean metric.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=mAx8QqZ14f">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential privacy has become crucial in the real-world deployment of statistical and machine learning algorithms with rigorous privacy guarantees. The earliest statistical queries, for which differential privacy mechanisms have been developed, were for the release of the sample mean. In Geometric Statistics, the sample Fréchet mean represents one of the most fundamental statistical summaries, as it generalizes the sample mean for data belonging to nonlinear manifolds. In that spirit, the only geometric statistical query for which a differential privacy mechanism has been developed, so far, is for the release of the sample Fréchet mean: the \emph{Riemannian Laplace mechanism} was recently proposed to privatize the Fréchet mean on complete Riemannian manifolds. In many fields, the manifold of Symmetric Positive Definite (SPD) matrices is used to model data spaces, including in medical imaging where privacy requirements are key. We propose a novel, simple and fast mechanism - the \emph{tangent Gaussian mechanism} - to compute a differentially private Fréchet mean on the SPD manifold endowed with the log-Euclidean Riemannian metric. We show that our new mechanism has significantly better utility and is computationally efficient --- as confirmed by extensive experiments.},
  archive      = {J_TMLR},
  author       = {Saiteja Utpala and Praneeth Vepakomma and Nina Miolane},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Differentially private fréchet mean on the manifold of symmetric positive definite (SPD) matrices with log-euclidean metric},
  url          = {https://openreview.net/forum?id=mAx8QqZ14f},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stacking diverse architectures to improve machine
translation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=mNEqiC924B">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Repeated applications of the same neural block primarily based on self-attention characterize the current state-of-the-art in neural architectures for machine translation. In such architectures the decoder adopts a masked version of the same encoding block. Although simple this strategy doesn&#39;t encode the various inductive biases such as locality that arise from alternative architectures and that are central to the modelling of translation. We propose Lasagna, an encoder-decoder model that aims to combine the inductive benefits of different architectures by layering multiple instances of different blocks. Lasagna’s encoder first grows the representation from local to mid-sized using convolutional blocks and only then applies a pair of final self-attention blocks. Lasagna’s decoder uses only convolutional blocks that attend to the encoder representation. On a large suit of machine translation tasks, we find that Lasagna not only matches or outperforms the Transformer baseline, but it does so more efficiently thanks to widespread use of the efficient convolutional blocks. These findings suggest that the widespread use of uniform architectures may be suboptimal in certain scenarios and exploiting the diversity of inductive architectural biases can lead to substantial gains.},
  archive      = {J_TMLR},
  author       = {Andrea Schioppa and Nal Kalchbrenner},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Stacking diverse architectures to improve machine translation},
  url          = {https://openreview.net/forum?id=mNEqiC924B},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). U-statistics for importance-weighted variational inference.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=oXmwAPlbVw">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose the use of U-statistics to reduce variance for gradient estimation in importance-weighted variational inference. The key observation is that, given a base gradient estimator that requires $m &gt; 1$ samples and a total of $n &gt; m$ samples to be used for estimation, lower variance is achieved by averaging the base estimator on overlapping batches of size $m$ than disjoint batches, as currently done. We use classical U-statistic theory to analyze the variance reduction, and propose novel approximations with theoretical guarantees to ensure computational efficiency. We find empirically that U-statistic variance reduction can lead to modest to significant improvements in inference performance on a range of models, with little computational cost.},
  archive      = {J_TMLR},
  author       = {Javier Burroni and Kenta Takatsu and Justin Domke and Daniel Sheldon},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {U-statistics for importance-weighted variational inference},
  url          = {https://openreview.net/forum?id=oXmwAPlbVw},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust hybrid learning with expert augmentation.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=oe4dl4MCGY">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid modelling reduces the misspecification of expert models by combining them with machine learning (ML) components learned from data. Similarly to many ML algorithms, hybrid model performance guarantees are limited to the training distribution. Leveraging the insight that the expert model is usually valid even outside the training domain, we overcome this limitation by introducing a hybrid data augmentation strategy termed \textit{expert augmentation}. Based on a probabilistic formalization of hybrid modelling, we demonstrate that expert augmentation, which can be incorporated into existing hybrid systems, improves generalization. We empirically validate the expert augmentation on three controlled experiments modelling dynamical systems with ordinary and partial differential equations. Finally, we assess the potential real-world applicability of expert augmentation on a dataset of a real double pendulum.},
  archive      = {J_TMLR},
  author       = {Antoine Wehenkel and Jens Behrmann and Hsiang Hsu and Guillermo Sapiro and Gilles Louppe and Joern-Henrik Jacobsen},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Robust hybrid learning with expert augmentation},
  url          = {https://openreview.net/forum?id=oe4dl4MCGY},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved differentially private riemannian optimization:
Fast sampling and variance reduction. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=paguBNtqiO">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A common step in differentially private ({DP}) Riemannian optimization is sampling from the (tangent) Gaussian distribution as noise needs to be generated in the tangent space to perturb the gradient. In this regard, existing works either use the Markov chain Monte Carlo ({MCMC}) sampling or explicit basis construction based sampling methods on the tangent space. This becomes a computational bottleneck in the practical use of {DP} Riemannian optimization, especially when performing stochastic optimization. In this paper, we discuss different sampling strategies and develop efficient sampling procedures by exploiting linear isometry between tangent spaces and show them to be orders of magnitude faster than both the {MCMC} and sampling using explicit basis construction. Furthermore, we develop the {DP} Riemannian stochastic variance reduced gradient algorithm and compare it with DP Riemannian gradient descent and stochastic gradient descent algorithms on various problems.},
  archive      = {J_TMLR},
  author       = {Saiteja Utpala and Andi Han and Pratik Jawanpuria and Bamdev Mishra},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Improved differentially private riemannian optimization: Fast sampling and variance reduction},
  url          = {https://openreview.net/forum?id=paguBNtqiO},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Beyond intuition: Rethinking token attributions inside
transformers. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=rm0zIzlhcX">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-head attention mechanism, or rather the Transformer-based models have always been under the spotlight, not only in the domain of text processing, but also for computer vision. Several works have recently been proposed around exploring the token attributions along the intrinsic decision process. However, the ambiguity of the expression formulation can lead to an accumulation of error, which makes the interpretation less trustworthy and less applicable to different variants. In this work, we propose a novel method to approximate token contributions inside Transformers. We start from the partial derivative to each token, divide the interpretation process into attention perception and reasoning feedback with the chain rule and explore each part individually with explicit mathematical derivations. In attention perception, we propose the head-wise and token-wise approximations in order to learn how the tokens interact to form the pooled vector. As for reasoning feedback, we adopt a noise-decreasing strategy by applying the integrated gradients to the last attention map. Our method is further validated qualitatively and quantitatively through the faithfulness evaluations across different settings: single modality (BERT and ViT) and bi-modality (CLIP), different model sizes (ViT-L) and different pooling strategies (ViT-MAE) to demonstrate the broad applicability and clear improvements over existing methods.},
  archive      = {J_TMLR},
  author       = {Jiamin Chen and Xuhong Li and Lei Yu and Dejing Dou and Haoyi Xiong},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Beyond intuition: Rethinking token attributions inside transformers},
  url          = {https://openreview.net/forum?id=rm0zIzlhcX},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bayesian causal bandits with backdoor adjustment prior.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=sMsGv5Kfm3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The causal bandit problem setting is a sequential decision-making framework where actions of interest correspond to interventions on variables in a system assumed to be governed by a causal model. The underlying causality may be exploited when investigating actions in the interest of optimizing the yield of the reward variable. Most existing approaches assume prior knowledge of the underlying causal graph, which is in practice restrictive and often unrealistic. In this paper, we develop a novel Bayesian framework for tackling causal bandit problems that does not rely on possession of the causal graph, but rather simultaneously learns the causal graph while exploiting causal inferences to optimize the reward. Our methods efficiently utilize joint inferences from interventional and observational data in a unified Bayesian model constructed with intervention calculus and causal graph learning. For the implementation of our proposed methodology in the discrete distributional setting, we derive an approximation of the sampling variance of the backdoor adjustment estimator. In the Gaussian setting, we characterize the interventional variance with intervention calculus and propose a simple graphical criterion to share information between arms. We validate our proposed methodology in an extensive empirical study, demonstrating compelling cumulative regret performance against state-of-the-art standard algorithms as well as optimistic implementations of their causal variants that assume strong prior knowledge of the causal structure.},
  archive      = {J_TMLR},
  author       = {Jireh Huang and Qing Zhou},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bayesian causal bandits with backdoor adjustment prior},
  url          = {https://openreview.net/forum?id=sMsGv5Kfm3},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Separable self-attention for mobile vision transformers.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=tBl4yBEjKi">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile vision transformers (MobileViT) can achieve state-of-the-art performance across several mobile vision tasks, including classification and detection. Though these models have fewer parameters, they have high latency as compared to convolutional neural network-based models. The main efficiency bottleneck in MobileViT is the multi-headed self-attention (MHA) in transformers, which requires $O(k^2)$ time complexity with respect to the number of tokens (or patches) $k$. Moreover, MHA requires costly operations (e.g., batch-wise matrix multiplication) for computing self-attention, impacting latency on resource-constrained devices. This paper introduces a separable self-attention method with linear complexity, i.e. $O(k)$. A simple yet effective characteristic of the proposed method is that it uses element-wise operations for computing self-attention, making it a good choice for resource-constrained devices. The improved model, MobileViTv2, is state-of-the-art on several mobile vision tasks, including ImageNet object classification and MS-COCO object detection. With about three million parameters, MobileViTv2 achieves a top-1 accuracy of 75.6% on the ImageNet dataset, outperforming MobileViT by about 1% while running $3.2\times$ faster on a mobile device. Our source code is available at: https://github.com/apple/ml-cvnets},
  archive      = {J_TMLR},
  author       = {Sachin Mehta and Mohammad Rastegari},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Separable self-attention for mobile vision transformers},
  url          = {https://openreview.net/forum?id=tBl4yBEjKi},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Target propagation via regularized inversion for recurrent
neural networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=vxyjTUPV24">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Target Propagation (TP) algorithms compute targets instead of gradients along neural networks and propagate them backward in a way that is similar to yet different than gradient back-propagation (BP). The idea initially appeared as a perturbative alternative to BP that may improve gradient evaluation accuracy when training multi-layer neural networks (LeCun, 1985) and has gained popularity as a biologically plausible counterpart of BP. However, there have been many variations of TP, and a simple version of TP still remains worthwhile. Revisiting the insights of LeCun (1985) and Lee et al (2015), we present a simple version of TP based on regularized inversions of layers of recurrent neural networks. The proposed TP algorithm is easily implementable in a differentiable programming framework. We illustrate the algorithm with recurrent neural networks on long sequences in various sequence modeling problems and delineate the regimes in which the computational complexity of TP can be attractive compared to BP.},
  archive      = {J_TMLR},
  author       = {Vincent Roulet and Zaid Harchaoui},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Target propagation via regularized inversion for recurrent neural networks},
  url          = {https://openreview.net/forum?id=vxyjTUPV24},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lo-fi: Distributed fine-tuning without communication.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=1U0aPkBVz0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When fine-tuning large neural networks, it is common to use multiple nodes and to communicate gradients at each optimization step. By contrast, we investigate completely local fine-tuning, which we refer to as lo-fi. During lo-fi, each node fine-tunes independently without any communication. Then, the weights are averaged across nodes at the conclusion of fine-tuning. When fine-tuning DeiT-base and DeiT-large on ImageNet, this procedure matches accuracy in-distribution and improves accuracy under distribution shift compared to the baseline, which observes the same amount of data but communicates gradients at each step. We also observe that lo-fi matches the baseline&#39;s performance when fine-tuning OPT language models (up to 1.3B parameters) on Common Crawl. By removing the communication requirement, lo-fi reduces resource barriers for fine-tuning large models and enables fine-tuning in settings with prohibitive communication cost.},
  archive      = {J_TMLR},
  author       = {Mitchell Wortsman and Suchin Gururangan and Shen Li and Ali Farhadi and Ludwig Schmidt and Michael Rabbat and Ari S. Morcos},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Lo-fi: Distributed fine-tuning without communication},
  url          = {https://openreview.net/forum?id=1U0aPkBVz0},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). OpenCon: Open-world contrastive learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=2wWJxtpFer">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models deployed in the wild naturally encounter unlabeled samples from both known and novel classes. Challenges arise in learning from both the labeled and unlabeled data, in an open-world semi-supervised manner. In this paper, we introduce a new learning framework, open-world contrastive learning (OpenCon). OpenCon tackles the challenges of learning compact representations for both known and novel classes and facilitates novelty discovery along the way. We demonstrate the effectiveness of OpenCon on challenging benchmark datasets and establish competitive performance. On the ImageNet dataset, OpenCon significantly outperforms the current best method by 11.9% and 7.4% on novel and overall classification accuracy, respectively. Theoretically, OpenCon can be rigorously interpreted from an EM algorithm perspective—minimizing our contrastive loss partially maximizes the likelihood by clustering similar samples in the embedding space. The code is available at https://github.com/deeplearning-wisc/opencon.},
  archive      = {J_TMLR},
  author       = {Yiyou Sun and Yixuan Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {OpenCon: Open-world contrastive learning},
  url          = {https://openreview.net/forum?id=2wWJxtpFer},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the role of fixed points of dynamical systems in training
physics-informed neural networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=56cTmVrg5w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper empirically studies commonly observed training difficulties of Physics-Informed Neural Networks (PINNs) on dynamical systems. Our results indicate that fixed points which are inherent to these systems play a key role in the optimization of the in PINNs embedded physics loss function. We observe that the loss landscape exhibits local optima that are shaped by the presence of fixed points. We find that these local optima contribute to the complexity of the physics loss optimization which can explain common training difficulties and resulting nonphysical predictions. Under certain settings, e.g., initial conditions close to fixed points or long simulations times, we show that those optima can even become better than that of the desired solution.},
  archive      = {J_TMLR},
  author       = {Franz M. Rohrhofer and Stefan Posch and Clemens Gößnitzer and Bernhard C Geiger},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the role of fixed points of dynamical systems in training physics-informed neural networks},
  url          = {https://openreview.net/forum?id=56cTmVrg5w},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intrinsic dimension for large-scale geometric learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=85BfDdYMBY">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of dimension is essential to grasp the complexity of data. A naive approach to determine the dimension of a dataset is based on the number of attributes. More sophisticated methods derive a notion of intrinsic dimension (ID) that employs more complex feature functions, e.g., distances between data points. Yet, many of these approaches are based on empirical observations, cannot cope with the geometric character of contemporary datasets, and do lack an axiomatic foundation. A different approach was proposed by V. Pestov, who links the intrinsic dimension axiomatically to the mathematical concentration of measure phenomenon. First methods to compute this and related notions for ID were computationally intractable for large-scale real-world datasets. In the present work, we derive a computationally feasible method for determining said axiomatic ID functions. Moreover, we demonstrate how the geometric properties of complex data are accounted for in our modeling. In particular, we propose a principle way to incorporate neighborhood information, as in graph data, into the ID. This allows for new insights into common graph learning procedures, which we illustrate by experiments on the Open Graph Benchmark.},
  archive      = {J_TMLR},
  author       = {Maximilian Stubbemann and Tom Hanika and Friedrich Martin Schneider},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Intrinsic dimension for large-scale geometric learning},
  url          = {https://openreview.net/forum?id=85BfDdYMBY},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Constrained parameter inference as a principle for learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=CUDdbTT1QC">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning in neural networks is often framed as a problem in which targeted error signals are directly propagated to parameters and used to produce updates that induce more optimal network behaviour. Backpropagation of error (BP) is an example of such an approach and has proven to be a highly successful application of stochastic gradient descent to deep neural networks. We propose constrained parameter inference (COPI) as a new principle for learning. The COPI approach assumes that learning can be set up in a manner where parameters infer their own values based upon observations of their local neuron activities. We find that this estimation of network parameters is possible under the constraints of decorrelated neural inputs and top-down perturbations of neural states for credit assignment. We show that the decorrelation required for COPI allows learning at extremely high learning rates, competitive with that of adaptive optimizers, as used by BP. We further demonstrate that COPI affords a new approach to feature analysis and network compression. Finally, we argue that COPI may shed new light on learning in biological networks given the evidence for decorrelation in the brain.},
  archive      = {J_TMLR},
  author       = {Nasir Ahmad and Ellen Schrader and Marcel van Gerven},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Constrained parameter inference as a principle for learning},
  url          = {https://openreview.net/forum?id=CUDdbTT1QC},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ViViT: Curvature access through the generalized
gauss-newton’s low-rank structure. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=DzJ7JfPXkE">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Curvature in form of the Hessian or its generalized Gauss-Newton (GGN) approximation is valuable for algorithms that rely on a local model for the loss to train, compress, or explain deep networks. Existing methods based on implicit multiplication via automatic differentiation or Kronecker-factored block diagonal approximations do not consider noise in the mini-batch. We present ViViT, a curvature model that leverages the GGN’s low-rank structure without further approximations. It allows for efficient computation of eigenvalues, eigenvectors, as well as per-sample first- and second-order directional derivatives. The representation is computed in parallel with gradients in one backward pass and offers a fine-grained cost-accuracy trade-off, which allows it to scale. We demonstrate this by conducting performance benchmarks and substantiate ViViT’s usefulness by studying the impact of noise on the GGN’s structural properties during neural network training.},
  archive      = {J_TMLR},
  author       = {Felix Dangel and Lukas Tatzel and Philipp Hennig},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ViViT: Curvature access through the generalized gauss-newton’s low-rank structure},
  url          = {https://openreview.net/forum?id=DzJ7JfPXkE},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On a continuous time model of gradient descent dynamics and
instability in deep learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=EYrRzKPinA">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recipe behind the success of deep learning has been the combination of neural networks and gradient-based optimization. Understanding the behavior of gradient descent however, and particularly its instability, has lagged behind its empirical success. To add to the theoretical tools available to study gradient descent we propose the principal flow (PF), a continuous time flow that approximates gradient descent dynamics. To our knowledge, the PF is the only continuous flow that captures the divergent and oscillatory behaviors of gradient descent, including escaping local minima and saddle points. Through its dependence on the eigendecomposition of the Hessian the PF sheds light on the recently observed edge of stability phenomena in deep learning. Using our new understanding of instability we propose a learning rate adaptation method which enables us to control the trade-off between training stability and test set evaluation performance.},
  archive      = {J_TMLR},
  author       = {Mihaela Rosca and Yan Wu and Chongli Qin and Benoit Dherin},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On a continuous time model of gradient descent dynamics and instability in deep learning},
  url          = {https://openreview.net/forum?id=EYrRzKPinA},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DisCo: Improving compositional generalization in visual
reasoning through distribution coverage. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=EgHnKOLaKW">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present DisCo, a learning paradigm for improving compositional generalization of visual reasoning models by leveraging unlabeled, out-of-distribution images from the test distribution. DisCo has two components. The first is an iterative pseudo-labeling framework with an entropy measure, which effectively labels images of novel attribute compositions paired with randomly sampled questions. The second is a distribution coverage metric, serving as a model selection strategy that approximates generalization capability to test examples drawn from a different attribute combination distribution to the train set, without the use of labeled data from the test distribution. Both components are built on strong empirical evidence of the correlation between the chosen metric and model generalization, and improve distribution coverage on unlabeled images. We apply DisCo to visual question answering, with three backbone networks (FiLM, TbD-net, and the Neuro-Symbolic Concept Learner), and demonstrate that it consistently enhances performance on a variety of compositional generalization tasks with varying levels of train data bias.},
  archive      = {J_TMLR},
  author       = {Joy Hsu and Jiayuan Mao and Jiajun Wu},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DisCo: Improving compositional generalization in visual reasoning through distribution coverage},
  url          = {https://openreview.net/forum?id=EgHnKOLaKW},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). VN-transformer: Rotation-equivariant attention for vector
neurons. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=EiX2L4sDPG">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rotation equivariance is a desirable property in many practical applications such as motion forecasting and 3D perception, where it can offer benefits like sample efficiency, better generalization, and robustness to input perturbations. Vector Neurons (VN) is a recently developed framework offering a simple yet effective approach for deriving rotation-equivariant analogs of standard machine learning operations by extending one-dimensional scalar neurons to three-dimensional &quot;vector neurons.&quot; We introduce a novel &quot;VN-Transformer&quot; architecture to address several shortcomings of the current VN models. Our contributions are: (i) we derive a rotation-equivariant attention mechanism which eliminates the need for the heavy feature preprocessing required by the original Vector Neurons models; (ii) we extend the VN framework to support non-spatial attributes, expanding the applicability of these models to real-world datasets; (iii) we derive a rotation-equivariant mechanism for multi-scale reduction of point-cloud resolution, greatly speeding up inference and training; (iv) we show that small tradeoffs in equivariance ($\epsilon$-approximate equivariance) can be used to obtain large improvements in numerical stability and training robustness on accelerated hardware, and we bound the propagation of equivariance violations in our models. Finally, we apply our VN-Transformer to 3D shape classification and motion forecasting with compelling results.},
  archive      = {J_TMLR},
  author       = {Serge Assaad and Carlton Downey and Rami Al-Rfou&#39; and Nigamaa Nayakanti and Benjamin Sapp},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {VN-transformer: Rotation-equivariant attention for vector neurons},
  url          = {https://openreview.net/forum?id=EiX2L4sDPG},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EdiBERT: A generative model for image editing.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=GRBbtkW3Lp">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in computer vision are pushing the limits of image manipulation, with generative models sampling highly-realistic detailed images on various tasks. However, a specialized model is often developed and trained for each specific task, even though many image edition tasks share similarities. In denoising, inpainting, or image compositing, one always aims at generating a realistic image from a low-quality one. In this paper, we aim at making a step towards a unified approach for image editing. To do so, we propose EdiBERT, a bidirectional transformer that re-samples image patches conditionally to a given image. Using one generic objective, we show that the model resulting from a single training matches state-of-the-art GANs inversion on several tasks: image denoising, image completion, and image composition. We also provide several insights on the latent space of vector-quantized auto-encoders, such as locality and reconstruction capacities. The code is available at https://github.com/EdiBERT4ImageManipulation/EdiBERT.},
  archive      = {J_TMLR},
  author       = {Thibaut Issenhuth and Ugo Tanielian and Jeremie Mary and David Picard},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {EdiBERT: A generative model for image editing},
  url          = {https://openreview.net/forum?id=GRBbtkW3Lp},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Euclidean-norm-induced schatten-p quasi-norm regularization
for low-rank tensor completion and tensor robust principal component
analysis. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Grhi800jVz">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nuclear norm and Schatten-$p$ quasi-norm are popular rank proxies in low-rank matrix recovery. However, computing the nuclear norm or Schatten-$p$ quasi-norm of a tensor is hard in both theory and practice, hindering their application to low-rank tensor completion (LRTC) and tensor robust principal component analysis (TRPCA). In this paper, we propose a new class of tensor rank regularizers based on the Euclidean norms of the CP component vectors of a tensor and show that these regularizers are monotonic transformations of tensor Schatten-$p$ quasi-norm. This connection enables us to minimize the Schatten-$p$ quasi-norm in LRTC and TRPCA implicitly via the component vectors. The method scales to big tensors and provides an arbitrarily sharper rank proxy for low-rank tensor recovery compared to the nuclear norm. On the other hand, we study the generalization abilities of LRTC with the Schatten-$p$ quasi-norm regularizer and LRTC with the proposed regularizers. The theorems show that a relatively sharper regularizer leads to a tighter error bound, which is consistent with our numerical results. Particularly, we prove that for LRTC with Schatten-$p$ quasi-norm regularizer on $d$-order tensors, $p=1/d$ is always better than any $p&gt;1/d$ in terms of the generalization ability. We also provide a recovery error bound to verify the usefulness of small $p$ in the Schatten-$p$ quasi-norm for TRPCA. Numerical results on synthetic data and real data demonstrate the effectiveness of the regularization methods and theorems.},
  archive      = {J_TMLR},
  author       = {Jicong Fan and Lijun Ding and Chengrun Yang and Zhao Zhang and Madeleine Udell},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Euclidean-norm-induced schatten-p quasi-norm regularization for low-rank tensor completion and tensor robust principal component analysis},
  url          = {https://openreview.net/forum?id=Grhi800jVz},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attention beats concatenation for conditioning neural
fields. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=GzqdMrFQsE">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural fields model signals by mapping coordinate inputs to sampled values. They are becoming an increasingly important backbone architecture across many fields from vision and graphics to biology and astronomy. In this paper, we explore the differences between common conditioning mechanisms within these networks, an essential ingredient in shifting neural fields from memorization of signals to generalization, where the set of signals lying on a manifold is modelled jointly. In particular, we are interested in the scaling behaviour of these mechanisms to increasingly high-dimensional conditioning variables. As we show in our experiments, high-dimensional conditioning is key to modelling complex data distributions, thus it is important to determine what architecture choices best enable this when working on such problems. To this end, we run experiments modelling 2D, 3D, and 4D signals with neural fields, employing concatenation, hyper-network, and attention-based conditioning strategies -- a necessary but laborious effort that has not been performed in the literature. We find that attention-based conditioning outperforms other approaches in a variety of settings.},
  archive      = {J_TMLR},
  author       = {Daniel Rebain and Mark J. Matthews and Kwang Moo Yi and Gopal Sharma and Dmitry Lagun and Andrea Tagliasacchi},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Attention beats concatenation for conditioning neural fields},
  url          = {https://openreview.net/forum?id=GzqdMrFQsE},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Calibrate and debias layer-wise sampling for graph
convolutional networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=JyKNuoZGux">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple sampling-based methods have been developed for approximating and accelerating node embedding aggregation in graph convolutional networks (GCNs) training. Among them, a layer-wise approach recursively performs importance sampling to select neighbors jointly for existing nodes in each layer. This paper revisits the approach from a matrix approximation perspective, and identifies two issues in the existing layer-wise sampling methods: suboptimal sampling probabilities and estimation biases induced by sampling without replacement. To address these issues, we accordingly propose two remedies: a new principle for constructing sampling probabilities and an efficient debiasing algorithm. The improvements are demonstrated by extensive analyses of estimation variance and experiments on common benchmarks. Code and algorithm implementations are publicly available at \url{https://github.com/ychen-stat-ml/GCN-layer-wise-sampling}.},
  archive      = {J_TMLR},
  author       = {Yifan Chen and Tianning Xu and Dilek Hakkani-Tur and Di Jin and Yun Yang and Ruoqing Zhu},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Calibrate and debias layer-wise sampling for graph convolutional networks},
  url          = {https://openreview.net/forum?id=JyKNuoZGux},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Investigating action encodings in recurrent neural networks
in reinforcement learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=K6g4MbAC1r">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building and maintaining state to learn policies and value functions is critical for deploying reinforcement learning (RL) agents in the real world. Recurrent neural networks (RNNs) have become a key point of interest for the state-building problem, and several large-scale reinforcement learning agents incorporate recurrent networks. While RNNs have become a mainstay in many RL applications, many key design choices and implementation details responsible for performance improvements are often not reported. In this work, we discuss one axis on which RNN architectures can be (and have been) modified for use in RL. Specifically, we look at how action information can be incorporated into the state update function of a recurrent cell. We discuss several choices in using action information and empirically evaluate the resulting architectures on a set of illustrative domains. Finally, we discuss future work in developing recurrent cells and discuss challenges specific to the RL setting.},
  archive      = {J_TMLR},
  author       = {Matthew Kyle Schlegel and Volodymyr Tkachuk and Adam M White and Martha White},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Investigating action encodings in recurrent neural networks in reinforcement learning},
  url          = {https://openreview.net/forum?id=K6g4MbAC1r},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recognition models to learn dynamics from partial
observations with neural ODEs. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=LTAdaRM29K">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying dynamical systems from experimental data is a notably difficult task. Prior knowledge generally helps, but the extent of this knowledge varies with the application, and customized models are often needed. Neural ordinary differential equations can be written as a flexible framework for system identification and can incorporate a broad spectrum of physical insight, giving physical interpretability to the resulting latent space. In the case of partial observations, however, the data points cannot directly be mapped to the latent state of the ODE. Hence, we propose to design recognition models, in particular inspired by nonlinear observer theory, to link the partial observations to the latent state. We demonstrate the performance of the proposed approach on numerical simulations and on an experimental dataset from a robotic exoskeleton.},
  archive      = {J_TMLR},
  author       = {Mona Buisson-Fenet and Valery Morgenthaler and Sebastian Trimpe and Florent Di Meglio},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Recognition models to learn dynamics from partial observations with neural ODEs},
  url          = {https://openreview.net/forum?id=LTAdaRM29K},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Implicit ensemble training for efficient and robust
multiagent reinforcement learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=LfTukxzxTj">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important issue in competitive multiagent scenarios is the distribution mismatch between training and testing caused by variations in other agents&#39; policies. As a result, policies optimized during training are typically sub-optimal (possibly very poor) in testing. Ensemble training is an effective approach for learning robust policies that avoid significant performance degradation when competing against previously unseen opponents. A large ensemble can improve diversity during the training, which leads to more robust learning. However, the computation and memory requirements increase linearly with respect to the ensemble size, which is not scalable as the ensemble size required for learning robust policy can be quite large. This paper proposes a novel parameterization of a policy ensemble based on a deep latent variable model with a multi-task network architecture, which represents an ensemble of policies implicitly within a single network. Our implicit ensemble training (IET) approach strikes a better trade-off between ensemble diversity and scalability compared to standard ensemble training. We demonstrate in several competitive multiagent scenarios in the board game and robotic domains that our new approach improves robustness against unseen adversarial opponents while achieving higher sample-efficiency and less computation.},
  archive      = {J_TMLR},
  author       = {Macheng Shen and JONATHAN P HOW},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Implicit ensemble training for efficient and robust multiagent reinforcement learning},
  url          = {https://openreview.net/forum?id=LfTukxzxTj},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gradient-adjusted incremental target propagation provides
effective credit assignment in deep neural networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Lx19EyKX77">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many of the recent advances in the field of artificial intelligence have been fueled by the highly successful backpropagation of error (BP) algorithm, which efficiently solves the credit assignment problem in artificial neural networks. However, it is unlikely that BP is implemented in its usual form within biological neural networks, because of its reliance on non-local information in propagating error gradients. Since biological neural networks are capable of highly efficient learning and responses from BP trained models can be related to neural responses, it seems reasonable that a biologically viable approximation of BP underlies synaptic plasticity in the brain. Gradient-adjusted incremental target propagation (GAIT-prop or GP for short) has recently been derived directly from BP and has been shown to successfully train networks in a more biologically plausible manner. However, so far, GP has only been shown to work on relatively low-dimensional problems, such as handwritten-digit recognition. This work addresses some of the scaling issues in GP and shows it to perform effective multi-layer credit assignment in deeper networks and on the much more challenging ImageNet dataset.},
  archive      = {J_TMLR},
  author       = {Sander Dalm and Nasir Ahmad and Luca Ambrogioni and Marcel van Gerven},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Gradient-adjusted incremental target propagation provides effective credit assignment in deep neural networks},
  url          = {https://openreview.net/forum?id=Lx19EyKX77},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FedDAG: Federated DAG structure learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=MzWgBjZ6Le">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To date, most directed acyclic graphs (DAGs) structure learning approaches require data to be stored in a central server. However, due to the consideration of privacy protection, data owners gradually refuse to share their personalized raw data to avoid private information leakage, making this task more troublesome by cutting off the first step. Thus, a puzzle arises: how do we discover the underlying DAG structure from decentralized data? In this paper, focusing on the additive noise models (ANMs) assumption of data generation, we take the first step in developing a gradient-based learning framework named FedDAG, which can learn the DAG structure without directly touching the local data and also can naturally handle the data heterogeneity. Our method benefits from a two-level structure of each local model. The first level structure learns the edges and directions of the graph and communicates with the server to get the model information from other clients during the learning procedure, while the second level structure approximates the mechanisms among variables and personally updates on its own data to accommodate the data heterogeneity. Moreover, FedDAG formulates the overall learning task as a continuous optimization problem by taking advantage of an equality acyclicity constraint, which can be solved by gradient descent methods to boost the searching efficiency. Extensive experiments on both synthetic and real-world datasets verify the efficacy of the proposed method.},
  archive      = {J_TMLR},
  author       = {Erdun Gao and Junjia Chen and Li Shen and Tongliang Liu and Mingming Gong and Howard Bondell},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FedDAG: Federated DAG structure learning},
  url          = {https://openreview.net/forum?id=MzWgBjZ6Le},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal convergence rates of deep convolutional neural
networks: Additive ridge functions. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Q6ZXm7VBFY">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks have shown impressive abilities in many applications, especially those related to the classification tasks. However, for the regression problem, the abilities of convolutional structures have not been fully understood, and further investigation is needed. In this paper, we consider the mean squared error analysis for deep convolutional neural networks. We show that, for additive ridge functions, convolutional neural networks followed by one fully connected layer with ReLU activation functions can reach optimal mini-max rates (up to a log factor). The input dimension only appears in the constant of convergence rates. This work shows the statistical optimality of convolutional neural networks and may shed light on why convolutional neural networks are able to behave well for high dimensional input.},
  archive      = {J_TMLR},
  author       = {Zhiying Fang and Guang Cheng},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Optimal convergence rates of deep convolutional neural networks: Additive ridge functions},
  url          = {https://openreview.net/forum?id=Q6ZXm7VBFY},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hidden heterogeneity: When to choose similarity-based
calibration. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=RA0TDqt3hC">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trustworthy classifiers are essential to the adoption of machine learning predictions in many real-world settings. The predicted probability of possible outcomes can inform high-stakes decision making, particularly when assessing the expected value of alternative decisions or the risk of bad outcomes. These decisions require well-calibrated probabilities, not just the correct prediction of the most likely class. Black-box classifier calibration methods can improve the reliability of a classifier’s output without requiring retraining. However, these methods are unable to detect subpopulations where calibration could also improve prediction accuracy. Such subpopulations are said to exhibit “hidden heterogeneity” (HH), because the original classifier did not detect them. The paper proposes a quantitative measure for HH. It also introduces two similarity-weighted calibration methods that can address HH by adapting locally to each test item: SWC weights the calibration set by similarity to the test item, and SWC-HH explicitly incorporates hidden heterogeneity to filter the calibration set. Experiments show that the improvements in calibration achieved by similarity-based calibration methods correlate with the amount of HH present and, given sufficient calibration data, generally exceed calibration achieved by global methods. HH can therefore serve as a useful diagnostic tool for identifying when local calibration methods would be beneficial.},
  archive      = {J_TMLR},
  author       = {Kiri L. Wagstaff and Thomas G Dietterich},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Hidden heterogeneity: When to choose similarity-based calibration},
  url          = {https://openreview.net/forum?id=RA0TDqt3hC},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the infinite-depth limit of finite-width neural networks.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=RbLsYz1Az9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the infinite-depth limit of finite-width residual neural networks with random Gaussian weights. With proper scaling, we show that by fixing the width and taking the depth to infinity, the pre-activations converge in distribution to a zero-drift diffusion process. Unlike the infinite-width limit where the pre-activation converge weakly to a Gaussian random variable, we show that the infinite-depth limit yields different distributions depending on the choice of the activation function. We document two cases where these distributions have closed-form (different) expressions. We further show an intriguing change-of-regime phenomenon of the post-activation norms when the width increases from 3 to 4. Lastly, we study the sequential limit infinite-depth-then-infinite-width, and compare it with the more commonly studied infinite-width-then-infinite-depth limit.},
  archive      = {J_TMLR},
  author       = {Soufiane Hayou},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the infinite-depth limit of finite-width neural networks},
  url          = {https://openreview.net/forum?id=RbLsYz1Az9},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Benchmarks and algorithms for offline preference-based
reward learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=TGuXXlbKsn">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning a reward function from human preferences is challenging as it typically requires having a high-fidelity simulator or using expensive and potentially unsafe actual physical rollouts in the environment. However, in many tasks the agent might have access to offline data from related tasks in the same target environment. While offline data is increasingly being used to aid policy optimization via offline RL, our observation is that it can be a surprisingly rich source of information for preference learning as well. We propose an approach that uses an offline dataset to craft preference queries via pool-based active learning, learns a distribution over reward functions, and optimizes a corresponding policy via offline RL. Crucially, our proposed approach does not require actual physical rollouts or an accurate simulator for either the reward learning or policy optimization steps. To test our approach, we first evaluate existing offline RL benchmarks for their suitability for offline reward learning. Surprisingly, for many offline RL domains, we find that simply using a trivial reward function results good policy performance, making these domains ill-suited for evaluating learned rewards. To address this, we identify a subset of existing offline RL benchmarks that are well suited for offline reward learning and also propose new offline apprenticeship learning benchmarks which allow for more open-ended behaviors. When evaluated on this curated set of domains, our empirical results suggest that combining offline RL with learned human preferences can enable an agent to learn to perform novel tasks that were not explicitly shown in the offline data.},
  archive      = {J_TMLR},
  author       = {Daniel Shin and Anca Dragan and Daniel S. Brown},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Benchmarks and algorithms for offline preference-based reward learning},
  url          = {https://openreview.net/forum?id=TGuXXlbKsn},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards large scale transfer learning for differentially
private image classification. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Uu8WwCFpQv">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differentially Private Stochastic Gradient Descent (DP-SGD) has emerged as a popular private training algorithm. Unfortunately, the computational cost of training large-scale models with DP-SGD is substantially higher than non-private training. This is further exacerbated by the fact that increasing the number of parameters leads to larger degradation in utility with DP. In this work, we zoom in on the ImageNet dataset and demonstrate that, similar to the non-private case, pre-training over-parameterized models on a large public dataset can lead to substantial gains when the models are finetuned privately. Moreover, by systematically comparing private and non-private models across a range of large batch sizes, we find that similar to the non-private setting, the choice of optimizer can further improve performance substantially with DP. By using the LAMB optimizer, we saw improvement of up to 20$\%$ points (absolute). We also show that finetuning just the last layer for a \emph{single step} in the full batch setting, combined with extremely small-scale (near-zero) initialization leads to both SOTA results of 81.7 $\%$ under a wide privacy budget range of $\epsilon \in [4, 10]$ and $\delta$ = $10^{-6}$ while minimizing the computational overhead substantially. Finally, we present additional results on CIFAR-10 and CIFAR-100, surpassing previous state of the art by leveraging transfer learning with our recommendations.},
  archive      = {J_TMLR},
  author       = {Harsh Mehta and Abhradeep Guha Thakurta and Alexey Kurakin and Ashok Cutkosky},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards large scale transfer learning for differentially private image classification},
  url          = {https://openreview.net/forum?id=Uu8WwCFpQv},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PCPs: Patient cardiac prototypes to probe AI-based medical
diagnoses, distill datasets, and retrieve patients. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=X1pjWMCMB0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical deep learning systems often generate population-based and opaque medical diagnoses. This is in contrast to how primary care physicians make decisions, often adapting population-based protocols to the unique patient under consideration. Inspired by the workflow of such physicians, we develop a framework for learning embeddings, referred to as patient cardiac prototypes (PCPs), which capture information that is unique to an individual patient&#39;s electrocardiogram (ECG) data. Through rigorous evaluation on three publicly-available ECG datasets, we show that PCPs allow researchers to inspect why a particular diagnosis was made. We also demonstrate that PCPs are effective dataset distillers, where they can be used to train a model in lieu of a dataset orders of magnitude larger to achieve comparable performance. We show that PCPs can also be exploited to retrieve similar patient data across clinical databases. Our framework contributes to the development of transparent and patient-specific clinical deep learning systems.},
  archive      = {J_TMLR},
  author       = {Dani Kiyasseh and Tingting Zhu and David A. Clifton},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {PCPs: Patient cardiac prototypes to probe AI-based medical diagnoses, distill datasets, and retrieve patients},
  url          = {https://openreview.net/forum?id=X1pjWMCMB0},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Beyond information gain: An empirical benchmark for
low-switching-cost reinforcement learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Xq1sTZTQVm">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A ubiquitous requirement in many practical reinforcement learning (RL) applications is that the deployed policy that actually interacts with the environment cannot change frequently. Such an RL setting is called low-switching-cost RL, i.e., achieving the highest reward while reducing the number of policy switches during training. It has been a recent trend in theoretical RL research to develop provably efficient RL algorithms with low switching cost. The core idea in these theoretical works is to measure the information gain and switch the policy when the information gain is doubled. Despite of the theoretical advances, none of existing approaches have been validated empirically. We conduct the first empirical evaluation of different policy switching criteria on popular RL testbeds, including a medical treatment environment, the Atari games, and robotic control tasks. Surprisingly, although information-gain-based methods do recover the optimal rewards, they often lead to a substantially higher switching cost. By contrast, we find that a feature-based criterion, which has been largely ignored in the theoretical research, consistently produces the best performances over all the domains. We hope our benchmark could bring insights to the community and inspire future research. Our code and complete results can be found at https: // sites. google. com/ view/ low-switching-cost-rl},
  archive      = {J_TMLR},
  author       = {Shusheng Xu and Yancheng Liang and Yunfei Li and Simon Shaolei Du and Yi Wu},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Beyond information gain: An empirical benchmark for low-switching-cost reinforcement learning},
  url          = {https://openreview.net/forum?id=Xq1sTZTQVm},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robustness through data augmentation loss consistency.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=a1meaRy1bN">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While deep learning through empirical risk minimization (ERM) has succeeded at achieving human-level performance at a variety of complex tasks, ERM is not robust to distribution shifts or adversarial attacks. Synthetic data augmentation followed by empirical risk minimization (DA-ERM) is a simple and widely used solution to improve robustness in ERM. In addition, consistency regularization can be applied to further improve the robustness of the model by forcing the representation of the original sample and the augmented one to be similar. However, existing consistency regularization methods are not applicable to covariant data augmentation, where the label in the augmented sample is dependent on the augmentation function. For example, dialog state covaries with named entity when we augment data with a new named entity. In this paper, we propose data augmented loss invariant regularization (DAIR), a simple form of consistency regularization that is applied directly at the loss level rather than intermediate features, making it widely applicable to both invariant and covariant data augmentation regardless of network architecture, problem setup, and task. We apply DAIR to real-world learning problems involving covariant data augmentation: robust neural task-oriented dialog state tracking and robust visual question answering. We also apply DAIR to tasks involving invariant data augmentation: robust regression, robust classification against adversarial attacks, and robust ImageNet classification under distribution shift. Our experiments show that DAIR consistently outperforms ERM and DA-ERM with little marginal computational cost and sets new state-of-the-art results in several benchmarks involving covariant data augmentation. Our code of all experiments are available at: https://github.com/optimization-for-data-driven-science/DAIR.},
  archive      = {J_TMLR},
  author       = {Tianjian Huang and Shaunak Ashish Halbe and Chinnadhurai Sankar and Pooyan Amini and Satwik Kottur and Alborz Geramifard and Meisam Razaviyayn and Ahmad Beirami},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Robustness through data augmentation loss consistency},
  url          = {https://openreview.net/forum?id=a1meaRy1bN},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SMILE: Sample-to-feature mixup for efficient transfer
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=czgMCpvrDM">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the performance of deep learning, mixup has been proposed to force the neural networks favoring simple linear behaviors in-between training samples. Performing mixup for transfer learning with pre-trained models however is not that simple,  a high capacity pre-trained model with a large fully-connected (FC) layer could easily overfit to the target dataset even with samples-to-labels mixed up. In this work, we propose SMILE — Sample-to-feature Mixup for Efficient Transfer Learning. With mixed images as inputs, SMILE regularizes the outputs of CNN feature extractors to learn from the mixed feature vectors of inputs, in addition to the mixed labels. SMILE incorporates a mean teacher to provide the surrogate &quot;ground truth&quot; for mixed feature vectors. The sample-to-feature mixup regularizer is imposed both on deep features for the target domain and classifier outputs for the source domain, bounding the linearity in-between samples for target tasks. Extensive experiments have been done to verify the performance improvement made by SMILE, in comparisons with a wide spectrum of transfer learning algorithms, including fine-tuning, L$^2$-SP, DELTA, BSS, RIFLE, Co-Tuning and RegSL, even with mixup strategies combined. Ablation studies show that the vanilla sample-to-label mixup strategies could marginally increase the linearity in-between training samples but lack of generalizability, while SMILE significantly improves the mixup effects in both label and feature spaces with both training and testing datasets. The empirical observations backup our design intuition and purposes.},
  archive      = {J_TMLR},
  author       = {Xingjian Li and Haoyi Xiong and Cheng-zhong Xu and Dejing Dou},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SMILE: Sample-to-feature mixup for efficient transfer learning},
  url          = {https://openreview.net/forum?id=czgMCpvrDM},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A ranking game for imitation learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=d3rHk4VAf0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new framework for imitation learning---treating imitation as a two-player ranking-based game between a policy and a reward. In this game, the reward agent learns to satisfy pairwise performance rankings between behaviors, while the policy agent learns to maximize this reward. In imitation learning, near-optimal expert data can be difficult to obtain, and even in the limit of infinite data cannot imply a total ordering over trajectories as preferences can. On the other hand, learning from preferences alone is challenging as a large number of preferences are required to infer a high-dimensional reward function, though preference data is typically much easier to collect than expert demonstrations. The classical inverse reinforcement learning (IRL) formulation learns from expert demonstrations but provides no mechanism to incorporate learning from offline preferences and vice versa. We instantiate the proposed ranking-game framework with a novel ranking loss giving an algorithm that can simultaneously learn from expert demonstrations and preferences, gaining the advantages of both modalities. Our experiments show that the proposed method achieves state-of-the-art sample efficiency and can solve previously unsolvable tasks in the Learning from Observation (LfO) setting.},
  archive      = {J_TMLR},
  author       = {Harshit Sikchi and Akanksha Saran and Wonjoon Goo and Scott Niekum},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A ranking game for imitation learning},
  url          = {https://openreview.net/forum?id=d3rHk4VAf0},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Linking neural collapse and l2 normalization with improved
out-of-distribution detection in deep neural networks. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=fjkN5Ur2d6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a simple modification to standard ResNet architectures--L2 normalization over feature space--that substantially improves out-of-distribution (OoD) performance on the previously proposed Deep Deterministic Uncertainty (DDU) benchmark. We show that this change also induces early Neural Collapse (NC), an effect linked to better OoD performance. Our method achieves comparable or superior OoD detection scores and classification accuracy in a small fraction of the training time of the benchmark. Additionally, it substantially improves worst case OoD performance over multiple, randomly initialized models. Though we do not suggest that NC is the sole mechanism or a comprehensive explanation for OoD behaviour in deep neural networks (DNN), we believe NC&#39;s simple mathematical and geometric structure can provide a framework for analysis of this complex phenomenon in future work.},
  archive      = {J_TMLR},
  author       = {Jarrod Haas and William Yolland and Bernhard T Rabus},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Linking neural collapse and l2 normalization with improved out-of-distribution detection in deep neural networks},
  url          = {https://openreview.net/forum?id=fjkN5Ur2d6},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Named tensor notation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=hVT7SHlilx">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a notation for tensors with named axes, which relieves the author, reader, and future implementers of machine learning models from the burden of keeping track of the order of axes and the purpose of each. The notation makes it easy to lift operations on low-order tensors to higher order ones, for example, from images to minibatches of images, or from an attention mechanism to multiple attention heads. After a brief overview and formal definition of the notation, we illustrate it through several examples from modern machine learning, from building blocks like attention and convolution to full models like Transformers and LeNet. We then discuss differential calculus in our notation and compare with some alternative notations. Our proposals build on ideas from many previous papers and software libraries. We hope that this document will encourage more authors to use named tensors, resulting in clearer papers and more precise implementations.},
  archive      = {J_TMLR},
  author       = {David Chiang and Alexander M Rush and Boaz Barak},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Named tensor notation},
  url          = {https://openreview.net/forum?id=hVT7SHlilx},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bounding generalization error with input compression: An
empirical study with infinite-width networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=jbZEUtULft">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the Generalization Error (GE) of Deep Neural Networks (DNNs) is an important task that often relies on availability of held-out data. The ability to better predict GE based on a single training set may yield overarching DNN design principles to reduce a reliance on trial-and-error, along with other performance assessment advantages. In search of a quantity relevant to GE, we investigate the Mutual Information (MI) between the input and final layer representations, using the infinite-width DNN limit to bound MI. An existing input compression-based GE bound is used to link MI and GE. To the best of our knowledge, this represents the first empirical study of this bound. In our attempt to empirically stress test the theoretical bound, we find that it is often tight for best-performing models. Furthermore, it detects randomization of training labels in many cases, reflects test-time perturbation robustness, and works well given only few training samples. These results are promising given that input compression is broadly applicable where MI can be estimated with confidence.},
  archive      = {J_TMLR},
  author       = {Angus Galloway and Anna Golubeva and Mahmoud Salem and Mihai Nica and Yani Ioannou and Graham W. Taylor},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bounding generalization error with input compression: An empirical study with infinite-width networks},
  url          = {https://openreview.net/forum?id=jbZEUtULft},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GSR: A generalized symbolic regression approach.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=lheUXtDNvP">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying the mathematical relationships that best describe a dataset remains a very challenging problem in machine learning, and is known as Symbolic Regression (SR). In contrast to neural networks which are often treated as black boxes, SR attempts to gain insight into the underlying relationships between the independent variables and the target variable of a given dataset by assembling analytical functions. In this paper, we present GSR, a Generalized Symbolic Regression approach, by modifying the conventional SR optimization problem formulation, while keeping the main SR objective intact. In GSR, we infer mathematical relationships between the independent variables and some transformation of the target variable. We constrain our search space to a weighted sum of basis functions, and propose a genetic programming approach with a matrix-based encoding scheme. We show that our GSR method is competitive with strong SR benchmark methods, achieving promising experimental performance on the well-known SR benchmark problem sets. Finally, we highlight the strengths of GSR by introducing SymSet, a new SR benchmark set which is more challenging relative to the existing benchmarks.},
  archive      = {J_TMLR},
  author       = {Tony Tohme and Dehong Liu and KAMAL YOUCEF-TOUMI},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {GSR: A generalized symbolic regression approach},
  url          = {https://openreview.net/forum?id=lheUXtDNvP},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal threshold labeling for ordinal regression methods.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=mHSAy1n65Z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For an ordinal regression task, a classification task for ordinal data, one-dimensional transformation (1DT)-based methods are often employed since they are considered to capture the ordinal relation of ordinal data well. They learn a 1DT of the observation of the explanatory variables so that an observation with a larger class label tends to have a larger value of the 1DT, and classify the observation by labeling that learned 1DT. In this paper, we study the labeling procedure for 1DT-based methods, which have not been sufficiently discussed in existing studies. While regression-based methods and classical threshold methods conventionally use threshold labelings, which label a learned 1DT according to the rank of the interval to which the 1DT belongs among intervals on the real line separated by threshold parameters, we prove that likelihood-based labeling used in popular statistical 1DT-based methods is also a threshold labeling in typical usages. Moreover, we show that these threshold labelings can be sub-optimal ones depending on the learning result of the 1DT and the task under consideration. On the basis of these findings, we propose to apply empirical optimal threshold labeling, which is a threshold labeling that uses threshold parameters minimizing the empirical task risk for a learned 1DT, to those methods. In experiments with real-world datasets, changing the labeling procedure of existing 1DT-based methods to the proposed one improved the classification performance in many tried cases.},
  archive      = {J_TMLR},
  author       = {Ryoya Yamasaki},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Optimal threshold labeling for ordinal regression methods},
  url          = {https://openreview.net/forum?id=mHSAy1n65Z},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fairness and robustness in anti-causal prediction.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=mrTXGDZns2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robustness to distribution shift and fairness have independently emerged as two important desiderata required of modern machine learning models. While these two desiderata seem related, the connection between them is often unclear in practice. Here, we discuss these connections through a causal lens, focusing on anti-causal prediction tasks, where the input to a classifier (e.g., an image) is assumed to be generated as a function of the target label and the protected attribute. By taking this perspective, we draw explicit connections between a common fairness criterion - separation - and a common notion of robustness - risk invariance. These connections provide new motivation for applying the separation criterion in anticausal settings, and inform old discussions regarding fairness-performance tradeoffs. In addition, our findings suggest that robustness-motivated approaches can be used to enforce separation, and that they often work better in practice than methods designed to directly enforce separation. Using a medical dataset, we empirically validate our findings on the task of detecting pneumonia from X-rays, in a setting where differences in prevalence across sex groups motivates a fairness mitigation. Our findings highlight the importance of considering causal structure when choosing and enforcing fairness criteria.},
  archive      = {J_TMLR},
  author       = {Maggie Makar and Alexander D&#39;Amour},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Fairness and robustness in anti-causal prediction},
  url          = {https://openreview.net/forum?id=mrTXGDZns2},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dropped scheduled task: Mitigating negative transfer in
multi-task learning using dynamic task dropping. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=myjAVQrRxS">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Multi-Task Learning (MTL), K distinct tasks are jointly optimized. With the varying nature and complexities of tasks, few tasks might dominate learning. For other tasks, their respective performances may get compromised due to a negative transfer from dominant tasks. We propose a Dropped-Scheduled Task (DST) algorithm, which probabilistically “drops” specific tasks during joint optimization while scheduling others to reduce negative transfer. For each task, a scheduling probability is decided based on four different metrics: (i) task depth, (ii) number of ground-truth samples per task, (iii) amount of training completed, and (iv) task stagnancy. Based on the scheduling probability, specific tasks get joint computation cycles while others are “dropped”. To demonstrate the effectiveness of the proposed DST algorithm, we perform multi-task learning on three applications and two architectures. Across unilateral (single input) and bilateral (multiple input) multi-task net- works, the chosen applications are (a) face (AFLW), (b) fingerprint (IIITD MOLF, MUST, and NIST SD27), and (c) character recognition (Omniglot) applications. Experimental results show that the proposed DST algorithm has the minimum negative transfer and overall least errors across different state-of-the-art algorithms and tasks.},
  archive      = {J_TMLR},
  author       = {Aakarsh Malhotra and Mayank Vatsa and Richa Singh},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Dropped scheduled task: Mitigating negative transfer in multi-task learning using dynamic task dropping},
  url          = {https://openreview.net/forum?id=myjAVQrRxS},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online learning for prediction via covariance fitting:
Computation, performance and robustness. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=nAr9PhyEbQ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of online prediction using linear smoothers that are functions of a nominal covariance model with unknown parameters. The model parameters are often learned using cross-validation or maximum-likelihood techniques. But when training data arrives in a streaming fashion, the implementation of such techniques can only be done in an approximate manner. Even if this limitation could be overcome, there appears to be no clear-cut results on the statistical properties of the resulting predictor. Here we consider a covariance-fitting method to learn the model parameters, which was initially developed for spectral estimation. We first show that the use of this approach results in a computationally efficient online learning method in which the resulting predictor can be updated sequentially. We then prove that, with high probability, its out-of-sample error approaches the optimal level at a root-$n$ rate, where $n$ is the number of data samples. This is so even if the nominal covariance model is misspecified. Moreover, we show that the resulting predictor enjoys two robustness properties. First, it corresponds to a predictor that minimizes the out-of-sample error with respect to the least favourable distribution within a given Wasserstein distance from the empirical distribution. Second, it is robust against errors in the covariate training data. We illustrate the performance of the proposed method in a numerical experiment.},
  archive      = {J_TMLR},
  author       = {Muhammad Osama and Dave Zachariah and Peter Stoica and Thomas B. Schön},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Online learning for prediction via covariance fitting: Computation, performance and robustness},
  url          = {https://openreview.net/forum?id=nAr9PhyEbQ},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Risk sensitive dead-end identification in safety-critical
offline reinforcement learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=oKlEOT83gI">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In safety-critical decision-making scenarios being able to identify worst-case outcomes, or dead-ends is crucial in order to develop safe and reliable policies in practice. These situations are typically rife with uncertainty due to unknown or stochastic characteristics of the environment as well as limited offline training data. As a result, the value of a decision at any time point should be based on the distribution of its anticipated effects. We propose a framework to identify worst-case decision points, by explicitly estimating distributions of the expected return of a decision. These estimates enable earlier indication of dead-ends in a manner that is tunable based on the risk tolerance of the designed task. We demonstrate the utility of Distributional Dead-end Discovery (DistDeD) in a toy domain as well as when assessing the risk of severely ill patients in the intensive care unit reaching a point where death is unavoidable. We find that DistDeD significantly improves over prior discovery approaches, providing indications of the risk 10 hours earlier on average as well as increasing detection by 20%.},
  archive      = {J_TMLR},
  author       = {Taylor W. Killian and Sonali Parbhoo and Marzyeh Ghassemi},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Risk sensitive dead-end identification in safety-critical offline reinforcement learning},
  url          = {https://openreview.net/forum?id=oKlEOT83gI},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Proportional fairness in federated learning. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=ryUHgEdWCQ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasingly broad deployment of federated learning (FL) systems in the real world, it is critical but challenging to ensure fairness in FL, i.e. reasonably satisfactory performances for each of the numerous diverse clients. In this work, we introduce and study a new fairness notion in FL, called proportional fairness (PF), which is based on the relative change of each client&#39;s performance. From its connection with the bargaining games, we propose PropFair, a novel and easy-to-implement algorithm for finding proportionally fair solutions in FL, and study its convergence properties. Through extensive experiments on vision and language datasets, we demonstrate that PropFair can approximately find PF solutions, and it achieves a good balance between the average performances of all clients and of the worst 10% clients.},
  archive      = {J_TMLR},
  author       = {Guojun Zhang and Saber Malekmohammadi and Xi Chen and Yaoliang Yu},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Proportional fairness in federated learning},
  url          = {https://openreview.net/forum?id=ryUHgEdWCQ},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Communication-efficient distributionally robust
decentralized learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=tnRRHzZPMq">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized learning algorithms empower interconnected devices to share data and computational resources to collaboratively train a machine learning model without the aid of a central coordinator. In the case of heterogeneous data distributions at the network nodes, collaboration can yield predictors with unsatisfactory performance for a subset of the devices. For this reason, in this work, we consider the formulation of a distributionally robust decentralized learning task and we propose a decentralized single loop gradient descent/ascent algorithm (AD-GDA) to directly solve the underlying minimax optimization problem. We render our algorithm communication-efficient by employing a compressed consensus scheme and we provide convergence guarantees for smooth convex and non-convex loss functions. Finally, we corroborate the theoretical findings with empirical results that highlight AD-GDA&#39;s ability to provide unbiased predictors and to greatly improve communication efficiency compared to existing distributionally robust algorithms.},
  archive      = {J_TMLR},
  author       = {Matteo Zecchin and Marios Kountouris and David Gesbert},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Communication-efficient distributionally robust decentralized learning},
  url          = {https://openreview.net/forum?id=tnRRHzZPMq},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning representations for pixel-based control: What
matters and why? <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=wIXHG8LZ2w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning representations for pixel-based control has garnered significant attention recently in reinforcement learning. A wide range of methods have been proposed to enable efficient learning, leading to sample complexities similar to those in the full state setting. However, moving beyond carefully curated pixel data sets (centered crop, appropriate lighting, clear background, etc.) remains challenging. In this paper, we adopt a more difficult setting, incorporating background distractors, as a first step towards addressing this challenge. We start by exploring a simple baseline approach that does not use metric-based learning, data augmentations, world-model learning, or contrastive learning. We then analyze when and why previously proposed methods are likely to fail or reduce to the same performance as the baseline in this harder setting and why we should think carefully about extending such methods beyond the well curated environments. Our results show that finer categorization of benchmarks on the basis of characteristics like density of reward, planning horizon of the problem, presence of task-irrelevant components, etc., is crucial in evaluating algorithms. Based on these observations, we propose different metrics to consider when evaluating an algorithm on benchmark tasks. We hope such a data-centric view can motivate researchers to rethink representation learning when investigating how to best apply RL to real-world tasks. Code available: https://github.com/UtkarshMishra04/pixel-representations-RL},
  archive      = {J_TMLR},
  author       = {Manan Tomar and Utkarsh Aashu Mishra and Amy Zhang and Matthew E. Taylor},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning representations for pixel-based control: What matters and why?},
  url          = {https://openreview.net/forum?id=wIXHG8LZ2w},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Revisiting adversarial training for the worst-performing
class. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=wkecshlYxI">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite progress in adversarial training (AT), there is a substantial gap between the top-performing and worst-performing classes in many datasets. For example, on CIFAR10, the accuracies for the best and worst classes are 74% and 23%, respectively. We argue that this gap can be reduced by explicitly optimizing for the worst-performing class, resulting in a min-max-max optimization formulation. Our method, called class focused online learning (CFOL), includes high probability convergence guarantees for the worst class loss and can be easily integrated into existing training setups with minimal computational overhead. We demonstrate an improvement to 32% in the worst class accuracy on CIFAR10, and we observe consistent behavior across CIFAR100 and STL10. Our study highlights the importance of moving beyond average accuracy, which is particularly important in safety-critical applications.},
  archive      = {J_TMLR},
  author       = {Thomas Pethick and Grigorios Chrysos and Volkan Cevher},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Revisiting adversarial training for the worst-performing class},
  url          = {https://openreview.net/forum?id=wkecshlYxI},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BIGRoC: Boosting image generation via a robust classifier.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=y7RGNXhGSR">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interest of the machine learning community in image synthesis has grown significantly in recent years, with the introduction of a wide range of deep generative models and means for training them. In this work, we propose a general model-agnostic technique for improving the image quality and the distribution fidelity of generated images obtained by any generative model. Our method, termed BIGRoC (Boosting Image Generation via a Robust Classifier), is based on a post-processing procedure via the guidance of a given robust classifier and without a need for additional training of the generative model. Given a synthesized image, we propose to update it through projected gradient steps over the robust classifier to refine its recognition. We demonstrate this post-processing algorithm on various image synthesis methods and show a significant quantitative and qualitative improvement on CIFAR-10 and ImageNet. Surprisingly, although BIGRoC is the first model agnostic among refinement approaches and requires much less information, it outperforms competitive methods. Specifically, BIGRoC improves the image synthesis best performing diffusion model on ImageNet $128\times128$ by 14.81%, attaining an FID score of 2.53 and on $256\times256$ by 7.87%, achieving an FID of 3.63. Moreover, we conduct an opinion survey, according to which humans significantly prefer our method&#39;s outputs.},
  archive      = {J_TMLR},
  author       = {Roy Ganz and Michael Elad},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {BIGRoC: Boosting image generation via a robust classifier},
  url          = {https://openreview.net/forum?id=y7RGNXhGSR},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PolyViT: Co-training vision transformers on images, videos
and audio. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=zKnqZeUCLO">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Can we train a single transformer model capable of processing multiple modalities and datasets, whilst sharing almost all of its learnable parameters? We present PolyViT, a model trained on images, audio and video to answer this question. PolyViT consists of a single transformer backbone, modality-specific tokenizers and task-specific output heads. By co-training on different tasks of a single modality, we are able to achieve significant accuracy improvements on 5 standard video- and audio-classification datasets. Furthermore, co-training PolyViT on multiple modalities and tasks leads to a parameter-efficient model which generalizes across multiple domains. In particular, our multi-modal PolyViT trained on 9 datasets across 3 modalities uses 8.3 times fewer parameters and outperforms a state-of-the-art single-task baseline on 2 of these datasets, whilst achieving competitive performance on the others. Finally, this simple and practical approach necessitates less hyperparameter tuning as the per-task hyperparameters can be readily reused.},
  archive      = {J_TMLR},
  author       = {Valerii Likhosherstov and Anurag Arnab and Krzysztof Marcin Choromanski and Mario Lucic and Yi Tay and Mostafa Dehghani},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {PolyViT: Co-training vision transformers on images, videos and audio},
  url          = {https://openreview.net/forum?id=zKnqZeUCLO},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accelerated quality-diversity through massive parallelism.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=znNITCJyTI">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality-Diversity (QD) optimization algorithms are a well-known approach to generate large collections of diverse and high-quality solutions. However, derived from evolutionary computation, QD algorithms are population-based methods which are known to be data-inefficient and requires large amounts of computational resources. This makes QD algorithms slow when used in applications where solution evaluations are computationally costly. A common approach to speed up QD algorithms is to evaluate solutions in parallel, for instance by using physical simulators in robotics. Yet, this approach is limited to several dozen of parallel evaluations as most physics simulators can only be parallelized more with a greater number of CPUs. With recent advances in simulators that run on accelerators, thousands of evaluations can now be performed in parallel on single GPU/TPU. In this paper, we present QDax, an accelerated implementation of MAP-Elites which leverages massive parallelism on accelerators to make QD algorithms more accessible. We show that QD algorithms are ideal candidates to take advantage of progress in hardware acceleration. We demonstrate that QD algorithms can scale with massive parallelism to be run at interactive timescales without any significant effect on the performance. Results across standard optimization functions and four neuroevolution benchmark environments shows that experiment runtimes are reduced by two factors of magnitudes, turning days of computation into minutes. More surprising, we observe that reducing the number of generations by two orders of magnitude, and thus having significantly shorter lineage does not impact the performance of QD algorithms. These results show that QD can now benefit from hardware acceleration, which contributed significantly to the bloom of deep learning.},
  archive      = {J_TMLR},
  author       = {Bryan Lim and Maxime Allard and Luca Grillotti and Antoine Cully},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Accelerated quality-diversity through massive parallelism},
  url          = {https://openreview.net/forum?id=znNITCJyTI},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
