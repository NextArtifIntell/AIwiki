<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TOSEM_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tosem---55">TOSEM - 55</h2>
<ul>
<li><details>
<summary>
(2023). A survey of learning-based automated program repair.
<em>TOSEM</em>, <em>33</em>(2), 55:1–69. (<a
href="https://doi.org/10.1145/3631974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated program repair (APR) aims to fix software bugs automatically and plays a crucial role in software development and maintenance. With the recent advances in deep learning (DL), an increasing number of APR techniques have been proposed to leverage neural networks to learn bug-fixing patterns from massive open-source code repositories. Such learning-based techniques usually treat APR as a neural machine translation (NMT) task, where buggy code snippets (i.e., source language) are translated into fixed code snippets (i.e., target language) automatically. Benefiting from the powerful capability of DL to learn hidden relationships from previous bug-fixing datasets, learning-based APR techniques have achieved remarkable performance. In this article, we provide a systematic survey to summarize the current state-of-the-art research in the learning-based APR community. We illustrate the general workflow of learning-based APR techniques and detail the crucial components, including fault localization, patch generation, patch ranking, patch validation, and patch correctness phases. We then discuss the widely adopted datasets and evaluation metrics and outline existing empirical studies. We discuss several critical aspects of learning-based APR techniques, such as repair domains, industrial deployment, and the open science issue. We highlight several practical guidelines on applying DL techniques for future APR studies, such as exploring explainable patch generation and utilizing code features. Overall, our article can help researchers gain a comprehensive understanding about the achievements of the existing learning-based APR techniques and promote the practical application of these techniques. Our artifacts are publicly available at the repository: https://github.com/iSEngLab/AwesomeLearningAPR .},
  archive      = {J_TOSEM},
  author       = {Quanjun Zhang and Chunrong Fang and Yuxiang Ma and Weisong Sun and Zhenyu Chen},
  doi          = {10.1145/3631974},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {55:1–69},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {A survey of learning-based automated program repair},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Survey of code search based on deep learning.
<em>TOSEM</em>, <em>33</em>(2), 54:1–42. (<a
href="https://doi.org/10.1145/3628161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code writing is repetitive and predictable, inspiring us to develop various code intelligence techniques. This survey focuses on code search, that is, to retrieve code that matches a given natural language query by effectively capturing the semantic similarity between the query and code. Deep learning, being able to extract complex semantics information, has achieved great success in this field. Recently, various deep learning methods, such as graph neural networks and pretraining models, have been applied to code search with significant progress. Deep learning is now the leading paradigm for code search. In this survey, we provide a comprehensive overview of deep learning-based code search. We review the existing deep learning-based code search framework that maps query/code to vectors and measures their similarity. Furthermore, we propose a new taxonomy to illustrate the state-of-the-art deep learning-based code search in a three-step process: query semantics modeling, code semantics modeling, and matching modeling, which involves the deep learning model training. Finally, we suggest potential avenues for future research in this promising field.},
  archive      = {J_TOSEM},
  author       = {Yutao Xie and Jiayi Lin and Hande Dong and Lei Zhang and Zhonghai Wu},
  doi          = {10.1145/3628161},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {54:1–42},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Survey of code search based on deep learning},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FormatFuzzer: Effective fuzzing of binary file formats.
<em>TOSEM</em>, <em>33</em>(2), 53:1–29. (<a
href="https://doi.org/10.1145/3628157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective fuzzing of programs that process structured binary inputs, such as multimedia files, is a challenging task, since those programs expect a very specific input format. Existing fuzzers, however, are mostly format-agnostic, which makes them versatile, but also ineffective when a specific format is required. We present FormatFuzzer , a generator for format-specific fuzzers . FormatFuzzer takes as input a binary template (a format specification used by the 010 Editor) and compiles it into C++ code that acts as parser, mutator, and highly efficient generator of inputs conforming to the rules of the language. The resulting format-specific fuzzer can be used as a standalone producer or mutator in black-box settings, where no guidance from the program is available. In addition, by providing mutable decision seeds, it can be easily integrated with arbitrary format-agnostic fuzzers such as AFL to make them format-aware. In our evaluation on complex formats such as MP4 or ZIP, FormatFuzzer showed to be a highly effective producer of valid inputs that also detected previously unknown memory errors in ffmpeg and timidity .},
  archive      = {J_TOSEM},
  author       = {Rafael Dutra and Rahul Gopinath and Andreas Zeller},
  doi          = {10.1145/3628157},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {53:1–29},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {FormatFuzzer: Effective fuzzing of binary file formats},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LibAM: An area matching framework for detecting third-party
libraries in binaries. <em>TOSEM</em>, <em>33</em>(2), 52:1–35. (<a
href="https://doi.org/10.1145/3625294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Third-party libraries (TPLs) are extensively utilized by developers to expedite the software development process and incorporate external functionalities. Nevertheless, insecure TPL reuse can lead to significant security risks. Existing methods, which involve extracting strings or conducting function matching, are employed to determine the presence of TPL code in the target binary. However, these methods often yield unsatisfactory results due to the recurrence of strings and the presence of numerous similar non-homologous functions. Furthermore, the variation in C/C++ binaries across different optimization options and architectures exacerbates the problem. Additionally, existing approaches struggle to identify specific pieces of reused code in the target binary, complicating the detection of complex reuse relationships and impeding downstream tasks. And, we call this issue the poor interpretability of TPL detection results. In this article, we observe that TPL reuse typically involves not just isolated functions but also areas encompassing several adjacent functions on the Function Call Graph (FCG). We introduce LibAM, a novel Area Matching framework that connects isolated functions into function areas on FCG and detects TPLs by comparing the similarity of these function areas, significantly mitigating the impact of different optimization options and architectures. Furthermore, LibAM is the first approach capable of detecting the exact reuse areas on FCG and offering substantial benefits for downstream tasks. To validate our approach, we compile the first TPL detection dataset for C/C++ binaries across various optimization options and architectures. Experimental results demonstrate that LibAM outperforms all existing TPL detection methods and provides interpretable evidence for TPL detection results by identifying exact reuse areas. We also evaluate LibAM’s scalability on large-scale, real-world binaries in IoT firmware and generate a list of potential vulnerabilities for these devices. Our experiments indicate that the Area Matching framework performs exceptionally well in the TPL detection task and holds promise for other binary similarity analysis tasks. Last but not least, by analyzing the detection results of IoT firmware, we make several interesting findings, for instance, different target binaries always tend to reuse the same code area of TPL. The datasets and source code used in this article are available at https://github.com/Siyuan-Li201/LibAM .},
  archive      = {J_TOSEM},
  author       = {Siyuan Li and Yongpan Wang and Chaopeng Dong and Shouguo Yang and Hong Li and Hao Sun and Zhe Lang and Zuxin Chen and Weijie Wang and Hongsong Zhu and Limin Sun},
  doi          = {10.1145/3625294},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {52:1–35},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {LibAM: An area matching framework for detecting third-party libraries in binaries},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The good, the bad, and the missing: Neural code generation
for machine learning tasks. <em>TOSEM</em>, <em>33</em>(2), 51:1–24. (<a
href="https://doi.org/10.1145/3630009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) has been increasingly used in a variety of domains, while solving ML programming tasks poses unique challenges due to the fundamental difference in the nature and the construct of general programming tasks, especially for developers who do not have ML backgrounds. Automatic code generation that produces a code snippet from a natural language description can be a promising technique to accelerate ML programming tasks. In recent years, although many deep learning-based neural code generation models have been proposed with high accuracy, the fact that most of them are mainly evaluated on general programming tasks calls into question their effectiveness and usefulness in ML programming tasks. In this article, we set out to investigate the effectiveness of existing neural code generation models on ML programming tasks. For our analysis, we select six state-of-the-art neural code generation models and evaluate their performance on four widely used ML libraries, with newly created 83K pairs of natural-language described ML programming tasks. Our empirical study reveals some good, bad, and missing aspects of neural code generation models on ML tasks, with a few major ones listed below. ( Good ) Neural code generation models perform significantly better on ML tasks than on non-ML tasks with an average difference of 10.6 points in BLEU-4 scores. ( Bad ) More than 80\% of the generated code is semantically incorrect. ( Bad ) Code generation models do not have significance in improving developers’ completion time. ( Good ) The generated code can help developers write correct code by providing developers with clues for using correct APIs. ( Missing ) The observation from our user study reveals the missing aspects of code generation for ML tasks, e.g., decomposing code generation for divide-and-conquer into API sequence identification and API usage generation.},
  archive      = {J_TOSEM},
  author       = {Jiho Shin and Moshi Wei and Junjie Wang and Lin Shi and Song Wang},
  doi          = {10.1145/3630009},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {51:1–24},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {The good, the bad, and the missing: Neural code generation for machine learning tasks},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generation-based differential fuzzing for deep learning
libraries. <em>TOSEM</em>, <em>33</em>(2), 50:1–28. (<a
href="https://doi.org/10.1145/3628159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) libraries have become the key component in developing and deploying DL-based software nowadays. With the growing popularity of applying DL models in both academia and industry across various domains, any bugs inherent in the DL libraries can potentially cause unexpected server outcomes. As such, there is an urgent demand for improving the software quality of DL libraries. Although there are some existing approaches specifically designed for testing DL libraries, their focus is usually limited to one specific domain, such as computer vision (CV). It is still not very clear how the existing approaches perform in detecting bugs of different DL libraries regarding different task domains and to what extent. To bridge this gap, we first conduct an empirical study on four representative and state-of-the-art DL library testing approaches. Our empirical study results reveal that it is hard for existing approaches to generalize to other task domains. We also find that the test inputs generated by these approaches usually lack diversity, with only a few types of bugs. What is worse, the false-positive rate of existing approaches is also high ( up to 58\% ). To address these issues, we propose a guided differential fuzzing approach based on generation , namely, Gandalf . To generate testing inputs across diverse task domains effectively, Gandalf adopts the context-free grammar to ensure validity and utilizes a Deep Q-Network to maximize the diversity. Gandalf also includes 15 metamorphic relations to make it possible for the generated test cases to generalize across different DL libraries. Such a design can decrease the false positives because of the semantic difference for different APIs. We evaluate the effectiveness of Gandalf on nine versions of three representative DL libraries, covering 309 operators from computer vision, natural language processing, and automated speech recognition. The evaluation results demonstrate that Gandalf can effectively and efficiently generate diverse test inputs. Meanwhile, Gandalf successfully detects five categories of bugs with only 3.1\% false-positive rates. We report all 49 new unique bugs found during the evaluation to the DL libraries’ developers, and most of these bugs have been confirmed. Details about our empirical study and evaluation results are available on our project website. 1},
  archive      = {J_TOSEM},
  author       = {Jiawei Liu and Yuheng Huang and Zhijie Wang and Lei Ma and Chunrong Fang and Mingzheng Gu and Xufan Zhang and Zhenyu Chen},
  doi          = {10.1145/3628159},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {50:1–28},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Generation-based differential fuzzing for deep learning libraries},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Aspect-level information discrepancies across heterogeneous
vulnerability reports: Severity, types and detection methods.
<em>TOSEM</em>, <em>33</em>(2), 49:1–38. (<a
href="https://doi.org/10.1145/3624734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vulnerable third-party libraries pose significant threats to software applications that reuse these libraries. At an industry scale of reuse, manual analysis of third-party library vulnerabilities can be easily overwhelmed by the sheer number of vulnerabilities continually collected from diverse sources for thousands of reused libraries. Our study of four large-scale, actively maintained vulnerability databases (NVD, IBM X-Force, ExploitDB, and Openwall) reveals the wide presence of information discrepancies, in terms of seven vulnerability aspects, i.e., product, version, component, vulnerability type, root cause, attack vector, and impact, between the reports for the same vulnerability from heterogeneous sources. It would be beneficial to integrate and cross-validate multi-source vulnerability information, but it demands automatic aspect extraction and aspect discrepancy detection. In this work, we experimented with a wide range of NLP methods to extract named entities (e.g., product) and free-form phrases (e.g., root cause) from textual vulnerability reports and to detect semantically different aspect mentions between the reports. Our experiments confirm the feasibility of applying NLP methods to automate aspect-level vulnerability analysis and identify the need for domain customization of general NLP methods. Based on our findings, we propose a discrepancy-aware, aspect-level vulnerability knowledge graph and a KG-based web portal that integrates diversified vulnerability key aspect information from heterogeneous vulnerability databases. Our conducted user study proves the usefulness of our web portal. Our study opens the door to new types of vulnerability integration and management, such as vulnerability portraits of a product and explainable prediction of silent vulnerabilities.},
  archive      = {J_TOSEM},
  author       = {Jiamou Sun and Zhenchang Xing and Xin Xia and Qinghua Lu and Xiwei Xu and Liming Zhu},
  doi          = {10.1145/3624734},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {49:1–38},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Aspect-level information discrepancies across heterogeneous vulnerability reports: Severity, types and detection methods},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). KAPE: KNN-based performance testing for deep code search.
<em>TOSEM</em>, <em>33</em>(2), 48:1–24. (<a
href="https://doi.org/10.1145/3624735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code search is a common yet important activity of software developers. An efficient code search model can largely facilitate the development process and improve the programming quality. Given the superb performance of learning the contextual representations, deep learning models, especially pre-trained language models, have been widely explored for the code search task. However, studies mainly focus on proposing new architectures for ever-better performance on designed test sets but ignore the performance on unseen test data where only natural language queries are available. The same problem in other domains, e.g., CV and NLP, is usually solved by test input selection that uses a subset of the unseen set to reduce the labeling effort. However, approaches from other domains are not directly applicable and still require labeling effort. In this article, we propose the k NN-b a sed p erformance t e sting ( KAPE ) to efficiently solve the problem without manually matching code snippets to test queries. The main idea is to use semantically similar training data to perform the evaluation. Extensive experiments on six programming language datasets, three state-of-the-art pre-trained models, and seven baseline methods demonstrate that KAPE can effectively assess the model performance (e.g., CodeBERT achieves MRR 0.5795 on JavaScript) with a slight difference (e.g., 0.0261).},
  archive      = {J_TOSEM},
  author       = {Yuejun Guo and Qiang Hu and Xiaofei Xie and Maxime Cordy and Mike Papadakis and Yves Le Traon},
  doi          = {10.1145/3624735},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {48:1–24},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {KAPE: KNN-based performance testing for deep code search},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated mapping of adaptive app GUIs from phones to TVs.
<em>TOSEM</em>, <em>33</em>(2), 47:1–31. (<a
href="https://doi.org/10.1145/3631968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing interconnection of smart devices, users often desire to adopt the same app on quite different devices for identical tasks, such as watching the same movies on both their smartphones and TVs. However, the significant differences in screen size, aspect ratio, and interaction styles make it challenging to adapt Graphical User Interfaces (GUIs) across these devices. Although there are millions of apps available on Google Play, only a few thousand are designed to support smart TV displays. Existing techniques to map a mobile app GUI to a TV either adopt a responsive design, which struggles to bridge the substantial gap between phone and TV, or use mirror apps for improved video display, which requires hardware support and extra engineering efforts. Instead of developing another app for supporting TVs, we propose a semi-automated approach to generate corresponding adaptive TV GUIs, given the phone GUIs as the input. Based on our empirical study of GUI pairs for TVs and phones in existing apps, we synthesize a list of rules for grouping and classifying phone GUIs, converting them to TV GUIs, and generating dynamic TV layouts and source code for the TV display. Our tool is not only beneficial to developers but also to GUI designers, who can further customize the generated GUIs for their TV app development. An evaluation and user study demonstrate the accuracy of our generated GUIs and the usefulness of our tool.},
  archive      = {J_TOSEM},
  author       = {Han Hu and Ruiqi Dong and John Grundy and Thai Minh Nguyen and Huaxiao Liu and Chunyang Chen},
  doi          = {10.1145/3631968},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {47:1–31},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Automated mapping of adaptive app GUIs from phones to TVs},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated test suite generation for software product lines
based on quality-diversity optimization. <em>TOSEM</em>, <em>33</em>(2),
46:1–52. (<a href="https://doi.org/10.1145/3628158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Software Product Line (SPL) is a set of software products that are built from a variability model. Real-world SPLs typically involve a vast number of valid products, making it impossible to individually test each of them. This arises the need for automated test suite generation, which was previously modeled as either a single-objective or a multi-objective optimization problem considering only objective functions. This article provides a completely different mathematical model by exploiting the benefits of Quality-Diversity (QD) optimization that is composed of not only an objective function (e.g., t -wise coverage or test suite diversity) but also a user-defined behavior space (e.g., the space with test suite size as its dimension). We argue that the new model is more suitable and generic than the two alternatives because it provides at a time a large set of diverse (measured in the behavior space) and high-performing solutions that can ease the decision-making process. We apply MAP-Elites, one of the most popular QD algorithms, to solve the model. The results of the evaluation, on both realistic and artificial SPLs, are promising, with MAP-Elites significantly and substantially outperforming both single- and multi-objective approaches, and also several state-of-the-art SPL testing tools. In summary, this article provides a new and promising perspective on the test suite generation for SPLs.},
  archive      = {J_TOSEM},
  author       = {Yi Xiang and Han Huang and Sizhe Li and Miqing Li and Chuan Luo and Xiaowei Yang},
  doi          = {10.1145/3628158},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {46:1–52},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Automated test suite generation for software product lines based on quality-diversity optimization},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CLFuzz: Vulnerability detection of cryptographic algorithm
implementation via semantic-aware fuzzing. <em>TOSEM</em>,
<em>33</em>(2), 45:1–28. (<a
href="https://doi.org/10.1145/3628160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cryptography is a core component of many security applications, and flaws hidden in its implementation will affect the functional integrity or, more severely, pose threats to data security. Hence, guaranteeing the correctness of the implementation is important. However, the semantic characteristics (e.g., diverse input data and complex functional transformation) challenge those traditional program validation techniques (e.g., static analysis and dynamic fuzzing). In this article, we propose CLFuzz, a semantic-aware fuzzer for the vulnerability detection of cryptographic algorithm implementation. CLFuzz first extracts the semantic information of targeted algorithms including their cryptographic-specific constraints and function signatures. Based on them, CLFuzz generates high-quality input data adaptively to trigger error-prone situations efficiently. Furthermore, CLFuzz applies innovative logical cross-check that strengthens the logical bug detection ability. We evaluate CLFuzz on the widely used implementations of 54 cryptographic algorithms. It outperforms state-of-the-art cryptographic fuzzing tools. For example, compared with Cryptofuzz, it achieves a coverage speedup of 3.4× and increases the final coverage by 14.4\%. Furthermore, CLFuzz has detected 12 previously unknown implementation bugs in 8 cryptographic algorithms (e.g., CMAC in OpenSSL and Message Digest in SymCrypt), most of which are security-critical and have been successfully collected in the national vulnerability database (7 in NVD/CNVD) and is awarded by the Microsoft bounty program (2 for $1,000).},
  archive      = {J_TOSEM},
  author       = {Yuanhang Zhou and Fuchen Ma and Yuanliang Chen and Meng Ren and Yu Jiang},
  doi          = {10.1145/3628160},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {45:1–28},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {CLFuzz: Vulnerability detection of cryptographic algorithm implementation via semantic-aware fuzzing},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Poracle: Testing patches under preservation conditions to
combat the overfitting problem of program repair. <em>TOSEM</em>,
<em>33</em>(2), 44:1–39. (<a
href="https://doi.org/10.1145/3625293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To date, the users of test-driven program repair tools suffer from the overfitting problem; a generated patch may pass all available tests without being correct. In the existing work, users are treated as merely passive consumers of the tests. However, what if they are willing to modify the test to better assess the patches obtained from a repair tool? In this work, we propose a novel semi-automatic patch-classification methodology named Poracle . Our key contributions are three-fold. First, we design a novel lightweight specification method that reuses the existing test. Specifically, the users extend the existing failing test with a preservation condition —the condition under which the patched and pre-patched versions should produce the same output. Second, we develop a fuzzer that performs differential fuzzing with a test containing a preservation condition. Once we find an input that satisfies a specified preservation condition but produces different outputs between the patched and pre-patched versions, we classify the patch as incorrect with high confidence. We show that our approach is more effective than the four state-of-the-art patch classification approaches. Last, we show through a user study that the users find our semi-automatic patch assessment method more effective and preferable than the manual assessment.},
  archive      = {J_TOSEM},
  author       = {Elkhan Ismayilzada and Md Mazba Ur Rahman and Dongsun Kim and Jooyong Yi},
  doi          = {10.1145/3625293},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {44:1–39},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Poracle: Testing patches under preservation conditions to combat the overfitting problem of program repair},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to detect memory-related vulnerabilities.
<em>TOSEM</em>, <em>33</em>(2), 43:1–35. (<a
href="https://doi.org/10.1145/3624744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Memory-related vulnerabilities can result in performance degradation or even program crashes, constituting severe threats to the security of modern software. Despite the promising results of deep learning (DL)-based vulnerability detectors, there exist three main limitations: (1) rich contextual program semantics related to vulnerabilities have not yet been fully modeled; (2) multi-granularity vulnerability features in hierarchical code structure are still hard to be captured; and (3) heterogeneous flow information is not well utilized. To address these limitations, in this article, we propose a novel DL-based approach, called MVD+ , to detect memory-related vulnerabilities at the statement-level. Specifically, it conducts both intraprocedural and interprocedural analysis to model vulnerability features, and adopts a hierarchical representation learning strategy, which performs syntax-aware neural embedding within statements and captures structured context information across statements based on a novel Flow-Sensitive Graph Neural Networks, to learn both syntactic and semantic features of vulnerable code. To demonstrate the performance, we conducted extensive experiments against eight state-of-the-art DL-based approaches as well as five well-known static analyzers on our constructed dataset with 6,879 vulnerabilities in 12 popular C/C++ applications. The experimental results confirmed that MVD+ can significantly outperform current state-of-the-art baselines and make a great trade-off between effectiveness and efficiency.},
  archive      = {J_TOSEM},
  author       = {Sicong Cao and Xiaobing Sun and Lili Bo and Rongxin Wu and Bin Li and Xiaoxue Wu and Chuanqi Tao and Tao Zhang and Wei Liu},
  doi          = {10.1145/3624744},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {43:1–35},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Learning to detect memory-related vulnerabilities},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical distribution-aware testing of deep learning.
<em>TOSEM</em>, <em>33</em>(2), 42:1–35. (<a
href="https://doi.org/10.1145/3625290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With its growing use in safety/security-critical applications, Deep Learning (DL) has raised increasing concerns regarding its dependability. In particular, DL has a notorious problem of lacking robustness. Input added with adversarial perturbations, i.e., Adversarial Examples (AEs) , are easily mispredicted by the DL model. Despite recent efforts made in detecting AEs via state-of-the-art attack and testing methods, they are normally input distribution–agnostic and/or disregard the perceptual quality of adversarial perturbations. Consequently, the detected AEs are irrelevant inputs in the application context or noticeably unrealistic to humans. This may lead to a limited effect on improving the DL model’s dependability, as the testing budget is likely to be wasted on detecting AEs that are encountered very rarely in its real-life operations. In this article, we propose a new robustness testing approach for detecting AEs that considers both the feature-level distribution and the pixel-level distribution, capturing the perceptual quality of adversarial perturbations. The two considerations are encoded by a novel hierarchical mechanism. First, we select test seeds based on the density of feature-level distribution and the vulnerability of adversarial robustness. The vulnerability of test seeds is indicated by the auxiliary information, which are highly correlated with local robustness. Given a test seed, we then develop a novel genetic algorithm–based local test case generation method, in which two fitness functions work alternatively to control the perceptual quality of detected AEs. Finally, extensive experiments confirm that our holistic approach considering hierarchical distributions is superior to the state-of-the-arts that either disregard any input distribution or only consider a single (non-hierarchical) distribution, in terms of not only detecting imperceptible AEs but also improving the overall robustness of the DL model under testing.},
  archive      = {J_TOSEM},
  author       = {Wei Huang and Xingyu Zhao and Alec Banks and Victoria Cox and Xiaowei Huang},
  doi          = {10.1145/3625290},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {42:1–35},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Hierarchical distribution-aware testing of deep learning},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Variable-based fault localization via enhanced decision
tree. <em>TOSEM</em>, <em>33</em>(2), 41:1–32. (<a
href="https://doi.org/10.1145/3624741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault localization, aiming at localizing the root cause of the bug under repair, has been a longstanding research topic. Although many approaches have been proposed in past decades, most of the existing studies work at coarse-grained statement or method levels with very limited insights about how to repair the bug ( granularity problem ), but few studies target the finer-grained fault localization. In this article, we target the granularity problem and propose a novel finer-grained variable-level fault localization technique. Specifically, the basic idea of our approach is that fault-relevant variables may exhibit different values in failed and passed test runs, and variables that have higher discrimination ability have a larger possibility to be the root causes of the failure. Based on this, we propose a program-dependency-enhanced decision tree model to boost the identification of fault-relevant variables via discriminating failed and passed test cases based on the variable values. To evaluate the effectiveness of our approach, we have implemented it in a tool called VarDT and conducted an extensive study over the Defects4J benchmark. The results show that VarDT outperforms the state-of-the-art fault localization approaches with at least 268.4\% improvement in terms of bugs located at Top-1, and the average improvement is 351.3\%. Besides, to investigate whether our finer-grained fault localization result can further improve the effectiveness of downstream APR techniques, we have adapted VarDT to the application of patch filtering, where we use the variables located by VarDT to filter incorrect patches. The results denote that VarDT outperforms the state-of-the-art PATCH-SIM and BATS by filtering 14.8\% and 181.8\% more incorrect patches, respectively, demonstrating the effectiveness of our approach. It also provides a new way of thinking for improving automatic program repair techniques.},
  archive      = {J_TOSEM},
  author       = {Jiajun Jiang and Yumeng Wang and Junjie Chen and Delin Lv and Mengjiao Liu},
  doi          = {10.1145/3624741},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {41:1–32},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Variable-based fault localization via enhanced decision tree},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Search-based software testing driven by automatically
generated and manually defined fitness functions. <em>TOSEM</em>,
<em>33</em>(2), 40:1–37. (<a
href="https://doi.org/10.1145/3624745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Search-based software testing (SBST) typically relies on fitness functions to guide the search exploration toward software failures. There are two main techniques to define fitness functions: (a) automated fitness function computation from the specification of the system requirements, and (b) manual fitness function design. Both techniques have advantages. The former uses information from the system requirements to guide the search toward portions of the input domain more likely to contain failures. The latter uses the engineers’ domain knowledge. We propose ATheNA , a novel SBST framework that combines fitness functions automatically generated from requirements specifications and those manually defined by engineers. We design and implement ATheNA-S , an instance of ATheNA that targets Simulink ® models. We evaluate ATheNA-S by considering a large set of models from different domains. Our results show that ATheNA-S generates more failure-revealing test cases than existing baseline tools and that the difference between the runtime performance of ATheNA-S and the baseline tools is not statistically significant. We also assess whether ATheNA-S could generate failure-revealing test cases when applied to two representative case studies: one from the automotive domain and one from the medical domain. Our results show that ATheNA-S successfully revealed a requirement violation in our case studies.},
  archive      = {J_TOSEM},
  author       = {Federico Formica and Tony Fan and Claudio Menghi},
  doi          = {10.1145/3624745},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {40:1–37},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Search-based software testing driven by automatically generated and manually defined fitness functions},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ALL: Supporting experiential accessibility education and
inclusive software development. <em>TOSEM</em>, <em>33</em>(2), 39:1–30.
(<a href="https://doi.org/10.1145/3625292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Creating accessible software is imperative for making software inclusive for all users.Unfortunately, the topic of accessibility is frequently excluded from computing education, leading to scenarios where students are unaware of either how to develop accessible software or see the need to create it. To address this challenge, we have created a set of educational labs that are systematically designed to not only inform students about fundamental topics in producing accessible software but also demonstrate its importance. Over the previous year, these labs were included in several Computer Science 2 offerings at the Rochester Institute of Technology, comprising a total of 500 student participants. This article discusses instructional observations from these offerings, some of which include the following: (i) many of the research findings from previous efforts remain true with the larger, more diverse evaluation; (ii) our created material and format reduced students’ belief that creating accessible software was difficult in relation to the baseline,; (iii) we observed that our created material and format benefited student opinion that creating accessible software is important, and (iv) computing majors may not be uniformly impacted by experiential educational accessibility material. The educational labs are publicly available on the project website (https://all.rit.edu).},
  archive      = {J_TOSEM},
  author       = {Weishi Shi and Heather Moses and Qi Yu and Samuel Malachowsky and Daniel E. Krutz},
  doi          = {10.1145/3625292},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {39:1–30},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {ALL: Supporting experiential accessibility education and inclusive software development},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LoGenText-plus: Improving neural machine translation based
logging texts generation with syntactic templates. <em>TOSEM</em>,
<em>33</em>(2), 38:1–45. (<a
href="https://doi.org/10.1145/3624740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developers insert logging statements in the source code to collect important runtime information about software systems. The textual descriptions in logging statements (i.e., logging texts) are printed during system executions and exposed to multiple stakeholders including developers, operators, users, and regulatory authorities. Writing proper logging texts is an important but often challenging task for developers. Prior studies find that developers spend significant efforts modifying their logging texts. However, despite extensive research on automated logging suggestions, research on suggesting logging texts rarely exists. To fill this knowledge gap, we first propose LoGenText (initially reported in our conference paper), an automated approach that uses neural machine translation (NMT) models to generate logging texts by translating the related source code into short textual descriptions. LoGenText takes the preceding source code of a logging text as the input and considers other context information, such as the location of the logging statement, to automatically generate the logging text. LoGenText ’s evaluation on 10 open source projects indicates that the approach is promising for automatic logging text generation and significantly outperforms the state-of-the-art approach. Furthermore, we extend LoGenText to LoGenText-Plus by incorporating the syntactic templates of the logging texts. Different from LoGenText , LoGenText-Plus decomposes the logging text generation process into two stages. LoGenText-Plus first adopts an NMT model to generate the syntactic template of the target logging text. Then LoGenText-Plus feeds the source code and the generated template as the input to another NMT model for logging text generation. We also evaluate LoGenText-Plus on the same 10 projects and observe that it outperforms LoGenText on 9 of them. According to a human evaluation from developers’ perspectives, the logging texts generated by LoGenText-Plus have a higher quality than those generated by LoGenText and the prior baseline approach. By manually examining the generated logging texts, we then identify five aspects that can serve as guidance for writing or generating good logging texts. Our work is an important step toward the automated generation of logging statements, which can potentially save developers’ efforts and improve the quality of software logging. Our findings shed light on research opportunities that leverage advances in NMT techniques for automated generation and suggestion of logging statements.},
  archive      = {J_TOSEM},
  author       = {Zishuo Ding and Yiming Tang and Xiaoyu Cheng and Heng Li and Weiyi Shang},
  doi          = {10.1145/3624740},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {38:1–45},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {LoGenText-plus: Improving neural machine translation based logging texts generation with syntactic templates},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Characterizing and detecting WebAssembly runtime bugs.
<em>TOSEM</em>, <em>33</em>(2), 37:1–29. (<a
href="https://doi.org/10.1145/3624743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {WebAssembly (abbreviated WASM) has emerged as a promising language of the Web and also been used for a wide spectrum of software applications such as mobile applications and desktop applications. These applications, named WASM applications, commonly run in WASM runtimes. Bugs in WASM runtimes are frequently reported by developers and cause the crash of WASM applications. However, these bugs have not been well studied. To fill in the knowledge gap, we present a systematic study to characterize and detect bugs in WASM runtimes. We first harvest a dataset of 311 real-world bugs from hundreds of related posts on GitHub. Based on the collected high-quality bug reports, we distill 31 bug categories of WASM runtimes and summarize their common fix strategies. Furthermore, we develop a pattern-based bug detection framework to automatically detect bugs in WASM runtimes. We apply the detection framework to seven popular WASM runtimes and successfully uncover 60 bugs that have never been reported previously, among which 13 have been confirmed and 9 have been fixed by runtime developers.},
  archive      = {J_TOSEM},
  author       = {Yixuan Zhang and Shangtong Cao and Haoyu Wang and Zhenpeng Chen and Xiapu Luo and Dongliang Mu and Yun Ma and Gang Huang and Xuanzhe Liu},
  doi          = {10.1145/3624743},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {37:1–29},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Characterizing and detecting WebAssembly runtime bugs},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Understanding the helpfulness of stale bot for pull-based
development: An empirical study of 20 large open-source projects.
<em>TOSEM</em>, <em>33</em>(2), 36:1–43. (<a
href="https://doi.org/10.1145/3624739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pull Requests (PRs) that are neither progressed nor resolved clutter the list of PRs, making it difficult for the maintainers to manage and prioritize unresolved PRs. To automatically track, follow up, and close such inactive PRs, Stale bot was introduced by GitHub. Despite its increasing adoption, there are ongoing debates on whether using Stale bot alleviates or exacerbates the problem of inactive PRs. To better understand if and how Stale bot helps projects in their pull-based development workflow, we perform an empirical study of 20 large and popular open source projects. We find that Stale bot can help deal with a backlog of unresolved PRs, as the projects closed more PRs within the first few months of adoption. Moreover, Stale bot can help improve the efficiency of the PR review process as the projects reviewed PRs that ended up merged and resolved PRs that ended up closed faster after the adoption. However, Stale bot can also negatively affect the contributors, as the projects experienced a considerable decrease in their number of active contributors after the adoption. Therefore, relying solely on Stale bot to deal with inactive PRs may lead to decreased community engagement and an increased probability of contributor abandonment.},
  archive      = {J_TOSEM},
  author       = {Sayedhassan Khatoonabadi and Diego Elias Costa and Suhaib Mujahid and Emad Shihab},
  doi          = {10.1145/3624739},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {36:1–43},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Understanding the helpfulness of stale bot for pull-based development: An empirical study of 20 large open-source projects},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stress testing control loops in cyber-physical systems.
<em>TOSEM</em>, <em>33</em>(2), 35:1–58. (<a
href="https://doi.org/10.1145/3624742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber-physical Systems (CPSs) are often safety-critical and deployed in uncertain environments. Identifying scenarios where CPSs do not comply with requirements is fundamental but difficult due to the multidisciplinary nature of CPSs. We investigate the testing of control-based CPSs, where control and software engineers develop the software collaboratively. Control engineers make design assumptions during system development to leverage control theory and obtain guarantees on CPS behaviour. In the implemented system, however, such assumptions are not always satisfied, and their falsification can lead the loss of guarantees. We define stress testing of control-based CPSs as generating tests to falsify such design assumptions. We highlight different types of assumptions, focusing on the use of linearised physics models. To generate stress tests falsifying such assumptions, we leverage control theory to qualitatively characterise the input space of a control-based CPS. We propose a novel test parametrisation for control-based CPSs and use it with the input space characterisation to develop a stress testing approach. We evaluate our approach on three case study systems, including a drone, a continuous-current motor (in five configurations), and an aircraft. Our results show the effectiveness of the proposed testing approach in falsifying the design assumptions and highlighting the causes of assumption violations.},
  archive      = {J_TOSEM},
  author       = {Claudio Mandrioli and Seung Yeob Shin and Martina Maggio and Domenico Bianculli and Lionel Briand},
  doi          = {10.1145/3624742},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {35:1–58},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Stress testing control loops in cyber-physical systems},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A closer look at the security risks in the rust ecosystem.
<em>TOSEM</em>, <em>33</em>(2), 34:1–30. (<a
href="https://doi.org/10.1145/3624738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rust is an emerging programming language designed for the development of systems software. To facilitate the reuse of Rust code, crates.io , as a central package registry of the Rust ecosystem, hosts thousands of third-party Rust packages. The openness of crates.io enables the growth of the Rust ecosystem but comes with security risks by severe security advisories. Although Rust guarantees a software program to be safe via programming language features and strict compile-time checking, the unsafe keyword in Rust allows developers to bypass compiler safety checks for certain regions of code. Prior studies empirically investigate the memory safety and concurrency bugs in the Rust ecosystem, as well as the usage of unsafe keywords in practice. Nonetheless, the literature lacks a systematic investigation of the security risks in the Rust ecosystem. In this article, we perform a comprehensive investigation into the security risks present in the Rust ecosystem, asking “what are the characteristics of the vulnerabilities, what are the characteristics of the vulnerable packages, and how are the vulnerabilities fixed in practice?”. To facilitate the study, we first compile a dataset of 433 vulnerabilities, 300 vulnerable code repositories, and 218 vulnerability fix commits in the Rust ecosystem, spanning over 7 years. With the dataset, we characterize the types, life spans, and evolution of the disclosed vulnerabilities. We then characterize the popularity, categorization, and vulnerability density of the vulnerable Rust packages, as well as their versions and code regions affected by the disclosed vulnerabilities. Finally, we characterize the complexity of vulnerability fixes and localities of corresponding code changes, and inspect how practitioners fix vulnerabilities in Rust packages with various localities. We find that memory safety and concurrency issues account for nearly two thirds of the vulnerabilities in the Rust ecosystem. It takes over 2 years for the vulnerabilities to become publicly disclosed, and one-third of the vulnerabilities have no fixes committed before their disclosure. In terms of vulnerability density, we observe a continuous upward trend at the package level over time, but a decreasing trend at the code level since August 2020. In the vulnerable Rust packages, the vulnerable code tends to be localized at the file level, and contains statistically significantly more unsafe functions and blocks than the rest of the code. More popular packages tend to have more vulnerabilities, while the less popular packages suffer from vulnerabilities for more versions. The vulnerability fix commits tend to be localized to a limited number of lines of code. Developers tend to address vulnerable safe functions by adding safe functions or lines to them, vulnerable unsafe blocks by removing them, and vulnerable unsafe functions by modifying unsafe trait implementations. Based on our findings, we discuss implications, provide recommendations for software practitioners, and outline directions for future research.},
  archive      = {J_TOSEM},
  author       = {Xiaoye Zheng and Zhiyuan Wan and Yun Zhang and Rui Chang and David Lo},
  doi          = {10.1145/3624738},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {34:1–30},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {A closer look at the security risks in the rust ecosystem},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Acrobats and safety nets: Problematizing large-scale agile
software development. <em>TOSEM</em>, <em>33</em>(2), 33:1–45. (<a
href="https://doi.org/10.1145/3617169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agile development methods have become a standard in the software industry, including in large-scale projects. These methods share a set of underlying assumptions that distinguish them from more traditional plan-driven approaches. In this article, we adopt Alvesson and Sandberg&#39;s problematization approach to challenge three key assumptions that are prevalent in the large-scale agile literature: (1) agile and plan-driven methods are mutually exclusive; (2) self-managing and hierarchically organized teams are mutually exclusive; and (3) agile methods can scale through simple linear composition. Using a longitudinal case study of large-scale agile development, we describe a series of trigger events and episodes whereby the agile approach was tailored to address the needs of the large-scale development context, which was very much at odds with these fundamental assumptions. We develop a set of new underlying assumptions which suggest that agile and plan-driven practices are mutually enabling and necessary for coordination and scaling in large-scale agile projects. We develop nine propositions for large-scale agile projects based on these new alternative underlying assumptions. Finally, we summarize our theoretical contribution in a generic process model of continuously adjusting agile and plan-driven practices in order to accommodate process challenges in large-scale agile projects.},
  archive      = {J_TOSEM},
  author       = {Knut H. Rolland and Brian Fitzgerald and Torgeir Dingsøyr and Klaas-Jan Stol},
  doi          = {10.1145/3617169},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {33:1–45},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Acrobats and safety nets: Problematizing large-scale agile software development},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Probabilistic safe WCET estimation for weakly hard real-time
systems at design stages. <em>TOSEM</em>, <em>33</em>(2), 32:1–34. (<a
href="https://doi.org/10.1145/3617176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly hard real-time systems can, to some degree, tolerate deadline misses, but their schedulability still needs to be analyzed to ensure their quality of service. Such analysis usually occurs at early design stages to provide implementation guidelines to engineers so they can make better design decisions. Estimating worst-case execution times (WCET) is a key input to schedulability analysis. However, early on during system design, estimating WCET values is challenging, and engineers usually determine them as plausible ranges based on their domain knowledge. Our approach aims at finding restricted, safe WCET sub-ranges given a set of ranges initially estimated by experts in the context of weakly hard real-time systems. To this end, we leverage (1) multi-objective search aiming at maximizing the violation of weakly hard constraints to find worst-case scheduling scenarios and (2) polynomial logistic regression to infer safe WCET ranges with a probabilistic interpretation. We evaluated our approach by applying it to an industrial system in the satellite domain and several realistic synthetic systems. The results indicate that our approach significantly outperforms a baseline relying on random search without learning and estimates safe WCET ranges with a high degree of confidence in practical time (&lt; 23 h).},
  archive      = {J_TOSEM},
  author       = {Jaekwon Lee and Seung Yeob Shin and Lionel C. Briand and Shiva Nejati},
  doi          = {10.1145/3617176},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {32:1–34},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Probabilistic safe WCET estimation for weakly hard real-time systems at design stages},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FQN inference in partial code by prompt-tuned language model
of code. <em>TOSEM</em>, <em>33</em>(2), 31:1–32. (<a
href="https://doi.org/10.1145/3617174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial code usually involves non-fully-qualified type names (non-FQNs) and undeclared receiving objects. Resolving the FQNs of these non-FQN types and undeclared receiving objects (referred to as type inference) is the prerequisite to effective search and reuse of partial code. Existing dictionary-lookup based methods build a symbolic knowledge base of API names and code contexts, which involve significant compilation overhead and are sensitive to unseen API names and code context variations. In this article, we propose using a p rompt-tuned c o de m asked language mod e l (MLM) as a neural knowledge base for type inference, called POME, which is lightweight and has minimal requirements on code compilation. Unlike the existing symbol name and context matching for type inference, POME infers the FQNs syntax and usage knowledge encapsulated in prompt-tuned code MLM through a colze-style fill-in-blank strategy. POME is integrated as a plug-in into web and integrated development environments (IDE) to assist developers in inferring FQNs in the real world. We systematically evaluate POME on a large amount of source code from GitHub and Stack Overflow, and explore its generalization and hybrid capability. The results validate the effectiveness of the POME design and its applicability for partial code type inference, and they can be easily extended to different programming languages (PL). POME can also be used to generate a PL-hybrid type inference model for providing a one-for-all solution. As the first of its kind, our neural type inference method opens the door to many innovative ways of using partial code.},
  archive      = {J_TOSEM},
  author       = {Qing Huang and Zhiqiang Yuan and Zhenchang Xing and Xin Peng and Xiwei Xu and Qinghua Lu},
  doi          = {10.1145/3617174},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {31:1–32},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {FQN inference in partial code by prompt-tuned language model of code},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DRIVE: Dockerfile rule mining and violation detection.
<em>TOSEM</em>, <em>33</em>(2), 30:1–23. (<a
href="https://doi.org/10.1145/3617173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Dockerfile defines a set of instructions to build Docker images, which can then be instantiated to support containerized applications. Recent studies have revealed a considerable amount of quality issues with Dockerfiles. In this article, we propose a novel approach, Dockerfiles Rule mIning and Violation dEtection ( DRIVE ), to mine implicit rules and detect potential violations of such rules in Dockerfiles. DRIVE first parses Dockerfiles and transforms them to an intermediate representation. It then leverages an efficient sequential pattern mining algorithm to extract potential patterns. With heuristic-based reduction and moderate human intervention, potential rules are identified, which can then be utilized to detect potential violations of Dockerfiles. DRIVE identifies 34 semantic rules and 19 syntactic rules including 9 new semantic rules that have not been reported elsewhere. Extensive experiments on real-world Dockerfiles demonstrate the efficacy of our approach.},
  archive      = {J_TOSEM},
  author       = {Yu Zhou and Weilin Zhan and Zi Li and Tingting Han and Taolue Chen and Harald Gall},
  doi          = {10.1145/3617173},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {12},
  number       = {2},
  pages        = {30:1–23},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {DRIVE: Dockerfile rule mining and violation detection},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Adopting two supervisors for efficient use of large-scale
remote deep neural networks - RCR report. <em>TOSEM</em>,
<em>33</em>(1), 29:1–4. (<a
href="https://doi.org/10.1145/3617594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This is the Replicated Computational Results (RCR) Report for our TOSEM paper “Adopting Two Supervisors for Efficient Use of Large-Scale Remote Deep Neural Networks”, where we propose a novel client-server architecture allowing to leverage the high accuracy of huge neural networks running on remote servers while reducing the economical and latency costs typically coming from using such models. As part of this RCR, we provide a replication package, which allows the full replication of all our results and is specifically designed to facilitate reuse.},
  archive      = {J_TOSEM},
  author       = {Michael Weiss and Paolo Tonella},
  doi          = {10.1145/3617594},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {29:1–4},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Adopting two supervisors for efficient use of large-scale remote deep neural networks - RCR report},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Adopting two supervisors for efficient use of large-scale
remote deep neural networks. <em>TOSEM</em>, <em>33</em>(1), 28:1–29.
(<a href="https://doi.org/10.1145/3617593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent decades have seen the rise of large-scale Deep Neural Networks (DNNs) to achieve human-competitive performance in a variety of AI tasks. Often consisting of hundreds of million, if not hundreds of billion, parameters, these DNNs are too large to be deployed to or efficiently run on resource-constrained devices such as mobile phones or Internet of Things microcontrollers. Systems relying on large-scale DNNs thus have to call the corresponding model over the network, leading to substantial costs for hosting and running the large-scale remote model, costs which are often charged on a per-use basis. In this article, we propose BiSupervised , a novel architecture, where, before relying on a large remote DNN, a system attempts to make a prediction on a small-scale local model. A DNN supervisor monitors said prediction process and identifies easy inputs for which the local prediction can be trusted. For these inputs, the remote model does not have to be invoked, thus saving costs while only marginally impacting the overall system accuracy. Our architecture furthermore foresees a second supervisor to monitor the remote predictions and identify inputs for which not even these can be trusted, allowing to raise an exception or run a fallback strategy instead. We evaluate the cost savings and the ability to detect incorrectly predicted inputs on four diverse case studies: IMDb movie review sentiment classification, GitHub issue triaging, ImageNet image classification, and SQuADv2 free-text question answering. In all four case studies, we find that BiSupervised allows to reduce cost by at least 30\% while maintaining similar system-level prediction performance. In two case studies (IMDb and SQuADv2), we find that BiSupervised even achieves a higher system-level accuracy, at reduced cost, compared to a remote-only model. Furthermore, measurements taken on our setup indicate a large potential of BiSupervised to reduce average prediction latency.},
  archive      = {J_TOSEM},
  author       = {Michael Weiss and Paolo Tonella},
  doi          = {10.1145/3617593},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {28:1–29},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Adopting two supervisors for efficient use of large-scale remote deep neural networks},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Testing RESTful APIs: A survey. <em>TOSEM</em>,
<em>33</em>(1), 27:1–41. (<a
href="https://doi.org/10.1145/3617175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industry, RESTful APIs are widely used to build modern Cloud Applications. Testing them is challenging, because not only do they rely on network communications, but also they deal with external services like databases. Therefore, there has been a large amount of research sprout in recent years on how to automatically verify this kind of web services. In this article, we present a comprehensive review of the current state-of-the-art in testing RESTful APIs based on the analysis of 92 scientific articles. These articles were gathered by utilizing search queries formulated around the concept of RESTful API testing on seven popular databases. We eliminated irrelevant articles based on our predefined criteria and conducted a snowballing phase to minimize the possibility of missing any relevant paper. This survey categorizes and summarizes the existing scientific work on testing RESTful APIs and discusses the current challenges in the verification of RESTful APIs. This survey clearly shows an increasing interest among researchers in this field, from 2017 onward. However, there are still a lot of open research challenges to overcome.},
  archive      = {J_TOSEM},
  author       = {Amid Golmohammadi and Man Zhang and Andrea Arcuri},
  doi          = {10.1145/3617175},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {27:1–41},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Testing RESTful APIs: A survey},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A first look at on-device models in iOS apps.
<em>TOSEM</em>, <em>33</em>(1), 26:1–30. (<a
href="https://doi.org/10.1145/3617177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Powered by the rising popularity of deep learning techniques on smartphones, on-device deep learning models are being used in vital fields such as finance, social media, and driving assistance. Because of the transparency of the Android platform and the on-device models inside, on-device models on Android smartphones have been proven to be extremely vulnerable. However, due to the challenge in accessing and analyzing iOS app files, despite iOS being a mobile platform as popular as Android, there are no relevant works on on-device models in iOS apps. Since the functionalities of the same app on Android and iOS platforms are similar, the same vulnerabilities may exist on both platforms. In this article, we present the first empirical study about on-device models in iOS apps, including their adoption of deep learning frameworks, structure, functionality, and potential security issues. We study why current developers use different on-device models for one app between iOS and Android. We propose a more general attack against white-box models that does not rely on pre-trained models and a new adversarial attack approach based on our findings to target iOS’s gray-box on-device models. Our results show the effectiveness of our approaches. Finally, we successfully exploit the vulnerabilities of on-device models to attack real-world iOS apps.},
  archive      = {J_TOSEM},
  author       = {Han Hu and Yujin Huang and Qiuyuan Chen and Terry Yue Zhuo and Chunyang Chen},
  doi          = {10.1145/3617177},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {26:1–30},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {A first look at on-device models in iOS apps},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LaF: Labeling-free model selection for automated deep neural
network reusing. <em>TOSEM</em>, <em>33</em>(1), 25:1–28. (<a
href="https://doi.org/10.1145/3611666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying deep learning (DL) to science is a new trend in recent years, which leads DL engineering to become an important problem. Although training data preparation, model architecture design, and model training are the normal processes to build DL models, all of them are complex and costly. Therefore, reusing the open-sourced pre-trained model is a practical way to bypass this hurdle for developers. Given a specific task, developers can collect massive pre-trained deep neural networks from public sources for reusing. However, testing the performance (e.g., accuracy and robustness) of multiple deep neural networks (DNNs) and recommending which model should be used is challenging regarding the scarcity of labeled data and the demand for domain expertise. In this article, we propose a labeling-free (LaF) model selection approach to overcome the limitations of labeling efforts for automated model reusing. The main idea is to statistically learn a Bayesian model to infer the models’ specialty only based on predicted labels. We evaluate LaF using nine benchmark datasets, including image, text, and source code, and 165 DNNs, considering both the accuracy and robustness of models. The experimental results demonstrate that LaF outperforms the baseline methods by up to 0.74 and 0.53 on Spearman’s correlation and Kendall’s τ, respectively.},
  archive      = {J_TOSEM},
  author       = {Qiang Hu and Yuejun Guo and Xiaofei Xie and Maxime Cordy and Mike Papadakis and Yves Le Traon},
  doi          = {10.1145/3611666},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {25:1–28},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {LaF: Labeling-free model selection for automated deep neural network reusing},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Snippet comment generation based on code context expansion.
<em>TOSEM</em>, <em>33</em>(1), 24:1–30. (<a
href="https://doi.org/10.1145/3611664">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code commenting plays an important role in program comprehension. Automatic comment generation helps improve software maintenance efficiency. The code comments to annotate a method mainly include header comments and snippet comments. The header comment aims to describe the functionality of the entire method, thereby providing a general comment at the beginning of the method. The snippet comment appears at multiple code segments in the body of a method, where a code segment is called a code snippet. Both of them help developers quickly understand code semantics, thereby improving code readability and code maintainability. However, existing automatic comment generation models mainly focus more on header comments, because there are public datasets to validate the performance. By contrast, it is challenging to collect datasets for snippet comments, because it is difficult to determine their scope. Even worse, code snippets are often too short to capture complete syntax and semantic information. To address this challenge, we propose a novel S nippet C omment Gen eration approach called SCGen . First, we utilize the context of the code snippet to expand the syntax and semantic information. Specifically, 600,243 snippet code-comment pairs are collected from 959 Java projects. Then, we capture variables from code snippets and extract variable-related statements from the context. After that, we devise an algorithm to parse and traverse abstract syntax tree (AST) information of code snippets and corresponding context. Finally, SCGen generates snippet comments after inputting the source code snippet and corresponding AST information into a sequence-to-sequence-based model. We conducted extensive experiments on the dataset we collected to evaluate our SCGen . Our approach obtains 18.23 in BLEU-4 metrics, 18.83 in METEOR, and 23.65 in ROUGE-L, which outperforms state-of-the-art comment generation models.},
  archive      = {J_TOSEM},
  author       = {Hanyang Guo and Xiangping Chen and Yuan Huang and Yanlin Wang and Xi Ding and Zibin Zheng and Xiaocong Zhou and Hong-Ning Dai},
  doi          = {10.1145/3611664},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {24:1–30},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Snippet comment generation based on code context expansion},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Seed selection for testing deep neural networks.
<em>TOSEM</em>, <em>33</em>(1), 23:1–33. (<a
href="https://doi.org/10.1145/3607190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) has been applied in many applications. Meanwhile, the quality of DL systems is becoming a big concern. To evaluate the quality of DL systems, a number of DL testing techniques have been proposed. To generate test cases, a set of initial seed inputs are required. Existing testing techniques usually construct seed corpus by randomly selecting inputs from training or test dataset. Till now, there is no study on how initial seed inputs affect the performance of DL testing and how to construct an optimal one. To fill this gap, we conduct the first systematic study to evaluate the impact of seed selection strategies on DL testing. Specifically, considering three popular goals of DL testing (i.e., coverage, failure detection, and robustness), we develop five seed selection strategies, including three based on single-objective optimization (SOO) and two based on multi-objective optimization (MOO). We evaluate these strategies on seven testing tools. Our results demonstrate that the selection of initial seed inputs greatly affects the testing performance. SOO-based selection can construct the best seed corpus that can boost DL testing with respect to the specific testing goal. MOO-based selection strategies can construct seed corpus that achieve balanced improvement on multiple objectives.},
  archive      = {J_TOSEM},
  author       = {Yuhan Zhi and Xiaofei Xie and Chao Shen and Jun Sun and Xiaoyu Zhang and Xiaohong Guan},
  doi          = {10.1145/3607190},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {23:1–33},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Seed selection for testing deep neural networks},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GraphPrior: Mutation-based test input prioritization for
graph neural networks. <em>TOSEM</em>, <em>33</em>(1), 22:1–40. (<a
href="https://doi.org/10.1145/3607191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have achieved promising performance in a variety of practical applications. Similar to traditional DNNs, GNNs could exhibit incorrect behavior that may lead to severe consequences, and thus testing is necessary and crucial. However, labeling all the test inputs for GNNs can be costly and time-consuming, especially when dealing with large and complex graphs, which seriously affects the efficiency of GNN testing. Existing studies have focused on test prioritization for DNNs, which aims to identify and prioritize fault-revealing tests (i.e., test inputs that are more likely to be misclassified) to detect system bugs earlier in a limited time. Although some DNN prioritization approaches have been demonstrated effective, there is a significant problem when applying them to GNNs: They do not take into account the connections (edges) between GNN test inputs (nodes), which play a significant role in GNN inference. In general, DNN test inputs are independent of each other, while GNN test inputs are usually represented as a graph with complex relationships between each test. In this article, we propose GraphPrior ( GNN -oriented Test Prior itization), a set of approaches to prioritize test inputs specifically for GNNs via mutation analysis. Inspired by mutation testing in traditional software engineering, in which test suites are evaluated based on the mutants they kill, GraphPrior generates mutated models for GNNs and regards test inputs that kill many mutated models as more likely to be misclassified. Then, GraphPrior leverages the mutation results in two ways, killing-based and feature-based methods. When scoring a test input, the killing-based method considers each mutated model equally important, while feature-based methods learn different importance for each mutated model through ranking models. Finally, GraphPrior ranks all the test inputs based on their scores. We conducted an extensive study based on 604 subjects to evaluate GraphPrior on both natural and adversarial test inputs. The results demonstrate that KMGP, the killing-based GraphPrior approach, outperforms the compared approaches in a majority of cases, with an average improvement of 4.76\% ~49.60\% in terms of APFD. Furthermore, the feature-based GraphPrior approach, RFGP, performs the best among all the GraphPrior approaches. On adversarial test inputs, RFGP outperforms the compared approaches across different adversarial attacks, with the average improvement of 2.95\% ~46.69\%.},
  archive      = {J_TOSEM},
  author       = {Xueqi Dang and Yinghua Li and Mike Papadakis and Jacques Klein and Tegawendé F. Bissyandé and Yves Le Traon},
  doi          = {10.1145/3607191},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {22:1–40},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {GraphPrior: Mutation-based test input prioritization for graph neural networks},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Faire: Repairing fairness of neural networks via neuron
condition synthesis. <em>TOSEM</em>, <em>33</em>(1), 21:1–24. (<a
href="https://doi.org/10.1145/3617168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) have achieved tremendous success in many applications, while it has been demonstrated that DNNs can exhibit some undesirable behaviors on concerns such as robustness, privacy, and other trustworthiness issues. Among them, fairness (i.e., non-discrimination) is one important property, especially when they are applied to some sensitive applications (e.g., finance and employment). However, DNNs easily learn spurious correlations between protected attributes (e.g., age, gender, race) and the classification task and develop discriminatory behaviors if the training data is imbalanced. Such discriminatory decisions in sensitive applications would introduce severe social impacts. To expose potential discrimination problems in DNNs before putting them in use, some testing techniques have been proposed to identify the discriminatory instances (i.e., instances that show defined discrimination 1 ). However, how to repair DNNs after detecting such discrimination is still challenging. Existing techniques mainly rely on retraining on a large number of discriminatory instances generated by testing methods, which requires huge time overhead and makes the repairing inefficient. In this work, we propose the method Faire to effectively and efficiently repair the fairness issues of DNNs, without using additional data (e.g., discriminatory instances). Our basic idea is inspired by the traditional program repair method that synthesizes proper condition checking. To repair traditional programs, a typical method is to localize the program defects and repair the program logic by adding condition checking. Similarly, for DNNs, we try to understand the unfair logic and reformulate it with well-designed condition checking. In this article, we synthesize the condition that can reduce the effect of features relevant to the protected attributes in the DNN. Specifically, we first perform the neuron-based analysis and check the functionalities of neurons to identify neurons whose outputs could be regarded as features relevant to protected attributes and original tasks. Then a new condition layer is added after each hidden layer to penalize neurons that are accountable for the protected features (i.e., intermediate features relevant to protected attributes) and promote neurons that are accountable for the non-protected features (i.e., intermediate features relevant to original tasks). In sum, the repair rate 2 of Faire reaches up to more than 99\%, which outperforms other methods, and the whole repairing process only takes no more than 340 s. The evaluation results demonstrate that our approach can effectively and efficiently repair the individual discriminatory instances of the target model.},
  archive      = {J_TOSEM},
  author       = {Tianlin Li and Xiaofei Xie and Jian Wang and Qing Guo and Aishan Liu and Lei Ma and Yang Liu},
  doi          = {10.1145/3617168},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {21:1–24},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Faire: Repairing fairness of neural networks via neuron condition synthesis},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TopicAns: Topic-informed architecture for answer
recommendation on technical q&amp;a site. <em>TOSEM</em>,
<em>33</em>(1), 20:1–25. (<a
href="https://doi.org/10.1145/3607189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technical Q&amp;A sites, such as Stack Overflow and Ask Ubuntu, have been widely utilized by software engineers to seek support for development challenges. However, not all the raised questions get instant feedback, and the retrieved answers can vary in quality. The users can hardly avoid spending much time before solving their problems. Prior studies propose approaches to automatically recommend answers for the question posts on technical Q&amp;A sites. However, the lengthiness and the lack of background knowledge issues limit the performance of answer recommendation on these sites. The irrelevant sentences in the posts may introduce noise to the semantics learning and prevent neural models from capturing the gist of texts. The lexical gap between question and answer posts further misleads current models to make failure recommendations. From this end, we propose a novel neural network named TopicAns for answer selection on technical Q&amp;A sites. TopicAns aims at learning high-quality representations for the posts in Q&amp;A sites with a neural topic model and a pre-trained model. This involves three main steps: (1) generating topic-aware representations of Q&amp;A posts with the neural topic model, (2) incorporating the corpus-level knowledge from the neural topic model to enhance the deep representations generated by the pre-trained language model, and (3) determining the most suitable answer for a given query based on the topic-aware representation and the deep representation. Moreover, we propose a two-stage training technique to improve the stability of our model. We conduct comprehensive experiments on four benchmark datasets to verify our proposed TopicAns’s effectiveness. Experiment results suggest that TopicAns consistently outperforms state-of-the-art techniques by over 30\% in terms of Precision@1.},
  archive      = {J_TOSEM},
  author       = {Yuanhang Yang and Wei He and Cuiyun Gao and Zenglin Xu and Xin Xia and Chuanyi Liu},
  doi          = {10.1145/3607189},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {20:1–25},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {TopicAns: Topic-informed architecture for answer recommendation on technical Q&amp;A site},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differentiable quantum programming with unbounded loops.
<em>TOSEM</em>, <em>33</em>(1), 19:1–63. (<a
href="https://doi.org/10.1145/3617178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of variational quantum applications has led to the development of automatic differentiation techniques in quantum computing. Existing work has formulated differentiable quantum programming with bounded loops, providing a framework for scalable gradient calculation by quantum means for training quantum variational applications. However, promising parameterized quantum applications, e.g., quantum walk and unitary implementation, cannot be trained in the existing framework due to the natural involvement of unbounded loops. To fill in the gap, we provide the first differentiable quantum programming framework with unbounded loops, including a newly designed differentiation rule, code transformation, and their correctness proof. Technically, we introduce a randomized estimator for derivatives to deal with the infinite sum in the differentiation of unbounded loops, whose applicability in classical and probabilistic programming is also discussed. We implement our framework with Python and Q# and demonstrate a reasonable sample efficiency. Through extensive case studies, we showcase an exciting application of our framework in automatically identifying close-to-optimal parameters for several parameterized quantum applications.},
  archive      = {J_TOSEM},
  author       = {Wang Fang and Mingsheng Ying and Xiaodi Wu},
  doi          = {10.1145/3617178},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {19:1–63},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Differentiable quantum programming with unbounded loops},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Testing abstractions for cyber-physical control systems.
<em>TOSEM</em>, <em>33</em>(1), 18:1–32. (<a
href="https://doi.org/10.1145/3617170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Control systems are ubiquitous and often at the core of Cyber-Physical Systems, like cars and aeroplanes. They are implemented as embedded software that interacts in closed loop with the physical world through sensors and actuators. As a consequence, the software cannot just be tested in isolation. To close the loop in a testing environment and root causing failure generated by different parts of the system, executable models are used to abstract specific components. Different testing setups can be implemented by abstracting different elements: The most common ones are model-in-the-loop, software-in-the-loop, hardware-in-the-loop, and real-physics-in-the-loop. In this article, we discuss the properties of these setups and the types of faults they can expose. We develop a comprehensive case study using the Crazyflie, a drone whose software and hardware are open source. We implement all the most common testing setups and ensure the consistent injection of faults in each of them. We inject faults in the control system and we compare with the nominal performance of the non-faulty software. Our results show the specific capabilities of the different setups in exposing faults. Contrary to intuition and previous literature, we show that the setups do not belong to a strict hierarchy, and they are best designed to maximize the differences across them rather than to be as close as possible to reality.},
  archive      = {J_TOSEM},
  author       = {Claudio Mandrioli and Max Nyberg Carlsson and Martina Maggio},
  doi          = {10.1145/3617170},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {18:1–32},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Testing abstractions for cyber-physical control systems},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the caching schemes to speed up program reduction.
<em>TOSEM</em>, <em>33</em>(1), 17:1–30. (<a
href="https://doi.org/10.1145/3617172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Program reduction is a highly practical, widely demanded technique to help debug language tools, such as compilers, interpreters and debuggers. Given a program P that exhibits a property ψ, conceptually, program reduction iteratively applies various program transformations to generate a vast number of variants from P by deleting certain tokens and returns the minimal variant preserving ψ as the result. A program reduction process inevitably generates duplicate variants, and the number of them can be significant. Our study reveals that on average 61.8\% and 24.3\% of the generated variants in two representative program reducers HDD and Perses, respectively, are duplicates. Checking them against ψ is thus redundant and unnecessary, which wastes time and computation resources. Although it seems that simply caching the generated variants can avoid redundant property tests, such a trivial method is impractical in the real world due to the significant memory footprint. Therefore, a memory-efficient caching scheme for program reduction is in great demand. This study is the first effort to conduct a systematic, extensive analysis of memory-efficient caching schemes for program reduction. We first propose to use two well-known compression methods, ZIP and SHA , to compress the generated variants before they are stored in the cache. Furthermore, our keen understanding on the program reduction process motivates us to propose a novel, domain-specific, both memory and computation-efficient caching scheme, R efreshable C ompact C aching ( RCC ). Our key insight is two-fold: ① by leveraging the correlation between variants and the original program P , we losslessly encode each variant into an equivalent , compact , canonical representation; ② periodically, stale cache entries, which will never be accessed, are timely removed to minimize the memory footprint over time. Our extensive evaluation on 31 real-world C compiler bugs demonstrates that caching schemes help avoid issuing redundant queries by 61.8\% and 24.3\% in HDD and Perses, respectively; correspondingly, the runtime performance is notably boosted by 22.8\% and 18.2\%. With regard to the memory efficiency, all three methods use less memory than the state-of-the-art string-based scheme STR . Specifically, ZIP and SHA cut down the memory footprint by more than 80\% and 90\% in both Perses and HDD compared to STR ; moreover, the highly-scalable, domain-specific RCC dominates peer schemes, and outperforms the SHA by 96.4\% and 91.74\% in HDD and Perses, respectively.},
  archive      = {J_TOSEM},
  author       = {Yongqiang Tian and Xueyan Zhang and Yiwen Dong and Zhenyang Xu and Mengxiao Zhang and Yu Jiang and Shing-Chi Cheung and Chengnian Sun},
  doi          = {10.1145/3617172},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {17:1–30},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {On the caching schemes to speed up program reduction},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). StubCoder: Automated generation and repair of stub code for
mock objects. <em>TOSEM</em>, <em>33</em>(1), 16:1–31. (<a
href="https://doi.org/10.1145/3617171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mocking is an essential unit testing technique for isolating the class under test from its dependencies. Developers often leverage mocking frameworks to develop stub code that specifies the behaviors of mock objects. However, developing and maintaining stub code is labor-intensive and error-prone. In this article, we present StubCoder to automatically generate and repair stub code for regression testing. StubCoder implements a novel evolutionary algorithm that synthesizes test-passing stub code guided by the runtime behavior of test cases. We evaluated our proposed approach on 59 test cases from 13 open source projects. Our evaluation results show that StubCoder can effectively generate stub code for incomplete test cases without stub code and repair obsolete test cases with broken stub code.},
  archive      = {J_TOSEM},
  author       = {Hengcheng Zhu and Lili Wei and Valerio Terragni and Yepang Liu and Shing-Chi Cheung and Jiarong Wu and Qin Sheng and Bing Zhang and Lihong Song},
  doi          = {10.1145/3617171},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {16:1–31},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {StubCoder: Automated generation and repair of stub code for mock objects},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatically detecting incompatible android APIs.
<em>TOSEM</em>, <em>33</em>(1), 15:1–33. (<a
href="https://doi.org/10.1145/3624737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fragmentation is a serious problem in the Android ecosystem, which is mainly caused by the fast evolution of the system itself and the various system customizations. Many efforts have attempted to mitigate its impact via approaches to automatically pinpointing compatibility issues in Android apps. We conducted a literature review to identify all the currently available approaches to addressing this issue. Within the nine identified approaches, the four issue detection tools and one incompatible API harvesting tool could be successfully executed. We tried to reproduce them based on their original datasets and then empirically compared those approaches against common datasets. Our experimental results show that existing tool capabilities are quite distinct with only a small overlap in the compatibility issues being identified. Moreover, these detection tools commonly detect compatibility issues via two separate steps including incompatible APIs gathering and compatibility issues (induced by the incorrect invocations of the identified incompatible APIs) determination. To help developers better identify compatibility issues in Android apps, we developed a new approach, AndroMevol , to systematically spot incompatible APIs as they play a crucial role in issue detection. AndroMevol was able to pinpoint 397,678 incompatible APIs against the full history of the official Android framework and 52 customized Android frameworks spanning five popular device manufacturers. Our approach could enhance the ability of the state-of-the-art detection tools by identifying many more incompatible APIs that may cause compatibility issues in Android apps and foster more advanced approaches to pinpointing all types of compatibility issues.},
  archive      = {J_TOSEM},
  author       = {Pei Liu and Yanjie Zhao and Mattia Fazzini and Haipeng Cai and John Grundy and Li Li},
  doi          = {10.1145/3624737},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {15:1–33},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Automatically detecting incompatible android APIs},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The human side of fuzzing: Challenges faced by developers
during fuzzing activities. <em>TOSEM</em>, <em>33</em>(1), 14:1–26. (<a
href="https://doi.org/10.1145/3611668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzz testing, also known as fuzzing, is a software testing technique aimed at identifying software vulnerabilities. In recent decades, fuzzing has gained increasing popularity in the research community. However, existing studies led by fuzzing experts mainly focus on improving the coverage and performance of fuzzing techniques. That is, there is still a gap in empirical knowledge regarding fuzzing, especially about the challenges developers face when they adopt fuzzing. Understanding these challenges can provide valuable insights to both practitioners and researchers on how to further improve fuzzing processes and techniques. We conducted a study to understand the challenges encountered by developers during fuzzing. More specifically, we first manually analyzed 829 randomly sampled fuzzing-related GitHub issues and constructed a taxonomy consisting of 39 types of challenges (22 related to the fuzzing process itself, 17 related to using external fuzzing providers). We then surveyed 106 fuzzing practitioners to verify the validity of our taxonomy and collected feedback on how the fuzzing process can be improved. Our taxonomy, accompanied with representative examples and highlighted implications, can serve as a reference point on how to better adopt fuzzing techniques for practitioners, and indicates potential directions researchers can work on toward better fuzzing approaches and practices.},
  archive      = {J_TOSEM},
  author       = {Olivier Nourry and Yutaro Kashiwa and Bin Lin and Gabriele Bavota and Michele Lanza and Yasutaka Kamei},
  doi          = {10.1145/3611668},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {14:1–26},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {The human side of fuzzing: Challenges faced by developers during fuzzing activities},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards causal analysis of empirical software engineering
data: The impact of programming languages on coding competitions.
<em>TOSEM</em>, <em>33</em>(1), 13:1–35. (<a
href="https://doi.org/10.1145/3611667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is abundant observational data in the software engineering domain, whereas running large-scale controlled experiments is often practically impossible. Thus, most empirical studies can only report statistical correlations —instead of potentially more insightful and robust causal relations. To support analyzing purely observational data for causal relations and to assess any differences between purely predictive and causal models of the same data, this article discusses some novel techniques based on structural causal models (such as directed acyclic graphs of causal Bayesian networks). Using these techniques, one can rigorously express, and partially validate, causal hypotheses and then use the causal information to guide the construction of a statistical model that captures genuine causal relations—such that correlation does imply causation. We apply these ideas to analyzing public data about programmer performance in Code Jam, a large world-wide coding contest organized by Google every year. Specifically, we look at the impact of different programming languages on a participant’s performance in the contest. While the overall effect associated with programming languages is weak compared to other variables—regardless of whether we consider correlational or causal links—we found considerable differences between a purely associational and a causal analysis of the very same data. The takeaway message is that even an imperfect causal analysis of observational data can help answer the salient research questions more precisely and more robustly than with just purely predictive techniques—where genuine causal effects may be confounded.},
  archive      = {J_TOSEM},
  author       = {Carlo A. Furia and Richard Torkar and Robert Feldt},
  doi          = {10.1145/3611667},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {13:1–35},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Towards causal analysis of empirical software engineering data: The impact of programming languages on coding competitions},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated and efficient test-generation for grid-based
multiagent systems: Comparing random input filtering versus constraint
solving. <em>TOSEM</em>, <em>33</em>(1), 12:1–32. (<a
href="https://doi.org/10.1145/3624736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic generation of random test inputs is an approach that can alleviate the challenges of manual test case design. However, random test cases may be ineffective in fault detection and increase testing cost, especially in systems where test execution is resource- and time-consuming. To remedy this, the domain knowledge of test engineers can be exploited to select potentially effective test cases. To this end, test selection constraints suggested by domain experts can be utilized either for filtering randomly generated test inputs or for direct generation of inputs using constraint solvers. In this article, we propose a domain specific language (DSL) for formalizing locality-based test selection constraints of autonomous agents and discuss the impact of test selection filters, specified in our DSL, on randomly generated test cases. We study and compare the performance of filtering and constraint solving approaches in generating selective test cases for different test scenario parameters and discuss the role of these parameters in test generation performance. Through our study, we provide criteria for suitability of the random data filtering approach versus the constraint solving one under the varying size and complexity of our testing problem. We formulate the corresponding research questions and answer them by designing and conducting experiments using QuickCheck for random test data generation with filtering and Z3 for constraint solving. Our observations and statistical analysis indicate that applying filters can significantly improve test efficiency of randomly generated test cases. Furthermore, we observe that test scenario parameters affect the performance of the filtering and constraint solving approaches differently. In particular, our results indicate that the two approaches have complementary strengths: random generation and filtering works best for large agent numbers and long paths, while its performance degrades in the larger grid sizes and more strict constraints. On the contrary, constraint solving has a robust performance for large grid sizes and strict constraints, while its performance degrades with more agents and long paths.},
  archive      = {J_TOSEM},
  author       = {Sina Entekhabi and Wojciech Mostowski and Mohammad Reza Mousavi},
  doi          = {10.1145/3624736},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {12:1–32},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Automated and efficient test-generation for grid-based multiagent systems: Comparing random input filtering versus constraint solving},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Horus: Accelerating kernel fuzzing through efficient host-VM
memory access procedures. <em>TOSEM</em>, <em>33</em>(1), 11:1–25. (<a
href="https://doi.org/10.1145/3611665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel fuzzing is an effective technique in operating system vulnerability detection. Fuzzers such as Syzkaller and Moonshine frequently pass highly structured data between fuzzer processes in guest virtual machines and manager processes in the host operating system to synchronize fuzzing-relevant data and information. Since the guest virtual machines’ and the host operating system’s memory spaces are mutually isolated, fuzzers conduct synchronization operations using mechanisms such as Remote Procedure Calls over TCP/IP networks, incurring significant overheads that negatively impact the fuzzer’s efficiency and effectiveness in increasing code coverage and finding vulnerabilities. In this paper, we propose Horus , a kernel fuzzing data transfer mechanism that mitigates the aforementioned data transfer overheads. Horus removes host-VM memory isolation and performs data transfers through copying to and from target memory locations in the guest virtual machine. Horus facilitates such efficient transfers through using fixed stub structures in the guest’s memory space, whose addresses, along with the guest’s RAM contents, are exposed to the host during the fuzzer’s initialization process. When conducting transfers, Horus passes highly-structured non-trivial data between the host and guest instances through copying the data directly to and from the stub structures, reducing the overall overhead significantly compared to that of using a network-based approach. We implemented Horus upon state-of-the-art kernel fuzzers Syzkaller , Moonshine and kAFL and evaluated its effectiveness. For Syzkaller and Moonshine , Horus increased their transfer speeds by 84.5\% and 85.8\% for non-trivial workloads on average and improved their fuzzing throughputs by 31.07\% and 30.62\%, respectively. Syzkaller and Moonshine both achieved a coverage speedup of 1.6× through using Horus . For kAFL, Horus improved specifically its Redqueen component’s execution speeds by 19.4\%.},
  archive      = {J_TOSEM},
  author       = {Jianzhong Liu and Yuheng Shen and Yiru Xu and Hao Sun and Yu Jiang},
  doi          = {10.1145/3611665},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {11:1–25},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Horus: Accelerating kernel fuzzing through efficient host-VM memory access procedures},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Testing causality in scientific modelling software.
<em>TOSEM</em>, <em>33</em>(1), 10:1–42. (<a
href="https://doi.org/10.1145/3607184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From simulating galaxy formation to viral transmission in a pandemic, scientific models play a pivotal role in developing scientific theories and supporting government policy decisions that affect us all. Given these critical applications, a poor modelling assumption or bug could have far-reaching consequences. However, scientific models possess several properties that make them notoriously difficult to test, including a complex input space, long execution times, and non-determinism, rendering existing testing techniques impractical. In fields such as epidemiology, where researchers seek answers to challenging causal questions, a statistical methodology known as Causal inference has addressed similar problems, enabling the inference of causal conclusions from noisy, biased, and sparse data instead of costly experiments. This article introduces the causal testing framework: a framework that uses causal inference techniques to establish causal effects from existing data, enabling users to conduct software testing activities concerning the effect of a change, such as metamorphic testing, a posteriori . We present three case studies covering real-world scientific models, demonstrating how the causal testing framework can infer metamorphic test outcomes from reused, confounded test data to provide an efficient solution for testing scientific modelling software.},
  archive      = {J_TOSEM},
  author       = {Andrew G. Clark and Michael Foster and Benedikt Prifling and Neil Walkinshaw and Robert M. Hierons and Volker Schmidt and Robert D. Turner},
  doi          = {10.1145/3607184},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {10:1–42},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Testing causality in scientific modelling software},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Framework for SQL error message design: A data-driven
approach. <em>TOSEM</em>, <em>33</em>(1), 9:1–50. (<a
href="https://doi.org/10.1145/3607180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software developers use a significant amount of time reading and interpreting error messages. However, error messages have often been based on either anecdotal evidence or expert opinion, disregarding novices, who arguably are the ones who benefit the most from effective error messages. Furthermore, the usability aspects of Structured Query Language (SQL) error messages have not received much scientific attention. In this mixed-methods study, we coded a total of 128 error messages from eight database management systems (DBMS), and using data from 311 participants, analysed 4,796 queries using regression analysis to find out if and how acknowledged error message qualities explain SQL syntax error fixing success rates. Additionally, we performed a conventional content analysis on 1,505 suggestions on how to improve SQL error messages, and based on the analysis, formulated a framework consisting of nine guidelines for SQL error message design. The results indicate that general error message qualities do not necessarily explain query fixing success in the context of SQL syntax errors and that even some novel NewSQL systems fail to account for basic error message design guidelines. The error message design framework and examples of its practical applications shown in this study are applicable in educational contexts as well as by DBMS vendors in understanding novice perspectives in error message design.},
  archive      = {J_TOSEM},
  author       = {Toni Taipalus and Hilkka Grahn},
  doi          = {10.1145/3607180},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {9:1–50},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Framework for SQL error message design: A data-driven approach},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An interleaving guided metamorphic testing approach for
concurrent programs. <em>TOSEM</em>, <em>33</em>(1), 8:1–21. (<a
href="https://doi.org/10.1145/3607182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concurrent programs are normally composed of multiple concurrent threads sharing memory space. These threads are often interleaved, which may lead to some non-determinism in execution results, even for the same program input. This poses huge challenges to the testing of concurrent programs, especially on the test result verification—that is, the prevalent existence of the oracle problem. In this article, we investigate the application of metamorphic testing (MT), a mainstream technique to address the oracle problem, into the testing of concurrent programs. Based on the unique features of interleaved executions in concurrent programming, we propose an extended notion of metamorphic relations, the core part of MT, which are particularly designed for the testing of concurrent programs. A comprehensive testing approach, namely ConMT , is thus developed and a tool is built to automate its implementation on concurrent programs written in Java. Empirical studies have been conducted to evaluate the performance of ConMT, and the experimental results show that in addition to addressing the oracle problem, ConMT outperforms the baseline traditional testing techniques with respect to a higher degree of automation, better bug detection capability, and shorter testing time. It is clear that ConMT can significantly improve the cost-effectiveness for the testing of concurrent programs and thus advances the state of the art in the field. The study also brings novelty into MT, hence promoting the fundamental research of software testing.},
  archive      = {J_TOSEM},
  author       = {Chang-Ai Sun and Hepeng Dai and Ning Geng and Huai Liu and Tsong Yueh Chen and Peng Wu and Yan Cai and Jinqiu Wang},
  doi          = {10.1145/3607182},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {8:1–21},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {An interleaving guided metamorphic testing approach for concurrent programs},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finding near-optimal configurations in colossal spaces with
statistical guarantees. <em>TOSEM</em>, <em>33</em>(1), 7:1–36. (<a
href="https://doi.org/10.1145/3611663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Software Product Line ( SPL ) is a family of similar programs. Each program is defined by a unique set of features, called a configuration , that satisfies all feature constraints. “What configuration achieves the best performance for a given workload?” is the SPL Optimization ( SPLO ) challenge. SPLO is daunting: just 80 unconstrained features yield 10 24 unique configurations, which equals the estimated number of stars in the universe. We explain (a) how uniform random sampling and random search algorithms solve SPLO more efficiently and accurately than current machine-learned performance models and (b) how to compute statistical guarantees on the quality of a returned configuration; i.e., it is within x\% of optimal with y\% confidence.},
  archive      = {J_TOSEM},
  author       = {Jeho Oh and Don Batory and Rubén Heradio},
  doi          = {10.1145/3611663},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {7:1–36},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Finding near-optimal configurations in colossal spaces with statistical guarantees},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). API entity and relation joint extraction from text via
dynamic prompt-tuned language model. <em>TOSEM</em>, <em>33</em>(1),
6:1–25. (<a href="https://doi.org/10.1145/3607188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extraction of Application Programming Interfaces (APIs) and their semantic relations from unstructured text (e.g., Stack Overflow) is a fundamental work for software engineering tasks (e.g., API recommendation). However, existing approaches are rule based and sequence labeling based. They must manually enumerate the rules or label data for a wide range of sentence patterns, which involves a significant amount of labor overhead and is exacerbated by morphological and common-word ambiguity. In contrast to matching or labeling API entities and relations, this article formulates heterogeneous API extraction and API relation extraction task as a sequence-to-sequence generation task and proposes the API Entity-Relation Joint Extraction framework (AERJE), an API entity-relation joint extraction model based on the large pre-trained language model. After training on a small number of ambiguous but correctly labeled data, AERJE builds a multi-task architecture that extracts API entities and relations from unstructured text using dynamic prompts. We systematically evaluate AERJE on a set of long and ambiguous sentences from Stack Overflow. The experimental results show that AERJE achieves high accuracy and discrimination ability in API entity-relation joint extraction, even with zero or few-shot fine-tuning.},
  archive      = {J_TOSEM},
  author       = {Qing Huang and Yanbang Sun and Zhenchang Xing and Min Yu and Xiwei Xu and Qinghua Lu},
  doi          = {10.1145/3607188},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {6:1–25},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {API entity and relation joint extraction from text via dynamic prompt-tuned language model},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). What constitutes the deployment and runtime configuration
system? An empirical study on OpenStack projects. <em>TOSEM</em>,
<em>33</em>(1), 5:1–37. (<a
href="https://doi.org/10.1145/3607186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern software systems are designed to be deployed in different configured environments (e.g., permissions, virtual resources, network connections) and adapted at runtime to different situations (e.g., memory limits, enabling/disabling features, database credentials). Such a configuration during the deployment and runtime of a software system is implemented via a set of configuration files, which together constitute what we refer to as a “configuration system.” Recent research efforts investigated the evolution and maintenance of configuration files. However, they merely focused on a limited part of the configuration system (e.g., specific infrastructure configuration files or Dockerfiles), and their results do not generalize to the whole configuration system. To cope with such a limitation, we aim to better capture and understand what files constitute a configuration system. To do so, we leverage an open card sort technique to qualitatively study 1,756 configuration files from OpenStack, a large and widely studied open source software ecosystem. Our investigation reveals the existence of nine types of configuration files, which cover the creation of the infrastructure on top of which OpenStack will be deployed, along with other types of configuration files used to customize OpenStack after its deployment. These configuration files are interconnected while being used at different deployment stages. For instance, we observe specific configuration files used during the deployment stage to create other configuration files that are used in the runtime stage. We also observe that identifying and classifying these types of files is not straightforward, as five out of the nine types can be written in similar programming languages (e.g., Python and Bash) as regular source code files. We also found that the same file extensions (e.g., Yaml ) can be used for different configuration types, making it difficult to identify and classify configuration files. Thus, we first leverage a machine learning model to identify configuration from non-configuration files, which achieved a median area under the curve (AUC) of 0.91, a median Brier score of 0.12, a median precision of 0.86, and a median recall of 0.83. Thereafter, we leverage a multi-class classification model to classify configuration files based on the nine configuration types. Our multi-class classification model achieved a median weighted AUC of 0.92, a median Brier score of 0.04, a median weighted precision of 0.84, and a median weighted recall of 0.82. Our analysis also shows that with only 100 labeled configuration and non-configuration files, our model reached a median AUC higher than 0.69. Furthermore, our configuration model requires a minimum of 100 configuration files to reach a median weighted AUC higher than 0.75.},
  archive      = {J_TOSEM},
  author       = {Narjes Bessghaier and Mohammed Sayagh and Ali Ouni and Mohamed Wiem Mkaouer},
  doi          = {10.1145/3607186},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {5:1–37},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {What constitutes the deployment and runtime configuration system? an empirical study on OpenStack projects},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Programming by example made easy. <em>TOSEM</em>,
<em>33</em>(1), 4:1–36. (<a
href="https://doi.org/10.1145/3607185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Programming by example (PBE) is an emerging programming paradigm that automatically synthesizes programs specified by user-provided input-output examples. Despite the convenience for end-users, implementing PBE tools often requires strong expertise in programming language and synthesis algorithms. Such a level of knowledge is uncommon among software developers. It greatly limits the broad adoption of PBE by the industry. To facilitate the adoption of PBE techniques, we propose a PBE framework called Bee , which leverages an “entity-action” model based on relational tables to ease PBE development for a wide but restrained range of domains. Implementing PBE tools with Bee only requires adapting domain-specific data entities and user actions to tables, with no need to design a domain-specific language or an efficient synthesis algorithm. The synthesis algorithm of Bee exploits bidirectional searching and constraint-solving techniques to address the challenge of value computation nested in table transformation. We evaluated Bee ’s effectiveness on 64 PBE tasks from three different domains and usability with a human study of 12 participants. Evaluation results show that Bee is easier to learn and use than the state-of-the-art PBE framework, and the bidirectional algorithm achieves comparable performance to domain-specifically optimized synthesizers.},
  archive      = {J_TOSEM},
  author       = {Jiarong Wu and Lili Wei and Yanyan Jiang and Shing-Chi Cheung and Luyao Ren and Chang Xu},
  doi          = {10.1145/3607185},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {4:1–36},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Programming by example made easy},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A first look at dark mode in real-world android apps.
<em>TOSEM</em>, <em>33</em>(1), 3:1–26. (<a
href="https://doi.org/10.1145/3604607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Android apps often have a “dark mode” option used in low-light situations, for those who find the conventional color palette problematic, or because of personal preferences. Typically developers add a dark mode option for their apps with different backgrounds, text, and sometimes iconic forms. We wanted to understand the actual provision of this dark mode in real-world Android apps through an empirical study of posts from Stack Overflow and real-world Android app analysis. Using these approaches, we identified the aspects of dark mode that developers implemented as well as the key difficulties they experienced in implementing it. We performed a quantitative analysis using open-coding of more than 300 discussion threads to create a taxonomy regarding the aspects discussed by developers with respect to dark mode in Android. Our quantitative analysis of over 6,000 Android apps highlights which dark mode features are typically provided in Android apps and which aspects developers care about during dark mode design. We also examined four app development support tools to see how well they aid Android app development for dark mode. From our analysis, we distilled some key lessons to guide further research and actions in aiding developers with supporting users who require such assistive features. For example, developers should be aware of the potential risks in using unsuitable dark mode design schema and researchers should take dark mode features into consideration when developing app development support tools.},
  archive      = {J_TOSEM},
  author       = {Suyu Ma and Chunyang Chen and Hourieh Khalajzadeh and John Grundy},
  doi          = {10.1145/3604607},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {3:1–26},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {A first look at dark mode in real-world android apps},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adonis: Practical and efficient control flow recovery
through OS-level traces. <em>TOSEM</em>, <em>33</em>(1), 2:1–27. (<a
href="https://doi.org/10.1145/3607187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Control flow recovery is critical to promise the software quality, especially for large-scale software in production environment. However, the efficiency of most current control flow recovery techniques is compromised due to their runtime overheads along with deployment and development costs. To tackle this problem, we propose a novel solution, Adonis , which harnesses Operating System (OS) -level traces, such as dynamic library calls and system call traces, to efficiently and safely recover control flows in practice. Adonis operates in two steps: It first identifies the call-sites of trace entries, and then it executes a pairwise symbolic execution to recover valid execution paths. This technique has several advantages. First, Adonis does not require the insertion of any probes into existing applications, thereby minimizing runtime cost . Second, given that OS-level traces are hardware-independent, Adonis can be implemented across various hardware configurations without the need for hardware-specific engineering efforts, thus reducing deployment cost . Third, as Adonis is fully automated and does not depend on manually created logs, it circumvents additional development cost . We conducted an evaluation of Adonis on representative desktop applications and real-world IoT applications. Adonis can faithfully recover the control flow with 86.8\% recall and 81.7\% precision. Compared to the state-of-the-art log-based approach, Adonis can not only cover all the execution paths recovered but also recover 74.9\% of statements that cannot be covered. In addition, the runtime cost of Adonis is 18.3× lower than the instrument-based approach; the analysis time and storage cost (indicative of the deployment cost) of Adonis is 50× smaller and 443× smaller than the hardware-based approach, respectively. To facilitate future replication and extension of this work, we have made the code and data publicly available.},
  archive      = {J_TOSEM},
  author       = {Xuanzhe Liu and Chengxu Yang and Ding Li and Yuhan Zhou and Shaofei Li and Jiali Chen and Zhenpeng Chen},
  doi          = {10.1145/3607187},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {2:1–27},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Adonis: Practical and efficient control flow recovery through OS-level traces},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Asteria-pro: Enhancing deep learning-based binary code
similarity detection by incorporating domain knowledge. <em>TOSEM</em>,
<em>33</em>(1), 1:1–40. (<a
href="https://doi.org/10.1145/3604611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Widespread code reuse allows vulnerabilities to proliferate among a vast variety of firmware. There is an urgent need to detect these vulnerable codes effectively and efficiently. By measuring code similarities, AI-based binary code similarity detection is applied to detecting vulnerable code at scale. Existing studies have proposed various function features to capture the commonality for similarity detection. Nevertheless, the significant code syntactic variability induced by the diversity of IoT hardware architectures diminishes the accuracy of binary code similarity detection. In our earlier study and the tool Asteria , we adopted a Tree-LSTM network to summarize function semantics as function commonality, and the evaluation result indicates an advanced performance. However, it still has utility concerns due to excessive time costs and inadequate precision while searching for large-scale firmware bugs. To this end, we propose a novel deep learning-enhancement architecture by incorporating domain knowledge-based pre-filtration and re-ranking modules, and we develop a prototype named Asteria-Pro based on Asteria . The pre-filtration module eliminates dissimilar functions, thus reducing the subsequent deep learning-model calculations. The re-ranking module boosts the rankings of vulnerable functions among candidates generated by the deep learning model. Our evaluation indicates that the pre-filtration module cuts the calculation time by 96.9\%, and the re-ranking module improves MRR and Recall by 23.71\% and 36.4\%, respectively. By incorporating these modules, Asteria-Pro outperforms existing state-of-the-art approaches in the bug search task by a significant margin. Furthermore, our evaluation shows that embedding baseline methods with pre-filtration and re-ranking modules significantly improves their precision. We conduct a large-scale real-world firmware bug search, and Asteria-Pro manages to detect 1,482 vulnerable functions with a high precision 91.65\%.},
  archive      = {J_TOSEM},
  author       = {Shouguo Yang and Chaopeng Dong and Yang Xiao and Yiran Cheng and Zhiqiang Shi and Zhi Li and Limin Sun},
  doi          = {10.1145/3604611},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {11},
  number       = {1},
  pages        = {1:1–40},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Asteria-pro: Enhancing deep learning-based binary code similarity detection by incorporating domain knowledge},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
