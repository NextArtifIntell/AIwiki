<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TELO_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="telo---18">TELO - 18</h2>
<ul>
<li><details>
<summary>
(2023). Multi-objective hyperparameter optimization in machine
learning—an overview. <em>TELO</em>, <em>3</em>(4), 16:1–50. (<a
href="https://doi.org/10.1145/3610536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperparameter optimization constitutes a large part of typical modern machine learning (ML) workflows. This arises from the fact that ML methods and corresponding preprocessing steps often only yield optimal performance when hyperparameters are properly tuned. But in many applications, we are not only interested in optimizing ML pipelines solely for predictive accuracy; additional metrics or constraints must be considered when determining an optimal configuration, resulting in a multi-objective optimization problem. This is often neglected in practice, due to a lack of knowledge and readily available software implementations for multi-objective hyperparameter optimization. In this work, we introduce the reader to the basics of multi-objective hyperparameter optimization and motivate its usefulness in applied ML. Furthermore, we provide an extensive survey of existing optimization strategies from the domains of evolutionary algorithms and Bayesian optimization. We illustrate the utility of multi-objective optimization in several specific ML applications, considering objectives such as operating conditions, prediction time, sparseness, fairness, interpretability, and robustness.},
  archive      = {J_TELO},
  author       = {Florian Karl and Tobias Pielok and Julia Moosbauer and Florian Pfisterer and Stefan Coors and Martin Binder and Lennart Schneider and Janek Thomas and Jakob Richter and Michel Lang and Eduardo C. Garrido-Merchán and Juergen Branke and Bernd Bischl},
  doi          = {10.1145/3610536},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {4},
  pages        = {16:1–50},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {Multi-objective hyperparameter optimization in machine Learning—An overview},
  volume       = {3},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Model-based gradient search for permutation problems.
<em>TELO</em>, <em>3</em>(4), 15:1–35. (<a
href="https://doi.org/10.1145/3628605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global random search algorithms are characterized by using probability distributions to optimize problems. Among them, generative methods iteratively update the distributions by using the observations sampled. For instance, this is the case of the well-known Estimation of Distribution Algorithms. Although successful, this family of algorithms iteratively adopts numerical methods for estimating the parameters of a model or drawing observations from it. This is often a very time-consuming task, especially in permutation-based combinatorial optimization problems. In this work, we propose using a generative method, under the model-based gradient search framework, to optimize permutation-coded problems and address the mentioned computational overheads. To that end, the Plackett–Luce model is used to define the probability distribution on the search space of permutations. Not limited to that, a parameter-free variant of the algorithm is investigated. Conducted experiments, directed to validate the work, reveal that the gradient search scheme produces better results than other analogous competitors, reducing the computational cost and showing better scalability.},
  archive      = {J_TELO},
  author       = {Josu Ceberio and Valentino Santucci},
  doi          = {10.1145/3628605},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {4},
  pages        = {15:1–35},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {Model-based gradient search for permutation problems},
  volume       = {3},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A species-based particle swarm optimization with adaptive
population size and deactivation of species for dynamic optimization
problems. <em>TELO</em>, <em>3</em>(4), 14:1–25. (<a
href="https://doi.org/10.1145/3604812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Population clustering methods, which consider the position and fitness of individuals to form sub-populations in multi-population algorithms, have shown high efficiency in tracking the moving global optimum in dynamic optimization problems. However, most of these methods use a fixed population size, making them inflexible and inefficient when the number of promising regions is unknown. The lack of a functional relationship between the population size and the number of promising regions significantly degrades performance and limits an algorithm’s agility to respond to dynamic changes. To address this issue, we propose a new species-based particle swarm optimization with adaptive population size and number of sub-populations for solving dynamic optimization problems. The proposed algorithm also benefits from a novel systematic adaptive deactivation component that, unlike the previous deactivation components, adapts the computational resource allocation to the sub-populations by considering various characteristics of both the problem and the sub-populations. We evaluate the performance of our proposed algorithm for the Generalized Moving Peaks Benchmark and compare the results with several peer approaches. The results indicate the superiority of the proposed method.},
  archive      = {J_TELO},
  author       = {Delaram Yazdani and Danial Yazdani and Donya Yazdani and Mohammad Nabi Omidvar and Amir H. Gandomi and Xin Yao},
  doi          = {10.1145/3604812},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {4},
  pages        = {14:1–25},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {A species-based particle swarm optimization with adaptive population size and deactivation of species for dynamic optimization problems},
  volume       = {3},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evolving software: Combining online learning with
mutation-based stochastic search. <em>TELO</em>, <em>3</em>(4), 13:1–32.
(<a href="https://doi.org/10.1145/3597617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms and related mutation-based methods have been used in software engineering, with recent emphasis on the problem of repairing bugs. In this work, programs are typically not synthesized from a random start. Instead, existing solutions—which may be flawed or inefficient—are taken as starting points, with the evolutionary process searching for useful improvements. This approach, however, introduces a challenge for the search algorithm: what is the optimal number of neutral mutations that should be combined? Too much is likely to introduce errors and break the program while too little hampers the search process, inducing the classic tradeoff between exploration and exploitation. In the context of software improvement, this work considers MWRepair, an algorithm for enhancing mutation-based searches, which uses online learning to optimize the tradeoff between exploration and exploitation. The aggressiveness parameter governs how many individual mutations should be applied simultaneously to an individual between fitness evaluations. MWRepair is evaluated in the context of automated program repair problems, where the goal is repairing software bugs with minimal human involvement. The article analyzes the search space for automated program repair induced by neutral mutations, finding that the greatest probability of finding successful repairs often occurs when many neutral mutations are applied to the original program. Moreover, repair probability follows a characteristic, unimodal distribution. MWRepair uses online learning to leverage this property, finding both rare and multi-edit repairs to defects in the popular Defects4J benchmark set of buggy Java programs.},
  archive      = {J_TELO},
  author       = {Joseph Renzullo and Westley Weimer and Stephanie Forrest},
  doi          = {10.1145/3597617},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {4},
  pages        = {13:1–32},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {Evolving software: Combining online learning with mutation-based stochastic search},
  volume       = {3},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Curiosity creates diversity in policy search. <em>ACM
Transactions on Evolutionary Learning</em>, <em>3</em>(3), 12:1–20. (<a
href="https://doi.org/10.1145/3605782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {When searching for policies, reward-sparse environments often lack sufficient information about which behaviors to improve upon or avoid. In such environments, the policy search process is bound to blindly search for reward-yielding transitions and no early reward can bias this search in one direction or another. A way to overcome this is to use intrinsic motivation in order to explore new transitions until a reward is found. In this work, we use a recently proposed definition of intrinsic motivation, Curiosity, in an evolutionary policy search method. We propose Curiosity-ES, 1 an evolutionary strategy adapted to use Curiosity as a fitness metric. We compare Curiosity-ES with other evolutionary algorithms intended for exploration, as well as with Curiosity-based reinforcement learning, and find that Curiosity-ES can generate higher diversity without the need for an explicit diversity criterion and leads to more policies which find reward.},
  archive  = {J},
  author   = {Paul-Antoine Le Tolguenec and Emmanuel Rachelson and Yann Besse and Dennis G. Wilson},
  doi      = {10.1145/3605782},
  journal  = {ACM Transactions on Evolutionary Learning},
  number   = {3},
  pages    = {12:1–20},
  title    = {Curiosity creates diversity in policy search},
  volume   = {3},
  year     = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). P2P energy trading through prospect theory, differential
evolution, and reinforcement learning. <em>ACM Transactions on
Evolutionary Learning</em>, <em>3</em>(3), 11:1–22. (<a
href="https://doi.org/10.1145/3603148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Peer-to-peer (P2P) energy trading is a decentralized energy market where local energy prosumers act as peers, trading energy among each other. Existing works in this area largely overlook the importance of user behavioral modeling and assume users’ sustained active participation and full compliance in the decision-making process. To overcome these unrealistic assumptions, and their deleterious consequences, in this article, we propose an automated P2P energy-trading framework that specifically considers the users’ perception by exploiting prospect theory . We formalize an optimization problem that maximizes the buyers’ perceived utility while matching energy production and demand. We prove that the problem is NP-hard and we propose a Differential Evolution-based Algorithm for Trading Energy ( DEbATE ) heuristic. Additionally, we propose two automated pricing solutions to improve the sellers’ profit based on reinforcement learning. The first solution, named Pricing mechanism with Q-learning and Risk-sensitivity ( PQR ), is based on Q-learning. Additionally, given the scalability issues of PQR , we propose a Deep Q-Network-based algorithm called ProDQN that exploits deep learning and a novel loss function rooted in prospect theory. Results based on real traces of energy consumption and production, as well as realistic prospect theory functions, show that our approaches achieve 26\% higher perceived value for buyers and generate 7\% more reward for sellers, compared to recent state-of-the-art approaches.},
  archive  = {J},
  author   = {Ashutosh Timilsina and Simone Silvestri},
  doi      = {10.1145/3603148},
  journal  = {ACM Transactions on Evolutionary Learning},
  number   = {3},
  pages    = {11:1–22},
  title    = {P2P energy trading through prospect theory, differential evolution, and reinforcement learning},
  volume   = {3},
  year     = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combining evolution and deep reinforcement learning for
policy search: A survey. <em>ACM Transactions on Evolutionary
Learning</em>, <em>3</em>(3), 10:1–20. (<a
href="https://doi.org/10.1145/3569096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Deep neuroevolution and deep Reinforcement Learning have received a lot of attention over the past few years. Some works have compared them, highlighting their pros and cons, but an emerging trend combines them so as to benefit from the best of both worlds. In this article, we provide a survey of this emerging trend by organizing the literature into related groups of works and casting all the existing combinations in each group into a generic framework. We systematically cover all easily available papers irrespective of their publication status, focusing on the combination mechanisms rather than on the experimental results. In total, we cover 45 algorithms more recent than 2017. We hope this effort will favor the growth of the domain by facilitating the understanding of the relationships between the methods, leading to deeper analyses, outlining missing useful comparisons and suggesting new combinations of mechanisms.},
  archive  = {J},
  author   = {Olivier Sigaud},
  doi      = {10.1145/3569096},
  journal  = {ACM Transactions on Evolutionary Learning},
  number   = {3},
  pages    = {10:1–20},
  title    = {Combining evolution and deep reinforcement learning for policy search: A survey},
  volume   = {3},
  year     = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial to the “evolutionary reinforcement learning”
special issue. <em>ACM Transactions on Evolutionary Learning</em>,
<em>3</em>(3), 9:1–2. (<a
href="https://doi.org/10.1145/3624559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Adam Gaier and Giuseppe Paolo and Antoine Cully},
  doi     = {10.1145/3624559},
  journal = {ACM Transactions on Evolutionary Learning},
  number  = {3},
  pages   = {9:1–2},
  title   = {Editorial to the “Evolutionary reinforcement learning” special issue},
  volume  = {3},
  year    = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Covariance matrix adaptation evolutionary strategy with
worst-case ranking approximation for min–max optimization and its
application to berthing control tasks. <em>TELO</em>, <em>3</em>(2),
8:1–32. (<a href="https://doi.org/10.1145/3603716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we consider a continuous min–max optimization problem min x ∈ 𝕏 max y ∈ 𝕐 f ( x, y ) whose objective function is a black-box. We propose a novel approach to minimize the worst-case objective function F ( x ) = max y ∈ 𝕐 f ( x, y ) directly using a covariance matrix adaptation evolution strategy in which the rankings of solution candidates are approximated by our proposed worst-case ranking approximation mechanism. We develop two variants of worst-case ranking approximation combined with a covariance matrix adaptation evolution strategy and approximate gradient ascent as numerical solvers for the inner maximization problem. Numerical experiments show that our proposed approach outperforms several existing approaches when the objective function is a smooth strongly convex–concave function and the interaction between x and y is strong. We investigate the advantages of the proposed approach for problems where the objective function is not limited to smooth strongly convex–concave functions. The effectiveness of the proposed approach is demonstrated in the robust berthing control problem with uncertainty.},
  archive      = {J_TELO},
  author       = {Atsuhiro Miyagi and Yoshiki Miyauchi and Atsuo Maki and Kazuto Fukuchi and Jun Sakuma and Youhei Akimoto},
  doi          = {10.1145/3603716},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {2},
  pages        = {8:1–32},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {Covariance matrix adaptation evolutionary strategy with worst-case ranking approximation for Min–Max optimization and its application to berthing control tasks},
  volume       = {3},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transformation-interaction-rational representation for
symbolic regression: A detailed analysis of SRBench results. <em>ACM
Transactions on Evolutionary Learning</em>, <em>3</em>(2), 7:1–19. (<a
href="https://doi.org/10.1145/3597312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Symbolic Regression searches for a parametric model with the optimal value of the parameters that best fits a set of samples to a measured target. The desired solution has a balance between accuracy and interpretability. Commonly, there is no constraint in the way the functions are composed in the expression or where the numerical parameters are placed, which can potentially lead to expressions that require a nonlinear optimization to find the optimal parameters. The representation called Interaction-Transformation alleviates this problem by describing expressions as a linear regression of the composition of functions applied to the interaction of the variables. One advantage is that any model that follows this representation is linear in its parameters, allowing an efficient computation. More recently, this representation was extended by applying a univariate function to the rational function of two Interaction-Transformation expressions, called Transformation-Interaction-Rational ( TIR ). The use of this representation was shown to be competitive with the current literature of Symbolic Regression. In this article, we make a detailed analysis of these results using the SRBench benchmark. For this purpose, we split the datasets into different categories to understand the algorithm behavior in different settings. We also test the use of nonlinear optimization to adjust the numerical parameters instead of Ordinary Least Squares. We find through the experiments that TIR has some difficulties handling high-dimensional and noisy datasets, especially when most of the variables are composed of random noise. These results point to new directions for improving the evolutionary search of TIR expressions.},
  archive  = {J},
  author   = {Fabrício Olivetti De França},
  doi      = {10.1145/3597312},
  journal  = {ACM Transactions on Evolutionary Learning},
  number   = {2},
  pages    = {7:1–19},
  title    = {Transformation-interaction-rational representation for symbolic regression: A detailed analysis of SRBench results},
  volume   = {3},
  year     = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online damage recovery for physical robots with hierarchical
quality-diversity. <em>ACM Transactions on Evolutionary Learning</em>,
<em>3</em>(2), 6:1–23. (<a
href="https://doi.org/10.1145/3596912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In real-world environments, robots need to be resilient to damages and robust to unforeseen scenarios. Quality-Diversity (QD) algorithms have been successfully used to make robots adapt to damages in seconds by leveraging a diverse set of learned skills. A high diversity of skills increases the chances of a robot to succeed at overcoming new situations since there are more potential alternatives to solve a new task. However, finding and storing a large behavioural diversity of multiple skills often leads to an increase in computational complexity. Furthermore, robot planning in a large skill space is an additional challenge that arises with an increased number of skills. Hierarchical structures can help to reduce this search and storage complexity by breaking down skills into primitive skills. In this article, we extend the analysis of the Hierarchical Trial and Error algorithm, which uses a hierarchical behavioural repertoire to learn diverse skills and leverages them to make the robot adapt quickly in the physical world. We show that the hierarchical decomposition of skills enables the robot to learn more complex behaviours while keeping the learning of the repertoire tractable. Experiments with a hexapod robot both in simulation and the physical world show that our method solves a maze navigation task with up to, respectively, 20\% and 43\% less actions than the best baselines while having 78\% less complete failures.},
  archive  = {J},
  author   = {Maxime Allard and Simón C. Smith and Konstantinos Chatzilygeroudis and Bryan Lim and Antoine Cully},
  doi      = {10.1145/3596912},
  journal  = {ACM Transactions on Evolutionary Learning},
  number   = {2},
  pages    = {6:1–23},
  title    = {Online damage recovery for physical robots with hierarchical quality-diversity},
  volume   = {3},
  year     = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Crossover for cardinality constrained optimization. <em>ACM
Transactions on Evolutionary Learning</em>, <em>3</em>(2), 5:1–32. (<a
href="https://doi.org/10.1145/3603629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {To understand better how and why crossover can benefit constrained optimization, we consider pseudo-Boolean functions with an upper bound B on the number of 1-bits allowed in the length- n bit string (i.e., a cardinality constraint). We investigate the natural translation of the OneMax test function to this setting, a linear function where B bits have a weight of 1+ 1/ n and the remaining bits have a weight of 1. Friedrich et al. [TCS 2020] gave a bound of Θ ( n 2 ) for the expected running time of the (1+1) EA on this function. Part of the difficulty when optimizing this problem lies in having to improve individuals meeting the cardinality constraint by flipping a 1 and a 0 simultaneously. The experimental literature proposes balanced operators, preserving the number of 1-bits, as a remedy. We show that a balanced mutation operator optimizes the problem in O(n log n ) if n-B = O (1). However, if n-B = Θ ( n ), we show a bound of Ω ( n 2 ), just as for classic bit mutation. Crossover together with a simple island model gives running times of O ( n 2 / log n ) (uniform crossover) and \(O(n\sqrt {n})\) (3-ary majority vote crossover). For balanced uniform crossover with Hamming-distance maximization for diversity, we show a bound of O ( n log n ). As an additional contribution, we present an extensive analysis of different balanced crossover operators from the literature.},
  archive  = {J},
  author   = {Tobias Friedrich and Timo Kötzing and Aishwarya Radhakrishnan and Leon Schiller and Martin Schirneck and Georg Tennigkeit and Simon Wietheger},
  doi      = {10.1145/3603629},
  journal  = {ACM Transactions on Evolutionary Learning},
  number   = {2},
  pages    = {5:1–32},
  title    = {Crossover for cardinality constrained optimization},
  volume   = {3},
  year     = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial to the “best of GECCO 2022” special issue: Part i.
<em>ACM Transactions on Evolutionary Learning</em>, <em>3</em>(2),
4:1–2. (<a href="https://doi.org/10.1145/3606034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Jonathan Fieldsend and Markus Wagner},
  doi     = {10.1145/3606034},
  journal = {ACM Transactions on Evolutionary Learning},
  number  = {2},
  pages   = {4:1–2},
  title   = {Editorial to the “Best of GECCO 2022” special issue: Part i},
  volume  = {3},
  year    = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Factors impacting diversity and effectiveness of evolved
modular robots. <em>ACM Transactions on Evolutionary Learning</em>,
<em>3</em>(1), 3:1–33. (<a
href="https://doi.org/10.1145/3587101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In many natural environments, different forms of living organisms successfully accomplish the same task while being diverse in shape and behavior. This biodiversity is what made life capable of adapting to disrupting changes. Being able to reproduce biodiversity in artificial agents, while still optimizing them for a particular task, might increase their applicability to scenarios where human response to unexpected changes is not possible. In this work, we focus on Voxel-based Soft Robots (VSRs), a form of robots that grants great freedom in the design of both morphology and controller and is hence promising in terms of biodiversity. We use evolutionary computation for optimizing, at the same time, morphology and controller of VSRs for the task of locomotion. We investigate experimentally whether three key factors—representation, Evolutionary Algorithm (EA), and environment—impact the emergence of biodiversity and if this occurs at the expense of effectiveness. We devise an automatic machine learning pipeline for systematically characterizing the morphology and behavior of robots resulting from the optimization process. We classify the robots into species and then measure biodiversity in populations of robots evolved in a multitude of conditions resulting from the combination of different morphology representations, controller representations, EAs, and environments. The experimental results suggest that, in general, EA and environment matter more than representation. We also propose a novel EA based on a speciation mechanism that operates on morphology and behavior descriptors and we show that it allows to jointly evolve morphology and controller of effective and diverse VSRs.},
  archive  = {J},
  author   = {Federico Pigozzi and Eric Medvet and Alberto Bartoli and Marco Rochelli},
  doi      = {10.1145/3587101},
  journal  = {ACM Transactions on Evolutionary Learning},
  number   = {1},
  pages    = {3:1–33},
  title    = {Factors impacting diversity and effectiveness of evolved modular robots},
  volume   = {3},
  year     = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The generation of visually credible adversarial examples
with genetic algorithms. <em>ACM Transactions on Evolutionary
Learning</em>, <em>3</em>(1), 2:1–44. (<a
href="https://doi.org/10.1145/3582276">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {An adversarial example is an input that a neural network misclassifies although the input differs only slightly from an input that the network classifies correctly. Adversarial examples are used to augment neural network training data, measure the vulnerability of neural networks, and provide intuitive interpretations of neural network output that humans can understand. Although adversarial examples are defined in the literature as similar to authentic input from the perspective of humans, the literature measures similarity with mathematical norms that are not scientifically correlated with human perception. Our main contributions are to construct a genetic algorithm (GA) that generates adversarial examples more similar to authentic input than do existing methods and to demonstrate with a survey that humans perceive those adversarial examples to have greater visual similarity than existing methods. The GA incorporates a neural network, and we test many parameter sets to determine which fitness function, selection operator, mutation operator, and neural network generate adversarial examples most visually similar to authentic input. We establish which mathematical norms are most correlated with human perception, which permits future research to incorporate the human perspective without testing many norms or conducting intensive surveys with human subjects. We also document a tradeoff between speed and quality in adversarial examples generated by GAs and existing methods. Although existing adversarial methods are faster, a GA provides higher-quality adversarial examples in terms of visual similarity and feasibility of adversarial examples. We apply the GA to the Modified National Institute of Standards and Technology (MNIST) and Canadian Institute for Advanced Research (CIFAR-10) datasets.},
  archive  = {J},
  author   = {James R. Bradley and A. Paul Blossom},
  doi      = {10.1145/3582276},
  journal  = {ACM Transactions on Evolutionary Learning},
  number   = {1},
  pages    = {2:1–44},
  title    = {The generation of visually credible adversarial examples with genetic algorithms},
  volume   = {3},
  year     = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Empirical analysis of PGA-MAP-elites for neuroevolution in
uncertain domains. <em>ACM Transactions on Evolutionary Learning</em>,
<em>3</em>(1), 1:1–32. (<a
href="https://doi.org/10.1145/3577203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Quality-Diversity algorithms, among which are the Multi-dimensional Archive of Phenotypic Elites (MAP-Elites), have emerged as powerful alternatives to performance-only optimisation approaches as they enable generating collections of diverse and high-performing solutions to an optimisation problem. However, they are often limited to low-dimensional search spaces and deterministic environments. The recently introduced Policy Gradient Assisted MAP-Elites (PGA-MAP-Elites) algorithm overcomes this limitation by pairing the traditional Genetic operator of MAP-Elites with a gradient-based operator inspired by deep reinforcement learning. This new operator guides mutations toward high-performing solutions using policy gradients (PG). In this work, we propose an in-depth study of PGA-MAP-Elites. We demonstrate the benefits of PG on the performance of the algorithm and the reproducibility of the generated solutions when considering uncertain domains. We firstly prove that PGA-MAP-Elites is highly performant in both deterministic and uncertain high-dimensional environments, decorrelating the two challenges it tackles. Secondly, we show that in addition to outperforming all the considered baselines, the collections of solutions generated by PGA-MAP-Elites are highly reproducible in uncertain environments, approaching the reproducibility of solutions found by Quality-Diversity approaches built specifically for uncertain applications. Finally, we propose an ablation and in-depth analysis of the dynamic of the PG-based variation. We demonstrate that the PG variation operator is determinant to guarantee the performance of PGA-MAP-Elites but is only essential during the early stage of the process, where it finds high-performing regions of the search space.},
  archive  = {J},
  author   = {Manon Flageat and Félix Chalumeau and Antoine Cully},
  doi      = {10.1145/3577203},
  journal  = {ACM Transactions on Evolutionary Learning},
  number   = {1},
  pages    = {1:1–32},
  title    = {Empirical analysis of PGA-MAP-elites for neuroevolution in uncertain domains},
  volume   = {3},
  year     = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explainable regression via prototypes. <em>ACM Transactions
on Evolutionary Learning</em>, <em>2</em>(4), 14:1–26. (<a
href="https://doi.org/10.1145/3576903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Model interpretability/explainability is increasingly a concern when applying machine learning to real-world problems. In this article, we are interested in explaining regression models by exploiting prototypes, which are exemplar cases in the problem domain. Previous works focused on finding prototypes that are representative of all training data but ignore the model predictions, i.e., they explain the data distribution but not necessarily the predictions. We propose a two-level model-agnostic method that considers prototypes to provide global and local explanations for regression problems and that account for both the input features and the model output. M-PEER (Multiobjective Prototype-basEd Explanation for Regression) is based on a multi-objective evolutionary method that optimizes both the error of the explainable model and two other “semantics”-based measures of interpretability adapted from the context of classification, namely, model fidelity and stability. We compare the proposed method with the state-of-the-art method based on prototypes for explanation—ProtoDash—and with other methods widely used in correlated areas of machine learning, such as instance selection and clustering. We conduct experiments on 25 datasets, and results demonstrate significant gains of M-PEER over other strategies, with an average of 12\% improvement in the proposed metrics (i.e., model fidelity and stability) and 17\% in root mean squared error (RMSE) when compared to ProtoDash.},
  archive  = {J},
  author   = {Renato Miranda Filho and Anísio M. Lacerda and Gisele L. Pappa},
  doi      = {10.1145/3576903},
  journal  = {ACM Transactions on Evolutionary Learning},
  number   = {4},
  pages    = {14:1–26},
  title    = {Explainable regression via prototypes},
  volume   = {2},
  year     = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Theoretical and empirical analysis of parameter control
mechanisms in the (1 + (λ, λ)) genetic algorithm. <em>ACM Transactions
on Evolutionary Learning</em>, <em>2</em>(4), 13:1–39. (<a
href="https://doi.org/10.1145/3564755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The self-adjusting (1 + (λ, λ)) GA is the best known genetic algorithm for problems with a good fitness-distance correlation as in OneMax . It uses a parameter control mechanism for the parameter λ that governs the mutation strength and the number of offspring. However, on multimodal problems, the parameter control mechanism tends to increase λ uncontrollably. We study this problem for the standard Jump k benchmark problem class using runtime analysis. The self-adjusting (1 + (λ, λ)) GA behaves like a (1 + n )  EA whenever the maximum value for λ is reached. This is ineffective for problems where large jumps are required. Capping λ at smaller values is beneficial for such problems. Finally, resetting λ to 1 allows the parameter to cycle through the parameter space. We show that resets are effective for all Jump k problems: the self-adjusting (1 + (λ, λ)) GA performs as well as the (1 + 1) EA with the optimal mutation rate and evolutionary algorithms with heavy-tailed mutation, apart from a small polynomial overhead. Along the way, we present new general methods for translating existing runtime bounds from the (1 + 1) EA to the self-adjusting (1 + (λ, λ)) GA. We also show that the algorithm presents a bimodal parameter landscape with respect to λ on Jump k . For appropriate n and k , the landscape features a local optimum in a wide basin of attraction and a global optimum in a narrow basin of attraction. To our knowledge this is the first proof of a bimodal parameter landscape for the runtime of an evolutionary algorithm on a multimodal problem.},
  archive  = {J},
  author   = {Mario Alejandro Hevia Fajardo and Dirk Sudholt},
  doi      = {10.1145/3564755},
  journal  = {ACM Transactions on Evolutionary Learning},
  number   = {4},
  pages    = {13:1–39},
  title    = {Theoretical and empirical analysis of parameter control mechanisms in the (1 + (λ, λ)) genetic algorithm},
  volume   = {2},
  year     = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
