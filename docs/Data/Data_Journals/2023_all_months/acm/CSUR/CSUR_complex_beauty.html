<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>CSUR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="csur---126">CSUR - 126</h2>
<ul>
<li><details>
<summary>
(2023). Bridging the gap between spatial and spectral domains: A
unified framework for graph neural networks. <em>CSUR</em>,
<em>56</em>(5), 126:1–42. (<a
href="https://doi.org/10.1145/3627816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning’s performance has been extensively recognized recently. Graph neural networks (GNNs) are designed to deal with graph-structural data that classical deep learning does not easily manage. Since most GNNs were created using distinct theories, direct comparisons are impossible. Prior research has primarily concentrated on categorizing existing models, with little attention paid to their intrinsic connections. The purpose of this study is to establish a unified framework that integrates GNNs based on spectral graph and approximation theory. The framework incorporates a strong integration between spatial- and spectral-based GNNs while tightly associating approaches that exist within each respective domain.},
  archive      = {J_CSUR},
  author       = {Zhiqian Chen and Fanglan Chen and Lei Zhang and Taoran Ji and Kaiqun Fu and Liang Zhao and Feng Chen and Lingfei Wu and Charu Aggarwal and Chang-Tien Lu},
  doi          = {10.1145/3627816},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {5},
  pages        = {126:1–42},
  shortjournal = {ACM Comput. Surv.},
  title        = {Bridging the gap between spatial and spectral domains: A unified framework for graph neural networks},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explainability in deep reinforcement learning: A review into
current methods and applications. <em>CSUR</em>, <em>56</em>(5),
125:1–35. (<a href="https://doi.org/10.1145/3623377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of Deep Reinforcement Learning (DRL) schemes has increased dramatically since their first introduction in 2015. Though uses in many different applications are being found, they still have a problem with the lack of interpretability. This has bread a lack of understanding and trust in the use of DRL solutions from researchers and the general public. To solve this problem, the field of Explainable Artificial Intelligence has emerged. This entails a variety of different methods that look to open the DRL black boxes, ranging from the use of interpretable symbolic Decision Trees to numerical methods like Shapley Values. This review looks at which methods are being used and for which applications. This is done to identify which models are the best suited to each application or if a method is being underutilised.},
  archive      = {J_CSUR},
  author       = {Thomas Hickling and Abdelhafid Zenati and Nabil Aouf and Phillippa Spencer},
  doi          = {10.1145/3623377},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {5},
  pages        = {125:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Explainability in deep reinforcement learning: A review into current methods and applications},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Control schemes for quadrotor UAV: Taxonomy and survey.
<em>CSUR</em>, <em>56</em>(5), 124:1–32. (<a
href="https://doi.org/10.1145/3617652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quadrotor Unmanned Aerial Vehicle (UAV) is an unstable system, so it needs to be controlled efficiently and intelligently. Moreover, due to its non-linear, coupled, and under-actuated nature, the quadrotor has become an important research platform to study and validate various control theories. Different control approaches have been used to control the quadrotor UAV. In this context, a comprehensive study of different control schemes is presented in this research. First, an overview of the working and different applications of quadrotor UAVs is presented. Second, a mathematical model of the quadrotor is discussed. Later, the experimental results of various existing control techniques are discussed and compared. The various control schemes discussed and described for quadrotors are; Proportional Integral and Derivative (PID), Linear Quadratic Regulator (LQR), H-infinity ( H ∞ ), Sliding Mode Control (SMC), Feedback Linearization (FBL), Model Predictive Control (MPC), Fuzzy Logic Control (FLC), Artificial Neural Network (ANN), Iterative Learning Control (ILC), Reinforcement Learning Control (RLC), Brain Emotional Learning Control (BELC), Memory Based Control (MBC), Nested Saturation Control (NSC), and Hybrid Controllers (HC). Comparison is done among all the control techniques and it is concluded that the hybrid control method gives improved results. This survey presents a broad overview of the state-of-the-art in UAV design, control, and implementation for real-life applications.},
  archive      = {J_CSUR},
  author       = {Adnan Khalid and Zohaib Mushtaq and Saad Arif and Kamran Zeb and Muhammad Attique Khan and Sambit Bakshi},
  doi          = {10.1145/3617652},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {5},
  pages        = {124:1–32},
  shortjournal = {ACM Comput. Surv.},
  title        = {Control schemes for quadrotor UAV: Taxonomy and survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rare category analysis for complex data: A review.
<em>CSUR</em>, <em>56</em>(5), 123:1–35. (<a
href="https://doi.org/10.1145/3626520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Though the sheer volume of data that is collected is immense, it is the rare categories that are often the most important in many high-impact domains, ranging from financial fraud detection in online transaction networks to emerging trend detection in social networks, from spam image detection on social media platforms to rare disease diagnosis in medical decision support systems. The unique challenges of rare category analysis include (1) the highly skewed class distribution; (2) the non-separable nature of the rare categories from the majority classes; (3) data and task heterogeneity; and (4) the time-evolving property of the input data sources. This survey reviews state-of-the-art techniques used in complex rare category analysis, where the majority classes have a smooth distribution while the minority classes exhibit the compactness property in the feature space or subspace. Rare category analysis aims to identify, characterize, represent, and interpret anomalies that not only show statistical significance but also exhibit interesting patterns (e.g., compactness, high-order structures, showing in a burst). We introduce our study, define the problem setting, and describe the unique challenges of complex rare category analysis. We then present a comprehensive review of recent advances that are designed for this problem setting, from rare category exploration without any label information to rare category exposition that characterizes rare examples with a compact representation, from the representation of rare patterns in a salient embedding space to the interpretation the prediction results and providing relevant clues for the end-users’ interpretation. Finally we discuss potential challenges and shed light on the future directions for complex rare category analysis. 1},
  archive      = {J_CSUR},
  author       = {Dawei Zhou and Jingrui He},
  doi          = {10.1145/3626520},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {5},
  pages        = {123:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Rare category analysis for complex data: A review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on conflict detection in IoT-based smart homes.
<em>CSUR</em>, <em>56</em>(5), 122:1–40. (<a
href="https://doi.org/10.1145/3629517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the adoption of IoT-based smart homes continues to grow, the importance of addressing potential conflicts becomes increasingly vital for ensuring seamless functionality and user satisfaction. In this survey, we introduce a novel conflict taxonomy, complete with formal definitions of each conflict type that may arise within the smart home environment. We design an advanced conflict model to effectively categorize these conflicts, setting the stage for our in-depth review of recent research in the field. By employing our proposed model, we systematically classify conflicts and present a comprehensive overview of cutting-edge conflict detection approaches. This extensive analysis allows us to highlight similarities, clarify significant differences, and uncover prevailing trends in conflict detection techniques. In conclusion, we shed light on open issues and suggest promising avenues for future research to foster accelerated development and deployment of IoT-based smart homes, ultimately enhancing their overall performance and user experience.},
  archive      = {J_CSUR},
  author       = {Bing Huang and Dipankar Chaki and Athman Bouguettaya and Kwok-Yan Lam},
  doi          = {10.1145/3629517},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {5},
  pages        = {122:1–40},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on conflict detection in IoT-based smart homes},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computational technologies for fashion recommendation: A
survey. <em>CSUR</em>, <em>56</em>(5), 121:1–45. (<a
href="https://doi.org/10.1145/3627100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fashion recommendation is a key research field in computational fashion research and has attracted considerable interest in the computer vision, multimedia, and information retrieval communities in recent years. Due to the great demand for applications, various fashion recommendation tasks, such as personalized fashion product recommendation, complementary (mix-and-match) recommendation, and outfit recommendation, have been posed and explored in the literature. The continuing research attention and advances impel us to look back and in-depth into the field for a better understanding. In this article, we comprehensively review recent research efforts on fashion recommendation from a technological perspective. We first introduce fashion recommendation at a macro level and analyze its characteristics and differences with general recommendation tasks. We then clearly categorize different fashion recommendation efforts into several sub-tasks and focus on each sub-task in terms of its problem formulation, research focus, state-of-the-art methods, and limitations. We also summarize the datasets proposed in the literature for use in fashion recommendation studies to give readers a brief illustration. Finally, we discuss several promising directions for future research in this field. Overall, this survey systematically reviews the development of fashion recommendation research. It also discusses the current limitations and gaps between academic research and the real needs of the fashion industry. In the process, we offer a deep insight into how the fashion industry could benefit from the computational technologies of fashion recommendation.},
  archive      = {J_CSUR},
  author       = {Yujuan Ding and Zhihui Lai and P.Y. Mok and Tat-Seng Chua},
  doi          = {10.1145/3627100},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {5},
  pages        = {121:1–45},
  shortjournal = {ACM Comput. Surv.},
  title        = {Computational technologies for fashion recommendation: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comprehensive and comparative analysis of QCA-based circuit
designs for next-generation computation. <em>CSUR</em>, <em>56</em>(5),
120:1–36. (<a href="https://doi.org/10.1145/3622932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the past several decades, VLSI design has been focused on lowering the size, power, and delay. As of now, this miniaturization does not seems to be a possible way to address the demands of consumers. Quantum Dot Cellular Automata (QCA) technology is a promising technique that is able to provide low-power high-speed circuits at nano-scale. Much work has been done in this area where the researchers have proposed a variety of combinational and sequential logic circuits for future computation. This article presents a concrete review of design approaches, logic circuits, clocking schemes, implementation tools, and possible fabrication methodologies presented so far in QCA technology. A critical comparative analysis is provided on the basis of reported performance parameters in the domain. The aim of this article is to collect all necessary information into a single source, highlight the research challenges to be taken in the near future, and enlighten the path for upcoming researchers in the area.},
  archive      = {J_CSUR},
  author       = {Vaibhav Jain and Devendra Kumar Sharma and Hari Mohan Gaur and Ashutosh Kumar Singh and Xiaoqing Wen},
  doi          = {10.1145/3622932},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {5},
  pages        = {120:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Comprehensive and comparative analysis of QCA-based circuit designs for next-generation computation},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on searchable symmetric encryption. <em>CSUR</em>,
<em>56</em>(5), 119:1–42. (<a
href="https://doi.org/10.1145/3617991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outsourcing data to the cloud has become prevalent, so Searchable Symmetric Encryption (SSE), one of the methods for protecting outsourced data, has arisen widespread interest. Moreover, many novel technologies and theories have emerged, especially for the attacks on SSE and privacy-preserving. But most surveys related to SSE concentrate on one aspect (e.g., single keyword search, fuzzy keyword search) or lack in-depth analysis. Therefore, we revisit the existing work and conduct a comprehensive analysis and summary. We provide an overview of state-of-the-art in SSE and focus on the privacy it can protect. Generally, (1) we study the work of the past few decades and classify SSE based on query expressiveness. Meanwhile, we summarize the existing schemes and analyze their performance on efficiency, storage space, index structures, and so on.; (2) we complement the gap in the privacy of SSE and introduce in detail the attacks and the related defenses; (3) we discuss the open issues and challenges in existing schemes and future research directions. We desire that our work will help novices to grasp and understand SSE comprehensively. We expect it can inspire the SSE community to discover more crucial leakages and design more efficient and secure constructions.},
  archive      = {J_CSUR},
  author       = {Feng Li and Jianfeng Ma and Yinbin Miao and Ximeng Liu and Jianting Ning and Robert H. Deng},
  doi          = {10.1145/3617991},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {5},
  pages        = {119:1–42},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on searchable symmetric encryption},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of computer vision technologies in urban and
controlled-environment agriculture. <em>CSUR</em>, <em>56</em>(5),
118:1–39. (<a href="https://doi.org/10.1145/3626186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the evolution of agriculture to its next stage, Agriculture 5.0, artificial intelligence will play a central role. Controlled-environment agriculture, or CEA, is a special form of urban and suburban agricultural practice that offers numerous economic, environmental, and social benefits, including shorter transportation routes to population centers, reduced environmental impact, and increased productivity. Due to its ability to control environmental factors, CEA couples well with computer vision (CV) in the adoption of real-time monitoring of the plant conditions and autonomous cultivation and harvesting. The objective of this article is to familiarize CV researchers with agricultural applications and agricultural practitioners with the solutions offered by CV. We identify five major CV applications in CEA, analyze their requirements and motivation, and survey the state-of-the-art as reflected in 68 technical papers using deep learning methods. In addition, we discuss five key subareas of computer vision and how they related to these CEA problems, as well as 14 vision-based CEA datasets. We hope the survey will help researchers quickly gain a bird’s-eye view of the striving research area and will spark inspiration for new research and development.},
  archive      = {J_CSUR},
  author       = {Jiayun Luo and Boyang Li and Cyril Leung},
  doi          = {10.1145/3626186},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {5},
  pages        = {118:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of computer vision technologies in urban and controlled-environment agriculture},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards practical secure neural network inference: The
journey so far and the road ahead. <em>CSUR</em>, <em>56</em>(5),
117:1–37. (<a href="https://doi.org/10.1145/3628446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks (NNs) have become one of the most important tools for artificial intelligence. Well-designed and trained NNs can perform inference (e.g., make decisions or predictions) on unseen inputs with high accuracy. Using NNs often involves sensitive data: Depending on the specific use case, the input to the NN and/or the internals of the NN  (e.g., the weights and biases) may be sensitive. Thus, there is a need for techniques for performing NN inference securely, ensuring that sensitive data remain secret. In the past few years, several approaches have been proposed for secure neural network inference. These approaches achieve better and better results in terms of efficiency, security, accuracy, and applicability, thus making big progress toward practical secure neural network inference. The proposed approaches make use of many different techniques, such as homomorphic encryption and secure multi-party computation. The aim of this article is to give an overview of the main approaches proposed so far, their different properties, and the techniques used. In addition, remaining challenges toward large-scale deployments are identified.},
  archive      = {J_CSUR},
  author       = {Zoltán Ádám Mann and Christian Weinert and Daphnee Chabal and Joppe W. Bos},
  doi          = {10.1145/3628446},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {5},
  pages        = {117:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Towards practical secure neural network inference: The journey so far and the road ahead},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic collection of medical image datasets for deep
learning. <em>CSUR</em>, <em>56</em>(5), 116:1–51. (<a
href="https://doi.org/10.1145/3615862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The astounding success made by artificial intelligence in healthcare and other fields proves that it can achieve human-like performance. However, success always comes with challenges. Deep learning algorithms are data dependent and require large datasets for training. Many junior researchers face a lack of data for a variety of reasons. Medical image acquisition, annotation, and analysis are costly, and their usage is constrained by ethical restrictions. They also require several other resources, such as professional equipment and expertise. That makes it difficult for novice and non-medical researchers to have access to medical data. Thus, as comprehensively as possible, this article provides a collection of medical image datasets with their associated challenges for deep learning research. We have collected the information of approximately 300 datasets and challenges mainly reported between 2007 and 2020 and categorized them into four categories: head and neck, chest and abdomen, pathology and blood, and others. The purpose of our work is to provide a list, as up-to-date and complete as possible, that can be used as a reference to easily find the datasets for medical image analysis and the information related to these datasets.},
  archive      = {J_CSUR},
  author       = {Johann Li and Guangming Zhu and Cong Hua and Mingtao Feng and Basheer Bennamoun and Ping Li and Xiaoyuan Lu and Juan Song and Peiyi Shen and Xu Xu and Lin Mei and Liang Zhang and Syed Afaq Ali Shah and Mohammed Bennamoun},
  doi          = {10.1145/3615862},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {5},
  pages        = {116:1–51},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic collection of medical image datasets for deep learning},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning and physics: A survey of integrated models.
<em>CSUR</em>, <em>56</em>(5), 115:1–33. (<a
href="https://doi.org/10.1145/3611383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive modeling of various systems around the world is extremely essential from the physics and engineering perspectives. The recognition of different systems and the capacity to predict their future behavior can lead to numerous significant applications. For the most part, physics is frequently used to model different systems. Using physical modeling can also very well help the resolution of complexity and achieve superior performance with the emerging field of novel artificial intelligence and the challenges associated with it. Physical modeling provides data and knowledge that offer a meaningful and complementary understanding about the system. So, by using enriched data and training phases, the overall general integrated model achieves enhanced accuracy. The effectiveness of hybrid physics-guided or machine learning-guided models has been validated by experimental results of diverse use cases. Increased accuracy, interpretability, and transparency are the results of such hybrid models. In this article, we provide a detailed overview of how machine learning and physics can be integrated into an interactive approach. Regarding this, we propose a classification of possible interactions between physical modeling and machine learning techniques. Our classification includes three types of approaches: (1) physics-guided machine learning (2) machine learning-guided physics, and (3) mutually-guided physics and ML. We studied the models and specifications for each of these three approaches in-depth for this survey.},
  archive      = {J_CSUR},
  author       = {Azra Seyyedi and Mahdi Bohlouli and Seyedehsan Nedaaee Oskoee},
  doi          = {10.1145/3611383},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {5},
  pages        = {115:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Machine learning and physics: A survey of integrated models},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). From digital media to empathic spaces: A systematic review
of empathy research in extended reality environments. <em>CSUR</em>,
<em>56</em>(5), 114:1–40. (<a
href="https://doi.org/10.1145/3626518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in extended reality (XR) technologies have enabled new and increasingly realistic empathy tools and experiences. In XR, all interactions take place in different spatial contexts, all with different features, affordances, and constraints. We present a systematic literature survey of recent work on empathy in XR. As a result, we contribute a research roadmap with three future opportunities and six open questions in XR-enabled empathy research across both physical and virtual spaces.},
  archive      = {J_CSUR},
  author       = {Ville Paananen and Mohammad Sina Kiarostami and Lee Lik-Hang and Tristan Braud and Simo Hosio},
  doi          = {10.1145/3626518},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {5},
  pages        = {114:1–40},
  shortjournal = {ACM Comput. Surv.},
  title        = {From digital media to empathic spaces: A systematic review of empathy research in extended reality environments},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of deep learning for low-shot object detection.
<em>CSUR</em>, <em>56</em>(5), 113:1–37. (<a
href="https://doi.org/10.1145/3626312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection has achieved a huge breakthrough with deep neural networks and massive annotated data. However, current detection methods cannot be directly transferred to the scenario where the annotated data is scarce due to the severe overfitting problem. Although few-shot learning and zero-shot learning have been extensively explored in the field of image classification, it is indispensable to design new methods for object detection in the data-scarce scenario, since object detection has an additional challenging localization task. Low-Shot Object Detection (LSOD) is an emerging research topic of detecting objects from a few or even no annotated samples, consisting of One-Shot Object Localization (OSOL), Few-Shot Object Detection (FSOD), and Zero-Shot Object Detection (ZSOD). This survey provides a comprehensive review of LSOD methods. First, we propose a thorough taxonomy of LSOD methods and analyze them systematically, comprising some extensional topics of LSOD (semi-supervised LSOD, weakly supervised LSOD, and incremental LSOD). Then, we indicate the pros and cons of current LSOD methods with a comparison of their performance.Finally, we discuss the challenges and promising directions of LSOD to provide guidance for future works.},
  archive      = {J_CSUR},
  author       = {Qihan Huang and Haofei Zhang and Mengqi Xue and Jie Song and Mingli Song},
  doi          = {10.1145/3626312},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {5},
  pages        = {113:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of deep learning for low-shot object detection},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Location reference recognition from texts: A survey and
comparison. <em>CSUR</em>, <em>56</em>(5), 112:1–37. (<a
href="https://doi.org/10.1145/3625819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A vast amount of location information exists in unstructured texts, such as social media posts, news stories, scientific articles, web pages, travel blogs, and historical archives. Geoparsing refers to recognizing location references from texts and identifying their geospatial representations. While geoparsing can benefit many domains, a summary of its specific applications is still missing. Further, there is a lack of a comprehensive review and comparison of existing approaches for location reference recognition, which is the first and core step of geoparsing. To fill these research gaps, this review first summarizes seven typical application domains of geoparsing: geographic information retrieval, disaster management, disease surveillance, traffic management, spatial humanities, tourism management, and crime management. We then review existing approaches for location reference recognition by categorizing these approaches into four groups based on their underlying functional principle: rule-based, gazetteer matching–based, statistical learning-–based, and hybrid approaches. Next, we thoroughly evaluate the correctness and computational efficiency of the 27 most widely used approaches for location reference recognition based on 26 public datasets with different types of texts (e.g., social media posts and news stories) containing 39,736 location references worldwide. Results from this thorough evaluation can help inform future methodological developments and can help guide the selection of proper approaches based on application needs.},
  archive      = {J_CSUR},
  author       = {Xuke Hu and Zhiyong Zhou and Hao Li and Yingjie Hu and Fuqiang Gu and Jens Kersten and Hongchao Fan and Friederike Klan},
  doi          = {10.1145/3625819},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {5},
  pages        = {112:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Location reference recognition from texts: A survey and comparison},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic review of IoT security: Research potential,
challenges, and future directions. <em>CSUR</em>, <em>56</em>(5),
111:1–40. (<a href="https://doi.org/10.1145/3625094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) encompasses a network of physical objects embedded with sensors, software, and data processing technologies that can establish connections and exchange data with other devices and systems via the Internet. IoT devices are incorporated into various products, ranging from ordinary household items to complex industrial appliances. Despite the increasing demand for IoT, security concerns have impeded its development. This article systematically reviews IoT security research, focusing on vulnerabilities, challenges, technologies, and future directions. It surveys 171 recent publications in the field, providing a comprehensive discussion on the development status, challenges, and solutions in IoT. The article outlines IoT architecture patterns and typical features, evaluates existing limitations, and explores strategies for enhancing IoT security. Additionally, the article delves into known IoT attacks and discusses the security countermeasures and mechanisms to address these challenges. It explores the functional requirements of IoT security and explores related technologies and standards. Finally, the article discusses potential future research directions in IoT security.},
  archive      = {J_CSUR},
  author       = {Wen Fei and Hiroyuki Ohno and Srinivas Sampalli},
  doi          = {10.1145/3625094},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {5},
  pages        = {111:1–40},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic review of IoT security: Research potential, challenges, and future directions},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluation of XR applications: A tertiary review.
<em>CSUR</em>, <em>56</em>(5), 110:1–35. (<a
href="https://doi.org/10.1145/3626517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extended reality (XR) applications—encompassing virtual reality, augmented reality, and mixed reality—are finding their way into multiple domains. Each area has different motivations for employing and different criteria for evaluating XR. Multiple surveys describe XR and its evaluation in particular fields. However, these surveys do not always agree on the definition of XR. This lack of consensus makes it hard to compare and use learnings from XR research across areas. Through a tertiary systematic literature review, we analyzed 81 surveys from several fields to provide a comprehensive summary of the state of XR research regarding the evaluation of XR applications. We seek to understand (i) how is XR defined? (ii) why is XR employed? (iii) how is XR evaluated? (iv) what are the main criticisms and future research paths outlined by the surveys? and (v) how good are the surveys? We present our findings describing XR research in 10 categories. Given our findings, we propose that future research should build upon a solid XR taxonomy and depart from effectiveness into efficiency research—to understand not only if but also how XR achieves the desired outcomes.},
  archive      = {J_CSUR},
  author       = {Artur Becker and Carla M. Dal Sasso Freitas},
  doi          = {10.1145/3626517},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {5},
  pages        = {110:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Evaluation of XR applications: A tertiary review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Co-located human–human interaction analysis using nonverbal
cues: A survey. <em>CSUR</em>, <em>56</em>(5), 109:1–41. (<a
href="https://doi.org/10.1145/3626516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated co-located human–human interaction analysis has been addressed by the use of nonverbal communication as measurable evidence of social and psychological phenomena. We survey the computing studies (since 2010) detecting phenomena related to social traits (e.g., leadership, dominance, and personality traits), social roles/relations, and interaction dynamics (e.g., group cohesion, engagement, and rapport). Our target is to identify the nonverbal cues and computational methodologies resulting in effective performance. This survey differs from its counterparts by involving the widest spectrum of social phenomena and interaction settings (free-standing conversations, meetings, dyads, and crowds). We also present a comprehensive summary of the related datasets and outline future research directions, which are regarding the implementation of artificial intelligence, dataset curation, and privacy-preserving interaction analysis. Some major observations are: the most often used nonverbal cue, computational method, interaction environment, and sensing approach are speaking activity, support vector machines, and meetings composed of 3–4 persons equipped with microphones and cameras, respectively; multimodal features are prominently performing better; deep learning architectures showed improved performance in overall, but there exist many phenomena whose detection has never been implemented through deep models. We also identified several limitations such as the lack of scalable benchmarks, annotation reliability tests, cross-dataset experiments, and explainability analysis.},
  archive      = {J_CSUR},
  author       = {Cigdem Beyan and Alessandro Vinciarelli and Alessio Del Bue},
  doi          = {10.1145/3626516},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {5},
  pages        = {109:1–41},
  shortjournal = {ACM Comput. Surv.},
  title        = {Co-located Human–Human interaction analysis using nonverbal cues: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of stability in topic modeling: Metrics for
assessing and techniques for improving stability. <em>CSUR</em>,
<em>56</em>(5), 108:1–32. (<a
href="https://doi.org/10.1145/3623269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topic modeling includes a variety of machine learning techniques for identifying latent themes in a corpus of documents. Generating an exact solution (i.e., finding global optimum) is often computationally intractable. Various optimization techniques (e.g., Variational Bayes or Gibbs Sampling) are employed to generate topic solutions approximately by finding local optima. Such an approximation often begins with a random initialization, which leads to different results with different initializations. The term “stability” refers to a topic model’s ability to produce solutions that are partially or completely identical across multiple runs with different random initializations. Although a variety of work has been done analyzing, measuring, or improving stability, no single paper has provided a thorough review of different stability metrics nor of various techniques that improved the stability of a topic model. This paper fills that gap and provides a systematic review of different approaches to measure stability and of various techniques that are intended to improve stability. It also describes differences and similarities between stability measures and other metrics (e.g., generality, coherence). Finally, the paper discusses the importance of analyzing both stability and quality metrics to assess and to compare topic models.},
  archive      = {J_CSUR},
  author       = {Amin Hosseiny Marani and Eric P. S. Baumer},
  doi          = {10.1145/3623269},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {5},
  pages        = {108:1–32},
  shortjournal = {ACM Comput. Surv.},
  title        = {A review of stability in topic modeling: Metrics for assessing and techniques for improving stability},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Survey of information encoding techniques for DNA.
<em>CSUR</em>, <em>56</em>(4), 107:1–30. (<a
href="https://doi.org/10.1145/3626233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The yearly global production of data is growing exponentially, outpacing the capacity of existing storage media, such as tape and disk, and surpassing our ability to store it. DNA storage—the representation of arbitrary information as sequences of nucleotides—offers a promising storage medium. DNA is nature’s information-storage molecule of choice and has a number of key properties: It is extremely dense, offering the theoretical possibility of storing 455 EB/g; it is durable, with a half-life of approximately 520 years that can be increased to thousands of years when DNA is chilled and stored dry; and it is amenable to automated synthesis and sequencing. Furthermore, biochemical processes that act on DNA potentially enable highly parallel data manipulation. While biological information is encoded in DNA via a specific mapping from triplet sequences of nucleotides to amino acids, DNA storage is not limited to a single encoding scheme, and there are many possible ways to map data to chemical sequences of nucleotides for synthesis, storage, retrieval, and data manipulation. However, there are several biological, error-tolerance, and information-retrieval considerations that an encoding scheme needs to address to be viable. This comprehensive review focuses on comparing existing work done in encoding arbitrary data within DNA in terms of their encoding schemes, methods to address biological constraints, and measures to provide error correction. We compare encoding approaches on the overall information density and coverage they achieve, as well as the data-retrieval method they use (i.e., sequential or random access). We also discuss the background and evolution of the encoding schemes.},
  archive      = {J_CSUR},
  author       = {Thomas Heinis and Roman Sokolovskii and Jamie J. Alnasir},
  doi          = {10.1145/3626233},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {4},
  pages        = {107:1–30},
  shortjournal = {ACM Comput. Surv.},
  title        = {Survey of information encoding techniques for DNA},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 40 years of designing code comprehension experiments: A
systematic mapping study. <em>CSUR</em>, <em>56</em>(4), 106:1–42. (<a
href="https://doi.org/10.1145/3626522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The relevance of code comprehension in a developer’s daily work was recognized more than 40 years ago. Consequently, many experiments were conducted to find out how developers could be supported during code comprehension and which code characteristics contribute to better comprehension. Today, such studies are more common than ever. While this is great for advancing the field, the number of publications makes it difficult to keep an overview. Additionally, designing rigorous code comprehension experiments with human participants is a challenging task, and the multitude of design options can make it difficult for researchers, especially newcomers to the field, to select a suitable design. We therefore conducted a systematic mapping study of 95 source code comprehension experiments published between 1979 and 2019. By structuring the design characteristics of code comprehension studies, we provide a basis for subsequent discussion of the huge diversity of design options in the face of a lack of basic research on their consequences and comparability. We describe what topics have been studied, as well as how these studies have been designed, conducted, and reported. Frequently chosen design options and deficiencies are pointed out to support researchers of all levels of domain expertise in designing their own studies.},
  archive      = {J_CSUR},
  author       = {Marvin Wyrich and Justus Bogner and Stefan Wagner},
  doi          = {10.1145/3626522},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {4},
  pages        = {106:1–42},
  shortjournal = {ACM Comput. Surv.},
  title        = {40 years of designing code comprehension experiments: A systematic mapping study},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diffusion models: A comprehensive survey of methods and
applications. <em>CSUR</em>, <em>56</em>(4), 105:1–39. (<a
href="https://doi.org/10.1145/3626235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models have emerged as a powerful new family of deep generative models with record-breaking performance in many applications, including image synthesis, video generation, and molecule design. In this survey, we provide an overview of the rapidly expanding body of work on diffusion models, categorizing the research into three key areas: efficient sampling, improved likelihood estimation, and handling data with special structures. We also discuss the potential for combining diffusion models with other generative models for enhanced results. We further review the wide-ranging applications of diffusion models in fields spanning from computer vision, natural language processing, temporal data modeling, to interdisciplinary applications in other scientific disciplines. This survey aims to provide a contextualized, in-depth look at the state of diffusion models, identifying the key areas of focus and pointing to potential areas for further exploration. Github: https://github.com/YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy},
  archive      = {J_CSUR},
  author       = {Ling Yang and Zhilong Zhang and Yang Song and Shenda Hong and Runsheng Xu and Yue Zhao and Wentao Zhang and Bin Cui and Ming-Hsuan Yang},
  doi          = {10.1145/3626235},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {4},
  pages        = {105:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Diffusion models: A comprehensive survey of methods and applications},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Defect categorization in compilers: A multi-vocal literature
review. <em>CSUR</em>, <em>56</em>(4), 104:1–42. (<a
href="https://doi.org/10.1145/3626313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Context: Compilers are the fundamental tools for software development. Thus, compiler defects can disrupt development productivity and propagate errors into developer-written software source code. Categorizing defects in compilers can inform practitioners and researchers about the existing defects in compilers and techniques that can be used to identify defects systematically. Objective: The goal of this paper is to help researchers understand the nature of defects in compilers by conducting a review of Internet artifacts and peer-reviewed publications that study defect characteristics of compilers. Methodology: We conduct a multi-vocal literature review (MLR) with 26 publications and 32 Internet artifacts to characterize compiler defects. Results: From our MLR, we identify 13 categories of defects, amongst which optimization defects have been the most reported defects in our artifacts publications. We observed 15 defect identification techniques tailored for compilers and no single technique identifying all observed defect categories. Conclusion: Our MLR lays the groundwork for practitioners and researchers to identify defects in compilers systematically.},
  archive      = {J_CSUR},
  author       = {Akond Rahman and Dibyendu Brinto Bose and Farhat Lamia Barsha and Rahul Pandita},
  doi          = {10.1145/3626313},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {4},
  pages        = {104:1–42},
  shortjournal = {ACM Comput. Surv.},
  title        = {Defect categorization in compilers: A multi-vocal literature review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of single image rain removal based on deep
learning. <em>CSUR</em>, <em>56</em>(4), 103:1–35. (<a
href="https://doi.org/10.1145/3625818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rain removal task is to restore a clean image from the contaminated image by separating the background. Since the rise of deep learning in 2016, the task of image deraining has also stepped into the era of deep learning. Numerous researchers have devoted themselves to the field of computer vision and pattern recognition. However, there is still a lack of comprehensive review papers focused on using deep learning to perform rain removal tasks. In this paper, we present a comprehensive review of single image deraining based on deep learning over the past ten years. Two categories of deraining methods are discussed: the data-driven approach and the data-model-based approach. For the first type, we compare the existing network structures and loss functions. For the second type, we analyze the combination of different deraining models with deep learning, and each branch method is introduced in detail. Additionally, we quantitatively investigate the performances of the existing state-of-the-art methods on both publicly synthetic and real datasets. The trend of image deraining is also discussed.},
  archive      = {J_CSUR},
  author       = {Zhipeng Su and Yixiong Zhang and Jianghong Shi and Xiao-Ping Zhang},
  doi          = {10.1145/3625818},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {4},
  pages        = {103:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of single image rain removal based on deep learning},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dataset discovery and exploration: A survey. <em>CSUR</em>,
<em>56</em>(4), 102:1–37. (<a
href="https://doi.org/10.1145/3626521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data scientists are tasked with obtaining insights from data. However, suitable data is often not immediately at hand, and there may be many potentially relevant datasets in a data lake or in open data repositories. As a result, data discovery and exploration are necessary, but often time consuming, steps in a data analysis workflow. Data discovery is the process of identifying datasets that may meet an information need. Data exploration is the process of understanding the properties of candidate datasets and the relationships between them. Data discovery and data exploration often go hand in hand and benefit from tool support. This article surveys research areas that can contribute to data discovery and exploration, particularly considering dataset search, data navigation, data annotation and schema inference. For each of these areas, we identify key dimensions that can be used to characterize approaches and the values they can hold, and apply the dimensions to describe and compare prominent results. In addition, by surveying several adjacent areas that are often considered in isolation, we identify recurring techniques and alternative approaches to related challenges, thereby placing results within a wider context than is generally considered.},
  archive      = {J_CSUR},
  author       = {Norman W. Paton and Jiaoyan Chen and Zhenyu Wu},
  doi          = {10.1145/3626521},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {4},
  pages        = {102:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Dataset discovery and exploration: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of privacy attacks in machine learning.
<em>CSUR</em>, <em>56</em>(4), 101:1–34. (<a
href="https://doi.org/10.1145/3624010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As machine learning becomes more widely used, the need to study its implications in security and privacy becomes more urgent. Although the body of work in privacy has been steadily growing over the past few years, research on the privacy aspects of machine learning has received less focus than the security aspects. Our contribution in this research is an analysis of more than 45 papers related to privacy attacks against machine learning that have been published during the past seven years. We propose an attack taxonomy, together with a threat model that allows the categorization of different attacks based on the adversarial knowledge, and the assets under attack. An initial exploration of the causes of privacy leaks is presented, as well as a detailed analysis of the different attacks. Finally, we present an overview of the most commonly proposed defenses and a discussion of the open problems and future directions identified during our analysis.},
  archive      = {J_CSUR},
  author       = {Maria Rigaki and Sebastian Garcia},
  doi          = {10.1145/3624010},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {4},
  pages        = {101:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of privacy attacks in machine learning},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed scrum: A case meta-analysis. <em>CSUR</em>,
<em>56</em>(4), 100:1–37. (<a
href="https://doi.org/10.1145/3626519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed Scrum adapts the Scrum project management framework for geographically distributed software teams. Experimentally evaluating the effectiveness of Distributed Scrum is impractical, but many case studies and experience reports describe teams and projects that used Distributed Scrum. This article synthesizes the results of these cases using case meta-analysis, a technique for quantitatively analyzing qualitative case reports. On balance, the evidence suggests that Distributed Scrum has no impact, positive or negative, on overall project success. Consequently, claims by agile consultants who present Distributed Scrum as a recipe for project success should be treated with great caution, while researchers should investigate more varied perspectives to identify the real drivers of success in distributed and global software development.},
  archive      = {J_CSUR},
  author       = {Ronnie De Souza Santos and Paul Ralph and Arham Arshad and Klaas-Jan Stol},
  doi          = {10.1145/3626519},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {4},
  pages        = {100:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Distributed scrum: A case meta-analysis},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Economic systems in the metaverse: Basics, state of the art,
and challenges. <em>CSUR</em>, <em>56</em>(4), 99:1–33. (<a
href="https://doi.org/10.1145/3626315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Economic systems play pivotal roles in the metaverse. However, we have not yet found an overview that systematically introduces economic systems for the metaverse. Therefore, we review the state-of-the-art solutions, architectures, and systems related to economic systems. When investigating those state-of-the-art studies, we keep two questions in mind: (1) What is the framework of economic systems in the context of the metaverse? and (2) What activities would economic systems engage in the metaverse? This article aims to disclose insights into the economic systems that work for both the current and the future metaverse. To have a clear overview of the economic system framework, we mainly discuss the connections among three fundamental elements in the metaverse, i.e., digital creation, digital assets, and the digital trading market. After that, we elaborate on each topic of the proposed economic system framework. Those topics include incentive mechanisms, monetary systems, digital wallets, decentralized finance activities, and cross-platform interoperability for the metaverse. For each topic, we mainly discuss three questions: (a) the rationale of this topic, (b) why the metaverse needs this topic, and (c) how this topic will evolve in the metaverse. Through this overview, we wish readers can better understand what economic systems the metaverse needs and the insights behind the economic activities in the metaverse.},
  archive      = {J_CSUR},
  author       = {Huang Huawei and Zhang Qinnan and Li Taotao and Yang Qinglin and Yin Zhaokang and Wu Junhao and Zehui Xiong and Zhu Jianming and Jiajing Wu and Zibin Zheng},
  doi          = {10.1145/3626315},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {4},
  pages        = {99:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Economic systems in the metaverse: Basics, state of the art, and challenges},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on collaborative learning for intelligent
autonomous systems. <em>CSUR</em>, <em>56</em>(4), 98:1–37. (<a
href="https://doi.org/10.1145/3625544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This survey examines approaches to promote Collaborative Learning in distributed systems for emergent Intelligent Autonomous Systems (IAS). The study involves a literature review of Intelligent Autonomous Systems based on Collaborative Learning, analyzing aspects in four dimensions: computing environment, performance concerns, system management, and privacy concerns, mapping the significant requirements of systems to the emerging Artificial intelligence models. Furthermore, the article explores Collaborative Learning Taxonomy for IAS to demonstrate the correlation between IoT, Big Data, and Human-in-the-Loop. Several technological open issues exist in the aforementioned domains (such as in applications of autonomous driving, robotics in healthcare, cyber security, and others) to effectively achieve the future deployment of Intelligent Autonomous Systems. This Survey aims to organize concepts around IAS, indicating the approaches used to extract knowledge from data in Collaborative Learning for IAS, and identifying open issues. Moreover, it presents a guide to overcoming the existing challenges in decision-making mechanisms with IAS, providing a holistic vision of Big Data and Human-in-the-Loop.},
  archive      = {J_CSUR},
  author       = {Julio C. S. Dos Anjos and Kassiano J. Matteussi and Fernanda C. Orlandi and Jorge L. V. Barbosa and Jorge Sá Silva and Luiz F. Bittencourt and Cláudio F. R. Geyer},
  doi          = {10.1145/3625544},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {4},
  pages        = {98:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on collaborative learning for intelligent autonomous systems},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Early detection of bark beetle attack using remote sensing
and machine learning: A review. <em>CSUR</em>, <em>56</em>(4), 97:1–40.
(<a href="https://doi.org/10.1145/3625387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bark beetle outbreaks can have serious consequences on forest ecosystem processes, biodiversity, forest structure and function, and economies. Thus, accurate and timely detection of bark beetle infestations in the early stage (known as green-attack detection) is crucial to mitigate the further impact, develop proactive forest management activities, and minimize economic losses. Incorporating remote sensing (RS) data with machine learning (ML) (or deep learning (DL)) can provide a great alternative to the current approaches that primarily rely on aerial surveys and field surveys, which can be impractical over vast areas. Existing approaches that exploit RS and ML/DL exhibit substantial diversity due to the wide range of factors involved. This article provides a comprehensive review of past and current advances in green-attack detection from three primary perspectives: bark beetle and host interactions, RS, and ML/DL. In contrast to prior efforts, this review encompasses all RS systems and emphasizes ML/DL methods to investigate their strengths and weaknesses. We parse existing literature based on multi- or hyperspectral analyses and distill their knowledge based on bark beetle species and attack phases with a primary emphasis on early stages of attacks, host trees, study regions, RS platforms and sensors, spectral/spatial/temporal resolutions, spectral signatures, spectral vegetation indices, ML approaches, learning schemes, task categories, models, algorithms, classes/clusters, features, and DL networks and architectures. Although DL-based methods and the random forest algorithm showed promising results, highlighting their potential to detect subtle changes across visible, thermal, and short-wave infrared spectral regions, their effectiveness remains limited, and high uncertainties persist due to the subtle distinctions between healthy and attacked trees. To inspire novel solutions to these shortcomings, we delve into the principal challenges and opportunities from different perspectives, enabling a deeper understanding of the current state of research and guiding future research directions.},
  archive      = {J_CSUR},
  author       = {S. Mojtaba Marvasti-Zadeh and Devin Goodsman and Nilanjan Ray and Nadir Erbilgin},
  doi          = {10.1145/3625387},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {4},
  pages        = {97:1–40},
  shortjournal = {ACM Comput. Surv.},
  title        = {Early detection of bark beetle attack using remote sensing and machine learning: A review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Assessing aircraft security: A comprehensive survey and
methodology for evaluation. <em>CSUR</em>, <em>56</em>(4), 96:1–40. (<a
href="https://doi.org/10.1145/3610772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sophistication and complexity of cyber attacks and the variety of targeted platforms have grown in recent years. Adversaries are targeting a wide range of platforms, e.g., enterprise networks, mobile phones, PCs, and industrial control systems. The past few years have also seen various cyber attacks on transportation systems, including attacks on ports, trains, airports, and aircraft. Due to the enormous potential damage inherent in attacking vehicles carrying many passengers and the lack of security measures applied in existing airborne systems, the vulnerability of aircraft systems is one of the most concerning topics in the vehicle security domain. This article provides a comprehensive review of aircraft systems and components and their various networks, emphasizing the cyber threats they are exposed to and the impact of a cyber attack on these components and networks and an aircraft’s essential capabilities. In addition, we present a comprehensive and in-depth taxonomy that standardizes the knowledge and understanding of cyber security in the avionics field. The taxonomy divides attack techniques into relevant categories (tactics) reflecting the various phases of the adversarial attack lifecycle and maps existing attacks according to the MITRE ATT&amp;CK methodology. To contribute to increased understanding of the potential risks, we categorize the identified threats related to the various systems based on STRIDE threat model and demonstrate the practical application of this taxonomy in the analysis of real-world attack use cases. Finally, we review various mitigation techniques aimed at addressing security risks related to aircraft systems. Future work directions are presented as guidelines for industry and academia.},
  archive      = {J_CSUR},
  author       = {Edan Habler and Ron Bitton and Asaf Shabtai},
  doi          = {10.1145/3610772},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {4},
  pages        = {96:1–40},
  shortjournal = {ACM Comput. Surv.},
  title        = {Assessing aircraft security: A comprehensive survey and methodology for evaluation},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic quality assessment of wikipedia articles—a
systematic literature review. <em>CSUR</em>, <em>56</em>(4), 95:1–37.
(<a href="https://doi.org/10.1145/3625286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wikipedia is the world’s largest online encyclopedia, but maintaining article quality through collaboration is challenging. Wikipedia designed a quality scale, but with such a manual assessment process, many articles remain unassessed. We review existing methods for automatically measuring the quality of Wikipedia articles, identifying and comparing machine learning algorithms, article features, quality metrics, and used datasets, examining 149distinct studies, and exploring commonalities and gaps in them. The literature is extensive, and the approaches follow past technological trends. However, machine learning is still not widely used by Wikipedia, and we hope that our analysis helps future researchers change that reality.},
  archive      = {J_CSUR},
  author       = {Pedro Miguel Moás and Carla Teixeira Lopes},
  doi          = {10.1145/3625286},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {4},
  pages        = {95:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Automatic quality assessment of wikipedia Articles—A systematic literature review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A comprehensive survey on automatic knowledge graph
construction. <em>CSUR</em>, <em>56</em>(4), 94:1–62. (<a
href="https://doi.org/10.1145/3618295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic knowledge graph construction aims at manufacturing structured human knowledge. To this end, much effort has historically been spent extracting informative fact patterns from different data sources. However, more recently, research interest has shifted to acquiring conceptualized structured knowledge beyond informative data. In addition, researchers have also been exploring new ways of handling sophisticated construction tasks in diversified scenarios. Thus, there is a demand for a systematic review of paradigms to organize knowledge structures beyond data-level mentions. To meet this demand, we comprehensively survey more than 300 methods to summarize the latest developments in knowledge graph construction. A knowledge graph is built in three steps: knowledge acquisition, knowledge refinement, and knowledge evolution. The processes of knowledge acquisition are reviewed in detail, including obtaining entities with fine-grained types and their conceptual linkages to knowledge graphs; resolving coreferences; and extracting entity relationships in complex scenarios. The survey covers models for knowledge refinement, including knowledge graph completion, and knowledge fusion. Methods to handle knowledge evolution are also systematically presented, including condition knowledge acquisition, condition knowledge graph completion, and knowledge dynamic. We present the paradigms to compare the distinction among these methods along the axis of the data environment, motivation, and architecture. Additionally, we also provide briefs on accessible resources that can help readers to develop practical knowledge graph systems. The survey concludes with discussions on the challenges and possible directions for future exploration.},
  archive      = {J_CSUR},
  author       = {Lingfeng Zhong and Jia Wu and Qian Li and Hao Peng and Xindong Wu},
  doi          = {10.1145/3618295},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {4},
  pages        = {94:1–62},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive survey on automatic knowledge graph construction},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generative models for synthetic urban mobility data: A
systematic literature review. <em>CSUR</em>, <em>56</em>(4), 93:1–37.
(<a href="https://doi.org/10.1145/3610224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although highly valuable for a variety of applications, urban mobility data are rarely made openly available, as it contains sensitive personal information. Synthetic data aims to solve this issue by generating artificial data that resembles an original dataset in structural and statistical characteristics, but omits sensitive information. For mobility data, a large number of corresponding models have been proposed in the past decade. This systematic review provides a structured comparative overview of the current state of this heterogeneous, active field of research. A special focus is put on the applicability of the reviewed models in practice.},
  archive      = {J_CSUR},
  author       = {Alexandra Kapp and Julia Hansmeyer and Helena Mihaljević},
  doi          = {10.1145/3610224},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {4},
  pages        = {93:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Generative models for synthetic urban mobility data: A systematic literature review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Defenses to membership inference attacks: A survey.
<em>CSUR</em>, <em>56</em>(4), 92:1–34. (<a
href="https://doi.org/10.1145/3620667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) has gained widespread adoption in a variety of fields, including computer vision and natural language processing. However, ML models are vulnerable to membership inference attacks (MIAs), which can infer whether access data was used in training a target model, thus compromising the privacy of training data. This has led researchers to focus on protecting the privacy of ML. To date, although there have been extensive efforts to defend against MIAs, we still lack a comprehensive understanding of the progress made in this area, which can often impede our ability to design the most effective defense strategies. In this article, we aim to fill this critical knowledge gap by providing a systematic analysis of membership inference defense. Specifically, we classify and summarize the existing membership inference defense schemes, focusing on optimization phase and objective, basic intuition, and key technology, and we discuss possible research directions of membership inference defense in the future.},
  archive      = {J_CSUR},
  author       = {Li Hu and Anli Yan and Hongyang Yan and Jin Li and Teng Huang and Yingying Zhang and Changyu Dong and Chunsheng Yang},
  doi          = {10.1145/3620667},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {4},
  pages        = {92:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Defenses to membership inference attacks: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generative adversarial networks: A survey on attack and
defense perspective. <em>CSUR</em>, <em>56</em>(4), 91:1–35. (<a
href="https://doi.org/10.1145/3615336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) are a remarkable creation with regard to deep generative models. Thanks to their ability to learn from complex data distributions, GANs have been credited with the capacity to generate plausible data examples, which have been widely applied to various data generation tasks over image, text, and audio. However, as with any powerful technology, GANs have a flip side: their capability to generate realistic data can be exploited for malicious purposes. Many recent studies have demonstrated the security and privacy (S&amp;P) threats brought by GANs, especially the attacks on machine learning (ML) systems. Nevertheless, so far as we know, there is no existing survey that has systematically categorized and discussed the threats and strategies of these GAN-based attack methods. In this article, we provide a comprehensive survey of GAN-based attacks and countermeasures. We summarize and articulate: (1) what S&amp;P threats of GANs expose to ML systems; (2) why GANs are useful for certain attacks; (3) what strategies can be used for GAN-based attacks; and (4) what countermeasures can be effective to GAN-based attacks. Finally, we provide several promising research directions combining the existing limitations of GAN-based studies and the prevailing trend in the associated research fields.},
  archive      = {J_CSUR},
  author       = {Chenhan Zhang and Shui Yu and Zhiyi Tian and James J. Q. Yu},
  doi          = {10.1145/3615336},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {4},
  pages        = {91:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Generative adversarial networks: A survey on attack and defense perspective},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on deep generative 3D-aware image synthesis.
<em>CSUR</em>, <em>56</em>(4), 90:1–34. (<a
href="https://doi.org/10.1145/3626193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have seen remarkable progress in deep learning powered visual content creation. This includes deep generative 3D-aware image synthesis, which produces high-fidelity images in a 3D-consistent manner while simultaneously capturing compact surfaces of objects from pure image collections without the need for any 3D supervision, thus bridging the gap between 2D imagery and 3D reality. The field of computer vision has been recently captivated by the task of deep generative 3D-aware image synthesis, with hundreds of papers appearing in top-tier journals and conferences over the past few years (mainly the past two years), but there lacks a comprehensive survey of this remarkable and swift progress. Our survey aims to introduce new researchers to this topic, provide a useful reference for related works, and stimulate future research directions through our discussion section. Apart from the presented papers, we aim to constantly update the latest relevant papers along with corresponding implementations at https://weihaox.github.io/3D-aware-Gen .},
  archive      = {J_CSUR},
  author       = {Weihao Xia and Jing-Hao Xue},
  doi          = {10.1145/3626193},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {4},
  pages        = {90:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on deep generative 3D-aware image synthesis},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Temporal link prediction: A unified framework, taxonomy, and
review. <em>CSUR</em>, <em>56</em>(4), 89:1–40. (<a
href="https://doi.org/10.1145/3625820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic graphs serve as a generic abstraction and description of the evolutionary behaviors of various complex systems (e.g., social networks and communication networks). Temporal link prediction (TLP) is a classic yet challenging inference task on dynamic graphs, which predicts possible future linkage based on historical topology. The predicted future topology can be used to support some advanced applications on real-world systems (e.g., resource pre-allocation) for better system performance. This survey provides a comprehensive review of existing TLP methods. Concretely, we first give the formal problem statements and preliminaries regarding data models, task settings, and learning paradigms that are commonly used in related research. A hierarchical fine-grained taxonomy is further introduced to categorize existing methods in terms of their data models, learning paradigms, and techniques. From a generic perspective, we propose a unified encoder-decoder framework to formulate all the methods reviewed, where different approaches only differ in terms of some components of the framework. Moreover, we envision serving the community with an open-source project OpenTLP 1 that refactors or implements some representative TLP methods using the proposed unified framework and summarizes other public resources. As a conclusion, we finally discuss advanced topics in recent research and highlight possible future directions.},
  archive      = {J_CSUR},
  author       = {Meng Qin and Dit-Yan Yeung},
  doi          = {10.1145/3625820},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {4},
  pages        = {89:1–40},
  shortjournal = {ACM Comput. Surv.},
  title        = {Temporal link prediction: A unified framework, taxonomy, and review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sentiment analysis for the natural environment: A systematic
review. <em>CSUR</em>, <em>56</em>(4), 88:1–37. (<a
href="https://doi.org/10.1145/3604605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this systematic review, Kitchenham’s framework is used to explore what tasks, techniques, and benchmarks for Sentiment Analysis have been developed for addressing topics about the natural environment. We comprehensively analyze seven dimensions including contribution, topical focus, data source and query, annotation, language, detail of the task, and technology/algorithm used. By showing how this research area has grown during the last few years, our investigation provides important findings about the results achieved and the challenges that need to be still addressed for making this technology actually helpful for stakeholders such as policymakers and governments.},
  archive      = {J_CSUR},
  author       = {Muhammad Okky Ibrohim and Cristina Bosco and Valerio Basile},
  doi          = {10.1145/3604605},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {4},
  pages        = {88:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Sentiment analysis for the natural environment: A systematic review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of modern fashion recommender systems.
<em>CSUR</em>, <em>56</em>(4), 87:1–37. (<a
href="https://doi.org/10.1145/3624733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The textile and apparel industries have grown tremendously over the past few years. Customers no longer have to visit many stores, stand in long queues, or try on garments in dressing rooms, as millions of products are now available in online catalogs. However, given the plethora of options available, an effective recommendation system is necessary to properly sort, order, and communicate relevant product material or information to users. Effective fashion recommender systems (RSs) can have a noticeable impact on billions of customers’ shopping experiences and increase sales and revenues on the provider side. The goal of this survey is to provide a review of RSs that operate in the specific vertical domain of garment and fashion products. We have identified the most pressing challenges in fashion RS research and created a taxonomy that categorizes the literature according to the objective they are trying to accomplish (e.g., item or outfit recommendation, size recommendation, and explainability, among others) and type of side information (users, items, context). We have also identified the most important evaluation goals and perspectives (outfit generation, outfit recommendation, pairing recommendation, and fill-in-the-blank outfit compatibility prediction) and the most commonly used datasets and evaluation metrics.},
  archive      = {J_CSUR},
  author       = {Yashar Deldjoo and Fatemeh Nazary and Arnau Ramisa and Julian McAuley and Giovanni Pellegrini and Alejandro Bellogin and Tommaso Di Noia},
  doi          = {10.1145/3624733},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {4},
  pages        = {87:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A review of modern fashion recommender systems},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Wireless underground sensor networks: A comprehensive survey
and tutorial. <em>CSUR</em>, <em>56</em>(4), 86:1–44. (<a
href="https://doi.org/10.1145/3625388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things has developed greatly over the past decade to cater to many diverse applications across almost all fields of life. Many of these applications can either profit or even explicitly require deployment underground, such as precision agriculture, but also land, pipeline, or mine monitoring. Underground deployment offers many advantages, such as concealment of the devices for their protection. However, the underground environment is also very challenging, especially for wireless communications and energy harvesting. In this survey and tutorial, we offer a comprehensive view of the complete topic, from theoretical foundations of wireless communications underground, through system architectures and applications, to energy harvesting options. These topics cannot be viewed separately from each other, as they are deeply intertwined and all of them need to be considered before a possible deployment. We will show that wireless underground sensor networks have a great potential for a variety of applications and are an intriguing alternative to overground deployments. We will describe the state of the art in a tutorial style, so that beginners can also profit. Last but not least, we will identify remaining challenges to guide researchers in this area.},
  archive      = {J_CSUR},
  author       = {Damien Wohwe Sambo and Anna Förster},
  doi          = {10.1145/3625388},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {4},
  pages        = {86:1–44},
  shortjournal = {ACM Comput. Surv.},
  title        = {Wireless underground sensor networks: A comprehensive survey and tutorial},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explainable deep learning methods in medical image
classification: A survey. <em>CSUR</em>, <em>56</em>(4), 85:1–41. (<a
href="https://doi.org/10.1145/3625287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The remarkable success of deep learning has prompted interest in its application to medical imaging diagnosis. Even though state-of-the-art deep learning models have achieved human-level accuracy on the classification of different types of medical data, these models are hardly adopted in clinical workflows, mainly due to their lack of interpretability. The black-box nature of deep learning models has raised the need for devising strategies to explain the decision process of these models, leading to the creation of the topic of eXplainable Artificial Intelligence (XAI). In this context, we provide a thorough survey of XAI applied to medical imaging diagnosis, including visual, textual, example-based and concept-based explanation methods. Moreover, this work reviews the existing medical imaging datasets and the existing metrics for evaluating the quality of the explanations. In addition, we include a performance comparison among a set of report generation–based methods. Finally, the major challenges in applying XAI to medical imaging and the future research directions on the topic are discussed.},
  archive      = {J_CSUR},
  author       = {Cristiano Patrício and João C. Neves and Luís F. Teixeira},
  doi          = {10.1145/3625287},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {4},
  pages        = {85:1–41},
  shortjournal = {ACM Comput. Surv.},
  title        = {Explainable deep learning methods in medical image classification: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A joint study of the challenges, opportunities, and roadmap
of MLOps and AIOps: A systematic survey. <em>CSUR</em>, <em>56</em>(4),
84:1–30. (<a href="https://doi.org/10.1145/3625289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data science projects represent a greater challenge than software engineering for organizations pursuing their adoption. The diverse stakeholders involved emphasize the need for a collaborative culture in organizations. This article aims to offer joint insights into the role of MLOps and AIOps methodologies for raising the success of data science projects in various fields, ranging from pure research to more traditional industries. We analyze the open issues, opportunities, and future trends organizations face when implementing MLOps and AIOps. Then, the frameworks and architectures that promote these paradigms are presented, as are the different fields in which they are being utilized. This systematic review was conducted using an automated procedure that identified 44,903 records, which were filtered down to 93 studies. These articles are meant to better clarify the problem at hand and highlight the future areas in both research and industry in which MLOPs and AIOps are thriving. Our findings indicate that AIOps flourish in challenging circumstances like those presented by 5G and 6G technologies, whereas MLOps is more prevalent in traditional industrial environments. The use of AIOps in certain stages of the ML lifecycle, such as deployment, remains underrepresented in scientific literature.},
  archive      = {J_CSUR},
  author       = {Josu Diaz-de-Arcaya and Ana I. Torre-Bastida and Gorka Zárate and Raúl Miñón and Aitor Almeida},
  doi          = {10.1145/3625289},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {4},
  pages        = {84:1–30},
  shortjournal = {ACM Comput. Surv.},
  title        = {A joint study of the challenges, opportunities, and roadmap of MLOps and AIOps: A systematic survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A scoping survey on cross-reality systems. <em>CSUR</em>,
<em>56</em>(4), 83:1–38. (<a
href="https://doi.org/10.1145/3616536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Immersive technologies such as Virtual Reality (VR) and Augmented Reality (AR) empower users to experience digital realities. Known as distinct technology classes, the lines between them are becoming increasingly blurry with recent technological advancements. New systems enable users to interact across technology classes or transition between them—referred to as cross-reality systems . Nevertheless, these systems are not well understood. Hence, in this article, we conducted a scoping literature review to classify and analyze cross-reality systems proposed in previous work. First, we define these systems by distinguishing three different types. Thereafter, we compile a literature corpus of 306 relevant publications, analyze the proposed systems, and present a comprehensive classification, including research topics, involved environments, and transition types. Based on the gathered literature, we extract nine guiding principles that can inform the development of cross-reality systems. We conclude with research challenges and opportunities.},
  archive      = {J_CSUR},
  author       = {Jonas Auda and Uwe Gruenefeld and Sarah Faltaous and Sven Mayer and Stefan Schneegass},
  doi          = {10.1145/3616536},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {4},
  pages        = {83:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A scoping survey on cross-reality systems},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tackling industrial downtimes with artificial intelligence
in data-driven maintenance. <em>CSUR</em>, <em>56</em>(4), 82:1–33. (<a
href="https://doi.org/10.1145/3623378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of Artificial Intelligence (AI) approaches in industrial maintenance for fault detection and prediction has gained much attention from scholars and practitioners. This survey systematically assesses and classifies the state-of-the-art algorithms applied to data-driven maintenance in recent literature. The taxonomy provides a so far not existing overview and decision aid for research and practice regarding suitable AI approaches for each maintenance application. Moreover, we consider trends and further research demand in this area. Finally, a newly developed holistic maintenance framework contributes to a practice-oriented implementation of AI and considers crucial managerial aspects of an efficient maintenance system.},
  archive      = {J_CSUR},
  author       = {Marcel André Hoffmann and Rainer Lasch},
  doi          = {10.1145/3623378},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {4},
  pages        = {82:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Tackling industrial downtimes with artificial intelligence in data-driven maintenance},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Benchmarks for automated commonsense reasoning: A survey.
<em>CSUR</em>, <em>56</em>(4), 81:1–41. (<a
href="https://doi.org/10.1145/3615355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {More than one hundred benchmarks have been developed to test the commonsense knowledge and commonsense reasoning abilities of artificial intelligence (AI) systems. However, these benchmarks are often flawed, and many aspects of common sense remain untested. Consequently, there is currently no reliable way of measuring to what extent existing AI systems have achieved these abilities. This article surveys the development and uses of AI commonsense benchmarks. It enumerates 139 commonsense benchmarks that have been developed: 102 text-based, 18 image-based, 12 video-based, and 7 based in simulated physical environments. It gives more detailed descriptions of twelve of these, three from each category. It surveys the various methods used to construct commonsense benchmarks. It discusses the nature of common sense, the role of common sense in AI, the goals served by constructing commonsense benchmarks, desirable features of commonsense benchmarks, and flaws and gap in existing benchmarks. It concludes with a number of recommendations for future development of commonsense AI benchmarks; most importantly, that the creators of benchmarks invest the work needed to ensure that benchmark examples are consistently high quality.},
  archive      = {J_CSUR},
  author       = {Ernest Davis},
  doi          = {10.1145/3615355},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {4},
  pages        = {81:1–41},
  shortjournal = {ACM Comput. Surv.},
  title        = {Benchmarks for automated commonsense reasoning: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-modality neuroimage synthesis: A survey.
<em>CSUR</em>, <em>56</em>(3), 80:1–28. (<a
href="https://doi.org/10.1145/3625227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modality imaging improves disease diagnosis and reveals distinct deviations in tissues with anatomical properties. The existence of completely aligned and paired multi-modality neuroimaging data has proved its effectiveness in brain research. However, collecting fully aligned and paired data is expensive or even impractical, since it faces many difficulties, including high cost, long acquisition time, image corruption, and privacy issues. An alternative solution is to explore unsupervised or weakly supervised learning methods to synthesize the absent neuroimaging data. In this article, we provide a comprehensive review of cross-modality synthesis for neuroimages, from the perspectives of weakly supervised and unsupervised settings, loss functions, evaluation metrics, imaging modalities, datasets, and downstream applications based on synthesis. We begin by highlighting several opening challenges for cross-modality neuroimage synthesis. Then, we discuss representative architectures of cross-modality synthesis methods under different supervisions. This is followed by a stepwise in-depth analysis to evaluate how cross-modality neuroimage synthesis improves the performance of its downstream tasks. Finally, we summarize the existing research findings and point out future research directions. All resources are available at https://github.com/M-3LAB/awesome-multimodal-brain-image-systhesis.},
  archive      = {J_CSUR},
  author       = {Guoyang Xie and Yawen Huang and Jinbao Wang and Jiayi Lyu and Feng Zheng and Yefeng Zheng and Yaochu Jin},
  doi          = {10.1145/3625227},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {80:1–28},
  shortjournal = {ACM Comput. Surv.},
  title        = {Cross-modality neuroimage synthesis: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Heterogeneous federated learning: State-of-the-art and
research challenges. <em>CSUR</em>, <em>56</em>(3), 79:1–44. (<a
href="https://doi.org/10.1145/3625558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) has drawn increasing attention owing to its potential use in large-scale industrial applications. Existing FL works mainly focus on model homogeneous settings. However, practical FL typically faces the heterogeneity of data distributions, model architectures, network environments, and hardware devices among participant clients. Heterogeneous Federated Learning (HFL) is much more challenging, and corresponding solutions are diverse and complex. Therefore, a systematic survey on this topic about the research challenges and state-of-the-art is essential. In this survey, we firstly summarize the various research challenges in HFL from five aspects: statistical heterogeneity, model heterogeneity, communication heterogeneity, device heterogeneity, and additional challenges. In addition, recent advances in HFL are reviewed and a new taxonomy of existing HFL methods is proposed with an in-depth analysis of their pros and cons. We classify existing methods from three different levels according to the HFL procedure: data-level, model-level, and server-level. Finally, several critical and promising future research directions in HFL are discussed, which may facilitate further developments in this field. A periodically updated collection on HFL is available at https://github.com/marswhu/HFL_Survey.},
  archive      = {J_CSUR},
  author       = {Mang Ye and Xiuwen Fang and Bo Du and Pong C. Yuen and Dacheng Tao},
  doi          = {10.1145/3625558},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {79:1–44},
  shortjournal = {ACM Comput. Surv.},
  title        = {Heterogeneous federated learning: State-of-the-art and research challenges},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on UAV-enabled edge computing: Resource management
perspective. <em>CSUR</em>, <em>56</em>(3), 78:1–36. (<a
href="https://doi.org/10.1145/3626566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing facilitates low-latency services at the network’s edge by distributing computation, communication, and storage resources within the geographic proximity of mobile and Internet-of-Things devices. The recent advancement in Unmanned Aerial Vehicle (UAV) technologies has opened new opportunities for edge computing in military operations, disaster response, or remote areas where traditional terrestrial networks are limited or unavailable. In such environments, UAVs can be deployed as aerial edge servers or relays to facilitate edge computing services. This form of computing is also known as UAV-enabled Edge Computing (UEC), which offers several unique benefits such as mobility, line-of-sight, flexibility, computational capability, and cost-efficiency. However, the resources on UAVs, edge servers, and Internet-of-Things devices are typically very limited in the context of UEC. Efficient resource management is therefore a critical research challenge in UEC. In this article, we present a survey on the existing research in UEC from the resource management perspective. We identify a conceptual architecture, different types of collaborations, wireless communication models, research directions, key techniques, and performance indicators for resource management in UEC. We also present a taxonomy of resource management in UEC. Finally, we identify and discuss some open research challenges that can stimulate future research directions for resource management in UEC.},
  archive      = {J_CSUR},
  author       = {Xiaoyu Xia and Sheik Mohammad Mostakim Fattah and Muhammad Ali Babar},
  doi          = {10.1145/3626566},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {78:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on UAV-enabled edge computing: Resource management perspective},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 3D face reconstruction: The road to forensics.
<em>CSUR</em>, <em>56</em>(3), 77:1–38. (<a
href="https://doi.org/10.1145/3625288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D face reconstruction algorithms from images and videos are applied to many fields, from plastic surgery to the entertainment sector, thanks to their advantageous features. However, when looking at forensic applications, 3D face reconstruction must observe strict requirements that still make its possible role in bringing evidence to a lawsuit unclear. An extensive investigation of the constraints, potential, and limits of its application in forensics is still missing. Shedding some light on this matter is the goal of the present survey, which starts by clarifying the relation between forensic applications and biometrics, with a focus on face recognition. Therefore, it provides an analysis of the achievements of 3D face reconstruction algorithms from surveillance videos and mugshot images and discusses the current obstacles that separate 3D face reconstruction from an active role in forensic applications. Finally, it examines the underlying datasets, with their advantages and limitations, while proposing alternatives that could substitute or complement them.},
  archive      = {J_CSUR},
  author       = {Simone Maurizio La Cava and Giulia Orrù and Martin Drahansky and Gian Luca Marcialis and Fabio Roli},
  doi          = {10.1145/3625288},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {77:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {3D face reconstruction: The road to forensics},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Information-theoretic approaches to differential privacy.
<em>CSUR</em>, <em>56</em>(3), 76:1–18. (<a
href="https://doi.org/10.1145/3604904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This tutorial studies relations between differential privacy and various information-theoretic measures by using several selective articles. In particular, we present how these connections can provide new interpretations for the privacy guarantee in systems that deploy differential privacy in an information-theoretic framework. Accordingly, the tutorial delivers an extensive summary on the existing literature that makes use of information-theoretic measures and tools such as mutual information, min-entropy, Kullback-Leibler divergence, and rate-distortion function for quantification and characterization of differential privacy in various settings.},
  archive      = {J_CSUR},
  author       = {Ayşe Ünsal and Melek Önen},
  doi          = {10.1145/3604904},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {76:1–18},
  shortjournal = {ACM Comput. Surv.},
  title        = {Information-theoretic approaches to differential privacy},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A primer on Seq2Seq models for generative chatbots.
<em>CSUR</em>, <em>56</em>(3), 75:1–58. (<a
href="https://doi.org/10.1145/3604281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent spread of Deep Learning-based solutions for Artificial Intelligence and the development of Large Language Models has pushed forwards significantly the Natural Language Processing area. The approach has quickly evolved in the last ten years, deeply affecting NLP, from low-level text pre-processing tasks –such as tokenisation or POS tagging– to high-level, complex NLP applications like machine translation and chatbots. This article examines recent trends in the development of open-domain data-driven generative chatbots, focusing on the Seq2Seq architectures. Such architectures are compatible with multiple learning approaches, ranging from supervised to reinforcement and, in the last years, allowed to realise very engaging open-domain chatbots. Not only do these architectures allow to directly output the next turn in a conversation but, to some extent, they also allow to control the style or content of the response. To offer a complete view on the subject, we examine possible architecture implementations as well as training and evaluation approaches. Additionally, we provide information about the openly available corpora to train and evaluate such models and about the current and past chatbot competitions. Finally, we present some insights on possible future directions, given the current research status.},
  archive      = {J_CSUR},
  author       = {Vincenzo Scotti and Licia Sbattella and Roberto Tedesco},
  doi          = {10.1145/3604281},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {75:1–58},
  shortjournal = {ACM Comput. Surv.},
  title        = {A primer on Seq2Seq models for generative chatbots},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transient-execution attacks: A computer architect
perspective. <em>CSUR</em>, <em>56</em>(3), 74:1–38. (<a
href="https://doi.org/10.1145/3603619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer architects employ a series of performance optimizations at the micro-architecture level. These optimizations are meant to be invisible to the programmer but they are implicitly programmed alongside the architectural state. Critically, the incorrect results of these optimizations are not scrubbed off the micro-architectural state. This side-effect may seem innocuous. However, through transient-execution, an attacker can leverage this knowledge to obtain information from the micro-architectural state and transmit the data to itself. Transient-Execution is a class of attacks that use the side-effects of executed instructions to leak data. Transient-Execution attacks are split into two categories: speculation-based (Spectre-type) and exception-based (Meltdown-type). A successful attack requires, first, access to the sensitive information, and, second, a transmission channel such that the data can be recovered. Therefore, this survey explains how an attacker can use the state from optimizations in the micro-architecture to access sensitive information from other programs running in the same device; and, once the information is obtained, it describes how the data can be encoded and transmitted in the micro-architectural state. Moreover, it introduces a taxonomy and analyzes defenses for such malicious attacks.},
  archive      = {J_CSUR},
  author       = {Luís Fiolhais and Leonel Sousa},
  doi          = {10.1145/3603619},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {74:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Transient-execution attacks: A computer architect perspective},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of the f-measure: Its history, properties,
criticism, and alternatives. <em>CSUR</em>, <em>56</em>(3), 73:1–24. (<a
href="https://doi.org/10.1145/3606367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Methods to classify objects into two or more classes are at the core of various disciplines. When a set of objects with their true classes is available, a supervised classifier can be trained and employed to decide if, for example, a new patient has cancer or not. The choice of performance measure is critical in deciding which supervised method to use in any particular classification problem. Different measures can lead to very different choices, so the measure should match the objectives. Many performance measures have been developed, and one of them is the F-measure, the harmonic mean of precision and recall. Originally proposed in information retrieval, the F-measure has gained increasing interest in the context of classification. However, the rationale underlying this measure appears weak, and unlike other measures, it does not have a representational meaning. The use of the harmonic mean also has little theoretical justification. The F-measure also stresses one class, which seems inappropriate for general classification problems. We provide a history of the F-measure and its use in computational disciplines, describe its properties, and discuss criticism about the F-Measure. We conclude with alternatives to the F-measure, and recommendations of how to use it effectively.},
  archive      = {J_CSUR},
  author       = {Peter Christen and David J. Hand and Nishadi Kirielle},
  doi          = {10.1145/3606367},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {73:1–24},
  shortjournal = {ACM Comput. Surv.},
  title        = {A review of the F-measure: Its history, properties, criticism, and alternatives},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detecting harmful content on online platforms: What
platforms need vs. Where research efforts go. <em>CSUR</em>,
<em>56</em>(3), 72:1–17. (<a
href="https://doi.org/10.1145/3603399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of harmful content on online platforms is a major societal problem, which comes in many different forms, including hate speech, offensive language, bullying and harassment, misinformation, spam, violence, graphic content, sexual abuse, self-harm, and many others. Online platforms seek to moderate such content to limit societal harm, to comply with legislation, and to create a more inclusive environment for their users. Researchers have developed different methods for automatically detecting harmful content, often focusing on specific sub-problems or on narrow communities, as what is considered harmful often depends on the platform and on the context. We argue that there is currently a dichotomy between what types of harmful content online platforms seek to curb, and what research efforts there are to automatically detect such content. We thus survey existing methods as well as content moderation policies by online platforms in this light and suggest directions for future work.},
  archive      = {J_CSUR},
  author       = {Arnav Arora and Preslav Nakov and Momchil Hardalov and Sheikh Muhammad Sarwar and Vibha Nayak and Yoan Dinkov and Dimitrina Zlatkova and Kyle Dent and Ameya Bhatawdekar and Guillaume Bouchard and Isabelle Augenstein},
  doi          = {10.1145/3603399},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {72:1–17},
  shortjournal = {ACM Comput. Surv.},
  title        = {Detecting harmful content on online platforms: What platforms need vs. where research efforts go},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Demystify the fuzzing methods: A comprehensive survey.
<em>CSUR</em>, <em>56</em>(3), 71:1–38. (<a
href="https://doi.org/10.1145/3623375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Massive software applications possess complex data structures or parse complex data structures; in such cases, vulnerabilities in the software become inevitable. The vulnerabilities are the source of cyber-security threats, and discovering this before the software deployment is challenging. Fuzzing is a vulnerability discovery solution that resonates with random-mutation, feedback-driven, coverage-guided, constraint-guided, seed-scheduling, and target-oriented strategies. Each technique is wrapped beneath the black-, white-, and grey-box fuzzers to uncover diverse vulnerabilities. It consists of methods such as identifying structural information about the test cases to detect security vulnerabilities, symbolic and concrete program states to explore the unexplored locations, and full semantics of code coverage to create new test cases. We methodically examine each kind of fuzzers and contemporary fuzzers with a profound observation that addresses various research questions and systematically reviews and analyze the gaps and their solutions. Our survey comprised the recent related works on fuzzing techniques to demystify the fuzzing methods concerning the application domains and the target that, in turn, achieves higher code coverage and sound vulnerability detection.},
  archive      = {J_CSUR},
  author       = {Sanoop Mallissery and Yu-Sung Wu},
  doi          = {10.1145/3623375},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {71:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Demystify the fuzzing methods: A comprehensive survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantum combinatorial optimization in the NISQ era: A
systematic mapping study. <em>CSUR</em>, <em>56</em>(3), 70:1–36. (<a
href="https://doi.org/10.1145/3620668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of quantum computing to combinatorial optimization problems is attracting increasing research interest, resulting in diverse approaches and research streams. This study aims at identifying, classifying, and understanding existing solution approaches as well as typical use cases in the field. The obtained classification schemes are based on a full-text analysis of 156 included papers. Our results can be used by researchers and practitioners to (i) better understand adaptations to and utilizations of existing gate-based and quantum annealing approaches and (ii) identify typical use cases for quantum computing in areas such as graph optimization, routing, and scheduling.},
  archive      = {J_CSUR},
  author       = {Felix Gemeinhardt and Antonio Garmendia and Manuel Wimmer and Benjamin Weder and Frank Leymann},
  doi          = {10.1145/3620668},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {70:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Quantum combinatorial optimization in the NISQ era: A systematic mapping study},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Metaheuristic biclustering algorithms: From state-of-the-art
to future opportunities. <em>CSUR</em>, <em>56</em>(3), 69:1–38. (<a
href="https://doi.org/10.1145/3617590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biclustering is an unsupervised machine-learning technique that simultaneously clusters rows and columns in a data matrix. Over the past two decades, the field of biclustering has emerged and grown significantly, and currently plays an essential role in various applications such as bioinformatics, text mining, and pattern recognition. However, finding significant biclusters in large-scale datasets is an NP-hard problem that can be formulated as an optimization problem. Therefore, metaheuristics have been applied to address biclustering problems due to their (i) ability to efficiently explore search spaces of complex optimization problems, (ii) capability to find solutions in reasonable computation time, and (iii) facility to adapt to different problem formulations, as they are considered general-purpose heuristic algorithms. Although several studies on biclustering approaches have been proposed, a comprehensive study using metaheuristics for bicluster analysis is missing. This work presents a survey of metaheuristic approaches to address the biclustering problem in various scientific applications. The review focuses on the underlying optimization methods and their main search components: representation, objective function, and variation operators. A specific discussion on single versus multi-objective approaches is presented. Finally, some emerging research directions are presented.},
  archive      = {J_CSUR},
  author       = {Adán José-García and Julie Jacques and Vincent Sobanski and Clarisse Dhaenens},
  doi          = {10.1145/3617590},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {69:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Metaheuristic biclustering algorithms: From state-of-the-art to future opportunities},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on the unmanned aircraft system traffic management.
<em>CSUR</em>, <em>56</em>(3), 68:1–37. (<a
href="https://doi.org/10.1145/3617992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Unmanned Aircraft System Traffic Management (UTM) system is a set of services offering an automated management of the airspace and thus providing safe and secure Unmanned Aerial Vehicle (UAV) flights in both controlled and uncontrolled airspace. Controlled airspace refers to the portion of the airspace that is under the authority of Air Traffic Control (ATC) and where separation services are offered, while uncontrolled airspace refers to the portion of airspace where aircraft are not regulated by ATC. This article is a comprehensive survey of the existing UTMs development efforts with a focus on the different UTMs architectures, the provided services, the used communication technologies and the decision-making process within UTMs. We firstly review the different UTM architecture and propose a novel UTM taxonomy based on high-level qualitative criteria. Secondly, we detail the services provided by UTMs with an emphasis on the used technologies in the identification, the surveillance, the monitoring, and the deconfliction services. Effective decision-making is crucial, particularly in emergency scenarios such as Air-to-Ground (A2G) communication loss, battery or motor malfunction, or encountering aerial obstacles, among other potential hazards. Despite its significance, the UTM decision-making process is not enough considered in the literature and especially in UTM surveys. We analyze and compare in this article both the centralized and decentralized UTM decision-making. Centralized decision-making is not conducted in real-time and primarily relies on Air-to-Ground (A2G) communication. In the decentralized case, the decision-making process primarily relies on communication and collaboration among UAVs with varying degrees of autonomy. We show in this paper that centralized decision-making may encounter issues with packet loss and imperfect data, which can negatively impact the quality of decision-making. We also highlight that the decentralized decision-making may also face challenges related to security and scalability, which can hinder its effectiveness. Finally, evaluating the performance of UTMs on a real environment raises several challenges and the simulation is a cost-effective alternative. Hence, we provide a summary of the existing UTMs simulators and discuss their main features.},
  archive      = {J_CSUR},
  author       = {Asma Hamissi and Amine Dhraief},
  doi          = {10.1145/3617992},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {68:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on the unmanned aircraft system traffic management},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Taxonomy of abstractive dialogue summarization: Scenarios,
approaches, and future directions. <em>CSUR</em>, <em>56</em>(3),
67:1–38. (<a href="https://doi.org/10.1145/3622933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstractive dialogue summarization generates a concise and fluent summary covering the salient information in a dialogue among two or more interlocutors. It has attracted significant attention in recent years based on the massive emergence of social communication platforms and an urgent requirement for efficient dialogue information understanding and digestion. Different from news or articles in traditional document summarization, dialogues bring unique characteristics and additional challenges, including different language styles and formats, scattered information, flexible discourse structures, and unclear topic boundaries. This survey provides a comprehensive investigation of existing work for abstractive dialogue summarization from scenarios, approaches to evaluations. It categorizes the task into two broad categories according to the type of input dialogues, i.e., open-domain and task-oriented, and presents a taxonomy of existing techniques in three directions, namely, injecting dialogue features, designing auxiliary training tasks, and using additional data. A list of datasets under different scenarios and widely accepted evaluation metrics are summarized for completeness. After that, the trends of scenarios and techniques are summarized, together with deep insights into correlations between extensively exploited features and different scenarios. Based on these analyses, we recommend future directions, including more controlled and complicated scenarios, technical innovations and comparisons, publicly available datasets in special domains, and so on.},
  archive      = {J_CSUR},
  author       = {Qi Jia and Yizhu Liu and Siyu Ren and Kenny Q. Zhu},
  doi          = {10.1145/3622933},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {67:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Taxonomy of abstractive dialogue summarization: Scenarios, approaches, and future directions},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on deep learning based forest environment sound
classification at the edge. <em>CSUR</em>, <em>56</em>(3), 66:1–36. (<a
href="https://doi.org/10.1145/3618104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forest ecosystems are of paramount importance to the sustainable existence of life on earth. Unique natural and artificial phenomena pose severe threats to the perseverance of such ecosystems. With the advancement of artificial intelligence technologies, the effectiveness of implementing forest monitoring systems based on acoustic surveillance has been established due to the practicality of the approach. It can be identified that with the support of transfer learning, deep learning algorithms outperform conventional machine learning algorithms for forest acoustic classification. Further, a clear requirement to move the conventional cloud-based sound classification to the edge is raised among the research community to ensure real-time identification of acoustic incidents. This article presents a comprehensive survey on the state-of-the-art forest sound classification approaches, publicly available datasets for forest acoustics, and the associated infrastructure. Further, we discuss the open challenges and future research aspects that govern forest acoustic classification.},
  archive      = {J_CSUR},
  author       = {Dulani Meedeniya and Isuru Ariyarathne and Meelan Bandara and Roshinie Jayasundara and Charith Perera},
  doi          = {10.1145/3618104},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {66:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on deep learning based forest environment sound classification at the edge},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Landscape of high-performance python to develop data science
and machine learning applications. <em>CSUR</em>, <em>56</em>(3),
65:1–30. (<a href="https://doi.org/10.1145/3617588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Python has become the prime language for application development in the data science and machine learning domains. However, data scientists are not necessarily experienced programmers. Although Python lets them quickly implement their algorithms, when moving at scale, computation efficiency becomes inevitable. Thus, harnessing high-performance devices such as multi-core processors and graphical processing units to their potential is generally not trivial. The present narrative survey can be thought of as a reference document for such practitioners to help them make their way in the wealth of tools and techniques available for the Python language. Our document revolves around user scenarios, which are meant to cover most situations they may face. We believe that this document may also be of practical use to tool developers, who may use our work to identify potential lacks in existing tools and help them motivate their contributions.},
  archive      = {J_CSUR},
  author       = {Oscar Castro and Pierrick Bruneau and Jean-Sébastien Sottet and Dario Torregrossa},
  doi          = {10.1145/3617588},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {65:1–30},
  shortjournal = {ACM Comput. Surv.},
  title        = {Landscape of high-performance python to develop data science and machine learning applications},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of controllable text generation using
transformer-based pre-trained language models. <em>CSUR</em>,
<em>56</em>(3), 64:1–37. (<a
href="https://doi.org/10.1145/3617680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controllable Text Generation (CTG) is an emerging area in the field of natural language generation (NLG). It is regarded as crucial for the development of advanced text generation technologies that better meet the specific constraints in practical applications. In recent years, methods using large-scale pre-trained language models (PLMs), in particular the widely used Transformer-based PLMs, have become a new paradigm of NLG, allowing generation of more diverse and fluent text. However, due to the limited level of interpretability of deep neural networks, the controllability of these methods needs to be guaranteed. To this end, controllable text generation using Transformer-based PLMs has become a rapidly growing yet challenging new research hotspot. A diverse range of approaches have emerged in the past 3 to 4 years, targeting different CTG tasks that require different types of controlled constraints. In this article, we present a systematic critical review on the common tasks, main approaches, and evaluation methods in this area. Finally, we discuss the challenges that the field is facing, and put forward various promising future directions. To the best of our knowledge, this is the first survey article to summarize the state-of-the-art CTG techniques from the perspective of Transformer-based PLMs. We hope it can help researchers and practitioners in the related fields to quickly track the academic and technological frontier, providing them with a landscape of the area and a roadmap for future research.},
  archive      = {J_CSUR},
  author       = {Hanqing Zhang and Haolin Song and Shaoyu Li and Ming Zhou and Dawei Song},
  doi          = {10.1145/3617680},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {64:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of controllable text generation using transformer-based pre-trained language models},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Survey on secure keyword search over outsourced data: From
cloud to blockchain-assisted architecture. <em>CSUR</em>,
<em>56</em>(3), 63:1–40. (<a
href="https://doi.org/10.1145/3617824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Secure keyword search is a prevailing search service offered in outsourced environments. However, with the increasingly severe security vulnerabilities of conventional centralized outsourcing, the architecture of secure keyword search, with searchable encryption (SE) as the underlying technique, has recently shifted from cloud-centered models to blockchain-assisted models. Existing surveys commonly fail to capture such an evolution and the corresponding benefits. What on earth does blockchain bring about and what are the unexplored challenges? This survey provides a systematic review of secure keyword search over outsourced data from cloud to blockchain-assisted architectures. We propose a taxonomy assorting present studies, depending on whether cloud/blockchain and data sharing are included, in which blockchain-assisted architecture is further divided into blockchain-side and cloud-side keyword search, respectively. Technically, we conclude five types of representative SE techniques with fitting architectures, either cryptographic-based or hardware-dependent. Notably, we propose comprehensive methodologies to select relevant papers, discuss, and compare existing schemes regarding functionalities, security, efficiency, and fairness (up to 21 compared items). Finally, open issues and potential research directions are identified for future work. We aspire to help pave the way for addressing the theoretical and empirical aspects of secure keyword search and full-fledged real-world implementation of blockchain-based keyword search applications.},
  archive      = {J_CSUR},
  author       = {Haiqin Wu and Boris Düdder and Liangmin Wang and Zhenfu Cao and Jun Zhou and Xia Feng},
  doi          = {10.1145/3617824},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {63:1–40},
  shortjournal = {ACM Comput. Surv.},
  title        = {Survey on secure keyword search over outsourced data: From cloud to blockchain-assisted architecture},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning approaches on image captioning: A review.
<em>CSUR</em>, <em>56</em>(3), 62:1–39. (<a
href="https://doi.org/10.1145/3617592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image captioning is a research area of immense importance, aiming to generate natural language descriptions for visual content in the form of still images. The advent of deep learning and more recently vision-language pre-training techniques has revolutionized the field, leading to more sophisticated methods and improved performance. In this survey article, we provide a structured review of deep learning methods in image captioning by presenting a comprehensive taxonomy and discussing each method category in detail. Additionally, we examine the datasets commonly employed in image captioning research, as well as the evaluation metrics used to assess the performance of different captioning models. We address the challenges faced in this field by emphasizing issues such as object hallucination, missing context, illumination conditions, contextual understanding, and referring expressions. We rank different deep learning methods’ performance according to widely used evaluation metrics, giving insight into the current state-of-the-art. Furthermore, we identify several potential future directions for research in this area, which include tackling the information misalignment problem between image and text modalities, mitigating dataset bias, incorporating vision-language pre-training methods to enhance caption generation, and developing improved evaluation tools to accurately measure the quality of image captions.},
  archive      = {J_CSUR},
  author       = {Taraneh Ghandi and Hamidreza Pourreza and Hamidreza Mahyar},
  doi          = {10.1145/3617592},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {62:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning approaches on image captioning: A review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Survey on digital sovereignty and identity: From
digitization to digitalization. <em>CSUR</em>, <em>56</em>(3), 61:1–36.
(<a href="https://doi.org/10.1145/3616400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Through digital transformation, lots of personal data are captured, but individuals often do not have ownership or control over them. This results in the emerging Web 3.0, where people demand data sovereignty. There are actually two conceptually related terms, data sovereignty and digital sovereignty. This paper first explains these two concepts in terms of their points of focus, guiding principles, laws and regulations requirements, and then analyses the requirements and technical challenges of their implementation. To understand the emerging trend shift in digital sovereignty towards individuals taking control of security and privacy preserving over their own digital assets, this paper conducts a systematic review and analysis on Self-Sovereign Identity (SSI), which is a user-centric decentralized model and autonomy for an individual to self-determine the access and use of one&#39;s identity and credentials. The review covers existing SSI solutions and points out that an efficient key management system, the scalability and interoperability of the solution, and a well-established standard are some of the challenges for SSI deployment. Finally, the paper concludes with open issues about digital identity, including dynamic attributes, persona, and attribute ownership, that challenge the current reference architecture of SSI as well as its implementation.},
  archive      = {J_CSUR},
  author       = {Kheng Leong Tan and Chi-Hung Chi and Kwok-Yan Lam},
  doi          = {10.1145/3616400},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {61:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Survey on digital sovereignty and identity: From digitization to digitalization},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differentiated location privacy protection in mobile
communication services: A survey from the semantic perception
perspective. <em>CSUR</em>, <em>56</em>(3), 60:1–36. (<a
href="https://doi.org/10.1145/3617589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile communication services raise user privacy concerns in sharing the traveling trajectories while facilitating people’s daily lives. According to these shared trajectories, adversaries can dig users’ multi-modal behavioral semantics by combining with extensive open-source web information. These behavioral semantics have differentiated privacy sensitivity, raising different levels of privacy concerns. It makes users have personalized requirements for protecting their travelings. Resulting in the inevitable evolutionary trend from location privacy protection to differentiated location privacy protection (DLPP). DLPP digs into mobile semantics and characterizes the differentiated location sensitivity by simulating the potential attacks. It provides the privacy protection with differentiated strength to each location. Differentiated and appropriate strength well balances the tradeoff between privacy protection and data availability for the quality of application service. We are motivated to conduct a comprehensive survey on DLPP from the semantic perception perspective. It forms a complete overview of the mobile semantics-aware differentiation in location privacy protection. Specifically, we first review the research works on multi-modal mobile semantic representation. Then, taking the dug semantics as a clue, we summarize the basic principles of DLPP research systematically. To complete the overview, we also summarize their design modes and discuss the open opportunities and challenges for future works.},
  archive      = {J_CSUR},
  author       = {Guoying Qiu and Guoming Tang and Chuandong Li and Lailong Luo and Deke Guo and Yulong Shen},
  doi          = {10.1145/3617589},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {60:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Differentiated location privacy protection in mobile communication services: A survey from the semantic perception perspective},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Container-based virtualization for real-time industrial
systems—a systematic review. <em>CSUR</em>, <em>56</em>(3), 59:1–38. (<a
href="https://doi.org/10.1145/3617591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial Automation and Control systems have matured into a stable infrastructure model that has been kept fundamentally unchanged, using discrete embedded systems (such as Programmable Logic Controllers) to implement the first line of sensorization, actuation, and process control and stations and servers providing monitoring, supervision, logging/database and data-sharing capabilities, among others. More recently, with the emergence of the Industry 4.0 paradigm and the need for more flexibility, there has been a steady trend towards virtualizing some of the automation station/server components, first by using virtual machines and, more recently, by using container technology. This trend is pushing for better support for real-time requirements on enabling virtualization technologies such as virtual machines and containers. This article provides a systematic review on the use of container virtualization in real-time environments such as cyber-physical systems, assessing how existing and emerging technologies can fulfill the associated requirements. Starting by reviewing fundamental concepts related to container technology and real-time requirements, it goes on to present the methodology and results of a systematic study of 37 selected papers covering aspects related to the enforcement of real-time constrains within container hosts and the expected task latency on such environments, as well as an overview of container platforms and orchestration mechanisms for RT systems.},
  archive      = {J_CSUR},
  author       = {Rui Queiroz and Tiago Cruz and Jérôme Mendes and Pedro Sousa and Paulo Simões},
  doi          = {10.1145/3617591},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {59:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Container-based virtualization for real-time industrial Systems—A systematic review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence applied to software testing: A
tertiary study. <em>CSUR</em>, <em>56</em>(3), 58:1–38. (<a
href="https://doi.org/10.1145/3616372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Context: Artificial intelligence (AI) methods and models have extensively been applied to support different phases of the software development lifecycle, including software testing (ST). Several secondary studies investigated the interplay between AI and ST but restricted the scope of the research to specific domains or sub-domains within either area. Objective: This research aims to explore the overall contribution of AI to ST, while identifying the most popular applications and potential paths for future research directions. Method: We executed a tertiary study following well-established guidelines for conducting systematic literature mappings in software engineering and for answering nine research questions. Results : We identified and analyzed 20 relevant secondary studies. The analysis was performed by drawing from well-recognized AI and ST taxonomies and mapping the selected studies according to them. The resulting mapping and discussions provide extensive and detailed information on the interplay between AI and ST. Conclusion: The application of AI to support ST is a well-consolidated and growing interest research topic. The mapping resulting from our study can be used by researchers to identify opportunities for future research, and by practitioners looking for evidence-based information on which AI-supported technology to possibly adopt in their testing processes.},
  archive      = {J_CSUR},
  author       = {Domenico Amalfitano and Stefano Faralli and Jean Carlo Rossa Hauck and Santiago Matalonga and Damiano Distante},
  doi          = {10.1145/3616372},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {58:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Artificial intelligence applied to software testing: A tertiary study},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automation for network security configuration: State of the
art and research trends. <em>CSUR</em>, <em>56</em>(3), 57:1–37. (<a
href="https://doi.org/10.1145/3616401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The size and complexity of modern computer networks are progressively increasing, as a consequence of novel architectural paradigms such as the Internet of Things and network virtualization. Consequently, a manual orchestration and configuration of network security functions is no more feasible in an environment where cyber attacks can dramatically exploit breaches related to any minimum configuration error. A new frontier is then the introduction of automation in network security configuration, i.e., automatically designing the architecture of security services and the configurations of network security functions, such as firewalls, Virtual Private Networks gateways, and so on. This opportunity has been enabled by modern computer networks technologies, such as virtualization. In view of these considerations, the motivations for the introduction of automation in network security configuration are first introduced, along with the key automation enablers. Then, the current state of the art in this context is surveyed, focusing on both the achieved improvements and the current limitations. Finally, possible future trends in the field are illustrated.},
  archive      = {J_CSUR},
  author       = {Daniele Bringhenti and Guido Marchetto and Riccardo Sisto and Fulvio Valenza},
  doi          = {10.1145/3616401},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {57:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Automation for network security configuration: State of the art and research trends},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A taxonomy of live migration management in cloud computing.
<em>CSUR</em>, <em>56</em>(3), 56:1–33. (<a
href="https://doi.org/10.1145/3615353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud Data Centers have become the key infrastructure for providing services. Instance migration across different computing nodes in edge and cloud computing is essential to guarantee the quality of service in dynamic environments. Many studies have been conducted on dynamic resource management involving migrating Virtual Machines to achieve various objectives, such as load balancing, consolidation, performance, energy-saving, and disaster recovery. Some have investigated to improve and predict the performance of single live migration. Recently, several research studies service migration in edge-centric computing paradigms. However, there is a lack of taxonomy and survey that focuses on the management of live migration in edge and cloud computing environments. In this article, we examine the characteristics of each field and propose a migration management-centric taxonomy to provide a holistic framework and guideline for researchers on the topic, including the performance and cost model, migration generations in resource management algorithms, migration planning and scheduling, and migration lifecycle management and orchestration. We also identify research gaps and opportunities to improve the performance of resource management with live migrations.},
  archive      = {J_CSUR},
  author       = {Tianzhang He and Rajkumar Buyya},
  doi          = {10.1145/3615353},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {56:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {A taxonomy of live migration management in cloud computing},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pre-trained language models in biomedical domain: A
systematic survey. <em>CSUR</em>, <em>56</em>(3), 55:1–52. (<a
href="https://doi.org/10.1145/3611651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-trained language models (PLMs) have been the de facto paradigm for most natural language processing tasks. This also benefits the biomedical domain: researchers from informatics, medicine, and computer science communities propose various PLMs trained on biomedical datasets, e.g., biomedical text, electronic health records, protein, and DNA sequences for various biomedical tasks. However, the cross-discipline characteristics of biomedical PLMs hinder their spreading among communities; some existing works are isolated from each other without comprehensive comparison and discussions. It is nontrivial to make a survey that not only systematically reviews recent advances in biomedical PLMs and their applications but also standardizes terminology and benchmarks. This article summarizes the recent progress of pre-trained language models in the biomedical domain and their applications in downstream biomedical tasks. Particularly, we discuss the motivations of PLMs in the biomedical domain and introduce the key concepts of pre-trained language models. We then propose a taxonomy of existing biomedical PLMs that categorizes them from various perspectives systematically. Plus, their applications in biomedical downstream tasks are exhaustively discussed, respectively. Last, we illustrate various limitations and future trends, which aims to provide inspiration for the future research.},
  archive      = {J_CSUR},
  author       = {Benyou Wang and Qianqian Xie and Jiahuan Pei and Zhihong Chen and Prayag Tiwari and Zhao Li and Jie Fu},
  doi          = {10.1145/3611651},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {55:1–52},
  shortjournal = {ACM Comput. Surv.},
  title        = {Pre-trained language models in biomedical domain: A systematic survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 3D face recognition: Two decades of progress and prospects.
<em>CSUR</em>, <em>56</em>(3), 54:1–39. (<a
href="https://doi.org/10.1145/3615863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional (3D) face recognition has been extensively investigated in the last two decades due to its wide range of applications in many areas, such as security and forensics. Numerous methods have been proposed to deal with the challenges faced by 3D face recognition, such as facial expressions, pose variations, and occlusions. These methods have achieved superior performances on several small-scale datasets, including FRGC v2.0, Bosphorus, BU-3DFE, and Gavab. However, deep learning–based 3D face recognition methods are still in their infancy due to the lack of large-scale 3D face datasets. To stimulate future research in this area, we present a comprehensive review of the progress achieved by both traditional and deep learning–based 3D face recognition methods in the last two decades. Comparative results on several publicly available datasets under different challenges of facial expressions, pose variations, and occlusions are also presented.},
  archive      = {J_CSUR},
  author       = {Yulan Guo and Hanyun Wang and Longguang Wang and Yinjie Lei and Li Liu and Mohammed Bennamoun},
  doi          = {10.1145/3615863},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {3},
  pages        = {54:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {3D face recognition: Two decades of progress and prospects},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Extensions of fuzzy cognitive maps: A systematic review.
<em>CSUR</em>, <em>56</em>(2), 53:1–36. (<a
href="https://doi.org/10.1145/3610771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy Cognitive Maps (FCMs) are widely used to simulate complex systems. However, they cannot handle nonlinear relationships or time delays/lags, nor can they fully represent uncertain information, which prompted the development of extended FCMs. The latest review covered extensions up to 2010. We search for extensions from 2011 to March 2023 and assess their motivations, features, operationalizations, use cases, reproducibility, and evaluation to support modelers in reusing existing solutions. We reviewed 26 extensions and found a paucity of extensions addressing multiple limitations, and none of the extensions provided code, hindering modelers in reusing existing extensions while suggesting future work.},
  archive      = {J_CSUR},
  author       = {Ryan Schuerkamp and Philippe J. Giabbanelli},
  doi          = {10.1145/3610771},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {53:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Extensions of fuzzy cognitive maps: A systematic review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bias in reinforcement learning: A review in healthcare
applications. <em>CSUR</em>, <em>56</em>(2), 52:1–17. (<a
href="https://doi.org/10.1145/3609502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) can assist in medical decision making using patient data collected in electronic health record (EHR) systems. RL, a type of machine learning, can use these data to develop treatment policies. However, RL models are typically trained using imperfect retrospective EHR data. Therefore, if care is not taken in training, RL policies can propagate existing bias in healthcare. Literature that considers and addresses the issues of bias and fairness in sequential decision making are reviewed. The major themes to mitigate bias that emerge relate to (1) data management; (2) algorithmic design; and (3) clinical understanding of the resulting policies.},
  archive      = {J_CSUR},
  author       = {Benjamin Smith and Anahita Khojandi and Rama Vasudevan},
  doi          = {10.1145/3609502},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {52:1–17},
  shortjournal = {ACM Comput. Surv.},
  title        = {Bias in reinforcement learning: A review in healthcare applications},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sentiment analysis for hotel reviews: A systematic
literature review. <em>CSUR</em>, <em>56</em>(2), 51:1–38. (<a
href="https://doi.org/10.1145/3605152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment Analysis (SA) helps to automatically and meaningfully discover hotel customers’ satisfaction from their shared experiences and feelings on social media. Several studies have been conducted to improve the precision of SA in the hospitality industry, which vary in data preprocessing techniques, feature representation, sentiment classification levels, and models, and they use different datasets. Such variations are worthy of attention and monitoring. Despite the importance of SA in hospitality and tourism, review studies identifying gaps and suggesting future research directions are limited. This article introduces a systematic literature review to label and discuss state-of-the-art studies that deal with SA for hotel reviews.},
  archive      = {J_CSUR},
  author       = {Asma Ameur and Sana Hamdi and Sadok Ben Yahia},
  doi          = {10.1145/3605152},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {51:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Sentiment analysis for hotel reviews: A systematic literature review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A comprehensive survey on collaborative data-access enablers
in the IIoT. <em>CSUR</em>, <em>56</em>(2), 50:1–37. (<a
href="https://doi.org/10.1145/3612918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scope of the Industrial Internet of Things (IIoT) has stretched beyond manufacturing to include energy, healthcare, transportation, and all that tomorrow’s smart cities will entail. The realm of IIoT includes smart sensors, actuators, programmable logic controllers, distributed control systems (DCS), embedded devices, supervisory control, and data acquisition systems—all produced by manufacturers for different purposes and with different data structures and formats; designed according to different standards and made to follow different protocols. In this sea of incompatibility, how can we flexibly acquire these heterogeneous data, and how can we uniformly structure them to suit thousands of different applications? In this article, we survey the four pillars of information science that enable collaborative data access in an IIoT—standardization, data acquisition, data fusion, and scalable architecture—to provide an up-to-date audit of current research in the field. Here, standardization in IIoT relies on standards and technologies to make things communicative; data acquisition attempts to transparently collect data through plug-and-play architectures, reconfigurable schemes, or hardware expansion; data fusion refers to the techniques and strategies for overcoming heterogeneity in data formats and sources; and scalable architecture provides basic techniques to support heterogeneous requirements. The article also concludes with an overview of the frontier researches and emerging technologies for supporting or challenging data access from the aspects of 5G, machine learning, blockchain, and semantic web.},
  archive      = {J_CSUR},
  author       = {Danfeng Sun and Junjie Hu and Huifeng Wu and Jia Wu and Jian Yang and Quan Z. Sheng and Schahram Dustdar},
  doi          = {10.1145/3612918},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {50:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive survey on collaborative data-access enablers in the IIoT},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Swarm robotics: A survey from a multi-tasking perspective.
<em>CSUR</em>, <em>56</em>(2), 49:1–38. (<a
href="https://doi.org/10.1145/3611652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The behaviour of social insects such as bees and ants has influenced the development of swarm robots. To enable robots to cooperate together, swarm robotics employs principles such as communication, coordination, and collaboration. Collaboration among multiple robots can lead to a faster task completion time compared to the utilisation of a single, complex robot. One of the key aspects of swarm robotics is that control is distributed uniformly across the robots in the swarm, which boosts the system’s resilience and fault tolerance. Through the use of the robots’ embodied sensors and actuators, this distributed control often facilitates the emergence of collective behaviours through the interaction of the robots with one another and with the environment. The purpose of this survey is to examine the reasons behind the lack of utilisation of swarm robots in multi-tasking applications, which will be accomplished by studying previous research works in the field. We examine the literature from the perspective of multi-tasking: we pay particular attention to concepts that contribute to the progress of swarm robotics for multi-tasking applications. To do this, we first examine the different studies in multi-tasking swarm robotics, covering platforms, multi-tasking scenarios, sub-task allocation methodologies, and performance metrics. We then highlight several swarm robotics related disciplines that have significant effect on the development of swarm robotics for multi-tasking problems. We propose two taxonomies: the first categorises works based on the characteristics of the scenarios being handled, whereas the second taxonomy categorises works based on the swarming strategies utilised to achieve multi-tasking capabilities. We finish with a discussion of swarm robots’ existing limitations for real-world multi-tasking applications, as well as recommendations for future research directions.},
  archive      = {J_CSUR},
  author       = {Essam Debie and Kathryn Kasmarik and Matt Garratt},
  doi          = {10.1145/3611652},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {49:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Swarm robotics: A survey from a multi-tasking perspective},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Where are the (cellular) data? <em>CSUR</em>,
<em>56</em>(2), 48:1–25. (<a
href="https://doi.org/10.1145/3610402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New generations of cellular networks are data oriented, targeting the integration of machine learning and artificial intelligence solutions. Data availability, required to train and compare machine learning based networking solutions, is therefore becoming an important topic and a significant concern. Operators do collect data, but they rarely share it because of privacy concerns. This article starts by reviewing the few publicly available cellular datasets, which created bursts of innovation with their release. The scarcity of such data is so acute that researchers are collecting network data using their own tools, developed in-house and covered in the second part of this survey.},
  archive      = {J_CSUR},
  author       = {Maryam Amini and Razvan Stanica and Catherine Rosenberg},
  doi          = {10.1145/3610402},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {48:1–25},
  shortjournal = {ACM Comput. Surv.},
  title        = {Where are the (Cellular) data?},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The business impact of inner source and how to quantify it.
<em>CSUR</em>, <em>56</em>(2), 47:1–27. (<a
href="https://doi.org/10.1145/3611648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inner source software development is the practice of using open source practices for firm-internal software development. Practitioner reports have shown that inner source can increase flexibility and reduce costs. Despite the potential benefits of inner source, there has been little research on its impact on businesses and their processes. To address this gap, we conducted a systematic literature review that identified which business processes are affected by inner source development, particularly within the accounting and management domain. Our review revealed the need for new dedicated community building processes within companies. In addition, we examined computational tools and techniques that can be used to measure inner source development. We found that existing tools and techniques are insufficiently suitable to manage inner source processes. Based on this, we propose research topics for future work on quantifying inner source.},
  archive      = {J_CSUR},
  author       = {Stefan Buchner and Dirk Riehle},
  doi          = {10.1145/3611648},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {47:1–27},
  shortjournal = {ACM Comput. Surv.},
  title        = {The business impact of inner source and how to quantify it},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). I/o access patterns in HPC applications: A 360-degree
survey. <em>CSUR</em>, <em>56</em>(2), 46:1–41. (<a
href="https://doi.org/10.1145/3611007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The high-performance computing I/O stack has been complex due to multiple software layers, the inter-dependencies among these layers, and the different performance tuning options for each layer. In this complex stack, the definition of an “I/O access pattern” has been reappropriated to describe what an application is doing to write or read data from the perspective of different layers of the stack, often comprising a different set of features. It has become common to have to redefine what is meant when discussing a pattern in every new study, as no assumption can be made. This survey aims to propose a baseline taxonomy, harnessing the I/O community’s knowledge over the past 20 years. This definition can serve as a common ground for high-performance computing I/O researchers and developers to apply known I/O tuning strategies and design new strategies for improving I/O performance. We seek to summarize and bring a consensus to the multiple ways to describe a pattern based on common features already used by the community over the years.},
  archive      = {J_CSUR},
  author       = {Jean Luca Bez and Suren Byna and Shadi Ibrahim},
  doi          = {10.1145/3611007},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {46:1–41},
  shortjournal = {ACM Comput. Surv.},
  title        = {I/O access patterns in HPC applications: A 360-degree survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Beyond smart homes: An in-depth analysis of smart aging care
system security. <em>CSUR</em>, <em>56</em>(2), 45:1–35. (<a
href="https://doi.org/10.1145/3610225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The upward trend in the percentage of the population older than 65 has made smart aging more relevant than ever before. Growing old in a traditional assisted living facility can take a toll on the mental well-being of the elderly individual, on top of other factors like extravagant costs, potential negligence from caregivers, and a ceaseless demand for healthcare personnel. Aging in one’s own space instead of a senior residence is the desirable alternative thanks to enabling technologies like the Internet of Things (IoT). The IoT facilitates connected healthcare, safety, entertainment, and social well-being of the older population. However, it suffers from a multitude of security vulnerabilities. Although researchers have investigated the security challenges of several IoT ecosystems, IoT systems in the context of smart aging care have not been well studied from a security perspective. In this article, we present an in-depth analysis of smart aging care system security issues. A smart aging care system is essentially a superset of smart homes and healthcare monitoring systems. The sheer variety of technologies at play and the amount of data generated, combined with physical vulnerabilities and a lack of technological exposure of the intended occupant group put smart aging care systems at great risk. Attacks against relatively benign smart home devices can bring serious consequences because of the context in which these devices are employed. Thus, the purpose of our study is four-fold: (i) defining the components and functionalities of a smart aging care system, (ii) identifying security vulnerabilities and outlining suitable countermeasures for them, (iii) analyzing how the attacks uniquely impact senior users’ Quality of Life (QoL), (iv) highlighting avenues for future research and how the threat landscape in smart aging care systems differ from general smart homes.},
  archive      = {J_CSUR},
  author       = {Youssef Yamout and Tashaffi Samin Yeasar and Shahrear Iqbal and Mohammad Zulkernine},
  doi          = {10.1145/3610225},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {45:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Beyond smart homes: An in-depth analysis of smart aging care system security},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A knowledge graph-based survey on distributed ledger
technology for IoT verticals. <em>CSUR</em>, <em>56</em>(2), 44:1–36.
(<a href="https://doi.org/10.1145/3609503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) and distributed ledger technology (DLT) have significantly changed our daily lives. Due to their distributed operational environment and naturally decentralized applications, the convergence of these two technologies indicates a more lavish arrangement for the future. This article develops a comprehensive survey to investigate and illustrate state-of-the-art DLT for various IoT use cases, from smart homes to autonomous vehicles and smart cities. We develop a novel framework for conducting a systematic and comprehensive review of DLT over the IoT by extending the knowledge graph approach. With relevant insights from this review, we extract innovative and pragmatic techniques to DLT design that enable high-performance, sustainable, and highly scalable IoT systems. Our findings support designing an end-to-end IoT-native DLT architecture for the future that fully coordinates network-assisted functionalities.},
  archive      = {J_CSUR},
  author       = {Rongxin Xu and Qiujun Lan and Shiva Raj Pokhrel and Gang Li},
  doi          = {10.1145/3609503},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {44:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A knowledge graph-based survey on distributed ledger technology for IoT verticals},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Service caching and computation reuse strategies at the
edge: A survey. <em>CSUR</em>, <em>56</em>(2), 43:1–38. (<a
href="https://doi.org/10.1145/3609504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the proliferation of connected devices including smartphones, novel network connectivity and management methods are needed to meet user Quality of Experience (QoE) and computational demands of contemporary applications. Service caching and computation reuse techniques are being employed to alleviate challenges due to scalability, interoperability, and mobility, as well as to reduce application latency by enabling caching at the edge. This survey provides a taxonomy for service caching and computation reuse and describes the current state of the research and its challenges. This is the first survey that provides a comprehensive analysis and suggests future research directions on this topic.},
  archive      = {J_CSUR},
  author       = {Carlos Barrios and Mohan Kumar},
  doi          = {10.1145/3609504},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {43:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Service caching and computation reuse strategies at the edge: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Survey on architectural attacks: A unified classification
and attack model. <em>CSUR</em>, <em>56</em>(2), 42:1–32. (<a
href="https://doi.org/10.1145/3604803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to the World Economic Forum, cyberattacks are considered as one of the most important sources of risk to companies and institutions worldwide. Attacks can target the network, software, and/or hardware. Over the years, much knowledge has been developed to understand and mitigate cyberattacks. However, new threats have appeared in recent years regarding software attacks that exploit hardware vulnerabilities. This article defines these attacks as architectural attacks. Today, both industry and academia have only limited comprehension of architectural attacks, which represents a critical issue for the design of future systems. To this end, this work proposes a new taxonomy, a new attack model, and a complete survey of existing architectural attacks. As a result, it provides the tools to understand architectural attacks in more depth and to start building improved designs and protection mechanisms.},
  archive      = {J_CSUR},
  author       = {Tara Ghasempouri and Jaan Raik and Cezar Reinbrecht and Said Hamdioui and Mottaqiallah Taouil},
  doi          = {10.1145/3604803},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {42:1–32},
  shortjournal = {ACM Comput. Surv.},
  title        = {Survey on architectural attacks: A unified classification and attack model},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Survey on evolutionary deep learning: Principles,
algorithms, applications, and open issues. <em>CSUR</em>,
<em>56</em>(2), 41:1–34. (<a
href="https://doi.org/10.1145/3603704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over recent years, there has been a rapid development of deep learning (DL) in both industry and academia fields. However, finding the optimal hyperparameters of a DL model often needs high computational cost and human expertise. To mitigate the above issue, evolutionary computation (EC) as a powerful heuristic search approach has shown significant merits in the automated design of DL models, so-called evolutionary deep learning (EDL). This article aims to analyze EDL from the perspective of automated machine learning (AutoML). Specifically, we first illuminate EDL from DL and EC and regard EDL as an optimization problem. According to the DL pipeline, we systematically introduce EDL methods ranging from data preparation, model generation, to model deployment with a new taxonomy (i.e., what and how to evolve/optimize), and focus on the discussions of solution representation and search paradigm in handling the optimization problem by EC. Finally, key applications, open issues, and potentially promising lines of future research are suggested. This survey has reviewed recent developments of EDL and offers insightful guidelines for the development of EDL.},
  archive      = {J_CSUR},
  author       = {Nan Li and Lianbo Ma and Guo Yu and Bing Xue and Mengjie Zhang and Yaochu Jin},
  doi          = {10.1145/3603704},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {41:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Survey on evolutionary deep learning: Principles, algorithms, applications, and open issues},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of malware analysis using community detection
algorithms. <em>CSUR</em>, <em>56</em>(2), 40:1–29. (<a
href="https://doi.org/10.1145/3610223">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, we have witnessed an overwhelming and fast proliferation of different types of malware targeting organizations and individuals, which considerably increased the time required to detect malware. The malware developers make this issue worse by spreading many variants of the same malware [ 13 ]. To deal with this issue, graph theory techniques, and particularly community detection algorithms, can be leveraged to achieve bulk detection of malware families and variants to identify malicious communities instead of focusing on the detection of an individual instance of malware, which could significantly reduce the detection time. In this article, we review the state-of-the-art malware analysis solutions that employ community detection algorithms and provide a taxonomy that classifies the solutions with respect to five facets: analysis task, community detection approach, target platform, analysis type, and source of features. We present the solutions with respect to the analysis task, which covers malware detection, malware classification, cyber-threat infrastructure detection, and feature selection. The findings of this survey indicate that there is still room for contributions to further improve the state of the art and address research gaps. Finally, we discuss the advantages and the limitations of the solutions, identify open issues, and provide future research directions.},
  archive      = {J_CSUR},
  author       = {Abdelouahab Amira and Abdelouahid Derhab and Elmouatez Billah Karbab and Omar Nouali},
  doi          = {10.1145/3610223},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {40:1–29},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of malware analysis using community detection algorithms},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Privacy and fairness in federated learning: On the
perspective of tradeoff. <em>CSUR</em>, <em>56</em>(2), 39:1–37. (<a
href="https://doi.org/10.1145/3606017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) has been a hot topic in recent years. Ever since it was introduced, researchers have endeavored to devise FL systems that protect privacy or ensure fair results, with most research focusing on one or the other. As two crucial ethical notions, the interactions between privacy and fairness are comparatively less studied. However, since privacy and fairness compete, considering each in isolation will inevitably come at the cost of the other. To provide a broad view of these two critical topics, we presented a detailed literature review of privacy and fairness issues, highlighting unique challenges posed by FL and solutions in federated settings. We further systematically surveyed different interactions between privacy and fairness, trying to reveal how privacy and fairness could affect each other and point out new research directions in fair and private FL.},
  archive      = {J_CSUR},
  author       = {Huiqiang Chen and Tianqing Zhu and Tao Zhang and Wanlei Zhou and Philip S. Yu},
  doi          = {10.1145/3606017},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {39:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Privacy and fairness in federated learning: On the perspective of tradeoff},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards a unified pandemic management architecture: Survey,
challenges, and future directions. <em>CSUR</em>, <em>56</em>(2),
38:1–32. (<a href="https://doi.org/10.1145/3609324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pandemic caused by Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) has impacted the economy, health, and society. Emerging strains are making pandemic management challenging. There is an urge to collect epidemiological, clinical, and physiological data to make an informed decision on mitigation. Advances in the Internet of Things (IoT) and edge computing provide solutions for pandemic management through data collection and intelligent computation. While existing data-driven architectures operate on specific application domains and attempt to automate decision-making, they do not capture the multifaceted interaction among computational models, communication infrastructure, and data. In this article, we survey the existing approaches for pandemic management, including data repositories and contact-tracing applications. We envision a unified pandemic management architecture that leverages the IoT and edge computing paradigms to automate recommendations on vaccine distribution, dynamic lockdown, mobility scheduling, and pandemic trend prediction. We elucidate the data flow among the layers, namely, cloud, edge, and end device layers. Moreover, we address the privacy implications, threats, regulations, and solutions that may be adapted to optimize the utility of health data with security guarantees. The article ends with a discussion of the limitations of the architecture and research directions to enhance its practicality.},
  archive      = {J_CSUR},
  author       = {Satyaki Roy and Nirnay Ghosh and Nitish Uplavikar and Preetam Ghosh},
  doi          = {10.1145/3609324},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {38:1–32},
  shortjournal = {ACM Comput. Surv.},
  title        = {Towards a unified pandemic management architecture: Survey, challenges, and future directions},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of tool support for working with design decisions
in code. <em>CSUR</em>, <em>56</em>(2), 37:1–37. (<a
href="https://doi.org/10.1145/3607868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whenever developers choose among alternative technical approaches, they make a design decision. Collectively, design decisions shape how software implements its requirements and shape non-functional quality attributes such as maintainability, extensibility, and performance. Developers work with design decisions both when identifying, choosing, and documenting alternatives and when later work requires following and understanding previously made design decisions. Design decisions encompass design rationale, describing the alternatives and justification for a design choice, as well as design rules, describing the constraints imposed by specific alternatives. This article summarizes and classifies research on these activities, examining different approaches through which tools may support developers in working with design decisions in code. We focus both on the technical aspects of tools as well as the human aspects of how tools support developers. Our survey identifies goals developers have in working with design decisions throughout the lifecycle of design decisions. We also examine the potential support tools may offer developers in achieving these goals and the challenges in offering better support.},
  archive      = {J_CSUR},
  author       = {Sahar Mehrpour and Thomas D. Latoza},
  doi          = {10.1145/3607868},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {37:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of tool support for working with design decisions in code},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning for zero-day malware detection and
classification: A survey. <em>CSUR</em>, <em>56</em>(2), 36:1–37. (<a
href="https://doi.org/10.1145/3605775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-day malware is malware that has never been seen before or is so new that no anti-malware software can catch it. This novelty and the lack of existing mitigation strategies make zero-day malware challenging to detect and defend against. In recent years, deep learning has become the dominant and leading branch of machine learning in various research fields, including malware detection. Considering the significant threat of zero-day malware to cybersecurity and business continuity, it is necessary to identify deep learning techniques that can somehow be effective in detecting or classifying such malware. But so far, such a comprehensive review has not been conducted. In this article, we study deep learning techniques in terms of their ability to detect or classify zero-day malware. Based on our findings, we propose a taxonomy and divide different zero-day resistant, deep malware detection and classification techniques into four main categories: unsupervised, semi-supervised, few-shot, and adversarial resistant. We compare the techniques in each category in terms of various factors, including deep learning architecture, feature encoding, platform, detection or classification functionality, and whether the authors have performed a zero-day evaluation. We also provide a summary view of the reviewed papers and discuss their main characteristics and challenges.},
  archive      = {J_CSUR},
  author       = {Fatemeh Deldar and Mahdi Abadi},
  doi          = {10.1145/3605775},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {36:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning for zero-day malware detection and classification: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Survey on activation functions for optical neural networks.
<em>CSUR</em>, <em>56</em>(2), 35:1–30. (<a
href="https://doi.org/10.1145/3607533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrated photonics arises as a fast and energy-efficient technology for the implementation of artificial neural networks (ANNs). Indeed, with the growing interest in ANNs, photonics shows great promise to overcome current limitations of electronic-based implementation. For example, it has been shown that neural networks integrating optical matrix multiplications can potentially run two orders of magnitude faster than their electronic counterparts. However, the transposition in the optical domain of the activation functions, which is a key feature of ANNs, remains a challenge. There is no direct optical implementation of state-of-the-art activation functions. Currently, most designs require time-consuming and power-hungry electro-optical conversions. In this survey, we review both all-optical and opto-electronic activation functions proposed in the state-of-the-art. We present activation functions with their key characteristics, and we summarize challenges for their use in the context of all-optical neural networks. We then highlight research directions for the implementation of fully optical neural networks.},
  archive      = {J_CSUR},
  author       = {Oceane Destras and Sébastien Le Beux and Felipe Gohring De Magalhães and Gabriela Nicolescu},
  doi          = {10.1145/3607533},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {35:1–30},
  shortjournal = {ACM Comput. Surv.},
  title        = {Survey on activation functions for optical neural networks},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An end-to-end review of gaze estimation and its interactive
applications on handheld mobile devices. <em>CSUR</em>, <em>56</em>(2),
34:1–38. (<a href="https://doi.org/10.1145/3606947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, we have witnessed an increasing number of interactive systems on handheld mobile devices which utilise gaze as a single or complementary interaction modality. This trend is driven by the enhanced computational power of these devices, higher resolution and capacity of their cameras, and improved gaze estimation accuracy obtained from advanced machine learning techniques, especially in deep learning. As the literature is fast progressing, there is a pressing need to review the state-of-the-art, delineate the boundary, and identify the key research challenges and opportunities in gaze estimation and interaction. This article aims to serve this purpose by presenting an end-to-end holistic view in this area, from gaze capturing sensors, to gaze estimation workflows, to deep learning techniques, and to gaze interactive applications.},
  archive      = {J_CSUR},
  author       = {Yaxiong Lei and Shijing He and Mohamed Khamis and Juan Ye},
  doi          = {10.1145/3606947},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {34:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {An end-to-end review of gaze estimation and its interactive applications on handheld mobile devices},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Soft delivery: Survey on a new paradigm for wireless and
mobile multimedia streaming. <em>CSUR</em>, <em>56</em>(2), 33:1–37. (<a
href="https://doi.org/10.1145/3607139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing demand for video streaming services is the key driver of modern wireless and mobile communications. Although many studies have designed digital-based delivery schemes to send video content over wireless and mobile networks, significant quality degradation, known as cliff and leveling effects, often occurs owing to fluctuating channel characteristics. In this article, we present a comprehensive summary of soft delivery, which is a new paradigm for wireless and mobile video streaming and discuss the future directions of soft delivery. Existing studies found that introducing multi-dimensional cosine transform, human vision system, and graph signal processing can make soft delivery schemes more effective in untethered immersive experiences, including virtual reality and volumetric media, than digital-based delivery schemes. In addition, this study finds that soft delivery has the potential to be a new standard to deliver deep neural network models and tactile information over wireless and mobile networks.},
  archive      = {J_CSUR},
  author       = {Takuya Fujihashi and Toshiaki Koike-Akino and Takashi Watanabe},
  doi          = {10.1145/3607139},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {33:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Soft delivery: Survey on a new paradigm for wireless and mobile multimedia streaming},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An interdisciplinary survey on information flows in supply
chains. <em>CSUR</em>, <em>56</em>(2), 32:1–38. (<a
href="https://doi.org/10.1145/3606693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supply chains form the backbone of modern economies and therefore require reliable information flows. In practice, however, supply chains face severe technical challenges, especially regarding security and privacy. In this work, we consolidate studies from supply chain management, information systems, and computer science from 2010–2021 in an interdisciplinary meta-survey to make this topic holistically accessible to interdisciplinary research. In particular, we identify a significant potential for computer scientists to remedy technical challenges and improve the robustness of information flows. We subsequently present a concise information flow-focused taxonomy for supply chains before discussing future research directions to provide possible entry points.},
  archive      = {J_CSUR},
  author       = {Jan Pennekamp and Roman Matzutt and Christopher Klinkmüller and Lennart Bader and Martin Serror and Eric Wagner and Sidra Malik and Maria Spiß and Jessica Rahn and Tan Gürpinar and Eduard Vlad and Sander J. J. Leemans and Salil S. Kanhere and Volker Stich and Klaus Wehrle},
  doi          = {10.1145/3606693},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {32:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {An interdisciplinary survey on information flows in supply chains},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Demystifying graph databases: Analysis and taxonomy of data
organization, system designs, and graph queries. <em>CSUR</em>,
<em>56</em>(2), 31:1–40. (<a
href="https://doi.org/10.1145/3604932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous irregular graph datasets, for example social networks or web graphs, may contain even trillions of edges. Often, their structure changes over time and they have domain-specific rich data associated with vertices and edges. Graph database systems such as Neo4j enable storing, processing, and analyzing such large, evolving, and rich datasets. Due to the sheer size and irregularity of such datasets, these systems face unique design challenges. To facilitate the understanding of this emerging domain, we present the first survey and taxonomy of graph database systems. We focus on identifying and analyzing fundamental categories of these systems (e.g., document stores, tuple stores, native graph database systems, or object-oriented systems), the associated graph models (e.g., Resource Description Framework or Labeled Property Graph), data organization techniques (e.g., storing graph data in indexing structures or dividing data into records), and different aspects of data distribution and query execution (e.g., support for sharding and Atomicity, Consistency, Isolation, Durability). Fifty-one graph database systems are presented and compared, including Neo4j, OrientDB, and Virtuoso. We outline graph database queries and relationships with associated domains (NoSQL stores, graph streaming, and dynamic graph algorithms). Finally, we outline future research and engineering challenges related to graph databases.},
  archive      = {J_CSUR},
  author       = {Maciej Besta and Robert Gerstenberger and Emanuel Peter and Marc Fischer and Michał Podstawski and Claude Barthels and Gustavo Alonso and Torsten Hoefler},
  doi          = {10.1145/3604932},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {31:1–40},
  shortjournal = {ACM Comput. Surv.},
  title        = {Demystifying graph databases: Analysis and taxonomy of data organization, system designs, and graph queries},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recent advances in natural language processing via large
pre-trained language models: A survey. <em>CSUR</em>, <em>56</em>(2),
30:1–40. (<a href="https://doi.org/10.1145/3605943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large, pre-trained language models (PLMs) such as BERT and GPT have drastically changed the Natural Language Processing (NLP) field. For numerous NLP tasks, approaches leveraging PLMs have achieved state-of-the-art performance. The key idea is to learn a generic, latent representation of language from a generic task once, then share it across disparate NLP tasks. Language modeling serves as the generic task, one with abundant self-supervised text available for extensive training. This article presents the key fundamental concepts of PLM architectures and a comprehensive view of the shift to PLM-driven NLP techniques. It surveys work applying the pre-training then fine-tuning, prompting, and text generation approaches. In addition, it discusses PLM limitations and suggested directions for future research.},
  archive      = {J_CSUR},
  author       = {Bonan Min and Hayley Ross and Elior Sulem and Amir Pouran Ben Veyseh and Thien Huu Nguyen and Oscar Sainz and Eneko Agirre and Ilana Heintz and Dan Roth},
  doi          = {10.1145/3605943},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {30:1–40},
  shortjournal = {ACM Comput. Surv.},
  title        = {Recent advances in natural language processing via large pre-trained language models: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Document image quality assessment: A survey. <em>CSUR</em>,
<em>56</em>(2), 29:1–36. (<a
href="https://doi.org/10.1145/3606692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid emergence of new portable capturing technologies has significantly increased the number and diversity of document images acquired for business and personal applications. The performance of document image processing systems and applications depends directly on the quality of the document images captured. Therefore, estimating the document&#39;s image quality is an essential step in the early stages of the document analysis pipeline. This article surveys research on Document Image Quality Assessment (DIQA). We first provide a detailed analysis of both subjective and objective DIQA methods. Subjective methods, including ratings and pair-wise comparison-based approaches, are based on human opinions. Objective methods are based on quantitative measurements, including document modeling and human perception-based methods. Second, we summarize the types and sources of document degradations and techniques used to model degradations. In addition, we thoroughly review two standard measures to characterize document image quality: Optical Character Recognition (OCR)-based and objective human perception-based. Finally, we outline open challenges regarding developing DIQA methods and provide insightful discussion and future research directions for this problem. This survey will become an essential resource for the document analysis research community and serve as a basis for future research.},
  archive      = {J_CSUR},
  author       = {Alireza Alaei and Vinh Bui and David Doermann and Umapada Pal},
  doi          = {10.1145/3606692},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {29:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Document image quality assessment: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on thwarting memory corruption in RISC-v.
<em>CSUR</em>, <em>56</em>(2), 28:1–29. (<a
href="https://doi.org/10.1145/3604906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With embedded devices becoming more pervasive and entrenched in society, it is paramount to keep these systems secure. A threat plaguing these systems consists of software vulnerabilities that cause memory corruption, potentially allowing an attacker to breach the device. Software-based countermeasures exist, but suffer from high overhead. In this survey, we investigate whether this could be mitigated using dedicated hardware. Driven by the advancements of open hardware, we focus on implementations for RISC-V, a novel and open architecture tailored for customization. We distinguish between methods validating memory accesses beforehand, obfuscating information necessary for an attack, and detecting memory values corrupted earlier. We compare on qualitative metrics, such as the security coverage and level of transparency, and performance in both software and hardware. Although current implementations do not easily allow for a fair comparison as their evaluation methodologies vary widely, we show that current implementations are suitable to minimize the runtime overhead with a relatively small area overhead. Nevertheless, we identified that further research is still required to mitigate more fine-grained attacks such as intra-object overflows, to integrate into more sophisticated protected execution environments towards resilient systems that are automatically recoverable, and to move towards more harmonized evaluation.},
  archive      = {J_CSUR},
  author       = {Marco Brohet and Francesco Regazzoni},
  doi          = {10.1145/3604906},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {28:1–29},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on thwarting memory corruption in RISC-V},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Named entity recognition and classification in historical
documents: A survey. <em>CSUR</em>, <em>56</em>(2), 27:1–47. (<a
href="https://doi.org/10.1145/3604931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {After decades of massive digitisation, an unprecedented number of historical documents are available in digital format, along with their machine-readable texts. While this represents a major step forward with respect to preservation and accessibility, it also opens up new opportunities in terms of content mining and the next fundamental challenge is to develop appropriate technologies to efficiently search, retrieve, and explore information from this ‘big data of the past’. Among semantic indexing opportunities, the recognition and classification of named entities are in great demand among humanities scholars. Yet, named entity recognition (NER) systems are heavily challenged with diverse, historical, and noisy inputs. In this survey, we present the array of challenges posed by historical documents to NER, inventory existing resources, describe the main approaches deployed so far, and identify key priorities for future developments.},
  archive      = {J_CSUR},
  author       = {Maud Ehrmann and Ahmed Hamdi and Elvys Linhares Pontes and Matteo Romanello and Antoine Doucet},
  doi          = {10.1145/3604931},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {27:1–47},
  shortjournal = {ACM Comput. Surv.},
  title        = {Named entity recognition and classification in historical documents: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards smart education through internet of things: A
survey. <em>CSUR</em>, <em>56</em>(2), 26:1–33. (<a
href="https://doi.org/10.1145/3610401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IoT is a fundamental enabling technology for creating smart spaces, which can assist the effective face-to-face and online education systems. The transition to smart education (integrating IoT and AI into the education system) is appealing, which has a concrete impact on learners’ engagement, motivation, attendance, and deep learning. Traditional education faces many challenges, including administration, pedagogy, assessment, and classroom supervision. Recent developments in ICT (e.g., IoT, AI, and 5G) have yielded lots of smart solutions for various aspects of life; however, smart solutions are not well integrated into the education system. In particular, the COVID-19 pandemic situation had further emphasized the adoption of new smart solutions in education. This study reviews the related studies and addresses the (i) problems in the traditional education system with possible solutions, (ii) the transition towards smart education, and (iii) research challenges in the transition to smart education (i.e., computational and social resistance). Considering these studies, smart solutions (e.g., smart pedagogy, smart assessment, smart classroom, smart administration) are introduced to the problems of the traditional system. This exploratory study opens new trends for scholars and the market to integrate ICT, IoT, and AI into smart education.},
  archive      = {J_CSUR},
  author       = {Afzal Badshah and Anwar Ghani and Ali Daud and Ateeqa Jalal and Muhammad Bilal and Jon Crowcroft},
  doi          = {10.1145/3610401},
  journal      = {ACM Computing Surveys},
  month        = {9},
  number       = {2},
  pages        = {26:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Towards smart education through internet of things: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Big code search: A bibliography. <em>CSUR</em>,
<em>56</em>(1), 25:1–49. (<a
href="https://doi.org/10.1145/3604905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code search is an essential task in software development. Developers often search the internet and other code databases for necessary source code snippets to ease the development efforts. Code search techniques also help learn programming as novice programmers or students can quickly retrieve (hopefully good) examples already used in actual software projects. Given the recurrence of the code search activity in software development, there is an increasing interest in the research community. To improve the code search experience, the research community suggests many code search tools and techniques. These tools and techniques leverage several different ideas and claim a better code search performance. However, it is still challenging to illustrate a comprehensive view of the field considering that existing studies generally explore narrow and limited subsets of used components. This study aims to devise a grounded approach to understanding the procedure for code search and build an operational taxonomy capturing the critical facets of code search techniques. Additionally, we investigate evaluation methods, benchmarks, and datasets used in the field of code search.},
  archive      = {J_CSUR},
  author       = {Kisub Kim and Sankalp Ghatpande and Dongsun Kim and Xin Zhou and Kui Liu and Tegawendé F. Bissyandé and Jacques Klein and Yves Le Traon},
  doi          = {10.1145/3604905},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {25:1–49},
  shortjournal = {ACM Comput. Surv.},
  title        = {Big code search: A bibliography},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on hypergraph representation learning.
<em>CSUR</em>, <em>56</em>(1), 24:1–38. (<a
href="https://doi.org/10.1145/3605776">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypergraphs have attracted increasing attention in recent years thanks to their flexibility in naturally modeling a broad range of systems where high-order relationships exist among their interacting parts. This survey reviews the newly born hypergraph representation learning problem, whose goal is to learn a function to project objects—most commonly nodes—of an input hyper-network into a latent space such that both the structural and relational properties of the network can be encoded and preserved. We provide a thorough overview of existing literature and offer a new taxonomy of hypergraph embedding methods by identifying three main families of techniques, i.e., spectral, proximity-preserving, and (deep) neural networks. For each family, we describe its characteristics and our insights in a single yet flexible framework and then discuss the peculiarities of individual methods, as well as their pros and cons. We then review the main tasks, datasets, and settings in which hypergraph embeddings are typically used. We finally identify and discuss open challenges that would inspire further research in this field.},
  archive      = {J_CSUR},
  author       = {Alessia Antelmi and Gennaro Cordasco and Mirko Polato and Vittorio Scarano and Carmine Spagnuolo and Dingqi Yang},
  doi          = {10.1145/3605776},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {24:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on hypergraph representation learning},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of next-generation computing technologies in
space-air-ground integrated networks. <em>CSUR</em>, <em>56</em>(1),
23:1–40. (<a href="https://doi.org/10.1145/3606018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Space-air-ground integrated networks (SAGINs) are key elements for facilitating high-speed seamless connectivity to the devices/users in infrastructure-less environments, where the traditional terrestrial networks are critically infeasible or uneconomical to be fully deployed. This article comprehensively surveys the advanced computing technologies that support the utilization of SAGINs for infrastructure-less environments. The advanced computing technologies refer to the emerging computing techniques, tools, and the processes that can be utilized to support SAGINs in handling the increasing computing tasks. The main contents include: (1) background of SAGINs, (2) typical use cases of SAGINs in infrastructure-less environments, (3) advanced computing technologies to assist SAGINs to meet the requirements of various services in infrastructure-less environments, (4) the related practical initiatives, and (5) the open research challenges and the future research directions.},
  archive      = {J_CSUR},
  author       = {Zhishu Shen and Jiong Jin and Cheng Tan and Atsushi Tagami and Shangguang Wang and Qing Li and Qiushi Zheng and Jingling Yuan},
  doi          = {10.1145/3606018},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {23:1–40},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of next-generation computing technologies in space-air-ground integrated networks},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Survey on sketch-to-photo translation. <em>CSUR</em>,
<em>56</em>(1), 22:1–25. (<a
href="https://doi.org/10.1145/3606694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sketch-based understanding is involved in human communication and cognitive development, making it essential in visual perception. A specific task in this domain is sketch-to-photo translation, where a model produces realistic images from simple drawings. To this end, large paired training datasets are commonly required, which is impractical in real applications. Thus, this work studies conditional generative models for sketch-to-photo translation, overcoming the lack of training datasets by a self-supervised approach that produces sketch-photo pairs from a target catalog. Our study shows the benefit of cycle-consistency loss and UNet architectures that, together with the proposed dataset generation, improve performance in real applications like eCommerce. Our results also reveal the weakness of conditional DDPMs for generating images resembling the input sketch, even though they achieve a high FID score.},
  archive      = {J_CSUR},
  author       = {Diego Donoso and Jose M. Saavedra},
  doi          = {10.1145/3606694},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {22:1–25},
  shortjournal = {ACM Comput. Surv.},
  title        = {Survey on sketch-to-photo translation},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of accelerating parallel sparse linear algebra.
<em>CSUR</em>, <em>56</em>(1), 21:1–38. (<a
href="https://doi.org/10.1145/3604606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse linear algebra includes the fundamental and important operations in various large-scale scientific computing and real-world applications. There exists performance bottleneck for sparse linear algebra since it mainly contains the memory-bound computations with low arithmetic intensity. How to improve its performance has increasingly become a focus of research efforts. Using parallel computing techniques to accelerate sparse linear algebra is currently the most popular method, while facing various challenges, e.g., large-scale data brings difficulties in storage, and the sparsity of data leads to irregular memory accesses and parallel load imbalance. Therefore, this article provides a comprehensive overview on acceleration of sparse linear algebra operations using parallel computing platforms, where we focus on four main classifications: sparse matrix-vector multiplication (SpMV), sparse matrix-sparse vector multiplication (SpMSpV), sparse general matrix-matrix multiplication (SpGEMM), and sparse tensor algebra. The takeaways from this article include the following: understanding the challenges of accelerating linear sparse algebra on various hardware platforms; understanding how structured data sparsity can improve storage efficiency; understanding how to optimize parallel load balance; understanding how to improve the efficiency of memory accesses; understanding how do the adaptive frameworks automatically select the optimal algorithms; and understanding recent design trends for acceleration of parallel sparse linear algebra.},
  archive      = {J_CSUR},
  author       = {Guoqing Xiao and Chuanghui Yin and Tao Zhou and Xueqi Li and Yuedan Chen and Kenli Li},
  doi          = {10.1145/3604606},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {21:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of accelerating parallel sparse linear algebra},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of design and optimization for systolic array-based
DNN accelerators. <em>CSUR</em>, <em>56</em>(1), 20:1–37. (<a
href="https://doi.org/10.1145/3604802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, it has been witnessed that the systolic array is a successful architecture for DNN hardware accelerators. However, the design of systolic arrays also encountered many challenges. As DNN structures and applications become more complex, a DNN hardware accelerator based on the typical systolic array architecture suffers severe performance and efficiency penalties. So, it has motivated a significant amount of research on the redesign and optimization of the systolic array architecture. In this article, we survey these works on analyzing, redesigning, and improving the performance and efficiency of the systolic array architecture. These works are critical to the design flow of DNN accelerators based on systolic arrays. We also provide a technique classification of these works on the basis of their main research idea. Further, we attempt to compare the advantages and disadvantages of different designs and different technologies and provide quantitative results for reference. The aim of this survey is to provide researchers with knowledge of the state-of-the-art in the systolic array architecture and motivate them to design highly efficient DNN accelerators of tomorrow.},
  archive      = {J_CSUR},
  author       = {Rui Xu and Sheng Ma and Yang Guo and Dongsheng Li},
  doi          = {10.1145/3604802},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {20:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of design and optimization for systolic array-based DNN accelerators},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning models for serendipity recommendations: A
survey and new perspectives. <em>CSUR</em>, <em>56</em>(1), 19:1–26. (<a
href="https://doi.org/10.1145/3605145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Serendipitous recommendations have emerged as a compelling approach to deliver users with unexpected yet valuable information, contributing to heightened user satisfaction and engagement. This survey presents an investigation of the most recent research in serendipity recommenders, with a specific emphasis on deep learning recommendation models. We categorize these models into three types, distinguishing their integration of the serendipity objective across distinct stages: pre-processing, in-processing, and post-processing. Additionally, we provide a review and summary of the serendipity definition, available ground truth datasets, and evaluation experiments employed in the field. We propose three promising avenues for future exploration: (1) leveraging user reviews to identify and explore serendipity, (2) employing reinforcement learning to construct a model for discerning appropriate timing for serendipitous recommendations, and (3) utilizing cross-domain learning to enhance serendipitous recommendations. With this review, we aim to cultivate a deeper understanding of serendipity in recommender systems and inspire further advancements in this domain.},
  archive      = {J_CSUR},
  author       = {Zhe Fu and Xi Niu and Mary Lou Maher},
  doi          = {10.1145/3605145},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {19:1–26},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning models for serendipity recommendations: A survey and new perspectives},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Offloading machine learning to programmable data planes: A
systematic survey. <em>CSUR</em>, <em>56</em>(1), 18:1–34. (<a
href="https://doi.org/10.1145/3605153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The demand for machine learning (ML) has increased significantly in recent decades, enabling several applications, such as speech recognition, computer vision, and recommendation engines. As applications become more sophisticated, the models trained become more complex while also increasing the amount of data used for training. Several domain-specific techniques can be helpful to scale machine learning to large amounts of data and more complex models. Among the methods employed, of particular interest is offloading machine learning functionality to the network infrastructure, which is enabled by the use of emerging programmable data plane hardware, such as SmartNICs and programmable switches. As such, offloading machine learning to programmable network hardware has attracted considerable attention from the research community in the last few years. This survey presents a study of programmable data planes applied to machine learning, also highlighting how in-network computing is helping to speed up machine learning applications. In this article, we provide various concepts and propose a taxonomy to classify existing research. Next, we systematically review the literature that offloads machine learning functionality to programmable data plane devices, classifying it based on our proposed taxonomy. Finally, we discuss open challenges in the field and suggest directions for future research.},
  archive      = {J_CSUR},
  author       = {Ricardo Parizotto and Bruno Loureiro Coelho and Diego Cardoso Nunes and Israat Haque and Alberto Schaeffer-Filho},
  doi          = {10.1145/3605153},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {18:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Offloading machine learning to programmable data planes: A systematic survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reinforcement learning methods for computation offloading: A
systematic review. <em>CSUR</em>, <em>56</em>(1), 17:1–41. (<a
href="https://doi.org/10.1145/3603703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, cloud computation offloading may not be an appropriate solution for delay-sensitive applications due to the long distance between end-devices and remote datacenters. In addition, offloading to a remote cloud can consume bandwidth and dramatically increase costs. However, end-devices such as sensors, cameras, and smartphones have limited computing and storage capacity. Processing tasks on such battery-powered and energy-constrained devices becomes even more complex. To address these challenges, a new paradigm called Edge Computing (EC) emerged nearly a decade ago to bring computing resources closer to end-devices. Here, edge servers located between the end-device and the remote cloud perform user tasks. Recently, several new computing paradigms such as Mobile Edge Computing (MEC) and Fog Computing (FC) have emerged to complement Cloud Computing (CC) and EC. Although these paradigms are heterogeneous, they can further reduce energy consumption and task response time, especially for delay-sensitive applications. Computation offloading is a multi-objective, NP-hard optimization problem. A significant part of previous research in this field is devoted to Machine Learning (ML) methods. One of the essential types of ML is Reinforcement Learning (RL), in which an agent learns how to make the best decision using the experiences gained from the environment. This article provides a systematic review of the widely used RL approaches in computation offloading. It covers research in complementary paradigms such as mobile cloud computing, edge computing, fog computing, and the Internet of Things. We explain the reasons for using various RL methods in computation offloading from a technical point of view. This analysis includes both binary offloading and partial offloading techniques. For each method, the essential elements of RL and the characteristics of the environment are discussed regarding the most important criteria. Research challenges and Future trends are also mentioned.},
  archive      = {J_CSUR},
  author       = {Zeinab Zabihi and Amir Masoud Eftekhari Moghadam and Mohammad Hossein Rezvani},
  doi          = {10.1145/3603703},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {17:1–41},
  shortjournal = {ACM Comput. Surv.},
  title        = {Reinforcement learning methods for computation offloading: A systematic review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A model and survey of distributed data-intensive systems.
<em>CSUR</em>, <em>56</em>(1), 16:1–69. (<a
href="https://doi.org/10.1145/3604801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data is a precious resource in today’s society, and it is generated at an unprecedented and constantly growing pace. The need to store, analyze, and make data promptly available to a multitude of users introduces formidable challenges in modern software platforms. These challenges radically impacted the research fields that gravitate around data management and processing, with the introduction of distributed data-intensive systems that offer innovative programming models and implementation strategies to handle data characteristics such as its volume, the rate at which it is produced, its heterogeneity, and its distribution. Each data-intensive system brings its specific choices in terms of data model, usage assumptions, synchronization, processing strategy, deployment, guarantees in terms of consistency, fault tolerance, and ordering. Yet, the problems data-intensive systems face and the solutions they propose are frequently overlapping. This article proposes a unifying model that dissects the core functionalities of data-intensive systems, and discusses alternative design and implementation strategies, pointing out their assumptions and implications. The model offers a common ground to understand and compare highly heterogeneous solutions, with the potential of fostering cross-fertilization across research communities. We apply our model by classifying tens of systems: an exercise that brings to interesting observations on the current trends in the domain of data-intensive systems and suggests open research directions.},
  archive      = {J_CSUR},
  author       = {Alessandro Margara and Gianpaolo Cugola and Nicolò Felicioni and Stefano Cilloni},
  doi          = {10.1145/3604801},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {16:1–69},
  shortjournal = {ACM Comput. Surv.},
  title        = {A model and survey of distributed data-intensive systems},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of quantum-cognitively inspired sentiment analysis
models. <em>CSUR</em>, <em>56</em>(1), 15:1–37. (<a
href="https://doi.org/10.1145/3604550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum theory, originally proposed as a physical theory to describe the motions of microscopic particles, has been applied to various non-physics domains involving human cognition and decision-making that are inherently uncertain and exhibit certain non-classical, quantum-like characteristics. Sentiment analysis is a typical example of such domains. In the last few years, by leveraging the modeling power of quantum probability (a non-classical probability stemming from quantum mechanics methodology) and deep neural networks, a range of novel quantum-cognitively inspired models for sentiment analysis have emerged and performed well. This survey presents a timely overview of the latest developments in this fascinating cross-disciplinary area. We first provide a background of quantum probability and quantum cognition at a theoretical level, analyzing their advantages over classical theories in modeling the cognitive aspects of sentiment analysis. Then, recent quantum-cognitively inspired models are introduced and discussed in detail, focusing on how they approach the key challenges of the sentiment analysis task. Finally, we discuss the limitations of the current research and highlight future research directions.},
  archive      = {J_CSUR},
  author       = {Yaochen Liu and Qiuchi Li and Benyou Wang and Yazhou Zhang and Dawei Song},
  doi          = {10.1145/3604550},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {15:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of quantum-cognitively inspired sentiment analysis models},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Challenges and opportunities of biometric user
authentication in the age of IoT: A survey. <em>CSUR</em>,
<em>56</em>(1), 14:1–37. (<a
href="https://doi.org/10.1145/3603705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the Internet of Things (IoT) devices, such as smartwatches, provide a range of services from managing financial transactions to monitoring smart homes, these devices often lead to gateways for malicious access to a user’s cyber-physical space. Biometric-based authentications are becoming popular to secure IoT devices and provide other services. However, when to use what type of biometrics remains challenging due to various factors, including sensing and computing requirements, user interaction requirements, stability over time, and application scenarios, among others. Unlike soft biometrics, e.g., gait, traditional biometrics, e.g., iris, are more stable over time but require active user input and robust sensing and computing, which limits their continuous adaptability to secure a user’s cyber-physical space. Additionally, the integration of new sensors to IoT devices brings opportunistic data types that can individually or in combination with other common biometrics to identify a user. There is a dearth of knowledge about the limitations and applications of new opportunistic biometrics and their combinations with existing biometrics obtained from single or multiple IoT-connected devices. Therefore, this article thoroughly discusses different biometrics that can be implemented on IoT devices to understand the potential of biometric authentications better.},
  archive      = {J_CSUR},
  author       = {Chi-Wei Lien and Sudip Vhaduri},
  doi          = {10.1145/3603705},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {14:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Challenges and opportunities of biometric user authentication in the age of IoT: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mobile edge computing and machine learning in the internet
of unmanned aerial vehicles: A survey. <em>CSUR</em>, <em>56</em>(1),
13:1–31. (<a href="https://doi.org/10.1145/3604933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicles (UAVs) play an important role in the Internet of Things and form the paradigm of the Internet of UAVs, due to their characteristics of flexibility, mobility, and low costs. However, resource constraints such as dynamic wireless channels, limited battery capacities, and computation resources of UAVs make traditional methods inefficient in the Internet of UAVs. The thriving of Mobile Edge Computing (MEC) and Machine Learning (ML) is of great significance and is promising for real-time resource allocation, trajectory design, and intelligent decision making. This survey provides a comprehensive review of key technologies, applications, solutions, and challenges based on the integration of MEC and ML in the Internet of UAVs. First, key technologies of MEC and ML are presented. Then, their integration and major issues in the Internet of UAVs are presented. Furthermore, the applications of MEC and ML in the Internet of UAVs under urban, industrial, and emergency scenarios are discussed. After that, this survey summarizes the current solutions for MEC and ML in the Internet of UAVs based on the considered issues. Finally, some open problems and challenges are discussed.},
  archive      = {J_CSUR},
  author       = {Zhaolong Ning and Hao Hu and Xiaojie Wang and Lei Guo and Song Guo and Guoyin Wang and Xinbo Gao},
  doi          = {10.1145/3604933},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {13:1–31},
  shortjournal = {ACM Comput. Surv.},
  title        = {Mobile edge computing and machine learning in the internet of unmanned aerial vehicles: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Natural language–based conceptual modelling frameworks:
State of the art and future opportunities. <em>CSUR</em>,
<em>56</em>(1), 12:1–26. (<a
href="https://doi.org/10.1145/3596597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying requirements for an information system is an important task and conceptual modelling is the first step in this process. Conceptual modelling plays a critical role in the information system design process and usually involves domain experts and knowledge engineers who brainstorm together to identify the required knowledge to build an information system. The conceptual modelling process starts with the collection of necessary information from the domain experts by the knowledge engineers. Afterwards, the knowledge engineers use traditional model driven engineering techniques to design the system based on the collected information. Natural language–based conceptual modelling frameworks or systems are used to help domain experts and knowledge engineers in eliciting requirements and building conceptual models from a natural language text. In this article, we discuss the state of the art of some recent conceptual modelling frameworks that are based on natural language. We take a closer look at how these frameworks are built, in particular at the underlying motivation, architecture, types of natural language used (e.g., restricted vs. unrestricted), types of the conceptual model generated, verification support of the requirements specifications as well as the conceptual models, and underlying knowledge representation formalism. We also discuss some future research opportunities that these frameworks offer.},
  archive      = {J_CSUR},
  author       = {Bayzid Ashik Hossain and Md. Saddam Hossain Mukta and Md Adnanul Islam and Akib Zaman and Rolf Schwitter},
  doi          = {10.1145/3596597},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {12:1–26},
  shortjournal = {ACM Comput. Surv.},
  title        = {Natural Language–Based conceptual modelling frameworks: State of the art and future opportunities},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning-based human pose estimation: A survey.
<em>CSUR</em>, <em>56</em>(1), 11:1–37. (<a
href="https://doi.org/10.1145/3603618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human pose estimation aims to locate the human body parts and build human body representation (e.g., body skeleton) from input data such as images and videos. It has drawn increasing attention during the past decade and has been utilized in a wide range of applications including human-computer interaction, motion analysis, augmented reality, and virtual reality. Although the recently developed deep learning-based solutions have achieved high performance in human pose estimation, there still remain challenges due to insufficient training data, depth ambiguities, and occlusion. The goal of this survey article is to provide a comprehensive review of recent deep learning-based solutions for both 2D and 3D pose estimation via a systematic analysis and comparison of these solutions based on their input data and inference procedures. More than 260 research papers since 2014 are covered in this survey. Furthermore, 2D and 3D human pose estimation datasets and evaluation metrics are included. Quantitative performance comparisons of the reviewed methods on popular datasets are summarized and discussed. Finally, the challenges involved, applications, and future research directions are concluded. A regularly updated project page is provided: https://github.com/zczcwh/DL-HPE .},
  archive      = {J_CSUR},
  author       = {Ce Zheng and Wenhan Wu and Chen Chen and Taojiannan Yang and Sijie Zhu and Ju Shen and Nasser Kehtarnavaz and Mubarak Shah},
  doi          = {10.1145/3603618},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {11:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning-based human pose estimation: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sensor-based locomotion data mining for supporting the
diagnosis of neurodegenerative disorders: A survey. <em>CSUR</em>,
<em>56</em>(1), 10:1–36. (<a
href="https://doi.org/10.1145/3603495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Locomotion characteristics and movement patterns are reliable indicators of neurodegenerative diseases (NDDs). This survey provides a systematic literature review of locomotion data mining systems for supporting NDD diagnosis. We discuss techniques for discovering low-level locomotion indicators, sensor data acquisition and processing methods, and NDD detection algorithms. The survey presents a comprehensive discussion on the main challenges for this active area, including the addressed diseases, locomotion data types, duration of monitoring, employed algorithms, and experimental validation strategies. We also identify prominent open challenges and research directions regarding ethics and privacy issues, technological and usability aspects, and availability of public benchmarks.},
  archive      = {J_CSUR},
  author       = {Samaneh Zolfaghari and Sumaiya Suravee and Daniele Riboni and Kristina Yordanova},
  doi          = {10.1145/3603495},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {10:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Sensor-based locomotion data mining for supporting the diagnosis of neurodegenerative disorders: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine unlearning: A survey. <em>CSUR</em>, <em>56</em>(1),
9:1–36. (<a href="https://doi.org/10.1145/3603620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning has attracted widespread attention and evolved into an enabling technology for a wide range of highly successful applications, such as intelligent computer vision, speech recognition, medical diagnosis, and more. Yet, a special need has arisen where, due to privacy, usability, and/or the right to be forgotten , information about some specific samples needs to be removed from a model, called machine unlearning. This emerging technology has drawn significant interest from both academics and industry due to its innovation and practicality. At the same time, this ambitious problem has led to numerous research efforts aimed at confronting its challenges. To the best of our knowledge, no study has analyzed this complex topic or compared the feasibility of existing unlearning solutions in different kinds of scenarios. Accordingly, with this survey, we aim to capture the key concepts of unlearning techniques. The existing solutions are classified and summarized based on their characteristics within an up-to-date and comprehensive review of each category’s advantages and limitations. The survey concludes by highlighting some of the outstanding issues with unlearning techniques, along with some feasible directions for new research opportunities.},
  archive      = {J_CSUR},
  author       = {Heng Xu and Tianqing Zhu and Lefeng Zhang and Wanlei Zhou and Philip S. Yu},
  doi          = {10.1145/3603620},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {9:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Machine unlearning: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Impossibility results in AI: A survey. <em>CSUR</em>,
<em>56</em>(1), 8:1–24. (<a
href="https://doi.org/10.1145/3603371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An impossibility theorem demonstrates that a particular problem or set of problems cannot be solved as described in the claim. Such theorems put limits on what is possible to do concerning artificial intelligence, especially the super-intelligent one. As such, these results serve as guidelines, reminders, and warnings to AI safety, AI policy, and governance researchers. These might enable solutions to some long-standing questions in the form of formalizing theories in the framework of constraint satisfaction without committing to one option. We strongly believe this to be the most prudent approach to long-term AI safety initiatives. In this article, we have categorized impossibility theorems applicable to AI into five mechanism-based categories: Deduction, indistinguishability, induction, tradeoffs, and intractability. We found that certain theorems are too specific or have implicit assumptions that limit application. Also, we added new results (theorems) such as the unfairness of explainability, the first explainability-related result in the induction category. The remaining results deal with misalignment between the clones and put a limit to the self-awareness of agents. We concluded that deductive impossibilities deny 100\%-guarantees for security. In the end, we give some ideas that hold potential in explainability, controllability, value alignment, ethics, and group decision-making.},
  archive      = {J_CSUR},
  author       = {Mario Brcic and Roman V. Yampolskiy},
  doi          = {10.1145/3603371},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {8:1–24},
  shortjournal = {ACM Comput. Surv.},
  title        = {Impossibility results in AI: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on deep learning for symbolic music generation:
Representations, algorithms, evaluations, and challenges. <em>CSUR</em>,
<em>56</em>(1), 7:1–39. (<a
href="https://doi.org/10.1145/3597493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Significant progress has been made in symbolic music generation with the help of deep learning techniques. However, the tasks covered by symbolic music generation have not been well summarized, and the evolution of generative models for the specific music generation task has not been illustrated systematically. This paper attempts to provide a task-oriented survey of symbolic music generation based on deep learning techniques, covering most of the currently popular music generation tasks. The distinct models under the same task are set forth briefly and strung according to their motivations, basically in chronological order. Moreover, we summarize the common datasets suitable for various tasks, discuss the music representations and the evaluation methods, highlight current challenges in symbolic music generation, and finally point out potential future research directions.},
  archive      = {J_CSUR},
  author       = {Shulei Ji and Xinyu Yang and Jing Luo},
  doi          = {10.1145/3597493},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {7:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on deep learning for symbolic music generation: Representations, algorithms, evaluations, and challenges},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The evolution of distributed systems for graph neural
networks and their origin in graph processing and deep learning: A
survey. <em>CSUR</em>, <em>56</em>(1), 6:1–37. (<a
href="https://doi.org/10.1145/3597428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are an emerging research field. This specialized deep neural network architecture is capable of processing graph structured data and bridges the gap between graph processing and deep learning. As graphs are everywhere, GNNs can be applied to various domains including recommendation systems, computer vision, natural language processing, biology, and chemistry. With the rapid growing size of real-world graphs, the need for efficient and scalable GNN training solutions has come. Consequently, many works proposing GNN systems have emerged throughout the past few years. However, there is an acute lack of overview, categorization, and comparison of such systems. We aim to fill this gap by summarizing and categorizing important methods and techniques for large-scale GNN solutions. Additionally, we establish connections between GNN systems, graph processing systems, and deep learning systems.},
  archive      = {J_CSUR},
  author       = {Jana Vatter and Ruben Mayer and Hans-Arno Jacobsen},
  doi          = {10.1145/3597428},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {6:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {The evolution of distributed systems for graph neural networks and their origin in graph processing and deep learning: A survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Review on query-focused multi-document summarization (QMDS)
with comparative analysis. <em>CSUR</em>, <em>56</em>(1), 5:1–38. (<a
href="https://doi.org/10.1145/3597299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of query-focused multi-document summarization (QMDS) is to generate a summary from multiple source documents on identical/similar topics based on the query submitted by the users. This article provides a systematic review of the literature of QMDS. The research works are classified into six major categories based on the summarization methodologies used. Different techniques used for finding query-relevant summaries for different algorithms under each of the six major groups are reported. Further, 17 evaluation metrics used for evaluating algorithms for text summaries against the human-curated summaries are compiled here in this article. Extensive experiments are performed on eight different datasets. Comparative results of nine methodologies, each representing one of the six different groups, are presented. Seven different evaluation metrics are used in the comparative study. It is observed that DL- and ML-based QMDS methods perform. better in comparison to the other methods.},
  archive      = {J_CSUR},
  author       = {Prasenjeet Roy and Suman Kundu},
  doi          = {10.1145/3597299},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {5:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Review on query-focused multi-document summarization (QMDS) with comparative analysis},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Security aspects of cryptocurrency wallets—a systematic
literature review. <em>CSUR</em>, <em>56</em>(1), 4:1–31. (<a
href="https://doi.org/10.1145/3596906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cryptocurrencies are gaining prominence among individuals and companies alike, resulting in the growing adoption of so-called cryptocurrency wallet applications, as these simplify transactions. These wallets are available in a myriad of different forms and specifications. All of them are susceptible to various ways the attacker can exploit the vulnerabilities and steal money from victims. Cryptocurrency wallets create a unique field as they combine features of password managers, banking applications, and the need to keep their users and their transactions anonymous. We collect the findings from previous literature to provide an overview of the different attack surfaces, possible countermeasures, and further research. Existing literature focused on one of the features mentioned before, while we considered all of them. Our systematic study shows that there is a considerable variety of attack vectors, which we have divided into six subcategories, (i) Memory and Storage, (ii) Operating Systems, (iii) Software Layer, (iv) Network Layer, (v) Blockchain Protocol, and (vi) Others. We have found a large gap between the possible countermeasures and their actual adoption. Therefore, we provide a list of possible directions for future research to tackle this gap.},
  archive      = {J_CSUR},
  author       = {Sabine Houy and Philipp Schmid and Alexandre Bartel},
  doi          = {10.1145/3596906},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {4:1–31},
  shortjournal = {ACM Comput. Surv.},
  title        = {Security aspects of cryptocurrency Wallets—A systematic literature review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A taxonomy and analysis of misbehaviour detection in
cooperative intelligent transport systems: A systematic review.
<em>CSUR</em>, <em>56</em>(1), 3:1–38. (<a
href="https://doi.org/10.1145/3596598">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative Intelligent Transport Systems (C-ITS) is one of the proposed solutions to improve the safety and efficiency of road transport. However, C-ITS is prone to misbehaviours that can cause devastating effects such as road accidents and potential loss of life. While there are several research studies including technical studies and surveys that discuss misbehaviour detection in C-ITS, they tend to focus on specific aspects of misbehaviour detection and do not provide a comprehensive and unified coverage. With the objective of serving as a reference for future researchers, this study provides a comprehensive survey of misbehaviour detection in C-ITS. It identifies and discusses the key causes of misbehaviour in C-ITS, and the mechanisms used to detect them. Additionally, it proposes a thematic taxonomy on misbehaviour detection based on a comparative analysis of the technical studies. Furthermore, the existing solutions from the state-of-the-art and their shortcomings are also presented. Finally, this study highlights several significant research challenges and discusses future research directions in the area of misbehaviour detection in C-ITS. In doing so, this study contributes to the existing literature in an important field of study.},
  archive      = {J_CSUR},
  author       = {Mohamed Ahzam Amanullah and Seng W. Loke and Mohan Baruwal Chhetri and Robin Doss},
  doi          = {10.1145/3596598},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {3:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A taxonomy and analysis of misbehaviour detection in cooperative intelligent transport systems: A systematic review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Component-based distributed software reconfiguration: A
verification-oriented survey. <em>CSUR</em>, <em>56</em>(1), 2:1–37. (<a
href="https://doi.org/10.1145/3595376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed software built from components has become a mainstay of service-oriented applications, which frequently undergo reconfigurations to adapt to changes in their operating environment or their functional requirements. Given the complexity of distributed software and the adverse effects of incorrect reconfigurations, a suitable methodology is needed to ensure the correctness of reconfigurations in component-based systems. This survey gives the reader a global perspective over existing formal techniques that pursue this goal. It distinguishes different ways in which formal methods can improve the reliability of reconfigurations, and lists techniques that contribute to solving each of these particular scientific challenges.},
  archive      = {J_CSUR},
  author       = {Héléne Coullon and Ludovic Henrio and Frédéric Loulergue and Simon Robillard},
  doi          = {10.1145/3595376},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {2:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Component-based distributed software reconfiguration: A verification-oriented survey},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning for variable renewable energy: A systematic
review. <em>CSUR</em>, <em>56</em>(1), 1:1–37. (<a
href="https://doi.org/10.1145/3586006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, both fields, AI and VRE, have received increasing attention in scientific research. Thus, this article’s purpose is to investigate the potential of DL-based applications on VRE and as such provide an introduction to and structured overview of the field. First, we conduct a systematic literature review of the application of Artificial Intelligence (AI), especially Deep Learning (DL), on the integration of Variable Renewable Energy (VRE). Subsequently, we provide a comprehensive overview of specific DL-based solution approaches and evaluate their applicability, including a survey of the most applied and best suited DL architectures. We identify ten DL-based approaches to support the integration of VRE in modern power systems. We find (I) solar PV and wind power generation forecasting, (II) system scheduling and grid management, and (III) intelligent condition monitoring as three high potential application areas.},
  archive      = {J_CSUR},
  author       = {Janice Klaiber and Clemens Van Dinther},
  doi          = {10.1145/3586006},
  journal      = {ACM Computing Surveys},
  month        = {8},
  number       = {1},
  pages        = {1:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning for variable renewable energy: A systematic review},
  volume       = {56},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
