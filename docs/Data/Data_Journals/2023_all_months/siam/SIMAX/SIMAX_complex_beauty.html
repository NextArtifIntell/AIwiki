<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SIMAX_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="simax---74">SIMAX - 74</h2>
<ul>
<li><details>
<summary>
(2023). Bounded rank perturbations of quasi-regular pencils over
arbitrary fields. <em>SIMAX</em>, <em>44</em>(4), 1879–1907. (<a
href="https://doi.org/10.1137/22M1504068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We solve the open problem of describing the possible Kronecker invariants of quasi-regular matrix pencils under bounded rank perturbations. By a quasi-regular matrix pencil we mean the full (normal) rank matrix pencil. The solution is explicit and constructive, and it is valid over arbitrary fields.},
  archive      = {J_SIMAX},
  author       = {Marija Dodig and Marko Stošić},
  doi          = {10.1137/22M1504068},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {4},
  pages        = {1879-1907},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Bounded rank perturbations of quasi-regular pencils over arbitrary fields},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sharp majorization-type cluster robust bounds for block
filters and eigensolvers. <em>SIMAX</em>, <em>44</em>(4), 1852–1878. (<a
href="https://doi.org/10.1137/23M1551729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Convergence analysis of block iterative solvers for Hermitian eigenvalue problems and closely related research on properties of matrix-based signal filters are challenging and are attracting increased attention due to their recent applications in spectral data clustering and graph-based signal processing. We combine majorization-based techniques pioneered for investigating the Rayleigh–Ritz method in [A. V. Knyazev and M. E. Argentati, SIAM J. Matrix Anal. Appl., 31 (2010), pp. 1521–1537] with tools of classical analysis of the block power method by Rutishauser [Numer. Math., 13 (1969), pp. 4–13] to derive sharp convergence rate bounds of abstract block iterations, wherein tuples of tangents of principal angles or relative errors of Ritz values are bounded using majorization in terms of arranged partial sums and tuples of convergence factors. Our novel bounds are robust in the presence of clusters of eigenvalues, improve previous results, and are applicable to most known block iterative solvers and matrix-based filters, e.g., to block power, Chebyshev, and Lanczos methods combined with polynomial filtering. The sharpness of our bounds is fundamental, implying that the bounds cannot be improved without further assumptions.},
  archive      = {J_SIMAX},
  author       = {Ming Zhou and Merico Argentati and Andrew V. Knyazev and Klaus Neymeyr},
  doi          = {10.1137/23M1551729},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {4},
  pages        = {1852-1878},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Sharp majorization-type cluster robust bounds for block filters and eigensolvers},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Uniformization stable markov models and their jordan
algebraic structure. <em>SIMAX</em>, <em>44</em>(4), 1822–1851. (<a
href="https://doi.org/10.1137/22M1474527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We provide a characterization of the continuous-time Markov models where the Markov matrices from the model can be parameterized directly in terms of the associated rate matrices (generators). That is, each Markov matrix can be expressed as the sum of the identity matrix and a rate matrix from the model. We show that the existence of an underlying Jordan algebra provides a sufficient condition, which becomes necessary for (so-called) linear models. We connect this property to the well-known uniformization procedure for continuous-time Markov chains by demonstrating that the property is equivalent to all Markov matrices from the model taking the same form as the corresponding discrete-time Markov matrices in the uniformized process. We apply our results to analyze two model hierarchies practically important to phylogenetic inference, obtained by assuming (i) time reversibility and (ii) permutation symmetry, respectively.},
  archive      = {J_SIMAX},
  author       = {Luke Cooper and Jeremy Sumner},
  doi          = {10.1137/22M1474527},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {4},
  pages        = {1822-1851},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Uniformization stable markov models and their jordan algebraic structure},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identifiability in continuous lyapunov models.
<em>SIMAX</em>, <em>44</em>(4), 1799–1821. (<a
href="https://doi.org/10.1137/22M1520311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The recently introduced graphical continuous Lyapunov models provide a new approach to statistical modeling of correlated multivariate data. The models view each observation as a one-time cross-sectional snapshot of a multivariate dynamic process in equilibrium. The covariance matrix for the data is obtained by solving a continuous Lyapunov equation that is parametrized by the drift matrix of the dynamic process. In this context, different statistical models postulate different sparsity patterns in the drift matrix, and it becomes a crucial problem to clarify whether a given sparsity assumption allows one to uniquely recover the drift matrix parameters from the covariance matrix of the data. We study this identifiability problem by representing sparsity patterns by directed graphs. Our main result proves that the drift matrix is globally identifiable if and only if the graph for the sparsity pattern is simple (i.e., does not contain directed 2-cycles). Moreover, we present a necessary condition for generic identifiability and provide a computational classification of small graphs with up to 5 nodes.},
  archive      = {J_SIMAX},
  author       = {Philipp Dettling and Roser Homs and Carlos Améndola and Mathias Drton and Niels Richard Hansen},
  doi          = {10.1137/22M1520311},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {4},
  pages        = {1799-1821},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Identifiability in continuous lyapunov models},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PinT preconditioner for forward-backward evolutionary
equations. <em>SIMAX</em>, <em>44</em>(4), 1771–1798. (<a
href="https://doi.org/10.1137/22M1516476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Solving the linear system is often the major computational burden when a forward-backward evolutionary equation must be solved in a problem, where is the so-called all-at-once matrix of the forward subproblem after space-time discretization. An efficient solver requires a good preconditioner for . Inspired by the structure of , we precondition by with being a block -circulant matrix constructed by replacing the Toeplitz matrices in by the -circulant matrices. By a block Fourier diagonalization of , the computation of the preconditioning step is parallelizable for all the time steps. We give a spectral analysis for the preconditioned matrix and prove that for any one-step stable time-integrator the eigenvalues of spread in a mesh-independent interval if the parameter weakly scales in terms of the number of time steps as , where is a free constant. Two applications of the proposed preconditioner are illustrated: PDE-constrained optimal control problems and parabolic source identification problems. Numerical results for both problems indicate that spectral analysis predicts the convergence rate of the preconditioned conjugate gradient method very well.},
  archive      = {J_SIMAX},
  author       = {Shu-Lin Wu and Zhiyong Wang and Tao Zhou},
  doi          = {10.1137/22M1516476},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {4},
  pages        = {1771-1798},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {PinT preconditioner for forward-backward evolutionary equations},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stochastic algebraic riccati equations are almost as easy as
deterministic ones theoretically. <em>SIMAX</em>, <em>44</em>(4),
1749–1770. (<a href="https://doi.org/10.1137/22M1514647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Stochastic algebraic Riccati equations, also known as rational algebraic Riccati equations, arising in linear-quadratic optimal control for stochastic linear time-invariant systems, were considered to be not easy to solve. The state-of-the-art numerical methods mostly rely on differentiability or continuity, such as the Newton-type method, the LMI method, or the homotopy method. In this paper, we will build a novel theoretical framework and reveal the intrinsic algebraic structure appearing in this kind of algebraic Riccati equation. This structure guarantees that to solve them is almost as easy as to solve deterministic/classical ones, which will shed light on the theoretical analysis and numerical algorithm design for this topic.},
  archive      = {J_SIMAX},
  author       = {Zhen-Chen Guo and Xin Liang},
  doi          = {10.1137/22M1514647},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {4},
  pages        = {1749-1770},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Stochastic algebraic riccati equations are almost as easy as deterministic ones theoretically},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Introducing the class of SemiDoubly stochastic matrices: A
novel scaling approach for rectangular matrices. <em>SIMAX</em>,
<em>44</em>(4), 1731–1748. (<a
href="https://doi.org/10.1137/22M1519791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. It is easy to verify that if is a doubly stochastic matrix, then both its normal equations and are also doubly stochastic, but the reciprocal is not true. In this paper, we introduce and analyze the complete class of nonnegative matrices whose normal equations are doubly stochastic. This class contains and extends the class of doubly stochastic matrices to the rectangular case. In particular, we characterize these matrices in terms of their row and column sums and provide results regarding their nonzero structure. We then consider the diagonal equivalence of any rectangular nonnegative matrix to a matrix of this new class, and we identify the properties for such a diagonal equivalence to exist. To this end, we present a scaling algorithm and establish the conditions for its convergence. We also provide numerical experiments to highlight the behavior of the algorithm in the general case.},
  archive      = {J_SIMAX},
  author       = {Philip A. Knight and Luce le Gorrec and Sandrine Mouysset and Daniel Ruiz},
  doi          = {10.1137/22M1519791},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {4},
  pages        = {1731-1748},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Introducing the class of SemiDoubly stochastic matrices: A novel scaling approach for rectangular matrices},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalized matrix nearness problems. <em>SIMAX</em>,
<em>44</em>(4), 1709–1730. (<a
href="https://doi.org/10.1137/22M1526034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We show that the global minimum solution of can be found in closed form with singular value decompositions and generalized singular value decompositions for a variety of constraints on involving rank, norm, symmetry, two-sided product, and prescribed eigenvalue. This extends the solution of Friedland–Torokhti for the generalized rank-constrained approximation problem to other constraints and provides an alternative solution for rank constraint in terms of singular value decompositions. For more complicated constraints on involving structures such as Toeplitz, Hankel, circulant, nonnegativity, stochasticity, positive semidefiniteness, prescribed eigenvector, etc., we prove that a simple iterative method is linearly and globally convergent to the global minimum solution.},
  archive      = {J_SIMAX},
  author       = {Zihao Li and Lek-Heng Lim},
  doi          = {10.1137/22M1526034},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {4},
  pages        = {1709-1730},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Generalized matrix nearness problems},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Kronecker product approximation of operators in spectral
norm via alternating SDP. <em>SIMAX</em>, <em>44</em>(4), 1693–1708. (<a
href="https://doi.org/10.1137/22M1509953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The decomposition or approximation of a linear operator on a matrix space as a sum of Kronecker products plays an important role in matrix equations and low-rank modeling. The approximation problem in Frobenius norm admits a well-known solution via the singular value decomposition. However, the approximation problem in spectral norm, which is more natural for linear operators, is much more challenging. In particular, the Frobenius norm solution can be far from optimal in spectral norm. We describe an alternating optimization method based on semidefinite programming to obtain high-quality approximations in spectral norm, and we present computational experiments to illustrate the advantages of our approach.},
  archive      = {J_SIMAX},
  author       = {Mareike Dressler and André Uschmajew and Venkat Chandrasekaran},
  doi          = {10.1137/22M1509953},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {4},
  pages        = {1693-1708},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Kronecker product approximation of operators in spectral norm via alternating SDP},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semidefinite relaxation methods for tensor absolute value
equations. <em>SIMAX</em>, <em>44</em>(4), 1667–1692. (<a
href="https://doi.org/10.1137/22M1539137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we consider the tensor absolute value equations (TAVEs). When one tensor is row diagonal with odd order, we show that the TAVEs can be reduced to an algebraic equation; when it is row diagonal and nonsingular with even order, we prove that the TAVEs is equivalent to a polynomial complementary problem. When no tensor is row diagonal, we formulate the TAVEs equivalently as polynomial optimization problems in two different ways. Each of them can be solved by Lasserre’s hierarchy of semidefinite relaxations. The finite convergence properties are also discussed. Numerical experiments show the efficiency of the proposed methods.},
  archive      = {J_SIMAX},
  author       = {Anwa Zhou and Kun Liu and Jinyan Fan},
  doi          = {10.1137/22M1539137},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {4},
  pages        = {1667-1692},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Semidefinite relaxation methods for tensor absolute value equations},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalized perron roots and solvability of the absolute
value equation. <em>SIMAX</em>, <em>44</em>(4), 1645–1666. (<a
href="https://doi.org/10.1137/22M1517184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Let be an real matrix. The piecewise linear equation system is called an absolute value equation (AVE). It is well known to be equivalent to the linear complementarity problem. Unique solvability of the AVE is known to be characterized in terms of a generalized Perron root called the sign-real spectral radius of . For mere, possibly nonunique, solvability no such characterization exists. We narrow this gap in the theory. That is, we define the concept of the aligned spectrum of and prove, under some mild genericity assumptions on , that the mapping degree of the piecewise linear function is congruent to , where is the number of aligned values of which are larger than 1. We also derive an exact—but more technical—formula for the degree of in terms of the aligned spectrum. Finally, we derive the analogous quantities and results for the linear complementarity problem.},
  archive      = {J_SIMAX},
  author       = {Manuel Radons and Josué Tonelli-Cueto},
  doi          = {10.1137/22M1517184},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {4},
  pages        = {1645-1666},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Generalized perron roots and solvability of the absolute value equation},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contour integration for eigenvector nonlinearities.
<em>SIMAX</em>, <em>44</em>(4), 1619–1644. (<a
href="https://doi.org/10.1137/22M1497985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Solving polynomial eigenvalue problems with eigenvector nonlinearities (PEPv) is an interesting computational challenge, outside the reach of the well-developed methods for nonlinear eigenvalue problems. We present a natural generalization of these methods which leads to a contour integration approach for computing all eigenvalues of a PEPv in a compact region of the complex plane. Our methods can be used to solve any suitably generic system of polynomial or rational function equations.},
  archive      = {J_SIMAX},
  author       = {Rob Claes and Karl Meerbergen and Simon Telen},
  doi          = {10.1137/22M1497985},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {4},
  pages        = {1619-1644},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Contour integration for eigenvector nonlinearities},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving singular generalized eigenvalue problems. Part II:
Projection and augmentation. <em>SIMAX</em>, <em>44</em>(4), 1589–1618.
(<a href="https://doi.org/10.1137/22M1513174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Generalized eigenvalue problems involving a singular pencil may be very challenging to solve, both with respect to accuracy and efficiency. While Part I presented a rank-completing addition to a singular pencil, we now develop two alternative methods. The first technique is based on a projection onto subspaces with dimension equal to the normal rank of the pencil while the second approach exploits an augmented matrix pencil. The projection approach seems to be the most attractive version for generic singular pencils because of its efficiency, while the augmented pencil approach may be suitable for applications where a linear system with the augmented pencil can be solved efficiently.},
  archive      = {J_SIMAX},
  author       = {Michiel E. Hochstenbach and Christian Mehl and Bor Plestenjak},
  doi          = {10.1137/22M1513174},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {4},
  pages        = {1589-1618},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Solving singular generalized eigenvalue problems. part II: Projection and augmentation},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust recovery of low-rank matrices and low-tubal-rank
tensors from noisy sketches. <em>SIMAX</em>, <em>44</em>(4), 1566–1588.
(<a href="https://doi.org/10.1137/22M150071X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A common approach for compressing large-scale data is through matrix sketching. In this work, we consider the problem of recovering low-rank matrices from two noisy linear sketches using the double sketching scheme discussed in Fazel et al. [Compressed sensing and robust recovery of low rank matrices, in Proceedings of the 42nd IEEE Asilomar Conference on Signals, Systems and Computers, 2008, pp. 1043–1047], which is based on an approach by Woolfe et al. [Appl. Comput. Harmon. Anal., 25 (2008), pp. 335–366]. Using tools from nonasymptotic random matrix theory, we provide the first theoretical guarantees characterizing the error between the output of the double sketch algorithm and the ground truth low-rank matrix. We apply our result to the problems of low-rank matrix approximation and low-tubal-rank tensor recovery.},
  archive      = {J_SIMAX},
  author       = {Anna Ma and Dominik Stöger and Yizhe Zhu},
  doi          = {10.1137/22M150071X},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {4},
  pages        = {1566-1588},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Robust recovery of low-rank matrices and low-tubal-rank tensors from noisy sketches},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Block preconditioners for the marker-and-cell discretization
of the stokes–darcy equations. <em>SIMAX</em>, <em>44</em>(4),
1540–1565. (<a href="https://doi.org/10.1137/22M1518384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the problem of iteratively solving large and sparse double saddle-point systems arising from the stationary Stokes–Darcy equations in two dimensions, discretized by the marker-and-cell finite difference method. We analyze the eigenvalue distribution of a few ideal block preconditioners. We then derive practical preconditioners that are based on approximations of Schur complements that arise in a block decomposition of the double saddle-point matrix. We show that including the interface conditions in the preconditioners is key in the pursuit of scalability. Numerical results show good convergence behavior of our preconditioned GMRES solver and demonstrate robustness of the proposed preconditioner with respect to the physical parameters of the problem.},
  archive      = {J_SIMAX},
  author       = {Chen Greif and Yunhui He},
  doi          = {10.1137/22M1518384},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {4},
  pages        = {1540-1565},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Block preconditioners for the marker-and-cell discretization of the Stokes–Darcy equations},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On characteristic invariants of matrix pencils and linear
relations. <em>SIMAX</em>, <em>44</em>(4), 1510–1539. (<a
href="https://doi.org/10.1137/22M1535449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The relationship between linear relations and matrix pencils is investigated. Given a linear relation, we introduce its Weyr characteristic. If the linear relation is the range (or the kernel) representation of a given matrix pencil, we show that there is a correspondence between this characteristic and the Kronecker canonical form of the pencil. This relationship is exploited to obtain estimations on the invariant characteristics of matrix pencils under rank-one perturbations.},
  archive      = {J_SIMAX},
  author       = {H. Gernandt and F. Martínez Pería and F. Philipp and C. Trunk},
  doi          = {10.1137/22M1535449},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {4},
  pages        = {1510-1539},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {On characteristic invariants of matrix pencils and linear relations},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A preconditioned MINRES method for optimal control of wave
equations and its asymptotic spectral distribution theory.
<em>SIMAX</em>, <em>44</em>(4), 1477–1509. (<a
href="https://doi.org/10.1137/23M1547251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work, we propose a novel preconditioned Krylov subspace method for solving an optimal control problem of wave equations, after explicitly identifying the asymptotic spectral distribution of the involved sequence of linear coefficient matrices from the optimal control problem. Namely, we first show that the all-at-once system stemming from the wave control problem is associated to a structured coefficient matrix-sequence possessing an eigenvalue distribution. Then, based on such a spectral distribution of which the symbol is explicitly identified, we develop an ideal preconditioner and two parallel-in-time preconditioners for the saddle point system composed of two block Toeplitz matrices. For the ideal preconditioner, we show that the eigenvalues of the preconditioned matrix-sequence all belong to the set well separated from zero, leading to mesh-independent convergence when the minimal residual method is employed. The proposed parallel-in-time preconditioners can be implemented efficiently using fast Fourier transforms or discrete sine transforms, and their effectiveness is theoretically shown in the sense that the eigenvalues of the preconditioned matrix-sequences are clustered around , which leads to rapid convergence. When these parallel-in-time preconditioners are not fastly diagonalizable, we further propose modified versions which can be efficiently inverted. Several numerical examples are reported to verify our derived localization and spectral distribution result and to support the effectiveness of our proposed preconditioners and the related advantages with respect to the relevant literature.},
  archive      = {J_SIMAX},
  author       = {Sean Hon and Jiamei Dong and Stefano Serra-Capizzano},
  doi          = {10.1137/23M1547251},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {4},
  pages        = {1477-1509},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {A preconditioned MINRES method for optimal control of wave equations and its asymptotic spectral distribution theory},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bures–wasserstein minimizing geodesics between covariance
matrices of different ranks. <em>SIMAX</em>, <em>44</em>(3), 1447–1476.
(<a href="https://doi.org/10.1137/22M149168X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The set of covariance matrices equipped with the Bures–Wasserstein distance is the orbit space of the smooth, proper, and isometric action of the orthogonal group on the Euclidean space of square matrices. This construction induces a natural orbit stratification on covariance matrices, which is exactly the stratification by the rank. Thus, the strata are the manifolds of symmetric positive semidefinite matrices of fixed rank endowed with the Bures–Wasserstein Riemannian metric. In this work, we study the geodesics of the Bures–Wasserstein distance. First, we complete the literature on geodesics in each stratum by clarifying the set of preimages of the exponential map and by specifying the injectivity domain. We also give explicit formulae of the horizontal lift, the exponential map, and the Riemannian logarithms that were kept implicit in previous works. Second, we give the expression of all the minimizing geodesic segments joining two covariance matrices of any rank. More precisely, we show that the set of all minimizing geodesics between two covariance matrices and is parametrized by the closed unit ball of for the spectral norm, where are the respective ranks of . In particular, the minimizing geodesic is unique if and only if . Otherwise, there are infinitely many. As a secondary contribution, we provide a review of the definitions related to geodesics in metric spaces, affine connection manifolds, and Riemannian manifolds, which is helpful for the study of other spaces.},
  archive      = {J_SIMAX},
  author       = {Yann Thanwerdas and Xavier Pennec},
  doi          = {10.1137/22M149168X},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {3},
  pages        = {1447-1476},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Bures–Wasserstein minimizing geodesics between covariance matrices of different ranks},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Approximate solutions of linear systems at a universal rate.
<em>SIMAX</em>, <em>44</em>(3), 1436–1446. (<a
href="https://doi.org/10.1137/22M1517196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Let be invertible, unknown, and given. We are interested in approximate solutions: vectors such that is small. We prove that for all , there is a composition of orthogonal projections onto the hyperplanes generated by the rows of , where , which maps the origin to a vector satisfying . We note that this upper bound on is independent of the matrix . This procedure is stable in the sense that . The existence proof is based on a probabilistically refined analysis of the randomized Kaczmarz method, which seems to achieve this rate when solving for with high likelihood. We also prove a general version for matrices with and full rank.},
  archive      = {J_SIMAX},
  author       = {Stefan Steinerberger},
  doi          = {10.1137/22M1517196},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {3},
  pages        = {1436-1446},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Approximate solutions of linear systems at a universal rate},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An apocalypse-free first-order low-rank optimization
algorithm with at most one rank reduction attempt per iteration.
<em>SIMAX</em>, <em>44</em>(3), 1421–1435. (<a
href="https://doi.org/10.1137/22M1518256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the problem of minimizing a differentiable function with locally Lipschitz continuous gradient on the real determinantal variety and present a first-order algorithm designed to find a stationary point of that problem. This algorithm applies steps of a retraction-free descent method proposed by Schneider and Uschmajew [SIAM J. Optim., 25 (2015), pp. 622–646], while taking the numerical rank into account to attempt rank reductions. We prove that this algorithm produces a sequence of iterates whose accumulation points are stationary and therefore does not follow the so-called apocalypses described by Levin, Kileel, and Boumal [Math. Program., 199 (2023), pp. 831–864]. Moreover, the rank reduction mechanism of this algorithm requires at most one rank reduction attempt per iteration, in contrast with the one of the algorithm introduced by Olikier, Gallivan, and Absil [An Apocalypse-Free First-Order Low-Rank Optimization Algorithm, Technical report UCL-INMA-2022.01, https://arxiv.org/abs/2201.03962, 2022], which can require a number of rank reduction attempts equal to the rank of the iterate in the worst-case scenario.},
  archive      = {J_SIMAX},
  author       = {Guillaume Olikier and P.-A. Absil},
  doi          = {10.1137/22M1518256},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {3},
  pages        = {1421-1435},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {An apocalypse-free first-order low-rank optimization algorithm with at most one rank reduction attempt per iteration},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Coseparable nonnegative matrix factorization.
<em>SIMAX</em>, <em>44</em>(3), 1393–1420. (<a
href="https://doi.org/10.1137/22M1510509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Nonnegative matrix factorization (NMF) is a popular model in the field of pattern recognition. The aim is to find a low rank approximation for nonnegative matrix by a product of two nonnegative matrices and . In general, NMF is NP-hard to solve while it can be solved efficiently under a separability assumption, which requires that the columns of the factor matrix are some columns of the input matrix . In this paper, we generalize the separability assumption based on 3-factor NMF , and require that is a submatrix of the input matrix . We refer to this NMF as a Coseparable NMF (CoS-NMF). In the paper, we discuss and study mathematical properties of CoS-NMF, and present its relationships with other matrix factorizations such as generalized separable NMF, tri-symNMF, biorthogonal trifactorization and CUR decomposition. An optimization method for CoS-NMF is proposed, and an alternating fast gradient method is employed to determine the rows and the columns of for the submatrix . Numerical experiments on synthetic data sets, document data sets, and facial data sets are conducted to verify the effectiveness of the proposed CoS-NMF model. By comparison with state-of-the-art methods, the CoS-NMF model performs very well in a coclustering task by finding useful features, and keeps a good approximation to the input data matrix as well.},
  archive      = {J_SIMAX},
  author       = {Junjun Pan and Michael K. Ng},
  doi          = {10.1137/22M1510509},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {3},
  pages        = {1393-1420},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Coseparable nonnegative matrix factorization},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Randomized low-rank approximation for symmetric indefinite
matrices. <em>SIMAX</em>, <em>44</em>(3), 1370–1392. (<a
href="https://doi.org/10.1137/22M1538648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The Nyström method is a popular choice for finding a low-rank approximation to a symmetric positive semidefinite matrix. The method can fail when applied to symmetric indefinite matrices for which the error can be unboundedly large. In this work, we first identify the main challenges in finding a Nyström approximation to symmetric indefinite matrices. We then prove the existence of a variant that overcomes the instability, and establish relative-error nuclear norm bounds of the resulting approximation that hold when the singular values decay rapidly. The analysis naturally leads to a practical algorithm, whose robustness is illustrated with experiments.},
  archive      = {J_SIMAX},
  author       = {Yuji Nakatsukasa and Taejun Park},
  doi          = {10.1137/22M1538648},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {3},
  pages        = {1370-1392},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Randomized low-rank approximation for symmetric indefinite matrices},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Randomized block adaptive linear system solvers.
<em>SIMAX</em>, <em>44</em>(3), 1349–1369. (<a
href="https://doi.org/10.1137/22M1488715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Randomized linear solvers randomly compress and solve a linear system with compelling theoretical convergence rates and computational complexities. However, such solvers suffer a substantial disconnect between their theoretical rates and actual efficiency in practice. Fortunately, these solvers are quite flexible and can be adapted to specific problems and computing environments to ensure high efficiency in practice, even at the cost of lower effectiveness (i.e., having a slower theoretical rate of convergence). While highly efficient adapted solvers can be readily designed by application experts, will such solvers still converge and at what rate? To answer this, we distill three general criteria for randomized adaptive solvers, which, as we show, will guarantee a worst-case exponential rate of convergence of the solver applied to consistent and inconsistent linear systems irrespective of whether such systems are overdetermined, underdetermined, or rank deficient. As a result, we enable application experts to design randomized adaptive solvers that achieve efficiency and can be verified for effectiveness using our theory. We demonstrate our theory on 26 solvers, nine of which are novel or novel block extensions of existing methods to the best of our knowledge.},
  archive      = {J_SIMAX},
  author       = {Vivak Patel and Mohammad Jahangoshahi and D. Adrian Maldonado},
  doi          = {10.1137/22M1488715},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {3},
  pages        = {1349-1369},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Randomized block adaptive linear system solvers},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sensitivity of matrix function based network communicability
measures: Computational methods and a priori bounds. <em>SIMAX</em>,
<em>44</em>(3), 1321–1348. (<a
href="https://doi.org/10.1137/23M1556708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. When analyzing complex networks, an important task is the identification of those nodes which play a leading role for the overall communicability of the network. In the context of modifying networks (or making them robust against targeted attacks or outages), it is also relevant to know how sensitive the network’s communicability reacts to changes in certain nodes or edges. Recently, the concept of total network sensitivity was introduced in [O. De la Cruz Cabrera, J. Jin, S. Noschese, and L. Reichel, Appl. Numer. Math., 172 (2022) pp. 186–205], which allows one to measure how sensitive the total communicability of a network is to the addition or removal of certain edges. One shortcoming of this concept is that sensitivities are extremely costly to compute when using a straightforward approach (orders of magnitude more expensive than the corresponding communicability measures). In this work, we present computational procedures for estimating network sensitivity with a cost that is essentially linear in the number of nodes for many real-world complex networks. Additionally, we extend the sensitivity concept such that it also covers sensitivity of subgraph centrality and the Estrada index, and we discuss the case of node removal. We propose a priori bounds for these sensitivities which capture well the qualitative behavior and give insight into the general behavior of matrix function based network indices under perturbations. These bounds are based on decay results for Fréchet derivatives of matrix functions with structured, low-rank direction terms which might be of independent interest also for applications other than network analysis.},
  archive      = {J_SIMAX},
  author       = {Marcel Schweitzer},
  doi          = {10.1137/23M1556708},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {3},
  pages        = {1321-1348},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Sensitivity of matrix function based network communicability measures: Computational methods and a priori bounds},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Perturbation theory of transfer function matrices.
<em>SIMAX</em>, <em>44</em>(3), 1299–1320. (<a
href="https://doi.org/10.1137/22M1509825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Zeros of rational transfer function matrices are the eigenvalues of associated polynomial system matrices under minimality conditions. In this paper, we define a structured condition number for a simple eigenvalue of a (locally) minimal polynomial system matrix , which in turn is a simple zero of its transfer function matrix . Since any rational matrix can be written as the transfer function of a polynomial system matrix, our analysis yields a structured perturbation theory for simple zeros of rational matrices . To capture all the zeros of , regardless of whether they are poles, we consider the notion of root vectors. As corollaries of the main results, we pay particular attention to the special case of being not a pole of since in this case the results get simpler and can be useful in practice. We also compare our structured condition number with Tisseur’s unstructured condition number for eigenvalues of matrix polynomials and show that the latter can be unboundedly larger. Finally, we corroborate our analysis by numerical experiments.},
  archive      = {J_SIMAX},
  author       = {Vanni Noferini and Lauri Nyman and Javier Pérez and María C. Quintana},
  doi          = {10.1137/22M1509825},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {3},
  pages        = {1299-1320},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Perturbation theory of transfer function matrices},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analyzing the influence of agents in trust networks:
Applying nonsmooth eigensensitivity theory to a graph centrality
problem. <em>SIMAX</em>, <em>44</em>(3), 1271–1298. (<a
href="https://doi.org/10.1137/21M146884X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Graph centrality measures have found widespread use ranking agents in networks by characterizing their “importance” for the purpose of predicting and managing network outcomes. One major application of such a graph centrality problem is found in decentralized, peer-to-peer networks; in particular, the EigenTrust algorithm for trust management aims to reduce the amount of malware distributed in peer-to-peer networks by using graph centrality as a metric for reputation. This popular scheme has been successfully applied to many different types of peer-to-peer networks. However, the effect malicious agents can have on the reliability of schemes like EigenTrust through overt or covert behavior has not yet been fully investigated. In this work, we analyze vulnerabilities in EigenTrust by extending classical eigenvalue/eigenvector sensitivity theory to the nonsmooth setting, where the presence of nonsmoothness in this problem arises from defense mechanisms built into EigenTrust. This enables us to compute the sensitivity of trust scores to ratings provided by individual agents, revealing vulnerabilities in EigenTrust. Our findings indicate that malicious agents can have a large impact on a network despite having relatively low centrality themselves (i.e., appearing untrustworthy).},
  archive      = {J_SIMAX},
  author       = {Jon Donnelly and Peter Stechlinski},
  doi          = {10.1137/21M146884X},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {3},
  pages        = {1271-1298},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Analyzing the influence of agents in trust networks: Applying nonsmooth eigensensitivity theory to a graph centrality problem},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A structure-preserving divide-and-conquer method for
pseudosymmetric matrices. <em>SIMAX</em>, <em>44</em>(3), 1245–1270. (<a
href="https://doi.org/10.1137/22M1484985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We devise a spectral divide-and-conquer scheme for matrices that are self-adjoint with respect to a given indefinite scalar product (i.e., pseudosymmetic matrices). The pseudosymmetric structure of the matrix is preserved in the spectral division such that the method can be applied recursively to achieve full diagonalization. The method is well suited for structured matrices that come up in computational quantum physics and chemistry. In this application context, additional definiteness properties guarantee a convergence of the matrix sign function iteration within two steps when Zolotarev functions are used. The steps are easily parallelizable. Furthermore, it is shown that the matrix decouples into symmetric definite eigenvalue problems after just one step of spectral division.},
  archive      = {J_SIMAX},
  author       = {Peter Benner and Yuji Nakatsukasa and Carolin Penke},
  doi          = {10.1137/22M1484985},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {3},
  pages        = {1245-1270},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {A structure-preserving divide-and-conquer method for pseudosymmetric matrices},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Krylov-aware stochastic trace estimation. <em>SIMAX</em>,
<em>44</em>(3), 1218–1244. (<a
href="https://doi.org/10.1137/22M1494257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We introduce an algorithm for estimating the trace of a matrix function using implicit products with a symmetric matrix . Existing methods for implicit trace estimation of a matrix function tend to treat matrix-vector products with as a black box to be computed by a Krylov subspace method. Like other recent algorithms for implicit trace estimation, our approach is based on a combination of deflation and stochastic trace estimation. However, we take a closer look at how products with are integrated into these approaches which enables several efficiencies not present in previously studied methods. In particular, we describe a Krylov subspace method for computing a low-rank approximation of a matrix function by a computationally efficient projection onto Krylov subspace.},
  archive      = {J_SIMAX},
  author       = {Tyler Chen and Eric Hallman},
  doi          = {10.1137/22M1494257},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {3},
  pages        = {1218-1244},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Krylov-aware stochastic trace estimation},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Eigenvalue embedding of damped vibroacoustic system with
no-spillover. <em>SIMAX</em>, <em>44</em>(3), 1189–1217. (<a
href="https://doi.org/10.1137/22M1527416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, the eigenvalue embedding problem of the damped vibroacoustic system with no-spillover (EEP-VA) is considered, which is to update the original system to a new damped vibroacoustic system such that some eigenvalues are replaced by newly given or measured ones, while the remaining eigenvalues and associated eigenvectors are kept unchanged. We provide a spectral decomposition of the damped vibroacoustic system and further give a set of parametric solutions to the EEP-VA. Moreover, our method can also be extended to the case of the undamped vibroacoustic system. Exploiting the freedoms of the parametric matrices in the solution, the modifications on the coefficient matrices can be minimized. Numerical experiments illustrate the performance of the proposed algorithms.},
  archive      = {J_SIMAX},
  author       = {Kang Zhao and Zhong Y. Liu},
  doi          = {10.1137/22M1527416},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {3},
  pages        = {1189-1217},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Eigenvalue embedding of damped vibroacoustic system with no-spillover},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Revisiting the matrix polynomial greatest common divisor.
<em>SIMAX</em>, <em>44</em>(3), 1164–1188. (<a
href="https://doi.org/10.1137/22M1531993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we revisit the greatest common right divisor (GCRD) extraction from a set of polynomial matrices , with coefficients in a generic field and with common column dimension . We give necessary and sufficient conditions for a matrix to be a GCRD using the Smith normal form of the compound matrix obtained by concatenating vertically, where . We also describe the complete set of degrees of freedom for the solution , and we link it to the Smith form and Hermite form of . We then give an algorithm for constructing a particular minimum size solution for this problem when or , using state-space techniques. This new method works directly on the coefficient matrices of , using orthogonal transformations only. The method is based on the staircase algorithm, applied to a particular pencil derived from a generalized state-space model of .},
  archive      = {J_SIMAX},
  author       = {Vanni Noferini and Paul Van Dooren},
  doi          = {10.1137/22M1531993},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {3},
  pages        = {1164-1188},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Revisiting the matrix polynomial greatest common divisor},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Probabilistic rounding error analysis of householder QR
factorization. <em>SIMAX</em>, <em>44</em>(3), 1146–1163. (<a
href="https://doi.org/10.1137/22M1514817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The standard worst-case normwise backward error bound for Householder QR factorization of an matrix is proportional to , where is the unit roundoff. We prove that the bound can be replaced by one proportional to that holds with high probability if the rounding errors are mean independent and of mean zero and if the normwise backward errors in applying a sequence of Householder matrices to a vector satisfy bounds proportional to with probability 1. The proof makes use of a matrix concentration inequality. The same square rooting of the error constant applies to two-sided transformations by Householder matrices and hence to standard QR-type algorithms for computing eigenvalues and singular values. It also applies to Givens QR factorization. These results complement recent probabilistic rounding error analysis results for inner product-based algorithms and show that the square rooting effect is widespread in numerical linear algebra. Our numerical experiments, which make use of a new backward error formula for QR factorization, show that the probabilistic bounds give a much better indicator of the actual backward errors and their rate of growth than the worst-case bounds.},
  archive      = {J_SIMAX},
  author       = {Michael P. Connolly and Nicholas J. Higham},
  doi          = {10.1137/22M1514817},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {3},
  pages        = {1146-1163},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Probabilistic rounding error analysis of householder QR factorization},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Matrix-analytic methods for solving poisson’s equation with
applications to markov chains of GI/g/1-type. <em>SIMAX</em>,
<em>44</em>(3), 1122–1145. (<a
href="https://doi.org/10.1137/22M1489861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we are devoted to developing matrix-analytic methods for solving Poisson’s equation for irreducible and positive recurrent discrete-time Markov chains. Two special solutions, including the deviation matrix and the expected additive-type functional matrix , will be considered. The results are applied to Markov chains of -type and queues with negative customers. Further extensions to continuous-time Markov chains are also investigated.},
  archive      = {J_SIMAX},
  author       = {Jinpeng Liu and Yuanyuan Liu and Yiqiang Q. Zhao},
  doi          = {10.1137/22M1489861},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {3},
  pages        = {1122-1145},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Matrix-analytic methods for solving poisson’s equation with applications to markov chains of GI/G/1-type},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-dual polyhedral cones and their slack matrices.
<em>SIMAX</em>, <em>44</em>(3), 1096–1121. (<a
href="https://doi.org/10.1137/22M1519869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We analyze self-dual polyhedral cones and prove several properties about their slack matrices. In particular, we show that self-duality is equivalent to the existence of a positive semidefinite (PSD) slack. Beyond that, we show that if the underlying cone is irreducible, then the corresponding PSD slacks are not only doubly nonnegative matrices (DNN) but are extreme rays of the cone of DNN matrices, which correspond to a family of extreme rays not previously described. More surprisingly, we show that, unless the cone is simplicial, PSD slacks not only fail to be completely positive matrices but they also lie outside the cone of completely positive semidefinite matrices. Finally, we show how one can use semidefinite programming to probe the existence of self-dual cones with given combinatorics. Our results are given for polyhedral cones but we also discuss some consequences for negatively self-polar polytopes.},
  archive      = {J_SIMAX},
  author       = {João Gouveia and Bruno F. Lourenço},
  doi          = {10.1137/22M1519869},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {3},
  pages        = {1096-1121},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Self-dual polyhedral cones and their slack matrices},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Randomized sketching for krylov approximations of
large-scale matrix functions. <em>SIMAX</em>, <em>44</em>(3), 1073–1095.
(<a href="https://doi.org/10.1137/22M1518062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The computation of , the action of a matrix function on a vector, is a task arising in many areas of scientific computing. In many applications, the matrix is sparse but so large that only a rather small number of Krylov basis vectors can be stored. Here we discuss a new approach to overcome this limitation by randomized sketching combined with an integral representation of . Two different approximation methods are introduced, one based on sketched FOM and another based on sketched GMRES. The convergence of the latter method is analyzed for Stieltjes functions of positive real matrices. We also derive a closed-form expression for the sketched FOM approximant and bound its distance to the full FOM approximant. Numerical experiments demonstrate the potential of the presented sketching approaches.},
  archive      = {J_SIMAX},
  author       = {Stefan Güttel and Marcel Schweitzer},
  doi          = {10.1137/22M1518062},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {3},
  pages        = {1073-1095},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Randomized sketching for krylov approximations of large-scale matrix functions},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A higher-order generalized singular value decomposition for
rank-deficient matrices. <em>SIMAX</em>, <em>44</em>(3), 1047–1072. (<a
href="https://doi.org/10.1137/21M1443881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The higher-order generalized singular value decomposition (HO-GSVD) is a matrix factorization technique that extends the GSVD to data matrices and can be used to identify common subspaces that are shared across multiple large-scale datasets with different row dimensions. The standard HO-GSVD factors matrices as but requires that each of the matrices has full column rank. We propose a modification of the HO-GSVD that extends its applicability to rank-deficient data matrices . If the matrix of stacked has full rank, we show that the properties of the original HO-GSVD extend to our approach. We extend the notion of common subspaces to isolated subspaces, which identify features that are unique to one . We also extend our results to the higher-order cosine-sine decomposition (HO-CSD), which is closely related to the HO-GSVD. Our extension of the standard HO-GSVD allows its application to matrices with or rank , such as those encountered in bioinformatics, neuroscience, control theory, and classification problems.},
  archive      = {J_SIMAX},
  author       = {Idris Kempf and Paul J. Goulart and Stephen R. Duncan},
  doi          = {10.1137/21M1443881},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {3},
  pages        = {1047-1072},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {A higher-order generalized singular value decomposition for rank-deficient matrices},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spectrum consistent coarsening approximates edge weights.
<em>SIMAX</em>, <em>44</em>(3), 1032–1046. (<a
href="https://doi.org/10.1137/21M1458119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Finding coarse representations of large graphs which preserve particular features is important in many fields of study, including clustering, numerical approximation, and the creation of reduced order models. Likewise, preserving spectral properties of the original graph during coarsening is also of particular interest for several domains of study. Our contributions are twofold. First, we generalize previous work on coarsening graphs while preserving eigenvalues of the normalized Laplacian by merging nodes with similar adjacencies, and we show that a similar analysis can be done in the case of the combinatorial Laplacian. We additionally show that when the lifted graph of a coarsening spectrally approximates the original graph, the difference between the edge weights of the graph and the edge weights of the lift depend only on the quality of spectral approximation and the strength of connectivity of the graph. It is then shown that in the case of weighted regular graphs the difference between the edge weights of the graph and the edge weights of the lift are bounded purely by the quality of spectral approximation.},
  archive      = {J_SIMAX},
  author       = {Christopher Brissette and Andy Huang and George Slota},
  doi          = {10.1137/21M1458119},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {3},
  pages        = {1032-1046},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Spectrum consistent coarsening approximates edge weights},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dominant z-eigenpairs of tensor kronecker products decouple.
<em>SIMAX</em>, <em>44</em>(3), 1006–1031. (<a
href="https://doi.org/10.1137/22M1502008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Tensor Kronecker products, the natural generalization of the matrix Kronecker product, are independently emerging in multiple research communities. Like their matrix counterpart, the tensor generalization gives structure for implicit multiplication and factorization theorems. We present a theorem that decouples the dominant eigenvectors of tensor Kronecker products, which is a rare generalization from matrix theory to tensor eigenvectors. This theorem implies low-rank structure ought to be present in the iterates of tensor power methods on Kronecker products. We investigate low-rank structure in the network alignment algorithm TAME, a power method heuristic. Using the low-rank structure directly or via a new heuristic embedding approach, we produce new algorithms which are faster while improving or maintaining accuracy, and which scale to problems that cannot be realistically handled with existing techniques.},
  archive      = {J_SIMAX},
  author       = {Charles Colley and Huda Nassar and David F. Gleich},
  doi          = {10.1137/22M1502008},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {3},
  pages        = {1006-1031},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Dominant Z-eigenpairs of tensor kronecker products decouple},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A predictor-corrector strategy for adaptivity in dynamical
low-rank approximations. <em>SIMAX</em>, <em>44</em>(3), 971–1005. (<a
href="https://doi.org/10.1137/22M1519493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we present a predictor-corrector strategy for constructing rank-adaptive, dynamical low-rank approximations (DLRAs) of matrix-valued ODE systems. The strategy is a compromise between (i) low-rank step-truncation approaches that alternately evolve and compress solutions and (ii) strict DLRA approaches that augment the low-rank manifold using subspaces generated locally in time by the DLRA integrator. The strategy is based on an analysis of the error between a forward temporal update into the ambient full-rank space, which is typically computed in a step-truncation approach before recompressing, and the standard DLRA update, which is forced to live in a low-rank manifold. We use this error, without requiring its full-rank representation, to correct the DLRA solution. A key ingredient for maintaining a low-rank representation of the error is a randomized SVD, which introduces some degree of stochastic variability into the implementation. The strategy is formulated and implemented in the context of discontinuous Galerkin spatial discretizations of PDEs and applied to several versions of DLRA methods found in the literature as well as a new variant. Numerical experiments comparing the predictor-corrector strategy to other methods demonstrate robustness to overcome shortcomings of step truncation or strict DLRA approaches: The former may require more memory than is strictly needed, while the latter may miss transients solution features that cannot be recovered. The effect of randomization, tolerances, and other implementation parameters is also explored.},
  archive      = {J_SIMAX},
  author       = {Cory D. Hauck and Stefan Schnake},
  doi          = {10.1137/22M1519493},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {3},
  pages        = {971-1005},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {A predictor-corrector strategy for adaptivity in dynamical low-rank approximations},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Growth factors of random butterfly matrices and the
stability of avoiding pivoting. <em>SIMAX</em>, <em>44</em>(3), 945–970.
(<a href="https://doi.org/10.1137/22M148762X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Random butterfly matrices were introduced by Parker in 1995 to remove the need for pivoting when using Gaussian elimination. The growing applications of butterfly matrices have often eclipsed the mathematical understanding of how or why butterfly matrices are able to accomplish these given tasks. To help begin to close this gap using theoretical and numerical approaches, we explore the impact on the growth factor of preconditioning a linear system by butterfly matrices. These results are compared to other common methods found in randomized numerical linear algebra. In these experiments, we show that preconditioning using butterfly matrices has a more significant dampening impact on large growth factors than other common preconditioners and a smaller increase to minimal growth factor systems. Moreover, we are able to determine the full distribution of the growth factors for a subclass of random butterfly matrices. Previous results by Trefethen and Schreiber relating to the distribution of random growth factors were limited to empirical estimates of the first moment for Ginibre matrices.},
  archive      = {J_SIMAX},
  author       = {John Peca-Medlin and Thomas Trogdon},
  doi          = {10.1137/22M148762X},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {3},
  pages        = {945-970},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Growth factors of random butterfly matrices and the stability of avoiding pivoting},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Extreme ratio between spectral and frobenius norms of
nonnegative tensors. <em>SIMAX</em>, <em>44</em>(2), 919–944. (<a
href="https://doi.org/10.1137/22M1502951">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. One of the fundamental problems in multilinear algebra, the minimum ratio between the spectral and Frobenius norms of tensors, has received considerable attention in recent years. While most values are unknown for real and complex tensors, the asymptotic order of magnitude and tight lower bounds have been established. However, little is known about nonnegative tensors. In this paper, we present an almost complete picture of the ratio for nonnegative tensors. In particular, we provide a tight lower bound that can be achieved by a wide class of nonnegative tensors under a simple necessary and sufficient condition, which helps to characterize the extreme tensors and obtain results such as the asymptotic order of magnitude. We show that the ratio for symmetric tensors is no more than that for general tensors multiplied by a constant depending only on the order of tensors, hence determining the asymptotic order of magnitude for real, complex, and nonnegative symmetric tensors. We also find that the ratio is in general different from the minimum ratio between the Frobenius and nuclear norms for nonnegative tensors, a sharp contrast to the case for real tensors and complex tensors.},
  archive      = {J_SIMAX},
  author       = {Shengyu Cao and Simai He and Zhening Li and Zhen Wang},
  doi          = {10.1137/22M1502951},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {2},
  pages        = {919-944},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Extreme ratio between spectral and frobenius norms of nonnegative tensors},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Randomized low-rank approximation of monotone matrix
functions. <em>SIMAX</em>, <em>44</em>(2), 894–918. (<a
href="https://doi.org/10.1137/22M1523923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This work is concerned with computing low-rank approximations of a matrix function for a large symmetric positive semidefinite matrix , a task that arises in, e.g., statistical learning and inverse problems. The application of popular randomized methods, such as the randomized singular value decomposition or the Nyström approximation, to requires multiplying with a few random vectors. A significant disadvantage of such an approach, matrix-vector products with are considerably more expensive than matrix-vector products with , even when carried out only approximately via, e.g., the Lanczos method. In this work, we present and analyze funNyström, a simple and inexpensive method that constructs a low-rank approximation of directly from a Nyström approximation of , completely bypassing the need for matrix-vector products with . It is sensible to use funNyström whenever is monotone and satisfies . Under the stronger assumption that is operator monotone, which includes the matrix square root and the matrix logarithm , we derive probabilistic bounds for the error in the Frobenius, nuclear, and operator norms. These bounds confirm the numerical observation that funNyström tends to return an approximation that compares well with the best low-rank approximation of . Furthermore, compared to existing methods, funNyström requires significantly fewer matrix-vector products with to obtain a low-rank approximation of , without sacrificing accuracy or reliability. Our method is also of interest when estimating quantities associated with , such as the trace or the diagonal entries of . In particular, we propose and analyze funNyström++, a combination of funNyström with the recently developed Hutch++ method for trace estimation.},
  archive      = {J_SIMAX},
  author       = {David Persson and Daniel Kressner},
  doi          = {10.1137/22M1523923},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {2},
  pages        = {894-918},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Randomized low-rank approximation of monotone matrix functions},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On best low rank approximation of positive definite tensors.
<em>SIMAX</em>, <em>44</em>(2), 867–893. (<a
href="https://doi.org/10.1137/22M1494178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Tensors, or multi-indexed arrays, play an important role in machine learning and signal processing. These higher-order generalizations of matrices allow for preservation of higher-order structure in data, and low rank decompositions of tensors allow for recovery of underlying information. In many cases, the underlying tensor of interest is positive (semi)definite, i.e., the homogeneous polynomial associated to the tensor has nonnegative evaluation on all inputs. An archetypal problem is that one has a noisy measurement of some low rank signal tensor of interest. This measurement itself does not have low rank, so one must compute a best low rank approximation of the measured tensor to recover component information. As it turns out, the set of tensors of rank less than or equal to is, in general, not closed when , and, as a consequence, best low rank approximations can fail to exist. In the case when a best low rank approximation does not exist, near optimal low rank approximations suffer numerical issues and cannot be used to reliably approximate underlying component information. As a consequence, existence guarantees for best low rank tensor approximations are of great practical and theoretical interest. This article develops deterministic guarantees for the existence of best low rank approximations of tensors which are positive semidefinite. In particular, we show that the set of low rank positive semidefinite tensors is relatively closed as a subset of the set of positive semidefinite tensors. We use this fact to give a deterministic bound which may be used to guarantee the existence of a best low rank approximation of a noisy low rank positive semidefinite tensor. Furthermore, we show that this condition guarantees uniqueness of the canonical polyadic decomposition for best low rank approximations. In addition, for order three tensors, we prove that our bound is sharp and that it can be computed using semidefinite programming. The main results of this article are illustrated through numerical experiments, which show that our bound is highly predictive of numerical issues when attempting to recover underlying component information from a noisy low rank positive semidefinite tensor.},
  archive      = {J_SIMAX},
  author       = {Eric Evert and Lieven De Lathauwer},
  doi          = {10.1137/22M1494178},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {2},
  pages        = {867-893},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {On best low rank approximation of positive definite tensors},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Euclidean representation of low-rank matrices and its
geometric properties. <em>SIMAX</em>, <em>44</em>(2), 822–866. (<a
href="https://doi.org/10.1137/22M1489125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we propose a novel and user-friendly Euclidean representation framework for low-rank matrices. Correspondingly, we establish a collection of technical and theoretical tools for analyzing the intrinsic perturbation and geometry of low-rank matrices in which the underlying referential matrix and the perturbed matrix both live on the same low-rank matrix manifold. It turns out that the Frobenius distance between low-rank matrices is locally equivalent to the Euclidean distance between the corresponding representing vectors. Our analyses also show that, locally around the referential matrix, the sine-theta distance between subspaces is equivalent to the Euclidean distance between two appropriately selected orthonormal basis, circumventing the orthogonal Procrustes analysis. We further establish the regularity of the proposed Euclidean representation function by showing that it has a nondegenerate Fréchet derivative, thereby establishing the manifold structure over the collection of all low-rank matrices. Two applications of the proposed framework are showcased, namely, constructing the Riemannian structure on the Grassmannian using the Cayley parameterization and the multiplicative perturbation analysis of low-rank matrices.},
  archive      = {J_SIMAX},
  author       = {Fangzheng Xie},
  doi          = {10.1137/22M1489125},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {2},
  pages        = {822-866},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Euclidean representation of low-rank matrices and its geometric properties},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A spectral method for joint community detection and
orthogonal group synchronization. <em>SIMAX</em>, <em>44</em>(2),
781–821. (<a href="https://doi.org/10.1137/21M1467845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Community detection and orthogonal group synchronization are both fundamental problems with a variety of important applications in science and engineering. In this work, we consider the joint problem of community detection and orthogonal group synchronization which aims to recover the communities and perform synchronization simultaneously. To this end, we propose a simple algorithm that consists of a spectral decomposition step followed by a blockwise column pivoted QR factorization. The proposed algorithm is efficient and scales linearly with the number of edges in the graph. We also leverage the recently developed “leave-one-out” technique to establish a near-optimal guarantee for exact recovery of the cluster memberships and stable recovery of the orthogonal transforms. Numerical experiments demonstrate the efficiency and efficacy of our algorithm and confirm our theoretical characterization of it.},
  archive      = {J_SIMAX},
  author       = {Yifeng Fan and Yuehaw Khoo and Zhizhen Zhao},
  doi          = {10.1137/21M1467845},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {2},
  pages        = {781-821},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {A spectral method for joint community detection and orthogonal group synchronization},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Root-max problems, hybrid expansion-contraction, and
quadratically convergent optimization of passive systems.
<em>SIMAX</em>, <em>44</em>(2), 753–780. (<a
href="https://doi.org/10.1137/21M1450367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present quadratically convergent algorithms to compute the extremal value of a real parameter for which a given rational transfer function of a linear time-invariant system is passive. This problem is formulated for both continuous-time and discrete-time systems and is linked to the problem of finding a realization of a rational transfer function such that its passivity radius is maximized. Our new methods make use of a generalization of the hybrid expansion-contraction algorithm, which we have extended to the setting of what we call root-max problems.},
  archive      = {J_SIMAX},
  author       = {Tim Mitchell and Paul Van Dooren},
  doi          = {10.1137/21M1450367},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {2},
  pages        = {753-780},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Root-max problems, hybrid expansion-contraction, and quadratically convergent optimization of passive systems},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Randomized nyström preconditioning. <em>SIMAX</em>,
<em>44</em>(2), 718–752. (<a
href="https://doi.org/10.1137/21M1466244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper introduces the Nyström preconditioned conjugate gradient (PCG) algorithm for solving a symmetric positive-definite linear system. The algorithm applies the randomized Nyström method to form a low-rank approximation of the matrix, which leads to an efficient preconditioner that can be deployed with the conjugate gradient algorithm. Theoretical analysis shows that the preconditioned system has constant condition number as soon as the rank of the approximation is comparable with the number of effective degrees of freedom in the matrix. The paper also develops adaptive methods that provably achieve similar performance without knowledge of the effective dimension. Numerical tests show that Nyström PCG can rapidly solve large linear systems that arise in data analysis problems, and it surpasses several competing methods from the literature.},
  archive      = {J_SIMAX},
  author       = {Zachary Frangella and Joel A. Tropp and Madeleine Udell},
  doi          = {10.1137/21M1466244},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {2},
  pages        = {718-752},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Randomized nyström preconditioning},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Krylov subspace restarting for matrix laplace transforms.
<em>SIMAX</em>, <em>44</em>(2), 693–717. (<a
href="https://doi.org/10.1137/22M1499674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A common way to approximate —the action of a matrix function on a vector—is to use the Arnoldi approximation. Since a new vector needs to be generated and stored in every iteration, one is often forced to rely on restart algorithms which are either not efficient, not stable, or applicable only to restricted classes of functions. We present a new representation of the error of the Arnoldi iterates if the function is given as a Laplace transform. Based on this representation we build an efficient and stable restart algorithm. In doing so we extend earlier work for the class of Stieltjes functions which are special Laplace transforms. We report several numerical experiments including comparisons with the restart method for Stieltjes functions.},
  archive      = {J_SIMAX},
  author       = {A. Frommer and K. Kahl and M. Schweitzer and M. Tsolakis},
  doi          = {10.1137/22M1499674},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {2},
  pages        = {693-717},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Krylov subspace restarting for matrix laplace transforms},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Low-memory krylov subspace methods for optimal rational
matrix function approximation. <em>SIMAX</em>, <em>44</em>(2), 670–692.
(<a href="https://doi.org/10.1137/22M1479853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We describe a Lanczos-based algorithm for approximating the product of a rational matrix function with a vector. This algorithm, which we call the Lanczos method for optimal rational matrix function approximation (Lanczos-OR), returns the optimal approximation from a given Krylov subspace in a norm depending on the rational function’s denominator, and it can be computed using the information from a slightly larger Krylov subspace. We also provide a low-memory implementation which only requires storing a number of vectors proportional to the denominator degree of the rational function. Finally, we show that Lanczos-OR can be used to derive algorithms for computing other matrix functions, including the matrix sign function and quadrature-based rational function approximations. In many cases, it improves on the approximation quality of prior approaches, including the standard Lanczos method, with little additional computational overhead.},
  archive      = {J_SIMAX},
  author       = {Tyler Chen and Anne Greenbaum and Cameron Musco and Christopher Musco},
  doi          = {10.1137/22M1479853},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {2},
  pages        = {670-692},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Low-memory krylov subspace methods for optimal rational matrix function approximation},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An edge centrality measure based on the kemeny constant.
<em>SIMAX</em>, <em>44</em>(2), 648–669. (<a
href="https://doi.org/10.1137/22M1486728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A new measure of the centrality of an edge in an undirected graph is introduced. It is based on the variation of the Kemeny constant of the graph after removing the edge . The new measure is designed to satisfy certain monotonicity and positivity properties, and hence using it one can avoid the Braess paradox, i.e., the phenomenon in which removing an edge can increase the connectivity of a network rather than reduce it. A numerical method for computing is introduced, and a regularization technique is designed in order to deal with cut-edges and disconnected graphs. Numerical experiments performed both on artificial examples and on real road networks show that this measure is particularly effective in revealing bottleneck roads whose removal would greatly reduce the connectivity of the network.},
  archive      = {J_SIMAX},
  author       = {Diego Altafini and Dario A. Bini and Valerio Cutini and Beatrice Meini and Federico Poloni},
  doi          = {10.1137/22M1486728},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {2},
  pages        = {648-669},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {An edge centrality measure based on the kemeny constant},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pseudoinverses of signed laplacian matrices. <em>SIMAX</em>,
<em>44</em>(2), 622–647. (<a
href="https://doi.org/10.1137/22M1493392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Even for nonnegative graphs, the pseudoinverse of a Laplacian matrix is not an “ordinary” (i.e., unsigned) Laplacian matrix but rather a signed Laplacian. In this paper, we show that the property of eventual positivity provides a natural embedding class for both signed and unsigned Laplacians, class which is closed with respect to pseudoinversion as well as to stability. Such a class can deal with both undirected and directed graphs. In particular, for digraphs, when dealing with pseudoinverse-related quantities such as effective resistance, two possible solutions naturally emerge, differing in the order in which the operations of pseudoinversion and of symmetrization are performed. Both lead to an effective resistance which is a Euclidean metric on the graph.},
  archive      = {J_SIMAX},
  author       = {Angela Fontan and Claudio Altafini},
  doi          = {10.1137/22M1493392},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {2},
  pages        = {622-647},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Pseudoinverses of signed laplacian matrices},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Convergence of gradient-based block coordinate descent
algorithms for nonorthogonal joint approximate diagonalization of
matrices. <em>SIMAX</em>, <em>44</em>(2), 592–621. (<a
href="https://doi.org/10.1137/21M1456972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a gradient-based block coordinate descent (BCD-G) framework to solve the joint approximate diagonalization of matrices defined on the product of the complex Stiefel manifold and the special linear group. Instead of the cyclic fashion, we choose a block optimization based on the Riemannian gradient. To update the first block variable in the complex Stiefel manifold, we use the well-known line search descent method. To update the second block variable in the special linear group, based on four different kinds of elementary transformations, we construct three classes, GLU, GQU and GU, and then get three BCD-G algorithms, BCD-GLU, BCD-GQU and BCD-GU. We establish the global convergence and weak convergence of these three algorithms using the Łojasiewicz gradient inequality under the assumption that the iterates are bounded. We also propose a gradient-based Jacobi-type framework to solve the joint approximate diagonalization of matrices defined on the special linear group. As in the BCD-G case, using the GLU and GQU classes of elementary transformations, we focus on the Jacobi-GLU and Jacobi-GQU algorithms and establish their global convergence and weak convergence as well. All the algorithms and convergence results described in this paper also apply to the real case.},
  archive      = {J_SIMAX},
  author       = {Jianze Li and Konstantin Usevich and Pierre Comon},
  doi          = {10.1137/21M1456972},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {2},
  pages        = {592-621},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Convergence of gradient-based block coordinate descent algorithms for nonorthogonal joint approximate diagonalization of matrices},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved analysis and unified perspective on
deterministic and randomized low-rank matrix approximation.
<em>SIMAX</em>, <em>44</em>(2), 559–591. (<a
href="https://doi.org/10.1137/21M1391316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We introduce a Generalized LU Factorization (GLU) for low-rank matrix approximation. We relate this to past approaches and extensively analyze its approximation properties. The established deterministic guarantees are combined with sketching ensembles satisfying Johnson–Lindenstrauss properties to present complete bounds. Particularly good performance is shown for the subsampled randomized Hadamard transform (SRHT) ensemble. Moreover, the factorization is shown to unify and generalize many past algorithms, sometimes providing strictly better approximations. It also helps to explain the effect of sketching on the growth factor during Gaussian elimination.},
  archive      = {J_SIMAX},
  author       = {James Demmel and Laura Grigori and Alexander Rusciano},
  doi          = {10.1137/21M1391316},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {2},
  pages        = {559-591},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {An improved analysis and unified perspective on deterministic and randomized low-rank matrix approximation},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finding the least element of a nonnegative solution set of a
class of polynomial inequalities. <em>SIMAX</em>, <em>44</em>(2),
530–558. (<a href="https://doi.org/10.1137/22M1476733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we consider the least element problem of a nonnegative solution set of a system of inequalities defined by a homogeneous polynomial mapping and a vector. In the set under consideration, the homogeneous polynomial mapping is defined by a tensor. When the tensor involved is square, the set under consideration is just the feasible region of the tensor complementarity problem (TCP). We first introduce the concept of the generalized -tensor, which is a natural generalization of the -tensor. Then, under the assumption that the considered set is nonempty and the tensor involved is a generalized -tensor, we propose an iterative method for finding the least element of the considered set. Specifically, by recognizing the position indices of positive components in the least element continuously, we solve a series of lower-dimensional system of tensor equations corresponding to these indices and prove that the least element of the set can be obtained within finite step iterations. When the tensor involved is square, the least element obtained is also a solution of the TCP. Compared with the existing methods for finding the least-element solution of the TCP with a -tensor, our method does not require any additional assumptions and has lower computational cost. Preliminary numerical experiments show that the proposed method is effective.},
  archive      = {J_SIMAX},
  author       = {Zheng-Hai Huang and Yu-Fan Li and Xinhe Miao},
  doi          = {10.1137/22M1476733},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {2},
  pages        = {530-558},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Finding the least element of a nonnegative solution set of a class of polynomial inequalities},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spurious valleys, NP-hardness, and tractability of sparse
matrix factorization with fixed support. <em>SIMAX</em>, <em>44</em>(2),
503–529. (<a href="https://doi.org/10.1137/22M1496657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The problem of approximating a dense matrix by a product of sparse factors is a fundamental problem for many signal processing and machine learning tasks. It can be decomposed into two subproblems: finding the position of the nonzero coefficients in the sparse factors, and determining their values. While the first step is usually seen as the most challenging one due to its combinatorial nature, this paper focuses on the second step, referred to as sparse matrix approximation with fixed support. First, we show its NP-hardness, while also presenting a nontrivial family of supports making the problem practically tractable with a dedicated algorithm. Then we investigate the landscape of its natural optimization formulation, proving the absence of spurious local valleys and spurious local minima, whose presence could prevent local optimization methods to achieve global optimality. The advantages of the proposed algorithm over state-of-the-art first-order optimization methods are discussed.},
  archive      = {J_SIMAX},
  author       = {Quoc-Tung Le and Elisa Riccietti and Remi Gribonval},
  doi          = {10.1137/22M1496657},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {2},
  pages        = {503-529},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Spurious valleys, NP-hardness, and tractability of sparse matrix factorization with fixed support},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Householder orthogonalization with a nonstandard inner
product. <em>SIMAX</em>, <em>44</em>(2), 481–502. (<a
href="https://doi.org/10.1137/21M1414814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Householder orthogonalization plays an important role in numerical linear algebra. It attains perfect orthogonality regardless of the conditioning of the input. However, in the context of a nonstandard inner product, it becomes difficult to apply Householder orthogonalization, partly due to the lack of an initial orthonormal basis. We propose strategies to overcome this obstacle and discuss algorithms and variants of Householder orthogonalization with a nonstandard inner product. Theoretical analysis and numerical experiments demonstrate that our approach is numerically stable under mild assumptions.},
  archive      = {J_SIMAX},
  author       = {Meiyue Shao},
  doi          = {10.1137/21M1414814},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {2},
  pages        = {481-502},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Householder orthogonalization with a nonstandard inner product},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fifty three matrix factorizations: A systematic approach.
<em>SIMAX</em>, <em>44</em>(2), 415–480. (<a
href="https://doi.org/10.1137/21M1416035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The success of matrix factorizations such as the singular value decomposition (SVD) has motivated the search for even more factorizations. We catalog 53 matrix factorizations, most of which we believe to be new. Our systematic approach, inspired by the generalized Cartan decomposition of the Lie theory, also encompasses known factorizations such as the SVD, the symmetric eigendecomposition, the CS decomposition, the hyperbolic SVD, structured SVDs, the Takagi factorization, and others thereby covering familiar matrix factorizations, as well as ones that were waiting to be discovered. We suggest that the Lie theory has one way or another been lurking hidden in the foundations of the very successful field of matrix computations with applications routinely used in so many areas of computation. In this paper, we investigate consequences of the Cartan decomposition and the little known generalized Cartan decomposition for matrix factorizations. We believe that these factorizations once properly identified can lead to further work on algorithmic computations and applications.},
  archive      = {J_SIMAX},
  author       = {Alan Edelman and Sungwoo Jeong},
  doi          = {10.1137/21M1416035},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {2},
  pages        = {415-480},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Fifty three matrix factorizations: A systematic approach},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nearly optimal block-jacobi preconditioning. <em>SIMAX</em>,
<em>44</em>(1), 408–413. (<a
href="https://doi.org/10.1137/22M1504901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The goal of Jacobi preconditioning of a symmetric positive definite matrix by a diagonal matrix is to choose to minimize the condition number . In 1969, van der Sluis proved that choosing so that the diagonal entries of are all ones reduces to within a factor of the minimum possible, where the factor depends on both the dimension and the norms used to define the condition number. We extend this result in two ways to block-Jacobi preconditioning, where is a block-diagonal matrix with blocks of given sizes, and we consider instead of to maintain the symmetric positive definite (spd) property. First, we extend van der Sluis’s original bound to include block-Jacobi. Second, we define a new norm in which choosing so that the corresponding diagonal blocks of are identity matrices minimizes the condition number. We use this to show that the condition number in the 2-norm of this optimally scaled is at least as large as the condition number in the new norm, and at most a factor larger, where is the number of diagonal blocks. We give an example where the optimal 2-norm condition number nearly attains this new upper bound, which for this example is tighter than van der Sluis’s bound by a factor equal to the matrix dimension. Finally, all these results generalize to the case of one-sided scaling of a full row-rank matrix .},
  archive      = {J_SIMAX},
  author       = {James Demmel},
  doi          = {10.1137/22M1504901},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {1},
  pages        = {408-413},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Nearly optimal block-jacobi preconditioning},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The joint bidiagonalization method for large GSVD
computations in finite precision. <em>SIMAX</em>, <em>44</em>(1),
382–407. (<a href="https://doi.org/10.1137/22M1483608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The joint bidiagonalization (JBD) method has been used to compute some extreme generalized singular values and vectors of a large regular matrix pair . We make a numerical analysis of the underlying JBD process and establish relationships between it and two mathematically equivalent Lanczos bidiagonalizations in finite precision. Based on the results of numerical analysis, we investigate the convergence of the approximate generalized singular values and vectors of . The results show that, under some mild conditions, the semiorthogonality of Lanczos-type vectors suffices to deliver approximate generalized singular values with the same accuracy as the full orthogonality does, meaning that it is only necessary to seek for efficient semiorthogonalization strategies for the JBD process. We establish a sharp bound for the residual norm of an approximate generalized singular value and corresponding approximate right generalized singular vectors, which can reliably estimate the residual norm without explicitly computing the approximate right generalized singular vectors before the convergence occurs.},
  archive      = {J_SIMAX},
  author       = {Zhongxiao Jia and Haibo Li},
  doi          = {10.1137/22M1483608},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {1},
  pages        = {382-407},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {The joint bidiagonalization method for large GSVD computations in finite precision},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analysis of the truncated conjugate gradient method for
linear matrix equations. <em>SIMAX</em>, <em>44</em>(1), 359–381. (<a
href="https://doi.org/10.1137/22M147880X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The matrix-oriented version of the conjugate gradient (CG) method can be used to approximate the solution to certain linear matrix equations. To limit memory consumption, low-rank reduction of the factored iterates is often employed, possibly leading to disruption of the regular convergence behavior. We analyze the properties of the method in the matrix regime and identify the quantities that are responsible for early termination, usually stagnation, when truncation is in effect. Moreover, we illustrate relations between CG and a projection technique directly applied to the same matrix equation.},
  archive      = {J_SIMAX},
  author       = {Valeria Simoncini and Yue Hao},
  doi          = {10.1137/22M147880X},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {1},
  pages        = {359-381},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Analysis of the truncated conjugate gradient method for linear matrix equations},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A structure preserving shift-invert infinite arnoldi
algorithm for a class of delay eigenvalue problems with hamiltonian
symmetry. <em>SIMAX</em>, <em>44</em>(1), 331–358. (<a
href="https://doi.org/10.1137/21M1452706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This work considers a class of delay eigenvalue problems that admit a spectrum similar to that of a Hamiltonian matrix, in the sense that the spectrum is symmetric with respect to both the real and imaginary axes. We propose a method to iteratively approximate the eigenvalues closest to a given purely real or imaginary shift, while preserving the symmetries of the spectrum. To this end, our method exploits the equivalence between the considered delay eigenvalue problem and the eigenvalue problem associated with a linear but infinite-dimensional operator. To compute the eigenvalues closest to the given shift, we apply a specifically chosen shift-invert transformation to this linear operator and compute the eigenvalues with the largest modulus of the new shifted and inverted operator using an (infinite) Arnoldi procedure. The advantage of the chosen shift-invert transformation is that the spectrum of the transformed operator has a “real skew-Hamiltonian”-like structure. Furthermore, it is proven that the Krylov subspace constructed by applying this operator satisfies an orthogonality property in terms of a specifically chosen bilinear form. By taking this property into account during the orthogonalization process, it is ensured that, even in the presence of rounding errors, the obtained approximation for, e.g., a simple, purely imaginary eigenvalue is simple and purely imaginary. The presented work can thus be seen as an extension of [V. Mehrmann and D. Watkins, SIAM J. Sci. Comput., 22 (2001), pp. 1905–1925] to the considered class of delay eigenvalue problems. Although the presented method is initially defined on function spaces, it can be implemented using finite-dimensional linear algebra operations. The performance of the resulting numerical algorithm is verified for two example problems: the first example illustrates the advantage of the proposed approach in preserving purely imaginary eigenvalues when working in finite precision, while the second one demonstrates its applicability to a large scale problem.},
  archive      = {J_SIMAX},
  author       = {Pieter Appeltans and Wim Michiels},
  doi          = {10.1137/21M1452706},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {1},
  pages        = {331-358},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {A structure preserving shift-invert infinite arnoldi algorithm for a class of delay eigenvalue problems with hamiltonian symmetry},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An optimal scheduled learning rate for a randomized kaczmarz
algorithm. <em>SIMAX</em>, <em>44</em>(1), 312–330. (<a
href="https://doi.org/10.1137/22M148803X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study how the learning rate affects the performance of a relaxed randomized Kaczmarz algorithm for solving , where is a consistent linear system and has independent mean zero random entries. We derive a learning rate schedule which optimizes a bound on the expected error that is sharp in certain cases; in contrast to the exponential convergence of the standard randomized Kaczmarz algorithm, our optimized bound involves the reciprocal of the Lambert- function of an exponential.},
  archive      = {J_SIMAX},
  author       = {Nicholas F. Marshall and Oscar Mickelin},
  doi          = {10.1137/22M148803X},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {1},
  pages        = {312-330},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {An optimal scheduled learning rate for a randomized kaczmarz algorithm},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GPMR: An iterative method for unsymmetric partitioned linear
systems. <em>SIMAX</em>, <em>44</em>(1), 293–311. (<a
href="https://doi.org/10.1137/21M1459265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We introduce an iterative method named Gpmr (general partitioned minimum residual) for solving block unsymmetric linear systems. Gpmr is based on a new process that simultaneously reduces two rectangular matrices to upper Hessenberg form and is closely related to the block-Arnoldi process. Gpmr is tantamount to Block-Gmres with two right-hand sides in which the two approximate solutions are summed at each iteration, but its storage and work per iteration are similar to those of Gmres. We compare the performance of Gpmr with Gmres on linear systems from the SuiteSparse Matrix Collection. In our experiments, Gpmr terminates significantly earlier than Gmres on a residual-based stopping condition with an improvement ranging from around 10\% up to 50\% in terms of number of iterations.},
  archive      = {J_SIMAX},
  author       = {Alexis Montoison and Dominique Orban},
  doi          = {10.1137/21M1459265},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {1},
  pages        = {293-311},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {GPMR: An iterative method for unsymmetric partitioned linear systems},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Kron reduction and effective resistance of directed graphs.
<em>SIMAX</em>, <em>44</em>(1), 270–292. (<a
href="https://doi.org/10.1137/22M1480823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In network theory, the concept of effective resistance is a distance measure on a graph that relates the global network properties to individual connections between nodes. In addition, the Kron reduction method is a standard tool for reducing or eliminating the desired nodes, which preserves the interconnection structure and the effective resistance of the original graph. Although these two graph-theoretic concepts stem from the electric network on an undirected graph, they also have a number of applications throughout a wide variety of other fields. In this study, we propose a generalization of a Kron reduction for directed graphs. Furthermore, we prove that this reduction method preserves the structure of the original graphs, such as the strong connectivity or weight balance. In addition, we generalize the effective resistance to a directed graph using Markov chain theory, which is invariant under a Kron reduction. Although the effective resistance of our proposal is asymmetric, we prove that it induces two novel graph metrics in general strongly connected directed graphs. In particular, the effective resistance captures the commute and covering times for strongly connected weight balanced directed graphs. Finally, we compare our method with existing approaches and relate the hitting probability metrics and effective resistance in a stochastic case. In addition, we show that the effective resistance in a doubly stochastic case is the same as the resistance distance in an ergodic Markov chain.},
  archive      = {J_SIMAX},
  author       = {Tomohiro Sugiyama and Kazuhiro Sato},
  doi          = {10.1137/22M1480823},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {1},
  pages        = {270-292},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Kron reduction and effective resistance of directed graphs},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Monte carlo methods for estimating the diagonal of a real
symmetric matrix. <em>SIMAX</em>, <em>44</em>(1), 240–269. (<a
href="https://doi.org/10.1137/22M1476277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. For real symmetric matrices that are accessible only through matrix vector products, we present Monte Carlo estimators for computing the diagonal elements. Our probabilistic bounds for normwise absolute and relative errors apply to Monte Carlo estimators based on random Rademacher, sparse Rademacher, and normalized and unnormalized Gaussian vectors and to vectors with bounded fourth moments. The novel use of matrix concentration inequalities in our proofs represents a systematic model for future analyses. Our bounds mostly do not depend explicitly on the matrix dimension, target different error measures than existing work, and imply that the accuracy of the estimators increases with the diagonal dominance of the matrix. Applications to derivative-based global sensitivity metrics and node centrality measures in network science corroborate this, as do numerical experiments on synthetic test matrices. We recommend against the use in practice of sparse Rademacher vectors, which are the basis for many randomized sketching and sampling algorithms, because they tend to deliver barely a digit of accuracy even under large sampling amounts.},
  archive      = {J_SIMAX},
  author       = {Eric Hallman and Ilse C. F. Ipsen and Arvind K. Saibaba},
  doi          = {10.1137/22M1476277},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {1},
  pages        = {240-269},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Monte carlo methods for estimating the diagonal of a real symmetric matrix},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deterministic kaczmarz algorithm for solving linear
systems. <em>SIMAX</em>, <em>44</em>(1), 212–239. (<a
href="https://doi.org/10.1137/21M1463306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a new deterministic Kaczmarz algorithm for solving consistent linear systems . Basically, the algorithm replaces orthogonal projections with reflections in the original scheme of Stefan Kaczmarz. Building on this, we give a geometric description of solutions of linear systems. Suppose is , we show that the algorithm generates a series of points distributed with patterns on an -sphere centered on a solution. These points lie evenly on lower-dimensional spheres , with the property that for any , the midpoint of the centers of is exactly a solution of . With this discovery, we prove that taking the average of points on any effectively approximates a solution up to relative error , where characterizes the eigengap of the orthogonal matrix produced by the product of reflections generated by the rows of . We also analyze the connection between and , the condition number of . In the worst case , while for random matrices on average. Finally, we prove that the algorithm indeed solves the linear system , where is the lower-triangular matrix such that . The connection between this linear system and the original one is studied. The numerical tests indicate that this new Kaczmarz algorithm has comparable performance to randomized (block) Kaczmarz algorithms.},
  archive      = {J_SIMAX},
  author       = {Changpeng Shao},
  doi          = {10.1137/21M1463306},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {1},
  pages        = {212-239},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {A deterministic kaczmarz algorithm for solving linear systems},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Primitivity and hurwitz primitivity of nonnegative matrix
tuples: A unified approach. <em>SIMAX</em>, <em>44</em>(1), 196–211. (<a
href="https://doi.org/10.1137/22M1471535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. For an -tuple of nonnegative matrices , primitivity/Hurwitz primitivity means the existence of a positive product/Hurwitz product, respectively (all products are with repetitions permitted). The Hurwitz product with a Parikh vector is the sum of all products with multipliers , . Ergodicity/Hurwitz ergodicity means the existence of the corresponding product with a positive row. We give a unified proof for the Protasov–Vonyov characterization (2012) of primitive tuples of matrices without zero rows and columns and for the Protasov characterization (2013) of Hurwitz primitive tuples of matrices without zero rows. By establishing a connection with synchronizing automata, we, under the aforementioned conditions, find an -time algorithm to decide primitivity and an -time algorithm to construct a Hurwitz primitive vector of weight . We also report results on ergodic and Hurwitz ergodic matrix tuples.},
  archive      = {J_SIMAX},
  author       = {Yaokun Wu and Yinfeng Zhu},
  doi          = {10.1137/22M1471535},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {1},
  pages        = {196-211},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Primitivity and hurwitz primitivity of nonnegative matrix tuples: A unified approach},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Properties of the solution set of absolute value equations
and the related matrix classes. <em>SIMAX</em>, <em>44</em>(1), 175–195.
(<a href="https://doi.org/10.1137/22M1497018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The absolute value equations (AVE) problem is an algebraic problem of solving . So far, most of the research has focused on methods for solving AVE, but we address the problem itself by analyzing properties of AVE and the corresponding solution set. In particular, we investigate topological properties of the solution set, such as convexity, boundedness, or connectedness, or whether it consists of finitely many solutions. Further, we address problems related to the nonnegativity of solutions such as solvability or unique solvability. AVE can be formulated by means of different optimization problems, and in this regard we are interested in how the solutions of AVE are related with optima, Karush–Kuhn–Tucker points, and feasible solutions of these optimization problems. We characterize the matrix classes associated with the above mentioned properties and inspect the computational complexity of the recognition problem; some of the classes are polynomially recognizable, but some others are proved to be NP-hard. For the intractable cases, we propose various sufficient conditions. We also post new challenging problems that were raised during the investigation of the problem.},
  archive      = {J_SIMAX},
  author       = {Milan Hladík},
  doi          = {10.1137/22M1497018},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {1},
  pages        = {175-195},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Properties of the solution set of absolute value equations and the related matrix classes},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computing the square root of a low-rank perturbation of the
scaled identity matrix. <em>SIMAX</em>, <em>44</em>(1), 156–174. (<a
href="https://doi.org/10.1137/22M1471559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the problem of computing the square root of a perturbation of the scaled identity matrix, where and are matrices with . This problem arises in various applications, including computer vision and optimization methods for machine learning. We derive a new formula for the th root of that involves a weighted sum of powers of the th root of the matrix . This formula is particularly attractive for the square root, since the sum has just one term when . We also derive a new class of Newton iterations for computing the square root that exploit the low-rank structure. We test these new methods on random matrices and on positive definite matrices arising in applications. Numerical experiments show that the new approaches can yield a much smaller residual than existing alternatives and can be significantly faster when the perturbation has low rank.},
  archive      = {J_SIMAX},
  author       = {Massimiliano Fasi and Nicholas J. Higham and Xiaobo Liu},
  doi          = {10.1137/22M1471559},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {1},
  pages        = {156-174},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Computing the square root of a low-rank perturbation of the scaled identity matrix},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unimodular completions and orthogonal complements of
matrices over univariate ore extensions. <em>SIMAX</em>, <em>44</em>(1),
128–155. (<a href="https://doi.org/10.1137/22M1477027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We generalize an efficient hyper-regularity and unimodularity test from differential Ore polynomial matrices to arbitrary Ore polynomial matrices. The core of the contribution consists of algorithms for unimodular row and column completions of arbitrary univariate Ore polynomial matrices, respectively. After a possible degree reduction using noncommutative companion matrices, this is done by a systematic projection of suitable coordinates with a subsequent elimination. Based on previous work for differential Ore polynomial matrices, we remove rather restrictive conditions, which now allows for the application of this algorithm to a larger class of systems that may contain pure algebraic equations.},
  archive      = {J_SIMAX},
  author       = {Klemens Fritzsche and Klaus Röbenack},
  doi          = {10.1137/22M1477027},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {1},
  pages        = {128-155},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Unimodular completions and orthogonal complements of matrices over univariate ore extensions},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Higher-order QR with tournament pivoting for tensor
compression. <em>SIMAX</em>, <em>44</em>(1), 106–127. (<a
href="https://doi.org/10.1137/20M1387663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present in this paper a parallel algorithm that generates a low-rank approximation of a distributed tensor using QR decomposition with tournament pivoting (QRTP). The algorithm, which is a parallel variant of the higher-order singular value decomposition, generates factor matrices for a Tucker decomposition by applying QRTP to the unfolding matrices of a tensor distributed blockwise (by subtensor) on a set of processors. For each unfolding mode the algorithm logically reorganizes (unfolds) the processors so that the associated unfolding matrix has a suitable logical distribution. We also establish error bounds between a tensor and the compressed version of the tensor generated by the algorithm.},
  archive      = {J_SIMAX},
  author       = {Matthias Beaupère and David Frenkiel and Laura Grigori},
  doi          = {10.1137/20M1387663},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {1},
  pages        = {106-127},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Higher-order QR with tournament pivoting for tensor compression},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Measuring segregation via analysis on graphs.
<em>SIMAX</em>, <em>44</em>(1), 80–105. (<a
href="https://doi.org/10.1137/21M1466773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we use analysis on graphs to study quantitative measures of segregation. We focus on a classical statistic from the geography and urban sociology literature known as Moran’s , which in our language is a score associated to a real-valued function on a graph, computed with respect to a spatial weight matrix such as the adjacency matrix associated to the geographic units that tile a city. Our results characterizing the extremal behavior of illustrate the important role of the underlying graph structure, especially the degree distribution, in interpreting the score. In addition to the standard spatial weight matrices encoding unit adjacency, we consider the Laplacian and a doubly-stochastic approximation . These alternatives allow us to connect to ideas from Fourier analysis and random walks. We offer illustrations of our theoretical results with a mix of stylized synthetic examples and real geographic/demographic data.},
  archive      = {J_SIMAX},
  author       = {Moon Duchin and James M. Murphy and Thomas Weighill},
  doi          = {10.1137/21M1466773},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {1},
  pages        = {80-105},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Measuring segregation via analysis on graphs},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Krylov subspace approach to core problems within multilinear
approximation problems: A unifying framework. <em>SIMAX</em>,
<em>44</em>(1), 53–79. (<a
href="https://doi.org/10.1137/21M1462155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Error contaminated linear approximation problems appear in a large variety of applications. The presence of redundant or irrelevant data complicates their solution. It was shown that such data can be removed by the core reduction yielding a minimally dimensioned subproblem called the core problem. Direct (SVD or Tucker decomposion-based) reduction has been introduced previously for problems with matrix models and vector, or matrix, or tensor observations; and also for problems with bilinear models. For the cases of vector and matrix observations a Krylov subspace method, the generalized Golub–Kahan bidiagonalization, can be used to extract the core problem. In this paper, we first unify previously studied variants of linear approximation problems under the general framework of a multilinear approximation problem. We show how the direct core reduction can be extended to it. Then we show that the generalized Golub–Kahan bidiagonalization yields the core problem for any multilinear approximation problem. This further allows one to prove various properties of core problems, in particular, we give upper bounds on the multiplicity of singular values of reduced matrices.},
  archive      = {J_SIMAX},
  author       = {Iveta Hnětynková and Martin Plešinger and Jana Žáková},
  doi          = {10.1137/21M1462155},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {1},
  pages        = {53-79},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Krylov subspace approach to core problems within multilinear approximation problems: A unifying framework},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Partial identifiability for nonnegative matrix
factorization. <em>SIMAX</em>, <em>44</em>(1), 27–52. (<a
href="https://doi.org/10.1137/22M1507553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Given a nonnegative matrix factorization, and a factorization rank, exact nonnegative matrix factorization (exact NMF) decomposes as the product of two nonnegative matrices, and with columns, such as . A central research topic in the literature is the conditions under which such a decomposition is unique/identifiable up to trivial ambiguities. In this paper, we focus on partial identifiability, that is, the uniqueness of a subset of columns of and . We start our investigations with the data‐based uniqueness (DBU) theorem from the chemometrics literature. The DBU theorem analyzes all feasible solutions of exact NMF and relies on sparsity conditions on and . We provide a mathematically rigorous theorem of a recently published restricted version of the DBU theorem, relying only on simple sparsity and algebraic conditions: it applies to a particular solution of exact NMF (as opposed to all feasible solutions) and allows us to guarantee the partial uniqueness of a single column of or . Second, based on a geometric interpretation of the restricted DBU theorem, we obtain a new partial identifiability result. This geometric interpretation also leads us to another partial identifiability result in the case . Third, we show how partial identifiability results can be used sequentially to guarantee the identifiability of more columns of and . We illustrate these results on several examples, including one from the chemometrics literature.},
  archive      = {J_SIMAX},
  author       = {Nicolas Gillis and Róbert Rajkó},
  doi          = {10.1137/22M1507553},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {1},
  pages        = {27-52},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Partial identifiability for nonnegative matrix factorization},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Smoothing analysis of two robust multigrid methods for
elliptic optimal control problems. <em>SIMAX</em>, <em>44</em>(1), 1–26.
(<a href="https://doi.org/10.1137/22M1485759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we study and compare two multigrid relaxation schemes with coarsening by two, three, and four for solving elliptic sparse optimal control problems with control constraints and combined and cost functional. First, we perform a detailed local Fourier analysis (LFA) of a well-known collective Jacobi relaxation (CJR) scheme for the unconstrained case with only cost functional, where the optimal smoothing factors are derived. This insightful analysis reveals that the optimal relaxation parameters depend on both the mesh step size and the regularization parameter , which was not investigated in literature. Second, we propose and analyze a new mass-based Braess--Sarazin relaxation (BSR) scheme, which is proven to provide smaller smoothing factors than the CJR scheme when for a small constant . Finally, these schemes are successfully extended to control-constrained cases through the semismooth Newton method, where the corresponding Jacobian systems are treated by the proposed multigrid schemes. The nonstandard coarsening by three or four with BSR is competitive with the standard coarsening by two. Numerical examples are presented to validate our theoretical outcomes. The proposed inexact BSR (IBSR) scheme, where two preconditioned conjugate gradients (PCG) iterations are applied to solve the Schur complement system, yields a better computational efficiency than the CJR scheme in the conducted numerical comparison.},
  archive      = {J_SIMAX},
  author       = {Yunhui He and Jun Liu},
  doi          = {10.1137/22M1485759},
  journal      = {SIAM Journal on Matrix Analysis and Applications},
  number       = {1},
  pages        = {1-26},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  title        = {Smoothing analysis of two robust multigrid methods for elliptic optimal control problems},
  volume       = {44},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
