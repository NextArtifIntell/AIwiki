<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SIOPT_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="siopt---116">SIOPT - 116</h2>
<ul>
<li><details>
<summary>
(2023). Convex bi-level optimization problems with nonsmooth outer
objective function. <em>SIOPT</em>, <em>33</em>(4), 3114–3142. (<a
href="https://doi.org/10.1137/22M1533608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we propose the Bi-Sub-Gradient (Bi-SG) method, which is a generalization of the classical sub-gradient method to the setting of convex bi-level optimization problems. This is a first-order method that is very easy to implement in the sense that it requires only a computation of the associated proximal mapping or a sub-gradient of the outer nonsmooth objective function, in addition to a proximal gradient step on the inner optimization problem. We show, under very mild assumptions, that Bi-SG tackles bi-level optimization problems and achieves sublinear rates in terms of both the inner and outer objective functions. Moreover, if the outer objective function is additionally strongly convex (still could be nonsmooth), the outer rate can be improved to a linear rate. Last, we prove that the distance of the generated sequence to the set of optimal solutions of the bi-level problem converges to zero.},
  archive      = {J_SIOPT},
  author       = {Roey Merchav and Shoham Sabach},
  doi          = {10.1137/22M1533608},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3114-3142},
  shortjournal = {SIAM J. Optim.},
  title        = {Convex bi-level optimization problems with nonsmooth outer objective function},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Large-scale nonconvex optimization: Randomization, gap
estimation, and numerical resolution. <em>SIOPT</em>, <em>33</em>(4),
3083–3113. (<a href="https://doi.org/10.1137/22M1488892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We address a large-scale and nonconvex optimization problem, involving an aggregative term. This term can be interpreted as the sum of the contributions of agents to some common good, with large. We investigate a relaxation of this problem, obtained by randomization. The relaxation gap is proved to converge to zeros as goes to infinity, independently of the dimension of the aggregate. We propose a stochastic method to construct an approximate minimizer of the original problem, given an approximate solution of the randomized problem. McDiarmid’s concentration inequality is used to quantify the probability of success of the method. We consider the Frank–Wolfe (FW) algorithm for the resolution of the randomized problem. Each iteration of the algorithm requires to solve a subproblem which can be decomposed into independent optimization problems. A sublinear convergence rate is obtained for the FW algorithm. In order to handle the memory overflow problem possibly caused by the FW algorithm, we propose a stochastic FW) algorithm, which ensures the convergence in both expectation and probability senses. Numerical experiments on a mixed-integer quadratic program illustrate the efficiency of the method.},
  archive      = {J_SIOPT},
  author       = {J. Frédéric Bonnans and Kang Liu and Nadia Oudjane and Laurent Pfeiffer and Cheng Wan},
  doi          = {10.1137/22M1488892},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3083-3113},
  shortjournal = {SIAM J. Optim.},
  title        = {Large-scale nonconvex optimization: Randomization, gap estimation, and numerical resolution},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Direct search based on probabilistic descent in reduced
spaces. <em>SIOPT</em>, <em>33</em>(4), 3057–3082. (<a
href="https://doi.org/10.1137/22M1488569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Derivative-free algorithms seek the minimum value of a given objective function without using any derivative information. The performance of these methods often worsens as the dimension increases, a phenomenon predicted by their worst-case complexity guarantees. Nevertheless, recent algorithmic proposals have shown that incorporating randomization into otherwise deterministic frameworks could alleviate this effect for direct-search methods. In particular, the best guarantees and practical performance were obtained for direct-search schemes using a random vector uniformly distributed on the sphere and its negative at every iteration. This approach effectively draws directions from a random one-dimensional subspace, yet the properties of such subspaces have not been exploited in direct search, unlike for other derivative-free schemes. Moreover, existing theory is by design limited to bounded directions and thus does not fully account for the numerous possibilities for generating random directions (such as drawing from a Gaussian distribution). In this paper, we study a generic direct-search algorithm in which the polling directions are defined using random subspaces. Complexity guarantees for such an approach are derived thanks to probabilistic properties related to both the subspaces and the directions used within these subspaces. Our analysis crucially extends previous deterministic and probabilistic arguments by relaxing the need for directions to be deterministically bounded in norm. As a result, our approach encompasses a wide range of new optimal polling strategies that can be characterized using our subspace and direction properties. By leveraging results on random subspace embeddings and sketching matrices, we show that better complexity bounds are obtained for randomized instances of our framework. A numerical investigation confirms the benefit of randomization, particularly when done in subspaces, when solving problems of moderately large dimension.},
  archive      = {J_SIOPT},
  author       = {Lindon Roberts and Clément W. Royer},
  doi          = {10.1137/22M1488569},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3057-3082},
  shortjournal = {SIAM J. Optim.},
  title        = {Direct search based on probabilistic descent in reduced spaces},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Convergence analysis of the proximal gradient method in the
presence of the kurdyka–łojasiewicz property without global lipschitz
assumptions. <em>SIOPT</em>, <em>33</em>(4), 3038–3056. (<a
href="https://doi.org/10.1137/23M1548293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a composite optimization problem where the sum of a continuously differentiable and a merely lower semicontinuous function has to be minimized. The proximal gradient algorithm is the classical method for solving such a problem numerically. The corresponding global convergence and local rate-of-convergence theory typically assumes, besides some technical conditions, that the smooth function has a globally Lipschitz continuous gradient and that the objective function satisfies the Kurdyka–Łojasiewicz property. Though this global Lipschitz assumption is satisfied in several applications where the objective function is, e.g., quadratic, this requirement is very restrictive in the nonquadratic case. Some recent contributions therefore try to overcome this global Lipschitz condition by replacing it with a local one, but, to the best of our knowledge, they still require some extra condition in order to obtain the desired global and rate-of-convergence results. The aim of this paper is to show that the local Lipschitz assumption together with the Kurdyka–Łojasiewicz property is sufficient to recover these convergence results.},
  archive      = {J_SIOPT},
  author       = {Xiaoxi Jia and Christian Kanzow and Patrick Mehlitz},
  doi          = {10.1137/23M1548293},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3038-3056},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergence analysis of the proximal gradient method in the presence of the kurdyka–Łojasiewicz property without global lipschitz assumptions},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Convergence of the momentum method for semialgebraic
functions with locally lipschitz gradients. <em>SIOPT</em>,
<em>33</em>(4), 3012–3037. (<a
href="https://doi.org/10.1137/23M1545720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a new length formula that governs the iterates of the momentum method when minimizing differentiable semialgebraic functions with locally Lipschitz gradients. It enables us to establish local convergence, global convergence, and convergence to local minimizers without assuming global Lipschitz continuity of the gradient, coercivity, and a global growth condition, as is done in the literature. As a result, we provide the first convergence guarantee of the momentum method starting from arbitrary initial points when applied to matrix factorization, matrix sensing, and linear neural networks.},
  archive      = {J_SIOPT},
  author       = {Cédric Josz and Lexiao Lai and Xiaopeng Li},
  doi          = {10.1137/23M1545720},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3012-3037},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergence of the momentum method for semialgebraic functions with locally lipschitz gradients},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Strong variational sufficiency for nonlinear semidefinite
programming and its implications. <em>SIOPT</em>, <em>33</em>(4),
2988–3011. (<a href="https://doi.org/10.1137/22M1530161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Strong variational sufficiency is a newly proposed property, which turns out to be of great use in the convergence analysis of multiplier methods. However, what this property implies for nonpolyhedral problems remains a puzzle. In this paper, we prove the equivalence between the strong variational sufficiency and the strong second-order sufficient condition (SOSC) for nonlinear semidefinite programming (NLSDP) without requiring the uniqueness of the multiplier or any other constraint qualifications. Based on this characterization, the local convergence property of the augmented Lagrangian method (ALM) for NLSDP can be established under the strong SOSC in the absence of constraint qualifications. Moreover, under the strong SOSC, we can apply the semismooth Newton method to solve the ALM subproblems of NLSDP because the positive definiteness of the generalized Hessian of augmented Lagrangian function is satisfied.},
  archive      = {J_SIOPT},
  author       = {Shiwei Wang and Chao Ding and Yangjing Zhang and Xinyuan Zhao},
  doi          = {10.1137/22M1530161},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2988-3011},
  shortjournal = {SIAM J. Optim.},
  title        = {Strong variational sufficiency for nonlinear semidefinite programming and its implications},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Universal conditional gradient sliding for convex
optimization. <em>SIOPT</em>, <em>33</em>(4), 2962–2987. (<a
href="https://doi.org/10.1137/21M1406234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we present a first-order projection-free method, namely, the universal conditional gradient sliding (UCGS) method, for computing -approximate solutions to convex differentiable optimization problems with bounded domains. For objective functions with Hölder continuous gradients under the Euclidean norm we show that UCGS is able to terminate with -solutions with at most gradient evaluations and linear objective optimizations, where and are the exponent and constant of the Hölder condition and is the diameter of the constraint set. Furthermore, UCGS is able to perform such computations without requiring any specific knowledge of the smoothness information and . In the weakly smooth case when , both complexity results improve the current state-of-the-art results Y. Nesterov, Math. Program., 171 (2018), pp. 311–330, S. Ghadimi, Math. Program., 173 (2019), pp. 431–464 on a first-order projection-free method achieved by the conditional gradient method. Within the class of sliding-type algorithms following from the work of G. Lan and Y. Zhou, SIAM J. Optim., 26 (2016), pp. 1379–1409, Y. Chen, G. Lan, Y. Ouyang, and W. Zhang, Comput. Optim. Appl., 73 (2019), pp. 159–199, to the best of our knowledge, this is the first time a sliding-type algorithm has been able to improve not only the gradient complexity but also the overall complexity for computing an approximate solution. In the smooth case when , UCGS matches the state-of-the-art complexity result achieved by the conditional gradient sliding method G. Lan and Y. Zhou, SIAM J. Optim., 26 (2016), pp. 1379–1409, but adds more features allowing for practical implementation.},
  archive      = {J_SIOPT},
  author       = {Yuyuan Ouyang and Trevor Squires},
  doi          = {10.1137/21M1406234},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2962-2987},
  shortjournal = {SIAM J. Optim.},
  title        = {Universal conditional gradient sliding for convex optimization},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cyclic coordinate dual averaging with extrapolation.
<em>SIOPT</em>, <em>33</em>(4), 2935–2961. (<a
href="https://doi.org/10.1137/22M1470104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Cyclic block coordinate methods are a fundamental class of optimization methods widely used in practice and implemented as part of standard software packages for statistical learning. Nevertheless, their convergence is generally not well understood and so far their good practical performance has not been explained by existing convergence analyses. In this work, we introduce a new block coordinate method that applies to the general class of variational inequality (VI) problems with monotone operators. This class includes composite convex optimization problems and convex-concave min-max optimization problems as special cases and has not been addressed by the existing work. The resulting convergence bounds match the optimal convergence bounds of full gradient methods, but are provided in terms of a novel gradient Lipschitz condition w.r.t. a Mahalanobis norm. For coordinate blocks, the resulting gradient Lipschitz constant in our bounds is never larger than a factor compared to the traditional Euclidean Lipschitz constant, while it is possible for it to be much smaller. Further, for the case when the operator in the VI has a finite-sum structure, we propose a variance-reduced variant of our method which further decreases the per-iteration cost and has better convergence rates in certain regimes. To obtain these results, we use a gradient extrapolation strategy that allows us to view a cyclic collection of block coordinatewise gradients as one implicit gradient.},
  archive      = {J_SIOPT},
  author       = {Chaobing Song and Jelena Diakonikolas},
  doi          = {10.1137/22M1470104},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2935-2961},
  shortjournal = {SIAM J. Optim.},
  title        = {Cyclic coordinate dual averaging with extrapolation},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The bipartite boolean quadric polytope with multiple-choice
constraints. <em>SIOPT</em>, <em>33</em>(4), 2909–2934. (<a
href="https://doi.org/10.1137/22M147579X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the bipartite boolean quadric polytope (BQP) with multiple-choice constraints and analyze its combinatorial properties. The well-studied BQP is defined as the convex hull of all quadric incidence vectors over a bipartite graph. In this work, we study the case where there is a partition on one of the two bipartite node sets such that at most one node per subset of the partition can be chosen. This polytope arises, for instance, in pooling problems with fixed proportions of the inputs at each pool. We show that it inherits many characteristics from BQP, among them a wide range of facet classes and operations which are facet preserving. Moreover, we characterize various cases in which the polytope is completely described via the relaxation-linearization inequalities. The special structure induced by the additional multiple-choice constraints also allows for new facet-preserving symmetries as well as lifting operations. Furthermore, it leads to several novel facet classes as well as extensions of these via lifting. We additionally give computationally tractable exact separation algorithms, most of which run in polynomial time. Finally, we demonstrate the strength of both the inherited and the new facet classes in computational experiments for a pooling application stemming from tea production, using real-world problem data. It turns out that in many cases solution times can be reduced significantly.},
  archive      = {J_SIOPT},
  author       = {Andreas Bärmann and Alexander Martin and Oskar Schneider},
  doi          = {10.1137/22M147579X},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2909-2934},
  shortjournal = {SIAM J. Optim.},
  title        = {The bipartite boolean quadric polytope with multiple-choice constraints},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sion’s minimax theorem in geodesic metric spaces and a
riemannian extragradient algorithm. <em>SIOPT</em>, <em>33</em>(4),
2885–2908. (<a href="https://doi.org/10.1137/22M1505475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Deciding whether saddle points exist or are approximable for nonconvex-nonconcave problems is usually intractable. This paper takes a step towards understanding a broad class of nonconvex-nonconcave minimax problems that do remain tractable. Specifically, it studies minimax problems over geodesic metric spaces, which provide a vast generalization of the usual convex-concave saddle point problems. The first main result of the paper is a geodesic metric space version of Sion’s minimax theorem; we believe our proof is novel and broadly accessible as it relies on the finite intersection property alone. The second main result is a specialization to geodesically complete Riemannian manifolds: here, we devise and analyze the complexity of first-order methods for smooth minimax problems.},
  archive      = {J_SIOPT},
  author       = {Peiyuan Zhang and Jingzhao Zhang and Suvrit Sra},
  doi          = {10.1137/22M1505475},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2885-2908},
  shortjournal = {SIAM J. Optim.},
  title        = {Sion’s minimax theorem in geodesic metric spaces and a riemannian extragradient algorithm},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal self-concordant barriers for quantum relative
entropies. <em>SIOPT</em>, <em>33</em>(4), 2858–2884. (<a
href="https://doi.org/10.1137/22M1500216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Quantum relative entropies are jointly convex functions of two positive definite matrices that generalize the Kullback–Leibler divergence and arise naturally in quantum information theory. In this paper, we prove self-concordance of natural barrier functions for the epigraphs of various quantum relative entropies and divergences. Furthermore we show that these barriers have optimal barrier parameters. These barriers allow convex optimization problems involving quantum relative entropies to be directly solved using interior point methods for nonsymmetric cones, avoiding the approximations and lifting techniques used in previous approaches. More generally, we establish the self-concordance of natural barriers for various closed convex cones related to the noncommutative perspectives of operator concave functions and show that the resulting barrier parameters are optimal.},
  archive      = {J_SIOPT},
  author       = {Hamza Fawzi and James Saunderson},
  doi          = {10.1137/22M1500216},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2858-2884},
  shortjournal = {SIAM J. Optim.},
  title        = {Optimal self-concordant barriers for quantum relative entropies},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Two-stage robust quadratic optimization with equalities and
its application to optimal power flow. <em>SIOPT</em>, <em>33</em>(4),
2830–2857. (<a href="https://doi.org/10.1137/22M1469651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work, we consider two-stage quadratic optimization problems under ellipsoidal uncertainty. In the first stage, one needs to decide upon the values of a subset of optimization variables (control variables). In the second stage, the uncertainty is revealed, and the rest of the optimization variables (state variables) are set up as a solution to a known system of possibly nonlinear equations. This type of problem occurs, for instance, in optimization for dynamical systems, such as electric power systems as well as gas and water networks. We propose a convergent iterative algorithm to build a sequence of approximately robustly feasible solutions with an improving objective value. At each iteration, the algorithm optimizes over a subset of the feasible set and uses affine approximations of the second-stage equations while preserving the nonlinearity of other constraints. We implement our approach and demonstrate its performance on Matpower instances of AC optimal power flow. Although this paper focuses on quadratic problems, the approach is suitable for more general setups.},
  archive      = {J_SIOPT},
  author       = {Olga Kuryatnikova and Bissan Ghaddar and Daniel K. Molzahn},
  doi          = {10.1137/22M1469651},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2830-2857},
  shortjournal = {SIAM J. Optim.},
  title        = {Two-stage robust quadratic optimization with equalities and its application to optimal power flow},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved unconstrained approach for bilevel optimization.
<em>SIOPT</em>, <em>33</em>(4), 2801–2829. (<a
href="https://doi.org/10.1137/22M1513034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we focus on the nonconvex-strongly-convex bilevel optimization problem (BLO). In this BLO, the objective function of the upper-level problem is nonconvex and possibly nonsmooth, and the lower-level problem is smooth and strongly convex with respect to the underlying variable . We show that the feasible region of BLO is a Riemannian manifold. Then we transform BLO to its corresponding unconstrained constraint dissolving problem (CDB), whose objective function is explicitly formulated from the objective functions in BLO. We prove that BLO is equivalent to the unconstrained optimization problem CDB. Therefore, various efficient unconstrained approaches, together with their theoretical results, can be directly applied to BLO through CDB. We propose a unified framework for developing subgradient-based methods for CDB. Remarkably, we show that several existing efficient algorithms can fit the unified framework and be interpreted as descent algorithms for CDB. These examples further demonstrate the great potential of our proposed approach.},
  archive      = {J_SIOPT},
  author       = {Xiaoyin Hu and Nachuan Xiao and Xin Liu and Kim-Chuan Toh},
  doi          = {10.1137/22M1513034},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2801-2829},
  shortjournal = {SIAM J. Optim.},
  title        = {An improved unconstrained approach for bilevel optimization},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multilevel objective-function-free optimization with an
application to neural networks training. <em>SIOPT</em>, <em>33</em>(4),
2772–2800. (<a href="https://doi.org/10.1137/23M1553455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A class of multilevel algorithms for unconstrained nonlinear optimization is presented which does not require the evaluation of the objective function. The class contains the momentum-less AdaGrad method as a particular (single-level) instance. The choice of avoiding the evaluation of the objective function is intended to make the algorithms of the class less sensitive to noise, while the multilevel feature aims at reducing their computational cost. The evaluation complexity of these algorithms is analyzed and their behavior in the presence of noise is then illustrated in the context of training deep neural networks for supervised learning applications.},
  archive      = {J_SIOPT},
  author       = {Serge Gratton and Alena Kopaničáková and Philippe L. Toint},
  doi          = {10.1137/23M1553455},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2772-2800},
  shortjournal = {SIAM J. Optim.},
  title        = {Multilevel objective-function-free optimization with an application to neural networks training},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evolution of mixed strategies in monotone games.
<em>SIOPT</em>, <em>33</em>(4), 2750–2771. (<a
href="https://doi.org/10.1137/22M1486066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the basic problem of approximating Nash equilibria in noncooperative games. For monotone games, we design continuous time flows which converge in an averaged sense to Nash equilibria. We also study mean field equilibria, which arise in the large player limit of symmetric noncooperative games. In this setting, we will additionally show that the approximation of mean field equilibria is possible under a suitable monotonicity hypothesis.},
  archive      = {J_SIOPT},
  author       = {Ryan Hynd},
  doi          = {10.1137/22M1486066},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2750-2771},
  shortjournal = {SIAM J. Optim.},
  title        = {Evolution of mixed strategies in monotone games},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dualities for non-euclidean smoothness and strong convexity
under the light of generalized conjugacy. <em>SIOPT</em>,
<em>33</em>(4), 2721–2749. (<a
href="https://doi.org/10.1137/21M1465913">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Relative smoothness and strong convexity have recently gained considerable attention in optimization. These notions are generalizations of the classical Euclidean notions of smoothness and strong convexity that are known to be dual to each other. However, conjugate dualities for non-Euclidean relative smoothness and strong convexity remain an open problem, as noted earlier by Lu, Freund, and Nesterov [SIAM J. Optim., 28 (2018), pp. 333–354]. In this paper, we address this question by introducing the notions of anisotropic strong convexity and smoothness as the respective dual counterparts. The dualities are developed under the light of generalized conjugacy, which leads us to embed the anticipated dual notions within the superclasses of certain upper and lower envelopes. In contrast to the Euclidean case, these inclusions are proper in general, as showcased by means of counterexamples.},
  archive      = {J_SIOPT},
  author       = {Emanuel Laude and Andreas Themelis and Panagiotis Patrinos},
  doi          = {10.1137/21M1465913},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2721-2749},
  shortjournal = {SIAM J. Optim.},
  title        = {Dualities for non-euclidean smoothness and strong convexity under the light of generalized conjugacy},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Locating theorems of differential inclusions governed by
maximally monotone operators. <em>SIOPT</em>, <em>33</em>(4), 2703–2720.
(<a href="https://doi.org/10.1137/22M1523030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we are interested in studying the asymptotic behavior of the solutions of differential inclusions governed by maximally monotone operators. In the case where the LaSalle’s invariance principle is inconclusive, we provide a refined version of the invariance principle theorem. This result derives from the problem of locating the -limit set of a bounded solution of the dynamic. In addition, we propose an extension of LaSalle’s invariance principle, which allows us to give a sharper location of the -limit set. The provided results are given in terms of nonsmooth Lyapunov pair-type functions.},
  archive      = {J_SIOPT},
  author       = {Minh N. Dao and Hassan Saoud and Michel A. Théra},
  doi          = {10.1137/22M1523030},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2703-2720},
  shortjournal = {SIAM J. Optim.},
  title        = {Locating theorems of differential inclusions governed by maximally monotone operators},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Minimax problems with coupled linear constraints:
Computational complexity and duality. <em>SIOPT</em>, <em>33</em>(4),
2675–2702. (<a href="https://doi.org/10.1137/21M1462428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work we study a special minimax problem where there are linear constraints that couple both the minimization and maximization decision variables. The problem is a generalization of the traditional saddle point problem (which does not have the coupling constraint), and it finds applications in wireless communication, game theory, transportation, just to name a few. We show that the considered problem is challenging, in the sense that it violates the classical max-min inequality, and that it is NP-hard even under very strong assumptions (e.g., when the objective is strongly-convex–strongly-concave). We then develop a duality theory for it, and analyze conditions under which the duality gap becomes zero. Finally, we study a class of stationary solutions defined based on the dual problem, and evaluate their practical performance in an application on adversarial attacks on network flow problems.},
  archive      = {J_SIOPT},
  author       = {Ioannis Tsaknakis and Mingyi Hong and Shuzhong Zhang},
  doi          = {10.1137/21M1462428},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2675-2702},
  shortjournal = {SIAM J. Optim.},
  title        = {Minimax problems with coupled linear constraints: Computational complexity and duality},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Affine invariant convergence rates of the conditional
gradient method. <em>SIOPT</em>, <em>33</em>(4), 2654–2674. (<a
href="https://doi.org/10.1137/21M1465263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We show that the conditional gradient method for the convex composite problem generates primal and dual iterates with a duality gap converging to zero provided a suitable growth property holds and the algorithm makes a judicious choice of stepsizes. The rate of convergence of the duality gap to zero ranges from sublinear to linear depending on the degree of the growth property. The growth property and convergence results depend on the pair in an affine invariant and norm-independent fashion.},
  archive      = {J_SIOPT},
  author       = {Javier F. Peña},
  doi          = {10.1137/21M1465263},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2654-2674},
  shortjournal = {SIAM J. Optim.},
  title        = {Affine invariant convergence rates of the conditional gradient method},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Second-order optimality conditions for general nonconvex
optimization problems and variational analysis of disjunctive systems.
<em>SIOPT</em>, <em>33</em>(4), 2625–2653. (<a
href="https://doi.org/10.1137/22M1484742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we propose second-order sufficient optimality conditions for a very general nonconvex constrained optimization problem, which covers many prominent mathematical programs. Unlike the existing results in the literature, our conditions prove to be sufficient, for an essential local minimizer of second order, under merely basic smoothness and closedness assumptions on the data defining the problem. In the second part, we propose a comprehensive first- and second-order variational analysis of disjunctive systems and demonstrate how the second-order objects appearing in the optimality conditions can be effectively computed in this case.},
  archive      = {J_SIOPT},
  author       = {Matúš Benko and Helmut Gfrerer and Jane J. Ye and Jin Zhang and Jinchuan Zhou},
  doi          = {10.1137/22M1484742},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2625-2653},
  shortjournal = {SIAM J. Optim.},
  title        = {Second-order optimality conditions for general nonconvex optimization problems and variational analysis of disjunctive systems},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Algorithms to solve unbounded convex vector optimization
problems. <em>SIOPT</em>, <em>33</em>(4), 2598–2624. (<a
href="https://doi.org/10.1137/22M1507693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper is concerned with solution algorithms for general convex vector optimization problems (CVOPs). So far, solution concepts and approximation algorithms for solving CVOPs exist only for bounded problems [Ç. Ararat, F. Ulus, and M. Umer, J. Optim. Theory Appl., 194 (2022), pp. 681–712], [D. Dörfler, A. Löhne, C. Schneider, and B. Weißing, Optim. Methods Softw., 37 (2022), pp. 1006–1026], [A. Löhne, B. Rudloff, and F. Ulus, J. Global Optim., 60 (2014), pp. 713–736]. They provide a polyhedral inner and outer approximation of the upper image that have a Hausdorff distance of at most . However, it is well known (see [F. Ulus, J. Global Optim., 72 (2018), pp. 731–742]), that for some unbounded problems such polyhedral approximations do not exist. In this paper, we will propose a generalized solution concept, called an –solution, that allows one to also consider unbounded CVOPs. It is based on additionally bounding the recession cones of the inner and outer polyhedral approximations of the upper image in a meaningful way. An algorithm is proposed that computes such –outer and –inner approximations of the recession cone of the upper image. In combination with the results of [A. Löhne, B. Rudloff, and F. Ulus, J. Global Optim., 60 (2014), pp. 713–736] this provides a primal and a dual algorithm that allow one to compute –solutions of (potentially unbounded) CVOPs. Numerical examples are provided.},
  archive      = {J_SIOPT},
  author       = {Andrea Wagner and Firdevs Ulus and Birgit Rudloff and Gabriela Kováčová and Niklas Hey},
  doi          = {10.1137/22M1507693},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2598-2624},
  shortjournal = {SIAM J. Optim.},
  title        = {Algorithms to solve unbounded convex vector optimization problems},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Strongly nonexpansive mappings revisited: Uniform
monotonicity and operator splitting. <em>SIOPT</em>, <em>33</em>(4),
2570–2597. (<a href="https://doi.org/10.1137/22M1501696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The correspondence between the class of nonexpansive mappings and the class of maximally monotone operators via the reflected resolvents of the latter has played an instrumental role in the convergence analysis of the splitting methods. Indeed, the performance of some of these methods, e.g., the Douglas–Rachford and Peaceman–Rachford methods, hinges on iterating the so-called splitting operator associated with the individual operators. This splitting operator is a function of the composition of the reflected resolvents of the underlying operators. In this paper, we provide a comprehensive study of the class of uniformly monotone operators and their corresponding reflected resolvents. We show that the latter is closely related to the class of strongly nonexpansive operators introduced by Bruck and Reich. Connections to duality via inverse operators are systematically studied. We provide applications to the Douglas–Rachford and Peaceman–Rachford methods. Examples that illustrate and tighten our results are presented.},
  archive      = {J_SIOPT},
  author       = {Leon Liu and Walaa M. Moursi and Jon Vanderwerff},
  doi          = {10.1137/22M1501696},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2570-2597},
  shortjournal = {SIAM J. Optim.},
  title        = {Strongly nonexpansive mappings revisited: Uniform monotonicity and operator splitting},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Subgradient sampling for nonsmooth nonconvex minimization.
<em>SIOPT</em>, <em>33</em>(4), 2542–2569. (<a
href="https://doi.org/10.1137/22M1479178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Risk minimization for nonsmooth nonconvex problems naturally leads to first-order sampling or, by an abuse of terminology, to stochastic subgradient descent. We establish the convergence of this method in the path-differentiable case and describe more precise results under additional geometric assumptions. We recover and improve results from Ermoliev and Norkin [Cybern. Syst. Anal., 34 (1998), pp. 196–215] by using a different approach: conservative calculus and the ODE method. In the definable case, we show that first-order subgradient sampling avoids artificial critical points with probability one and applies moreover to a large range of risk minimization problems in deep learning, based on the backpropagation oracle. As byproducts of our approach, we obtain several results on integration of independent interest, such as an interchange result for conservative derivatives and integrals or the definability of set-valued parameterized integrals.},
  archive      = {J_SIOPT},
  author       = {Jérôme Bolte and Tam Le and Edouard Pauwels},
  doi          = {10.1137/22M1479178},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2542-2569},
  shortjournal = {SIAM J. Optim.},
  title        = {Subgradient sampling for nonsmooth nonconvex minimization},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Shape optimization for variational inequalities: The scalar
tresca friction problem. <em>SIOPT</em>, <em>33</em>(4), 2512–2541. (<a
href="https://doi.org/10.1137/22M1497560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper investigates, without any regularization or penalization procedure, a shape optimization problem involving a simplified friction phenomenon modeled by a scalar Tresca friction law. Precisely, using tools from convex and variational analysis such as proximal operators and the notion of twice epi-differentiability, we prove that the solution to a scalar Tresca friction problem admits a directional derivative with respect to the shape which moreover coincides with the solution to a boundary value problem involving Signorini-type unilateral conditions. Then we explicitly characterize the shape gradient of the corresponding energy functional and we exhibit a descent direction. Finally, numerical simulations are performed to solve the corresponding energy minimization problem under a volume constraint which shows the applicability of our method and our theoretical results.},
  archive      = {J_SIOPT},
  author       = {Samir Adly and Loïc Bourdin and Fabien Caubet and Aymeric Jacob de Cordemoy},
  doi          = {10.1137/22M1497560},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2512-2541},
  shortjournal = {SIAM J. Optim.},
  title        = {Shape optimization for variational inequalities: The scalar tresca friction problem},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Maximal monotonicity and cyclic involutivity of
multiconjugate convex functions. <em>SIOPT</em>, <em>33</em>(4),
2489–2511. (<a href="https://doi.org/10.1137/23M1549201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A cornerstone in convex analysis is the crucial relationship between functions and their convex conjugate via the Fenchel–Young inequality. In this dual variable setting, the maximal monotonicity of the contact set is due to the involution holding for convex lower-semicontinuous functions defined on any Hilbert space. We investigate the validity of the cyclic version of involution and maximal monotonicity for multiple (more than two) convex functions. As a result, we show that when the underlying space is the real line, cyclical involutivity and maximal monotonicity induced by multiconjugate convex functions continue to hold as for the dual variable case. On the other hand, when the underlying space is multidimensional, we show that the corresponding properties do not hold in general unless a further regularity assumption is imposed. We provide detailed examples that illustrate the significant differences between dual- and multi-conjugate convex functions, as well as between uni- and multi-dimensional underlying spaces.},
  archive      = {J_SIOPT},
  author       = {Tongseok Lim},
  doi          = {10.1137/23M1549201},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2489-2511},
  shortjournal = {SIAM J. Optim.},
  title        = {Maximal monotonicity and cyclic involutivity of multiconjugate convex functions},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Corrigendum: Convex optimization problems on differentiable
sets. <em>SIOPT</em>, <em>33</em>(3), 2484–2488. (<a
href="https://doi.org/10.1137/23M1562901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This corrigendum provides a variant of the Brøndsted–Rockafellar theorem, which helps to correct an error in the proof of the sufficiency part of Theorem 2.8 in [X. Y. Zheng, SIAM J. Optim., 33 (2023), pp. 338–359] and to establish the correct characterization for a closed convex set to be -differentiable. In particular, in the original paper, Theorem 2.8 holds with replacing , and Theorem 3.2 holds with “ -order-well-posed solvable” replacing “ -order-well-posed solvable.” All other results remain true.},
  archive      = {J_SIOPT},
  author       = {Xi Yin Zheng},
  doi          = {10.1137/23M1562901},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2484-2488},
  shortjournal = {SIAM J. Optim.},
  title        = {Corrigendum: Convex optimization problems on differentiable sets},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The semiconvex regularization of functions. <em>SIOPT</em>,
<em>33</em>(3), 2457–2483. (<a
href="https://doi.org/10.1137/22M1496426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A variant of the compensated convexity process introduced and studied by Zhang and his colleagues is considered. It makes amenable the results and tools from convex analysis. It allows the regularization of functions with a strong decay, a new feature. It yields a family of tight approximations of the function that are always semiconvex functions. Thus, these approximating functions have interesting regularity properties. Their convergence is obtained under various assumptions. Additional questions and geometric applications that are important for several fields such as image analysis are deferred to the papers [H. V. Ngai, Proximal Subgradient Methods via the Semiconvex Regularization, in preparation], [H. V. Ngai and J.-P. Penot, Questions About the Semiconvex Regularization Method, in preparation], [H. V. Ngai and J.-P. Penot, Combining Different Regularization Methods, in preparation], and [H. V. Ngai and J.-P. Penot, The Medial Set and the Landscape Function of a Set, in preparation].},
  archive      = {J_SIOPT},
  author       = {Van Huynh Ngai and Jean-Paul Penot},
  doi          = {10.1137/22M1496426},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2457-2483},
  shortjournal = {SIAM J. Optim.},
  title        = {The semiconvex regularization of functions},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Min-max-min optimization with smooth and strongly convex
objectives. <em>SIOPT</em>, <em>33</em>(3), 2435–2456. (<a
href="https://doi.org/10.1137/22M1489940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider min-max-min optimization with smooth and strongly convex objectives. Our motivation for studying this class of problems stems from its connection to the -center problem and the growing literature on min-max-min robust optimization. In particular, the considered class of problems nontrivially generalizes the Euclidean -center problem in the sense that distances in this more general setting do not necessarily satisfy metric properties. We present a -approximation algorithm (where is the maximum condition number of the functions involved) that generalizes a simple greedy 2-approximation algorithm for the classical -center problem. We show that for any choice of , there is an instance with a condition number of per which our algorithm yields a -approximation guarantee, implying that our analysis is tight when . Finally, we compare the computational performance of our approximation algorithm with an exact mixed integer linear programming approach.},
  archive      = {J_SIOPT},
  author       = {Jourdain Lamperski and Oleg A. Prokopyev and Luca G. Wrabetz},
  doi          = {10.1137/22M1489940},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2435-2456},
  shortjournal = {SIAM J. Optim.},
  title        = {Min-max-min optimization with smooth and strongly convex objectives},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust optimization with continuous decision-dependent
uncertainty with applications to demand response management.
<em>SIOPT</em>, <em>33</em>(3), 2406–2434. (<a
href="https://doi.org/10.1137/22M1502082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a robust optimization problem with continuous decision-dependent uncertainty (RO-CDDU), which has two significant features: an uncertainty set linearly dependent on continuous decision variables, and a convex piecewise-linear objective function. We prove that RO-CDDU is strongly -hard in general and reformulate it into an equivalent mixed-integer nonlinear program (MINLP) with a decomposable structure to address the computational challenges. Such an MINLP model can be further transformed into a mixed-integer linear program (MILP) using extreme points of the dual polyhedron of the uncertainty set. We propose an alternating direction algorithm and a column generation algorithm for RO-CDDU. We model a robust demand response (DR) management problem in electricity markets as RO-CDDU, where electricity demand reduction from users is uncertain and depends on the DR planning decision. Extensive computational results demonstrate the promising performance of the proposed algorithms in both speed and solution quality. The results also shed light on how different magnitudes of decision-dependent uncertainty affect the DR decision.},
  archive      = {J_SIOPT},
  author       = {Hongfan (Kevin) Chen and Xu Andy Sun and Haoxiang Yang},
  doi          = {10.1137/22M1502082},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2406-2434},
  shortjournal = {SIAM J. Optim.},
  title        = {Robust optimization with continuous decision-dependent uncertainty with applications to demand response management},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A sequential quadratic programming algorithm for nonsmooth
problems with upper- <span
class="math inline">𝒞<sup><strong>2</strong></sup></span> objective.
<em>SIOPT</em>, <em>33</em>(3), 2379–2405. (<a
href="https://doi.org/10.1137/22M1490995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. An optimization algorithm for nonsmooth nonconvex constrained optimization problems with upper- objective functions is proposed and analyzed. Upper- is a weakly concave property that exists in difference of convex (DC) functions and arises naturally in many applications, particularly certain classes of solutions to parametric optimization problems e.g., recourse of stochastic programming and projection onto closed sets. The algorithm can be viewed as an extension of sequential quadratic programming (SQP) to nonsmooth problems with upper- objectives or a simplified bundle method. It is globally convergent with bounded algorithm parameters that are updated with a trust-region criterion. The algorithm handles general smooth constraints through linearization and uses a line search to ensure progress. The potential inconsistencies from the linearization of the constraints are addressed through a penalty method. The capabilities of the algorithm are demonstrated by solving both simple upper- problems and a real-world optimal power flow problem used in current power grid industry practices.},
  archive      = {J_SIOPT},
  author       = {Jingyi Wang and Cosmin G. Petra},
  doi          = {10.1137/22M1490995},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2379-2405},
  shortjournal = {SIAM J. Optim.},
  title        = {A sequential quadratic programming algorithm for nonsmooth problems with upper- \({\boldsymbol{\mathcal{C}^2}}\) objective},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Block policy mirror descent. <em>SIOPT</em>, <em>33</em>(3),
2341–2378. (<a href="https://doi.org/10.1137/22M1480409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we present a new policy gradient (PG) method, namely, the block policy mirror descent (BPMD) method, for solving a class of regularized reinforcement learning (RL) problems with (strongly) convex regularizers. Compared to the traditional PG methods with a batch update rule, which visits and updates the policy for every state, the BPMD method has cheap per-iteration computation via a partial update rule that performs the policy update on a sampled state. Despite the nonconvex nature of the problem and a partial update rule, we provide a unified analysis for several sampling schemes and show that BPMD achieves fast linear convergence to the global optimality. In particular, uniform sampling leads to worst-case total computational complexity comparable to batch PG methods. A necessary and sufficient condition for convergence with on-policy sampling is also identified. With a hybrid sampling scheme, we further show that BPMD enjoys potential instance-dependent acceleration, leading to improved dependence on the state space and consequently outperforming batch PG methods. We then extend BPMD methods to the stochastic setting by utilizing stochastic first-order information constructed from samples. With a generative model, (resp., ) sample complexities are established for the strongly convex (resp., non-strongly convex) regularizers, where denotes the target accuracy. To the best of our knowledge, this is the first time that block coordinate descent methods have been developed and analyzed for policy optimization in reinforcement learning, which provides a new perspective on solving large-scale RL problems.},
  archive      = {J_SIOPT},
  author       = {Guanghui Lan and Yan Li and Tuo Zhao},
  doi          = {10.1137/22M1480409},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2341-2378},
  shortjournal = {SIAM J. Optim.},
  title        = {Block policy mirror descent},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Existence of solutions for deterministic bilevel games under
a general bayesian approach. <em>SIOPT</em>, <em>33</em>(3), 2311–2340.
(<a href="https://doi.org/10.1137/21M1442164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In 1996, Mallozzi and Morgan [Hierarchical Systems with Weighted Reaction Set, Springer, Boston, 1996, pp. 271–282] proposed a new model for Stackelberg games which we refer to here to as the Bayesian approach. The leader has only partial information about how followers select their reaction among possibly multiple optimal ones. This partial information is modeled as a decision-dependent distribution, the so-called belief of the leader. In this work, we formalize the setting of this approach for bilevel games admitting multiple leaders and we provide new results of existence of solutions. We pay particular attention to the fundamental case of linear bilevel problems, which has not been studied before, and which main difficulty is given by possible variations in the dimension of the reaction set of the follower. Our main technique to address this difficulty is based on a stronger notion of continuity for set-valued maps that we call rectangular continuity, and which is verified by the solution set of parametric linear problems. Finally, we provide some numerical experiments to address linear bilevel problems under the Bayesian approach.},
  archive      = {J_SIOPT},
  author       = {David Salas and Anton Svensson},
  doi          = {10.1137/21M1442164},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2311-2340},
  shortjournal = {SIAM J. Optim.},
  title        = {Existence of solutions for deterministic bilevel games under a general bayesian approach},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accelerated first-order methods for convex optimization with
locally lipschitz continuous gradient. <em>SIOPT</em>, <em>33</em>(3),
2275–2310. (<a href="https://doi.org/10.1137/22M1500496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we develop accelerated first-order methods for convex optimization with locally Lipschitz continuous gradient (LLCG), which is beyond the well-studied class of convex optimization with Lipschitz continuous gradient. In particular, we first consider unconstrained convex optimization with LLCG and propose accelerated proximal gradient (APG) methods for solving it. The proposed APG methods are equipped with a verifiable termination criterion and enjoy an operation complexity of and for finding an -residual solution of an unconstrained convex and strongly convex optimization problem, respectively. We then consider constrained convex optimization with LLCG and propose a first-order proximal augmented Lagrangian method for solving it by applying one of our proposed APG methods to approximately solve a sequence of proximal augmented Lagrangian subproblems. The resulting method is equipped with a verifiable termination criterion and enjoys an operation complexity of and for finding an -KKT solution of a constrained convex and strongly convex optimization problem, respectively. All the proposed methods in this paper are parameter-free or almost parameter-free except that knowledge of the convexity parameter is required. In addition, preliminary numerical results are presented to demonstrate the performance of our proposed methods. To the best of our knowledge, no prior studies have been conducted to investigate accelerated first-order methods with complexity guarantees for convex optimization with LLCG. All the complexity results obtained in this paper are new.},
  archive      = {J_SIOPT},
  author       = {Zhaosong Lu and Sanyou Mei},
  doi          = {10.1137/22M1500496},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2275-2310},
  shortjournal = {SIAM J. Optim.},
  title        = {Accelerated first-order methods for convex optimization with locally lipschitz continuous gradient},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven approximation of contextual chance-constrained
stochastic programs. <em>SIOPT</em>, <em>33</em>(3), 2248–2274. (<a
href="https://doi.org/10.1137/22M1528045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Uncertainty in classical stochastic programming models is often described solely by independent random parameters, ignoring their dependence on multidimensional features. We describe a novel contextual chance-constrained programming formulation that incorporates features, and argue that solutions that do not take them into account may not be implementable. Our formulation cannot be solved exactly in most cases, and we propose a tractable and fully data-driven approximate model that relies on weighted sums of random variables. We obtain a stochastic lower bound for the optimal value and feasibility results that include convergence to the true feasible set as the number of data points increases, as well as the minimal number of data points needed to obtain a feasible solution with high probability. We illustrate our findings in a vaccine allocation problem and compare the results with a naïve sample average approximation approach.},
  archive      = {J_SIOPT},
  author       = {Hamed Rahimian and Bernardo Pagnoncelli},
  doi          = {10.1137/22M1528045},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2248-2274},
  shortjournal = {SIAM J. Optim.},
  title        = {Data-driven approximation of contextual chance-constrained stochastic programs},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Harnessing structure in composite nonsmooth minimization.
<em>SIOPT</em>, <em>33</em>(3), 2222–2247. (<a
href="https://doi.org/10.1137/22M1505827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the problem of minimizing the composition of a nonsmooth function with a smooth mapping in the case where the proximity operator of the nonsmooth function can be explicitly computed. We first show that this proximity operator can provide the exact smooth substructure of minimizers, not only of the nonsmooth function, but also of the full composite function. We then exploit this proximal identification by proposing an algorithm which combines proximal steps with sequential quadratic programming steps. We show that our method locally identifies the optimal smooth substructure and then converges quadratically. We illustrate its behavior on two problems: the minimization of a maximum of quadratic functions and the minimization of the maximal eigenvalue of a parametrized matrix.},
  archive      = {J_SIOPT},
  author       = {Gilles Bareilles and Franck Iutzeler and Jérôme Malick},
  doi          = {10.1137/22M1505827},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2222-2247},
  shortjournal = {SIAM J. Optim.},
  title        = {Harnessing structure in composite nonsmooth minimization},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Worst-case complexity of TRACE with inexact subproblem
solutions for nonconvex smooth optimization. <em>SIOPT</em>,
<em>33</em>(3), 2191–2221. (<a
href="https://doi.org/10.1137/22M1492428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. An algorithm for solving nonconvex smooth optimization problems is proposed, analyzed, and tested. The algorithm is an extension of the trust-region algorithm with contractions and expansions (TRACE) [F. E. Curtis, D. P. Robinson, and M. Samadi, Math. Program., 162 (2017), pp. 1–32]. In particular, the extension allows the algorithm to use inexact solutions of the arising subproblems, which is an important feature for solving large-scale problems. Inexactness is allowed in a manner such that the optimal iteration complexity of for attaining an -approximate first-order stationary point is maintained, while the worst-case complexity in terms of Hessian-vector products may be significantly improved as compared to the original TRACE. Numerical experiments show the benefits of allowing inexact subproblem solutions and that the algorithm compares favorably to state-of-the-art techniques.},
  archive      = {J_SIOPT},
  author       = {Frank E. Curtis and Qi Wang},
  doi          = {10.1137/22M1492428},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2191-2221},
  shortjournal = {SIAM J. Optim.},
  title        = {Worst-case complexity of TRACE with inexact subproblem solutions for nonconvex smooth optimization},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Random coordinate descent methods for nonseparable composite
optimization. <em>SIOPT</em>, <em>33</em>(3), 2160–2190. (<a
href="https://doi.org/10.1137/22M148700X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we consider large-scale composite optimization problems having the objective function formed as a sum of two terms (possibly nonconvex); one has a (block) coordinatewise Lipschitz continuous gradient and the other is differentiable but nonseparable. Under these general settings we derive and analyze two new coordinate descent methods. The first algorithm, referred to as the coordinate proximal gradient method, considers the composite form of the objective function, while the other algorithm disregards the composite form of the objective and uses the partial gradient of the full objective, yielding a coordinate gradient descent scheme with novel adaptive stepsize rules. We prove that these new stepsize rules make the coordinate gradient scheme a descent method, provided that additional assumptions hold for the second term in the objective function. We present a complete worst-case complexity analysis for these two new methods in both convex and nonconvex settings, provided that the (block) coordinates are chosen random or cyclic. Preliminary numerical results also confirm the efficiency of our two algorithms for practical problems.},
  archive      = {J_SIOPT},
  author       = {Flavia Chorobura and Ion Necoara},
  doi          = {10.1137/22M148700X},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2160-2190},
  shortjournal = {SIAM J. Optim.},
  title        = {Random coordinate descent methods for nonseparable composite optimization},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exponential convergence of sum-of-squares hierarchies for
trigonometric polynomials. <em>SIOPT</em>, <em>33</em>(3), 2137–2159.
(<a href="https://doi.org/10.1137/22M1540818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the unconstrained optimization of multivariate trigonometric polynomials by the sum-of-squares hierarchy of lower bounds. We first show a convergence rate of for the relaxation with degree without any assumption on the trigonometric polynomial to minimize. Second, when the polynomial has a finite number of global minimizers with invertible Hessians at these minimizers, we show an exponential convergence rate with explicit constants. Our results also apply to minimizing regular multivariate polynomials on the hypercube.},
  archive      = {J_SIOPT},
  author       = {Francis Bach and Alessandro Rudi},
  doi          = {10.1137/22M1540818},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2137-2159},
  shortjournal = {SIAM J. Optim.},
  title        = {Exponential convergence of sum-of-squares hierarchies for trigonometric polynomials},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Constrained optimization in the presence of noise.
<em>SIOPT</em>, <em>33</em>(3), 2118–2136. (<a
href="https://doi.org/10.1137/21M1450999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The problem of interest is the minimization of a nonlinear function subject to nonlinear equality constraints using a sequential quadratic programming (SQP) method. The minimization must be performed while observing only noisy evaluations of the objective and constraint functions. In order to obtain stability, the classical SQP method is modified by relaxing the standard Armijo line search based on the noise level in the functions, which is assumed to be known. Convergence theory is presented giving conditions under which the iterates converge to a neighborhood of the solution characterized by the noise level and the problem conditioning. The analysis assumes that the SQP algorithm does not require regularization or trust regions. Numerical experiments indicate that the relaxed line search improves the practical performance of the method on problems involving uniformly distributed noise, compared to a standard line search.},
  archive      = {J_SIOPT},
  author       = {Figen Oztoprak and Richard Byrd and Jorge Nocedal},
  doi          = {10.1137/21M1450999},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2118-2136},
  shortjournal = {SIAM J. Optim.},
  title        = {Constrained optimization in the presence of noise},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PCA sparsified. <em>SIOPT</em>, <em>33</em>(3), 2089–2117.
(<a href="https://doi.org/10.1137/22M1492325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose an inverted approach to the Sparse Principal Component Analysis (SPCA) problem. Most previous research efforts focused on solving the problem of maximizing the variance subject to sparsity constraints or penalizing lack of sparsity. We focus on the problem of minimizing the number of nonzero elements of the loadings subject to a variance constraint. We derive a tractable approach for this problem using Semidefinite Programming (SDP). Our method minimizes a non-convex penalty function mimicking a cardinality penalty function more closely than the convex norm which has been studied before. We develop a novel iterative weighted norm minimization algorithm referred to as PCA Sparsified. We develop two algorithms to solve the weighted norm minimization problem which have different efficiency estimates and computational complexity. Convergence properties of PCA Sparsified are studied. Connections to previously proposed methods are discussed. We introduce a preprocessing method to shrink the problem size which can also be used in previously proposed approaches. Numerical results based on careful implementation show the efficacy and potential of the proposed approach.},
  archive      = {J_SIOPT},
  author       = {Fatih S. Aktaş and Mustafa Ç. Pinar},
  doi          = {10.1137/22M1492325},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2089-2117},
  shortjournal = {SIAM J. Optim.},
  title        = {PCA sparsified},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Approximating tensor norms via sphere covering: Bridging the
gap between primal and dual. <em>SIOPT</em>, <em>33</em>(3), 2062–2088.
(<a href="https://doi.org/10.1137/22M1482391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The matrix spectral norm and nuclear norm appear in enormous applications. The generalization of these norms to higher-order tensors is becoming increasingly important, but unfortunately they are NP-hard to compute or even approximate. Although the two norms are dual to each other, the best-known approximation bound achieved by polynomial-time algorithms for the tensor nuclear norm is worse than that for the tensor spectral norm. In this paper, we bridge this gap by proposing deterministic algorithms with the best bound for both tensor norms. Our methods not only improve the approximation bound for the nuclear norm but also are data independent and easily implementable compared to existing approximation methods for the tensor spectral norm. The main idea is to construct a selection of unit vectors that can approximately represent the unit sphere, in other words, a collection of spherical caps to cover the sphere. For this purpose, we explicitly construct several collections of spherical caps for sphere covering with adjustable parameters for different levels of approximations and cardinalities. These readily available constructions are of independent interest, as they provide a powerful tool for various decision-making problems on spheres and related problems. We believe the ideas of constructions and the applications to approximate tensor norms can be useful to tackle optimization problems over other sets, such as the binary hypercube.},
  archive      = {J_SIOPT},
  author       = {Simai He and Haodong Hu and Bo Jiang and Zhening Li},
  doi          = {10.1137/22M1482391},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2062-2088},
  shortjournal = {SIAM J. Optim.},
  title        = {Approximating tensor norms via sphere covering: Bridging the gap between primal and dual},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Low-rank univariate sum of squares has no spurious local
minima. <em>SIOPT</em>, <em>33</em>(3), 2041–2061. (<a
href="https://doi.org/10.1137/22M1516208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study the problem of decomposing a polynomial into a sum of squares by minimizing a quadratically penalized objective . This objective is nonconvex and is equivalent to the rank- Burer–Monteiro factorization of a semidefinite program (SDP) encoding the sum of squares decomposition. We show that for all univariate polynomials , if , then has no spurious second-order critical points, showing that all local optima are also global optima. This is in contrast to previous work showing that for general SDPs, in addition to genericity conditions, has to be roughly the square root of the number of constraints (the degree of ) for there to be no spurious second-order critical points. Our proof uses tools from computational algebraic geometry and can be interpreted as constructing a certificate using the first- and second-order necessary conditions. We also show that by choosing a norm based on sampling equally spaced points on the circle, the gradient can be computed in nearly linear time using fast Fourier transforms. Experimentally we demonstrate that this method has very fast convergence using first-order optimization algorithms such as L-BFGS, with near-linear scaling to million-degree polynomials.},
  archive      = {J_SIOPT},
  author       = {Benoît Legat and Chenyang Yuan and Pablo Parrilo},
  doi          = {10.1137/22M1516208},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2041-2061},
  shortjournal = {SIAM J. Optim.},
  title        = {Low-rank univariate sum of squares has no spurious local minima},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Relative lipschitz-like property of parametric systems via
projectional coderivatives. <em>SIOPT</em>, <em>33</em>(3), 2021–2040.
(<a href="https://doi.org/10.1137/22M151296X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper concerns upper estimates of the projectional coderivative of implicit mappings and corresponding applications on analyzing the relative Lipschitz-like property. Under different constraint qualifications, we provide upper estimates of the projectional coderivative for solution mappings of parametric systems. For the solution mapping of affine variational inequalities, a generalized critical face condition is obtained for sufficiency of its Lipschitz-like property relative to a polyhedral set within its domain under a constraint qualification. The necessity is also obtainable under some regularity or when the polyhedral set is further the domain of the solution mapping. We further discuss possible conditions for the necessity and consider the solution mapping of a linear complementarity problem with a matrix as an example.},
  archive      = {J_SIOPT},
  author       = {Wenfang Yao and Xiaoqi Yang},
  doi          = {10.1137/22M151296X},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2021-2040},
  shortjournal = {SIAM J. Optim.},
  title        = {Relative lipschitz-like property of parametric systems via projectional coderivatives},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Convergence rate of inexact proximal point algorithms for
operator with hölder metric subregularity. <em>SIOPT</em>,
<em>33</em>(3), 1996–2020. (<a
href="https://doi.org/10.1137/22M152147X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study the issue of strong convergence of inexact proximal point algorithms (introduced by Rockafellar in [SIAM J. Control Optim., 14 (1976), pp. 877–898]) for maximal monotone operators on Hilbert spaces. A unified global/local strong convergence of inexact proximal point algorithms is established under the Hölder metrically subregular condition. Furthermore, quantitative estimates on the convergence rate of inexact proximal point algorithms are also provided. Applying to the special case of the classical (exact) proximal point algorithm, our results improve the corresponding ones in [G. Li and B. S. Mordukhovich, SIAM J. Optim., 22 (2012), pp. 1655–1684]. Finally, as applications, global/local strong convergence and estimates on the convergence rate of inexact proximal point algorithms for optimization problems are presented.},
  archive      = {J_SIOPT},
  author       = {Jinhua Wang and Chong Li and K. F. Ng},
  doi          = {10.1137/22M152147X},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1996-2020},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergence rate of inexact proximal point algorithms for operator with hölder metric subregularity},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bayesian joint chance constrained optimization:
Approximations and statistical consistency. <em>SIOPT</em>,
<em>33</em>(3), 1968–1995. (<a
href="https://doi.org/10.1137/21M1430005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper considers data-driven chance-constrained stochastic optimization problems in a Bayesian framework. Bayesian posteriors afford a principled mechanism to incorporate data and prior knowledge into stochastic optimization problems. However, the computation of Bayesian posteriors is typically an intractable problem and has spawned a large literature on approximate Bayesian computation. Here, in the context of chance-constrained optimization, we focus on the question of statistical consistency (in an appropriate sense) of the optimal value, computed using an approximate posterior distribution. To this end, we rigorously prove a frequentist consistency result demonstrating the convergence of the optimal value to the optimal value of a fixed, parameterized constrained optimization problem. We augment this by also establishing a probabilistic rate of convergence of the optimal value. We also prove the convex feasibility of the approximate Bayesian stochastic optimization problem. Finally, we demonstrate the utility of our approach on an optimal staffing problem for an M/M/c queueing model.},
  archive      = {J_SIOPT},
  author       = {Prateek Jaiswal and Harsha Honnappa and Vinayak A. Rao},
  doi          = {10.1137/21M1430005},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1968-1995},
  shortjournal = {SIAM J. Optim.},
  title        = {Bayesian joint chance constrained optimization: Approximations and statistical consistency},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stochastic saddle point problems with decision-dependent
distributions. <em>SIOPT</em>, <em>33</em>(3), 1943–1967. (<a
href="https://doi.org/10.1137/22M1488077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper focuses on stochastic saddle point problems with decision-dependent distributions. These are problems whose objective is the expected value of a stochastic payoff function and whose data distribution drifts in response to decision variables—a phenomenon represented by a distributional map. A common approach to accommodating distributional shift is to retrain optimal decisions once a new distribution is revealed, or repeated retraining. We introduce the notion of equilibrium points, which are the fixed points of this repeated retraining procedure, and provide sufficient conditions for their existence and uniqueness. To find equilibrium points, we develop deterministic and stochastic primal-dual algorithms and demonstrate their convergence with constant step size in the former and polynomial decay step-size schedule in the latter. By modeling errors emerging from a stochastic gradient estimator as sub-Weibull random variables, we provide error bounds in expectation and in high probability that hold for each iteration. Without additional knowledge of the distributional map, computing saddle points is intractable. Thus we propose a condition on the distributional map—which we call opposing mixture dominance—that ensures that the objective is strongly-convex–strongly-concave. Finally, we demonstrate that derivative-free algorithms with a single function evaluation are capable of approximating saddle points.},
  archive      = {J_SIOPT},
  author       = {Killian Wood and Emiliano Dall’Anese},
  doi          = {10.1137/22M1488077},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1943-1967},
  shortjournal = {SIAM J. Optim.},
  title        = {Stochastic saddle point problems with decision-dependent distributions},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Affine relaxations of the best response algorithm: Global
convergence in ratio-bounded games. <em>SIOPT</em>, <em>33</em>(3),
1914–1942. (<a href="https://doi.org/10.1137/21M140612X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In a two-player noncooperative game framework, we deal with the affine relaxations of the best response algorithm (where a player’s strategy is a best response to the strategy of the other player that comes from the previous step), motivated by the first results obtained for convex relaxations in zero-sum games (J. Morgan, Int. J. Comput. Math., 4 (1974), pp. 143–175) and for nonconvex affine relaxations in non-zero-sum games (F. Caruso, M. C. Ceparano, and J. Morgan, SIAM J. Optim., 30 (2020), pp. 1638–1663). In order to be able to specify the convergence of any type of affine relaxation of the best response algorithm, we define a new class of games, called ratio-bounded games. This class contains games broadly used in literature (such as weighted potential and zero-sum games), both in finite and infinite dimensional settings. Its definition relies on a unifying property and on three associate key parameters explicitly related to the data. Depending on how the parameters are ordered, we provide a classification of the ratio-bounded games in four subclasses such that, for each of them, the following issues are answered when the strategy sets are real Hilbert spaces: existence and uniqueness of the Nash equilibria, global convergence of the affine relaxations of the best response algorithm, estimation of the related errors, determination of the algorithm with the highest speed of convergence, and comparison with the known results. Moreover, the investigation is supplemented by illustrating numerical examples and by describing a black-box model with a first-order oracle for an implementation of the algorithm.},
  archive      = {J_SIOPT},
  author       = {Francesco Caruso and Maria Carmela Ceparano and Jacqueline Morgan},
  doi          = {10.1137/21M140612X},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1914-1942},
  shortjournal = {SIAM J. Optim.},
  title        = {Affine relaxations of the best response algorithm: Global convergence in ratio-bounded games},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Alternating proximal-gradient steps for (stochastic)
nonconvex-concave minimax problems. <em>SIOPT</em>, <em>33</em>(3),
1884–1913. (<a href="https://doi.org/10.1137/21M1465470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Minimax problems of the form have attracted increased interest largely due to advances in machine learning, in particular generative adversarial networks and adversarial learning. These are typically trained using variants of stochastic gradient descent for the two players. Although convex-concave problems are well understood with many efficient solution methods to choose from, theoretical guarantees outside of this setting are sometimes lacking even for the simplest algorithms. In particular, this is the case for alternating gradient descent ascent, where the two agents take turns updating their strategies. To partially close this gap in the literature we prove a novel global convergence rate for the stochastic version of this method for finding a critical point of in a setting which is not convex-concave.},
  archive      = {J_SIOPT},
  author       = {Radu Ioan Boţ and Axel Böhm},
  doi          = {10.1137/21M1465470},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1884-1913},
  shortjournal = {SIAM J. Optim.},
  title        = {Alternating proximal-gradient steps for (Stochastic) nonconvex-concave minimax problems},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive third-order methods for composite convex
optimization. <em>SIOPT</em>, <em>33</em>(3), 1855–1883. (<a
href="https://doi.org/10.1137/22M1480872">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we propose third-order methods for composite convex optimization problems in which the smooth part is a three-times continuously differentiable function with Lipschitz continuous third-order derivatives. The methods are adaptive in the sense that they do not require knowledge of the Lipschitz constant. Trial points are computed by the inexact minimization of models that consist in the nonsmooth part of the objective plus a quartic regularization of third-order Taylor polynomial of the smooth part. Specifically, approximate solutions of the auxiliary problems are obtained by using a Bregman gradient method as inner solver. Different from existing adaptive approaches for high-order methods, in our new schemes the regularization parameters are tuned by checking the progress of the inner solver. With this technique, we show that the basic method finds an -approximate minimizer of the objective function performing at most iterations of the inner solver. An accelerated adaptive third-order method is also presented with total inner iteration complexity of .},
  archive      = {J_SIOPT},
  author       = {G. N. Grapiglia and Yu. Nesterov},
  doi          = {10.1137/22M1480872},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1855-1883},
  shortjournal = {SIAM J. Optim.},
  title        = {Adaptive third-order methods for composite convex optimization},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Performance bounds for PDE-constrained optimization under
uncertainty. <em>SIOPT</em>, <em>33</em>(3), 1828–1854. (<a
href="https://doi.org/10.1137/21M1457916">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Computational approaches to PDE-constrained optimization under uncertainty may involve finite-dimensional approximations of control and state spaces, sample average approximations of measures of risk and reliability, smooth approximations of nonsmooth functions, penalty approximations of constraints, and many other kinds of inaccuracies. In this paper, we analyze the performance of controls obtained by an approximation-based algorithm and in the process develop estimates of optimality gaps for general optimization problems defined on metric spaces. Under mild assumptions, we establish that limiting controls have arbitrarily small optimality gaps provided that the inaccuracies in the various approximations vanish. We carry out the analysis for a broad class of problems with multiple expectation, risk, and reliability functions involving PDE solutions and appearing in objective as well as constraint expressions. In particular, we address problems with buffered failure probability constraints approximated via an augmented Lagrangian. We demonstrate the framework on an elliptic PDE with a random coefficient field and a distributed control function.},
  archive      = {J_SIOPT},
  author       = {Peng Chen and Johannes O. Royset},
  doi          = {10.1137/21M1457916},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1828-1854},
  shortjournal = {SIAM J. Optim.},
  title        = {Performance bounds for PDE-constrained optimization under uncertainty},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Riemannian hamiltonian methods for min-max optimization on
manifolds. <em>SIOPT</em>, <em>33</em>(3), 1797–1827. (<a
href="https://doi.org/10.1137/22M1492684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we study min-max optimization problems on Riemannian manifolds. We introduce a Riemannian Hamiltonian function, minimization of which serves as a proxy for solving the original min-max problems. Under the Riemannian Polyak–Łojasiewicz condition on the Hamiltonian function, its minimizer corresponds to the desired min-max saddle point. We also provide cases where this condition is satisfied. For geodesic-bilinear optimization in particular, solving the proxy problem leads to the correct search direction towards global optimality, which becomes challenging with the min-max formulation. To minimize the Hamiltonian function, we propose Riemannian Hamiltonian methods (RHMs) and present their convergence analyses. We extend RHMs to include consensus regularization and to the stochastic setting. We illustrate the efficacy of the proposed RHMs in applications such as subspace robust Wasserstein distance, robust training of neural networks, and generative adversarial networks.},
  archive      = {J_SIOPT},
  author       = {Andi Han and Bamdev Mishra and Pratik Jawanpuria and Pawan Kumar and Junbin Gao},
  doi          = {10.1137/22M1492684},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1797-1827},
  shortjournal = {SIAM J. Optim.},
  title        = {Riemannian hamiltonian methods for min-max optimization on manifolds},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Regularized equilibrium problems with equilibrium
constraints with application to energy markets. <em>SIOPT</em>,
<em>33</em>(3), 1767–1796. (<a
href="https://doi.org/10.1137/20M1353538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Equilibrium problems with equilibrium constraints are appropriate modeling formulations in a number of important areas, such as energy markets, transportation planning, and logistics. These models often correspond to bilevel games, in which certain dual variables, representing the equilibrium price, play a fundamental role. We consider multileader single-follower equilibrium problems having a linear program in the lower level. Because in this setting the lower-level response to the leaders’ decisions may not be unique, the game formulation becomes ill-posed. We resolve possible ambiguities by considering a sequence of bilevel equilibrium problems, endowed with a special regularization term. We prove convergence of the approximating scheme. Our technique proves useful numerically over several instances related to energy markets. When using PATH to solve the corresponding mixed-complementarity formulations, we exhibit that, in the given context, the regularization approach computes a genuine equilibrium price almost always, while without regularization the outcome is quite the opposite.},
  archive      = {J_SIOPT},
  author       = {Juan Pablo Luna and Claudia Sagastizábal and Julia Filiberti and Steven A. Gabriel and Mikhail V. Solodov},
  doi          = {10.1137/20M1353538},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1767-1796},
  shortjournal = {SIAM J. Optim.},
  title        = {Regularized equilibrium problems with equilibrium constraints with application to energy markets},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A newton-CG based augmented lagrangian method for finding a
second-order stationary point of nonconvex equality constrained
optimization with complexity guarantees. <em>SIOPT</em>, <em>33</em>(3),
1734–1766. (<a href="https://doi.org/10.1137/22M1489824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we consider finding a second-order stationary point (SOSP) of nonconvex equality constrained optimization when a nearly feasible point is known. In particular, we first propose a new Newton-conjugate gradient (Newton-CG) method for finding an approximate SOSP of unconstrained optimization and show that it enjoys a substantially better complexity than the Newton-CG method in [C. W. Royer, M. O’Neill, and S. J. Wright, Math. Program., 180 (2020), pp. 451–488]. We then propose a Newton-CG based augmented Lagrangian (AL) method for finding an approximate SOSP of nonconvex equality constrained optimization, in which the proposed Newton-CG method is used as a subproblem solver. We show that under a generalized linear independence constraint qualification (GLICQ), our AL method enjoys a total inner iteration complexity of and an operation complexity of for finding an -SOSP of nonconvex equality constrained optimization with high probability, which are significantly better than the ones achieved by the proximal AL method in [Y. Xie and S. J. Wright, J. Sci. Comput., 86 (2021), pp. 1–30]. In addition, we show that it has a total inner iteration complexity of and an operation complexity of when the GLICQ does not hold. To the best of our knowledge, all the complexity results obtained in this paper are new for finding an approximate SOSP of nonconvex equality constrained optimization with high probability. Preliminary numerical results also demonstrate the superiority of our proposed methods over the other competing algorithms.},
  archive      = {J_SIOPT},
  author       = {Chuan He and Zhaosong Lu and Ting Kei Pong},
  doi          = {10.1137/22M1489824},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1734-1766},
  shortjournal = {SIAM J. Optim.},
  title        = {A newton-CG based augmented lagrangian method for finding a second-order stationary point of nonconvex equality constrained optimization with complexity guarantees},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Space mapping for PDE constrained shape optimization.
<em>SIOPT</em>, <em>33</em>(3), 1707–1733. (<a
href="https://doi.org/10.1137/22M1515665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The space mapping technique is used to efficiently solve complex optimization problems. It combines the accuracy of fine model simulations with the speed of coarse model optimizations to approximate the solution of the fine model optimization problem. In this paper, we propose novel space mapping methods for solving shape optimization problems constrained by PDEs. We present the methods in a Riemannian setting based on Steklov–Poincaré-type metrics and discuss their numerical discretization and implementation. We investigate the numerical performance of the space mapping methods on several model problems. Our numerical results highlight the methods’ great efficiency for solving complex shape optimization problems.},
  archive      = {J_SIOPT},
  author       = {Sebastian Blauth},
  doi          = {10.1137/22M1515665},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1707-1733},
  shortjournal = {SIAM J. Optim.},
  title        = {Space mapping for PDE constrained shape optimization},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A regularized newton method for <span
class="math inline"><strong>ℓ</strong><sub><em>q</em></sub></span> -norm
composite optimization problems. <em>SIOPT</em>, <em>33</em>(3),
1676–1706. (<a href="https://doi.org/10.1137/22M1482822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper is concerned with -norm regularized minimization problems with a twice continuously differentiable loss function. For this class of nonconvex and nonsmooth composite problems, many algorithms have been proposed to solve them, most of which are of the first-order type. In this work, we propose a hybrid of the proximal gradient method and the subspace regularized Newton method, called HpgSRN. The whole iterate sequence produced by HpgSRN is proved to have a finite length and to converge to an -type stationary point under a mild curve-ratio condition and the Kurdyka–Łojasiewicz property of the cost function; it converges linearly if a further Kurdyka–Łojasiewicz property of exponent holds. Moreover, a superlinear convergence rate for the iterate sequence is also achieved under an additional local error bound condition. Our convergence results do not require the isolatedness and strict local minimality properties of the -stationary point. Numerical comparisons with ZeroFPR, a hybrid of proximal gradient method and quasi-Newton method for the forward-backward envelope of the cost function, proposed in [A. Themelis, L. Stella, and P. Patrinos, SIAM J. Optim., 28 (2018), pp. 2274–2303] for the -norm regularized linear and logistic regressions on real data, indicate that HpgSRN not only requires much less computing time but also yields comparable or even better sparsities and objective function values.},
  archive      = {J_SIOPT},
  author       = {Yuqia Wu and Shaohua Pan and Xiaoqi Yang},
  doi          = {10.1137/22M1482822},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1676-1706},
  shortjournal = {SIAM J. Optim.},
  title        = {A regularized newton method for \({\boldsymbol{\ell}}_{q}\) -norm composite optimization problems},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph topology invariant gradient and sampling complexity
for decentralized and stochastic optimization. <em>SIOPT</em>,
<em>33</em>(3), 1647–1675. (<a
href="https://doi.org/10.1137/20M138956X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. One fundamental problem in constrained decentralized multiagent optimization is the trade-off between gradient/sampling complexity and communication complexity. In this paper, we propose new algorithms whose gradient and sampling complexities are graph topology invariant, while their communication complexities remain optimal. Specifically, for convex smooth deterministic problems, we propose a primal-dual sliding (PDS) algorithm that is able to compute an -solution with gradient complexity and communication complexity, where is the smoothness parameter of the objective function and is related to either the graph Laplacian or the transpose of the oriented incidence matrix of the communication network. The complexities can be further improved to and , respectively, with the additional assumption of strong convexity modulus . We also propose a stochastic variant, namely, the stochastic primal-dual sliding (SPDS) algorithm, for convex smooth problems with stochastic gradients. The SPDS algorithm utilizes the minibatch technique and enables the agents to perform sampling and communication simultaneously. It computes a stochastic -solution with sampling complexity, which can be further improved to in the strong convexity case. Here is the variance of the stochastic gradient. The communication complexities of SPDS remain the same as that of the deterministic case.},
  archive      = {J_SIOPT},
  author       = {Guanghui Lan and Yuyuan Ouyang and Yi Zhou},
  doi          = {10.1137/20M138956X},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1647-1675},
  shortjournal = {SIAM J. Optim.},
  title        = {Graph topology invariant gradient and sampling complexity for decentralized and stochastic optimization},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Convergence properties of an objective-function-free
optimization regularization algorithm, including an <span
class="math inline">𝒪<strong>(</strong><strong>ϵ</strong><sup><strong>−</strong><strong>3</strong><strong>/</strong><strong>2</strong></sup><strong>)</strong></span>
complexity bound. <em>SIOPT</em>, <em>33</em>(3), 1621–1646. (<a
href="https://doi.org/10.1137/22M1499522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. An adaptive regularization algorithm for unconstrained nonconvex optimization is presented in which the objective function is never evaluated but only derivatives are used. This algorithm belongs to the class of adaptive regularization methods, for which optimal worst-case complexity results are known for the standard framework where the objective function is evaluated. It is shown in this paper that these excellent complexity bounds are also valid for the new algorithm despite the fact that significantly less information is used. In particular, it is shown that if derivatives of degree one to are used, the algorithm will find an -approximate first-order minimizer in at most iterations and an -approximate second-order minimizer in at most iterations. As a special case, the new algorithm using first and second derivatives, when applied to functions with Lipschitz continuous Hessian, will find an iterate at which the gradient’s norm is less than in at most iterations.},
  archive      = {J_SIOPT},
  author       = {Serge Gratton and Sadok Jerad and Philippe L. Toint},
  doi          = {10.1137/22M1499522},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1621-1646},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergence properties of an objective-function-free optimization regularization algorithm, including an \(\boldsymbol{\mathcal{O}(\epsilon^{-3/2})}\) complexity bound},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rational generalized nash equilibrium problems.
<em>SIOPT</em>, <em>33</em>(3), 1587–1620. (<a
href="https://doi.org/10.1137/21M1456285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper studies generalized Nash equilibrium problems that are given by rational functions. The optimization problems are not assumed to be convex. Rational expressions for Lagrange multipliers and feasible extensions of KKT points are introduced to compute a generalized Nash equilibrium (GNE). We give a hierarchy of rational optimization problems to solve rational generalized Nash equilibrium problems. The existence and computation of feasible extensions are studied. The Moment-SOS relaxations are applied to solve the rational optimization problems. Under some general assumptions, we show that the proposed hierarchy can compute a GNE if it exists or detect its nonexistence. Numerical experiments are given to show the efficiency of the proposed method.},
  archive      = {J_SIOPT},
  author       = {Jiawang Nie and Xindong Tang and Suhan Zhong},
  doi          = {10.1137/21M1456285},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1587-1620},
  shortjournal = {SIAM J. Optim.},
  title        = {Rational generalized nash equilibrium problems},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic approach to lyapunov analyses of
continuous-time models in convex optimization. <em>SIOPT</em>,
<em>33</em>(3), 1558–1586. (<a
href="https://doi.org/10.1137/22M1498486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. First-order methods are often analyzed via their continuous-time models, where their worst-case convergence properties are usually approached via Lyapunov functions. In this work, we provide a systematic and principled approach to finding and verifying Lyapunov functions for classes of ordinary and stochastic differential equations. More precisely, we extend the performance estimation framework, originally proposed by Drori and Teboulle [Math. Program., 145 (2014), pp. 451–482], to continuous-time models. We retrieve convergence results comparable to those of discrete-time methods using fewer assumptions and inequalities and provide new results for a family of stochastic accelerated gradient flows.},
  archive      = {J_SIOPT},
  author       = {Céline Moucer and Adrien Taylor and Francis Bach},
  doi          = {10.1137/22M1498486},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1558-1586},
  shortjournal = {SIAM J. Optim.},
  title        = {A systematic approach to lyapunov analyses of continuous-time models in convex optimization},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal methods for convex risk-averse distributed
optimization. <em>SIOPT</em>, <em>33</em>(3), 1518–1557. (<a
href="https://doi.org/10.1137/22M1485309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper studies the communication complexity of convex risk-averse optimization over a network. The problem generalizes the well-studied risk-neutral finite-sum distributed optimization problem, and its importance stems from the need to handle risk in an uncertain environment. For algorithms in the literature, a gap exists in communication complexities for solving risk-averse and risk-neutral problems. We propose two distributed algorithms, namely the distributed risk-averse optimization (DRAO) method and the distributed risk-averse optimization with sliding (DRAO-S) method, to close the gap. Specifically, the DRAO method achieves optimal communication complexity by assuming a certain saddle point subproblem can be easily solved in the server node. The DRAO-S method removes the strong assumption by introducing a novel saddle point sliding subroutine which only requires the projection over the ambiguity set . We observe that the number of -projections performed by DRAO-S is optimal. Moreover, we develop matching lower complexity bounds to show the communication complexities of both DRAO and DRAO-S to be unimprovable. Numerical experiments are conducted to demonstrate the encouraging empirical performance of the DRAO-S method.},
  archive      = {J_SIOPT},
  author       = {Guanghui Lan and Zhe Zhang},
  doi          = {10.1137/22M1485309},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1518-1557},
  shortjournal = {SIAM J. Optim.},
  title        = {Optimal methods for convex risk-averse distributed optimization},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The derivatives of sinkhorn–knopp converge. <em>SIOPT</em>,
<em>33</em>(3), 1494–1517. (<a
href="https://doi.org/10.1137/22M1512703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We show that the derivatives of the Sinkhorn–Knopp algorithm, or iterative proportional fitting procedure, converge towards the derivatives of the entropic regularization of the optimal transport problem with a locally uniform linear convergence rate.},
  archive      = {J_SIOPT},
  author       = {Edouard Pauwels and Samuel Vaiter},
  doi          = {10.1137/22M1512703},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1494-1517},
  shortjournal = {SIAM J. Optim.},
  title        = {The derivatives of Sinkhorn–Knopp converge},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A dynamic smoothing technique for a class of nonsmooth
optimization problems on manifolds. <em>SIOPT</em>, <em>33</em>(3),
1473–1493. (<a href="https://doi.org/10.1137/22M1489447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the problem of minimizing the sum of a smooth nonconvex function and a nonsmooth convex function over a compact embedded submanifold. We describe an algorithm, which we refer to as “dynamic smoothing gradient descent on manifolds” (DSGM), that is based on applying Riemmanian gradient steps on a series of smooth approximations of the objective function that are determined by a diminishing sequence of smoothing parameters. The DSGM algorithm is simple and can be easily employed for a broad class of problems without any complex adjustments. We show that all accumulation points of the sequence generated by the method are stationary. We devise a convergence rate of in terms of an optimality measure that can be easily computed. Numerical experiments illustrate the potential of the DSGM method.},
  archive      = {J_SIOPT},
  author       = {Amir Beck and Israel Rosset},
  doi          = {10.1137/22M1489447},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1473-1493},
  shortjournal = {SIAM J. Optim.},
  title        = {A dynamic smoothing technique for a class of nonsmooth optimization problems on manifolds},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fenchel–young inequality with a remainder and applications
to convex duality and optimal transport. <em>SIOPT</em>, <em>33</em>(3),
1463–1472. (<a href="https://doi.org/10.1137/22M150839X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This short note is devoted to some applications of a simple quantitative form of the Fenchel–Young inequality in Hilbert spaces both for convex functions and for Fitzpatrick functions of maximal monotone operators. Our initial motivation comes from a stability question in optimal transport. We derive from the quantitative form of the Fenchel–Young inequality a simple and constructive proof of the Brøndsted–Rockafellar theorem and a perturbed primal-dual attainment result in Hilbert spaces.},
  archive      = {J_SIOPT},
  author       = {Guillaume Carlier},
  doi          = {10.1137/22M150839X},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1463-1472},
  shortjournal = {SIAM J. Optim.},
  title        = {Fenchel–Young inequality with a remainder and applications to convex duality and optimal transport},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Regularized newton method with global <span
class="math inline">𝒪<strong>(</strong><strong>1</strong><strong>/</strong><strong>k</strong><sup><strong>2</strong></sup><strong>)</strong></span>
convergence. <em>SIOPT</em>, <em>33</em>(3), 1440–1462. (<a
href="https://doi.org/10.1137/22M1488752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present a Newton-type method that converges fast from any initialization and for arbitrary convex objectives with Lipschitz Hessians. We achieve this by merging the ideas of cubic regularization with a certain adaptive Levenberg–Marquardt penalty. In particular, we show that the iterates given by , where is a constant, converge globally with a rate. Our method is the first variant of Newton’s method that has both cheap iterations and provably fast global convergence. Moreover, we prove that locally our method converges superlinearly when the objective is strongly convex. To boost the method’s performance, we present a line search procedure that does not need prior knowledge of and is provably efficient.},
  archive      = {J_SIOPT},
  author       = {Konstantin Mishchenko},
  doi          = {10.1137/22M1488752},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1440-1462},
  shortjournal = {SIAM J. Optim.},
  title        = {Regularized newton method with global \({\boldsymbol{\mathcal{O}(1/{k}^2)}}\) convergence},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Certifying the absence of spurious local minima at infinity.
<em>SIOPT</em>, <em>33</em>(3), 1416–1439. (<a
href="https://doi.org/10.1137/22M1479531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. When searching for global optima of nonconvex unconstrained optimization problems, it is desirable that every local minimum be a global minimum. This property of having no spurious local minima is true in various problems of interest nowadays, including principal component analysis, matrix sensing, and linear neural networks. However, since these problems are noncoercive, they may yet have spurious local minima at infinity. The classical tools used to analyze the optimization landscape, namely the gradient and the Hessian, are incapable of detecting spurious local minima at infinity. In this paper, we identify conditions that certify the absence of spurious local minima at infinity, one of which is having bounded subgradient trajectories. We check that they hold in several applications of interest.},
  archive      = {J_SIOPT},
  author       = {Cédric Josz and Xiaopeng Li},
  doi          = {10.1137/22M1479531},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1416-1439},
  shortjournal = {SIAM J. Optim.},
  title        = {Certifying the absence of spurious local minima at infinity},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual ascent and primal-dual algorithms for infinite-horizon
nonstationary markov decision processes. <em>SIOPT</em>, <em>33</em>(3),
1391–1415. (<a href="https://doi.org/10.1137/22M149185X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Infinite-horizon nonstationary Markov decision processes (MDPs) extend their stationary counterparts by allowing temporal variations in immediate costs and transition probabilities. Bellman’s characterization of optimality and equivalent primal-dual linear programming formulations for these MDPs include a countably infinite number of variables and equations. Simple policy iteration, also viewed as a primal simplex algorithm, is the state of the art in solving these MDPs. It produces a sequence of policies whose costs-to-go converge monotonically from above to optimal. This suffers from two limitations. A cost-improving policy update is computationally expensive and an optimality gap is missing. We propose two dual-based approaches to address these concerns. The first, called dual ascent, maintains approximate costs-to-go (dual variables) and corresponding nonnegative errors in Bellman’s equations. The dual variables are iteratively increased such that errors vanish asymptotically. This guarantees that dual variables converge monotonically from below to optimal. This has two limitations. It does not maintain a sequence of policies (primal variables). Hence, it does not provide a decision-making strategy at termination and does not offer an upper bound on the optimal costs-to-go. The second approach, termed the primal-dual method, addresses these limitations. It maintains a primal policy, dual approximations of its costs-to-go, the corresponding nonegative Bellman’s errors, and inherits monotonic dual value convergence. The key is a so-called rebalancing step, which leads to a duality gap–based stopping criterion and also primal value convergence. Computational experiments demonstrate the benefits of primal-dual over dual ascent and that primal-dual is orders of magnitude faster than simple policy iteration.},
  archive      = {J_SIOPT},
  author       = {Archis Ghate},
  doi          = {10.1137/22M149185X},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1391-1415},
  shortjournal = {SIAM J. Optim.},
  title        = {Dual ascent and primal-dual algorithms for infinite-horizon nonstationary markov decision processes},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A decomposition augmented lagrangian method for low-rank
semidefinite programming. <em>SIOPT</em>, <em>33</em>(3), 1361–1390. (<a
href="https://doi.org/10.1137/22M1474539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We develop a decomposition method based on the augmented Lagrangian framework to solve a broad family of semidefinite programming problems, possibly with nonlinear objective functions, nonsmooth regularization, and general linear equality/inequality constraints. In particular, the positive semidefinite variable along with a group of linear constraints can be transformed into a variable on a smooth manifold via matrix factorization. The nonsmooth regularization and other general linear constraints are handled by the augmented Lagrangian method. Therefore, each subproblem can be solved by a semismooth Newton method on a manifold. Theoretically, we show that the first and second-order necessary optimality conditions for the factorized subproblem are also sufficient for the original subproblem under certain conditions. Convergence analysis is established for the Riemannian subproblem and the augmented Lagrangian method. Extensive numerical experiments on large-scale semidefinite programming problems such as max-cut, nearest correlation estimation, clustering, and sparse principal component analysis demonstrate the strength of our proposed method compared to other state-of-the-art methods.},
  archive      = {J_SIOPT},
  author       = {Yifei Wang and Kangkang Deng and Haoyang Liu and Zaiwen Wen},
  doi          = {10.1137/22M1474539},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1361-1390},
  shortjournal = {SIAM J. Optim.},
  title        = {A decomposition augmented lagrangian method for low-rank semidefinite programming},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Normal cones intersection rule and optimality analysis for
low-rank matrix optimization with affine manifolds. <em>SIOPT</em>,
<em>33</em>(3), 1333–1360. (<a
href="https://doi.org/10.1137/22M147863X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The low-rank matrix optimization with affine manifold (rank-MOA) aims to minimize a continuously differentiable function over a low-rank set intersecting with an affine manifold. This paper is devoted to the optimality analysis for rank-MOA. As a cornerstone, the intersection rule of the Fréchet normal cone to the feasible set of rank-MOA is established under some mild linear independence assumptions. Aided with the resulting explicit formulae of the underlying normal cones, the so-called -stationary point and the -stationary point of rank-MOA are investigated and the relationship with local/global minimizers are then revealed in terms of first-order optimality conditions. Furthermore, the second-order optimality analysis, including the necessary and sufficient conditions, is proposed based on the second-order differentiation information of the model. All these results will enrich the theory of low-rank matrix optimization and give potential clues to designing efficient numerical algorithms for seeking low-rank solutions. Meanwhile, two specific applications of rank-MOA are discussed to illustrate our proposed optimality analysis.},
  archive      = {J_SIOPT},
  author       = {Xinrong Li and Ziyan Luo},
  doi          = {10.1137/22M147863X},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1333-1360},
  shortjournal = {SIAM J. Optim.},
  title        = {Normal cones intersection rule and optimality analysis for low-rank matrix optimization with affine manifolds},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Revisiting spectral bundle methods: Primal-dual (sub)linear
convergence rates. <em>SIOPT</em>, <em>33</em>(2), 1305–1332. (<a
href="https://doi.org/10.1137/21M1402340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The spectral bundle method proposed by Helmberg and Rendl [SIAM J. Optim., 10 (2000), pp. 673–696] is well established for solving large-scale semidefinite programs (SDPs) thanks to its low per iteration computational complexity and strong practical performance. In this paper, we revisit this classic method showing that it achieves sublinear convergence rates in terms of both primal and dual SDPs under merely strong duality, complementing previous guarantees on primal-dual convergence. Moreover, we show that the method speeds up to linear convergence if (1) structurally the SDP admits strict complementarity and (2) algorithmically the bundle method captures the rank of the optimal solutions. Such complementary and low-rank structure is prevalent in many modern and classical applications. The linear convergence result is established via an eigenvalue approximation lemma which might be of independent interest. Numerically, we confirm our theoretical findings that the spectral bundle method, for modern and classical applications, speeds up under these conditions. Finally, we show that the spectral bundle method combined with a recent matrix sketching technique is able to solve an SDP with billions of decision variables in a matter of minutes.},
  archive      = {J_SIOPT},
  author       = {Lijun Ding and Benjamin Grimmer},
  doi          = {10.1137/21M1402340},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1305-1332},
  shortjournal = {SIAM J. Optim.},
  title        = {Revisiting spectral bundle methods: Primal-dual (Sub)linear convergence rates},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bayesian distributionally robust optimization.
<em>SIOPT</em>, <em>33</em>(2), 1279–1304. (<a
href="https://doi.org/10.1137/21M1465548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We introduce a new framework, Bayesian distributionally robust optimization (Bayesian-DRO), for data-driven stochastic optimization where the underlying distribution is unknown. Bayesian-DRO contrasts with most of the existing DRO approaches in the use of Bayesian estimation of the unknown distribution. To make computation of Bayesian updating tractable, Bayesian-DRO first assumes the underlying distribution takes a parametric form with unknown parameter and then computes the posterior distribution of the parameter. To address the model uncertainty brought by the assumed parametric distribution, Bayesian-DRO constructs an ambiguity set of distributions with the assumed parametric distribution as the reference distribution and then optimizes with respect to the worst case in the ambiguity set. We show the consistency of the Bayesian posterior distribution and subsequently the convergence of objective functions and optimal solutions of Bayesian-DRO. Our consistency result of the Bayesian posterior requires simpler assumptions than the classical literature on Bayesian consistency. We also consider several approaches for selecting the ambiguity set size in Bayesian-DRO and compare them numerically. Our numerical experiments demonstrate the out-of-sample performance of Bayesian-DRO in comparison with Kullback–Leibler-based DRO (KL-DRO) and Wasserstein-based empirical DRO as well as risk-neutral Bayesian risk optimization. Our numerical results shed light on how to choose the modeling framework (Bayesian-DRO, KL-DRO, Wasserstein-DRO) for specific problems, but the choice for general problems remains an important and open question.},
  archive      = {J_SIOPT},
  author       = {Alexander Shapiro and Enlu Zhou and Yifan Lin},
  doi          = {10.1137/21M1465548},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1279-1304},
  shortjournal = {SIAM J. Optim.},
  title        = {Bayesian distributionally robust optimization},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Implicit regularity and linear convergence rates for the
generalized trust-region subproblem. <em>SIOPT</em>, <em>33</em>(2),
1250–1278. (<a href="https://doi.org/10.1137/21M1468073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we develop efficient first-order algorithms for the generalized trust-region subproblem (GTRS), which has applications in signal processing, compressed sensing, and engineering. Although the GTRS, as stated, is nonlinear and nonconvex, it is well known that objective value exactness holds for its semidefinite programming (SDP) relaxation under a Slater condition. While polynomial-time SDP-based algorithms exist for the GTRS, their relatively large computational complexity has motivated and spurred the development of custom approaches for solving the GTRS. In particular, recent work in this direction has developed first-order methods for the GTRS whose running times are linear in the sparsity (the number of nonzero entries) of the input data. In contrast to these algorithms, in this paper we develop algorithms for computing -approximate solutions to the GTRS whose running times are linear in both the input sparsity and the precision whenever a regularity parameter is positive. We complement our theoretical guarantees with numerical experiments comparing our approach against algorithms from the literature. Our numerical experiments highlight that our new algorithms significantly outperform prior state-of-the-art algorithms on sparse large-scale instances.},
  archive      = {J_SIOPT},
  author       = {Alex L. Wang and Yunlei Lu and Fatma Kilinç-Karzan},
  doi          = {10.1137/21M1468073},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1250-1278},
  shortjournal = {SIAM J. Optim.},
  title        = {Implicit regularity and linear convergence rates for the generalized trust-region subproblem},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A unified framework for pricing in nonconvex resource
allocation games. <em>SIOPT</em>, <em>33</em>(2), 1223–1249. (<a
href="https://doi.org/10.1137/21M1400924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a basic nonconvex resource allocation game, where the players’ strategy spaces are subsets of and cost functions are parameterized by some common vector and, otherwise, only depend on their own strategy choice. A strategy of a player can be interpreted as a vector of resource consumption and a joint strategy profile naturally leads to an aggregate consumption vector. Resources can be priced, that is, the game is augmented by a price vector and players have quasi-linear overall costs, meaning that in addition to the original costs, a player needs to pay the corresponding price per consumed unit. We investigate the following question: for which aggregated consumption vectors can we find prices that induce an equilibrium realizing the targeted consumption profile? For answering this question, we revisit a duality-based framework and derive a new characterization of the existence of such and using convexification techniques. Our characterization implies the following result: If strategy spaces of players are bounded linear mixed-integer sets and the cost functions are linear or even concave, the equilibrium existence problem reduces to solving a well-structured LP. We then consider aggregate formulations assuming that cost functions are additive over resources and homogeneous among players. We derive a characterization of enforceable consumption vectors , showing that is enforceable if and only if is a minimizer of a certain convex optimization problem with a linear functional. We demonstrate that this framework can unify parts of four largely independent streams in the literature: tolls in transportation systems, Walrasian equilibria, trading networks, and congestion control. Besides reproving existing results we establish new enforceability results for these domains as well.},
  archive      = {J_SIOPT},
  author       = {Tobias Harks and Julian Schwarz},
  doi          = {10.1137/21M1400924},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1223-1249},
  shortjournal = {SIAM J. Optim.},
  title        = {A unified framework for pricing in nonconvex resource allocation games},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A newton-CG based barrier method for finding a second-order
stationary point of nonconvex conic optimization with complexity
guarantees. <em>SIOPT</em>, <em>33</em>(2), 1191–1222. (<a
href="https://doi.org/10.1137/21M1457011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we consider finding an approximate second-order stationary point (SOSP) of nonconvex conic optimization that minimizes a twice differentiable function over the intersection of an affine subspace and a convex cone. In particular, we propose a Newton–conjugate gradient based barrier method for finding an -SOSP of this problem. Our method not only is implementable but also achieves an iteration complexity of , which matches the best known iteration complexity of second-order methods for finding an -SOSP of unconstrained nonconvex optimization. The operation complexity, consisting of Cholesky factorizations and other fundamental operations, is also established for our method, where n is the problem dimension and represents with logarithmic terms omitted.},
  archive      = {J_SIOPT},
  author       = {Chuan He and Zhaosong Lu},
  doi          = {10.1137/21M1457011},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1191-1222},
  shortjournal = {SIAM J. Optim.},
  title        = {A newton-CG based barrier method for finding a second-order stationary point of nonconvex conic optimization with complexity guarantees},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Iteration-complexity of first-order augmented lagrangian
methods for convex conic programming. <em>SIOPT</em>, <em>33</em>(2),
1159–1190. (<a href="https://doi.org/10.1137/21M1403837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we consider a class of convex conic programming. In particular, we first propose an inexact augmented Lagrangian (I-AL) method that resembles the classical I-AL method for solving this problem, in which the augmented Lagrangian subproblems are solved approximately by a variant of Nesterov’s optimal first-order method. We show that the total number of first-order iterations of the proposed I-AL method for finding an -KKT solution is at most . We then propose an adaptively regularized I-AL method and show that it achieves a first-order iteration complexity , which significantly improves existing complexity bounds achieved by first-order I-AL methods for finding an -KKT solution. Our complexity analysis of the I-AL methods is based on a sharp analysis of the inexact proximal point algorithm (PPA) and the connection between the I-AL methods and inexact PPA. It is vastly different from existing complexity analyses of the first-order I-AL methods in the literature, which typically regard the I-AL methods as an inexact dual gradient method.},
  archive      = {J_SIOPT},
  author       = {Zhaosong Lu and Zirui Zhou},
  doi          = {10.1137/21M1403837},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1159-1190},
  shortjournal = {SIAM J. Optim.},
  title        = {Iteration-complexity of first-order augmented lagrangian methods for convex conic programming},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Variational convexity of functions and variational
sufficiency in optimization. <em>SIOPT</em>, <em>33</em>(2), 1121–1158.
(<a href="https://doi.org/10.1137/22M1519250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The paper is devoted to the study, characterizations, and applications of variational convexity of functions, the property that has been recently introduced by Rockafellar together with its strong counterpart. First we show that these variational properties of an extended-real-valued function are equivalent to, respectively, the conventional (local) convexity and strong convexity of its Moreau envelope. Then we derive new characterizations of both variational convexity and variational strong convexity of general functions via their second-order subdifferentials (generalized Hessians), which are coderivatives of subgradient mappings. We also study relationships of these notions with local minimizers and tilt-stable local minimizers. The obtained results are used for characterizing related notions of variational and strong variational sufficiency in composite optimization with applications to nonlinear programming.},
  archive      = {J_SIOPT},
  author       = {Pham Duy Khanh and Boris S. Mordukhovich and Vo Thanh Phat},
  doi          = {10.1137/22M1519250},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1121-1158},
  shortjournal = {SIAM J. Optim.},
  title        = {Variational convexity of functions and variational sufficiency in optimization},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Convergence of random reshuffling under the
kurdyka–łojasiewicz inequality. <em>SIOPT</em>, <em>33</em>(2),
1092–1120. (<a href="https://doi.org/10.1137/21M1468048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study the random reshuffling method for smooth nonconvex optimization problems with a finite-sum structure. Though this method is widely utilized in practice, e.g., in the training of neural networks, its convergence behavior is only understood in several limited settings. In this paper, under the well-known Kurdyka–Łojasiewicz (KL) inequality, we establish strong limit-point convergence results for with appropriate diminishing step sizes; namely, the whole sequence of iterates generated by is convergent and converges to a single stationary point in an almost sure sense. In addition, we derive the corresponding rate of convergence, depending on the KL exponent and suitably selected diminishing step sizes. When the KL exponent lies in , the convergence is at a rate of with counting the number of iterations. When the KL exponent belongs to , our derived convergence rate is of the form with depending on the KL exponent. The standard KL inequality-based convergence analysis framework only applies to algorithms with a certain descent property. We conduct a novel convergence analysis for the nondescent method with diminishing step sizes based on the KL inequality, which generalizes the standard KL framework. We summarize our main steps and core ideas in an informal analysis framework, which is of independent interest. As a direct application of this framework, we establish similar strong limit-point convergence results for the reshuffled proximal point method.},
  archive      = {J_SIOPT},
  author       = {Xiao Li and Andre Milzarek and Junwen Qiu},
  doi          = {10.1137/21M1468048},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1092-1120},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergence of random reshuffling under the kurdyka–Łojasiewicz inequality},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Policy mirror descent for regularized reinforcement
learning: A generalized framework with linear convergence.
<em>SIOPT</em>, <em>33</em>(2), 1061–1091. (<a
href="https://doi.org/10.1137/21M1456789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Policy optimization, which learns the policy of interest by maximizing the value function via large-scale optimization techniques, lies at the heart of modern reinforcement learning (RL). In addition to value maximization, other practical considerations arise commonly as well, including the need of encouraging exploration, and that of ensuring certain structural properties of the learned policy due to safety, resource, and operational constraints. These considerations can often be accounted for by resorting to regularized RL, which augments the target value function with a structure-promoting regularization term. Focusing on an infinite-horizon discounted tabular Markov decision process, this paper proposes a generalized policy mirror descent (GPMD) algorithm for solving regularized RL. As a generalization of policy mirror descent [G. Lan, Math. Program., 198 (2023), pp. 1059–1106], the proposed algorithm accommodates a general class of convex regularizers as well as a broad family of Bregman divergence in cognizance of the regularizer in use. We demonstrate that our algorithm converges linearly to the global solution over an entire range of learning rates, in a dimension-free fashion, even when the regularizer lacks strong convexity and smoothness. In addition, this linear convergence feature is provably stable in the face of inexact policy evaluation and imperfect policy updates. Numerical experiments are provided to corroborate the applicability and appealing performance of GPMD.},
  archive      = {J_SIOPT},
  author       = {Wenhao Zhan and Shicong Cen and Baihe Huang and Yuxin Chen and Jason D. Lee and Yuejie Chi},
  doi          = {10.1137/21M1456789},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1061-1091},
  shortjournal = {SIAM J. Optim.},
  title        = {Policy mirror descent for regularized reinforcement learning: A generalized framework with linear convergence},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Primal-dual first-order methods for affinely constrained
multi-block saddle point problems. <em>SIOPT</em>, <em>33</em>(2),
1035–1060. (<a href="https://doi.org/10.1137/21M1451944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the convex-concave saddle point problem , where the decision variables and/or are subject to certain multi-block structure and affine coupling constraints, and possesses certain separable structure. Although the minimization counterpart of this problem has been widely studied under the topics of ADMM, this minimax problem is rarely investigated. In this paper, a convenient notion of -saddle point is proposed, under which the convergence rate of several proposed algorithms are analyzed. When only one of and has multiple blocks and affine constraint, several natural extensions of ADMM are proposed to solve the problem. Depending on the number of blocks and the level of smoothness, or convergence rates are derived for our algorithms. When both and have multiple blocks and affine constraints, a new algorithm called xtra- radient Method of ultipliers (EGMM) is proposed. Under desirable smoothness conditions, an rate of convergence can be guaranteed regardless of the number of blocks in and . An in-depth comparison between EGMM (fully primal-dual method) and ADMM (approximate dual method) is made over the multi-block optimization problems to illustrate the advantage of the EGMM.},
  archive      = {J_SIOPT},
  author       = {Junyu Zhang and Mengdi Wang and Mingyi Hong and Shuzhong Zhang},
  doi          = {10.1137/21M1451944},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1035-1060},
  shortjournal = {SIAM J. Optim.},
  title        = {Primal-dual first-order methods for affinely constrained multi-block saddle point problems},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A geodesic interior-point method for linear optimization
over symmetric cones. <em>SIOPT</em>, <em>33</em>(2), 1006–1034. (<a
href="https://doi.org/10.1137/20M1385019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We develop a new interior-point method (IPM) for symmetric-cone optimization, a common generalization of linear, second-order-cone, and semidefinite programming. In contrast to classical IPMs, we update iterates with a geodesic of the cone instead of the kernel of the linear constraints. This approach yields a primal-dual-symmetric, scale-invariant, and line-search-free algorithm that uses just half of the variables of a standard primal-dual IPM. With elementary arguments, we establish polynomial-time convergence matching the standard bound. Finally, we prove the global convergence of a longstep variant and provide an implementation that supports all symmetric cones. For linear programming, our algorithms reduce to central-path tracking in the log-domain.},
  archive      = {J_SIOPT},
  author       = {Frank Permenter},
  doi          = {10.1137/20M1385019},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1006-1034},
  shortjournal = {SIAM J. Optim.},
  title        = {A geodesic interior-point method for linear optimization over symmetric cones},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DIMIX: Diminishing mixing for sloppy agents. <em>SIOPT</em>,
<em>33</em>(2), 978–1005. (<a
href="https://doi.org/10.1137/21M143546X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study nonconvex distributed optimization problems where a set of agents collaboratively solve a separable optimization problem that is distributed over a time-varying network. The existing methods to solve these problems rely on (at most) one-time-scale algorithms, where each agent performs a diminishing or constant step-size gradient descent at the average estimate of the agents in the network. However, if possible at all, exchanging exact information, which is required to evaluate these average estimates, potentially introduces a massive communication overhead. Therefore, a reasonable practical assumption to be made is that agents only receive a rough approximation of the neighboring agents’ information. To address this, we introduce and study a two-time-scale decentralized algorithm with a broad class of lossy information sharing methods (which includes noisy, quantized, and/or compressed information sharing) over time-varying networks. In our method, one time-scale suppresses the (imperfect) incoming information from the neighboring agents, and one time-scale operates on local cost functions’ gradients. We show that with a proper choices for the step-sizes’ parameters, the algorithm achieves a convergence rate of for nonconvex distributed optimization problems over time-varying networks for any .},
  archive      = {J_SIOPT},
  author       = {Hadi Reisizadeh and Behrouz Touri and Soheil Mohajer},
  doi          = {10.1137/21M143546X},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {978-1005},
  shortjournal = {SIAM J. Optim.},
  title        = {DIMIX: Diminishing mixing for sloppy agents},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Strongly stable stationary points for a class of generalized
equations. <em>SIOPT</em>, <em>33</em>(2), 950–977. (<a
href="https://doi.org/10.1137/21M146750X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we consider a generalized equation that is mainly characterized by a cone-valued mapping. It is well known that optimality conditions for different classes of optimization problems can be formulated as such a generalized equation. Moreover, we generalize Kojima’s concept of strong stability and introduce appropriate constraint qualifications. We discuss corresponding properties between strong stability and these constraint qualifications. Finally, we apply these results to the particular class of mathematical programs with complementarity constraints and to that of mathematical programs with abstract constraints.},
  archive      = {J_SIOPT},
  author       = {Harald Günzel and Daniel Hernández Escobar and Jan-J. Rückmann},
  doi          = {10.1137/21M146750X},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {950-977},
  shortjournal = {SIAM J. Optim.},
  title        = {Strongly stable stationary points for a class of generalized equations},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A stochastic composite augmented lagrangian method for
reinforcement learning. <em>SIOPT</em>, <em>33</em>(2), 921–949. (<a
href="https://doi.org/10.1137/21M1421726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we consider the linear programming (LP) formulation for deep reinforcement learning. The number of the constraints depends on the size of state and action spaces, which makes the problem intractable in large or continuous environments. The general augmented Lagrangian method suffers the double-sampling obstacle in solving the linear program. Motivated from the updates of the multipliers, we overcome the obstacles in minimizing the augmented Lagrangian function by replacing the intractable conditional expectations with the multipliers. Therefore, a deep parameterized augmented Lagrangian method is proposed. The replacement provides a promising breakthrough to integrate the two steps in the augmented Lagrangian method into a single quadratic penalty problem. A general theoretical analysis shows that the solutions generated from a sequence of the constrained optimization converge to the optimal solution of the linear program if the error is controlled properly. A theoretical analysis on the quadratic penalty algorithm without using target networks under a neural tangent kernel setting shows the residual can be arbitrarily small if the parameter in the network and the optimization algorithm is chosen suitably. Preliminary experiments illustrate that our method is competitive with other state-of-the-art algorithms.},
  archive      = {J_SIOPT},
  author       = {Yongfeng Li and Mingming Zhao and Weijie Chen and Zaiwen Wen},
  doi          = {10.1137/21M1421726},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {921-949},
  shortjournal = {SIAM J. Optim.},
  title        = {A stochastic composite augmented lagrangian method for reinforcement learning},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Some strongly polynomially solvable convex quadratic
programs with bounded variables. <em>SIOPT</em>, <em>33</em>(2),
899–920. (<a href="https://doi.org/10.1137/21M1463793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper begins with the review of a class of strictly convex quadratic programs (QPs) with bounded variables solvable by the parametric principal pivoting algorithm with strongly polynomial complexity, where is the number of variables of the problem. Extensions of this Hessian class are the main contributions of this paper, which is motivated by a recent paper [P. Liu, S. Fattahi, A. Gómez, and S. Küçükyavuz, Math. Program. (2022), https://doi.org/10.1007/s10107-022-01845-0], wherein the efficient solution of a QP with a tridiagonal Hessian matrix in the quadratic objective is needed for the construction of a polynomial-time algorithm for solving an associated sparse variable selection problem. With the tridiagonal structure, the complexity of the QP algorithm reduces to . Our strongly polynomiality results extend previous works of some strongly polynomially solvable linear complementarity problems with a P-matrix [J. S. Pang and R. Chandrasekaran, Math. Program. Stud., 25 (1985), pp. 13–27]; special cases of the extended results include weakly quasi-diagonally dominant problems in addition to the tridiagonal ones.},
  archive      = {J_SIOPT},
  author       = {Jong-Shi Pang and Shaoning Han},
  doi          = {10.1137/21M1463793},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {899-920},
  shortjournal = {SIAM J. Optim.},
  title        = {Some strongly polynomially solvable convex quadratic programs with bounded variables},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sharp and fast bounds for the celis-dennis-tapia problem.
<em>SIOPT</em>, <em>33</em>(2), 868–898. (<a
href="https://doi.org/10.1137/21M144548X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In the Celis–Dennis–Tapia (CDT) problem a quadratic function is minimized over a region defined by two strictly convex quadratic constraints. In this paper we rederive a necessary and sufficient optimality condition for the exactness of the dual Lagrangian bound (equivalent to the Shor relaxation bound in this case). Starting from such a condition, we propose strengthening the dual Lagrangian bound by adding one or two linear cuts to the Lagrangian relaxation. Such cuts are obtained from supporting hyperplanes of one of the two constraints. Thus, they are redundant for the original problem, but they are not for the Lagrangian relaxation. The computational experiments show that the new bounds are effective and require limited computing times. In particular, one of the proposed bounds is able to solve all but one of the 212 hard instances of the CDT problem presented in [S. Burer and K. M. Anstreicher, SIAM J. Optim., 23 (2013), pp. 432–451].},
  archive      = {J_SIOPT},
  author       = {Luca Consolini and Marco Locatelli},
  doi          = {10.1137/21M144548X},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {868-898},
  shortjournal = {SIAM J. Optim.},
  title        = {Sharp and fast bounds for the celis-dennis-tapia problem},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The geometry of sparse analysis regularization.
<em>SIOPT</em>, <em>33</em>(2), 842–867. (<a
href="https://doi.org/10.1137/19M1271877">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Analysis sparsity is a common prior in inverse problem or machine learning including special cases such as total variation regularization, edge Lasso, and fused Lasso. We study the geometry of the solution set (a polyhedron) of the analysis regularization (with data fidelity term) when it is not reduced to a singleton without any assumption of the analysis dictionary nor the degradation operator. In contrast with most theoretical work, we do not focus on giving uniqueness and/or stability results but rather describe a worst-case scenario where the solution set can be big in terms of dimension. Leveraging a fine analysis of the sublevel set of the regularizer itself, we draw a connection between support of a solution and the minimal face containing it and, in particular, prove that extreme points can be recovered thanks to an algebraic test. Moreover, we draw a connection between the sign pattern of a solution and the ambient dimension of the smallest face containing it. Finally, we show that any arbitrary subpolyhedra of the level set can be seen as a solution set of sparse analysis regularization with explicit parameters.},
  archive      = {J_SIOPT},
  author       = {Xavier Dupuis and Samuel Vaiter},
  doi          = {10.1137/19M1271877},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {842-867},
  shortjournal = {SIAM J. Optim.},
  title        = {The geometry of sparse analysis regularization},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Moderate deviations and invariance principles for sample
average approximations. <em>SIOPT</em>, <em>33</em>(2), 816–841. (<a
href="https://doi.org/10.1137/22M1484584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study moderate deviations and convergence rates for the optimal values and optimal solutions of sample average approximations. Firstly, we give an extension of the Delta method in large deviations. Then under Lipschitz continuity on the objective function, we establish a moderate deviation principle for the optimal value by the Delta method. When the objective function is twice continuously differentiable and the optimal solution of true optimization problem is unique, we obtain a moderate deviation principle for the optimal solution and a Cramér-type moderate deviation for the optimal value. Motivated by the Donsker invariance principle, we consider a functional form of stochastic programming problem and establish a Donsker invariance principle, a functional moderate deviation principle, and a Strassen invariance principle for the optimal value.},
  archive      = {J_SIOPT},
  author       = {Mingjie Gao and Ka-Fai Cedric Yiu},
  doi          = {10.1137/22M1484584},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {816-841},
  shortjournal = {SIAM J. Optim.},
  title        = {Moderate deviations and invariance principles for sample average approximations},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Strong convergence for the alternating halpern–mann
iteration in CAT(0) spaces. <em>SIOPT</em>, <em>33</em>(2), 785–815. (<a
href="https://doi.org/10.1137/22M1511199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we consider, in the general context of CAT(0) spaces, an iterative schema which alternates between Halpern and Krasnoselskii–Mann style iterations. We prove, under suitable conditions, the strong convergence of this algorithm, benefiting from ideas from the proof mining program. We give quantitative information in the form of effective rates of asymptotic regularity and of metastability (in the sense of Tao). Motivated by these results, we are also able to obtain strongly convergent versions of the forward-backward and the Douglas–Rachford algorithms. Our results generalize recent work by Boţ, Csetnek, and Meier and Cheval and Leuştean.},
  archive      = {J_SIOPT},
  author       = {Bruno Dinis and Pedro Pinto},
  doi          = {10.1137/22M1511199},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {785-815},
  shortjournal = {SIAM J. Optim.},
  title        = {Strong convergence for the alternating Halpern–Mann iteration in CAT(0) spaces},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fréchet second-order subdifferentials of lagrangian
functions and optimality conditions. <em>SIOPT</em>, <em>33</em>(2),
766–784. (<a href="https://doi.org/10.1137/22M1512454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We establish some new results on second-order (necessary and sufficient) optimality conditions for minimization problems with abstract constraints in infinite-dimensional spaces, where the objective functions are only assumed to be -smooth. For doing so, we apply the concept of Fréchet (regular) second-order subdifferential from variational analysis to the Lagrangian function of the problem under investigation. Our results extend and refine several existing ones.},
  archive      = {J_SIOPT},
  author       = {Duong Thi Viet An and Hong-Kun Xu and Nguyen Dong Yen},
  doi          = {10.1137/22M1512454},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {766-784},
  shortjournal = {SIAM J. Optim.},
  title        = {Fréchet second-order subdifferentials of lagrangian functions and optimality conditions},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The splitting algorithms by ryu, by malitsky–tam, and by
campoy applied to normal cones of linear subspaces converge strongly to
the projection onto the intersection. <em>SIOPT</em>, <em>33</em>(2),
739–765. (<a href="https://doi.org/10.1137/22M1483165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Finding a zero of a sum of maximally monotone operators is a fundamental problem in modern optimization and nonsmooth analysis. Assuming that the resolvents of the operators are available, this problem can be tackled with the Douglas–Rachford algorithm. However, when dealing with three or more operators, one must work in a product space with as many factors as there are operators. In groundbreaking recent work by Ryu and by Malitsky and Tam, it was shown that the number of factors can be reduced by one. A similar reduction was achieved recently by Campoy through a clever reformulation originally proposed by Kruger. All three splitting methods guarantee weak convergence to some solution of the underlying sum problem; strong convergence holds in the presence of uniform monotonicity. In this paper, we provide a case study when the operators involved are normal cone operators of subspaces and the solution set is thus the intersection of the subspaces. Even though these operators lack strict convexity, we show that striking conclusions are available in this case: strong (instead of weak) convergence and the solution obtained is (not arbitrary but) the projection onto the intersection. To illustrate our results, we also perform numerical experiments.},
  archive      = {J_SIOPT},
  author       = {Heinz H. Bauschke and Shambhavi Singh and Xianfu Wang},
  doi          = {10.1137/22M1483165},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {739-765},
  shortjournal = {SIAM J. Optim.},
  title        = {The splitting algorithms by ryu, by Malitsky–Tam, and by campoy applied to normal cones of linear subspaces converge strongly to the projection onto the intersection},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the global convergence of randomized coordinate gradient
descent for nonconvex optimization. <em>SIOPT</em>, <em>33</em>(2),
713–738. (<a href="https://doi.org/10.1137/21M1460375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work, we analyze the global convergence property of a coordinate gradient descent with random choice of coordinates and stepsizes for nonconvex optimization problems. Under generic assumptions, we prove that the algorithm iterate will almost surely escape strict saddle points of the objective function. As a result, the algorithm is guaranteed to converge to local minima if all saddle points are strict. Our proof is based on viewing the coordinate descent algorithm as a nonlinear random dynamical system and a quantitative finite block analysis of its linearization around saddle points.},
  archive      = {J_SIOPT},
  author       = {Ziang Chen and Yingzhou Li and Jianfeng Lu},
  doi          = {10.1137/21M1460375},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {713-738},
  shortjournal = {SIAM J. Optim.},
  title        = {On the global convergence of randomized coordinate gradient descent for nonconvex optimization},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Linear convergence of a proximal alternating minimization
method with extrapolation for <span
class="math inline"><strong>ℓ</strong><sub><strong>1</strong></sub></span>
-norm principal component analysis. <em>SIOPT</em>, <em>33</em>(2),
684–712. (<a href="https://doi.org/10.1137/21M1434507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A popular robust alternative of the classic principal component analysis (PCA) is the -norm PCA (L1-PCA), which aims to find a subspace that captures the most variation in a dataset as measured by the -norm. L1-PCA has shown great promise in alleviating the effect of outliers in data analytic applications. However, it gives rise to a challenging nonsmooth, nonconvex optimization problem, for which existing algorithms are either not scalable or lack strong theoretical guarantees on their convergence behavior. In this paper, we propose a proximal alternating minimization method with extrapolation (PAMe) for solving a two-block reformulation of the L1-PCA problem. We then show that for both the L1-PCA problem and its two-block reformulation, the Kurdyka–Łojasiewicz exponent at any of the limiting critical points is . This allows us to establish the linear convergence of the sequence of iterates generated by PAMe and to determine the criticality of the limit of the sequence with respect to both the L1-PCA problem and its two-block reformulation. To complement our theoretical development, we show via numerical experiments on both synthetic and real-world datasets that PAMe is competitive with a host of existing methods. Our results not only significantly advance the convergence theory of iterative methods for L1-PCA but also demonstrate the potential of our proposed method in applications.},
  archive      = {J_SIOPT},
  author       = {Peng Wang and Huikang Liu and Anthony Man-Cho So},
  doi          = {10.1137/21M1434507},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {684-712},
  shortjournal = {SIAM J. Optim.},
  title        = {Linear convergence of a proximal alternating minimization method with extrapolation for \(\boldsymbol{\ell_1}\) -norm principal component analysis},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Understanding a class of decentralized and federated
optimization algorithms: A multirate feedback control perspective.
<em>SIOPT</em>, <em>33</em>(2), 652–683. (<a
href="https://doi.org/10.1137/22M1475648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Distributed algorithms have been playing an increasingly important role in many applications such as machine learning, signal processing, and control. Significant research efforts have been devoted to developing and analyzing new algorithms for various applications. In this work, we provide a fresh perspective to understand, analyze, and design distributed optimization algorithms. Through the lens of multirate feedback control, we show that a wide class of distributed algorithms, including popular decentralized/federated schemes, can be viewed as discretizing a certain continuous-time feedback control system, possibly with multiple sampling rates, such as decentralized gradient descent, gradient tracking, and federated averaging. This key observation not only allows us to develop a generic framework to analyze the convergence of the entire algorithm class, but, more importantly, it also leads to an interesting way of designing new distributed algorithms. We develop the theory behind our framework and provide examples to highlight how the framework can be used in practice.},
  archive      = {J_SIOPT},
  author       = {Xinwei Zhang and Mingyi Hong and Nicola Elia},
  doi          = {10.1137/22M1475648},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {652-683},
  shortjournal = {SIAM J. Optim.},
  title        = {Understanding a class of decentralized and federated optimization algorithms: A multirate feedback control perspective},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Convergence of a class of nonmonotone descent methods for
kurdyka–łojasiewicz optimization problems. <em>SIOPT</em>,
<em>33</em>(2), 638–651. (<a
href="https://doi.org/10.1137/22M1469663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This note is concerned with a class of nonmonotone descent methods for minimizing a proper lower semicontinuous Kurdyka–Łojasiewicz (KL) function , which generates a sequence satisfying a nonmonotone decrease condition and a relative error tolerance. Under suitable assumptions, we prove that the whole sequence converges to a limiting critical point of , and, when is a KL function of exponent , the convergence admits a linear rate if and a sublinear rate associated to if . These assumptions are shown to be sufficient and necessary if in addition is weakly convex on a neighborhood of the set of critical points. Our results not only extend the convergence results of monotone descent methods for KL optimization problems but also resolve the convergence problem on the iterate sequence generated by a class of nonmonotone line search algorithms for nonconvex and nonsmooth problems.},
  archive      = {J_SIOPT},
  author       = {Yitian Qian and Shaohua Pan},
  doi          = {10.1137/22M1469663},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {638-651},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergence of a class of nonmonotone descent methods for kurdyka–Łojasiewicz optimization problems},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mini-batch risk forms. <em>SIOPT</em>, <em>33</em>(2),
615–637. (<a href="https://doi.org/10.1137/22M1503774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Risk forms are real functionals of two arguments: a bounded measurable function on a Polish space and a probability measure on that space. They are convenient mathematical structures adapting the coherent risk measures to the situation of a variable reference probability measure. We introduce a new class of risk forms called mini-batch forms. We construct them by using a random empirical probability measure as the second argument and by post-composition with the expected value operator. We prove that coherent and law invariant risk forms generate mini-batch risk forms which are well defined on the space of integrable random variables, and we derive their dual representation. We demonstrate how unbiased stochastic subgradients of such risk forms can be constructed. Then, we consider pre-compositions of mini-batch risk forms with nonsmooth and nonconvex functions, which are differentiable in a generalized way, and we derive generalized subgradients and unbiased stochastic subgradients of such compositions. Finally, we study the dependence of risk forms and mini-batch risk forms on perturbation of the probability measure and establish quantitative stability in terms of optimal transport metrics. We obtain finite-sample expected error estimates for mini-batch risk forms involving functions on a finite-dimensional space.},
  archive      = {J_SIOPT},
  author       = {Darinka Dentcheva and Andrzej Ruszczyński},
  doi          = {10.1137/22M1503774},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {615-637},
  shortjournal = {SIAM J. Optim.},
  title        = {Mini-batch risk forms},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Discrete optimal transport with independent marginals is
#p-hard. <em>SIOPT</em>, <em>33</em>(2), 589–614. (<a
href="https://doi.org/10.1137/22M1482044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study the computational complexity of the optimal transport problem that evaluates the Wasserstein distance between the distributions of two -dimensional discrete random vectors. The best known algorithms for this problem run in polynomial time in the maximum of the number of atoms of the two distributions. However, if the components of either random vector are independent, then this number can be exponential in even though the size of the problem description scales linearly with . We prove that the described optimal transport problem is #P-hard even if all components of the first random vector are independent uniform Bernoulli random variables, while the second random vector has merely two atoms, and even if only approximate solutions are sought. We also develop a dynamic programming–type algorithm that approximates the Wasserstein distance in pseudo-polynomial time when the components of the first random vector follow arbitrary independent discrete distributions, and we identify special problem instances that can be solved exactly in strongly polynomial time.},
  archive      = {J_SIOPT},
  author       = {Bahar Taşkesen and Soroosh Shafieezadeh-Abadeh and Daniel Kuhn and Karthik Natarajan},
  doi          = {10.1137/22M1482044},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {589-614},
  shortjournal = {SIAM J. Optim.},
  title        = {Discrete optimal transport with independent marginals is #P-hard},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spectrahedral regression. <em>SIOPT</em>, <em>33</em>(2),
553–588. (<a href="https://doi.org/10.1137/21M1455899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Convex regression is the problem of fitting a convex function to a data set consisting of input-output pairs. We present a new approach to this problem called spectrahedral regression, in which we fit a spectrahedral function to the data, i.e., a function that is the maximum eigenvalue of an affine matrix expression of the input. This method represents a significant generalization of polyhedral (also called max-affine) regression, in which a polyhedral function (a maximum of a fixed number of affine functions) is fit to the data. We prove bounds on how well spectrahedral functions can approximate arbitrary convex functions via statistical risk analysis. We also analyze an alternating minimization algorithm for the nonconvex optimization problem of fitting the best spectrahedral function to a given data set. We show that this algorithm converges geometrically with high probability to a small ball around the optimal parameter given a good initialization. Finally, we demonstrate the utility of our approach with experiments on synthetic data sets as well as real data arising in applications such as economics and engineering design.},
  archive      = {J_SIOPT},
  author       = {Eliza O’Reilly and Venkat Chandrasekaran},
  doi          = {10.1137/21M1455899},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {553-588},
  shortjournal = {SIAM J. Optim.},
  title        = {Spectrahedral regression},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Minimizing a low-dimensional convex function over a
high-dimensional cube. <em>SIOPT</em>, <em>33</em>(2), 538–552. (<a
href="https://doi.org/10.1137/22M1489988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. For a matrix , and a convex function , we are interested in minimizing over the set . We will study separable convex functions and sharp convex functions . Moreover, the matrix is unknown to us. Only the number of rows and are revealed. The composite function is presented by a zeroth and first order oracle only. Our main result is a proximity theorem that ensures that an integral minimum and a continuous minimum for separable convex and sharp convex functions are always “close” by. This will be a key ingredient in developing an algorithm for detecting an integer minimum that achieves a running time of roughly . In the special case when is given explicitly and is separable convex one can also adapt an algorithm of Hochbaum and Shanthikumar [J. ACM, 37 (1990), pp. 843–862]. The running time of this adapted algorithm matches the running time of our general algorithm.},
  archive      = {J_SIOPT},
  author       = {Christoph Hunkenschröder and Sebastian Pokutta and Robert Weismantel},
  doi          = {10.1137/22M1489988},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {538-552},
  shortjournal = {SIAM J. Optim.},
  title        = {Minimizing a low-dimensional convex function over a high-dimensional cube},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Construction of multivariate polynomial approximation
kernels via semidefinite programming. <em>SIOPT</em>, <em>33</em>(2),
513–537. (<a href="https://doi.org/10.1137/22M1494476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we construct a hierarchy of multivariate polynomial approximation kernels for uniformly continuous functions on the hypercube via semidefinite programming. We give details on the implementation of the semidefinite programs defining the kernels. Finally, we show how symmetry reduction may be performed to increase numerical tractability.},
  archive      = {J_SIOPT},
  author       = {Felix Kirschner and Etienne de Klerk},
  doi          = {10.1137/22M1494476},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {513-537},
  shortjournal = {SIAM J. Optim.},
  title        = {Construction of multivariate polynomial approximation kernels via semidefinite programming},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Convex relaxations of integral variational problems:
Pointwise dual relaxation and sum-of-squares optimization.
<em>SIOPT</em>, <em>33</em>(2), 481–512. (<a
href="https://doi.org/10.1137/21M1455127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present a method for finding lower bounds on the global infima of integral variational problems, wherein is minimized over functions satisfying given equality or inequality constraints. Each constraint may be imposed over or its boundary, either pointwise or in an integral sense. These global minimizations are generally nonconvex and intractable. We formulate a particular convex maximization, here called the pointwise dual relaxation (PDR), whose supremum is a lower bound on the infimum of the original problem. The PDR can be derived by dualizing and relaxing the original problem; its constraints are pointwise equalities or inequalities over finite-dimensional sets rather than over infinite-dimensional function spaces. When the original minimization can be specified by polynomial functions of , the PDR can be further relaxed by replacing pointwise inequalities with polynomial sum-of-squares (SOS) conditions. The resulting SOS program is computationally tractable when the dimensions and the number of constraints are not too large. The framework presented here generalizes an approach of Valmorbida, Ahmadi, and Papachristodoulou [IEEE Trans. Automat. Control, 61 (2016), pp. 1649–1654]. We prove that the optimal lower bound given by the PDR is sharp for several classes of problems, whose special cases include leading eigenvalues of Sturm–Liouville problems and optimal constants of Poincaré inequalities. For these same classes, we prove that SOS relaxations of the PDR converge to the sharp lower bound as polynomial degrees are increased. Convergence of SOS computations in practice is illustrated for several examples.},
  archive      = {J_SIOPT},
  author       = {Alexander Chernyavsky and Jason J. Bramburger and Giovanni Fantuzzi and David Goluskin},
  doi          = {10.1137/21M1455127},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {481-512},
  shortjournal = {SIAM J. Optim.},
  title        = {Convex relaxations of integral variational problems: Pointwise dual relaxation and sum-of-squares optimization},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On conditional risk assessments in scenario optimization.
<em>SIOPT</em>, <em>33</em>(2), 455–480. (<a
href="https://doi.org/10.1137/21M1451385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Scenario optimization is a data-driven technique in which one optimizes an objective function subject to a set of constraints, each given by a data point. In this article, we show that probabilistic claims on the violation of out-of-sample constraints (risk) conditional on the complexity of the solution (number of elements in the data set by which the solution can be reconstructed) are impossible if one does not use extra information in addition to the data. While this article establishes this fundamental limitation, it also proves that a “mild” prior suffices to draw strong conditional conclusions. Precisely, a prior on the distribution of the complexity (which has support in a finite dimensional space) allows one to effectively bound the conditional distribution of the risk. Besides its intrinsic epistemological value, this result is useful for the conditional quantification of the risk of constraints violation in various application endeavors.},
  archive      = {J_SIOPT},
  author       = {Simone Garatti and Marco C. Campi},
  doi          = {10.1137/21M1451385},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {455-480},
  shortjournal = {SIAM J. Optim.},
  title        = {On conditional risk assessments in scenario optimization},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal convergence rates for the proximal bundle method.
<em>SIOPT</em>, <em>33</em>(2), 424–454. (<a
href="https://doi.org/10.1137/21M1428601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study convergence rates of the classic proximal bundle method for a variety of nonsmooth convex optimization problems. We show that, without any modification, this algorithm adapts to converge faster in the presence of smoothness or a Hölder growth condition. Our analysis reveals that with a constant stepsize, the bundle method is adaptive, yet it exhibits suboptimal convergence rates. We overcome this shortcoming by proposing nonconstant stepsize schemes with optimal rates. These schemes use function information such as growth constants, which might be prohibitive in practice. We provide a parallelizable variant of the bundle method that can be applied without prior knowledge of function parameters while maintaining near-optimal rates. The practical impact of this scheme is limited since we incur a (parallelizable) log factor in the complexity. These results improve on the scarce existing convergence rates and provide a unified analysis approach across problem settings and algorithmic details. Numerical experiments support our findings.},
  archive      = {J_SIOPT},
  author       = {Mateo Díaz and Benjamin Grimmer},
  doi          = {10.1137/21M1428601},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {424-454},
  shortjournal = {SIAM J. Optim.},
  title        = {Optimal convergence rates for the proximal bundle method},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nonlinear gradient mappings and stochastic optimization: A
general framework with applications to heavy-tail noise. <em>SIOPT</em>,
<em>33</em>(2), 394–423. (<a
href="https://doi.org/10.1137/21M145896X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We introduce a general framework for nonlinear stochastic gradient descent (SGD) for the scenarios when gradient noise exhibits heavy tails. The proposed framework subsumes several popular nonlinearity choices, like clipped, normalized, signed, or quantized gradient, but we also consider novel nonlinearity choices. We establish for the considered class of methods strong convergence guarantees assuming a strongly convex cost function with Lipschitz continuous gradients under very general assumptions on the gradient noise. Most notably, we show that, for a nonlinearity with bounded outputs and for the gradient noise that may not have finite moments of order greater than one, the nonlinear SGD’s mean squared error (MSE), or equivalently, the expected cost function’s optimality gap, converges to zero at rate , . In contrast, for the same noise setting, the linear SGD generates a sequence with unbounded variances. Furthermore, for general nonlinearities that can be decoupled componentwise and a class of joint nonlinearities, we show that the nonlinear SGD asymptotically (locally) achieves an rate in the weak convergence sense and explicitly quantify the corresponding asymptotic variance. Experiments show that, while our framework is more general than existing studies of SGD under heavy-tail noise, several easy-to-implement nonlinearities from our framework are competitive with state-of-the-art alternatives on real datasets with heavy-tail noises.},
  archive      = {J_SIOPT},
  author       = {Dus̆an Jakovetić and Dragana Bajović and Anit Kumar Sahu and Soummya Kar and Nemanja Milos̆ević and Dus̆an Stamenković},
  doi          = {10.1137/21M145896X},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {394-423},
  shortjournal = {SIAM J. Optim.},
  title        = {Nonlinear gradient mappings and stochastic optimization: A general framework with applications to heavy-tail noise},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inertial proximal block coordinate method for a class of
nonsmooth sum-of-ratios optimization problems. <em>SIOPT</em>,
<em>33</em>(2), 361–393. (<a
href="https://doi.org/10.1137/22M1472000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we consider a class of nonsmooth sum-of-ratios fractional optimization problems with block structure. This model class is ubiquitous and encompasses several important nonsmooth optimization problems in the literature. We first propose an inertial proximal block coordinate method for solving this class of problems by exploiting the underlying structure. The global convergence of our method is guaranteed under the Kurdyka–Łojasiewicz (KL) property and some mild assumptions. We then identify the explicit exponents of the KL property for three important structured fractional optimization problems. In particular, for the sparse generalized eigenvalue problem with either cardinality regularization or sparsity constraint, we show that the KL exponents are 1/2, and so the proposed method exhibits a linear convergence rate. Finally, we illustrate our theoretical results with both analytic and simulated numerical examples.},
  archive      = {J_SIOPT},
  author       = {Radu Ioan Boţ and Minh N. Dao and Guoyin Li},
  doi          = {10.1137/22M1472000},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {361-393},
  shortjournal = {SIAM J. Optim.},
  title        = {Inertial proximal block coordinate method for a class of nonsmooth sum-of-ratios optimization problems},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Convex optimization problems on differentiable sets.
<em>SIOPT</em>, <em>33</em>(1), 338–359. (<a
href="https://doi.org/10.1137/22M1482494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Given a closed convex set in a Banach space , motivated by the continuity and Fréchet differentiability of introduced, respectively, in [D. Gale and V. Klee, Math. Scand., 7 (1959), pp. 379–391] and [X. Y. Zheng, SIAM J. Optim., 30 (2020), pp. 490–512], this paper considers the -differentiability, subdifferentiability, and Gâteaux differentiability of . Using the technique of variational analysis, it is proved that is -differentiable (resp., subdifferentiable or Gâteaux differentiable) if and only if for every continuous convex function with the corresponding constrained optimization problem is 2/ -order-well-posed solvable (resp., generalized well-posed solvable or weak well-posed solvable). It is also proved that if the conjugate function of a continuous convex function on is -differentiable on , then for every closed convex set in with the corresponding optimization problem is -order-well-posed solvable. As a byproduct, every constrained convex optimization problem with a strongly convex quadratic objective function is proved to be globally second-order-well-posed solvable. Our main results are new even in the case of finite dimensional spaces.},
  archive      = {J_SIOPT},
  author       = {Xi Yin Zheng},
  doi          = {10.1137/22M1482494},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {338-359},
  shortjournal = {SIAM J. Optim.},
  title        = {Convex optimization problems on differentiable sets},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A bundle trust region algorithm for minimizing locally
lipschitz functions. <em>SIOPT</em>, <em>33</em>(1), 319–337. (<a
href="https://doi.org/10.1137/22M1476125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a new algorithm for minimizing locally Lipschitz functions that combines both the bundle and trust region techniques. Based on the bundle methods the objective function is approximated by a piecewise linear working model which is updated by adding cutting planes at unsuccessful trial steps. The algorithm defines, at each iteration, a new trial point by solving a subproblem that employs the working model in the objective function subject to a region, which is called the trust region. The algorithm is studied from both theoretical and practical points of view. Under a assumption on the objective function, global convergence of it is verified to stationary points. In order to demonstrate the reliability and efficiency of the proposed algorithm, a MATLAB implementation of it is prepared and numerical experiments have been made using some academic nonsmooth test problems. Computational results show that the developed method is efficient for solving nonsmooth and nonconvex optimization problems.},
  archive      = {J_SIOPT},
  author       = {Najmeh Hoseini Monjezi},
  doi          = {10.1137/22M1476125},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {319-337},
  shortjournal = {SIAM J. Optim.},
  title        = {A bundle trust region algorithm for minimizing locally lipschitz functions},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The computation of approximate generalized feedback nash
equilibria. <em>SIOPT</em>, <em>33</em>(1), 294–318. (<a
href="https://doi.org/10.1137/21M142530X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present the concept of a generalized feedback Nash equilibrium (GFNE) in dynamic games, extending the feedback Nash equilibrium concept to games in which players are subject to state and input constraints. We formalize necessary and sufficient conditions for (local) GFNE solutions at the trajectory level, which enable the development of efficient numerical methods for their computation. Specifically, we propose a Newton-style method for finding game trajectories which satisfy necessary conditions for an equilibrium, which can then be checked against sufficiency conditions. We show that the evaluation of the necessary conditions in general requires computing a series of nested, implicitly defined derivatives, which quickly becomes intractable. To this end, we introduce an approximation to the necessary conditions which is amenable to efficient evaluation and, in turn, computation of solutions. We call the solutions to the approximate necessary conditions the generalized feedback quasi-Nash equilibria, and we introduce numerical methods for their computation. In particular, we develop a sequential linear-quadratic (LQ) game approach, in which an LQ local approximation of the game is solved at each iteration. The development of this method relies on the ability to compute a GFNE to inequality- and equality-constrained LQ games, and therefore specific methods for the solution of these special cases are developed in detail. We demonstrate the effectiveness of the proposed solution approach on a dynamic game arising in an autonomous driving application.},
  archive      = {J_SIOPT},
  author       = {Forrest Laine and David Fridovich-Keil and Chih-Yuan Chiu and Claire Tomlin},
  doi          = {10.1137/21M142530X},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {294-318},
  shortjournal = {SIAM J. Optim.},
  title        = {The computation of approximate generalized feedback nash equilibria},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On local minimizers of nonconvex homogeneous quadratically
constrained quadratic optimization with at most two constraints.
<em>SIOPT</em>, <em>33</em>(1), 267–293. (<a
href="https://doi.org/10.1137/21M1416746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study nonconvex homogeneous quadratically constrained quadratic optimization with constraints, denoted by (QQm). (QQ2) contains (QQ1), the trust region subproblem (TRS) and its generalization (GTRS), and the ellipsoid regularized total least squares problem as special cases. It is known that there is a necessary and sufficient optimality condition for the global minimizer of (QQ2). In this paper, we first show that any local minimizer of (QQ1) is globally optimal. Unlike its special case (TRS) with at most one local nonglobal minimizer, (QQ2) may have infinitely many local nonglobal minimizers. At any local nonglobal minimizer of (QQ2), both the linear independence constraint qualification and the strict complementary slackness condition hold, and the Hessian of the Lagrangian has exactly one negative eigenvalue. As the main contribution, we prove that the standard second-order sufficient optimality condition for any strict local nonglobal minimizer of (QQ2) remains necessary. It turns out that finding all local nonglobal minimizers of (GTRS) or proving the nonexistence can be done in polynomial time. More applications and the impossibility of extending our main result are discussed.},
  archive      = {J_SIOPT},
  author       = {Mengmeng Song and Hongying Liu and Jiulin Wang and Yong Xia},
  doi          = {10.1137/21M1416746},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {267-293},
  shortjournal = {SIAM J. Optim.},
  title        = {On local minimizers of nonconvex homogeneous quadratically constrained quadratic optimization with at most two constraints},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ALESQP: An augmented lagrangian equality-constrained SQP
method for optimization with general constraints. <em>SIOPT</em>,
<em>33</em>(1), 237–266. (<a
href="https://doi.org/10.1137/20M1378399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present a new algorithm for infinite-dimensional optimization with general constraints, called ALESQP. In short, ALESQP is an augmented Lagrangian method that penalizes inequality constraints and solves equality-constrained nonlinear optimization subproblems at every iteration. The subproblems are solved using a matrix-free trust-region sequential quadratic programming (SQP) method that takes advantage of iterative, i.e., inexact linear solvers, and is suitable for large-scale applications. A key feature of ALESQP is a constraint decomposition strategy that allows it to exploit problem-specific variable scalings and inner products. We analyze convergence of ALESQP under different assumptions. We show that strong accumulation points are stationary. Consequently, in finite dimensions ALESQP converges to a stationary point. In infinite dimensions we establish that weak accumulation points are feasible in many practical situations. Under additional assumptions we show that weak accumulation points are stationary. We present several infinite-dimensional examples where ALESQP shows remarkable discretization-independent performance in all of its iterative components, requiring a modest number of iterations to meet constraint tolerances at the level of machine precision. Also, we demonstrate a fully matrix-free solution of an infinite-dimensional problem with nonlinear inequality constraints.},
  archive      = {J_SIOPT},
  author       = {Harbir Antil and Drew P. Kouri and Denis Ridzal},
  doi          = {10.1137/20M1378399},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {237-266},
  shortjournal = {SIAM J. Optim.},
  title        = {ALESQP: An augmented lagrangian equality-constrained SQP method for optimization with general constraints},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Constrained consensus-based optimization. <em>SIOPT</em>,
<em>33</em>(1), 211–236. (<a
href="https://doi.org/10.1137/22M1471304">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work we are interested in the construction of numerical methods for high-dimensional constrained nonlinear optimization problems by particle-based gradient-free techniques. A consensus-based optimization (CBO) approach combined with suitable penalization techniques is introduced for this purpose. The method relies on a reformulation of the constrained minimization problem in an unconstrained problem for a penalty function and extends to the constrained settings of the class of CBO methods. Exact penalization is employed and, since the optimal penalty parameter is unknown, an iterative strategy is proposed that successively updates the parameter based on the constrained violation. Using a mean-field description of the many particle limit of the arising CBO dynamics, we are able to show convergence of the proposed method to the minimum for general nonlinear constrained problems. Properties of the new algorithm are analyzed. Several numerical examples, also in high dimensions, illustrate the theoretical findings and the good performance of the new numerical method.},
  archive      = {J_SIOPT},
  author       = {Giacomo Borghi and Michael Herty and Lorenzo Pareschi},
  doi          = {10.1137/22M1471304},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {211-236},
  shortjournal = {SIAM J. Optim.},
  title        = {Constrained consensus-based optimization},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Iteration complexity of an inner accelerated inexact
proximal augmented lagrangian method based on the classical lagrangian
function. <em>SIOPT</em>, <em>33</em>(1), 181–210. (<a
href="https://doi.org/10.1137/20M136147X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper establishes the iteration complexity of an inner accelerated inexact proximal augmented Lagrangian (IAIPAL) method for solving linearly constrained smooth nonconvex composite optimization problems that is based on the classical augmented Lagrangian (AL) function. More specifically, each IAIPAL iteration consists of inexactly solving a proximal AL subproblem by an accelerated composite gradient (ACG) method followed by a classical Lagrange multiplier update. Under the assumption that the domain of the composite function is bounded and the problem has a Slater point, it is shown that IAIPAL generates an approximate stationary solution in ACG iterations where is a tolerance for both stationarity and feasibility. Moreover, the above bound is derived without assuming that the initial point is feasible. Finally, numerical results are presented to demonstrate the strong practical performance of IAIPAL.},
  archive      = {J_SIOPT},
  author       = {Weiwei Kong and Jefferson G. Melo and Renato D. C. Monteiro},
  doi          = {10.1137/20M136147X},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {181-210},
  shortjournal = {SIAM J. Optim.},
  title        = {Iteration complexity of an inner accelerated inexact proximal augmented lagrangian method based on the classical lagrangian function},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A two-timescale stochastic algorithm framework for bilevel
optimization: Complexity analysis and application to actor-critic.
<em>SIOPT</em>, <em>33</em>(1), 147–180. (<a
href="https://doi.org/10.1137/20M1387341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper analyzes a two-timescale stochastic algorithm framework for bilevel optimization. Bilevel optimization is a class of problems which exhibits a two-level structure, and its goal is to minimize an outer objective function with variables which are constrained to be the optimal solution to an (inner) optimization problem. We consider the case when the inner problem is unconstrained and strongly convex, while the outer problem is constrained and has a smooth objective function. We propose a two-timescale stochastic approximation (TTSA) algorithm for tackling such a bilevel problem. In the algorithm, a stochastic gradient update with a larger step size is used for the inner problem, while a projected stochastic gradient update with a smaller step size is used for the outer problem. We analyze the convergence rates for the TTSA algorithm under various settings: when the outer problem is strongly convex (resp. weakly convex), the TTSA algorithm finds an -optimal (resp. -stationary) solution, where is the total iteration number. As an application, we show that a two-timescale natural actor-critic proximal policy optimization algorithm can be viewed as a special case of our TTSA framework. Importantly, the natural actor-critic algorithm is shown to converge at a rate of in terms of the gap in expected discounted reward compared to a global optimal policy.},
  archive      = {J_SIOPT},
  author       = {Mingyi Hong and Hoi-To Wai and Zhaoran Wang and Zhuoran Yang},
  doi          = {10.1137/20M1387341},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {147-180},
  shortjournal = {SIAM J. Optim.},
  title        = {A two-timescale stochastic algorithm framework for bilevel optimization: Complexity analysis and application to actor-critic},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Geometric duality results and approximation algorithms for
convex vector optimization problems. <em>SIOPT</em>, <em>33</em>(1),
116–146. (<a href="https://doi.org/10.1137/21M1458788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study geometric duality for convex vector optimization problems. For a primal problem with a -dimensional objective space, we formulate a dual problem with a -dimensional objective space. Consequently, different from an existing approach, the geometric dual problem does not depend on a fixed direction parameter, and the resulting dual image is a convex cone. We prove a one-to-one correspondence between certain faces of the primal and dual images. In addition, we show that a polyhedral approximation for one image gives rise to a polyhedral approximation for the other. Based on this, we propose a geometric dual algorithm which solves the primal and dual problems simultaneously and is free of direction-biasedness. We also modify an existing direction-free primal algorithm in such a way that it solves the dual problem as well. We test the performance of the algorithms for randomly generated problem instances by using the so-called primal error and hypervolume indicator as performance measures.},
  archive      = {J_SIOPT},
  author       = {Çağin Ararat and Sіmay Tekgül and Fіrdevs Ulus},
  doi          = {10.1137/21M1458788},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {116-146},
  shortjournal = {SIAM J. Optim.},
  title        = {Geometric duality results and approximation algorithms for convex vector optimization problems},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A unified analysis of descent sequences in weakly convex
optimization, including convergence rates for bundle methods.
<em>SIOPT</em>, <em>33</em>(1), 89–115. (<a
href="https://doi.org/10.1137/21M1465445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present a framework for analyzing convergence and local rates of convergence of a class of descent algorithms, assuming the objective function is weakly convex. The framework is general, in the sense that it combines the possibility of explicit iterations (based on the gradient or a subgradient at the current iterate), implicit iterations (using a subgradient at the next iteration, like in the proximal schemes), as well as iterations when the associated subgradient is specially constructed and does not correspond either to the current or the next point (this is the case of descent steps in bundle methods). Under the subdifferential-based error bound on the distance to critical points, linear rates of convergence are established. Our analysis applies, among other techniques, to prox-descent for decomposable functions, the proximal-gradient method for a sum of functions, redistributed bundle methods, and a class of algorithms that can be cast in the feasible descent framework for constrained optimization.},
  archive      = {J_SIOPT},
  author       = {Felipe Atenas and Claudia Sagastizábal and Paulo J. S. Silva and Mikhail Solodov},
  doi          = {10.1137/21M1465445},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {89-115},
  shortjournal = {SIAM J. Optim.},
  title        = {A unified analysis of descent sequences in weakly convex optimization, including convergence rates for bundle methods},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sum of squares decompositions of polynomials over their
gradient ideals with rational coefficients. <em>SIOPT</em>,
<em>33</em>(1), 63–88. (<a
href="https://doi.org/10.1137/21M1436245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Assessing nonnegativity of multivariate polynomials over the reals, through the computation of certificates of nonnegativity, is a topical issue in polynomial optimization. This is usually tackled through the computation of sum of squares decompositions which rely on efficient numerical solvers for semidefinite programming. This method faces two difficulties. The first one is that the certificates obtained this way are approximate and then nonexact. The second one is due to the fact that not all nonnegative polynomials are sums of squares. In this paper, we build on previous works by Parrilo and Nie, Demmel, and Sturmfels who introduced certificates of nonnegativity modulo gradient ideals. We prove that, actually, such certificates can be obtained exactly over the rationals if the polynomial under consideration has rational coefficients, and we provide exact algorithms to compute them. We analyze the bit complexity of these algorithms and deduce bitsize bounds of such certificates.},
  archive      = {J_SIOPT},
  author       = {Victor Magron and Mohab Safey El Din and Trung-Hieu Vu},
  doi          = {10.1137/21M1436245},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {63-88},
  shortjournal = {SIAM J. Optim.},
  title        = {Sum of squares decompositions of polynomials over their gradient ideals with rational coefficients},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Survey descent: A multipoint generalization of gradient
descent for nonsmooth optimization. <em>SIOPT</em>, <em>33</em>(1),
36–62. (<a href="https://doi.org/10.1137/21M1468450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. For strongly convex objectives that are smooth, the classical theory of gradient descent ensures linear convergence relative to the number of gradient evaluations. An analogous nonsmooth theory is challenging. Even when the objective is smooth at every iterate, the corresponding local models are unstable, and the number of cutting planes invoked by traditional remedies is difficult to bound, leading to convergence guarantees that are sublinear relative to the cumulative number of gradient evaluations. We instead propose a multipoint generalization of the gradient descent iteration for local optimization. While our iteration was designed with general objectives in mind, we are motivated by a “max-of-smooth” model that captures the subdifferential dimension at optimality. We prove linear convergence when the objective is itself max-of-smooth, and experiments suggest a more general phenomenon.},
  archive      = {J_SIOPT},
  author       = {X. Y. Han and Adrian S. Lewis},
  doi          = {10.1137/21M1468450},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {36-62},
  shortjournal = {SIAM J. Optim.},
  title        = {Survey descent: A multipoint generalization of gradient descent for nonsmooth optimization},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reducing the complexity of two classes of optimization
problems by inexact accelerated proximal gradient method.
<em>SIOPT</em>, <em>33</em>(1), 1–35. (<a
href="https://doi.org/10.1137/22M1469584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a double-loop inexact accelerated proximal gradient (APG) method for a strongly convex composite optimization problem with two smooth components of different smoothness constants and computational costs. Compared to APG, the inexact APG can reduce the time complexity for finding a near-stationary point when one smooth component has higher computational cost but a smaller smoothness constant than the other. The strongly convex composite optimization problem with this property arises from subproblems of a regularized augmented Lagrangian method for affine-constrained composite convex optimization and also from the smooth approximation for bilinear saddle-point structured nonsmooth convex optimization. We show that the inexact APG method can be applied to these two problems and reduce the time complexity for finding a near-stationary solution. Numerical experiments demonstrate significantly higher efficiency of our methods over an optimal primal-dual first-order method by Hamedani and Aybat [SIAM J. Optim., 31 (2021), pp. 1299–1329] and the gradient sliding method by Lan, Ouyang, and Zhou [arXiv2101.00143, 2021].},
  archive      = {J_SIOPT},
  author       = {Qihang Lin and Yangyang Xu},
  doi          = {10.1137/22M1469584},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {1-35},
  shortjournal = {SIAM J. Optim.},
  title        = {Reducing the complexity of two classes of optimization problems by inexact accelerated proximal gradient method},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
