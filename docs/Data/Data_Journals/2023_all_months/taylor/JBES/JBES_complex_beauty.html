<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JBES_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jbes---87">JBES - 87</h2>
<ul>
<li><details>
<summary>
(2023). Nonparametric, stochastic frontier models with multiple
inputs and outputs. <em>JBES</em>, <em>41</em>(4), 1391‚Äì1403. (<a
href="https://doi.org/10.1080/07350015.2022.2110882">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic frontier models along the lines of Aigner et al. are widely used to benchmark firms‚Äô performances in terms of efficiency. The models are typically fully parametric, with functional form specifications for the frontier as well as both the noise and the inefficiency processes. Studies such as Kumbhakar et al. have attempted to relax some of the restrictions in parametric models, but so far all such approaches are limited to a univariate response variable. Some (e.g., Simar and Zelenyuk; Kuosmanen and Johnson) have proposed nonparametric estimation of directional distance functions to handle multiple inputs and outputs, raising issues of endogeneity that are either ignored or addressed by imposing restrictive and implausible assumptions. This article extends nonparametric methods developed by Simar et al. and Hafner et al. to allow multiple inputs and outputs in an almost fully nonparametric framework while avoiding endogeneity problems. We discuss properties of the resulting estimators, and examine their finite-sample performance through Monte Carlo experiments. Practical implementation of the method is illustrated using data on U.S. commercial banks.},
  archive      = {J_JBES},
  author       = {L√©opold Simar and Paul W. Wilson},
  doi          = {10.1080/07350015.2022.2110882},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1391-1403},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Nonparametric, stochastic frontier models with multiple inputs and outputs},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). From conditional quantile regression to marginal quantile
estimation with applications to missing data and causal inference.
<em>JBES</em>, <em>41</em>(4), 1377‚Äì1390. (<a
href="https://doi.org/10.1080/07350015.2022.2140158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well known that information on the conditional distribution of an outcome variable given covariates can be used to obtain an enhanced estimate of the marginal outcome distribution. This can be done easily by integrating out the marginal covariate distribution from the conditional outcome distribution. However, to date, no analogy has been established between marginal quantile and conditional quantile regression. This article provides a link between them. We propose two novel marginal quantile and marginal mean estimation approaches through conditional quantile regression when some of the outcomes are missing at random. The first of these approaches is free from the need to choose a propensity score. The second is double robust to model misspecification: it is consistent if either the conditional quantile regression model is correctly specified or the missing mechanism of outcome is correctly specified. Consistency and asymptotic normality of the two estimators are established, and the second double robust estimator achieves the semiparametric efficiency bound. Extensive simulation studies are performed to demonstrate the utility of the proposed approaches. An application to causal inference is introduced. For illustration, we apply the proposed methods to a job training program dataset.},
  archive      = {J_JBES},
  author       = {Huijuan Ma and Jing Qin and Yong Zhou},
  doi          = {10.1080/07350015.2022.2140158},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1377-1390},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {From conditional quantile regression to marginal quantile estimation with applications to missing data and causal inference},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spectral estimation of large stochastic blockmodels with
discrete nodal covariates. <em>JBES</em>, <em>41</em>(4), 1364‚Äì1376. (<a
href="https://doi.org/10.1080/07350015.2022.2139709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many applications of network analysis, it is important to distinguish between observed and unobserved factors affecting network structure. We show that a network model with discrete unobserved link heterogeneity and binary (or discrete) covariates corresponds to a stochastic blockmodel (SBM). We develop a spectral estimator for the effect of covariates on link probabilities, exploiting the correspondence of SBMs and generalized random dot product graphs (GRDPG). We show that computing our estimator is much faster than standard variational expectation‚Äìmaximization algorithms and scales well for large networks. Monte Carlo experiments suggest that the estimator performs well under different data generating processes. Our application to Facebook data shows evidence of homophily in gender, role and campus-residence, while allowing us to discover unobserved communities. Finally, we establish asymptotic normality of our estimators.},
  archive      = {J_JBES},
  author       = {Angelo Mele and Lingxin Hao and Joshua Cape and Carey E. Priebe},
  doi          = {10.1080/07350015.2022.2139709},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1364-1376},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Spectral estimation of large stochastic blockmodels with discrete nodal covariates},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast variational bayes methods for multinomial probit
models. <em>JBES</em>, <em>41</em>(4), 1352‚Äì1363. (<a
href="https://doi.org/10.1080/07350015.2022.2139267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multinomial probit model is often used to analyze choice behavior. However, estimation with existing Markov chain Monte Carlo (MCMC) methods is computationally costly, which limits its applicability to large choice datasets. This article proposes a variational Bayes method that is accurate and fast, even when a large number of choice alternatives and observations are considered. Variational methods usually require an analytical expression for the unnormalized posterior density and an adequate choice of variational family. Both are challenging to specify in a multinomial probit, which has a posterior that requires identifying restrictions and is augmented with a large set of latent utilities. We employ a spherical transformation on the covariance matrix of the latent utilities to construct an unnormalized augmented posterior that identifies the parameters, and use the conditional posterior of the latent utilities as part of the variational family. The proposed method is faster than MCMC, and can be made scalable to both a large number of choice alternatives and a large number of observations. The accuracy and scalability of our method is illustrated in numerical experiments and real purchase data with one million observations.},
  archive      = {J_JBES},
  author       = {Rub√©n Loaiza-Maya and Didier Nibbering},
  doi          = {10.1080/07350015.2022.2139267},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1352-1363},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Fast variational bayes methods for multinomial probit models},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identifying structural vector autoregression via leptokurtic
economic shocks. <em>JBES</em>, <em>41</em>(4), 1341‚Äì1351. (<a
href="https://doi.org/10.1080/07350015.2022.2134872">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We revisit the generalized method of moments (GMM) estimation of the non-Gaussian structural vector autoregressive (SVAR) model. It is shown that in the n -dimensional SVAR model, global and local identification of the contemporaneous impact matrix is achieved with as few as n 2 + n ( n ‚àí 1 ) / 2 n 2 + n ( n ‚àí 1 ) / 2 n2+n(n‚àí1)/2 suitably selected moment conditions, when at least n ‚Äì 1 of the structural errors are all leptokurtic (or platykurtic). We also relax the potentially problematic assumption of mutually independent structural errors in part of the previous literature to the requirement that the errors be mutually uncorrelated. Moreover, we assume the error term to be only serially uncorrelated, not independent in time, which allows for univariate conditional heteroscedasticity in its components. A small simulation experiment highlights the good properties of the estimator and the proposed moment selection procedure. The use of the methods is illustrated by means of an empirical application to the effect of a tax increase on U.S. gasoline consumption and carbon dioxide emissions.},
  archive      = {J_JBES},
  author       = {Markku Lanne and Keyan Liu and Jani Luoto},
  doi          = {10.1080/07350015.2022.2134872},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1341-1351},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Identifying structural vector autoregression via leptokurtic economic shocks},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Teacher-to-classroom assignment and student achievement.
<em>JBES</em>, <em>41</em>(4), 1328‚Äì1340. (<a
href="https://doi.org/10.1080/07350015.2022.2126480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the effects of counterfactual teacher-to-classroom assignments on average student achievement in U.S. elementary and middle schools. We use the Measures of Effective Teaching (MET) experiment to semiparametrically identify the average reallocation effects (AREs) of such assignments. Our identification strategy exploits the random assignment of teachers to classrooms in MET schools. To account for noncompliance of some students and teachers to the random assignment, we develop and implement a semiparametric instrumental variables estimator. We find that changes in within-district teacher assignments could have appreciable effects on student achievement. Unlike policies that aim at changing the pool of teachers (e.g., teacher tenure policies or class-size reduction measures), alternative teacher-to-classroom assignments do not require that districts hire new teachers or lay off existing ones; they raise student achievement through a more efficient deployment of existing teachers.},
  archive      = {J_JBES},
  author       = {Bryan S. Graham and Geert Ridder and Petra Thiemann and Gema Zamarro},
  doi          = {10.1080/07350015.2022.2126480},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1328-1340},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Teacher-to-classroom assignment and student achievement},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalized covariance estimator. <em>JBES</em>,
<em>41</em>(4), 1315‚Äì1327. (<a
href="https://doi.org/10.1080/07350015.2022.2120486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a class of semi-parametric dynamic models with iid errors, including the nonlinear mixed causal-noncausal Vector Autoregressive (VAR), Double-Autoregressive (DAR) and stochastic volatility models. To estimate the parameters characterizing the (nonlinear) serial dependence, we introduce a generic Generalized Covariance (GCov) estimator, which minimizes a residual-based multivariate portmanteau statistic. In comparison to the standard methods of moments, the GCov estimator has an interpretable objective function, circumvents the inversion of high-dimensional matrices, and achieves semi-parametric efficiency in one step. We derive the asymptotic properties of the GCov estimator and show its semi-parametric efficiency. We also prove that the associated residual-based portmanteau statistic is asymptotically chi-square distributed. The finite sample performance of the GCov estimator is illustrated in a simulation study. The estimator is then applied to a dynamic model of commodity futures.},
  archive      = {J_JBES},
  author       = {Christian Gourieroux and Joann Jasiak},
  doi          = {10.1080/07350015.2022.2120486},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1315-1327},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Generalized covariance estimator},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Changepoint detection in heteroscedastic random coefficient
autoregressive models. <em>JBES</em>, <em>41</em>(4), 1300‚Äì1314. (<a
href="https://doi.org/10.1080/07350015.2022.2120485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a family of CUSUM-based statistics to detect the presence of changepoints in the deterministic part of the autoregressive parameter in a Random Coefficient Autoregressive (RCA) sequence. Our tests can be applied irrespective of whether the sequence is stationary or not, and no prior knowledge of stationarity or lack thereof is required. Similarly, our tests can be applied even when the error term and the stochastic part of the autoregressive coefficient are non iid, covering the cases of conditional volatility and shifts in the variance, again without requiring any prior knowledge as to the presence or type thereof. In order to ensure the ability to detect breaks at sample endpoints, we propose weighted CUSUM statistics, deriving the asymptotics for virtually all possible weighing schemes, including the standardized CUSUM process (for which we derive a Darling-Erd≈ës theorem) and even heavier weights (so-called R√©nyi statistics). Simulations show that our procedures work very well in finite samples. We complement our theory with an application to several financial time series.},
  archive      = {J_JBES},
  author       = {Lajos Horv√°th and Lorenzo Trapani},
  doi          = {10.1080/07350015.2022.2120485},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1300-1314},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Changepoint detection in heteroscedastic random coefficient autoregressive models},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Corporate probability of default: A single-index hazard
model approach. <em>JBES</em>, <em>41</em>(4), 1288‚Äì1299. (<a
href="https://doi.org/10.1080/07350015.2022.2120484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Corporate probability of default (PD) prediction is vitally important for risk management and asset pricing. In search of accurate PD prediction, we propose a flexible yet easy-to-interpret default-prediction single-index hazard model (DSI). By applying it to a comprehensive U.S. corporate bankruptcy database we constructed, we discover an interesting V-shaped relationship, indicating a violation of the common linear hazard specification. Most importantly, the single-index hazard model passes the Hosmer-Lemeshow goodness-of-fit calibration test while neither does a state-of-the-art linear hazard model in finance nor a parametric class of Box-Cox transformation survival models. In an economic value analysis, we find that this may translate to as much as three times of profit compared to the linear hazard model. In model estimation, we adopt a penalized-spline approximation for the unknown function and propose an efficient algorithm. With a diverging number of spline knots, we establish consistency and asymptotic theories for the penalized-spline likelihood estimators. Furthermore, we reexamine the distress risk anomaly, that is, higher financially distressed stocks deliver anomalously lower excess returns. Based on the PDs from the proposed single-index hazard model, we find that the distress risk anomaly has weakened or even disappeared during the extended period.},
  archive      = {J_JBES},
  author       = {Shaobo Li and Shaonan Tian and Yan Yu and Xiaorui Zhu and Heng Lian},
  doi          = {10.1080/07350015.2022.2120484},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1288-1299},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Corporate probability of default: A single-index hazard model approach},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Extremal dependence-based specification testing of time
series. <em>JBES</em>, <em>41</em>(4), 1274‚Äì1287. (<a
href="https://doi.org/10.1080/07350015.2022.2120483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a specification test for conditional location‚Äìscale models based on extremal dependence properties of the standardized residuals. We do so comparing the left-over serial extremal dependence‚Äîas measured by the pre-asymptotic tail copula‚Äîwith that arising under serial independence at different lags. Our main theoretical results show that the proposed Portmanteau-type test statistics have nuisance parameter-free asymptotic limits. The test statistics are easy to compute, as they only depend on the standardized residuals, and critical values are likewise easily obtained from the limiting distributions. This contrasts with some extant tests (based, e.g., on autocorrelations of squared residuals), where test statistics depend on the parameter estimator of the model and critical values may need to be bootstrapped. We show that our tests perform well in simulations. An empirical application to S&amp;P 500 constituents illustrates that our tests can uncover violations of residual serial independence that are not picked up by standard autocorrelation-based specification tests, yet are relevant when the model is used for, for example, risk forecasting.},
  archive      = {J_JBES},
  author       = {Yannick Hoga},
  doi          = {10.1080/07350015.2022.2120483},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1274-1287},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Extremal dependence-based specification testing of time series},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Testing stability in functional event observations with an
application to IPO performance. <em>JBES</em>, <em>41</em>(4),
1262‚Äì1273. (<a
href="https://doi.org/10.1080/07350015.2022.2118127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many sequentially observed functional data objects are available only at the times of certain events. For example, the trajectory of stock prices of companies after their initial public offering (IPO) can be observed when the offering occurs, and the resulting data may be affected by changing circumstances. It is of interest to investigate whether the mean behavior of such functions is stable over time, and if not, to estimate the times at which apparent changes occur. Since the frequency of events may fluctuates over time, we propose a change point analysis that has two steps. In the first step, we segment the series into segments in which the frequency of events is approximately homogeneous using a new binary segmentation procedure for event frequencies. After adjusting the observed curves in each segment based on the frequency of events, we proceed in the second step by developing a method to test for and estimate change points in the mean of the observed functional data objects. We establish the consistency and asymptotic distribution of the change point detector and estimator in both steps, and study their performance using Monte Carlo simulations. An application to IPO performance data illustrates the proposed methods.},
  archive      = {J_JBES},
  author       = {Lajos Horv√°th and Zhenya Liu and Gregory Rice and Shixuan Wang and Yaosong Zhan},
  doi          = {10.1080/07350015.2022.2118127},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1262-1273},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Testing stability in functional event observations with an application to IPO performance},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal model averaging of mixed-data kernel-weighted spline
regressions. <em>JBES</em>, <em>41</em>(4), 1251‚Äì1261. (<a
href="https://doi.org/10.1080/07350015.2022.2118126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model averaging has a rich history dating from its use for combining forecasts from time-series models (Bates and Granger) and presents a compelling alternative to model selection methods. We propose a frequentist model averaging procedure defined over categorical regression splines (Ma, Racine, and Yang) that allows for mixed-data predictors, as well as nonnested and heteroscedastic candidate models. We demonstrate the asymptotic optimality of the proposed model averaging estimator, and develop a post-averaging inference theory for it. Theoretical underpinnings are provided, finite-sample performance is evaluated, and an empirical illustration reveals that the method is capable of outperforming a range of popular model selection criteria in applied settings. An R package is available for practitioners (Racine).},
  archive      = {J_JBES},
  author       = {Jeffrey S. Racine and Qi Li and Dalei Yu and Li Zheng},
  doi          = {10.1080/07350015.2022.2118126},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1251-1261},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Optimal model averaging of mixed-data kernel-weighted spline regressions},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nonparametric quantile regression for homogeneity pursuit in
panel data models. <em>JBES</em>, <em>41</em>(4), 1238‚Äì1250. (<a
href="https://doi.org/10.1080/07350015.2022.2118125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many panel data have the latent subgroup effect on individuals, and it is important to correctly identify these groups since the efficiency of resulting estimators can be improved significantly by pooling the information of individuals within each group. However, the currently assumed parametric and semiparametric relationship between the response and predictors may be misspecified, which leads to a wrong grouping result, and the nonparametric approach hence can be considered to avoid such mistakes. Moreover, the response may depend on predictors in different ways at various quantile levels, and the corresponding grouping structure may also vary. To tackle these problems, this article proposes a nonparametric quantile regression method for homogeneity pursuit in panel data models with individual effects, and a pairwise fused penalty is used to automatically select the number of groups. The asymptotic properties are established, and an ADMM algorithm is also developed. The finite sample performance is evaluated by simulation experiments, and the usefulness of the proposed methodology is further illustrated by an empirical example.},
  archive      = {J_JBES},
  author       = {Xiaoyu Zhang and Di Wang and Heng Lian and Guodong Li},
  doi          = {10.1080/07350015.2022.2118125},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1238-1250},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Nonparametric quantile regression for homogeneity pursuit in panel data models},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A scalable frequentist model averaging method.
<em>JBES</em>, <em>41</em>(4), 1228‚Äì1237. (<a
href="https://doi.org/10.1080/07350015.2022.2116442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequentist model averaging is an effective technique to handle model uncertainty. However, calculation of the weights for averaging is extremely difficult, if not impossible, even when the dimension of the predictor vector, p , is moderate, because we may have 2 p 2 p 2p candidate models. The exponential size of the candidate model set makes it difficult to estimate all candidate models, and brings additional numeric errors when calculating the weights. This article proposes a scalable frequentist model averaging method, which is statistically and computationally efficient, to overcome this problem by transforming the original model using the singular value decomposition. The method enables us to find the optimal weights by considering at most p candidate models. We prove that the minimum loss of the scalable model averaging estimator is asymptotically equal to that of the traditional model averaging estimator. We apply the Mallows and Jackknife criteria to the scalable model averaging estimator and prove that they are asymptotically optimal estimators. We further extend the method to the high-dimensional case (i.e., p ‚â• n ). Numerical studies illustrate the superiority of the proposed method in terms of both statistical efficiency and computational cost.},
  archive      = {J_JBES},
  author       = {Rong Zhu and Haiying Wang and Xinyu Zhang and Hua Liang},
  doi          = {10.1080/07350015.2022.2116442},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1228-1237},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A scalable frequentist model averaging method},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Overnight GARCH-it√¥ volatility models. <em>JBES</em>,
<em>41</em>(4), 1215‚Äì1227. (<a
href="https://doi.org/10.1080/07350015.2022.2116027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various parametric volatility models for financial data have been developed to incorporate high-frequency realized volatilities and better capture market dynamics. However, because high-frequency trading data are not available during the close-to-open period, the volatility models often ignore volatility information over the close-to-open period and thus may suffer from loss of important information relevant to market dynamics. In this article, to account for whole-day market dynamics, we propose an overnight volatility model based on It√¥ diffusions to accommodate two different instantaneous volatility processes for the open-to-close and close-to-open periods. We develop a weighted least squares method to estimate model parameters for two different periods and investigate its asymptotic properties.},
  archive      = {J_JBES},
  author       = {Donggyu Kim and Minseok Shin and Yazhen Wang},
  doi          = {10.1080/07350015.2022.2116027},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1215-1227},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Overnight GARCH-it√¥ volatility models},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Consistent estimation of distribution functions under
increasing concave and convex stochastic ordering. <em>JBES</em>,
<em>41</em>(4), 1203‚Äì1214. (<a
href="https://doi.org/10.1080/07350015.2022.2116026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A random variable Y 1 is said to be smaller than Y 2 in the increasing concave stochastic order if ùîº [ œï ( Y 1 ) ] ‚â§ ùîº [ œï ( Y 2 ) ] E [ œï ( Y 1 ) ] ‚â§ E [ œï ( Y 2 ) ] E[œï(Y1)]‚â§E[œï(Y2)] for all increasing concave functions œï œï œï for which the expected values exist, and smaller than Y 2 in the increasing convex order if E [ œà ( Y 1 ) ] ‚â§ E [ œà ( Y 2 ) ] for all increasing convex œà . This article develops nonparametric estimators for the conditional cumulative distribution functions F x ( y ) = ‚Ñô ( Y ‚â§ y | X = x ) of a response variable Y given a covariate X , solely under the assumption that the conditional distributions are increasing in x in the increasing concave or increasing convex order. Uniform consistency and rates of convergence are established both for the K -sample case X ‚àà { 1 , ‚Ä¶ , K } and for continuously distributed X .},
  archive      = {J_JBES},
  author       = {Alexander Henzi},
  doi          = {10.1080/07350015.2022.2116026},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1203-1214},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Consistent estimation of distribution functions under increasing concave and convex stochastic ordering},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). When are google data useful to nowcast GDP? An approach via
preselection and shrinkage. <em>JBES</em>, <em>41</em>(4), 1188‚Äì1202.
(<a href="https://doi.org/10.1080/07350015.2022.2116025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alternative datasets are widely used for macroeconomic nowcasting together with machine learning‚Äìbased tools. The latter are often applied without a complete picture of their theoretical nowcasting properties. Against this background, this article proposes a theoretically grounded nowcasting methodology that allows researchers to incorporate alternative Google Search Data (GSD) among the predictors and that combines targeted preselection, Ridge regularization, and Generalized Cross Validation. Breaking with most existing literature, which focuses on asymptotic in-sample theoretical properties, we establish the theoretical out-of-sample properties of our methodology and support them by Monte Carlo simulations. We apply our methodology to GSD to nowcast GDP growth rate of several countries during various economic periods. Our empirical findings support the idea that GSD tend to increase nowcasting accuracy, even after controlling for official variables, but that the gain differs between periods of recessions and of macroeconomic stability.},
  archive      = {J_JBES},
  author       = {Laurent Ferrara and Anna Simoni},
  doi          = {10.1080/07350015.2022.2116025},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1188-1202},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {When are google data useful to nowcast GDP? an approach via preselection and shrinkage},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nonparametric option pricing with generalized entropic
estimators. <em>JBES</em>, <em>41</em>(4), 1173‚Äì1187. (<a
href="https://doi.org/10.1080/07350015.2022.2115499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a family of nonparametric estimators for an option price that require only the use of underlying return data, but can also easily incorporate information from observed option prices. Each estimator comes from a risk-neutral measure minimizing generalized entropy according to a different Cressie‚ÄìRead discrepancy. We apply our method to price S&amp;P 500 options and the cross-section of individual equity options, using distinct amounts of option data in the estimation. Estimators incorporating mild nonlinearities produce optimal pricing accuracy within the Cressie‚ÄìRead family and outperform several benchmarks such as Black‚ÄìScholes and different GARCH option pricing models. Overall, we provide a powerful option pricing technique suitable for scenarios of limited option data availability.},
  archive      = {J_JBES},
  author       = {Caio Almeida and Gustavo Freire and Rafael Azevedo and Kym Ardison},
  doi          = {10.1080/07350015.2022.2115499},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1173-1187},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Nonparametric option pricing with generalized entropic estimators},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nonparametric prediction distribution from resolution-wise
regression with heterogeneous data. <em>JBES</em>, <em>41</em>(4),
1157‚Äì1172. (<a
href="https://doi.org/10.1080/07350015.2022.2115498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling and inference for heterogeneous data have gained great interest recently due to rapid developments in personalized marketing. Most existing regression approaches are based on the conditional mean and may require additional cluster information to accommodate data heterogeneity. In this article, we propose a novel nonparametric resolution-wise regression procedure to provide an estimated distribution of the response instead of one single value. We achieve this by decomposing the information of the response and the predictors into resolutions and patterns, respectively, based on marginal binary expansions. The relationships between resolutions and patterns are modeled by penalized logistic regressions. Combining the resolution-wise prediction, we deliver a histogram of the conditional response to approximate the distribution. Moreover, we show a sure independence screening property and the consistency of the proposed method for growing dimensions. Simulations and a real estate valuation dataset further illustrate the effectiveness of the proposed method.},
  archive      = {J_JBES},
  author       = {Jialu Li and Wan Zhang and Peiyao Wang and Qizhai Li and Kai Zhang and Yufeng Liu},
  doi          = {10.1080/07350015.2022.2115498},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1157-1172},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Nonparametric prediction distribution from resolution-wise regression with heterogeneous data},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Procurements with bidder asymmetry in cost and
risk-aversion. <em>JBES</em>, <em>41</em>(4), 1143‚Äì1156. (<a
href="https://doi.org/10.1080/07350015.2022.2115497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an empirical method to analyze data from first-price procurements where bidders are asymmetric in their risk-aversion (CRRA) coefficients and distributions of private costs. Our Bayesian approach evaluates the likelihood by solving type-symmetric equilibria using the boundary-value method and integrates out unobserved heterogeneity through data augmentation. We study a new dataset from Russian government procurements focusing on the category of printing papers. We find that there is no unobserved heterogeneity (presumably because the job is routine), but bidders are highly asymmetric in their cost and risk-aversion. Our counterfactual study shows that choosing a type-specific cost-minimizing reserve price marginally reduces the procurement cost; however, inviting one more bidder substantially reduces the cost, by at least 5.5\%. Furthermore, incorrectly imposing risk-neutrality would severely mislead inference and policy recommendations, but the bias from imposing homogeneity in risk-aversion is small.},
  archive      = {J_JBES},
  author       = {Gaurab Aryal and Hanna Charankevich and Seungwon Jeong and Dong-Hyuk Kim},
  doi          = {10.1080/07350015.2022.2115497},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1143-1156},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Procurements with bidder asymmetry in cost and risk-aversion},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LASSO for stochastic frontier models with many efficient
firms. <em>JBES</em>, <em>41</em>(4), 1132‚Äì1142. (<a
href="https://doi.org/10.1080/07350015.2022.2110881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We apply the adaptive LASSO to select a set of maximally efficient firms in the panel fixed-effect stochastic frontier model. The adaptively weighted L 1 penalty with sign restrictions allows simultaneous selection of a group of maximally efficient firms and estimation of firm-level inefficiency parameters with a faster rate of convergence than least squares dummy variable estimators. Our estimator possesses the oracle property. We propose a tuning parameter selection criterion and an efficient optimization algorithm based on coordinate descent. We apply the method to estimate a group of efficient police officers who are best at detecting contraband in motor vehicle stops (i.e., search efficiency) in Syracuse, NY.},
  archive      = {J_JBES},
  author       = {William C. Horrace and Hyunseok Jung and Yoonseok Lee},
  doi          = {10.1080/07350015.2022.2110881},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1132-1142},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {LASSO for stochastic frontier models with many efficient firms},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bagged pretested portfolio selection. <em>JBES</em>,
<em>41</em>(4), 1116‚Äì1131. (<a
href="https://doi.org/10.1080/07350015.2022.2110880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article exploits the idea of combining pretesting and bagging to choose between competing portfolio strategies. We propose an estimator for the portfolio weight vector, which optimally trades off Type I against Type II errors when choosing the best investment strategy. Furthermore, we accommodate the idea of bagging in the portfolio testing problem, which helps to avoid sharp thresholding and reduces turnover costs substantially. Our Bagged Pretested Portfolio Selection (BPPS) approach borrows from both the shrinkage and the forecast combination literature. The portfolio weights of our strategy are weighted averages of the portfolio weights from a set of stand-alone strategies. More specifically, the weights are generated from pseudo-out-of-sample portfolio pretesting, such that they reflect the probability that a given strategy will be overall best performing. The resulting strategy allows for a flexible and smooth switch between the underlying strategies and outperforms the corresponding stand-alone strategies. Besides yielding high point estimates of the portfolio performance measures, the BPPS approach performs exceptionally well in terms of precision and is robust against outliers resulting from the choice of the asset space.},
  archive      = {J_JBES},
  author       = {Ekaterina Kazak and Winfried Pohlmeier},
  doi          = {10.1080/07350015.2022.2110880},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1116-1131},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Bagged pretested portfolio selection},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Specification testing of regression models with mixed
discrete and continuous predictors. <em>JBES</em>, <em>41</em>(4),
1101‚Äì1115. (<a
href="https://doi.org/10.1080/07350015.2022.2110879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a nonparametric projection-based adaptive-to-model specification test for regressions with discrete and continuous predictors. The test statistic is asymptotically normal under the null hypothesis and omnibus against alternative hypotheses. The test behaves like a locally smoothing test as if the number of continuous predictors was one and can detect the local alternative hypotheses distinct from the null hypothesis at the rate that can be achieved by existing locally smoothing tests for regressions with only one continuous predictor. Because of the model adaptation property, the test can fully use the model structure under the null hypothesis so that the dimensionality problem can be significantly alleviated. A discretization-expectation ordinary least squares estimation approach for partial central subspace in sufficient dimension reduction is developed as a by-product in the test construction. We suggest a residual-based wild bootstrap method to give an approximation by fully using the null model and thus closer to the limiting null distribution than existing bootstrap approximations. We conduct simulation studies to compare it with existing tests and two real data examples for illustration.},
  archive      = {J_JBES},
  author       = {Xuehu Zhu and Qiming Zhang and Lixing Zhu and Jun Zhang and Luoyao Yu},
  doi          = {10.1080/07350015.2022.2110879},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1101-1115},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Specification testing of regression models with mixed discrete and continuous predictors},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust covariance matrix estimation for high-dimensional
compositional data with application to sales data analysis.
<em>JBES</em>, <em>41</em>(4), 1090‚Äì1100. (<a
href="https://doi.org/10.1080/07350015.2022.2106990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compositional data arises in a wide variety of research areas when some form of standardization and composition is necessary. Estimating covariance matrices is of fundamental importance for high-dimensional compositional data analysis. However, existing methods require the restrictive Gaussian or sub-Gaussian assumption, which may not hold in practice. We propose a robust composition adjusted thresholding covariance procedure based on Huber-type M -estimation to estimate the sparse covariance structure of high-dimensional compositional data. We introduce a cross-validation procedure to choose the tuning parameters of the proposed method. Theoretically, by assuming a bounded fourth moment condition, we obtain the rates of convergence and signal recovery property for the proposed method and provide the theoretical guarantees for the cross-validation procedure under the high-dimensional setting. Numerically, we demonstrate the effectiveness of the proposed method in simulation studies and also a real application to sales data analysis.},
  archive      = {J_JBES},
  author       = {Danning Li and Arun Srinivasan and Qian Chen and Lingzhou Xue},
  doi          = {10.1080/07350015.2022.2106990},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1090-1100},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Robust covariance matrix estimation for high-dimensional compositional data with application to sales data analysis},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identification of SVAR models by combining sign restrictions
with external instruments. <em>JBES</em>, <em>41</em>(4), 1077‚Äì1089. (<a
href="https://doi.org/10.1080/07350015.2022.2104857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We discuss combining sign restrictions with information in external instruments (proxy variables) to identify structural vector autoregressive (SVAR) models. In one setting, we assume the availability of valid external instruments. Sign restrictions may then be used to identify further orthogonal shocks, or as an additional piece of information to pin down the shocks identified by the external instruments more precisely. In a second setting, we assume that proxy variables are only ‚Äúplausibly exogenous‚Äù and suggest various types of inequality restrictions to bound the relation between structural shocks and the external variable. This can be combined with conventional sign restrictions to further narrow down the set of admissible models. Within a proxy-augmented SVAR, we conduct Bayesian inference and discuss computation of Bayes factors. They can be useful to test either the sign- or IV restrictions as overidentifying. We illustrate the usefulness of our methodology in estimating the effects of oil supply and monetary policy shocks.},
  archive      = {J_JBES},
  author       = {Robin Braun and Ralf Br√ºggemann},
  doi          = {10.1080/07350015.2022.2104857},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1077-1089},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Identification of SVAR models by combining sign restrictions with external instruments},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Synthetic control with time varying coefficients a state
space approach with bayesian shrinkage. <em>JBES</em>, <em>41</em>(4),
1065‚Äì1076. (<a
href="https://doi.org/10.1080/07350015.2022.2102025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthetic control methods are a popular tool for measuring the effects of policy interventions on a single treated unit. In practice, researchers create a counterfactual using a linear combination of untreated units that closely mimic the treated unit. Oftentimes, creating a synthetic control is not possible due to untreated units‚Äô dynamic characteristics such as integrated processes or a time varying relationship. These are cases in which viewing the counterfactual estimation problem as a cross-sectional one fails. In this article, I investigate a new approach to estimate the synthetic control counterfactual incorporating time varying parameters to handle such situations. This is done using a state space framework and Bayesian shrinkage. The dynamics allow for a closer pretreatment fit leading to a more accurate counterfactual estimate. Monte Carlo simulations are performed showcasing the usefulness of the proposed model in a synthetic control setting. I then compare the proposed model to existing approaches in a classic synthetic control case study.},
  archive      = {J_JBES},
  author       = {Danny Klinenberg},
  doi          = {10.1080/07350015.2022.2102025},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1065-1076},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Synthetic control with time varying coefficients a state space approach with bayesian shrinkage},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatial correlation robust inference in linear regression
and panel models. <em>JBES</em>, <em>41</em>(4), 1050‚Äì1064. (<a
href="https://doi.org/10.1080/07350015.2022.2127737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider inference about a scalar coefficient in a linear regression with spatially correlated errors. Recent suggestions for more robust inference require stationarity of both regressors and dependent variables for their large sample validity. This rules out many empirically relevant applications, such as difference-in-difference designs. We develop a robustified version of the recently suggested SCPC method that addresses this challenge. We find that the method has good size properties in a wide range of Monte Carlo designs that are calibrated to real world applications, both in a pure cross sectional setting, but also for spatially correlated panel data. We provide numerically efficient methods for computing the associated spatial-correlation robust test statistics, critical values, and confidence intervals.},
  archive      = {J_JBES},
  author       = {Ulrich K. M√ºller and Mark W. Watson},
  doi          = {10.1080/07350015.2022.2127737},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1050-1064},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Spatial correlation robust inference in linear regression and panel models},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Rejoinder. <em>JBES</em>, <em>41</em>(4), 1046‚Äì1049. (<a
href="https://doi.org/10.1080/07350015.2023.2239870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JBES},
  author       = {Levon Barseghyan and Francesca Molinari},
  doi          = {10.1080/07350015.2023.2239870},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1046-1049},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Rejoinder},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Discussion of levon barseghyan and francesca molinari‚Äôs
‚Äúrisk preference types, limited consideration, and welfare.‚Äù
<em>JBES</em>, <em>41</em>(4), 1042‚Äì1045. (<a
href="https://doi.org/10.1080/07350015.2023.2223592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JBES},
  author       = {Julie Holland Mortimer},
  doi          = {10.1080/07350015.2023.2223592},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1042-1045},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Discussion of levon barseghyan and francesca molinari‚Äôs ‚ÄúRisk preference types, limited consideration, and welfare‚Äù},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Discussion of ‚Äúrisk preference types, limited consideration,
and welfare‚Äù by levon barseghyan and francesca molinari. <em>JBES</em>,
<em>41</em>(4), 1039‚Äì1041. (<a
href="https://doi.org/10.1080/07350015.2023.2217870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JBES},
  author       = {Elisabeth Honka},
  doi          = {10.1080/07350015.2023.2217870},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1039-1041},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Discussion of ‚ÄúRisk preference types, limited consideration, and welfare‚Äù by levon barseghyan and francesca molinari},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Discussion of ‚Äúrisk preference types, limited consideration,
and welfare‚Äù by levon barseghyan and francesca molinari. <em>JBES</em>,
<em>41</em>(4), 1035‚Äì1038. (<a
href="https://doi.org/10.1080/07350015.2023.2216255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JBES},
  author       = {Cristina Gualdani},
  doi          = {10.1080/07350015.2023.2216255},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1035-1038},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Discussion of ‚ÄúRisk preference types, limited consideration, and welfare‚Äù by levon barseghyan and francesca molinari},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Context-dependent heterogeneous preferences: A comment on
barseghyan and molinari (2023). <em>JBES</em>, <em>41</em>(4),
1030‚Äì1034. (<a
href="https://doi.org/10.1080/07350015.2023.2216740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Barseghyan and Molinari give sufficient conditions for semi-nonparametric point identification of parameters of interest in a mixture model of decision-making under risk, allowing for unobserved heterogeneity in utility functions and limited consideration. A key assumption in the model is that the heterogeneity of risk preferences is unobservable but context-independent. In this comment, we build on their insights and present identification results in a setting where the risk preferences are allowed to be context-dependent.},
  archive      = {J_JBES},
  author       = {Matias D. Cattaneo and Xinwei Ma and Yusufcan Masatlioglu},
  doi          = {10.1080/07350015.2023.2216740},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1030-1034},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Context-dependent heterogeneous preferences: A comment on barseghyan and molinari (2023)},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Risk preference types, limited consideration, and welfare.
<em>JBES</em>, <em>41</em>(4), 1011‚Äì1029. (<a
href="https://doi.org/10.1080/07350015.2023.2239949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide sufficient conditions for semi-nonparametric point identification of a mixture model of decision making under risk, when agents make choices in multiple lines of insurance coverage ( contexts ) by purchasing a bundle . As a first departure from the related literature, the model allows for two preference types. In the first one, agents behave according to standard expected utility theory with CARA Bernoulli utility function, with an agent-specific coefficient of absolute risk aversion whose distribution is left completely unspecified. In the other, agents behave according to the dual theory of choice under risk combined with a one-parameter family distortion function, where the parameter is agent-specific and is drawn from a distribution that is left completely unspecified. Within each preference type, the model allows for unobserved heterogeneity in consideration sets, where the latter form at the bundle level‚Äîa second departure from the related literature. Our point identification result rests on observing sufficient variation in covariates across contexts, without requiring any independent variation across alternatives within a single context. We estimate the model on data on households‚Äô deductible choices in two lines of property insurance, and use the results to assess the welfare implications of a hypothetical market intervention where the two lines of insurance are combined into a single one. We study the role of limited consideration in mediating the welfare effects of such intervention.},
  archive      = {J_JBES},
  author       = {Levon Barseghyan and Francesca Molinari},
  doi          = {10.1080/07350015.2023.2239949},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1011-1029},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Risk preference types, limited consideration, and welfare},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Can a machine correct option pricing models? <em>JBES</em>,
<em>41</em>(3), 995‚Äì1009. (<a
href="https://doi.org/10.1080/07350015.2022.2099871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel two-step approach to predict implied volatility surfaces. Given any fitted parametric option pricing model, we train a feedforward neural network on the model-implied pricing errors to correct for mispricing and boost performance. Using a large dataset of S&amp;P 500 options, we test our nonparametric correction on several parametric models ranging from ad-hoc Black‚ÄìScholes to structural stochastic volatility models and demonstrate the boosted performance for each model. Out-of-sample prediction exercises in the cross-section and in the option panel show that machine-corrected models always outperform their respective original ones, often by a large extent. Our method is relatively indiscriminate, bringing pricing errors down to a similar magnitude regardless of the misspecification of the original parametric model. Even so, correcting models that are less misspecified usually leads to additional improvements in performance and also outperforms a neural network fitted directly to the implied volatility surface.},
  archive      = {J_JBES},
  author       = {Caio Almeida and Jianqing Fan and Gustavo Freire and Francesca Tang},
  doi          = {10.1080/07350015.2022.2099871},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {995-1009},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Can a machine correct option pricing models?},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Large-scale generalized linear models for longitudinal data
with grouped patterns of unobserved heterogeneity. <em>JBES</em>,
<em>41</em>(3), 983‚Äì994. (<a
href="https://doi.org/10.1080/07350015.2022.2097913">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article provides methods for flexibly capturing unobservable heterogeneity from longitudinal data in the context of an exponential family of distributions. The group memberships of individual units are left unspecified, and their heterogeneity is influenced by group-specific unobservable factor structures. The model includes, as special cases, probit, logit, and Poisson regressions with interactive fixed effects along with unknown group membership. We discuss a computationally efficient estimation method and derive the corresponding asymptotic theory. Uniform consistency of the estimated group membership is established. To test heterogeneous regression coefficients within groups, we propose a Swamy-type test that allows for unobserved heterogeneity. We apply the proposed method to the study of market structure of the taxi industry in New York City. Our method unveils interesting and important insights from large-scale longitudinal data that consist of over 450 million data points.},
  archive      = {J_JBES},
  author       = {Tomohiro Ando and Jushan Bai},
  doi          = {10.1080/07350015.2022.2097913},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {983-994},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Large-scale generalized linear models for longitudinal data with grouped patterns of unobserved heterogeneity},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). News-driven uncertainty fluctuations. <em>JBES</em>,
<em>41</em>(3), 968‚Äì982. (<a
href="https://doi.org/10.1080/07350015.2022.2097912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the channels through which news influences the subjective beliefs of economic agents, with a particular focus on their subjective uncertainty. The main insight of the article is that news that is more at odds with agents‚Äô prior beliefs generates an increase in uncertainty; news that is more consistent with their prior beliefs generates a decrease in uncertainty. We illustrate this insight theoretically and then estimate the model empirically using data on U.S. output and professional forecasts to provide novel measures of news shocks and uncertainty. We then estimate impulse responses from the identified shocks to show that news shocks can affect macroeconomic variables in ways that resemble the effects of uncertainty shocks. Our results suggest that controlling for news can potentially diminish the estimated effects of uncertainty shocks on real variables, particularly at longer horizons.},
  archive      = {J_JBES},
  author       = {Dongho Song and Jenny Tang},
  doi          = {10.1080/07350015.2022.2097912},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {968-982},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {News-driven uncertainty fluctuations},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust signal recovery for high-dimensional linear
log-contrast models with compositional covariates. <em>JBES</em>,
<em>41</em>(3), 957‚Äì967. (<a
href="https://doi.org/10.1080/07350015.2022.2097911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a robust signal recovery method for high-dimensional linear log-contrast models, when the error distribution could be heavy-tailed and asymmetric. The proposed method is built on the Huber loss with ‚Ñì 1 penalization. We establish the ‚Ñì 1 and ‚Ñì 2 consistency for the resulting estimator. Under conditions analogous to the irrepresentability condition and the minimum signal strength condition, we prove that the signed support of the slope parameter vector can be recovered with high probability. The finite-sample behavior of the proposed method is evaluated through simulation studies, and applications to a GDP satisfaction dataset an HIV microbiome dataset are provided.},
  archive      = {J_JBES},
  author       = {Dongxiao Han and Jian Huang and Yuanyuan Lin and Lei Liu and Lianqiang Qu and Liuquan Sun},
  doi          = {10.1080/07350015.2022.2097911},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {957-967},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Robust signal recovery for high-dimensional linear log-contrast models with compositional covariates},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimation of leverage effect: Kernel function and
efficiency. <em>JBES</em>, <em>41</em>(3), 939‚Äì956. (<a
href="https://doi.org/10.1080/07350015.2022.2097910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes more efficient estimators for the leverage effect than the existing ones. The idea is to allow for nonuniform kernel functions in the spot volatility estimates or the aggregated returns. This finding highlights a critical difference between the leverage effect and integrated volatility functionals, where the uniform kernel is optimal. Another distinction between these two cases is that the overlapping estimators of the leverage effect are more efficient than the nonoverlapping ones. We offer two perspectives to explain these differences: one is based on the ‚Äúeffective kernel‚Äù and the other on the correlation structure of the nonoverlapping estimators. The simulation study shows that the proposed estimator with a nonuniform kernel substantially increases the estimation efficiency and testing power relative to the existing ones.},
  archive      = {J_JBES},
  author       = {Xiye Yang},
  doi          = {10.1080/07350015.2022.2097910},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {939-956},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Estimation of leverage effect: Kernel function and efficiency},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inference in a class of optimization problems: Confidence
regions and finite sample bounds on errors in coverage probabilities.
<em>JBES</em>, <em>41</em>(3), 927‚Äì938. (<a
href="https://doi.org/10.1080/07350015.2022.2093883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article describes three methods for carrying out nonasymptotic inference on partially identified parameters that are solutions to a class of optimization problems. Applications in which the optimization problems arise include estimation under shape restrictions, estimation of models of discrete games, and estimation based on grouped data. The partially identified parameters are characterized by restrictions that involve the unknown population means of observed random variables in addition to structural parameters. Inference consists of finding confidence intervals for functions of the structural parameters. Our theory provides finite-sample lower bounds on the coverage probabilities of the confidence intervals under three sets of assumptions of increasing strength. With the moderate sample sizes found in most economics applications, the bounds become tighter as the assumptions strengthen. We discuss estimation of population parameters that the bounds depend on and contrast our methods with alternative methods for obtaining confidence intervals for partially identified parameters. The results of Monte Carlo experiments and empirical examples illustrate the usefulness of our method.},
  archive      = {J_JBES},
  author       = {Joel L. Horowitz and Sokbae Lee},
  doi          = {10.1080/07350015.2022.2093883},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {927-938},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Inference in a class of optimization problems: Confidence regions and finite sample bounds on errors in coverage probabilities},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Covariate-assisted community detection in multi-layer
networks. <em>JBES</em>, <em>41</em>(3), 915‚Äì926. (<a
href="https://doi.org/10.1080/07350015.2022.2085726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communities in multi-layer networks consist of nodes with similar connectivity patterns across all layers. This article proposes a tensor-based community detection method in multi-layer networks, which leverages available node-wise covariates to improve community detection accuracy. This is motivated by the network homophily principle, which suggests that nodes with similar covariates tend to reside in the same community. To take advantage of the node-wise covariates, the proposed method augments the multi-layer network with an additional layer constructed from the node similarity matrix with proper scaling, and conducts a Tucker decomposition of the augmented multi-layer network, yielding the spectral embedding vector of each node for community detection. Asymptotic consistencies of the proposed method in terms of community detection are established, which are also supported by numerical experiments on various synthetic networks and two real-life multi-layer networks.},
  archive      = {J_JBES},
  author       = {Shirong Xu and Yaoming Zhen and Junhui Wang},
  doi          = {10.1080/07350015.2022.2085726},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {915-926},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Covariate-assisted community detection in multi-layer networks},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Empirical likelihood and uniform convergence rates for
dyadic kernel density estimation. <em>JBES</em>, <em>41</em>(3),
906‚Äì914. (<a
href="https://doi.org/10.1080/07350015.2022.2080684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies the asymptotic properties of and alternative inference methods for kernel density estimation (KDE) for dyadic data. We first establish uniform convergence rates for dyadic KDE. Second, we propose a modified jackknife empirical likelihood procedure for inference. The proposed test statistic is asymptotically pivotal regardless of presence of dyadic clustering. The results are further extended to cover the practically relevant case of incomplete dyadic data. Simulations show that this modified jackknife empirical likelihood-based inference procedure delivers precise coverage probabilities even with modest sample sizes and with incomplete dyadic data. Finally, we illustrate the method by studying airport congestion in the United States.},
  archive      = {J_JBES},
  author       = {Harold D. Chiang and Bing Yang Tan},
  doi          = {10.1080/07350015.2022.2080684},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {906-914},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Empirical likelihood and uniform convergence rates for dyadic kernel density estimation},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Large hybrid time-varying parameter VARs. <em>JBES</em>,
<em>41</em>(3), 890‚Äì905. (<a
href="https://doi.org/10.1080/07350015.2022.2080683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-varying parameter VARs with stochastic volatility are routinely used for structural analysis and forecasting in settings involving a few endogenous variables. Applying these models to high-dimensional datasets has proved to be challenging due to intensive computations and over-parameterization concerns. We develop an efficient Bayesian sparsification method for a class of models we call hybrid TVP-VARs‚ÄîVARs with time-varying parameters in some equations but constant coefficients in others. Specifically, for each equation, the new method automatically decides whether the VAR coefficients and contemporaneous relations among variables are constant or time-varying. Using U.S. datasets of various dimensions, we find evidence that the parameters in some, but not all, equations are time varying. The large hybrid TVP-VAR also forecasts better than many standard benchmarks.},
  archive      = {J_JBES},
  author       = {Joshua C. C. Chan},
  doi          = {10.1080/07350015.2022.2080683},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {890-905},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Large hybrid time-varying parameter VARs},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tail risk inference via expectiles in heavy-tailed time
series. <em>JBES</em>, <em>41</em>(3), 876‚Äì889. (<a
href="https://doi.org/10.1080/07350015.2022.2078332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expectiles define the only law-invariant, coherent and elicitable risk measure apart from the expectation. The popularity of expectile-based risk measures is steadily growing and their properties have been studied for independent data, but further results are needed to establish that extreme expectiles can be applied with the kind of dependent time series models relevant to finance. In this article we provide a basis for inference on extreme expectiles and expectile-based marginal expected shortfall in a general Œ≤ -mixing context that encompasses ARMA and GARCH models with heavy-tailed innovations. Our methods allow the estimation of marginal (pertaining to the stationary distribution) and dynamic (conditional on the past) extreme expectile-based risk measures. Simulations and applications to financial returns show that the new estimators and confidence intervals greatly improve on existing ones when the data are dependent.},
  archive      = {J_JBES},
  author       = {Anthony C. Davison and Simone A. Padoan and Gilles Stupfler},
  doi          = {10.1080/07350015.2022.2078332},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {876-889},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Tail risk inference via expectiles in heavy-tailed time series},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A robust approach to heteroscedasticity, error serial
correlation and slope heterogeneity in linear models with interactive
effects for large panel data. <em>JBES</em>, <em>41</em>(3), 862‚Äì875.
(<a href="https://doi.org/10.1080/07350015.2022.2077349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a robust approach against heteroscedasticity, error serial correlation and slope heterogeneity in linear models with interactive effects for large panel data. First, consistency and asymptotic normality of the pooled iterated principal component (IPC) estimator for random coefficient and homogeneous slope models are established. Then, we prove the asymptotic validity of the associated Wald test for slope parameter restrictions based on the panel heteroscedasticity and autocorrelation consistent (PHAC) variance matrix estimator for both random coefficient and homogeneous slope models, which does not require the Newey-West type time-series parameter truncation. These results asymptotically justify the use of the same pooled IPC estimator and the PHAC standard error for both homogeneous-slope and heterogeneous-slope models. This robust approach can significantly reduce the model selection uncertainty for applied researchers. In addition, we propose a Lagrange Multiplier (LM) test for correlated random coefficients with covariates. This test has nontrivial power against correlated random coefficients, but not for random coefficients and homogeneous slopes. The LM test is important because the IPC estimator becomes inconsistent with correlated random coefficients. The finite sample evidence and an empirical application support the reliability and the usefulness of our robust approach.},
  archive      = {J_JBES},
  author       = {Guowei Cui and Kazuhiko Hayakawa and Shuichi Nagata and Takashi Yamagata},
  doi          = {10.1080/07350015.2022.2077349},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {862-875},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A robust approach to heteroscedasticity, error serial correlation and slope heterogeneity in linear models with interactive effects for large panel data},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detection of multiple structural breaks in large covariance
matrices. <em>JBES</em>, <em>41</em>(3), 846‚Äì861. (<a
href="https://doi.org/10.1080/07350015.2022.2076686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies multiple structural breaks in large contemporaneous covariance matrices of high-dimensional time series satisfying an approximate factor model. The breaks in the second-order moment structure of the common components are due to sudden changes in either factor loadings or covariance of latent factors, requiring appropriate transformation of the factor models to facilitate estimation of the (transformed) common factors and factor loadings via the classical principal component analysis. With the estimated factors and idiosyncratic errors, an easy-to-implement CUSUM-based detection technique is introduced to consistently estimate the location and number of breaks and correctly identify whether they originate in the common or idiosyncratic error components. The algorithms of Wild Binary Segmentation for Covariance (WBS-Cov) and Wild Sparsified Binary Segmentation for Covariance (WSBS-Cov) are used to estimate breaks in the common and idiosyncratic error components, respectively. Under some technical conditions, the asymptotic properties of the proposed methodology are derived with near-optimal rates (up to a logarithmic factor) achieved for the estimated breaks. Monte Carlo simulation studies are conducted to examine the finite-sample performance of the developed method and its comparison with other existing approaches. We finally apply our method to study the contemporaneous covariance structure of daily returns of S&amp;P 500 constituents and identify a few breaks including those occurring during the 2007‚Äì2008 financial crisis and the recent coronavirus (COVID-19) outbreak. An R package ‚Äú BSCOV ‚Äù is provided to implement the proposed algorithms.},
  archive      = {J_JBES},
  author       = {Yu-Ning Li and Degui Li and Piotr Fryzlewicz},
  doi          = {10.1080/07350015.2022.2076686},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {846-861},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Detection of multiple structural breaks in large covariance matrices},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Singular conditional autoregressive wishart model for
realized covariance matrices. <em>JBES</em>, <em>41</em>(3), 833‚Äì845.
(<a href="https://doi.org/10.1080/07350015.2022.2075370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Realized covariance matrices are often constructed under the assumption that richness of intra-day return data is greater than the portfolio size, resulting in nonsingular matrix measures. However, when for example the portfolio size is large, assets suffer from illiquidity issues, or market microstructure noise deters sampling on very high frequencies, this relation is not guaranteed. Under these common conditions, realized covariance matrices may obtain as singular by construction. Motivated by this situation, we introduce the Singular Conditional Autoregressive Wishart (SCAW) model to capture the temporal dynamics of time series of singular realized covariance matrices, extending the rich literature on econometric Wishart time series models to the singular case. This model is furthermore developed by covariance targeting adapted to matrices and a sector wise BEKK-specification, allowing excellent scalability to large and extremely large portfolio sizes. Finally, the model is estimated to a 20-year long time series containing 50 stocks and to a 10-year long time series containing 300 stocks, and evaluated using out-of-sample forecast accuracy. It outperforms the benchmark models with high statistical significance and the parsimonious specifications perform better than the baseline SCAW model, while using considerably less parameters.},
  archive      = {J_JBES},
  author       = {Gustav Alfelt and Taras Bodnar and Farrukh Javed and Joanna Tyrcha},
  doi          = {10.1080/07350015.2022.2075370},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {833-845},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Singular conditional autoregressive wishart model for realized covariance matrices},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identification and estimation of structural VARMA models
using higher order dynamics. <em>JBES</em>, <em>41</em>(3), 819‚Äì832. (<a
href="https://doi.org/10.1080/07350015.2022.2075000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We use information from higher order moments to achieve identification of non-Gaussian structural vector autoregressive moving average (SVARMA) models, possibly nonfundamental or noncausal, through a frequency domain criterion based on higher order spectral densities. This allows us to identify the location of the roots of the determinantal lag matrix polynomials and to identify the rotation of the model errors leading to the structural shocks up to sign and permutation. We describe sufficient conditions for global and local parameter identification that rely on simple rank assumptions on the linear dynamics and on finite order serial and component independence conditions for the non-Gaussian structural innovations. We generalize previous univariate analysis to develop asymptotically normal and efficient estimates exploiting second and higher order cumulant dynamics given a particular structural shocks ordering without assumptions on causality or invertibility. Finite sample properties of estimates are explored with real and simulated data.},
  archive      = {J_JBES},
  author       = {Carlos Velasco},
  doi          = {10.1080/07350015.2022.2075000},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {819-832},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Identification and estimation of structural VARMA models using higher order dynamics},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Network gradient descent algorithm for decentralized
federated learning. <em>JBES</em>, <em>41</em>(3), 806‚Äì818. (<a
href="https://doi.org/10.1080/07350015.2022.2074426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a fully decentralized federated learning algorithm, which is a novel gradient descent algorithm executed on a communication-based network. For convenience, we refer to it as a network gradient descent (NGD) method. In the NGD method, only statistics (e.g., parameter estimates) need to be communicated, minimizing the risk of privacy. Meanwhile, different clients communicate with each other directly according to a carefully designed network structure without a central master. This greatly enhances the reliability of the entire algorithm. Those nice properties inspire us to carefully study the NGD method both theoretically and numerically. Theoretically, we start with a classical linear regression model. We find that both the learning rate and the network structure play significant roles in determining the NGD estimator‚Äôs statistical efficiency. The resulting NGD estimator can be statistically as efficient as the global estimator, if the learning rate is sufficiently small and the network structure is weakly balanced, even if the data are distributed heterogeneously. Those interesting findings are then extended to general models and loss functions. Extensive numerical studies are presented to corroborate our theoretical findings. Classical deep learning models are also presented for illustration purpose.},
  archive      = {J_JBES},
  author       = {Shuyuan Wu and Danyang Huang and Hansheng Wang},
  doi          = {10.1080/07350015.2022.2074426},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {806-818},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Network gradient descent algorithm for decentralized federated learning},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Culling the herd of moments with penalized empirical
likelihood. <em>JBES</em>, <em>41</em>(3), 791‚Äì805. (<a
href="https://doi.org/10.1080/07350015.2022.2071903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Models defined by moment conditions are at the center of structural econometric estimation, but economic theory is mostly agnostic about moment selection. While a large pool of valid moments can potentially improve estimation efficiency, in the meantime a few invalid ones may undermine consistency. This article investigates the empirical likelihood estimation of these moment-defined models in high-dimensional settings. We propose a penalized empirical likelihood (PEL) estimation and establish its oracle property with consistent detection of invalid moments. The PEL estimator is asymptotically normally distributed, and a projected PEL procedure further eliminates its asymptotic bias and provides more accurate normal approximation to the finite sample behavior. Simulation exercises demonstrate excellent numerical performance of these methods in estimation and inference.},
  archive      = {J_JBES},
  author       = {Jinyuan Chang and Zhentao Shi and Jia Zhang},
  doi          = {10.1080/07350015.2022.2071903},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {791-805},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Culling the herd of moments with penalized empirical likelihood},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimation of panel data models with random interactive
effects and multiple structural breaks when t is fixed. <em>JBES</em>,
<em>41</em>(3), 778‚Äì790. (<a
href="https://doi.org/10.1080/07350015.2022.2067546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a new estimator of panel data models with random interactive effects and multiple structural breaks that is suitable when the number of time periods, T , is fixed and only the number of cross-sectional units, N , is large. This is done by viewing the determination of the breaks as a shrinkage problem, and to estimate both the regression coefficients, and the number of breaks and their locations by applying a version of the Lasso approach. We show that with probability approaching one the approach can correctly determine the number of breaks and the dates of these breaks, and that the estimator of the regime-specific regression coefficients is consistent and asymptotically normal. We also provide Monte Carlo results suggesting that the approach performs very well in small samples, and empirical results suggesting that while the coefficients of the controls are breaking, the coefficients of the main deterrence regressors in a model of crime are not.},
  archive      = {J_JBES},
  author       = {Yousef Kaddoura and Joakim Westerlund},
  doi          = {10.1080/07350015.2022.2067546},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {778-790},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Estimation of panel data models with random interactive effects and multiple structural breaks when t is fixed},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combining p-values for multivariate predictive ability
testing. <em>JBES</em>, <em>41</em>(3), 765‚Äì777. (<a
href="https://doi.org/10.1080/07350015.2022.2067545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose an intersection-union test for multivariate forecast accuracy based on the combination of a sequence of univariate tests. The testing framework evaluates a global null hypothesis of equal predictive ability using any number of univariate forecast accuracy tests under arbitrary dependence structures, without specifying the underlying multivariate distribution. An extensive Monte Carlo simulation exercise shows that our proposed test has very good size and power properties under several relevant scenarios, and performs well in both low- and high-dimensional settings. We illustrate the empirical validity of our testing procedure using a large dataset of 84 daily exchange rates running from January 1, 2011 to April 1, 2021. We show that our proposed test addresses inconclusive results that often arise in practice.},
  archive      = {J_JBES},
  author       = {Lars Spreng and Giovanni Urga},
  doi          = {10.1080/07350015.2022.2067545},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {765-777},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Combining p-values for multivariate predictive ability testing},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Structural breaks in grouped heterogeneity. <em>JBES</em>,
<em>41</em>(3), 752‚Äì764. (<a
href="https://doi.org/10.1080/07350015.2022.2063132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating accurate forecasts in the presence of structural breaks requires careful management of bias-variance tradeoffs. Forecasting panel data under breaks offers the possibility to reduce parameter estimation error without inducing any bias if there exists a regime-specific pattern of grouped heterogeneity. To this end, we develop a new Bayesian methodology to estimate and formally test panel regression models in the presence of multiple breaks and unobserved regime-specific grouped heterogeneity. In an empirical application to forecasting inflation rates across 20‚ÄâU.S. industries, our method generates significantly more accurate forecasts relative to a range of popular methods.},
  archive      = {J_JBES},
  author       = {Simon C. Smith},
  doi          = {10.1080/07350015.2022.2063132},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {752-764},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Structural breaks in grouped heterogeneity},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Testing for unobserved heterogeneity via k-means clustering.
<em>JBES</em>, <em>41</em>(3), 737‚Äì751. (<a
href="https://doi.org/10.1080/07350015.2022.2061983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering methods such as k - means have found widespread use in a variety of applications. This article proposes a split-sample testing procedure to determine whether a null hypothesis of a single cluster, indicating homogeneity of the data, can be rejected in favor of multiple clusters. The test is simple to implement, valid under mild conditions (including nonnormality, and heterogeneity of the data in aspects beyond those in the clustering analysis), and applicable in a range of contexts (including clustering when the time series dimension is small, or clustering on parameters other than the mean). We verify that the test has good size control in finite samples, and we illustrate the test in applications to clustering vehicle manufacturers and U.S. mutual funds.},
  archive      = {J_JBES},
  author       = {Andrew J. Patton and Brian M. Weller},
  doi          = {10.1080/07350015.2022.2061983},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {737-751},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Testing for unobserved heterogeneity via k-means clustering},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Panel data quantile regression for treatment effect models.
<em>JBES</em>, <em>41</em>(3), 720‚Äì736. (<a
href="https://doi.org/10.1080/07350015.2022.2061495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we develop a novel estimation method for quantile treatment effects (QTE) under rank invariance and rank stationarity assumptions. Ishihara ( Citation 2020 ) explores identification of the nonseparable panel data model under these assumptions and proposes a parametric estimation based on the minimum distance method. However, when the dimensionality of the covariates is large, the minimum distance estimation using this process is computationally demanding. To overcome this problem, we propose a two-step estimation method based on the quantile regression and minimum distance methods. We then show the uniform asymptotic properties of our estimator and the validity of the nonparametric bootstrap. The Monte Carlo studies indicate that our estimator performs well in finite samples. Finally, we present two empirical illustrations, to estimate the distributional effects of insurance provision on household production and TV watching on child cognitive development.},
  archive      = {J_JBES},
  author       = {Takuya Ishihara},
  doi          = {10.1080/07350015.2022.2061495},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {720-736},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Panel data quantile regression for treatment effect models},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Forecasting with economic news. <em>JBES</em>,
<em>41</em>(3), 708‚Äì719. (<a
href="https://doi.org/10.1080/07350015.2022.2060988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of this article is to evaluate the informational content of sentiment extracted from news articles about the state of the economy. We propose a fine-grained aspect-based sentiment analysis that has two main characteristics: (a) we consider only the text in the article that is semantically dependent on a term of interest (aspect-based) and, (b) assign a sentiment score to each word based on a dictionary that we develop for applications in economics and finance (fine-grained). Our dataset includes six large U.S. newspapers, for a total of over 6.6 million articles and 4.2 billion words. Our findings suggest that several measures of economic sentiment track closely business cycle fluctuations and that they are relevant predictors for four major macroeconomic variables. We find that there are significant improvements in forecasting when sentiment is considered along with macroeconomic factors. In addition, we also find that sentiment matters to explains the tails of the probability distribution across several macroeconomic variables.},
  archive      = {J_JBES},
  author       = {Luca Barbaglia and Sergio Consoli and Sebastiano Manzan},
  doi          = {10.1080/07350015.2022.2060988},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {708-719},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Forecasting with economic news},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identification and estimation of multinomial choice models
with latent special covariates. <em>JBES</em>, <em>41</em>(3), 695‚Äì707.
(<a href="https://doi.org/10.1080/07350015.2022.2060987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identification of multinomial choice models is often established by using special covariates that have full support. This article shows how these identification results can be extended to a large class of multinomial choice models when all covariates are bounded. I also provide a new n ‚Äæ ‚àö n n -consistent asymptotically normal estimator of the finite-dimensional parameters of the model.},
  archive      = {J_JBES},
  author       = {Nail Kashaev},
  doi          = {10.1080/07350015.2022.2060987},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {695-707},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Identification and estimation of multinomial choice models with latent special covariates},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bootstrapping two-stage quasi-maximum likelihood estimators
of time series models. <em>JBES</em>, <em>41</em>(3), 683‚Äì694. (<a
href="https://doi.org/10.1080/07350015.2022.2058949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article provides results on the validity of bootstrap inference methods for two-stage quasi-maximum likelihood estimation involving time series data, such as those used for multivariate volatility models or copula-based models. Existing approaches require the researcher to compute and combine many first- and second-order derivatives, which can be difficult to do and is susceptible to error. Bootstrap methods are simpler to apply, allowing the substitution of capital (CPU cycles) for labor (keeping track of derivatives). We show the consistency of the bootstrap distribution and consistency of bootstrap variance estimators, thereby justifying the use of bootstrap percentile intervals and bootstrap standard errors.},
  archive      = {J_JBES},
  author       = {S√≠lvia Gon√ßalves and Ulrich Hounyo and Andrew J. Patton and Kevin Sheppard},
  doi          = {10.1080/07350015.2022.2058949},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {683-694},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Bootstrapping two-stage quasi-maximum likelihood estimators of time series models},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using survey information for improving the density
nowcasting of u.s. GDP. <em>JBES</em>, <em>41</em>(3), 667‚Äì682. (<a
href="https://doi.org/10.1080/07350015.2022.2058000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a methodology that efficiently combines the statistical models of nowcasting with the survey information for improving the (density) nowcasting of U.S. real GDP. Specifically, we use the conventional dynamic factor model together with stochastic volatility components as the baseline statistical model. We augment the model with information from the survey expectations by aligning the first and second moments of the predictive distribution implied by this baseline model with those extracted from the survey information at various horizons. Results indicate that survey information bears valuable information over the baseline model for nowcasting GDP. While the mean survey predictions deliver valuable information during extreme events such as the Covid-19 pandemic, the variation in the survey participants‚Äô predictions, often used as a measure of ‚Äúambiguity,‚Äù conveys crucial information beyond the mean of those predictions for capturing the tail behavior of the GDP distribution.},
  archive      = {J_JBES},
  author       = {Cem √áakmakl i and Hamza Demircan},
  doi          = {10.1080/07350015.2022.2058000},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {667-682},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Using survey information for improving the density nowcasting of U.S. GDP},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Structural breaks in interactive effects panels and the
stock market reaction to COVID-19. <em>JBES</em>, <em>41</em>(3),
653‚Äì666. (<a
href="https://doi.org/10.1080/07350015.2022.2053690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dealing with structural breaks is an essential step in most empirical economic research. This is particularly true in panel data comprised of many cross-sectional units, which are all affected by major events. The COVID-19 pandemic has affected most sectors of the global economy; however, its impact on stock markets is still unclear. Most markets seem to have recovered while the pandemic is ongoing, suggesting that the relationship between stock returns and COVID-19 has been subject to structural break. It is therefore important to know if a structural break has occurred and, if it has, to infer the date of the break. Motivated by this last observation, the present article develops a new break detection toolbox that is applicable to different sized panels, easy to implement and robust to general forms of unobserved heterogeneity. The toolbox, which is the first of its kind, includes a structural change test, a break date estimator, and a break date confidence interval. Application to a panel covering 61 countries from January 3 to September 25, 2020, leads to the detection of a structural break that is dated to the first week of April. The effect of COVID-19 is negative before the break and zero thereafter, implying that while markets did react, the reaction was short-lived. A possible explanation is the quantitative easing programs announced by central banks all over the world in the second half of March.},
  archive      = {J_JBES},
  author       = {Yiannis Karavias and Paresh Kumar Narayan and Joakim Westerlund},
  doi          = {10.1080/07350015.2022.2053690},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {653-666},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Structural breaks in interactive effects panels and the stock market reaction to COVID-19},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Corrigendum: Small sample methods for cluster-robust
variance estimation and hypothesis testing in fixed effects models.
<em>JBES</em>, <em>41</em>(2), 650‚Äì652. (<a
href="https://doi.org/10.1080/07350015.2023.2174123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pustejovsky and Tipton considered how to implement cluster-robust variance estimators for fixed effects models estimated by weighted (or unweighted) least squares. Theorem 2 of the paper concerns a computational short cut for a certain cluster-robust variance estimator in models with cluster-specific fixed effects. It claimed that this short cut works for models estimated by generalized least squares, as long as the weights are taken to be inverse of the working model. However, the theorem is incorrect. In this corrigendum, we review the CR2 variance estimator, describe the assertion of the theorem as originally stated, and demonstrate the error with a counter-example. We then provide a revised version of the theorem, which holds for the more limited set of models estimated by ordinary least squares.},
  archive      = {J_JBES},
  doi          = {10.1080/07350015.2023.2174123},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {650-652},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Corrigendum: Small sample methods for cluster-robust variance estimation and hypothesis testing in fixed effects models},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Circularly projected common factors for grouped data.
<em>JBES</em>, <em>41</em>(2), 636‚Äì649. (<a
href="https://doi.org/10.1080/07350015.2022.2051520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To extract the common factors from grouped data, multilevel factor models have been put forward in the literature, and methods based on iterative principal component analysis (PCA) and canonical correlation analysis (CCA) have been proposed for estimation purpose. While iterative PCA requires iteration and is hence time-consuming, CCA can only deal with two groups of data. Herein, we develop two new methods to address these problems. We first extract the factors within groups and then project the estimated group factors into the space spanned by them in a circular manner. We propose two projection processes to estimate the common factors and determine the number of them. The new methods do not require iteration and are thus computationally efficient. They can estimate the common factors for multiple groups of data in a uniform way, regardless of whether the number of groups is large or small. They not only overcome the drawbacks of CCA but also nest the CCA method as a special case. Finally, we theoretically and numerically study the consistency properties of these new methods and apply them to studying international business cycles and the comovements of retail prices.},
  archive      = {J_JBES},
  author       = {Mingjing Chen},
  doi          = {10.1080/07350015.2022.2051520},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {636-649},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Circularly projected common factors for grouped data},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Post-selection inference of high-dimensional logistic
regression under case‚Äìcontrol design. <em>JBES</em>, <em>41</em>(2),
624‚Äì635. (<a
href="https://doi.org/10.1080/07350015.2022.2050245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Confidence sets are of key importance in high-dimensional statistical inference. Under case‚Äìcontrol study, a popular response-selective sampling design in medical study or econometrics, we consider the confidence intervals and statistical tests for single or low-dimensional parameters in high-dimensional logistic regression model. The asymptotic properties of the resulting estimators are established under mild conditions. We also study statistical tests for testing more general and complex hypotheses of the high-dimensional parameters. The general testing procedures are proved to be asymptotically exact and have satisfactory power. Numerical studies including extensive simulations and a real data example confirm that the proposed method performs well in practical settings.},
  archive      = {J_JBES},
  author       = {Yuanyuan Lin and Jinhan Xie and Ruijian Han and Niansheng Tang},
  doi          = {10.1080/07350015.2022.2050245},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {624-635},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Post-selection inference of high-dimensional logistic regression under Case‚ÄìControl design},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simultaneous spatial panel data models with common shocks.
<em>JBES</em>, <em>41</em>(2), 608‚Äì623. (<a
href="https://doi.org/10.1080/07350015.2022.2046007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a simultaneous spatial panel data model, jointly modeling three effects: simultaneous effects, spatial effects and common shock effects. This joint modeling and consideration of cross-sectional heteroscedasticity result in a large number of incidental parameters. We propose two estimation approaches, a quasi-maximum likelihood method and an iterative generalized principal components method. We develop full inferential theories for the estimation approaches and study the tradeoff between the model specifications and their respective asymptotic properties. We further investigate the finite sample performance of both methods using Monte Carlo simulations. We find that both methods perform well and that the simulation results corroborate the inferential theories. Some extensions of the model are considered. Finally, we apply the model to analyze the relationship between trade and gross domestic product using a panel data over time and across countries.},
  archive      = {J_JBES},
  author       = {Lina Lu},
  doi          = {10.1080/07350015.2022.2046007},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {608-623},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Simultaneous spatial panel data models with common shocks},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Composite likelihood estimation of an autoregressive panel
ordered probit model with random effects. <em>JBES</em>, <em>41</em>(2),
593‚Äì607. (<a
href="https://doi.org/10.1080/07350015.2022.2044829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling and estimating autocorrelated discrete data can be challenging. In this article, we use an autoregressive panel ordered probit model where the serial correlation in the discrete variable is driven by the autocorrelation in the latent variable. In such a nonlinear model, the presence of a lagged latent variable results in an intractable likelihood containing high-dimensional integrals. To tackle this problem, we use composite likelihoods that involve a much lower order of integration. However, parameter identification might potentially become problematic since the information employed in lower dimensional distributions may not be rich enough for identification. Therefore, we characterize types of composite likelihoods that are valid for this model and study conditions under which the parameters can be identified. Moreover, we provide consistency and asymptotic normality results for two different composite likelihood estimators and conduct Monte Carlo studies to assess their finite-sample performances. Finally, we apply our method to analyze corporate bond ratings. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Kerem Tuzcuoglu},
  doi          = {10.1080/07350015.2022.2044829},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {593-607},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Composite likelihood estimation of an autoregressive panel ordered probit model with random effects},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Skilled mutual fund selection: False discovery control under
dependence. <em>JBES</em>, <em>41</em>(2), 578‚Äì592. (<a
href="https://doi.org/10.1080/07350015.2022.2044337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selecting skilled mutual funds through the multiple testing framework has received increasing attention from finance researchers and statisticians. The intercept Œ± of Carhart four-factor model is commonly used to measure the true performance of mutual funds, and positive Œ± ‚Äôs are considered as skilled. We observe that the standardized ordinary least-square estimates of Œ± ‚Äôs across the funds possess strong dependence and nonnormality structures, indicating that the conventional multiple testing methods are inadequate for selecting the skilled funds. We start from a decision theoretical perspective, and propose an optimal multiple testing procedure to minimize a combination of false discovery rate and false nondiscovery rate. Our proposed testing procedure is constructed based on the probability of each fund not being skilled conditional on the information across all of the funds in our study. To model the distribution of the information used for the testing procedure, we consider a mixture model under dependence and propose a new method called ‚Äúapproximate empirical Bayes‚Äù to fit the parameters. Empirical studies show that our selected skilled funds have superior long-term and short-term performance, for example, our selection strongly outperforms the S&amp;P 500 index during the same period.},
  archive      = {J_JBES},
  author       = {Lijia Wang and Xu Han and Xin Tong},
  doi          = {10.1080/07350015.2022.2044337},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {578-592},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Skilled mutual fund selection: False discovery control under dependence},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reconciled estimates of monthly GDP in the united states.
<em>JBES</em>, <em>41</em>(2), 563‚Äì577. (<a
href="https://doi.org/10.1080/07350015.2022.2044336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the United States, income and expenditure-side estimates of gross domestic product (GDP) (GDP I I I and GDP E E E ) measure ‚Äútrue‚Äù GDP with error and are available at a quarterly frequency. Methods exist for using these proxies to produce reconciled quarterly estimates of true GDP. In this paper, we extend these methods to provide reconciled historical true GDP estimates at a monthly frequency. We do this using a Bayesian mixed frequency vector autoregression (MF-VAR) involving GDP E , GDP I , unobserved true GDP, and monthly indicators of short-term economic activity. Our MF-VAR imposes restrictions that reflect a measurement-error perspective (i.e., the two GDP proxies are assumed to equal true GDP plus measurement error). Without further restrictions, our model is unidentified. We consider a range of restrictions that allow for point and set identification of true GDP and show that they lead to informative monthly GDP estimates. We illustrate how these new monthly data contribute to our historical understanding of business cycles and we provide a real-time application nowcasting monthly GDP over the pandemic recession.},
  archive      = {J_JBES},
  author       = {Gary Koop and Stuart McIntyre and James Mitchell and Aubrey Poon},
  doi          = {10.1080/07350015.2022.2044336},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {563-577},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Reconciled estimates of monthly GDP in the united states},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). QML and efficient GMM estimation of spatial autoregressive
models with dominant (popular) units. <em>JBES</em>, <em>41</em>(2),
550‚Äì562. (<a
href="https://doi.org/10.1080/07350015.2022.2041424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates QML and GMM estimation of spatial autoregressive (SAR) models in which the column sums of the spatial weights matrix might not be uniformly bounded. We develop a central limit theorem in which the number of columns with unbounded sums can be finite or infinite and the magnitude of their column sums can be O ( n Œ¥ ) if Œ¥ &lt; 1 . Asymptotic distributions of QML and GMM estimators are derived under this setting, including the GMM estimators with the best linear and quadratic moments when the disturbances are not normally distributed. The Monte Carlo experiments show that these QML and GMM estimators have satisfactory finite sample performances, while cases with a column sums magnitude of O ( n ) might not have satisfactory performance. An empirical application with growth convergence in which the trade flow network has the feature of dominant units is provided. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Lung-Fei Lee and Chao Yang and Jihai Yu},
  doi          = {10.1080/07350015.2022.2041424},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {550-562},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {QML and efficient GMM estimation of spatial autoregressive models with dominant (Popular) units},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inference for nonparametric high-frequency estimators with
an application to time variation in betas. <em>JBES</em>,
<em>41</em>(2), 538‚Äì549. (<a
href="https://doi.org/10.1080/07350015.2022.2040520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of conducting inference on nonparametric high-frequency estimators without knowing their asymptotic variances. We prove that a multivariate subsampling method achieves this goal under general conditions that were not previously available in the literature. By construction, the subsampling method delivers estimates of the variance-covariance matrices that are always positive semidefinite. Our simulation study indicates that the subsampling method is more robust than the plug-in method based on the asymptotic expression for the variance. We use our subsampling method to study the dynamics of financial betas of six stocks on the NYSE. We document significant variation in betas, and find that tick data captures more variation in betas than the data sampled at moderate frequencies such as every 5 or 20‚Äâmin. To capture this variation we estimate a simple dynamic model for betas. The variance estimation is also important for the correction of the errors-in-variables bias in such models. We find that the bias corrections are substantial, and that betas are more persistent than the naive estimators would lead one to believe.},
  archive      = {J_JBES},
  author       = {Ilze Kalnina},
  doi          = {10.1080/07350015.2022.2040520},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {538-549},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Inference for nonparametric high-frequency estimators with an application to time variation in betas},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantifying time-varying forecast uncertainty and risk for
the real price of oil. <em>JBES</em>, <em>41</em>(2), 523‚Äì537. (<a
href="https://doi.org/10.1080/07350015.2022.2039159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel and numerically efficient quantification approach to forecast uncertainty of the real price of oil using a combination of probabilistic individual model forecasts. Our combination method extends earlier approaches that have been applied to oil price forecasting, by allowing for sequentially updating of time-varying combination weights, estimation of time-varying forecast biases and facets of miscalibration of individual forecast densities and time-varying inter-dependencies among models. To illustrate the usefulness of the method, we present an extensive set of empirical results about time-varying forecast uncertainty and risk for the real price of oil over the period 1974‚Äì2018. We show that the combination approach systematically outperforms commonly used benchmark models and combination approaches, both in terms of point and density forecasts. The dynamic patterns of the estimated individual model weights are highly time-varying, reflecting a large time variation in the relative performance of the various individual models. The combination approach has built-in diagnostic information measures about forecast inaccuracy and/or model set incompleteness, which provide clear signals of model incompleteness during three crisis periods. To highlight that our approach also can be useful for policy analysis, we present a basic analysis of profit-loss and hedging against price risk.},
  archive      = {J_JBES},
  author       = {Knut Are Aastveit and Jamie L. Cross and Herman K. van Dijk},
  doi          = {10.1080/07350015.2022.2039159},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {523-537},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Quantifying time-varying forecast uncertainty and risk for the real price of oil},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detecting unobserved heterogeneity in efficient prices via
classifier-lasso. <em>JBES</em>, <em>41</em>(2), 509‚Äì522. (<a
href="https://doi.org/10.1080/07350015.2022.2036613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a new measure of efficient price as a weighted average of bid and ask prices, where the weights are constructed from the bid-ask long-run relationships in a panel error-correction model (ECM). To allow for heterogeneity in the long-run relationships, we consider a panel ECM with latent group structures so that all the stocks within a group share the same long-run relationship and do not otherwise. We extend the Classifier-Lasso method to the ECM to simultaneously identify the individual‚Äôs group membership and estimate the group-specific long-run relationship. We establish the uniform classification consistency and good asymptotic properties of the post-Lasso estimators under some regularity conditions. Empirically, we find that more than 30\% of the Standard &amp; Poor‚Äôs (S&amp;P) 1500 stocks have estimated efficient prices significantly deviating from the midpoint‚Äîa conventional measure of efficient price. Such deviations explored from our data-driven method can provide dynamic information on the extent and direction of informed trading activities.},
  archive      = {J_JBES},
  author       = {Wenxin Huang and Liangjun Su and Yuan Zhuang},
  doi          = {10.1080/07350015.2022.2036613},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {509-522},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Detecting unobserved heterogeneity in efficient prices via classifier-lasso},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Locally stationary multiplicative volatility modeling.
<em>JBES</em>, <em>41</em>(2), 497‚Äì508. (<a
href="https://doi.org/10.1080/07350015.2022.2036612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we study a semiparametric multiplicative volatility model, which splits up into a nonparametric part and a parametric GARCH component. The nonparametric part is modeled as a product of a deterministic time trend component and of further components that depend on stochastic regressors. We propose a two-step procedure to estimate the model. To estimate the nonparametric components, we transform the model and apply a backfitting procedure. The GARCH parameters are estimated in a second step via quasi maximum likelihood. We show consistency and asymptotic normality of our estimators. Our results are obtained using mixing properties and local stationarity. We illustrate our method using financial data. Finally, a small simulation study illustrates a substantial bias in the GARCH parameter estimates when omitting the stochastic regressors.},
  archive      = {J_JBES},
  author       = {Christopher Walsh and Michael Vogt},
  doi          = {10.1080/07350015.2022.2036612},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {497-508},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Locally stationary multiplicative volatility modeling},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Proper scoring rules for evaluating density forecasts with
asymmetric loss functions. <em>JBES</em>, <em>41</em>(2), 482‚Äì496. (<a
href="https://doi.org/10.1080/07350015.2022.2035229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel asymmetric continuous probabilistic score (ACPS) for evaluating and comparing density forecasts. It generalizes the proposed score and defines a weighted version, which emphasizes regions of interest, such as the tails or the center of a variable‚Äôs range. The (weighted) ACPS extends the symmetric (weighted) CRPS by allowing for asymmetries in the preferences underlying the scoring rule. A test is used to statistically compare the predictive ability of different forecasts. The ACPS is of general use in any situation where the decision-maker has asymmetric preferences in the evaluation of the forecasts. In an artificial experiment, the implications of varying the level of asymmetry in the ACPS are illustrated. Then, the proposed score and test are applied to assess and compare density forecasts of macroeconomic relevant datasets (U.S. employment growth) and of commodity prices (oil and electricity prices) with particular focus on the recent COVID-19 crisis period.},
  archive      = {J_JBES},
  author       = {Matteo Iacopini and Francesco Ravazzolo and Luca Rossini},
  doi          = {10.1080/07350015.2022.2035229},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {482-496},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Proper scoring rules for evaluating density forecasts with asymmetric loss functions},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimating density ratio of marginals to joint: Applications
to causal inference. <em>JBES</em>, <em>41</em>(2), 467‚Äì481. (<a
href="https://doi.org/10.1080/07350015.2022.2035228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In various fields of data science, researchers often face problems of estimating the ratios of two probability densities. Particularly in the context of causal inference, the product of marginals for a treatment variable and covariates to their joint density ratio typically emerges in the process of constructing causal effect estimators. This article applies the general least square density ratio estimation methodology by Kanamori, Hido and Sugiyama to the product of marginals to joint density ratio, and demonstrates its usefulness particularly for causal inference on continuous treatment effects and dose-response curves. The proposed method is illustrated by a simulation study and an empirical example to investigate the treatment effect of political advertisements in the U.S. presidential campaign data.},
  archive      = {J_JBES},
  author       = {Yukitoshi Matsushita and Taisuke Otsu and Keisuke Takahata},
  doi          = {10.1080/07350015.2022.2035228},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {467-481},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Estimating density ratio of marginals to joint: Applications to causal inference},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Testing for trend specifications in panel data models.
<em>JBES</em>, <em>41</em>(2), 453‚Äì466. (<a
href="https://doi.org/10.1080/07350015.2022.2035227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a consistent nonparametric test for common trend specifications in panel data models with fixed effects. The test is general enough to allow for heteroscedasticity, cross-sectional and serial dependence in the error components, has an asymptotically normal distribution under the null hypothesis of correct trend specification, and is consistent against various alternatives that deviate from the null. In addition, the test has an asymptotic unit power against two classes of local alternatives approaching the null at different rates. We also propose a wild bootstrap procedure to better approximate the finite sample null distribution of the test statistic. Simulation results show that the proposed test implemented with bootstrap p -values performs reasonably well in finite samples. Finally, an empirical application to the analysis of the U.S. per capita personal income trend highlights the usefulness of our test in real datasets.},
  archive      = {J_JBES},
  author       = {Jilin Wu and Xiaojun Song and Zhijie Xiao},
  doi          = {10.1080/07350015.2022.2035227},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {453-466},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Testing for trend specifications in panel data models},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predicting the global minimum variance portfolio.
<em>JBES</em>, <em>41</em>(2), 440‚Äì452. (<a
href="https://doi.org/10.1080/07350015.2022.2035226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel dynamic approach to forecast the weights of the global minimum variance portfolio (GMVP) for the conditional covariance matrix of asset returns. The GMVP weights are the population coefficients of a linear regression of a benchmark return on a vector of return differences. This representation enables us to derive a consistent loss function from which we can infer the GMVP weights without imposing any distributional assumptions on the returns. In order to capture time variation in the returns‚Äô conditional covariance structure, we model the portfolio weights through a recursive least squares (RLS) scheme as well as by generalized autoregressive score (GAS) type dynamics. Sparse parameterizations and targeting toward the weights of the equally weighted portfolio ensure scalability with respect to the number of assets. We apply these models to daily stock returns, and find that they perform well compared to existing static and dynamic approaches in terms of both the expected loss and unconditional portfolio variance.},
  archive      = {J_JBES},
  author       = {Laura Reh and Fabian Kr√ºger and Roman Liesenfeld},
  doi          = {10.1080/07350015.2022.2035226},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {440-452},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Predicting the global minimum variance portfolio},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bayesian dynamic tensor regression. <em>JBES</em>,
<em>41</em>(2), 429‚Äì439. (<a
href="https://doi.org/10.1080/07350015.2022.2032721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High- and multi-dimensional array data are becoming increasingly available. They admit a natural representation as tensors and call for appropriate statistical tools. We propose a new linear autoregressive tensor process (ART) for tensor-valued data, that encompasses some well-known time series models as special cases. We study its properties and derive the associated impulse response function. We exploit the PARAFAC low-rank decomposition for providing a parsimonious parameterization and develop a Bayesian inference allowing for shrinking effects. We apply the ART model to time series of multilayer networks and study the propagation of shocks across nodes, layers and time.},
  archive      = {J_JBES},
  author       = {Monica Billio and Roberto Casarin and Matteo Iacopini and Sylvia Kaufmann},
  doi          = {10.1080/07350015.2022.2032721},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {429-439},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Bayesian dynamic tensor regression},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A statistical recurrent stochastic volatility model for
stock markets. <em>JBES</em>, <em>41</em>(2), 414‚Äì428. (<a
href="https://doi.org/10.1080/07350015.2022.2028631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stochastic volatility (SV) model and its variants are widely used in the financial sector, while recurrent neural network (RNN) models are successfully used in many large-scale industrial applications of deep learning. We combine these two methods in a nontrivial way and propose a model, which we call the statistical recurrent stochastic volatility (SR-SV) model, to capture the dynamics of stochastic volatility. The proposed model is able to capture complex volatility effects, for example, nonlinearity and long-memory auto-dependence, overlooked by the conventional SV models, is statistically interpretable and has an impressive out-of-sample forecast performance. These properties are carefully discussed and illustrated through extensive simulation studies and applications to five international stock index datasets: the German stock index DAX30, the Hong Kong stock index HSI50, the France market index CAC40, the U.S. stock market index SP500 and the Canada market index TSX250. An user-friendly software package together with the examples reported in the article are available at https://github.com/vbayeslab .},
  archive      = {J_JBES},
  author       = {Trong-Nghia Nguyen and Minh-Ngoc Tran and David Gunawan and Robert Kohn},
  doi          = {10.1080/07350015.2022.2028631},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {414-428},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A statistical recurrent stochastic volatility model for stock markets},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel estimation method in generalized single index
models. <em>JBES</em>, <em>41</em>(2), 399‚Äì413. (<a
href="https://doi.org/10.1080/07350015.2022.2027777">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The single index and generalized single index models have been demonstrated to be a powerful tool for studying nonlinear interaction effects of variables in the low-dimensional case. In this article, we propose a new estimation approach for generalized single index models E ( Y ‚à£ ‚à£ Œ∏ ‚ä§ X ) = œà ( g ( Œ∏ ‚ä§ X ) ) E ( Y | Œ∏ ‚ä§ X ) = œà ( g ( Œ∏ ‚ä§ X ) ) E(Y¬†|¬†Œ∏‚ä§X)=œà(g(Œ∏‚ä§X)) with œà ( ¬∑ ) œà ( ¬∑ ) œà(¬∑) known but g ( ¬∑ ) g ( ¬∑ ) g(¬∑) unknown. Specifically, we first obtain a consistent estimator of the regression function by using a local linear smoother, and then estimate the parametric components by treating œà ( g ÃÇ ( Œ∏ ‚ä§ X i ) ) as our continuous response. The resulting estimators of Œ∏ are asymptotically normal. The proposed procedure can substantially overcome convergence problems encountered in generalized linear models with discrete response variables when sparseness occurs and misspecification. We conduct simulation experiments to evaluate the numerical performance of the proposed methods and analyze a financial dataset from a peer-to-peer lending platform of China as an illustration.},
  archive      = {J_JBES},
  author       = {Dixin Zhang and Yulin Wang and Hua Liang},
  doi          = {10.1080/07350015.2022.2027777},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {399-413},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A novel estimation method in generalized single index models},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning human activity patterns using clustered point
processes with active and inactive states. <em>JBES</em>,
<em>41</em>(2), 388‚Äì398. (<a
href="https://doi.org/10.1080/07350015.2021.2025065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling event patterns is a central task in a wide range of disciplines. In applications such as studying human activity patterns, events often arrive clustered with sporadic and long periods of inactivity. Such heterogeneity in event patterns poses challenges for existing point process models. In this article, we propose a new class of clustered point processes that alternate between active and inactive states. The proposed model is flexible, highly interpretable, and can provide useful insights into event patterns. A composite likelihood approach and a composite EM estimation procedure are developed for efficient and numerically stable parameter estimation. We study both the computational and statistical properties of the estimator including convergence, consistency, and asymptotic normality. The proposed method is applied to Donald Trump‚Äôs Twitter data to investigate if and how his behaviors evolved before, during, and after the presidential campaign. Additionally, we analyze large-scale social media data from Sina Weibo and identify interesting groups of users with distinct behaviors.},
  archive      = {J_JBES},
  author       = {Jingfei Zhang and Biao Cai and Xuening Zhu and Hansheng Wang and Ganggang Xu and Yongtao Guan},
  doi          = {10.1080/07350015.2021.2025065},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {388-398},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Learning human activity patterns using clustered point processes with active and inactive states},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-threshold structural equation model. <em>JBES</em>,
<em>41</em>(2), 377‚Äì387. (<a
href="https://doi.org/10.1080/07350015.2021.2023553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we consider the instrumental variable estimation for causal regression parameters with multiple unknown structural changes across subpopulations. We propose a multiple change point detection method to determine the number of thresholds and estimate the threshold locations in the two-stage least square procedure. After identifying the estimated threshold locations, we use the Wald method to estimate the parameters of interest, that is, the regression coefficients of the endogenous variable. Based on some technical assumptions, we carefully establish the consistency of estimated parameters and the asymptotic normality of causal coefficients. Simulation studies are included to examine the performance of the proposed method. Finally, our method is illustrated via an application of the Philippine farm households data for which some new findings are discovered.},
  archive      = {J_JBES},
  author       = {Jingli Wang and Jialiang Li},
  doi          = {10.1080/07350015.2021.2023553},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {377-387},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Multi-threshold structural equation model},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On testing equal conditional predictive ability under
measurement error. <em>JBES</em>, <em>41</em>(2), 364‚Äì376. (<a
href="https://doi.org/10.1080/07350015.2021.2021923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Loss functions are widely used to compare several competing forecasts. However, forecast comparisons are often based on mismeasured proxy variables for the true target. We introduce the concept of exact robustness to measurement error for loss functions and fully characterize this class of loss functions as the Bregman class. Hence, only conditional mean forecasts can be evaluated exactly robustly. For such exactly robust loss functions, forecast loss differences are on average unaffected by the use of proxy variables and, thus, inference on conditional predictive ability can be carried out as usual. Moreover, we show that more precise proxies give predictive ability tests higher power in discriminating between competing forecasts. Simulations illustrate the different behavior of exactly robust and nonrobust loss functions. An empirical application to U.S. GDP growth rates demonstrates the nonrobustness of quantile forecasts. It also shows that it is easier to discriminate between mean forecasts issued at different horizons if a better proxy for GDP growth is used.},
  archive      = {J_JBES},
  author       = {Yannick Hoga and Timo Dimitriadis},
  doi          = {10.1080/07350015.2021.2021923},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {364-376},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {On testing equal conditional predictive ability under measurement error},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Density forecasts in panel data models: A semiparametric
bayesian perspective. <em>JBES</em>, <em>41</em>(2), 349‚Äì363. (<a
href="https://doi.org/10.1080/07350015.2021.2021922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article constructs individual-specific density forecasts for a panel of firms or households using a dynamic linear model with common and heterogeneous coefficients as well as cross-sectional heteroscedasticity. The panel considered in this article features a large cross-sectional dimension N but short time series T. Due to the short T, traditional methods have difficulty in disentangling the heterogeneous parameters from the shocks, which contaminates the estimates of the heterogeneous parameters. To tackle this problem, I assume that there is an underlying distribution of heterogeneous parameters, model this distribution nonparametrically allowing for correlation between heterogeneous parameters and initial conditions as well as individual-specific regressors, and then estimate this distribution by combining information from the whole panel. Theoretically, I prove that in cross-sectional homoscedastic cases, both the estimated common parameters and the estimated distribution of the heterogeneous parameters achieve posterior consistency, and that the density forecasts asymptotically converge to the oracle forecast. Methodologically, I develop a simulation-based posterior sampling algorithm specifically addressing the nonparametric density estimation of unobserved heterogeneous parameters. Monte Carlo simulations and an empirical application to young firm dynamics demonstrate improvements in density forecasts relative to alternative approaches.},
  archive      = {J_JBES},
  author       = {Laura Liu},
  doi          = {10.1080/07350015.2021.2021922},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {349-363},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Density forecasts in panel data models: A semiparametric bayesian perspective},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diagnostic testing of finite moment conditions for the
consistency and root-n asymptotic normality of the GMM and m estimators.
<em>JBES</em>, <em>41</em>(2), 339‚Äì348. (<a
href="https://doi.org/10.1080/07350015.2021.2019047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Common econometric analyses based on point estimates, standard errors, and confidence intervals presume the consistency and the root-n asymptotic normality of the GMM or M estimators. However, their key assumptions that data entail finite moments may not be always satisfied in applications. This article proposes a method of diagnostic testing for these key assumptions with applications to both simulated and real datasets.},
  archive      = {J_JBES},
  author       = {Yuya Sasaki and Yulong Wang},
  doi          = {10.1080/07350015.2021.2019047},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {339-348},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Diagnostic testing of finite moment conditions for the consistency and root-N asymptotic normality of the GMM and m estimators},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identification-robust inference with simulation-based
pseudo-matching. <em>JBES</em>, <em>41</em>(2), 321‚Äì338. (<a
href="https://doi.org/10.1080/07350015.2021.2019046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a general simulation-based inference procedure for partially specified models. Our procedure is based on matching auxiliary statistics to simulated counterparts where nuisance parameters are calibrated neither assuming identification of parameters of interest nor a one-to-one binding function. The conditions underlying the asymptotic validity of our (pseudo-)simulators in conjunction with appropriate bootstraps are characterized beyond the strict and exact calibration of the parameters of the simulator. Our procedure is illustrated through impulse-response (IR) matching in a simulation study of a stylized dynamic stochastic equilibrium model, and two empirical applications on the New Keynesian Phillips curve and on the Industrial Production index. In addition to usual Wald-type statistics that combine structural or reduced form IRs, we analyze local projections IRs through a factor-analytic measure of distance which eschews the need to define a weighting matrix.},
  archive      = {J_JBES},
  author       = {Bertille Antoine and Lynda Khalaf and Maral Kichian and Zhenjiang Lin},
  doi          = {10.1080/07350015.2021.2019046},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {321-338},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Identification-robust inference with simulation-based pseudo-matching},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). No-crossing single-index quantile regression curve
estimation. <em>JBES</em>, <em>41</em>(2), 309‚Äì320. (<a
href="https://doi.org/10.1080/07350015.2021.2013245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-index quantile regression (QR) models can avoid the curse of dimensionality in nonparametric problems by assuming that the response is only related to a single linear combination of the covariates. Like the standard parametric or nonparametric QR whose estimated curves may cross, the single-index QR can also suffer quantile crossing, leading to an invalid distribution for the response. This issue has attracted considerable attention in the literature in the recent year. In this article, we consider single-index models, develop methods for QR that guarantee noncrossing quantile curves, and extend the methods and results to composite quantile regression. The asymptotic properties of the proposed estimators are derived and their advantages over existing methods are explained. Simulation studies and a real data application are conducted to illustrate the finite sample performance of the proposed methods.},
  archive      = {J_JBES},
  author       = {Rong Jiang and Keming Yu},
  doi          = {10.1080/07350015.2021.2013245},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {309-320},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {No-crossing single-index quantile regression curve estimation},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic score-driven independent component analysis.
<em>JBES</em>, <em>41</em>(2), 298‚Äì308. (<a
href="https://doi.org/10.1080/07350015.2021.2013244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A model for dynamic independent component analysis is introduced where the dynamics are driven by the score of the pseudo likelihood with respect to the rotation angle of model innovations. While conditional second moments are invariant with respect to rotations, higher conditional moments are not, which may have important implications for applications. The pseudo maximum likelihood estimator of the model is shown to be consistent and asymptotically normally distributed. A simulation study reports good finite sample properties of the estimator, including the case of a misspecification of the innovation density. In an application to a bivariate exchange rate series of the Euro and the British Pound against the U.S. Dollar, it is shown that the model-implied conditional portfolio kurtosis largely aligns with narratives on financial stress as a result of the global financial crisis in 2008, the European sovereign debt crisis (2010‚Äì2013) and early rumors signalling the United Kingdom to leave the European Union (2017). These insights are consistent with a recently proposed model that associates portfolio kurtosis with a geopolitical risk factor.},
  archive      = {J_JBES},
  author       = {Christian M. Hafner and Helmut Herwartz},
  doi          = {10.1080/07350015.2021.2013244},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {298-308},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Dynamic score-driven independent component analysis},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). -penalized pairwise difference estimation for a
high-dimensional censored regression model. <em>JBES</em>,
<em>41</em>(2), 283‚Äì297. (<a
href="https://doi.org/10.1080/07350015.2021.2013243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional data are nowadays readily available and increasingly common in various fields of empirical economics. This article considers estimation and model selection for a high-dimensional censored linear regression model. We combine l 1 l 1 l1 -penalization method with the ideas of pairwise difference and propose an l 1 l 1 l1 -penalized pairwise difference least absolute deviations (LAD) estimator. Estimation consistency and model selection consistency of the estimator are established under regularity conditions. We also propose a post-penalized estimator that applies unpenalized pairwise difference LAD estimation to the model selected by the l 1 -penalized estimator, and find that the post-penalized estimator generally can perform better than the l 1 -penalized estimator in terms of the rate of convergence. Novel fast algorithms for computing the proposed estimators are provided based on the alternating direction method of multipliers. A simulation study is conducted to show the great improvements of our algorithms in terms of computation time and to illustrate the satisfactory statistical performance of our estimators.},
  archive      = {J_JBES},
  author       = {Zhewen Pan and Jianhui Xie},
  doi          = {10.1080/07350015.2021.2013243},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {283-297},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {-penalized pairwise difference estimation for a high-dimensional censored regression model},
  volume       = {41},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
