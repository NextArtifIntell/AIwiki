<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NATMI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="natmi---180">NATMI - 180</h2>
<ul>
<li><details>
<summary>
(2023). A challenge for the law and artificial intelligence.
<em>NATMI</em>, <em>5</em>(12), 1508–1509. (<a
href="https://doi.org/10.1038/s42256-023-00768-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Borrowing the format of public competitions from engineering and computer science, a new type of challenge in 2023 tested real-world AI applications with legal assessments based on the EU AI Act.},
  archive      = {J_NATMI},
  author       = {Burri, Thomas},
  doi          = {10.1038/s42256-023-00768-5},
  journal      = {Nature Machine Intelligence},
  number       = {12},
  pages        = {1508-1509},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A challenge for the law and artificial intelligence},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A statistical mechanics framework for bayesian deep neural
networks beyond the infinite-width limit. <em>NATMI</em>,
<em>5</em>(12), 1497–1507. (<a
href="https://doi.org/10.1038/s42256-023-00767-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the practical success of deep neural networks, a comprehensive theoretical framework that can predict practically relevant scores, such as the test accuracy, from knowledge of the training data is currently lacking. Huge simplifications arise in the infinite-width limit, in which the number of units Nℓ in each hidden layer (ℓ = 1, …, L, where L is the depth of the network) far exceeds the number P of training examples. This idealization, however, blatantly departs from the reality of deep learning practice. Here we use the toolset of statistical mechanics to overcome these limitations and derive an approximate partition function for fully connected deep neural architectures, which encodes information on the trained models. The computation holds in the thermodynamic limit, where both Nℓ and P are large and their ratio αℓ = P/Nℓ is finite. This advance allows us to obtain: (1) a closed formula for the generalization error associated with a regression task in a one-hidden layer network with finite α1; (2) an approximate expression of the partition function for deep architectures (via an effective action that depends on a finite number of order parameters); and (3) a link between deep neural networks in the proportional asymptotic limit and Student’s t-processes. Theoretical frameworks aiming to understand deep learning rely on a so-called infinite-width limit, in which the ratio between the width of hidden layers and the training set size goes to zero. Pacelli and colleagues go beyond this restrictive framework by computing the partition function and generalization properties of fully connected, nonlinear neural networks, both with one and with multiple hidden layers, for the practically more relevant scenario in which the above ratio is finite and arbitrary.},
  archive      = {J_NATMI},
  author       = {Pacelli, R. and Ariosto, S. and Pastore, M. and Ginelli, F. and Gherardi, M. and Rotondo, P.},
  doi          = {10.1038/s42256-023-00767-6},
  journal      = {Nature Machine Intelligence},
  number       = {12},
  pages        = {1497-1507},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A statistical mechanics framework for bayesian deep neural networks beyond the infinite-width limit},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Defending ChatGPT against jailbreak attack via
self-reminders. <em>NATMI</em>, <em>5</em>(12), 1486–1496. (<a
href="https://doi.org/10.1038/s42256-023-00765-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ChatGPT is a societally impactful artificial intelligence tool with millions of users and integration into products such as Bing. However, the emergence of jailbreak attacks notably threatens its responsible and secure use. Jailbreak attacks use adversarial prompts to bypass ChatGPT’s ethics safeguards and engender harmful responses. This paper investigates the severe yet under-explored problems created by jailbreaks as well as potential defensive techniques. We introduce a jailbreak dataset with various types of jailbreak prompts and malicious instructions. We draw inspiration from the psychological concept of self-reminders and further propose a simple yet effective defence technique called system-mode self-reminder. This technique encapsulates the user’s query in a system prompt that reminds ChatGPT to respond responsibly. Experimental results demonstrate that self-reminders significantly reduce the success rate of jailbreak attacks against ChatGPT from 67.21\% to 19.34\%. Our work systematically documents the threats posed by jailbreak attacks, introduces and analyses a dataset for evaluating defensive interventions and proposes the psychologically inspired self-reminder technique that can efficiently and effectively mitigate against jailbreaks without further training. Interest in using large language models such as ChatGPT has grown rapidly, but concerns about safe and responsible use have emerged, in part because adversarial prompts can bypass existing safeguards with so-called jailbreak attacks. Wu et al. build a dataset of various types of jailbreak attack prompt and demonstrate a simple but effective technique to counter these attacks by encapsulating users’ prompts in another standard prompt that reminds ChatGPT to respond responsibly.},
  archive      = {J_NATMI},
  author       = {Xie, Yueqi and Yi, Jingwei and Shao, Jiawei and Curl, Justin and Lyu, Lingjuan and Chen, Qifeng and Xie, Xing and Wu, Fangzhao},
  doi          = {10.1038/s42256-023-00765-8},
  journal      = {Nature Machine Intelligence},
  number       = {12},
  pages        = {1486-1496},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Defending ChatGPT against jailbreak attack via self-reminders},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bridging the gap between chemical reaction pretraining and
conditional molecule generation with a unified model. <em>NATMI</em>,
<em>5</em>(12), 1476–1485. (<a
href="https://doi.org/10.1038/s42256-023-00764-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chemical reactions are the fundamental building blocks of drug design and organic chemistry research. In recent years, there has been a growing need for a large-scale deep-learning framework that can efficiently capture the basic rules of chemical reactions. In this paper, we have proposed a unified framework that addresses both the reaction-representation learning and molecule generation tasks, which allows for a more holistic approach. Inspired by the organic chemistry mechanism, we develop a new pretraining framework that enables us to incorporate inductive biases into the model. Our framework achieves state-of-the-art results in performance of challenging downstream tasks. By possessing chemical knowledge, our generative framework overcomes the limitations of current molecule generation models that rely on a small number of reaction templates. In extensive experiments, our model generates synthesizable drug-like structures of high quality. Overall, our work presents a noteworthy step toward a large-scale deep-learning framework for a variety of reaction-based applications. Virtual drug design has seen recent progress in methods that can generate new molecules with specific properties. Separately, methods have also improved in the task of computationally predicting the outcome of chemical reactions. Qiang and colleagues use the close relation of the two problems to train a model that aims at solving both tasks.},
  archive      = {J_NATMI},
  author       = {Qiang, Bo and Zhou, Yiran and Ding, Yuheng and Liu, Ningfeng and Song, Song and Zhang, Liangren and Huang, Bo and Liu, Zhenming},
  doi          = {10.1038/s42256-023-00764-9},
  journal      = {Nature Machine Intelligence},
  number       = {12},
  pages        = {1476-1485},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Bridging the gap between chemical reaction pretraining and conditional molecule generation with a unified model},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inverse design of nonlinear mechanical metamaterials via
video denoising diffusion models. <em>NATMI</em>, <em>5</em>(12),
1466–1475. (<a
href="https://doi.org/10.1038/s42256-023-00762-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accelerated inverse design of complex material properties—such as identifying a material with a given stress–strain response over a nonlinear deformation path—holds great potential for addressing challenges from soft robotics to biomedical implants and impact mitigation. Although machine learning models have provided such inverse mappings, they are typically restricted to linear target properties such as stiffness. Here, to tailor the nonlinear response, we show that video diffusion generative models trained on full-field data of periodic stochastic cellular structures can successfully predict and tune their nonlinear deformation and stress response under compression in the large-strain regime, including buckling and contact. Key to success is to break from the common strategy of directly learning a map from property to design and to extend the framework to intrinsically estimate the expected deformation path and the full-field internal stress distribution, which closely agree with finite element simulations. This work thus has the potential to simplify and accelerate the identification of materials with complex target performance. Machine learning models have been widely used in the inverse design of new materials, but typically only linear properties could be targeted. Bastek and Kochmann show that video diffusion generative models can produce the nonlinear deformation and stress response of cellular materials under large-scale compression.},
  archive      = {J_NATMI},
  author       = {Bastek, Jan-Hendrik and Kochmann, Dennis M.},
  doi          = {10.1038/s42256-023-00762-x},
  journal      = {Nature Machine Intelligence},
  number       = {12},
  pages        = {1466-1475},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Inverse design of nonlinear mechanical metamaterials via video denoising diffusion models},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Physics-enhanced deep surrogates for partial differential
equations. <em>NATMI</em>, <em>5</em>(12), 1458–1465. (<a
href="https://doi.org/10.1038/s42256-023-00761-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many physics and engineering applications demand partial differential equations (PDE) property evaluations that are traditionally computed with resource-intensive high-fidelity numerical solvers. Data-driven surrogate models provide an efficient alternative but come with a substantial cost of training. Emerging applications would benefit from surrogates with an improved accuracy–cost tradeoff when studied at scale. Here we present a ‘physics-enhanced deep-surrogate’ (PEDS) approach towards developing fast surrogate models for complex physical systems, which is described by PDEs. Specifically, a combination of a low-fidelity, explainable physics simulator and a neural network generator is proposed, which is trained end-to-end to globally match the output of an expensive high-fidelity numerical solver. Experiments on three exemplar test cases, diffusion, reaction–diffusion and electromagnetic scattering models, show that a PEDS surrogate can be up to three times more accurate than an ensemble of feedforward neural networks with limited data (approximately 103 training points), and reduces the training data need by at least a factor of 100 to achieve a target error of 5\%. Experiments reveal that PEDS provides a general, data-driven strategy to bridge the gap between a vast array of simplified physical models with corresponding brute-force numerical solvers modelling complex systems, offering accuracy, speed and data efficiency, as well as physical insights into the process. Data-driven surrogate models are used in computational physics and engineering to greatly speed up evaluations of the properties of partial differential equations, but they come with a heavy computational cost associated with training. Pestourie et al. combine a low-fidelity physics model with a generative deep neural network and demonstrate improved accuracy–cost trade-offs compared with standard deep neural networks and high-fidelity numerical solvers.},
  archive      = {J_NATMI},
  author       = {Pestourie, Raphaël and Mroueh, Youssef and Rackauckas, Chris and Das, Payel and Johnson, Steven G.},
  doi          = {10.1038/s42256-023-00761-y},
  journal      = {Nature Machine Intelligence},
  number       = {12},
  pages        = {1458-1465},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Physics-enhanced deep surrogates for partial differential equations},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-modal molecule structure–text model for text-based
retrieval and editing. <em>NATMI</em>, <em>5</em>(12), 1447–1457. (<a
href="https://doi.org/10.1038/s42256-023-00759-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is increasing adoption of artificial intelligence in drug discovery. However, existing studies use machine learning to mainly utilize the chemical structures of molecules but ignore the vast textual knowledge available in chemistry. Incorporating textual knowledge enables us to realize new drug design objectives, adapt to text-based instructions and predict complex biological activities. Here we present a multi-modal molecule structure–text model, MoleculeSTM, by jointly learning molecules’ chemical structures and textual descriptions via a contrastive learning strategy. To train MoleculeSTM, we construct a large multi-modal dataset, namely, PubChemSTM, with over 280,000 chemical structure–text pairs. To demonstrate the effectiveness and utility of MoleculeSTM, we design two challenging zero-shot tasks based on text instructions, including structure–text retrieval and molecule editing. MoleculeSTM has two main properties: open vocabulary and compositionality via natural language. In experiments, MoleculeSTM obtains the state-of-the-art generalization ability to novel biochemical concepts across various benchmarks. Machine learning methods in cheminformatics have made great progress in using chemical structures of molecules, but a large portion of textual information remains scarcely explored. Liu and colleagues trained MoleculeSTM, a foundation model that aligns the structure and text modalities through contrastive learning, and show its utility on the downstream tasks of structure–text retrieval, text-guided editing and molecular property prediction.},
  archive      = {J_NATMI},
  author       = {Liu, Shengchao and Nie, Weili and Wang, Chengpeng and Lu, Jiarui and Qiao, Zhuoran and Liu, Ling and Tang, Jian and Xiao, Chaowei and Anandkumar, Animashree},
  doi          = {10.1038/s42256-023-00759-6},
  journal      = {Nature Machine Intelligence},
  number       = {12},
  pages        = {1447-1457},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Multi-modal molecule structure–text model for text-based retrieval and editing},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reusability report: Learning the transcriptional grammar in
single-cell RNA-sequencing data using transformers. <em>NATMI</em>,
<em>5</em>(12), 1437–1446. (<a
href="https://doi.org/10.1038/s42256-023-00757-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of single-cell genomics is an attractive opportunity for data-hungry machine learning algorithms. The scBERT method, inspired by the success of BERT (‘bidirectional encoder representations from transformers’) in natural language processing, was recently introduced by Yang et al. as a data-driven tool to annotate cell types in single-cell genomics data. Analogous to contextual embedding in BERT, scBERT leverages pretraining and self-attention mechanisms to learn the ‘transcriptional grammar’ of cells. Here we investigate the reusability beyond the original datasets, assessing the generalizability of natural language techniques in single-cell genomics. The degree of imbalance in the cell-type distribution substantially influences the performance of scBERT. Anticipating an increased utilization of transformers, we highlight the necessity to consider data distribution carefully and introduce a subsampling technique to mitigate the influence of an imbalanced distribution. Our analysis serves as a stepping stone towards understanding and optimizing the use of transformers in single-cell genomics. scBERT, a pretrained neural network for single-cell sequencing tasks, was published last year in Nature Machine Intelligence. To test the reusability of the method, Khan et al. use the code to assess the generalizablility of transformer architectures on single-cell genomics tasks.},
  archive      = {J_NATMI},
  author       = {Khan, Sumeer Ahmad and Maillo, Alberto and Lagani, Vincenzo and Lehmann, Robert and Kiani, Narsis A. and Gomez-Cabrero, David and Tegner, Jesper},
  doi          = {10.1038/s42256-023-00757-8},
  journal      = {Nature Machine Intelligence},
  number       = {12},
  pages        = {1437-1446},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Reusability report: Learning the transcriptional grammar in single-cell RNA-sequencing data using transformers},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning characteristics of graph neural networks predicting
protein–ligand affinities. <em>NATMI</em>, <em>5</em>(12), 1427–1436.
(<a href="https://doi.org/10.1038/s42256-023-00756-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In drug design, compound potency prediction is a popular machine learning application. Graph neural networks (GNNs) predict ligand affinity from graph representations of protein–ligand interactions typically extracted from X-ray structures. Despite some promising findings leading to claims that GNNs can learn details of protein–ligand interactions, such predictions are also controversially viewed. For example, evidence has been presented that GNNs might not learn protein–ligand interactions but memorize ligand and protein training data instead. We have carried out affinity predictions with six GNN architectures on community-standard datasets and rationalized the predictions using explainable artificial intelligence. The results confirm a strong influence of ligand—but not protein—memorization during GNN learning and also show that some GNN architectures increasingly prioritize interaction information for predicting high affinities. Thus, while GNNs do not comprehensively account for protein–ligand interactions and physical reality, depending on the model, they balance ligand memorization with learning of interaction patterns. Graph neural networks have proved useful in modelling proteins and their ligand interactions, but it is not clear whether the patterns they identify have biological relevance or whether interactions are merely memorized. Mastropietro et al. use a Shapley value-based method to identify important edges in protein interaction graphs, enabling explanatory analysis of the model mechanisms.},
  archive      = {J_NATMI},
  author       = {Mastropietro, Andrea and Pasculli, Giuseppe and Bajorath, Jürgen},
  doi          = {10.1038/s42256-023-00756-9},
  journal      = {Nature Machine Intelligence},
  number       = {12},
  pages        = {1427-1436},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Learning characteristics of graph neural networks predicting protein–ligand affinities},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Better models of human high-level visual cortex emerge from
natural language supervision with a large and diverse dataset.
<em>NATMI</em>, <em>5</em>(12), 1415–1426. (<a
href="https://doi.org/10.1038/s42256-023-00753-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-performing neural networks for vision have dramatically advanced our ability to account for neural data in biological systems. Recently, further improvement in performance of these neural networks has been catalysed by joint training on images and natural language, increased dataset sizes and data diversity. We explored whether the same factors (joint training, dataset size and diversity) support similar improvements in the prediction of visual responses in the human brain. We used models pretrained with Contrastive Language-Image Pretraining (CLIP)—which learns image embeddings that best match text embeddings of image captions from diverse, large-scale datasets—to study visual representations. We built voxelwise encoding models based on CLIP image features to predict brain responses to real-world images. We found that ResNet50 with CLIP is a better model of high-level visual cortex, explaining up to R2 = 79\% of variance in voxel responses in held-out test data, a substantial increase from models trained only with image/label pairs (ImageNet trained ResNet) or text (BERT). Comparisons across different model backbones ruled out network architecture as a factor in performance improvements. Comparisons across models that controlled for dataset size and data diversity demonstrated that language feedback along with large and diverse datasets are important factors in explaining neural responses in high-level visual brain regions. Visualizations of model embeddings and principal component analysis revealed that our models capture both global and fine-grained semantic dimensions represented within human visual cortex. Prediction of high-level visual representations in the human brain may benefit from multimodal sources in network training and the incorporation of complex datasets. Wang and colleagues show that language pretraining and a large, diverse dataset together build better models of higher-level visual cortex compared to earlier models.},
  archive      = {J_NATMI},
  author       = {Wang, Aria Y. and Kay, Kendrick and Naselaris, Thomas and Tarr, Michael J. and Wehbe, Leila},
  doi          = {10.1038/s42256-023-00753-y},
  journal      = {Nature Machine Intelligence},
  number       = {12},
  pages        = {1415-1426},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Better models of human high-level visual cortex emerge from natural language supervision with a large and diverse dataset},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical generative modelling for autonomous robots.
<em>NATMI</em>, <em>5</em>(12), 1402–1414. (<a
href="https://doi.org/10.1038/s42256-023-00752-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans generate intricate whole-body motions by planning, executing and combining individual limb movements. We investigated this fundamental aspect of motor control and approached the problem of autonomous task completion by hierarchical generative modelling with multi-level planning, emulating the deep temporal architecture of human motor control. We explored the temporal depth of nested timescales, where successive levels of a forward or generative model unfold, for example, object delivery requires both global planning and local coordination of limb movements. This separation of temporal scales suggests the advantage of hierarchically organizing the global planning and local control of individual limbs. We validated our proposed formulation extensively through physics simulation. Using a hierarchical generative model, we showcase that an embodied artificial intelligence system, a humanoid robot, can autonomously complete a complex task requiring a holistic use of locomotion, manipulation and grasping: the robot adeptly retrieves and transports a box, opens and walks through a door, kicks a football and exhibits robust performance even in the presence of body damage and ground irregularities. Our findings demonstrated the efficacy and feasibility of human-inspired motor control for an embodied artificial intelligence robot, highlighting the viability of the formulized hierarchical architecture for achieving autonomous completion of challenging goal-directed tasks. Human and animal motion planning works at various timescales to allow the completion of complex tasks. Inspired by this natural strategy, Yuan and colleagues present a hierarchical motion planning approach for robotics, using deep reinforcement learning and predictive proprioception.},
  archive      = {J_NATMI},
  author       = {Yuan, Kai and Sajid, Noor and Friston, Karl and Li, Zhibin},
  doi          = {10.1038/s42256-023-00752-z},
  journal      = {Nature Machine Intelligence},
  number       = {12},
  pages        = {1402-1414},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Hierarchical generative modelling for autonomous robots},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Calibrated geometric deep learning improves kinase–drug
binding predictions. <em>NATMI</em>, <em>5</em>(12), 1390–1401. (<a
href="https://doi.org/10.1038/s42256-023-00751-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein kinases regulate various cellular functions and hold significant pharmacological promise in cancer and other diseases. Although kinase inhibitors are one of the largest groups of approved drugs, much of the human kinome remains unexplored but potentially druggable. Computational approaches, such as machine learning, offer efficient solutions for exploring kinase–compound interactions and uncovering novel binding activities. Despite the increasing availability of three-dimensional (3D) protein and compound structures, existing methods predominantly focus on exploiting local features from one-dimensional protein sequences and two-dimensional molecular graphs to predict binding affinities, overlooking the 3D nature of the binding process. Here we present KDBNet, a deep learning algorithm that incorporates 3D protein and molecule structure data to predict binding affinities. KDBNet uses graph neural networks to learn structure representations of protein binding pockets and drug molecules, capturing the geometric and spatial characteristics of binding activity. In addition, we introduce an algorithm to quantify and calibrate the uncertainties of KDBNet’s predictions, enhancing its utility in model-guided discovery in chemical or protein space. Experiments demonstrated that KDBNet outperforms existing deep learning models in predicting kinase–drug binding affinities. The uncertainties estimated by KDBNet are informative and well-calibrated with respect to prediction errors. When integrated with a Bayesian optimization framework, KDBNet enables data-efficient active learning and accelerates the exploration and exploitation of diverse high-binding kinase–drug pairs. Geometric deep learning has become a powerful tool in virtual drug design, but it is not always obvious when a model makes incorrect predictions. Luo and colleagues improve the accuracy of their deep learning model using uncertainty calibration and Bayesian optimization in an active learning cycle.},
  archive      = {J_NATMI},
  author       = {Luo, Yunan and Liu, Yang and Peng, Jian},
  doi          = {10.1038/s42256-023-00751-0},
  journal      = {Nature Machine Intelligence},
  number       = {12},
  pages        = {1390-1401},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Calibrated geometric deep learning improves kinase–drug binding predictions},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Topological structure of complex predictions.
<em>NATMI</em>, <em>5</em>(12), 1382–1389. (<a
href="https://doi.org/10.1038/s42256-023-00749-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current complex prediction models are the result of fitting deep neural networks, graph convolutional networks or transducers to a set of training data. A key challenge with these models is that they are highly parameterized, which makes describing and interpreting the prediction strategies difficult. We use topological data analysis to transform these complex prediction models into a simplified topological view of the prediction landscape. The result is a map of the predictions that enables inspection of the model results with more specificity than dimensionality-reduction methods such as tSNE and UMAP. The methods scale up to large datasets across different domains. We present a case study of a transformer-based model previously designed to predict expression levels of a piece of DNA in thousands of genomic tracks. When the model is used to study mutations in the BRCA1 gene, our topological analysis shows that it is sensitive to the location of a mutation and the exon structure of BRCA1 in ways that cannot be found with tools based on dimensionality reduction. Moreover, the topological framework offers multiple ways to inspect results, including an error estimate that is more accurate than model uncertainty. Further studies show how these ideas produce useful results in graph-based learning and image classification. Deep learning is a powerful method to process large datasets, and shown to be useful in many scientific fields, but models are highly parameterized and there are often challenges in interpretation and generalization. David Gleich and colleagues develop a method rooted in computational topology, starting with a graph-based topological representation of the data, to help assess and diagnose predictions from deep learning and other complex prediction methods.},
  archive      = {J_NATMI},
  author       = {Liu, Meng and Dey, Tamal K. and Gleich, David F.},
  doi          = {10.1038/s42256-023-00749-8},
  journal      = {Nature Machine Intelligence},
  number       = {12},
  pages        = {1382-1389},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Topological structure of complex predictions},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatially embedded recurrent neural networks reveal
widespread links between structural and functional neuroscience
findings. <em>NATMI</em>, <em>5</em>(12), 1369–1381. (<a
href="https://doi.org/10.1038/s42256-023-00748-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain networks exist within the confines of resource limitations. As a result, a brain network must overcome the metabolic costs of growing and sustaining the network within its physical space, while simultaneously implementing its required information processing. Here, to observe the effect of these processes, we introduce the spatially embedded recurrent neural network (seRNN). seRNNs learn basic task-related inferences while existing within a three-dimensional Euclidean space, where the communication of constituent neurons is constrained by a sparse connectome. We find that seRNNs converge on structural and functional features that are also commonly found in primate cerebral cortices. Specifically, they converge on solving inferences using modular small-world networks, in which functionally similar units spatially configure themselves to utilize an energetically efficient mixed-selective code. Because these features emerge in unison, seRNNs reveal how many common structural and functional brain motifs are strongly intertwined and can be attributed to basic biological optimization processes. seRNNs incorporate biophysical constraints within a fully artificial system and can serve as a bridge between structural and functional research communities to move neuroscientific understanding forwards. A fundamental question in neuroscience is what are the constraints that shape the structural and functional organization of the brain. By bringing biological cost constraints into the optimization process of artificial neural networks, Achterberg, Akarca and colleagues uncover the joint principle underlying a large set of neuroscientific findings.},
  archive      = {J_NATMI},
  author       = {Achterberg, Jascha and Akarca, Danyal and Strouse, D. J. and Duncan, John and Astle, Duncan E.},
  doi          = {10.1038/s42256-023-00748-9},
  journal      = {Nature Machine Intelligence},
  number       = {12},
  pages        = {1369-1381},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Spatially embedded recurrent neural networks reveal widespread links between structural and functional neuroscience findings},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Incorporating neuro-inspired adaptability for continual
learning in artificial intelligence. <em>NATMI</em>, <em>5</em>(12),
1356–1368. (<a
href="https://doi.org/10.1038/s42256-023-00747-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual learning aims to empower artificial intelligence with strong adaptability to the real world. For this purpose, a desirable solution should properly balance memory stability with learning plasticity, and acquire sufficient compatibility to capture the observed distributions. Existing advances mainly focus on preserving memory stability to overcome catastrophic forgetting, but it remains difficult to flexibly accommodate incremental changes as biological intelligence does. Here, by modelling a robust Drosophila learning system that actively regulates forgetting with multiple learning modules, we propose a generic approach that appropriately attenuates old memories in parameter distributions to improve learning plasticity, and accordingly coordinates a multi-learner architecture to ensure solution compatibility. Through extensive theoretical and empirical validation, our approach not only enhances the performance of continual learning, especially over synaptic regularization methods in task-incremental settings, but also potentially advances the understanding of neurological adaptive mechanisms. Continual learning is an innate ability in biological intelligence to accommodate real-world changes, but it remains challenging for artificial intelligence. Wang, Zhang and colleagues model key mechanisms of a biological learning system, in particular active forgetting and parallel modularity, to incorporate neuro-inspired adaptability to improve continual learning in artificial intelligence systems.},
  archive      = {J_NATMI},
  author       = {Wang, Liyuan and Zhang, Xingxing and Li, Qian and Zhang, Mingtian and Su, Hang and Zhu, Jun and Zhong, Yi},
  doi          = {10.1038/s42256-023-00747-w},
  journal      = {Nature Machine Intelligence},
  number       = {12},
  pages        = {1356-1368},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Incorporating neuro-inspired adaptability for continual learning in artificial intelligence},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence-powered electronic skin.
<em>NATMI</em>, <em>5</em>(12), 1344–1355. (<a
href="https://doi.org/10.1038/s42256-023-00760-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin-interfaced electronics is gradually changing medical practices by enabling continuous and non-invasive tracking of physiological and biochemical information. With the rise of big data and digital medicine, next-generation electronic skin (e-skin) will be able to use artificial intelligence (AI) to optimize its design as well as uncover user-personalized health profiles. Recent multimodal e-skin platforms have already used machine learning algorithms for autonomous data analytics. Unfortunately, there is a lack of appropriate AI protocols and guidelines for e-skin devices, resulting in overly complex models and non-reproducible conclusions for simple applications. This Review aims to present AI technologies in e-skin hardware and assess their potential for new inspired integrated platform solutions. We outline recent breakthroughs in AI strategies and their applications in engineering e-skins as well as understanding health information collected by e-skins, highlighting the transformative deployment of AI in robotics, prosthetics, virtual reality and personalized healthcare. We also discuss the challenges and prospects of AI-powered e-skins as well as predictions for the future trajectory of smart e-skins. Skin-like flexible electronics (electronic skin) has great potential in medical practices to enable continuous tracking of physical and biochemical information. Xu et al. review the integration of AI methods and electronic skins, especially how data collected from sensors are processed by AI to extract features for human–machine interactions and health monitoring purposes.},
  archive      = {J_NATMI},
  author       = {Xu, Changhao and Solomon, Samuel A. and Gao, Wei},
  doi          = {10.1038/s42256-023-00760-z},
  journal      = {Nature Machine Intelligence},
  number       = {12},
  pages        = {1344-1355},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Artificial intelligence-powered electronic skin},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatially embedded neuromorphic networks. <em>NATMI</em>,
<em>5</em>(12), 1342–1343. (<a
href="https://doi.org/10.1038/s42256-023-00771-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A framework for training artificial neural networks in physical space allows neuroscientists to build networks that look and function like real brains.},
  archive      = {J_NATMI},
  author       = {Milisav, Filip and Misic, Bratislav},
  doi          = {10.1038/s42256-023-00771-w},
  journal      = {Nature Machine Intelligence},
  number       = {12},
  pages        = {1342-1343},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Spatially embedded neuromorphic networks},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deconstructing the generalization gap. <em>NATMI</em>,
<em>5</em>(12), 1340–1341. (<a
href="https://doi.org/10.1038/s42256-023-00766-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New research reveals a duality between neural network weights and neuron activities that enables a geometric decomposition of the generalization gap. The framework provides a way to interpret the effects of regularization schemes such as stochastic gradient descent and dropout on generalization — and to improve upon these methods.},
  archive      = {J_NATMI},
  author       = {Gromov, Andrey},
  doi          = {10.1038/s42256-023-00766-7},
  journal      = {Nature Machine Intelligence},
  number       = {12},
  pages        = {1340-1341},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Deconstructing the generalization gap},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). How to break information cocoons. <em>NATMI</em>,
<em>5</em>(12), 1338–1339. (<a
href="https://doi.org/10.1038/s42256-023-00758-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are a predominant feature of online platforms and one of the most widespread applications of artificial intelligence. A new model captures information dynamics driven by algorithmic recommendations and offers ways to ensure that users are exposed to diverse content and information.},
  archive      = {J_NATMI},
  author       = {Santos, Fernando P.},
  doi          = {10.1038/s42256-023-00758-7},
  journal      = {Nature Machine Intelligence},
  number       = {12},
  pages        = {1338-1339},
  shortjournal = {Nat. Mach. Intell.},
  title        = {How to break information cocoons},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A year of racing ahead with AI and not breaking things.
<em>NATMI</em>, <em>5</em>(12), 1337. (<a
href="https://doi.org/10.1038/s42256-023-00782-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Looking back at a year of escalating, divisive debates in AI safety and who determines the agenda.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-023-00782-7},
  journal      = {Nature Machine Intelligence},
  number       = {12},
  pages        = {1337},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A year of racing ahead with AI and not breaking things},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Forecasting the future of artificial intelligence with
machine learning-based link prediction in an exponentially growing
knowledge network. <em>NATMI</em>, <em>5</em>(11), 1326–1335. (<a
href="https://doi.org/10.1038/s42256-023-00735-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A tool that could suggest new personalized research directions and ideas by taking insights from the scientific literature could profoundly accelerate the progress of science. A field that might benefit from such an approach is artificial intelligence (AI) research, where the number of scientific publications has been growing exponentially over recent years, making it challenging for human researchers to keep track of the progress. Here we use AI techniques to predict the future research directions of AI itself. We introduce a graph-based benchmark based on real-world data—the Science4Cast benchmark, which aims to predict the future state of an evolving semantic network of AI. For that, we use more than 143,000 research papers and build up a knowledge network with more than 64,000 concept nodes. We then present ten diverse methods to tackle this task, ranging from pure statistical to pure learning methods. Surprisingly, the most powerful methods use a carefully curated set of network features, rather than an end-to-end AI approach. These results indicate a great potential that can be unleashed for purely ML approaches without human knowledge. Ultimately, better predictions of new future research directions will be a crucial component of more advanced research suggestion tools. The number of publications in artificial intelligence (AI) has been increasing exponentially and staying on top of progress in the field is a challenging task. Krenn and colleagues model the evolution of the growing AI literature as a semantic network and use it to benchmark several machine learning methods that can predict promising research directions in AI.},
  archive      = {J_NATMI},
  author       = {Krenn, Mario and Buffoni, Lorenzo and Coutinho, Bruno and Eppel, Sagi and Foster, Jacob Gates and Gritsevskiy, Andrew and Lee, Harlin and Lu, Yichao and Moutinho, João P. and Sanjabi, Nima and Sonthalia, Rishi and Tran, Ngoc Mai and Valente, Francisco and Xie, Yangxinyu and Yu, Rose and Kopp, Michael},
  doi          = {10.1038/s42256-023-00735-0},
  journal      = {Nature Machine Intelligence},
  number       = {11},
  pages        = {1326-1335},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Forecasting the future of artificial intelligence with machine learning-based link prediction in an exponentially growing knowledge network},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development of the senseiver for efficient field
reconstruction from sparse observations. <em>NATMI</em>, <em>5</em>(11),
1317–1325. (<a
href="https://doi.org/10.1038/s42256-023-00746-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reconstruction of complex time-evolving fields from sensor observations is a grand challenge. Frequently, sensors have extremely sparse coverage and low-resource computing capacity for measuring highly nonlinear phenomena. While numerical simulations can model some of these phenomena using partial differential equations, the reconstruction problem is ill-posed. Data-driven-strategies provide crucial disambiguation, but these suffer in cases with small amounts of data, and struggle to handle large domains. Here we present the Senseiver, an attention-based framework that excels in reconstructing complex spatial fields from few observations with low overhead. The Senseiver reconstructs n-dimensional fields by encoding arbitrarily sized sparse sets of inputs into a latent space using cross-attention, producing uniform-sized outputs regardless of the number of observations. This allows efficient inference by decoding only a sparse set of output observations, while a dense set of observations is needed to train. This framework enables training of data with complex boundary conditions and extremely large fine-scale simulations. We build on the Perceiver IO by enabling training models with fewer parameters, which facilitates field deployment, and a training framework that allows a flexible number of sensors as input, which is critical for real-world applications. We show that the Senseiver advances the state-of-the-art of field reconstruction in many applications. The reconstruction of dynamic, spatial fields from sparse sensor data is an important challenge in various fields of science and technology. Santos et al. introduce the Senseiver, a deep learning framework that reconstructs spatial fields from few observations using attention layers to encode and decode sparse data, enabling efficient inference.},
  archive      = {J_NATMI},
  author       = {Santos, Javier E. and Fox, Zachary R. and Mohan, Arvind and O’Malley, Daniel and Viswanathan, Hari and Lubbers, Nicholas},
  doi          = {10.1038/s42256-023-00746-x},
  journal      = {Nature Machine Intelligence},
  number       = {11},
  pages        = {1317-1325},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Development of the senseiver for efficient field reconstruction from sparse observations},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning of causal structures in high dimensions under
data limitations. <em>NATMI</em>, <em>5</em>(11), 1306–1316. (<a
href="https://doi.org/10.1038/s42256-023-00744-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal learning is a key challenge in scientific artificial intelligence as it allows researchers to go beyond purely correlative or predictive analyses towards learning underlying cause-and-effect relationships, which are important for scientific understanding as well as for a wide range of downstream tasks. Here, motivated by emerging biomedical questions, we propose a deep neural architecture for learning causal relationships between variables from a combination of high-dimensional data and prior causal knowledge. We combine convolutional and graph neural networks within a causal risk framework to provide an approach that is demonstrably effective under the conditions of high dimensionality, noise and data limitations that are characteristic of many applications, including in large-scale biology. In experiments, we find that the proposed learners can effectively identify novel causal relationships across thousands of variables. Results include extensive (linear and nonlinear) simulations (where the ground truth is known and can be directly compared against), as well as real biological examples where the models are applied to high-dimensional molecular data and their outputs compared against entirely unseen validation experiments. These results support the notion that deep learning approaches can be used to learn causal networks at large scale. Learning causal relationships between variables in large datasets is an outstanding challenge in various scientific applications. Lagemann et al. introduce a deep neural network approach combining convolutional and graph models intended for causal learning in high-dimensional biomedical problems.},
  archive      = {J_NATMI},
  author       = {Lagemann, Kai and Lagemann, Christian and Taschler, Bernd and Mukherjee, Sach},
  doi          = {10.1038/s42256-023-00744-z},
  journal      = {Nature Machine Intelligence},
  number       = {11},
  pages        = {1306-1316},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Deep learning of causal structures in high dimensions under data limitations},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural scaling of deep chemical models. <em>NATMI</em>,
<em>5</em>(11), 1297–1305. (<a
href="https://doi.org/10.1038/s42256-023-00740-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Massive scale, in terms of both data availability and computation, enables important breakthroughs in key application areas of deep learning such as natural language processing and computer vision. There is emerging evidence that scale may be a key ingredient in scientific deep learning, but the importance of physical priors in scientific domains makes the strategies and benefits of scaling uncertain. Here we investigate neural-scaling behaviour in large chemical models by varying model and dataset sizes over many orders of magnitude, studying models with over one billion parameters, pre-trained on datasets of up to ten million datapoints. We consider large language models for generative chemistry and graph neural networks for machine-learned interatomic potentials. We investigate the interplay between physical priors and scale and discover empirical neural-scaling relations for language models in chemistry with a scaling exponent of 0.17 for the largest dataset size considered, and a scaling exponent of 0.26 for equivariant graph neural network interatomic potentials. Deep learning methods in natural language processing generally become more effective with larger datasets and bigger networks. But it is not evident whether the same is true for more specialized domains such as cheminformatics. Frey and colleagues provide empirical explorations of chemistry models and find that neural-scaling laws hold true even for the largest tested models and datasets.},
  archive      = {J_NATMI},
  author       = {Frey, Nathan C. and Soklaski, Ryan and Axelrod, Simon and Samsi, Siddharth and Gómez-Bombarelli, Rafael and Coley, Connor W. and Gadepally, Vijay},
  doi          = {10.1038/s42256-023-00740-3},
  journal      = {Nature Machine Intelligence},
  number       = {11},
  pages        = {1297-1305},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Neural scaling of deep chemical models},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mode switching in organisms for solving
explore-versus-exploit problems. <em>NATMI</em>, <em>5</em>(11),
1285–1296. (<a
href="https://doi.org/10.1038/s42256-023-00745-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trade-offs between producing costly movements for gathering information (‘explore’) and using previously acquired information to achieve a goal (‘exploit’) arise in a wide variety of problems, including foraging, reinforcement learning and sensorimotor control. Determining the optimal balance between exploration and exploitation is computationally intractable, necessitating heuristic solutions. Here we show that the electric fish Eigenmannia virescens uses a salience-dependent mode-switching strategy to solve the explore–exploit conflict during a refuge-tracking task in which the same category of movement (fore-aft swimming) is used for both gathering information and achieving task goals. The fish produced distinctive non-Gaussian distributions of movement velocities characterized by sharp peaks for slower, task-oriented ‘exploit’ movements and broad shoulders for faster ‘explore’ movements. The measures of non-normality increased with increased sensory salience, corresponding to a decrease in the prevalence of fast explore movements. We found the same sensory salience-dependent mode-switching behaviour across ten phylogenetically diverse organisms, from amoebae to humans, performing tasks such as postural balance and target tracking. We propose a state-uncertainty-based mode-switching heuristic that reproduces the distinctive velocity distribution, rationalizes modulation by sensory salience and outperforms the classic persistent excitation approach while using less energy. This mode-switching heuristic provides insights into purposeful exploratory behaviours in organisms, as well as a framework for more efficient state estimation and control of robots. Organisms show complex behaviour resulting from a trade-off between obtaining information (explore) and using current information (exploit). Biswas et al. observe a mode-switching strategy modulated by sensory salience in a diverse range of organisms, including electric fish and humans, and argue that the observed heuristic could inform the design of active-sensing behaviours in robotics.},
  archive      = {J_NATMI},
  author       = {Biswas, Debojyoti and Lamperski, Andrew and Yang, Yu and Hoffman, Kathleen and Guckenheimer, John and Fortune, Eric S. and Cowan, Noah J.},
  doi          = {10.1038/s42256-023-00745-y},
  journal      = {Nature Machine Intelligence},
  number       = {11},
  pages        = {1285-1296},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Mode switching in organisms for solving explore-versus-exploit problems},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Protein–protein contact prediction by geometric
triangle-aware protein language models. <em>NATMI</em>, <em>5</em>(11),
1275–1284. (<a
href="https://doi.org/10.1038/s42256-023-00741-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information regarding the residue–residue distance between interacting proteins is important for modelling the structures of protein complexes, as well as being valuable for understanding the molecular mechanism of protein–protein interactions. With the advent of deep learning, many methods have been developed to accurately predict the intra-protein residue–residue contacts of monomers. However, it is still challenging to accurately predict inter-protein residue–residue contacts for protein complexes, especially hetero-protein complexes. Here we develop a protein language model-based deep learning method to predict the inter-protein residue–residue contacts of protein complexes—named DeepInter—by introducing a triangle-aware mechanism of triangle update and triangle self-attention into the deep neural network. We extensively validate DeepInter on diverse test sets of 300 homodimeric, 28 CASP-CAPRI homodimeric and 99 heterodimeric complexes and compare it with state-of-the-art methods including CDPred, DeepHomo2.0, GLINTER and DeepHomo. The results demonstrate the accuracy and robustness of DeepInter. Contact prediction between two proteins is still computationally challenging, but is vital for understanding multi-protein complexes. Lin et al. use a geometric deep learning approach to provide accurate predictions of inter-protein residue–residue contacts.},
  archive      = {J_NATMI},
  author       = {Lin, Peicong and Tao, Huanyu and Li, Hao and Huang, Sheng-You},
  doi          = {10.1038/s42256-023-00741-2},
  journal      = {Nature Machine Intelligence},
  number       = {11},
  pages        = {1275-1284},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Protein–protein contact prediction by geometric triangle-aware protein language models},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design of prime-editing guide RNAs with deep transfer
learning. <em>NATMI</em>, <em>5</em>(11), 1261–1274. (<a
href="https://doi.org/10.1038/s42256-023-00739-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prime editors (PEs) are promising genome-editing tools, but effective optimization of prime-editing guide RNA (pegRNA) design remains a challenge owing to the lack of accurate and broadly applicable approaches. Here we develop Optimized Prime Editing Design (OPED), an interpretable nucleotide language model that leverages transfer learning to improve its accuracy and generalizability for the efficiency prediction and design optimization of pegRNAs. Comprehensive validations on various published datasets demonstrate its broad applicability in efficiency prediction across diverse scenarios. Notably, pegRNAs with high OPED scores consistently show significantly increased editing efficiencies. Furthermore, the versatility and efficacy of OPED in design optimization are confirmed by efficiently installing various ClinVar pathogenic variants using optimized pegRNAs in the PE2, PE3/PE3b and ePE editing systems. OPED consistently outperforms existing state-of-the-art approaches. We construct the OPEDVar database of optimized designs from over two billion candidates for all pathogenic variants and provide a user-friendly web application of OPED for any desired edit. Prime editors are innovative genome-editing tools, but selecting guide RNAs with high efficiency remains challenging and requires costly experimental efforts. Liu and colleagues develop a method to design prime-editing guide RNAs based on transfer learning for in silico prediction of editing efficacy.},
  archive      = {J_NATMI},
  author       = {Liu, Feng and Huang, Shuhong and Hu, Jiongsong and Chen, Xiaozhou and Song, Ziguo and Dong, Junguo and Liu, Yao and Huang, Xingxu and Wang, Shengqi and Wang, Xiaolong and Shu, Wenjie},
  doi          = {10.1038/s42256-023-00739-w},
  journal      = {Nature Machine Intelligence},
  number       = {11},
  pages        = {1261-1274},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Design of prime-editing guide RNAs with deep transfer learning},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mitigating the missing-fragmentation problem in de novo
peptide sequencing with a two-stage graph-based deep learning model.
<em>NATMI</em>, <em>5</em>(11), 1250–1260. (<a
href="https://doi.org/10.1038/s42256-023-00738-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Novel protein discovery and immunopeptidomics depend on highly sensitive de novo peptide sequencing with tandem mass spectrometry. Despite notable improvement using deep learning models, the missing-fragmentation problem remains an important hurdle that severely degrades the performance of de novo peptide sequencing. Here we reveal that in the process of peptide prediction, missing fragmentation results in the generation of incorrect amino acids within those regions and causes error accumulation thereafter. To tackle this problem, we propose GraphNovo, a two-stage de novo peptide-sequencing algorithm based on a graph neural network. GraphNovo focuses on finding the optimal path in the first stage to guide the sequence prediction in the second stage. Our experiments demonstrate that GraphNovo mitigates the effects of missing fragmentation and outperforms the state-of-the-art de novo peptide-sequencing algorithms. Identifying unknown peptides in tandem mass spectrometry is challenging as fragmentation of precursor peptides can be incomplete. Mao and colleagues present a method based on graph neural networks and a path-searching model to create more stable sequence predictions.},
  archive      = {J_NATMI},
  author       = {Mao, Zeping and Zhang, Ruixue and Xin, Lei and Li, Ming},
  doi          = {10.1038/s42256-023-00738-x},
  journal      = {Nature Machine Intelligence},
  number       = {11},
  pages        = {1250-1260},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Mitigating the missing-fragmentation problem in de novo peptide sequencing with a two-stage graph-based deep learning model},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep domain adversarial neural network for the deconvolution
of cell type mixtures in tissue proteome profiling. <em>NATMI</em>,
<em>5</em>(11), 1236–1249. (<a
href="https://doi.org/10.1038/s42256-023-00737-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cell type deconvolution is a computational method for the determination/resolution of cell type proportions from bulk sequencing data, and is frequently used for the analysis of divergent cell types in tumour tissue samples. However, deconvolution technology is still in its infancy for the analysis of cell types using proteomic data due to challenges with repeatability/reproducibility, variable reference standards and the lack of single-cell proteomic reference data. Here we develop a deep-learning-based deconvolution method (scpDeconv) specifically designed for proteomic data. scpDeconv uses an autoencoder to leverage the information from bulk proteomic data to improve the quality of single-cell proteomic data, and employs a domain adversarial architecture to bridge the single-cell and bulk data distributions and transfer labels from single-cell data to bulk data. Extensive experiments validate the performance of scpDeconv in the deconvolution of proteomic data produced from various species/sources and different proteomic technologies. This method should find broad applicability to areas including tumour microenvironment interpretation and clinical diagnosis/classification. Deconvolution of cell types in tissue proteomic data is a challenging computational task for the bioinformatics community. A deep-learning method termed scpDeconv is introduced that makes efficient use of single-cell proteomics data to deconvolve cell types and states from bulk proteomics measurements.},
  archive      = {J_NATMI},
  author       = {Wang, Fang and Yang, Fan and Huang, Longkai and Li, Wei and Song, Jiangning and Gasser, Robin B. and Aebersold, Ruedi and Wang, Guohua and Yao, Jianhua},
  doi          = {10.1038/s42256-023-00737-y},
  journal      = {Nature Machine Intelligence},
  number       = {11},
  pages        = {1236-1249},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Deep domain adversarial neural network for the deconvolution of cell type mixtures in tissue proteome profiling},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised deep learning for tracking degradation of
perovskite light-emitting diodes with multispectral imaging.
<em>NATMI</em>, <em>5</em>(11), 1225–1235. (<a
href="https://doi.org/10.1038/s42256-023-00736-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emerging functional materials such as halide perovskites are intrinsically unstable, causing long-term instability in optoelectronic devices made from these materials. This leads to difficulty in capturing useful information on device degradation through time-consuming optical characterization in their operating environments. Despite these challenges, understanding the degradation mechanism is crucial for advancing the technology towards commercialization. Here we present a self-supervised machine learning model that utilizes a multi-channel correlation and blind denoising to recover images without high-quality references, enabling fast and low-dose measurements. We perform operando luminescence mapping of various emerging optoelectronic semiconductors, including organic and halide perovskite photovoltaic and light-emitting devices. By tracking the spatially resolved degradation in electroluminescence of mixed-halide perovskite blue-light-emitting diodes, we discovered that lateral ion migration (perpendicular to the external electric field) during device operation triggers the formation of chloride-rich defective regions that emit poorly—a mechanism that would not be resolvable with conventional imaging approaches. Halide perovskites are promising materials for light-emitting devices, given their narrowband emission and solution processability. However, detailed information on device degradation during operation is required to improve their stability, and this is challenging to obtain. Ji et al. propose a self-supervised deep learning method to capture multi-dimensional images of such devices in their operating regime faster than allowed by conventional imaging techniques.},
  archive      = {J_NATMI},
  author       = {Ji, Kangyu and Lin, Weizhe and Sun, Yuqi and Cui, Lin-Song and Shamsi, Javad and Chiang, Yu-Hsien and Chen, Jiawei and Tennyson, Elizabeth M. and Dai, Linjie and Li, Qingbiao and Frohna, Kyle and Anaya, Miguel and Greenham, Neil C. and Stranks, Samuel D.},
  doi          = {10.1038/s42256-023-00736-z},
  journal      = {Nature Machine Intelligence},
  number       = {11},
  pages        = {1225-1235},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Self-supervised deep learning for tracking degradation of perovskite light-emitting diodes with multispectral imaging},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human–AI adaptive dynamics drives the emergence of
information cocoons. <em>NATMI</em>, <em>5</em>(11), 1214–1224. (<a
href="https://doi.org/10.1038/s42256-023-00731-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite AI-driven recommendation algorithms being widely adopted to counter information overload, substantial evidence suggests that they are building cocoons of homogeneous contents and viewpoints, further aggravating social polarization and prejudice. Curbing these perils requires a deep insight into the origin of information cocoons. Here we investigate information cocoons in the real world using two large datasets and find that a large number of users are trapped in information cocoons. Further empirical analysis suggests that two ingredients, each corresponding to a fundamental mechanism in human–AI interaction systems, are correlated with the loss of information diversity. Grounded on the empirical findings, we derive a mechanistic model for the adaptive information dynamics in complex human–AI interaction systems governed by these fundamental mechanisms. It allows us to predict critical transitions between three states: diversification, partial information cocoons, and deep information cocoons. Our work not only empirically traces real-world information cocoons in two representative scenarios, but also theoretically unearths basic mechanisms governing the emergence of information cocoons. We provide a theoretical method for understanding major social issues resulting from adaptive information dynamics in complex human–AI interaction systems. It is widely known that AI-based recommendation systems on social media and news websites can isolate humans from diverse information, eventually trapping them in so-called information cocoons, where they are exposed to a narrow range of viewpoints. Li et al. introduce an adaptive information dynamics model to uncover the origin of information cocoons in complex human–AI interaction systems, and test their findings on two large real-world datasets.},
  archive      = {J_NATMI},
  author       = {Piao, Jinghua and Liu, Jiazhen and Zhang, Fang and Su, Jun and Li, Yong},
  doi          = {10.1038/s42256-023-00731-4},
  journal      = {Nature Machine Intelligence},
  number       = {11},
  pages        = {1214-1224},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Human–AI adaptive dynamics drives the emergence of information cocoons},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Construction of a 3D whole organism spatial atlas by joint
modelling of multiple slices with deep neural networks. <em>NATMI</em>,
<em>5</em>(11), 1200–1213. (<a
href="https://doi.org/10.1038/s42256-023-00734-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial transcriptomics (ST) technologies are revolutionizing the way to explore the spatial architecture of tissues. Currently, ST data analysis is often restricted to a single two-dimensional (2D) tissue slice, limiting our capacity to understand biological processes that take place in 3D space. Here we present STitch3D, a unified framework that integrates multiple ST slices to reconstruct 3D cellular structures. By jointly modelling multiple slices and integrating them with single-cell RNA-sequencing data, STitch3D simultaneously identifies 3D spatial regions with coherent gene-expression levels and reveals 3D cell-type distributions. STitch3D distinguishes biological variation among slices from batch effects, and effectively borrows information across slices to assemble powerful 3D models. Through comprehensive experiments, we demonstrate STitch3D’s performance in building comprehensive 3D architectures, which allow 3D analysis in the entire tissue region or even the whole organism. The outputs of STitch3D can be used for multiple downstream tasks, enabling a comprehensive understanding of biological systems. Computational methods for analysing single 2D tissue slices from spatial transcriptomics studies are well established, but their extension to the 3D domain is challenging. Wang et al. develop a deep learning framework that can perform 3D reconstruction of cellular structures in tissues as well as whole organisms.},
  archive      = {J_NATMI},
  author       = {Wang, Gefei and Zhao, Jia and Yan, Yan and Wang, Yang and Wu, Angela Ruohao and Yang, Can},
  doi          = {10.1038/s42256-023-00734-1},
  journal      = {Nature Machine Intelligence},
  number       = {11},
  pages        = {1200-1213},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Construction of a 3D whole organism spatial atlas by joint modelling of multiple slices with deep neural networks},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differentiable visual computing for inverse problems and
machine learning. <em>NATMI</em>, <em>5</em>(11), 1189–1199. (<a
href="https://doi.org/10.1038/s42256-023-00743-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern 3D computer graphics technologies are able to reproduce the dynamics and appearance of real-world environments and phenomena, building on theoretical models in applied mathematics, statistics and physics. These methods are applied in architectural design and visualization, biological imaging and visual effects. Differentiable methods, instead, aim to determine how graphics outputs (that is, the real-world dynamics or appearance) change when the environment changes. We survey this growing body of work and propose a holistic and unified differentiable visual computing pipeline. Differentiable visual computing can be leveraged to efficiently solve otherwise intractable problems in physical inference, optimal control, object detection and scene understanding, computational design, manufacturing, autonomous vehicles and robotics. Any application that can benefit from an understanding of the underlying dynamics of the real world stands to benefit substantially from a differentiable graphics treatment. We draw parallels between the well-established computer graphics pipeline and a unified differentiable graphics pipeline, targeting consumers, practitioners and researchers. The breadth of fields that these pipelines draw upon—and are of interest to—includes the physical sciences, data sciences, vision and graphics, machine learning, and adjacent mathematical and computing communities. Traditionally, 3D graphics involves numerical methods for physical and virtual simulations of real-world scenes. Spielberg et al. review how deep learning enables differentiable visual computing, which determines how graphics outputs change when the environment changes, with applications in areas such as computer-aided design, manufacturing and robotics.},
  archive      = {J_NATMI},
  author       = {Spielberg, Andrew and Zhong, Fangcheng and Rematas, Konstantinos and Jatavallabhula, Krishna Murthy and Oztireli, Cengiz and Li, Tzu-Mao and Nowrouzezahrai, Derek},
  doi          = {10.1038/s42256-023-00743-0},
  journal      = {Nature Machine Intelligence},
  number       = {11},
  pages        = {1189-1199},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Differentiable visual computing for inverse problems and machine learning},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A social path to human-like artificial intelligence.
<em>NATMI</em>, <em>5</em>(11), 1181–1188. (<a
href="https://doi.org/10.1038/s42256-023-00754-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditionally, cognitive and computer scientists have viewed intelligence solipsistically, as a property of unitary agents devoid of social context. Given the success of contemporary learning algorithms, we argue that the bottleneck in artificial intelligence (AI) advancement is shifting from data assimilation to novel data generation. We bring together evidence showing that natural intelligence emerges at multiple scales in networks of interacting agents via collective living, social relationships and major evolutionary transitions, which contribute to novel data generation through mechanisms such as population pressures, arms races, Machiavellian selection, social learning and cumulative culture. Many breakthroughs in AI exploit some of these processes, from multi-agent structures enabling algorithms to master complex games such as Capture-The-Flag and StarCraft II, to strategic communication in the game Diplomacy and the shaping of AI data streams by other AIs. Moving beyond a solipsistic view of agency to integrate these mechanisms could provide a path to human-like compounding innovation through ongoing novel data generation. Advances in machine intelligence often depend on data assimilation, but data generation has been neglected. The authors discuss mechanisms that might achieve continuous novel data generation and the creation of intelligent systems that are capable of human-like innovation, focusing on social aspects of intelligence.},
  archive      = {J_NATMI},
  author       = {Duéñez-Guzmán, Edgar A. and Sadedin, Suzanne and Wang, Jane X. and McKee, Kevin R. and Leibo, Joel Z.},
  doi          = {10.1038/s42256-023-00754-x},
  journal      = {Nature Machine Intelligence},
  number       = {11},
  pages        = {1181-1188},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A social path to human-like artificial intelligence},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Listening in to perceived speech with contrastive learning.
<em>NATMI</em>, <em>5</em>(11), 1179–1180. (<a
href="https://doi.org/10.1038/s42256-023-00742-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New algorithms allow researchers to decode words the brain is hearing with a non-invasive method, outside the scalp.},
  archive      = {J_NATMI},
  author       = {Stavisky, Sergey D. and Wairagkar, Maitreyee},
  doi          = {10.1038/s42256-023-00742-1},
  journal      = {Nature Machine Intelligence},
  number       = {11},
  pages        = {1179-1180},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Listening in to perceived speech with contrastive learning},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reporting electricity consumption is essential for
sustainable AI. <em>NATMI</em>, <em>5</em>(11), 1176–1178. (<a
href="https://doi.org/10.1038/s42256-023-00750-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of artificial intelligence (AI) has relied on an increasing demand for energy, which threatens to outweigh its promised positive effects. To steer AI onto a more sustainable path, quantifying and comparing its energy consumption is key.},
  archive      = {J_NATMI},
  author       = {Debus, Charlotte and Piraud, Marie and Streit, Achim and Theis, Fabian and Götz, Markus},
  doi          = {10.1038/s42256-023-00750-1},
  journal      = {Nature Machine Intelligence},
  number       = {11},
  pages        = {1176-1178},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Reporting electricity consumption is essential for sustainable AI},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A social network for AI. <em>NATMI</em>, <em>5</em>(11),
1175. (<a href="https://doi.org/10.1038/s42256-023-00769-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Further progress in AI may require learning algorithms to generate their own data rather than assimilate static datasets. A Perspective in this issue proposes that they could do so by interacting with other learning agents in a socially structured way.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-023-00769-4},
  journal      = {Nature Machine Intelligence},
  number       = {11},
  pages        = {1175},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A social network for AI},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A taxonomy and review of generalization research in NLP.
<em>NATMI</em>, <em>5</em>(10), 1161–1174. (<a
href="https://doi.org/10.1038/s42256-023-00729-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to generalize well is one of the primary desiderata for models of natural language processing (NLP), but what ‘good generalization’ entails and how it should be evaluated is not well understood. In this Analysis we present a taxonomy for characterizing and understanding generalization research in NLP. The proposed taxonomy is based on an extensive literature review and contains five axes along which generalization studies can differ: their main motivation, the type of generalization they aim to solve, the type of data shift they consider, the source by which this data shift originated, and the locus of the shift within the NLP modelling pipeline. We use our taxonomy to classify over 700 experiments, and we use the results to present an in-depth analysis that maps out the current state of generalization research in NLP and make recommendations for which areas deserve attention in the future. With the rapid development of natural language processing (NLP) models in the last decade came the realization that high performance levels on test sets do not imply that a model robustly generalizes to a wide range of scenarios. Hupkes et al. review generalization approaches in the NLP literature and propose a taxonomy based on five axes to analyse such studies: motivation, type of generalization, type of data shift, the source of this data shift, and the locus of the shift within the modelling pipeline.},
  archive      = {J_NATMI},
  author       = {Hupkes, Dieuwke and Giulianelli, Mario and Dankers, Verna and Artetxe, Mikel and Elazar, Yanai and Pimentel, Tiago and Christodoulopoulos, Christos and Lasri, Karim and Saphra, Naomi and Sinclair, Arabella and Ulmer, Dennis and Schottmann, Florian and Batsuren, Khuyagbaatar and Sun, Kaiser and Sinha, Koustuv and Khalatbari, Leila and Ryskina, Maria and Frieske, Rita and Cotterell, Ryan and Jin, Zhijing},
  doi          = {10.1038/s42256-023-00729-y},
  journal      = {Nature Machine Intelligence},
  number       = {10},
  pages        = {1161-1174},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A taxonomy and review of generalization research in NLP},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A soft-packaged and portable rehabilitation glove capable of
closed-loop fine motor skills. <em>NATMI</em>, <em>5</em>(10),
1149–1160. (<a
href="https://doi.org/10.1038/s42256-023-00728-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regaining fine motor skills (FMSs; that is, the ability to make precise and coordinated movements of fingers) is the ultimate goal of hand rehabilitation. Although robotic-assisted technologies have been widely explored to help patients with simple hand activities, existing rehabilitation gloves still lack sensory feedback for closed-loop control or involve bulky external hardware, incapable of providing precise FMSs rehabilitation portably. Here we develop a soft rehabilitation glove that can accomplish diverse FMSs by integrating 15 bending sensors and 10 shape-memory-alloy (SMA) actuators. Three joint angles of each finger can be precisely sensed and thus are fed to the control system to actuate SMAs in a closed-loop manner. A touchable human–machine interface is also integrated to provide facile interaction for multi-modal rehabilitation exercises. Weighing only 0.49 kg, our soft glove has high portability, allowing for repetitive hand rehabilitation as needed. We validate that our glove can assist an individual with hand impairments after a stroke to realize a set of single and complex FMS rehabilitation exercises and to complete some activities of daily living. Fine motor skill recovery in hand rehabilitation is a challenge due to limited finger movement sensing and closed-loop control algorithms in existing rehabilitation gloves. Sui et al. develop a soft-packaged rehabilitation glove, integrating sensing, actuation, a human–machine interface, power, electronics and a closed-loop algorithm. The glove aids patients after a stroke to recover fine motor skills of the fingers in a portable manner.},
  archive      = {J_NATMI},
  author       = {Sui, Mengli and Ouyang, Yiming and Jin, Hu and Chai, Zhenyi and Wei, Changyang and Li, Jiyu and Xu, Min and Li, Weihua and Wang, Liu and Zhang, Shiwu},
  doi          = {10.1038/s42256-023-00728-z},
  journal      = {Nature Machine Intelligence},
  number       = {10},
  pages        = {1149-1160},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A soft-packaged and portable rehabilitation glove capable of closed-loop fine motor skills},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving wikipedia verifiability with AI. <em>NATMI</em>,
<em>5</em>(10), 1142–1148. (<a
href="https://doi.org/10.1038/s42256-023-00726-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Verifiability is a core content policy of Wikipedia: claims need to be backed by citations. Maintaining and improving the quality of Wikipedia references is an important challenge and there is a pressing need for better tools to assist humans in this effort. We show that the process of improving references can be tackled with the help of artificial intelligence (AI) powered by an information retrieval system and a language model. This neural-network-based system, which we call SIDE, can identify Wikipedia citations that are unlikely to support their claims, and subsequently recommend better ones from the web. We train this model on existing Wikipedia references, therefore learning from the contributions and combined wisdom of thousands of Wikipedia editors. Using crowdsourcing, we observe that for the top 10\% most likely citations to be tagged as unverifiable by our system, humans prefer our system’s suggested alternatives compared with the originally cited reference 70\% of the time. To validate the applicability of our system, we built a demo to engage with the English-speaking Wikipedia community and find that SIDE’s first citation recommendation is preferred twice as often as the existing Wikipedia citation for the same top 10\% most likely unverifiable claims according to SIDE. Our results indicate that an AI-based system could be used, in tandem with humans, to improve the verifiability of Wikipedia. The immense amount of Wikipedia articles makes it challenging for volunteers to ensure that cited sources support the claim they are attached to. Petroni et al. use an information-retrieval model to assist Wikipedia users in improving verifiability.},
  archive      = {J_NATMI},
  author       = {Petroni, Fabio and Broscheit, Samuel and Piktus, Aleksandra and Lewis, Patrick and Izacard, Gautier and Hosseini, Lucas and Dwivedi-Yu, Jane and Lomeli, Maria and Schick, Timo and Bevilacqua, Michele and Mazaré, Pierre-Emmanuel and Joulin, Armand and Grave, Edouard and Riedel, Sebastian},
  doi          = {10.1038/s42256-023-00726-1},
  journal      = {Nature Machine Intelligence},
  number       = {10},
  pages        = {1142-1148},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Improving wikipedia verifiability with AI},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep neural network for real-time optoacoustic image
reconstruction with adjustable speed of sound. <em>NATMI</em>,
<em>5</em>(10), 1130–1141. (<a
href="https://doi.org/10.1038/s42256-023-00724-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multispectral optoacoustic tomography is a high-resolution functional imaging modality that can non-invasively access a broad range of pathophysiological phenomena. Real-time imaging would enable translation of multispectral optoacoustic tomography into clinical imaging, visualize dynamic pathophysiological changes associated with disease progression and enable in situ diagnoses. Model-based reconstruction affords state-of-the-art optoacoustic images but cannot be used for real-time imaging. On the other hand, deep learning enables fast reconstruction of optoacoustic images, but the lack of experimental ground-truth training data leads to reduced image quality for in vivo scans. In this work we achieve accurate optoacoustic image reconstruction in 31 ms per image for arbitrary (experimental) input data by expressing model-based reconstruction with a deep neural network. The proposed deep learning framework, DeepMB, generalizes to experimental test data through training on optoacoustic signals synthesized from real-world images and ground truth optoacoustic images generated by model-based reconstruction. Based on qualitative and quantitative evaluation on a diverse dataset of in vivo images, we show that DeepMB reconstructs images approximately 1,000-times faster than the iterative model-based reference method while affording near-identical image qualities. Accurate and real-time image reconstructions with DeepMB can enable full access to the high-resolution and multispectral contrast of handheld optoacoustic tomography, thus adoption into clinical routines. State-of-the-art image reconstruction for multispectral optoacoustic tomography is currently too slow for clinical applications. Dehner, Zahnd et al. propose a deep learning framework to reconstruct optoacoustic images in real-time while maintaining similar quality.},
  archive      = {J_NATMI},
  author       = {Dehner, Christoph and Zahnd, Guillaume and Ntziachristos, Vasilis and Jüstel, Dominik},
  doi          = {10.1038/s42256-023-00724-3},
  journal      = {Nature Machine Intelligence},
  number       = {10},
  pages        = {1130-1141},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A deep neural network for real-time optoacoustic image reconstruction with adjustable speed of sound},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual adaptive training of photonic neural networks.
<em>NATMI</em>, <em>5</em>(10), 1119–1129. (<a
href="https://doi.org/10.1038/s42256-023-00723-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photonic neural networks (PNNs) are remarkable analogue artificial intelligence accelerators that compute using photons instead of electrons at low latency, high energy efficiency and high parallelism; however, the existing training approaches cannot address the extensive accumulation of systematic errors in large-scale PNNs, resulting in a considerable decrease in model performance in physical systems. Here we propose dual adaptive training (DAT), which allows the PNN model to adapt to substantial systematic errors and preserves its performance during deployment. By introducing the systematic error prediction networks with task-similarity joint optimization, DAT achieves high similarity mapping between the PNN numerical models and physical systems, as well as highly accurate gradient calculations during dual backpropagation training. We validated the effectiveness of DAT by using diffractive and interference-based PNNs on image classification tasks. Dual adaptive training successfully trained large-scale PNNs under major systematic errors and achieved high classification accuracies. The numerical and experimental results further demonstrated its superior performance over the state-of-the-art in situ training approaches. Dual adaptive training provides critical support for constructing large-scale PNNs to achieve advanced architectures and can be generalized to other types of artificial intelligence systems with analogue computing errors. Despite their efficiency advantages, the performance of photonic neural networks is hampered by the accumulation of inherent systematic errors. Zheng et al. propose a dual backpropagation training approach, which allows the network to adapt to systematic errors, thus outperforming state-of-the-art in situ training approaches.},
  archive      = {J_NATMI},
  author       = {Zheng, Ziyang and Duan, Zhengyang and Chen, Hang and Yang, Rui and Gao, Sheng and Zhang, Haiou and Xiong, Hongkai and Lin, Xing},
  doi          = {10.1038/s42256-023-00723-4},
  journal      = {Nature Machine Intelligence},
  number       = {10},
  pages        = {1119-1129},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Dual adaptive training of photonic neural networks},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Matching algorithms for blood donation. <em>NATMI</em>,
<em>5</em>(10), 1108–1118. (<a
href="https://doi.org/10.1038/s42256-023-00722-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global demand for donated blood far exceeds supply, and unmet need is greatest in low- and middle-income countries. Large-scale coordination is necessary to alleviate demand. Using the Facebook Blood Donations tool, we conduct a large-scale algorithmic matching of blood donors with donation opportunities. While measuring actual donation rates remains a challenge, we measure donor action (for example, making a donation appointment) as a proxy for actual donation. We develop automated policies for matching patients and donors, based on an online matching model. We provide theoretical guarantees for these policies, both regarding the number of expected donations and the equitable treatment of blood recipients. In simulations, a simple matching strategy increases the number of donations by 5–10\%; a pilot experiment with real donors shows a 5\% relative increase in donor action rate (from 3.7\% to 3.9\%). When scaled to the global Blood Donations tool user base, this corresponds to an increase of around 100,000 users taking action toward donation. Further, observing donor action on a social network can shed light on donor behaviour and response to incentives. Our initial findings align with several observations made in the medical and social science literature regarding donor behaviour. Online matching platforms are increasingly used for applications with positive social impact such as matching blood donors with recipients, where matching algorithms need to balance fairness with an efficiency objective. The authors demonstrate, both in computational simulations and using real data from the Facebook Blood Donations tool, that introducing a simple online matching policy can substantially increase the likelihood of donor action.},
  archive      = {J_NATMI},
  author       = {McElfresh, Duncan C. and Kroer, Christian and Pupyrev, Sergey and Sodomka, Eric and Sankararaman, Karthik and Chauvin, Zack and Dexter, Neil and Dickerson, John P.},
  doi          = {10.1038/s42256-023-00722-5},
  journal      = {Nature Machine Intelligence},
  number       = {10},
  pages        = {1108-1118},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Matching algorithms for blood donation},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Decoding speech perception from non-invasive brain
recordings. <em>NATMI</em>, <em>5</em>(10), 1097–1107. (<a
href="https://doi.org/10.1038/s42256-023-00714-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decoding speech from brain activity is a long-awaited goal in both healthcare and neuroscience. Invasive devices have recently led to major milestones in this regard: deep-learning algorithms trained on intracranial recordings can now start to decode elementary linguistic features such as letters, words and audio-spectrograms. However, extending this approach to natural speech and non-invasive brain recordings remains a major challenge. Here we introduce a model trained with contrastive learning to decode self-supervised representations of perceived speech from the non-invasive recordings of a large cohort of healthy individuals. To evaluate this approach, we curate and integrate four public datasets, encompassing 175 volunteers recorded with magneto-encephalography or electro-encephalography while they listened to short stories and isolated sentences. The results show that our model can identify, from 3 seconds of magneto-encephalography signals, the corresponding speech segment with up to 41\% accuracy out of more than 1,000 distinct possibilities on average across participants, and with up to 80\% in the best participants—a performance that allows the decoding of words and phrases absent from the training set. The comparison of our model with a variety of baselines highlights the importance of a contrastive objective, pretrained representations of speech and a common convolutional architecture simultaneously trained across multiple participants. Finally, the analysis of the decoder’s predictions suggests that they primarily depend on lexical and contextual semantic representations. Overall, this effective decoding of perceived speech from non-invasive recordings delineates a promising path to decode language from brain activity, without putting patients at risk of brain surgery. Deep learning can help develop non-invasive technology for decoding speech from brain activity, which could improve the lives of patients with brain injuries. Défossez et al. report a contrastive-learning approach to decode speech listening from human participants, using public databases of recordings based on non-invasive magnetic and electrical measurements.},
  archive      = {J_NATMI},
  author       = {Défossez, Alexandre and Caucheteux, Charlotte and Rapin, Jérémy and Kabeli, Ori and King, Jean-Rémi},
  doi          = {10.1038/s42256-023-00714-5},
  journal      = {Nature Machine Intelligence},
  number       = {10},
  pages        = {1097-1107},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Decoding speech perception from non-invasive brain recordings},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A method for multiple-sequence-alignment-free protein
structure prediction using a protein language model. <em>NATMI</em>,
<em>5</em>(10), 1087–1096. (<a
href="https://doi.org/10.1038/s42256-023-00721-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein structure prediction pipelines based on artificial intelligence, such as AlphaFold2, have achieved near-experimental accuracy. These advanced pipelines mainly rely on multiple sequence alignments (MSAs) as inputs to learn the co-evolution information from the homologous sequences. Nonetheless, searching MSAs from protein databases is time consuming, usually taking tens of minutes. Consequently, we attempt to explore the limits of fast protein structure prediction by using only primary structures of proteins. Our proposed method, HelixFold-Single, combines a large-scale protein language model with the superior geometric learning capability of AlphaFold2. HelixFold-Single first pre-trains a large-scale protein language model with thousands of millions of primary structures utilizing the self-supervised learning paradigm, which will be used as an alternative to MSAs for learning the co-evolution information. Then, by combining the pre-trained protein language model and the essential components of AlphaFold2, we obtain an end-to-end differentiable model to predict the three-dimensional coordinates of atoms from only the primary structure. HelixFold-Single is validated on datasets CASP14 and CAMEO, achieving competitive accuracy with the MSA-based methods on targets with large homologous families. Furthermore, HelixFold-Single consumes much less time than the mainstream pipelines for protein structure prediction, demonstrating its potential in tasks requiring many predictions. AlphaFold2 has revolutionized bioinformatics, but its ability to predict protein structures with high accuracy comes at the price of a costly database search for multiple sequence alignments. Fang and colleagues pre-train a large-scale protein language model and use it in conjunction with AlphaFold2 as a fully trainable and efficient model for structure prediction.},
  archive      = {J_NATMI},
  author       = {Fang, Xiaomin and Wang, Fan and Liu, Lihang and He, Jingzhou and Lin, Dayong and Xiang, Yingfei and Zhu, Kunrui and Zhang, Xiaonan and Wu, Hua and Li, Hui and Song, Le},
  doi          = {10.1038/s42256-023-00721-6},
  journal      = {Nature Machine Intelligence},
  number       = {10},
  pages        = {1087-1096},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A method for multiple-sequence-alignment-free protein structure prediction using a protein language model},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Influencing human–AI interaction by priming beliefs about AI
can increase perceived trustworthiness, empathy and effectiveness.
<em>NATMI</em>, <em>5</em>(10), 1076–1086. (<a
href="https://doi.org/10.1038/s42256-023-00720-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As conversational agents powered by large language models become more human-like, users are starting to view them as companions rather than mere assistants. Our study explores how changes to a person’s mental model of an AI system affects their interaction with the system. Participants interacted with the same conversational AI, but were influenced by different priming statements regarding the AI’s inner motives: caring, manipulative or no motives. Here we show that those who perceived a caring motive for the AI also perceived it as more trustworthy, empathetic and better-performing, and that the effects of priming and initial mental models were stronger for a more sophisticated AI model. Our work also indicates a feedback loop in which the user and AI reinforce the user’s mental model over a short time; further work should investigate long-term effects. The research highlights the importance of how AI systems are introduced can notably affect the interaction and how the AI is experienced. The recent accessibility of large language models brought them into contact with a large number of users and, due to the social nature of language, it is hard to avoid prescribing human characteristics such as intentions to a chatbot. Pataranutaporn and colleagues investigated how framing a bot as helpful or manipulative can influence this perception and the behaviour of the humans that interact with it.},
  archive      = {J_NATMI},
  author       = {Pataranutaporn, Pat and Liu, Ruby and Finn, Ed and Maes, Pattie},
  doi          = {10.1038/s42256-023-00720-7},
  journal      = {Nature Machine Intelligence},
  number       = {10},
  pages        = {1076-1086},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Influencing human–AI interaction by priming beliefs about AI can increase perceived trustworthiness, empathy and effectiveness},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Active learning for optimal intervention design in causal
models. <em>NATMI</em>, <em>5</em>(10), 1066–1075. (<a
href="https://doi.org/10.1038/s42256-023-00719-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential experimental design to discover interventions that achieve a desired outcome is a key problem in various domains including science, engineering and public policy. When the space of possible interventions is large, making an exhaustive search infeasible, experimental design strategies are needed. In this context, encoding the causal relationships between the variables, and thus the effect of interventions on the system, is critical for identifying desirable interventions more efficiently. Here we develop a causal active learning strategy to identify interventions that are optimal, as measured by the discrepancy between the post-interventional mean of the distribution and a desired target mean. The approach employs a Bayesian update for the causal model and prioritizes interventions using a carefully designed, causally informed acquisition function. This acquisition function is evaluated in closed form, allowing for fast optimization. The resulting algorithms are theoretically grounded with information-theoretic bounds and provable consistency results for linear causal models with known causal graph. We apply our approach to both synthetic data and single-cell transcriptomic data from Perturb–CITE-sequencing experiments to identify optimal perturbations that induce a specific cell-state transition. The causally informed acquisition function generally outperforms existing criteria, allowing for optimal intervention design with fewer but carefully selected samples. Identifying interventions that can induce a desired effect is challenging owing to the combinatorial number of possible choices in design space. Zhang and colleagues propose an active learning approach with theoretical guarantees to discover optimal interventions in causal models, and demonstrate the framework in the context of genetic perturbation design using single-cell transcriptomic data.},
  archive      = {J_NATMI},
  author       = {Zhang, Jiaqi and Cammarata, Louis and Squires, Chandler and Sapsis, Themistoklis P. and Uhler, Caroline},
  doi          = {10.1038/s42256-023-00719-0},
  journal      = {Nature Machine Intelligence},
  number       = {10},
  pages        = {1066-1075},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Active learning for optimal intervention design in causal models},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reply to: The pitfalls of negative data bias for the t-cell
epitope specificity challenge. <em>NATMI</em>, <em>5</em>(10),
1063–1065. (<a
href="https://doi.org/10.1038/s42256-023-00725-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Gao, Yicheng and Gao, Yuli and Dong, Kejing and Wu, Siqi and Liu, Qi},
  doi          = {10.1038/s42256-023-00725-2},
  journal      = {Nature Machine Intelligence},
  number       = {10},
  pages        = {1063-1065},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Reply to: The pitfalls of negative data bias for the T-cell epitope specificity challenge},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The pitfalls of negative data bias for the t-cell epitope
specificity challenge. <em>NATMI</em>, <em>5</em>(10), 1060–1062. (<a
href="https://doi.org/10.1038/s42256-023-00727-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Dens, Ceder and Laukens, Kris and Bittremieux, Wout and Meysman, Pieter},
  doi          = {10.1038/s42256-023-00727-0},
  journal      = {Nature Machine Intelligence},
  number       = {10},
  pages        = {1060-1062},
  shortjournal = {Nat. Mach. Intell.},
  title        = {The pitfalls of negative data bias for the T-cell epitope specificity challenge},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Many-body control with reinforcement learning and tensor
networks. <em>NATMI</em>, <em>5</em>(10), 1058–1059. (<a
href="https://doi.org/10.1038/s42256-023-00732-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient quantum-control protocols are required to utilize the full power of quantum computers. A new reinforcement learning approach can realize efficient, robust control of quantum many-body states, promising a practical advance in harnessing present-day quantum technologies.},
  archive      = {J_NATMI},
  author       = {Lu, Ying and Ran, Shi-Ju},
  doi          = {10.1038/s42256-023-00732-3},
  journal      = {Nature Machine Intelligence},
  number       = {10},
  pages        = {1058-1059},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Many-body control with reinforcement learning and tensor networks},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Battling disinformation with cryptography. <em>NATMI</em>,
<em>5</em>(10), 1056–1057. (<a
href="https://doi.org/10.1038/s42256-023-00733-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Sedlmeir, Johannes and Rieger, Alexander and Roth, Tamara and Fridgen, Gilbert},
  doi          = {10.1038/s42256-023-00733-2},
  journal      = {Nature Machine Intelligence},
  number       = {10},
  pages        = {1056-1057},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Battling disinformation with cryptography},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AI reality check. <em>NATMI</em>, <em>5</em>(10), 1055. (<a
href="https://doi.org/10.1038/s42256-023-00755-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AI-generated media are on the rise and are here to stay. Regulation is urgently needed, but in the meantime creators, users and content distributors need to pursue various ways, and adopt various tools, for responsible generation, sharing and detection of AI-generated content.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-023-00755-w},
  journal      = {Nature Machine Intelligence},
  number       = {10},
  pages        = {1055},
  shortjournal = {Nat. Mach. Intell.},
  title        = {AI reality check},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluating protein binding interfaces with transformer
networks. <em>NATMI</em>, <em>5</em>(9), 1042–1053. (<a
href="https://doi.org/10.1038/s42256-023-00715-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational protein-binding studies are widely used to investigate fundamental biological processes and facilitate the development of modern drugs, vaccines and therapeutics. Scoring functions aim to assess and rank the binding strength of the predicted protein complex. However, accurate scoring of protein binding interfaces remains a challenge. Here we show that our evaluating Protein binding Interfaces with Transformer Networks (PIsToN) approach can distinguish native-like protein complexes from incorrect conformations. Protein interfaces are transformed into a collection of two-dimensional images (interface maps), each corresponding to a geometric or biochemical property. Pixel intensities represent the feature values. A neural network was adapted from a popular vision transformer with several enhancements: a hybrid component to accept empirical-based energy terms, a multi-attention module to highlight essential features and binding sites, and the use of contrastive learning for better ranking performance. The resulting PIsToN model substantially outperforms state-of-the-art scoring functions on well-known datasets. For virtual protein docking, an accurate scoring function is necessary that evaluates how likely a protein conformation is. Stebliankin and colleagues present a method based on vision transformers that provides a more accurate score by evaluating individual binding interfaces as multi-channel images.},
  archive      = {J_NATMI},
  author       = {Stebliankin, Vitalii and Shirali, Azam and Baral, Prabin and Shi, Jimeng and Chapagain, Prem and Mathee, Kalai and Narasimhan, Giri},
  doi          = {10.1038/s42256-023-00715-4},
  journal      = {Nature Machine Intelligence},
  number       = {9},
  pages        = {1042-1053},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Evaluating protein binding interfaces with transformer networks},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CHGNet as a pretrained universal neural network potential
for charge-informed atomistic modelling. <em>NATMI</em>, <em>5</em>(9),
1031–1041. (<a
href="https://doi.org/10.1038/s42256-023-00716-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale simulations with complex electron interactions remain one of the greatest challenges for atomistic modelling. Although classical force fields often fail to describe the coupling between electronic states and ionic rearrangements, the more accurate ab initio molecular dynamics suffers from computational complexity that prevents long-time and large-scale simulations, which are essential to study technologically relevant phenomena. Here we present the Crystal Hamiltonian Graph Neural Network (CHGNet), a graph neural network-based machine-learning interatomic potential (MLIP) that models the universal potential energy surface. CHGNet is pretrained on the energies, forces, stresses and magnetic moments from the Materials Project Trajectory Dataset, which consists of over 10 years of density functional theory calculations of more than 1.5 million inorganic structures. The explicit inclusion of magnetic moments enables CHGNet to learn and accurately represent the orbital occupancy of electrons, enhancing its capability to describe both atomic and electronic degrees of freedom. We demonstrate several applications of CHGNet in solid-state materials, including charge-informed molecular dynamics in LixMnO2, the finite temperature phase diagram for LixFePO4 and Li diffusion in garnet conductors. We highlight the significance of charge information for capturing appropriate chemistry and provide insights into ionic systems with additional electronic degrees of freedom that cannot be observed by previous MLIPs. An outstanding challenge in materials science is doing large-scale simulations with complex electron interactions. Deng and colleagues introduce a universal graph neural network-based interatomic potential integrating atomic magnetic moments as charge constraints, which allows for capturing subtle chemical properties in several lithium-based solid-state materials},
  archive      = {J_NATMI},
  author       = {Deng, Bowen and Zhong, Peichen and Jun, KyuJung and Riebesell, Janosh and Han, Kevin and Bartel, Christopher J. and Ceder, Gerbrand},
  doi          = {10.1038/s42256-023-00716-3},
  journal      = {Nature Machine Intelligence},
  number       = {9},
  pages        = {1031-1041},
  shortjournal = {Nat. Mach. Intell.},
  title        = {CHGNet as a pretrained universal neural network potential for charge-informed atomistic modelling},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ResGen is a pocket-aware 3D molecular generation model based
on parallel multiscale modelling. <em>NATMI</em>, <em>5</em>(9),
1020–1030. (<a
href="https://doi.org/10.1038/s42256-023-00712-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most molecular generative models based on artificial intelligence for de novo drug design are ligand-centric and do not consider the detailed three-dimensional geometries of protein binding pockets. Pocket-aware three-dimensional molecular generation is challenging due to the need to impose physical equivariance and to evaluate protein–ligand interactions when incrementally growing partially built molecules. Inspired by multiscale modelling in condensed matter and statistical physics, we present a three-dimensional molecular generative model conditioned on protein pockets, termed ResGen, for designing organic molecules inside of a given target. ResGen is built on the principle of parallel multiscale modelling, which can capture higher-level interaction and achieve higher computational efficiency (about eight-times faster than the previous best art). The generation process is formulated as a hierarchical autoregression, that is, a global autoregression for learning protein–ligand interactions and atomic component autoregression for learning each atom’s topology and geometry distributions. We demonstrate that ResGen has a higher success rate than existing state-of-the-art approaches in generating novel molecules that can bind to unseen targets more tightly than the original ligands. Moreover, retrospective computational experiments on de novo drug design in real-world scenarios show that ResGen successfully generates drug-like molecules with lower binding energy and higher diversity than state-of-the-art approaches. Generating novel molecules that bind to specific protein targets is a challenging but important task in computational drug design. Zhang and colleagues present a molecular generation method based on hierarchical auto-regression.},
  archive      = {J_NATMI},
  author       = {Zhang, Odin and Zhang, Jintu and Jin, Jieyu and Zhang, Xujun and Hu, RenLing and Shen, Chao and Cao, Hanqun and Du, Hongyan and Kang, Yu and Deng, Yafeng and Liu, Furui and Chen, Guangyong and Hsieh, Chang-Yu and Hou, Tingjun},
  doi          = {10.1038/s42256-023-00712-7},
  journal      = {Nature Machine Intelligence},
  number       = {9},
  pages        = {1020-1030},
  shortjournal = {Nat. Mach. Intell.},
  title        = {ResGen is a pocket-aware 3D molecular generation model based on parallel multiscale modelling},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). From attribution maps to human-understandable explanations
through concept relevance propagation. <em>NATMI</em>, <em>5</em>(9),
1006–1019. (<a
href="https://doi.org/10.1038/s42256-023-00711-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of explainable artificial intelligence (XAI) aims to bring transparency to today’s powerful but opaque deep learning models. While local XAI methods explain individual predictions in the form of attribution maps, thereby identifying ‘where’ important features occur (but not providing information about ‘what’ they represent), global explanation techniques visualize what concepts a model has generally learned to encode. Both types of method thus provide only partial insights and leave the burden of interpreting the model’s reasoning to the user. Here we introduce the Concept Relevance Propagation (CRP) approach, which combines the local and global perspectives and thus allows answering both the ‘where’ and ‘what’ questions for individual predictions. We demonstrate the capability of our method in various settings, showcasing that CRP leads to more human interpretable explanations and provides deep insights into the model’s representation and reasoning through concept atlases, concept-composition analyses, and quantitative investigations of concept subspaces and their role in fine-grained decision-making. Local methods of explainable artificial intelligence identify where important features or inputs occur, while global methods try to understand what features or concepts have been learned by a model. The authors propose a concept-level explanation method that bridges the local and global perspectives, enabling more comprehensive and human-understandable explanations.},
  archive      = {J_NATMI},
  author       = {Achtibat, Reduan and Dreyer, Maximilian and Eisenbraun, Ilona and Bosse, Sebastian and Wiegand, Thomas and Samek, Wojciech and Lapuschkin, Sebastian},
  doi          = {10.1038/s42256-023-00711-8},
  journal      = {Nature Machine Intelligence},
  number       = {9},
  pages        = {1006-1019},
  shortjournal = {Nat. Mach. Intell.},
  title        = {From attribution maps to human-understandable explanations through concept relevance propagation},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid hierarchical learning for solving complex sequential
tasks using the robotic manipulation network ROMAN. <em>NATMI</em>,
<em>5</em>(9), 991–1005. (<a
href="https://doi.org/10.1038/s42256-023-00709-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving long sequential tasks remains a non-trivial challenge in the field of embodied artificial intelligence. Enabling a robotic system to perform diverse sequential tasks with a broad range of manipulation skills is a notable open problem and continues to be an active area of research. In this work, we present a hybrid hierarchical learning framework, the robotic manipulation network ROMAN, to address the challenge of solving multiple complex tasks over long time horizons in robotic manipulation. By integrating behavioural cloning, imitation learning and reinforcement learning, ROMAN achieves task versatility and robust failure recovery. It consists of a central manipulation network that coordinates an ensemble of various neural networks, each specializing in different recombinable subtasks to generate their correct in-sequence actions, to solve complex long-horizon manipulation tasks. Our experiments show that, by orchestrating and activating these specialized manipulation experts, ROMAN generates correct sequential activations accomplishing long sequences of sophisticated manipulation tasks and achieving adaptive behaviours beyond demonstrations, while exhibiting robustness to various sensory noises. These results highlight the significance and versatility of ROMAN’s dynamic adaptability featuring autonomous failure recovery capabilities, and underline its potential for various autonomous manipulation tasks that require adaptive motor skills. Achieving sequential robotic actions involving different manipulation skills is an open challenge that is critical to enable robots to interact meaningfully with their physical environment. Triantafyllidis and colleagues present a hierarchical learning framework based on an ensemble of specialized neural networks to solve complex long-horizon manipulation tasks.},
  archive      = {J_NATMI},
  author       = {Triantafyllidis, Eleftherios and Acero, Fernando and Liu, Zhaocheng and Li, Zhibin},
  doi          = {10.1038/s42256-023-00709-2},
  journal      = {Nature Machine Intelligence},
  number       = {9},
  pages        = {991-1005},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Hybrid hierarchical learning for solving complex sequential tasks using the robotic manipulation network ROMAN},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A temporally resolved DNA framework state machine in living
cells. <em>NATMI</em>, <em>5</em>(9), 980–990. (<a
href="https://doi.org/10.1038/s42256-023-00707-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The environments in living cells are highly heterogeneous and compartmentalized, posing a grand challenge for the deployment of theranostic agents with spatiotemporal precision. Despite rapid advancements in creating nanodevices responsive to various cues in cellular environments, it remains difficult to control their operations based on the temporal sequence of these cues. Here, inspired by the temporally resolved process of viral invasion in nature, we design a DNA framework state machine (DFSM) that can target specific chromatin loci in living cells in a temporally controllable manner. The DFSM is composed of a six-helix DNA framework with multiple locks that can be opened via DNA strand displacement. The opening of locks at different locations results in distinct structural configurations of the DFSM. We show that the DFSM can switch among up to six structural states with reversibility, in response to the temporally ordered molecular inputs, including DNA keys, adenosine triphosphate or nucleolin. By implementing state switching of the DFSM in living cells, we demonstrate temporally controlled CRISPR–Cas9 targeting towards specific chromatin loci, which sheds light on biocomputing and smart theranostics in complex biological environments. The heterogeneous and compartmentalized environments within living cells make it difficult to deploy theranostic agents with precise spatiotemporal accuracy. Zhao et al. demonstrate a DNA framework state machine that can switch among multiple structural states according to the temporal sequence of molecular cues, enabling temporally controlled CRISPR–Cas9 targeting in living mammalian cells.},
  archive      = {J_NATMI},
  author       = {Zhao, Yan and Cao, Shuting and Wang, Yue and Li, Fan and Lin, Lixuan and Guo, Linjie and Wang, Fei and Chao, Jie and Zuo, Xiaolei and Zhu, Ying and Wang, Lihua and Li, Jiang and Fan, Chunhai},
  doi          = {10.1038/s42256-023-00707-4},
  journal      = {Nature Machine Intelligence},
  number       = {9},
  pages        = {980-990},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A temporally resolved DNA framework state machine in living cells},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Annotating metabolite mass spectra with domain-inspired
chemical formula transformers. <em>NATMI</em>, <em>5</em>(9), 965–979.
(<a href="https://doi.org/10.1038/s42256-023-00708-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metabolomics studies have identified small molecules that mediate cell signaling, competition and disease pathology, in part due to large-scale community efforts to measure tandem mass spectra for thousands of metabolite standards. Nevertheless, the majority of spectra observed in clinical samples cannot be unambiguously matched to known structures. Deep learning approaches to small-molecule structure elucidation have surprisingly failed to rival classical statistical methods, which we hypothesize is due to the lack of in-domain knowledge incorporated into current neural network architectures. Here we introduce a neural network-driven workflow for untargeted metabolomics, Metabolite Inference with Spectrum Transformers (MIST), to annotate tandem mass spectra peaks with chemical structures. Unlike existing approaches, MIST incorporates domain insights into its architecture by encoding peaks with their chemical formula representations, implicitly featurizing pairwise neutral losses and training the network to additionally predict substructure fragments. MIST performs favorably compared with both standard neural architectures and the state-of-the-art kernel method on the task of fingerprint prediction for over 70\% of metabolite standards and retrieves 66\% of metabolites with equal or improved accuracy, with 29\% strictly better. We further demonstrate the utility of MIST by suggesting potential dipeptide and alkaloid structures for differentially abundant spectra found in an inflammatory bowel disease patient cohort. Tandem mass spectroscopy is a useful tool to identify metabolites but is limited by the capability of computational methods to annotate peaks with chemical structures when spectra are dissimilar to previously observed spectra. Goldman and colleagues use a transformer-based method to annotate chemical structure fragments, thereby incorporating domain insights into its architecture, and to simultaneously predict the structure of the metabolite and its fragments from the spectrum.},
  archive      = {J_NATMI},
  author       = {Goldman, Samuel and Wohlwend, Jeremy and Stražar, Martin and Haroush, Guy and Xavier, Ramnik J. and Coley, Connor W.},
  doi          = {10.1038/s42256-023-00708-3},
  journal      = {Nature Machine Intelligence},
  number       = {9},
  pages        = {965-979},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Annotating metabolite mass spectra with domain-inspired chemical formula transformers},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Testing the limits of natural language models for predicting
human language judgements. <em>NATMI</em>, <em>5</em>(9), 952–964. (<a
href="https://doi.org/10.1038/s42256-023-00718-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural network language models appear to be increasingly aligned with how humans process and generate language, but identifying their weaknesses through adversarial examples is challenging due to the discrete nature of language and the complexity of human language perception. We bypass these limitations by turning the models against each other. We generate controversial sentence pairs where two language models disagree about which sentence is more likely to occur. Considering nine language models (including n-gram, recurrent neural networks and transformers), we created hundreds of controversial sentence pairs through synthetic optimization or by selecting sentences from a corpus. Controversial sentence pairs proved highly effective at revealing model failures and identifying models that aligned most closely with human judgements of which sentence is more likely. The most human-consistent model tested was GPT-2, although experiments also revealed substantial shortcomings in its alignment with human perception. With the advances in neural language models, the question arises if some models align better with human processing than others. Golan et al. identify sentences that language models disagree about and use them to compare the shortcomings of different language models.},
  archive      = {J_NATMI},
  author       = {Golan, Tal and Siegelman, Matthew and Kriegeskorte, Nikolaus and Baldassano, Christopher},
  doi          = {10.1038/s42256-023-00718-1},
  journal      = {Nature Machine Intelligence},
  number       = {9},
  pages        = {952-964},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Testing the limits of natural language models for predicting human language judgements},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Updating the checklist for artificial intelligence in
medical imaging (CLAIM) for reporting AI research. <em>NATMI</em>,
<em>5</em>(9), 950–951. (<a
href="https://doi.org/10.1038/s42256-023-00717-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Tejani, Ali S. and Klontzas, Michail E. and Gatti, Anthony A. and Mongan, John and Moy, Linda and Park, Seong Ho and Kahn, Charles E.},
  doi          = {10.1038/s42256-023-00717-2},
  journal      = {Nature Machine Intelligence},
  number       = {9},
  pages        = {950-951},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Updating the checklist for artificial intelligence in medical imaging (CLAIM) for reporting AI research},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unlocking biomolecular intelligence. <em>NATMI</em>,
<em>5</em>(9), 949. (<a
href="https://doi.org/10.1038/s42256-023-00730-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in DNA nanoengineering promise the development of new computing devices within biological systems, with applications in nanoscale sensing, diagnostics and therapeutics.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-023-00730-5},
  journal      = {Nature Machine Intelligence},
  number       = {9},
  pages        = {949},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Unlocking biomolecular intelligence},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Author correction: Self-play reinforcement learning guides
protein engineering. <em>NATMI</em>, <em>5</em>(8), 947. (<a
href="https://doi.org/10.1038/s42256-023-00713-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Wang, Yi and Tang, Hui and Huang, Lichao and Pan, Lulu and Yang, Lixiang and Yang, Huanming and Mu, Feng and Yang, Meng},
  doi          = {10.1038/s42256-023-00713-6},
  journal      = {Nature Machine Intelligence},
  number       = {8},
  pages        = {947},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Author correction: Self-play reinforcement learning guides protein engineering},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of mechanistic subtypes of parkinson’s using
patient-derived stem cell models. <em>NATMI</em>, <em>5</em>(8),
933–946. (<a href="https://doi.org/10.1038/s42256-023-00702-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease is a common, incurable neurodegenerative disorder that is clinically heterogeneous: it is likely that different cellular mechanisms drive the pathology in different individuals. So far it has not been possible to define the cellular mechanism underlying the neurodegenerative disease in life. We generated a machine learning-based model that can simultaneously predict the presence of disease and its primary mechanistic subtype in human neurons. We used stem cell technology to derive control or patient-derived neurons, and generated different disease subtypes through chemical induction or the presence of mutation. Multidimensional fluorescent labelling of organelles was performed in healthy control neurons and in four different disease subtypes, and both the quantitative single-cell fluorescence features and the images were used to independently train a series of classifiers to build deep neural networks. Quantitative cellular profile-based classifiers achieve an accuracy of 82\%, whereas image-based deep neural networks predict control and four distinct disease subtypes with an accuracy of 95\%. The machine learning-trained classifiers achieve their accuracy across all subtypes, using the organellar features of the mitochondria with the additional contribution of the lysosomes, confirming the biological importance of these pathways in Parkinson’s. Altogether, we show that machine learning approaches applied to patient-derived cells are highly accurate at predicting disease subtypes, providing proof of concept that this approach may enable mechanistic stratification and precision medicine approaches in the future. Deep learning applied to live-cell images of patient-derived neurons aids predicting underlying mechanisms and gains insights into neurodegenerative diseases, facilitating the understanding of mechanistic heterogeneity. D’Sa and colleagues use patient-derived stem cell models, high-throughput imaging and machine learning algorithms to investigate Parkinson’s disease subtyping.},
  archive      = {J_NATMI},
  author       = {D’Sa, Karishma and Evans, James R. and Virdi, Gurvir S. and Vecchi, Giulia and Adam, Alexander and Bertolli, Ottavia and Fleming, James and Chang, Hojong and Leighton, Craig and Horrocks, Mathew H. and Athauda, Dilan and Choi, Minee L. and Gandhi, Sonia},
  doi          = {10.1038/s42256-023-00702-9},
  journal      = {Nature Machine Intelligence},
  number       = {8},
  pages        = {933-946},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Prediction of mechanistic subtypes of parkinson’s using patient-derived stem cell models},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identifying important sensory feedback for learning
locomotion skills. <em>NATMI</em>, <em>5</em>(8), 919–932. (<a
href="https://doi.org/10.1038/s42256-023-00701-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot motor skills can be acquired by deep reinforcement learning as neural networks to reflect state–action mapping. The selection of states has been demonstrated to be crucial for successful robot motor learning. However, because of the complexity of neural networks, human insights and engineering efforts are often required to select appropriate states through qualitative approaches, such as ablation studies, without a quantitative analysis of the state importance. Here we present a systematic saliency analysis that quantitatively evaluates the relative importance of different feedback states for motor skills learned through deep reinforcement learning. Our approach provides a guideline to identify the most essential feedback states for robot motor learning. By using only the important states including joint positions, gravity vector and base linear and angular velocities, we demonstrate that a simulated quadruped robot can learn various robust locomotion skills. We find that locomotion skills learned only with important states can achieve task performance comparable to the performance of those with more states. This work provides quantitative insights into the impacts of state observations on specific types of motor skills, enabling the learning of a wide range of motor skills with minimal sensing dependencies. Traditional feedback-state selection in robot learning is empirical and requires substantial engineering efforts. Yu et al. develop a quantitative and systematic state-importance analysis, revealing crucial feedback signals for learning locomotion skills.},
  archive      = {J_NATMI},
  author       = {Yu, Wanming and Yang, Chuanyu and McGreavy, Christopher and Triantafyllidis, Eleftherios and Bellegarda, Guillaume and Shafiee, Milad and Ijspeert, Auke Jan and Li, Zhibin},
  doi          = {10.1038/s42256-023-00701-w},
  journal      = {Nature Machine Intelligence},
  number       = {8},
  pages        = {919-932},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Identifying important sensory feedback for learning locomotion skills},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Activity–weight duality in feed-forward neural networks
reveals two co-determinants for generalization. <em>NATMI</em>,
<em>5</em>(8), 908–918. (<a
href="https://doi.org/10.1038/s42256-023-00700-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalization is a fundamental problem in machine learning. For overparameterized deep neural network models, there are many solutions that can fit the training data equally well. The key question is which solution has a better generalization performance measured by test loss (error). Here we report the discovery of exact duality relations between changes in activities and changes in weights in any fully connected layer in feed-forward neural networks. By using the activity–weight duality relation, we decompose the generalization loss into contributions from different directions in weight space. Our analysis reveals that two key factors, sharpness of the loss landscape and size of the solution, act together to determine generalization. In general, flatter and smaller solutions have better generalization. By using the generalization loss decomposition, we show how existing learning algorithms and regularization schemes affect generalization by controlling one or both factors. Furthermore, by applying our analysis framework to evaluate different algorithms for realistic large neural network models in the multi-learner setting, we find that the decentralized algorithms have better generalization performance as they introduce additional landscape-dependent noise that leads to flatter solutions without changing their sizes. A challenging problem in deep learning consists in developing theoretical frameworks suitable to study generalization. Feng and colleagues uncover a duality relation between neuron activities and weights in deep learning neural networks, and use it to show that sharpness of the loss landscape and norm of the solution act together in determining its generalization performance.},
  archive      = {J_NATMI},
  author       = {Feng, Yu and Zhang, Wei and Tu, Yuhai},
  doi          = {10.1038/s42256-023-00700-x},
  journal      = {Nature Machine Intelligence},
  number       = {8},
  pages        = {908-918},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Activity–weight duality in feed-forward neural networks reveals two co-determinants for generalization},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised learning of hologram reconstruction using
physics consistency. <em>NATMI</em>, <em>5</em>(8), 895–907. (<a
href="https://doi.org/10.1038/s42256-023-00704-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing applications of deep learning in computational imaging and microscopy mostly depend on supervised learning, requiring large-scale, diverse and labelled training data. The acquisition and preparation of such training image datasets is often laborious and costly, leading to limited generalization to new sample types. Here we report a self-supervised learning model, termed GedankenNet, that eliminates the need for labelled or experimental training data, and demonstrate its effectiveness and superior generalization on hologram reconstruction tasks. Without prior knowledge about the sample types, the self-supervised learning model was trained using a physics-consistency loss and artificial random images synthetically generated without any experiments or resemblance to real-world samples. After its self-supervised training, GedankenNet successfully generalized to experimental holograms of unseen biological samples, reconstructing the phase and amplitude images of different types of object using experimentally acquired holograms. Without access to experimental data, knowledge of real samples or their spatial features, GedankenNet achieved complex-valued image reconstructions consistent with the wave equation in free space. The GedankenNet framework also shows resilience to random, unknown perturbations in the physical forward model, including changes in the hologram distances, pixel size and illumination wavelength. This self-supervised learning of image reconstruction creates new opportunities for solving inverse problems in holography, microscopy and computational imaging. Microscopic imaging and holography aim to decrease reliance on labelled experimental training data, which can introduce biases, be time-consuming and costly to prepare, and may lack real-world diversity. Huang et al. develop a physics-driven self-supervised model that eliminates the need for labelled or experimental training data, demonstrating superior generalization on the reconstruction of experimental holograms of various samples.},
  archive      = {J_NATMI},
  author       = {Huang, Luzhe and Chen, Hanlong and Liu, Tairan and Ozcan, Aydogan},
  doi          = {10.1038/s42256-023-00704-7},
  journal      = {Nature Machine Intelligence},
  number       = {8},
  pages        = {895-907},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Self-supervised learning of hologram reconstruction using physics consistency},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Algorithmic fairness and bias mitigation for clinical
machine learning with deep reinforcement learning. <em>NATMI</em>,
<em>5</em>(8), 884–894. (<a
href="https://doi.org/10.1038/s42256-023-00697-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As models based on machine learning continue to be developed for healthcare applications, greater effort is needed to ensure that these technologies do not reflect or exacerbate any unwanted or discriminatory biases that may be present in the data. Here we introduce a reinforcement learning framework capable of mitigating biases that may have been acquired during data collection. In particular, we evaluated our model for the task of rapidly predicting COVID-19 for patients presenting to hospital emergency departments and aimed to mitigate any site (hospital)-specific and ethnicity-based biases present in the data. Using a specialized reward function and training procedure, we show that our method achieves clinically effective screening performances, while significantly improving outcome fairness compared with current benchmarks and state-of-the-art machine learning methods. We performed external validation across three independent hospitals, and additionally tested our method on a patient intensive care unit discharge status task, demonstrating model generalizability. The tendency of machine learning algorithms to learn biases from training data calls for methods to mitigate unfairness before deployment to healthcare and other applications. Yang et al. propose a reinforcement-learning-based method for algorithmic bias mitigation and demonstrate it on COVID-19 screening and patient discharge prediction tasks.},
  archive      = {J_NATMI},
  author       = {Yang, Jenny and Soltan, Andrew A. S. and Eyre, David W. and Clifton, David A.},
  doi          = {10.1038/s42256-023-00697-3},
  journal      = {Nature Machine Intelligence},
  number       = {8},
  pages        = {884-894},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Algorithmic fairness and bias mitigation for clinical machine learning with deep reinforcement learning},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explaining machine learning models with interactive natural
language conversations using TalkToModel. <em>NATMI</em>, <em>5</em>(8),
873–883. (<a href="https://doi.org/10.1038/s42256-023-00692-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Practitioners increasingly use machine learning (ML) models, yet models have become more complex and harder to understand. To understand complex models, researchers have proposed techniques to explain model predictions. However, practitioners struggle to use explainability methods because they do not know which explanation to choose and how to interpret the explanation. Here we address the challenge of using explainability methods by proposing TalkToModel: an interactive dialogue system that explains ML models through natural language conversations. TalkToModel consists of three components: an adaptive dialogue engine that interprets natural language and generates meaningful responses; an execution component that constructs the explanations used in the conversation; and a conversational interface. In real-world evaluations, 73\% of healthcare workers agreed they would use TalkToModel over existing systems for understanding a disease prediction model, and 85\% of ML professionals agreed TalkToModel was easier to use, demonstrating that TalkToModel is highly effective for model explainability. To ensure that a machine learning model has learned the intended features, it can be useful to have an explanation of why a specific output was given. Slack et al. have created a conversational environment, based on language models and feature importance, which can interactively explore explanations with questions asked in natural language.},
  archive      = {J_NATMI},
  author       = {Slack, Dylan and Krishna, Satyapriya and Lakkaraju, Himabindu and Singh, Sameer},
  doi          = {10.1038/s42256-023-00692-8},
  journal      = {Nature Machine Intelligence},
  number       = {8},
  pages        = {873-883},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Explaining machine learning models with interactive natural language conversations using TalkToModel},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep neural networks predict class i major
histocompatibility complex epitope presentation and transfer learn
neoepitope immunogenicity. <em>NATMI</em>, <em>5</em>(8), 861–872. (<a
href="https://doi.org/10.1038/s42256-023-00694-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying neoepitopes that elicit an adaptive immune response is a major bottleneck to developing personalized cancer vaccines. Experimental validation of candidate neoepitopes is extremely resource intensive and the vast majority of candidates are non-immunogenic, creating a needle-in-a-haystack problem. Here we address this challenge, presenting computational methods for predicting class I major histocompatibility complex (MHC-I) epitopes and identifying immunogenic neoepitopes with improved precision. The BigMHC method comprises an ensemble of seven pan-allelic deep neural networks trained on peptide–MHC eluted ligand data from mass spectrometry assays and transfer learned on data from assays of antigen-specific immune response. Compared with four state-of-the-art classifiers, BigMHC significantly improves the prediction of epitope presentation on a test set of 45,409 MHC ligands among 900,592 random negatives (area under the receiver operating characteristic = 0.9733; area under the precision-recall curve = 0.8779). After transfer learning on immunogenicity data, BigMHC yields significantly higher precision than seven state-of-the-art models in identifying immunogenic neoepitopes, making BigMHC effective in clinical settings. Out of the large number of neoepitopes, few elicit an immune response from the major histocompatibility complex. To predict which neoepitopes can be effective, Albert and colleagues present a method based on long short-term memory ensembles and transfer learning from immunogenicity assays.},
  archive      = {J_NATMI},
  author       = {Albert, Benjamin Alexander and Yang, Yunxiao and Shao, Xiaoshan M. and Singh, Dipika and Smith, Kellie N. and Anagnostou, Valsamo and Karchin, Rachel},
  doi          = {10.1038/s42256-023-00694-6},
  journal      = {Nature Machine Intelligence},
  number       = {8},
  pages        = {861-872},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Deep neural networks predict class i major histocompatibility complex epitope presentation and transfer learn neoepitope immunogenicity},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Self-play reinforcement learning guides protein
engineering. <em>NATMI</em>, <em>5</em>(8), 845–860. (<a
href="https://doi.org/10.1038/s42256-023-00691-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing protein sequences towards desired properties is a fundamental goal of protein engineering, with applications in drug discovery and enzymatic engineering. Machine learning-guided directed evolution has shown success in expediting the optimization cycle and reducing experimental burden. However, efficient sampling in the vast design space remains a challenge. To address this, we propose EvoPlay, a self-play reinforcement learning framework based on the single-player version of AlphaZero. In this work, we mutate a single-site residue as an action to optimize protein sequences, analogous to playing pieces on a chessboard. A policy-value neural network reciprocally interacts with look-ahead Monte Carlo tree search to guide the optimization agent with breadth and depth. We extensively evaluate EvoPlay on a suite of in silico directed evolution tasks over full-length sequences or combinatorial sites using functional surrogates. EvoPlay also supports AlphaFold2 as a structural surrogate to design peptide binders with high affinities, validated by binding assays. Moreover, we harness EvoPlay to prospectively engineer luciferase, resulting in the discovery of variants with 7.8-fold bioluminescence improvement beyond wild type. In sum, EvoPlay holds great promise for facilitating protein design to tackle unmet academic, industrial and clinical needs. There are currently promising developments in deep learning for protein design, with applications in drug discovery and synthetic biology. For more efficient exploration of the design space, Wang et al. demonstrate a reinforcement learning method, EvoZero, for directed evolution in protein engineering towards desired functional or structure-related properties.},
  archive      = {J_NATMI},
  author       = {Wang, Yi and Tang, Hui and Huang, Lichao and Pan, Lulu and Yang, Lixiang and Yang, Huanming and Mu, Feng and Yang, Meng},
  doi          = {10.1038/s42256-023-00691-9},
  journal      = {Nature Machine Intelligence},
  number       = {8},
  pages        = {845-860},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Self-play reinforcement learning guides protein engineering},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Resolution enhancement with a task-assisted GAN to guide
optical nanoscopy image analysis and acquisition. <em>NATMI</em>,
<em>5</em>(8), 830–844. (<a
href="https://doi.org/10.1038/s42256-023-00689-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Super-resolution fluorescence microscopy methods enable the characterization of nanostructures in living and fixed biological tissues. However, they require the adjustment of multiple imaging parameters while attempting to satisfy conflicting objectives, such as maximizing spatial and temporal resolution while minimizing light exposure. To overcome the limitations imposed by these trade-offs, post-acquisition algorithmic approaches have been proposed for resolution enhancement and image-quality improvement. Here we introduce the task-assisted generative adversarial network (TA-GAN), which incorporates an auxiliary task (for example, segmentation, localization) closely related to the observed biological nanostructure characterization. We evaluate how the TA-GAN improves generative accuracy over unassisted methods, using images acquired with different modalities such as confocal, bright-field, stimulated emission depletion and structured illumination microscopy. The TA-GAN is incorporated directly into the acquisition pipeline of the microscope to predict the nanometric content of the field of view without requiring the acquisition of a super-resolved image. This information is used to automatically select the imaging modality and regions of interest, optimizing the acquisition sequence by reducing light exposure. Data-driven microscopy methods like the TA-GAN will enable the observation of dynamic molecular processes with spatial and temporal resolutions that surpass the limits currently imposed by the trade-offs constraining super-resolution microscopy. Algorithmic super-resolution in the context of fluorescence microscopy is challenging due to the difficulty to reliably represent biological nanostructures in synthetically generated images. Bouchard and colleagues propose a deep learning model for live-cell imaging that can leverage auxiliary microscopy imaging tasks to guide and enhance reconstruction, while preserving the biological features of interest.},
  archive      = {J_NATMI},
  author       = {Bouchard, Catherine and Wiesner, Theresa and Deschênes, Andréanne and Bilodeau, Anthony and Turcotte, Benoît and Gagné, Christian and Lavoie-Cardinal, Flavie},
  doi          = {10.1038/s42256-023-00689-3},
  journal      = {Nature Machine Intelligence},
  number       = {8},
  pages        = {830-844},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Resolution enhancement with a task-assisted GAN to guide optical nanoscopy image analysis and acquisition},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiple stakeholders drive diverse interpretability
requirements for machine learning in healthcare. <em>NATMI</em>,
<em>5</em>(8), 824–829. (<a
href="https://doi.org/10.1038/s42256-023-00698-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applications of machine learning are becoming increasingly common in medicine and healthcare, enabling more accurate predictive models. However, this often comes at the cost of interpretability, limiting the clinical impact of machine learning methods. To realize the potential of machine learning in healthcare, it is critical to understand such models from the perspective of multiple stakeholders and various angles, necessitating different types of explanation. In this Perspective, we explore five fundamentally different types of post-hoc machine learning interpretability. We highlight the different types of information that they provide, and describe when each can be useful. We examine the various stakeholders in healthcare, delving into their specific objectives, requirements and goals. We discuss how current notions of interpretability can help meet these and what is required for each stakeholder to make machine learning models clinically impactful. Finally, to facilitate adoption, we release an open-source interpretability library containing implementations of the different types of interpretability, including tools for visualizing and exploring the explanations. Limited interpretability and understanding of machine learning methods in healthcare hinder their clinical impact. Imrie et al. discuss five types of machine learning interpretability. They examine medical stakeholders, highlight how interpretability meets their needs and emphasize the role of tailored interpretability in linking machine learning advancements to clinical impact.},
  archive      = {J_NATMI},
  author       = {Imrie, Fergus and Davis, Robert and van der Schaar, Mihaela},
  doi          = {10.1038/s42256-023-00698-2},
  journal      = {Nature Machine Intelligence},
  number       = {8},
  pages        = {824-829},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Multiple stakeholders drive diverse interpretability requirements for machine learning in healthcare},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enabling collaborative governance of medical AI.
<em>NATMI</em>, <em>5</em>(8), 821–823. (<a
href="https://doi.org/10.1038/s42256-023-00699-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical artificial intelligence needs governance to ensure safety and effectiveness, not just centrally (for example, by the US Food and Drug Administration) but also locally to account for differences in care, patients and system performance. Practical collaborative governance will enable health systems to carry out these challenging governance tasks, supported by central regulators.},
  archive      = {J_NATMI},
  author       = {Price, W. Nicholson and Sendak, Mark and Balu, Suresh and Singh, Karandeep},
  doi          = {10.1038/s42256-023-00699-1},
  journal      = {Nature Machine Intelligence},
  number       = {8},
  pages        = {821-823},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Enabling collaborative governance of medical AI},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Foundation models and the privatization of public knowledge.
<em>NATMI</em>, <em>5</em>(8), 818–820. (<a
href="https://doi.org/10.1038/s42256-023-00695-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To protect the integrity of knowledge production, the training procedures of foundation models such as GPT-4 need to be made accessible to regulators and researchers. Foundation models must become open and public, and those are not the same thing.},
  archive      = {J_NATMI},
  author       = {Ferrari, Fabian and van Dijck, José and van den Bosch, Antal},
  doi          = {10.1038/s42256-023-00695-5},
  journal      = {Nature Machine Intelligence},
  number       = {8},
  pages        = {818-820},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Foundation models and the privatization of public knowledge},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The TRIPOD-p reporting guideline for improving the integrity
and transparency of predictive analytics in healthcare through study
protocols. <em>NATMI</em>, <em>5</em>(8), 816–817. (<a
href="https://doi.org/10.1038/s42256-023-00705-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Dhiman, Paula and Whittle, Rebecca and Van Calster, Ben and Ghassemi, Marzyeh and Liu, Xiaoxuan and McCradden, Melissa D. and Moons, Karel G. M. and Riley, Richard D. and Collins, Gary S.},
  doi          = {10.1038/s42256-023-00705-6},
  journal      = {Nature Machine Intelligence},
  number       = {8},
  pages        = {816-817},
  shortjournal = {Nat. Mach. Intell.},
  title        = {The TRIPOD-P reporting guideline for improving the integrity and transparency of predictive analytics in healthcare through study protocols},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Taking ethics seriously in AV trajectory planning
algorithms. <em>NATMI</em>, <em>5</em>(8), 814–815. (<a
href="https://doi.org/10.1038/s42256-023-00706-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Kirchmair, Lando and Paulo, Norbert},
  doi          = {10.1038/s42256-023-00706-5},
  journal      = {Nature Machine Intelligence},
  number       = {8},
  pages        = {814-815},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Taking ethics seriously in AV trajectory planning algorithms},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Seeking a quantum advantage for machine learning.
<em>NATMI</em>, <em>5</em>(8), 813. (<a
href="https://doi.org/10.1038/s42256-023-00710-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning and quantum computing approaches are converging, fuelling considerable excitement over quantum devices and their capabilities. However, given the current hardware limitations, it is important to push the technology forward while being realistic about what quantum computers can do, now and in the near future.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-023-00710-9},
  journal      = {Nature Machine Intelligence},
  number       = {8},
  pages        = {813},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Seeking a quantum advantage for machine learning},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Publisher correction: A neural machine code and programming
framework for the reservoir computer. <em>NATMI</em>, <em>5</em>(7),
811. (<a href="https://doi.org/10.1038/s42256-023-00693-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Kim, Jason Z. and Bassett, Dani S.},
  doi          = {10.1038/s42256-023-00693-7},
  journal      = {Nature Machine Intelligence},
  number       = {7},
  pages        = {811},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Publisher correction: A neural machine code and programming framework for the reservoir computer},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Federated benchmarking of medical artificial intelligence
with MedPerf. <em>NATMI</em>, <em>5</em>(7), 799–810. (<a
href="https://doi.org/10.1038/s42256-023-00652-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical artificial intelligence (AI) has tremendous potential to advance healthcare by supporting and contributing to the evidence-based practice of medicine, personalizing patient treatment, reducing costs, and improving both healthcare provider and patient experience. Unlocking this potential requires systematic, quantitative evaluation of the performance of medical AI models on large-scale, heterogeneous data capturing diverse patient populations. Here, to meet this need, we introduce MedPerf, an open platform for benchmarking AI models in the medical domain. MedPerf focuses on enabling federated evaluation of AI models, by securely distributing them to different facilities, such as healthcare organizations. This process of bringing the model to the data empowers each facility to assess and verify the performance of AI models in an efficient and human-supervised process, while prioritizing privacy. We describe the current challenges healthcare and AI communities face, the need for an open platform, the design philosophy of MedPerf, its current implementation status and real-world deployment, our roadmap and, importantly, the use of MedPerf with multiple international institutions within cloud-based technology and on-premises scenarios. Finally, we welcome new contributions by researchers and organizations to further strengthen MedPerf as an open benchmarking platform. Federated learning can be used to train medical AI models on sensitive personal data while preserving important privacy properties; however, the sensitive nature of the data makes it difficult to evaluate approaches reproducibly on real data. The MedPerf project presented by Karargyris et al. provides the tools and infrastructure to distribute models to healthcare facilities, such that they can be trained and evaluated in realistic settings.},
  archive      = {J_NATMI},
  author       = {Karargyris, Alexandros and Umeton, Renato and Sheller, Micah J. and Aristizabal, Alejandro and George, Johnu and Wuest, Anna and Pati, Sarthak and Kassem, Hasan and Zenk, Maximilian and Baid, Ujjwal and Narayana Moorthy, Prakash and Chowdhury, Alexander and Guo, Junyi and Nalawade, Sahil and Rosenthal, Jacob and Kanter, David and Xenochristou, Maria and Beutel, Daniel J. and Chung, Verena and Bergquist, Timothy and Eddy, James and Abid, Abubakar and Tunstall, Lewis and Sanseviero, Omar and Dimitriadis, Dimitrios and Qian, Yiming and Xu, Xinxing and Liu, Yong and Goh, Rick Siow Mong and Bala, Srini and Bittorf, Victor and Puchala, Sreekar Reddy and Ricciuti, Biagio and Samineni, Soujanya and Sengupta, Eshna and Chaudhari, Akshay and Coleman, Cody and Desinghu, Bala and Diamos, Gregory and Dutta, Debo and Feddema, Diane and Fursin, Grigori and Huang, Xinyuan and Kashyap, Satyananda and Lane, Nicholas and Mallick, Indranil and Mascagni, Pietro and Mehta, Virendra and Moraes, Cassiano Ferro and Natarajan, Vivek and Nikolov, Nikola and Padoy, Nicolas and Pekhimenko, Gennady and Reddi, Vijay Janapa and Reina, G. Anthony and Ribalta, Pablo and Singh, Abhishek and Thiagarajan, Jayaraman J. and Albrecht, Jacob and Wolf, Thomas and Miller, Geralyn and Fu, Huazhu and Shah, Prashant and Xu, Daguang and Yadav, Poonam and Talby, David and Awad, Mark M. and Howard, Jeremy P. and Rosenthal, Michael and Marchionni, Luigi and Loda, Massimo and Johnson, Jason M. and Bakas, Spyridon and Mattson, Peter},
  doi          = {10.1038/s42256-023-00652-2},
  journal      = {Nature Machine Intelligence},
  number       = {7},
  pages        = {799-810},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Federated benchmarking of medical artificial intelligence with MedPerf},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reusability report: Evaluating reproducibility and
reusability of a fine-tuned model to predict drug response in cancer
patient samples. <em>NATMI</em>, <em>5</em>(7), 792–798. (<a
href="https://doi.org/10.1038/s42256-023-00688-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning and artificial intelligence methods are increasingly being used in personalized medicine, including precision oncology. Ma et al. (Nature Cancer 2021) have developed a new method called ‘transfer of cell line response prediction’ (TCRP) to train predictors of drug response in cancer cell lines and optimize their performance in higher complex cancer model systems via few-shot learning. TCRP has been presented as a successful modelling approach in multiple case studies. Given the importance of this approach for assisting clinicians in their treatment decision processes, we sought to independently reproduce the authors’ findings and improve the reusability of TCRP in new case studies, including validation in clinical-trial datasets—a high bar for drug-response prediction. Our reproducibility results, while not reaching the same level of superiority as those of the original authors, were able to confirm the superiority of TCRP in the original clinical context. Our reusability results indicate that, in the majority of novel clinical contexts, TCRP remains the superior method for predicting response for both preclinical and clinical settings. Our results thus support the superiority of TCRP over established statistical and machine learning approaches in preclinical and clinical settings. We also developed new resources to increase the reusability of the TCRP model for future improvements and validation studies. This Reusability Report revisits a recently developed machine learning method for precision oncology, called ‘transfer of cell line response prediction’ (TCRP). Emily So et al. confirm the reproducibility of the previously reported results in drug-response prediction and also test the reusability of the method on new case studies with clinical relevance.},
  archive      = {J_NATMI},
  author       = {So, Emily and Yu, Fengqing and Wang, Bo and Haibe-Kains, Benjamin},
  doi          = {10.1038/s42256-023-00688-4},
  journal      = {Nature Machine Intelligence},
  number       = {7},
  pages        = {792-798},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Reusability report: Evaluating reproducibility and reusability of a fine-tuned model to predict drug response in cancer patient samples},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-correcting quantum many-body control using
reinforcement learning with tensor networks. <em>NATMI</em>,
<em>5</em>(7), 780–791. (<a
href="https://doi.org/10.1038/s42256-023-00687-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum many-body control is a central milestone en route to harnessing quantum technologies. However, the exponential growth of the Hilbert space dimension with the number of qubits makes it challenging to classically simulate quantum many-body systems and, consequently, to devise reliable and robust optimal control protocols. Here we present a framework for efficiently controlling quantum many-body systems based on reinforcement learning (RL). We tackle the quantum-control problem by leveraging matrix product states (1) for representing the many-body state and (2) as part of the trainable machine learning architecture for our RL agent. The framework is applied to prepare ground states of the quantum Ising chain, including states in the critical region. It allows us to control systems far larger than neural-network-only architectures permit, while retaining the advantages of deep learning algorithms, such as generalizability and trainable robustness to noise. In particular, we demonstrate that RL agents are capable of finding universal controls, of learning how to optimally steer previously unseen many-body states and of adapting control protocols on the fly when the quantum dynamics is subject to stochastic perturbations. Furthermore, we map our RL framework to a hybrid quantum–classical algorithm that can be performed on noisy intermediate-scale quantum devices and test it under the presence of experimentally relevant sources of noise. Optimal control of quantum many-body systems is needed to make use of quantum technologies, but is challenging due to the exponentially large dimension of the Hilbert space as a function of the number of qubits. Metz and Bukov propose a framework combining matrix product states and reinforcement learning that allows control of a larger number of interacting quantum particles than achievable with standard neural-network-based methods.},
  archive      = {J_NATMI},
  author       = {Metz, Friederike and Bukov, Marin},
  doi          = {10.1038/s42256-023-00687-5},
  journal      = {Nature Machine Intelligence},
  number       = {7},
  pages        = {780-791},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Self-correcting quantum many-body control using reinforcement learning with tensor networks},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Encoding physics to learn reaction–diffusion processes.
<em>NATMI</em>, <em>5</em>(7), 765–779. (<a
href="https://doi.org/10.1038/s42256-023-00685-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modelling complex spatiotemporal dynamical systems, such as reaction–diffusion processes, which can be found in many fundamental dynamical effects in various disciplines, has largely relied on finding the underlying partial differential equations (PDEs). However, predicting the evolution of these systems remains a challenging task for many cases owing to insufficient prior knowledge and a lack of explicit PDE formulation for describing the nonlinear process of the system variables. With recent data-driven approaches, it is possible to learn from measurement data while adding prior physics knowledge. However, existing physics-informed machine learning paradigms impose physics laws through soft penalty constraints, and the solution quality largely depends on a trial-and-error proper setting of hyperparameters. Here we propose a deep learning framework that forcibly encodes a given physics structure in a recurrent convolutional neural network to facilitate learning of the spatiotemporal dynamics in sparse data regimes. We show with extensive numerical experiments how the proposed approach can be applied to a variety of problems regarding reaction–diffusion processes and other PDE systems, including forward and inverse analysis, data-driven modelling and discovery of PDEs. We find that our physics-encoding machine learning approach shows high accuracy, robustness, interpretability and generalizability. Reaction–diffusion processes, which can be found in many fundamental spatiotemporal dynamical phenomena in chemistry, biology, geology, physics and ecology, can be modelled by partial differential equations (PDEs). Physics-informed deep learning approaches can accelerate the discovery of PDEs and Rao et al. improve interpretability and generalizability by strong encoding of the underlying physics structure in the neural network.},
  archive      = {J_NATMI},
  author       = {Rao, Chengping and Ren, Pu and Wang, Qi and Buyukozturk, Oral and Sun, Hao and Liu, Yang},
  doi          = {10.1038/s42256-023-00685-7},
  journal      = {Nature Machine Intelligence},
  number       = {7},
  pages        = {765-779},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Encoding physics to learn reaction–diffusion processes},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application of variational graph encoders as an effective
generalist algorithm in computer-aided drug design. <em>NATMI</em>,
<em>5</em>(7), 754–764. (<a
href="https://doi.org/10.1038/s42256-023-00683-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although there has been considerable progress in molecular property prediction in computer-aided drug design, there is a critical need to have fast and accurate models. Many of the currently available methods are mostly specialize in predicting specific properties, leading to the use of many models side-by-side that lead to impossibly high computational overheads for the common researcher. Henceforth, the authors propose a single, generalist unified model exploiting graph convolutional variational encoders that can simultaneously predict multiple properties such as absorption, distribution, metabolism, excretion and toxicity, target-specific docking score prediction, and drug–drug interactions. The use of such a method allows for state-of-the-art virtual screening with a considerable acceleration advantage of up to two orders of magnitude. The minimization of a graph variational encoder’s latent space also allows for accelerated development of specific drugs for targets with Pareto optimality principles considered, and has the added advantage of explainability. Computer-aided drug design has a high computational cost and a newly identified drug candidate might be unsuitable due to a range of drug properties. Lam and colleagues trained a model based on graph convolutional variational encoders that predicts a range of properties simultaneously to accelerate virtual screening.},
  archive      = {J_NATMI},
  author       = {Lam, Hilbert Yuen In and Pincket, Robbe and Han, Hao and Ong, Xing Er and Wang, Zechen and Hinks, Jamie and Wei, Yanjie and Li, Weifeng and Zheng, Liangzhen and Mu, Yuguang},
  doi          = {10.1038/s42256-023-00683-9},
  journal      = {Nature Machine Intelligence},
  number       = {7},
  pages        = {754-764},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Application of variational graph encoders as an effective generalist algorithm in computer-aided drug design},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hypergraph factorization for multi-tissue gene expression
imputation. <em>NATMI</em>, <em>5</em>(7), 739–753. (<a
href="https://doi.org/10.1038/s42256-023-00684-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating gene expression across tissues and cell types is crucial for understanding the coordinated biological mechanisms that drive disease and characterize homoeostasis. However, traditional multi-tissue integration methods either cannot handle uncollected tissues or rely on genotype information, which is often unavailable and subject to privacy concerns. Here we present HYFA (hypergraph factorization), a parameter-efficient graph representation learning approach for joint imputation of multi-tissue and cell-type gene expression. HYFA is genotype agnostic, supports a variable number of collected tissues per individual, and imposes strong inductive biases to leverage the shared regulatory architecture of tissues and genes. In performance comparison on Genotype–Tissue Expression project data, HYFA achieves superior performance over existing methods, especially when multiple reference tissues are available. The HYFA-imputed dataset can be used to identify replicable regulatory genetic variations (expression quantitative trait loci), with substantial gains over the original incomplete dataset. HYFA can accelerate the effective and scalable integration of tissue and cell-type transcriptome biorepositories. Integrating gene expression across tissues is crucial for understanding coordinated biological mechanisms. Viñas et al. present a neural network for multi-tissue imputation of gene expression, exploiting the shared regulatory architecture of tissues.},
  archive      = {J_NATMI},
  author       = {Viñas, Ramon and Joshi, Chaitanya K. and Georgiev, Dobrik and Lin, Phillip and Dumitrascu, Bianca and Gamazon, Eric R. and Liò, Pietro},
  doi          = {10.1038/s42256-023-00684-8},
  journal      = {Nature Machine Intelligence},
  number       = {7},
  pages        = {739-753},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Hypergraph factorization for multi-tissue gene expression imputation},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Uncertainty-guided dual-views for semi-supervised volumetric
medical image segmentation. <em>NATMI</em>, <em>5</em>(7), 724–738. (<a
href="https://doi.org/10.1038/s42256-023-00682-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has led to tremendous progress in the field of medical artificial intelligence. However, training deep-learning models usually require large amounts of annotated data. Annotating large-scale datasets is prone to human biases and is often very laborious, especially for dense prediction tasks such as image segmentation. Inspired by semi-supervised algorithms that use both labelled and unlabelled data for training, we propose a dual-view framework based on adversarial learning for segmenting volumetric images. In doing so, we use critic networks to allow each view to learn from high-confidence predictions of the other view by measuring a notion of uncertainty. Furthermore, to jointly learn the dual-views and the critics, we formulate the learning problem as a min–max problem. We analyse and contrast our proposed method against state-of-the-art baselines, both qualitatively and quantitatively, on four public datasets with multiple modalities (for example, computerized topography and magnetic resonance imaging) and demonstrate that the proposed semi-supervised method substantially outperforms the competing baselines while achieving competitive performance compared to fully supervised counterparts. Our empirical results suggest that an uncertainty-guided co-training framework can make two neural networks robust to data artefacts and have the ability to generate plausible segmentation masks that can be helpful for semi-automated segmentation processes. It is challenging to obtain a sufficient amount of high-quality annotated images for deep-learning applications in medical imaging, and practical methods often use a combination of labelled and unlabelled data. A dual-view framework builds on such semi-supervised approaches and uses two independently trained critic networks that learn from each other to generate segmentation masks in different medical imaging modalities.},
  archive      = {J_NATMI},
  author       = {Peiris, Himashi and Hayat, Munawar and Chen, Zhaolin and Egan, Gary and Harandi, Mehrtash},
  doi          = {10.1038/s42256-023-00682-w},
  journal      = {Nature Machine Intelligence},
  number       = {7},
  pages        = {724-738},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Uncertainty-guided dual-views for semi-supervised volumetric medical image segmentation},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Uncertainty quantification via a memristor bayesian deep
neural network for risk-sensitive reinforcement learning.
<em>NATMI</em>, <em>5</em>(7), 714–723. (<a
href="https://doi.org/10.1038/s42256-023-00680-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many advanced artificial intelligence tasks, such as policy optimization, decision making and autonomous navigation, demand high-bandwidth data transfer and probabilistic computing, posing great challenges for conventional computing hardware. Since digital computers based on the von Neumann architecture are good at precise and deterministic computing, their computing efficiency is limited by the high cost of both data transfer between memory and computing units and massive random number generation. Here we develop a stochastic computation-in-memory computing system that can efficiently perform both in situ random number generation and computation based on the nanoscale physical behaviour of memristors. This system is constructed based on a hardware-implemented multiple-memristor-array system. To demonstrate its functionality and efficiency, we implement a typical risk-sensitive reinforcement learning task, namely the storm coast task, with a four-layer Bayesian deep neural network. The computing system efficiently decomposes aleatoric and epistemic uncertainties by exploiting the inherent stochasticity of memristor. Compared with the conventional digital computer, our memristor-based system achieves a 10 times higher speed and 150 times higher energy efficiency in uncertainty decomposition. This stochastic computation-in-memory computing system paves the way for high-speed and energy-efficient implementation of various probabilistic artificial intelligence algorithms. The stochastic features of memristors make them suitable for computation and probabilistic sampling; however, implementing these properties in hardware is extremely challenging. Lin et al. introduce an approach that leverages the cycle-to-cycle read variability of memristors as a physical random variable for in situ, real-time random number generation, and demonstrate it on a risk-sensitive reinforcement learning task.},
  archive      = {J_NATMI},
  author       = {Lin, Yudeng and Zhang, Qingtian and Gao, Bin and Tang, Jianshi and Yao, Peng and Li, Chongxuan and Huang, Shiyu and Liu, Zhengwu and Zhou, Ying and Liu, Yuyi and Zhang, Wenqiang and Zhu, Jun and Qian, He and Wu, Huaqiang},
  doi          = {10.1038/s42256-023-00680-y},
  journal      = {Nature Machine Intelligence},
  number       = {7},
  pages        = {714-723},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Uncertainty quantification via a memristor bayesian deep neural network for risk-sensitive reinforcement learning},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Extrapolating heterogeneous time-series gene expression data
using sagittarius. <em>NATMI</em>, <em>5</em>(7), 699–713. (<a
href="https://doi.org/10.1038/s42256-023-00679-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the temporal dynamics of gene expression is crucial for developmental biology, tumour biology and biogerontology. However, some timepoints remain challenging to measure in the laboratory, particularly during very early or very late stages of a biological process. Here we propose Sagittarius, a transformer-based model that can accurately simulate gene expression profiles at timepoints outside the range of times measured in the laboratory. The key idea behind Sagittarius is to learn a shared reference space for time-series measurements, thereby explicitly modelling unaligned timepoints and conditional batch effects between time series, and making the model widely applicable to diverse biological settings. We show Sagittarius’s promising performance when extrapolating mammalian developmental gene expression, simulating drug-induced expression at unmeasured dose and treatment times, and augmenting datasets to accurately predict drug sensitivity. We also used Sagittarius to extrapolate mutation profiles for early-stage cancer patients, which enabled us to discover a gene set connected to the Hedgehog signalling pathway that may be related to tumorigenesis in sarcoma patients, including PTCH1, ARID2 and MYCBP2. By augmenting experimental temporal datasets with crucial but difficult-to-measure extrapolated datapoints, Sagittarius enables deeper insights into the temporal dynamics of heterogeneous transcriptomic processes and can be broadly applied to biological time-series extrapolation. The temporal nature of the transcriptome is important for understanding many biological processes, but it is challenging to measure. By leveraging datasets with multiple time series, Woicik and colleagues present a model that accurately extrapolates genomic measurements to unmeasured timepoints, including developmental gene expression, drug-induced perturbations and cancer gene mutations.},
  archive      = {J_NATMI},
  author       = {Woicik, Addie and Zhang, Mingxin and Chan, Janelle and Ma, Jianzhu and Wang, Sheng},
  doi          = {10.1038/s42256-023-00679-5},
  journal      = {Nature Machine Intelligence},
  number       = {7},
  pages        = {699-713},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Extrapolating heterogeneous time-series gene expression data using sagittarius},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The importance of resource awareness in artificial
intelligence for healthcare. <em>NATMI</em>, <em>5</em>(7), 687–698. (<a
href="https://doi.org/10.1038/s42256-023-00670-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence and machine learning (AI/ML) models have been adopted in a wide range of healthcare applications, from medical image computing and analysis to continuous health monitoring and management. Recent data have demonstrated a clear trend that AI/ML model sizes, as well as their computational complexity, memory consumption and the scale of the required training data and costs, are experiencing an exponential increase. The developments in current computing hardware platforms, storage infrastructure, networking and domain expertise cannot keep up with this exponential growth in resources demanded by the AI/ML models. Here, we first analyse this recent trend and highlight that there are resource sustainability issues in AI/ML for healthcare. We then present various algorithm/system innovations that will help address these issues. We finally outline future directions to proactively and prospectively tackle these resource sustainability issues. Sustainability awareness is lacking in the development of AI systems and algorithms for healthcare. The authors discuss resource sustainability issues in energy, storage and domain knowledge, and present potential solutions.},
  archive      = {J_NATMI},
  author       = {Jia, Zhenge and Chen, Jianxu and Xu, Xiaowei and Kheir, John and Hu, Jingtong and Xiao, Han and Peng, Sui and Hu, Xiaobo Sharon and Chen, Danny and Shi, Yiyu},
  doi          = {10.1038/s42256-023-00670-0},
  journal      = {Nature Machine Intelligence},
  number       = {7},
  pages        = {687-698},
  shortjournal = {Nat. Mach. Intell.},
  title        = {The importance of resource awareness in artificial intelligence for healthcare},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Navigating the development challenges in creating complex
data systems. <em>NATMI</em>, <em>5</em>(7), 681–686. (<a
href="https://doi.org/10.1038/s42256-023-00665-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data science systems (DSSs) are a fundamental tool in many areas of research and are now being developed by people with a myriad of backgrounds. This is coupled with a crisis in the reproducibility of such DSSs, despite the wide availability of powerful tools for data science and machine learning over the past decade. We believe that perverse incentives and a lack of widespread software engineering skills are among the many causes of this crisis and analyse why software engineering and building large complex systems is, in general, hard. Based on these insights, we identify how software engineering addresses those difficulties and how one might apply and generalize software engineering methods to make DSSs more fit for purpose. We advocate two key development philosophies: one should incrementally grow—not plan then build—DSSs, and one should use two types of feedback loop during development—one that tests the code’s correctness and another that evaluates the code’s efficacy. With the explosion of machine learning models of increasing complexity for research applications, more attention is needed for the development of good quality codebases. Sören Dittmer, Michael Roberts and colleagues discuss how to embrace guiding principles from traditional software engineering, including the approach to incrementally grow software, and to use two types of feedback loop, testing correctness and efficacy.},
  archive      = {J_NATMI},
  author       = {Dittmer, Sören and Roberts, Michael and Gilbey, Julian and Biguri, Ander and Preller, Jacobus and Rudd, James H. F. and Aston, John A. D. and Schönlieb, Carola-Bibiane},
  doi          = {10.1038/s42256-023-00665-x},
  journal      = {Nature Machine Intelligence},
  number       = {7},
  pages        = {681-686},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Navigating the development challenges in creating complex data systems},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Addressing the harms of AI-generated inauthentic content.
<em>NATMI</em>, <em>5</em>(7), 679–680. (<a
href="https://doi.org/10.1038/s42256-023-00690-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Menczer, Filippo and Crandall, David and Ahn, Yong-Yeol and Kapadia, Apu},
  doi          = {10.1038/s42256-023-00690-w},
  journal      = {Nature Machine Intelligence},
  number       = {7},
  pages        = {679-680},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Addressing the harms of AI-generated inauthentic content},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Language models and linguistic theories beyond words.
<em>NATMI</em>, <em>5</em>(7), 677–678. (<a
href="https://doi.org/10.1038/s42256-023-00703-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of large language models is mainly a feat of engineering and so far has been largely disconnected from the field of linguistics. Exploring links between the two directions is reopening longstanding debates in the study of language.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-023-00703-8},
  journal      = {Nature Machine Intelligence},
  number       = {7},
  pages        = {677-678},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Language models and linguistic theories beyond words},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Author correction: Supervised learning of high-confidence
phenotypic subpopulations from single-cell data. <em>NATMI</em>,
<em>5</em>(6), 676. (<a
href="https://doi.org/10.1038/s42256-023-00681-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Ren, Tao and Chen, Canping and Danilov, Alexey V. and Liu, Susan and Guan, Xiangnan and Du, Shunyi and Wu, Xiwei and Sherman, Mara H. and Spellman, Paul T. and Coussens, Lisa M. and Adey, Andrew C. and Mills, Gordon B. and Wu, Ling-Yun and Xia, Zheng},
  doi          = {10.1038/s42256-023-00681-x},
  journal      = {Nature Machine Intelligence},
  number       = {6},
  pages        = {676},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Author correction: Supervised learning of high-confidence phenotypic subpopulations from single-cell data},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Morphological flexibility in robotic systems through
physical polygon meshing. <em>NATMI</em>, <em>5</em>(6), 669–675. (<a
href="https://doi.org/10.1038/s42256-023-00676-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shape-changing robots adapt their own morphology to address a wider range of functions or environments than is possible with a fixed or rigid structure. Akin to biological organisms, the ability to alter shape or configuration emerges from the underlying mechanical structure, materials or control methods. Soft robots, for instance, employ malleable materials to adapt to their environment, modular robots assemble multiple units into various three-dimensional configurations and insect-like swarm robots interact in large numbers to fulfil tasks. However, the promise of broad functional versatility in shape-changing robots has so far been constrained by the practical implications of either increasing the degree of morphological flexibility or addressing specific applications. Here we report a method for creating robotic systems that realizes both sides of this trade-off through the introduction of physical polygon meshing. By abstracting functional three-dimensional structures, collections of shape-changing robotic modules can recreate diverse three-dimensional shapes and dynamically control the resulting morphology. We demonstrate this approach by developing a system of polygon robots that change their own shape, attach to each other, communicate and reconfigure to form functional and articulated structures. Applying the system to three distinct application areas of robotics involving user interaction, locomotion and manipulation, our work demonstrates how physical polygon meshing provides a new framework for more versatile intelligent machines. Robots that can change their shape offer flexible functionality. A modular robotic platform is shown that implements physical polygon meshing, by combining triangles with sides of adjustable lengths, allowing flexible three-dimensional shape configurations.},
  archive      = {J_NATMI},
  author       = {Belke, Christoph H. and Holdcroft, Kevin and Sigrist, Alexander and Paik, Jamie},
  doi          = {10.1038/s42256-023-00676-8},
  journal      = {Nature Machine Intelligence},
  number       = {6},
  pages        = {669-675},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Morphological flexibility in robotic systems through physical polygon meshing},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A super-resolution strategy for mass spectrometry imaging
via transfer learning. <em>NATMI</em>, <em>5</em>(6), 656–668. (<a
href="https://doi.org/10.1038/s42256-023-00677-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-spatial-resolution mass spectrometry imaging (HSR-MSI) provides precise spatial information on thousands of biomolecules without labelling across a tissue section. Deep learning methods, trained on large numbers of images, can be used to further improve resolution. However, the limited amount of HSR-MSI data that are publicly available mean that super-resolution reconstruction of images obtained by MSI using deep learning is still a challenge. Here we develop a deep learning framework based on transfer learning called MSI from optical super-resolution (MOSR) that substantially reduces the requirement for sample size. Needing only ten HSR-MSI images, the method transfers knowledge learned from abundant optical images (~15,000) to MSI tasks. Compared with the deep learning model without transfer learning, the MOSR model obtains better image quality with higher peak signal-to-noise ratios and structural similarity index values. It also achieves higher training efficiency and a stronger generalization performance. The MOSR model predicts HSR-MSI images with very small sample size and could transform applications with super-resolution MSI. Mass spectrometry imaging (MSI) can provide important information, but long imaging times are needed to achieve a high spatial resolution, which is why the amount of publicly available high-resolution MSI data for deep learning applications is limited. Liao and colleagues use transfer learning from optical super-resolution images to reduce the amount of MSI data that is needed.},
  archive      = {J_NATMI},
  author       = {Liao, Tiepeng and Ren, Zihao and Chai, Zhaoliang and Yuan, Man and Miao, Chenjian and Li, Junjie and Chen, Qi and Li, Zhilin and Wang, Ziyi and Yi, Lin and Ge, Siyuan and Qian, Wenwei and Shen, Longfeng and Wang, Zilei and Xiong, Wei and Zhu, Hongying},
  doi          = {10.1038/s42256-023-00677-7},
  journal      = {Nature Machine Intelligence},
  number       = {6},
  pages        = {656-668},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A super-resolution strategy for mass spectrometry imaging via transfer learning},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Active mechanical haptics with high-fidelity perceptions for
immersive virtual reality. <em>NATMI</em>, <em>5</em>(6), 643–655. (<a
href="https://doi.org/10.1038/s42256-023-00671-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-centred mechanical sensory perceptions enable us to immerse ourselves in the physical environment by actively touching or holding objects so that we may feel their existence (that is, ownership) and their fundamental properties (for example, stiffness or hardness). In a virtual environment, the replication of these active perceptions can create authentic haptic experiences, serving as an essential supplement for visual and auditory experiences. We present here a first-person, human-triggered haptic device enabled by curved origami that allows humans to actively experience touching of objects with various stiffness perceptions from soft to hard and from positive to negative ranges. This device represents a substantial shift away from the third-person, machine-triggered and passive haptics currently in use. The device is synchronized with the virtual environment by changing its configuration to adapt various interactions by emulating body-centred physical perceptions, including hardness, softness and sensations of crushing and weightlessness. Quantitative evaluations demonstrate that the active haptic device creates a highly immersive virtual environment, outperforming existing vibration-based passive devices. These concepts and resulting technologies create new opportunities and application potential for a more authentic virtual world. Immersive virtual reality requires artificial sensory perceptions to simulate what we feel and how we interact in the natural environment. Zhang and colleagues present a first-person, human-triggered, active haptic device that allows users to experience mechanical touching with various stiffness perceptions from positive to negative ranges, achieved by the unique benefits of curved origami.},
  archive      = {J_NATMI},
  author       = {Zhang, Zhuang and Xu, Zhenghao and Emu, Luoqian and Wei, Pingdong and Chen, Sentao and Zhai, Zirui and Kong, Lingyu and Wang, Yong and Jiang, Hanqing},
  doi          = {10.1038/s42256-023-00671-z},
  journal      = {Nature Machine Intelligence},
  number       = {6},
  pages        = {643-655},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Active mechanical haptics with high-fidelity perceptions for immersive virtual reality},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint variational autoencoders for multimodal imputation and
embedding. <em>NATMI</em>, <em>5</em>(6), 631–642. (<a
href="https://doi.org/10.1038/s42256-023-00663-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-cell multimodal datasets have measured various characteristics of individual cells, enabling a deep understanding of cellular and molecular mechanisms. However, multimodal data generation remains costly and challenging, and missing modalities happen frequently. Recently, machine learning approaches have been developed for data imputation but typically require fully matched multimodalities to learn common latent embeddings that potentially lack modality specificity. To address these issues, we developed an open-source machine learning model, Joint Variational Autoencoders for multimodal Imputation and Embedding (JAMIE). JAMIE takes single-cell multimodal data that can have partially matched samples across modalities. Variational autoencoders learn the latent embeddings of each modality. Then, embeddings from matched samples across modalities are aggregated to identify joint cross-modal latent embeddings before reconstruction. To perform cross-modal imputation, the latent embeddings of one modality can be used with the decoder of the other modality. For interpretability, Shapley values are used to prioritize input features for cross-modal imputation and known sample labels. We applied JAMIE to both simulation data and emerging single-cell multimodal data including gene expression, chromatin accessibility, and electrophysiology in human and mouse brains. JAMIE significantly outperforms existing state-of-the-art methods in general and prioritized multimodal features for imputation, providing potentially novel mechanistic insights at cellular resolution. While single-cell multimodal datasets allow for the measurement of individual cells to understand cellular and molecular mechanisms, generating multimodal data for many cells is costly and challenging. Cohen Kalafut and colleagues develop a machine learning model capable of imputing single-cell modalities and prioritizing multimodal features, such as gene expression, chromatin accessibility and electrophysiology.},
  archive      = {J_NATMI},
  author       = {Cohen Kalafut, Noah and Huang, Xiang and Wang, Daifeng},
  doi          = {10.1038/s42256-023-00663-z},
  journal      = {Nature Machine Intelligence},
  number       = {6},
  pages        = {631-642},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Joint variational autoencoders for multimodal imputation and embedding},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). A neural machine code and programming framework for the
reservoir computer. <em>NATMI</em>, <em>5</em>(6), 622–630. (<a
href="https://doi.org/10.1038/s42256-023-00668-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From logical reasoning to mental simulation, biological and artificial neural systems possess an incredible capacity for computation. Such neural computers offer a fundamentally novel computing paradigm by representing data continuously and processing information in a natively parallel and distributed manner. To harness this computation, prior work has developed extensive training techniques to understand existing neural networks. However, the lack of a concrete and low-level machine code for neural networks precludes us from taking full advantage of a neural computing framework. Here we provide such a machine code along with a programming framework by using a recurrent neural network—a reservoir computer—to decompile, code and compile analogue computations. By decompiling the reservoir’s internal representation and dynamics into an analytic basis of its inputs, we define a low-level neural machine code that we use to program the reservoir to solve complex equations and store chaotic dynamical systems as random-access memory. We further provide a fully distributed neural implementation of software virtualization and logical circuits, and even program a playable game of pong inside of a reservoir computer. Importantly, all of these functions are programmed without requiring any example data or sampling of state space. Finally, we demonstrate that we can accurately decompile the analytic, internal representations of a full-rank reservoir computer that has been conventionally trained using data. Taken together, we define an implementation of neural computation that can both decompile computations from existing neural connectivity and compile distributed programs as new connections. Recurrent neural networks are flexible architectures that can perform a variety of complex, time-dependent computations. Kim and Bassett introduce an alternative, ‘programming’-like computational framework to determine the appropriate network parameters for a specific task without the need for supervised training.},
  archive      = {J_NATMI},
  author       = {Kim, Jason Z. and Bassett, Dani S.},
  doi          = {10.1038/s42256-023-00668-8},
  journal      = {Nature Machine Intelligence},
  number       = {6},
  pages        = {622-630},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A neural machine code and programming framework for the reservoir computer},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Structure-inducing pre-training. <em>NATMI</em>,
<em>5</em>(6), 612–621. (<a
href="https://doi.org/10.1038/s42256-023-00647-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language model pre-training and the derived general-purpose methods have reshaped machine learning research. However, there remains considerable uncertainty regarding why pre-training improves the performance of downstream tasks. This challenge is pronounced when using language model pre-training in domains outside of natural language. Here we investigate this problem by analysing how pre-training methods impose relational structure in induced per-sample latent spaces—that is, what constraints do pre-training methods impose on the distance or geometry between the pre-trained embeddings of samples. A comprehensive review of pre-training methods reveals that this question remains open, despite theoretical analyses showing the importance of understanding this form of induced structure. Based on this review, we introduce a pre-training framework that enables a granular and comprehensive understanding of how relational structure can be induced. We present a theoretical analysis of the framework from the first principles and establish a connection between the relational inductive bias of pre-training and fine-tuning performance. Empirical studies spanning three data modalities and ten fine-tuning tasks confirm theoretical analyses, inform the design of novel pre-training methods and establish consistent improvements over a compelling suite of methods. Designing methods to induce explicit and deep structural constraints in latent space at the sample level is an open problem in natural language processing-derived methods relying on transfer learning. McDermott and colleagues propose and analyse a pre-training framework imposing such structural constraints, and empirically demonstrate its advantages by showing that it outperforms existing pre-training state-of-the-art methods.},
  archive      = {J_NATMI},
  author       = {McDermott, Matthew B. A. and Yap, Brendan and Szolovits, Peter and Zitnik, Marinka},
  doi          = {10.1038/s42256-023-00647-z},
  journal      = {Nature Machine Intelligence},
  number       = {6},
  pages        = {612-621},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Structure-inducing pre-training},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpretable weather forecasting for worldwide stations
with a unified deep model. <em>NATMI</em>, <em>5</em>(6), 602–611. (<a
href="https://doi.org/10.1038/s42256-023-00667-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic weather stations are essential for fine-grained weather forecasting; they can be built almost anywhere around the world and are much cheaper than radars and satellites. However, these scattered stations only provide partial observations governed by the continuous space–time global weather system, thus introducing thorny challenges to worldwide forecasting. Here we present the Corrformer model with a novel multi-correlation mechanism, which unifies spatial cross-correlation and temporal auto-correlation into a learned multi-scale tree structure to capture worldwide spatiotemporal correlations. Corrformer reduces the canonical double quadratic complexity of spatiotemporal modelling to linear in spatial modelling and log-linear in temporal modelling, achieving collaborative forecasts for tens of thousands of stations within a unified deep model. Our model can generate interpretable predictions based on inferred propagation directions of weather processes, facilitating a fully data-driven artificial intelligence paradigm for discovering insights for meteorological science. Corrformer yields state-of-the-art forecasts on global, regional and citywide datasets with high confidence and provided skilful weather services for the 2022 Winter Olympics. Worldwide weather station forecasting is challenging because of high computational costs and the difficulty of modelling spatiotemporal correlations from partial observations. Wu et al. propose a transformer-based method that can reconstruct such complex correlations from scattered weather stations, leading to efficient and interpretable state-of-the-art forecasts.},
  archive      = {J_NATMI},
  author       = {Wu, Haixu and Zhou, Hang and Long, Mingsheng and Wang, Jianmin},
  doi          = {10.1038/s42256-023-00667-9},
  journal      = {Nature Machine Intelligence},
  number       = {6},
  pages        = {602-611},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Interpretable weather forecasting for worldwide stations with a unified deep model},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Algorithms to estimate shapley value feature attributions.
<em>NATMI</em>, <em>5</em>(6), 590–601. (<a
href="https://doi.org/10.1038/s42256-023-00657-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature attributions based on the Shapley value are popular for explaining machine learning models. However, their estimation is complex from both theoretical and computational standpoints. We disentangle this complexity into two main factors: the approach to removing feature information and the tractable estimation strategy. These two factors provide a natural lens through which we can better understand and compare 24 distinct algorithms. Based on the various feature-removal approaches, we describe the multiple types of Shapley value feature attributions and the methods to calculate each one. Then, based on the tractable estimation strategies, we characterize two distinct families of approaches: model-agnostic and model-specific approximations. For the model-agnostic approximations, we benchmark a wide class of estimation approaches and tie them to alternative yet equivalent characterizations of the Shapley value. For the model-specific approximations, we clarify the assumptions crucial to each method’s tractability for linear, tree and deep models. Finally, we identify gaps in the literature and promising future research directions. There are numerous algorithms for generating Shapley value explanations. The authors provide a comprehensive survey of Shapley value feature attribution algorithms by disentangling and clarifying the fundamental challenges underlying their computation.},
  archive      = {J_NATMI},
  author       = {Chen, Hugh and Covert, Ian C. and Lundberg, Scott M. and Lee, Su-In},
  doi          = {10.1038/s42256-023-00657-x},
  journal      = {Nature Machine Intelligence},
  number       = {6},
  pages        = {590-601},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Algorithms to estimate shapley value feature attributions},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards quantum enhanced adversarial robustness in machine
learning. <em>NATMI</em>, <em>5</em>(6), 581–589. (<a
href="https://doi.org/10.1038/s42256-023-00661-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning algorithms are powerful tools for data-driven tasks such as image classification and feature detection. However, their vulnerability to adversarial examples—input samples manipulated to fool the algorithm—remains a serious challenge. The integration of machine learning with quantum computing has the potential to yield tools offering not only better accuracy and computational efficiency, but also superior robustness against adversarial attacks. Indeed, recent work has employed quantum-mechanical phenomena to defend against adversarial attacks, spurring the rapid development of the field of quantum adversarial machine learning (QAML) and potentially yielding a new source of quantum advantage. Despite promising early results, there remain challenges in building robust real-world QAML tools. In this Perspective, we discuss recent progress in QAML and identify key challenges. We also suggest future research directions that could determine the route to practicality for QAML approaches as quantum computing hardware scales up and noise levels are reduced. To fulfil the potential of quantum machine learning for practical applications in the near future, it needs to be robust against adversarial attacks. West and colleagues give an overview of recent developments in quantum adversarial machine learning, and outline key challenges and future research directions to advance the field.},
  archive      = {J_NATMI},
  author       = {West, Maxwell T. and Tsang, Shu-Lok and Low, Jia S. and Hill, Charles D. and Leckie, Christopher and Hollenberg, Lloyd C. L. and Erfani, Sarah M. and Usman, Muhammad},
  doi          = {10.1038/s42256-023-00661-1},
  journal      = {Nature Machine Intelligence},
  number       = {6},
  pages        = {581-589},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Towards quantum enhanced adversarial robustness in machine learning},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Incorporating physics into data-driven computer vision.
<em>NATMI</em>, <em>5</em>(6), 572–580. (<a
href="https://doi.org/10.1038/s42256-023-00662-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many computer vision techniques infer properties of our physical world from images. Although images are formed through the physics of light and mechanics, computer vision techniques are typically data driven. This trend is mostly performance related: classical techniques from physics-based vision often score lower on metrics compared with modern deep learning. However, recent research, covered in this Perspective, has shown that physical models can be included as a constraint into data-driven pipelines. In doing so, one can combine the performance benefits of a data-driven method with advantages offered from a physics-based method, such as intepretability, falsifiability and generalizability. The aim of this Perspective is to provide an overview into specific approaches for integrating physical models into artificial intelligence pipelines, referred to as physics-based machine learning. We discuss technical approaches that range from modifications to the dataset, network design, loss functions, optimization and regularization schemes. Although computer vision techniques are often data-driven, they can be enhanced by including the physical models underlying image formation as constraints. Achuta Kadambi et al. provide an overview of various techniques to incorporate physics into data-driven vision pipelines.},
  archive      = {J_NATMI},
  author       = {Kadambi, Achuta and de Melo, Celso and Hsieh, Cho-Jui and Srivastava, Mani and Soatto, Stefano},
  doi          = {10.1038/s42256-023-00662-0},
  journal      = {Nature Machine Intelligence},
  number       = {6},
  pages        = {572-580},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Incorporating physics into data-driven computer vision},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A “programming” framework for recurrent neural networks.
<em>NATMI</em>, <em>5</em>(6), 570–571. (<a
href="https://doi.org/10.1038/s42256-023-00674-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A ‘programming’-like approach provides a one-step algorithm to find network parameters for recurrent neural networks that can model complex dynamical systems.},
  archive      = {J_NATMI},
  author       = {Beiran, Manuel and Spencer-Salmon, Camille A. and Rajan, Kanaka},
  doi          = {10.1038/s42256-023-00674-w},
  journal      = {Nature Machine Intelligence},
  number       = {6},
  pages        = {570-571},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A ‘programming’ framework for recurrent neural networks},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DishBrain plays pong and promises more. <em>NATMI</em>,
<em>5</em>(6), 568–569. (<a
href="https://doi.org/10.1038/s42256-023-00666-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An in vitro biological system of cultured brain cells has learned to play Pong. This feat opens up an avenue towards the convergence of biological and machine intelligence.},
  archive      = {J_NATMI},
  author       = {Goldwag, Joshua and Wang, Ge},
  doi          = {10.1038/s42256-023-00666-w},
  journal      = {Nature Machine Intelligence},
  number       = {6},
  pages        = {568-569},
  shortjournal = {Nat. Mach. Intell.},
  title        = {DishBrain plays pong and promises more},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The incentive gap in data work in the era of large models.
<em>NATMI</em>, <em>5</em>(6), 565–567. (<a
href="https://doi.org/10.1038/s42256-023-00673-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are repeated calls in the AI community to prioritize data work — collecting, curating, analysing and otherwise considering the quality of data. But this is not practised as much as advocates would like, often because of a lack of institutional and cultural incentives. One way to encourage data work would be to reframe it as more technically rigorous, and thereby integrate it into more-valued lines of research such as model innovation.},
  archive      = {J_NATMI},
  author       = {Gero, Katy Ilonka and Das, Payel and Dognin, Pierre and Padhi, Inkit and Sattigeri, Prasanna and Varshney, Kush R.},
  doi          = {10.1038/s42256-023-00673-x},
  journal      = {Nature Machine Intelligence},
  number       = {6},
  pages        = {565-567},
  shortjournal = {Nat. Mach. Intell.},
  title        = {The incentive gap in data work in the era of large models},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). How can LLMs transform the robotic design process?
<em>NATMI</em>, <em>5</em>(6), 561–564. (<a
href="https://doi.org/10.1038/s42256-023-00669-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that large language models (LLMs), such as ChatGPT, can guide the robot design process, on both the conceptual and technical level, and we propose new human–AI co-design strategies and their societal implications.},
  archive      = {J_NATMI},
  author       = {Stella, Francesco and Della Santina, Cosimo and Hughes, Josie},
  doi          = {10.1038/s42256-023-00669-7},
  journal      = {Nature Machine Intelligence},
  number       = {6},
  pages        = {561-564},
  shortjournal = {Nat. Mach. Intell.},
  title        = {How can LLMs transform the robotic design process?},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Why the european AI act transparency obligation is
insufficient. <em>NATMI</em>, <em>5</em>(6), 559–560. (<a
href="https://doi.org/10.1038/s42256-023-00672-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Li, Zihao},
  doi          = {10.1038/s42256-023-00672-y},
  journal      = {Nature Machine Intelligence},
  number       = {6},
  pages        = {559-560},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Why the european AI act transparency obligation is insufficient},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Judging the creative prowess of AI. <em>NATMI</em>,
<em>5</em>(6), 558. (<a
href="https://doi.org/10.1038/s42256-023-00664-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Chakraborty, Tanmoy and Masud, Sarah},
  doi          = {10.1038/s42256-023-00664-y},
  journal      = {Nature Machine Intelligence},
  number       = {6},
  pages        = {558},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Judging the creative prowess of AI},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A touch of virtual reality. <em>NATMI</em>, <em>5</em>(6),
557. (<a href="https://doi.org/10.1038/s42256-023-00686-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual worlds are typically encountered through simulated visual and auditory perceptions. Incorporating touch can create more immersive experiences with a sense of agency.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-023-00686-6},
  journal      = {Nature Machine Intelligence},
  number       = {6},
  pages        = {557},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A touch of virtual reality},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Life-threatening ventricular arrhythmia detection challenge
in implantable cardioverter–defibrillators. <em>NATMI</em>,
<em>5</em>(5), 554–555. (<a
href="https://doi.org/10.1038/s42256-023-00659-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The organizers of the TinyML Design Contest describe the top machine-learning-based real-time detection algorithms for ventricular arrhythmia.},
  archive      = {J_NATMI},
  author       = {Jia, Zhenge and Li, Dawei and Xu, Xiaowei and Li, Na and Hong, Feng and Ping, Lichuan and Shi, Yiyu},
  doi          = {10.1038/s42256-023-00659-9},
  journal      = {Nature Machine Intelligence},
  number       = {5},
  pages        = {554-555},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Life-threatening ventricular arrhythmia detection challenge in implantable cardioverter–defibrillators},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge graph-enhanced molecular contrastive learning with
functional prompt. <em>NATMI</em>, <em>5</em>(5), 542–553. (<a
href="https://doi.org/10.1038/s42256-023-00654-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models can accurately predict molecular properties and help making the search for potential drug candidates faster and more efficient. Many existing methods are purely data driven, focusing on exploiting the intrinsic topology and construction rules of molecules without any chemical prior information. The high data dependency makes them difficult to generalize to a wider chemical space and leads to a lack of interpretability of predictions. Here, to address this issue, we introduce a chemical element-oriented knowledge graph to summarize the basic knowledge of elements and their closely related functional groups. We further propose a method for knowledge graph-enhanced molecular contrastive learning with functional prompt (KANO), exploiting external fundamental domain knowledge in both pre-training and fine-tuning. Specifically, with element-oriented knowledge graph as a prior, we first design an element-guided graph augmentation in contrastive-based pre-training to explore microscopic atomic associations without violating molecular semantics. Then, we learn functional prompts in fine-tuning to evoke the downstream task-related knowledge acquired by the pre-trained model. Extensive experiments show that KANO outperforms state-of-the-art baselines on 14 molecular property prediction datasets and provides chemically sound explanations for its predictions. This work contributes to more efficient drug design by offering a high-quality knowledge prior, interpretable molecular representation and superior prediction performance. Deep learning can be used to predict molecular properties, but such methods usually need a large amount of data and are hard to generalize to different chemical spaces. To provide a useful primer for deep learning models models, Fang and colleagues use contrastive learning and a knowledge graph based on the Periodic Table and Wikipedia pages on chemical functional groups.},
  archive      = {J_NATMI},
  author       = {Fang, Yin and Zhang, Qiang and Zhang, Ningyu and Chen, Zhuo and Zhuang, Xiang and Shao, Xin and Fan, Xiaohui and Chen, Huajun},
  doi          = {10.1038/s42256-023-00654-0},
  journal      = {Nature Machine Intelligence},
  number       = {5},
  pages        = {542-553},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Knowledge graph-enhanced molecular contrastive learning with functional prompt},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Supervised learning of high-confidence phenotypic
subpopulations from single-cell data. <em>NATMI</em>, <em>5</em>(5),
528–541. (<a href="https://doi.org/10.1038/s42256-023-00656-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately identifying phenotype-relevant cell subsets from heterogeneous cell populations is crucial for delineating the underlying mechanisms driving biological or clinical phenotypes. Here by deploying a Learning with Rejection strategy, we developed a novel supervised learning framework called PENCIL to identify subpopulations associated with categorical or continuous phenotypes from single-cell data. By embedding a feature selection function into this flexible framework, for the first time, we were able to simultaneously select informative features and identify cell subpopulations, enabling accurate identification of phenotypic subpopulations otherwise missed by methods incapable of concurrent gene selection. Furthermore, the regression mode of PENCIL presents a novel ability for supervised phenotypic trajectory learning of subpopulations from single-cell data. We conducted comprehensive simulations to evaluate PENCIL’s versatility in simultaneous gene selection, subpopulation identification and phenotypic trajectory prediction. PENCIL is fast and scalable to analyse one million cells within 1 h. Using the classification mode, PENCIL detected T-cell subpopulations associated with melanoma immunotherapy outcomes. Moreover, when applied to single-cell RNA sequencing of a patient with mantle cell lymphoma with drug treatment across multiple timepoints, the regression mode of PENCIL revealed a transcriptional treatment response trajectory. Collectively, our work introduces a scalable and flexible infrastructure to accurately identify phenotype-associated subpopulations from single-cell data. To detect phenotype-related cell subpopulations from single-cell data, appropriate feature sets need to be chosen or learned simultaneously. Ren et al. present here a tool based on Learning with Rejection, a method that during training learns features from cells that can be predicted with high confidence, while cells that the model is not yet certain about are rejected.},
  archive      = {J_NATMI},
  author       = {Ren, Tao and Chen, Canping and Danilov, Alexey V. and Liu, Susan and Guan, Xiangnan and Du, Shunyi and Wu, Xiwei and Sherman, Mara H. and Spellman, Paul T. and Coussens, Lisa M. and Adey, Andrew C. and Mills, Gordon B. and Wu, Ling-Yun and Xia, Zheng},
  doi          = {10.1038/s42256-023-00656-y},
  journal      = {Nature Machine Intelligence},
  number       = {5},
  pages        = {528-541},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Supervised learning of high-confidence phenotypic subpopulations from single-cell data},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accurate online training of dynamical spiking neural
networks through forward propagation through time. <em>NATMI</em>,
<em>5</em>(5), 518–527. (<a
href="https://doi.org/10.1038/s42256-023-00650-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With recent advances in learning algorithms, recurrent networks of spiking neurons are achieving performance that is competitive with vanilla recurrent neural networks. However, these algorithms are limited to small networks of simple spiking neurons and modest-length temporal sequences, as they impose high memory requirements, have difficulty training complex neuron models and are incompatible with online learning. Here, we show how the recently developed Forward-Propagation Through Time (FPTT) learning combined with novel liquid time-constant spiking neurons resolves these limitations. Applying FPTT to networks of such complex spiking neurons, we demonstrate online learning of exceedingly long sequences while outperforming current online methods and approaching or outperforming offline methods on temporal classification tasks. The efficiency and robustness of FPTT enable us to directly train a deep and performant spiking neural network for joint object localization and recognition, demonstrating the ability to train large-scale dynamic and complex spiking neural network architectures. Memory efficient online training of recurrent spiking neural networks without compromising accuracy is an open challenge in neuromorphic computing. Yin and colleagues demonstrate that training a recurrent neural network consisting of so-called liquid time-constant spiking neurons using an algorithm called Forward-Propagation Through Time allows for online learning and state-of-the-art performance at a reduced computational cost compared with existing approaches.},
  archive      = {J_NATMI},
  author       = {Yin, Bojian and Corradi, Federico and Bohté, Sander M.},
  doi          = {10.1038/s42256-023-00650-4},
  journal      = {Nature Machine Intelligence},
  number       = {5},
  pages        = {518-527},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Accurate online training of dynamical spiking neural networks through forward propagation through time},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recurrent graph optimal transport for learning 3D flow
motion in particle tracking. <em>NATMI</em>, <em>5</em>(5), 505–517. (<a
href="https://doi.org/10.1038/s42256-023-00648-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flow visualization technologies such as particle tracking velocimetry are broadly used for studying three-dimensional turbulent flow in natural and industrial processes. Despite the advances in three-dimensional acquisition techniques, it is challenging to develop motion estimation algorithms in particle tracking due to large particle displacements, dense particle distributions and high computational cost. We present an end-to-end solution called graph optimal transport (GotFlow3D) to learn the three-dimensional fluid flow motion from consecutive particle images. The proposed model uses a graph neural network to extract geometric features and to further enrich the particle representations. The extracted deep features are subsequently used to correspond particles between consecutive frames, and the flow motion is then iteratively updated with a recurrent neural network approach. Experimental evaluations—including assessments on numerical experiments and validations on real-world experiments—demonstrate that GotFlow3D achieves state-of-the-art performance compared with recently developed scene flow learners and particle tracking algorithms. We believe that the high accuracy, robustness and generalization ability of our method can provide deeper insight into the complex dynamics of many physical and biological systems. Particle tracking velocimetry to estimate particle displacements in fluid flows in complex experimental scenarios is a challenging task and often comes with high computational cost. Liang and colleagues propose a graph neural network and optimal transport-based algorithm that can greatly improve the accuracy of existing tracking algorithms in real-world applications.},
  archive      = {J_NATMI},
  author       = {Liang, Jiaming and Xu, Chao and Cai, Shengze},
  doi          = {10.1038/s42256-023-00648-y},
  journal      = {Nature Machine Intelligence},
  number       = {5},
  pages        = {505-517},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Recurrent graph optimal transport for learning 3D flow motion in particle tracking},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adversarial competition and collusion in algorithmic
markets. <em>NATMI</em>, <em>5</em>(5), 497–504. (<a
href="https://doi.org/10.1038/s42256-023-00646-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Algorithms are now playing a central role in digital marketplaces, setting prices and automatically responding in real time to competitors’ behaviour. The deployment of automated pricing algorithms is scrutinized by economists and regulatory agencies, concerned about its impact on prices and competition. Existing research has so far been limited to cases where all firms use the same algorithm, suggesting that anti-competitive behaviour might spontaneously arise in that setting. Here we introduce and study a general anti-competitive mechanism, adversarial collusion, where one firm manipulates other sellers that use their own pricing algorithm. We propose a network-based framework to model the strategies of pricing algorithms on iterated two-firm and three-firm markets. In this framework, an attacker learns to endogenize competitors’ algorithms and then derive a strategy to artificially increase its profit at the expense of competitors. Facing a drastic loss of profits, competitors will eventually intervene and revise or turn off their pricing algorithm. To disincentivize this intervention, we show that the attacker can instead unilaterally increase both its profits and the profits of competitors. This leads to a collusive outcome with symmetric and supra-competitive profits, sustainable in the long run. Together, our findings highlight the need for policymakers and regulatory agencies to consider adversarial manipulations of algorithmic pricing, which might currently fall outside of the scope of current competition laws. Online commerce is increasingly relying on pricing algorithms. Using a network-based approach inspired by adversarial machine learning, a firm can learn the strategy of its competitors and use it to unilaterally increase all firms’ profits. This approach, termed as ‘adversarial collusion’, calls for new regulatory measures.},
  archive      = {J_NATMI},
  author       = {Rocher, Luc and Tournier, Arnaud J. and de Montjoye, Yves-Alexandre},
  doi          = {10.1038/s42256-023-00646-0},
  journal      = {Nature Machine Intelligence},
  number       = {5},
  pages        = {497-504},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Adversarial competition and collusion in algorithmic markets},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Linguistically inspired roadmap for building biologically
reliable protein language models. <em>NATMI</em>, <em>5</em>(5),
485–496. (<a href="https://doi.org/10.1038/s42256-023-00637-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural-network-based language models (LMs) are increasingly applied to large-scale protein sequence data to predict protein function. However, being largely black-box models and thus challenging to interpret, current protein LM approaches do not contribute to a fundamental understanding of sequence–function mappings, hindering rule-based biotherapeutic drug development. We argue that guidance drawn from linguistics, a field specialized in analytical rule extraction from natural language data, can aid with building more interpretable protein LMs that are more likely to learn relevant domain-specific rules. Differences between protein sequence data and linguistic sequence data require the integration of more domain-specific knowledge in protein LMs compared with natural language LMs. Here, we provide a linguistics-based roadmap for protein LM pipeline choices with regard to training data, tokenization, token embedding, sequence embedding and model interpretation. Incorporating linguistic ideas into protein LMs enables the development of next-generation interpretable machine learning models with the potential of uncovering the biological mechanisms underlying sequence–function relationships. Language models trained on proteins can help to predict functions from sequences but provide little insight into the underlying mechanisms. Vu and colleagues explain how extracting the underlying rules from a protein language model can make them interpretable and help explain biological mechanisms.},
  archive      = {J_NATMI},
  author       = {Vu, Mai Ha and Akbar, Rahmad and Robert, Philippe A. and Swiatczak, Bartlomiej and Sandve, Geir Kjetil and Greiff, Victor and Haug, Dag Trygve Truslew},
  doi          = {10.1038/s42256-023-00637-1},
  journal      = {Nature Machine Intelligence},
  number       = {5},
  pages        = {485-496},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Linguistically inspired roadmap for building biologically reliable protein language models},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Geometric deep learning of particle motion by MAGIK.
<em>NATMI</em>, <em>5</em>(5), 483–484. (<a
href="https://doi.org/10.1038/s42256-023-00660-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new geometric deep learning method can reconstruct cellular and subcellular trajectories and characterize mobility in microscopic imaging, for a broad range of challenging scenarios.},
  archive      = {J_NATMI},
  author       = {Fatemi, Bahare and Halcrow, Jonathan and Jaqaman, Khuloud},
  doi          = {10.1038/s42256-023-00660-2},
  journal      = {Nature Machine Intelligence},
  number       = {5},
  pages        = {483-484},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Geometric deep learning of particle motion by MAGIK},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ethical hazards of health data governance in the metaverse.
<em>NATMI</em>, <em>5</em>(5), 480–482. (<a
href="https://doi.org/10.1038/s42256-023-00658-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaverse-enabled healthcare is no longer hypothetical. Developers must now contend with ethical, legal and social hazards if they are to overcome the systematic inefficiencies and inequities that exist for patients who seek care in the real world.},
  archive      = {J_NATMI},
  author       = {Kostick-Quenet, Kristin and Rahimzadeh, Vasiliki},
  doi          = {10.1038/s42256-023-00658-w},
  journal      = {Nature Machine Intelligence},
  number       = {5},
  pages        = {480-482},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Ethical hazards of health data governance in the metaverse},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Translating intersectionality to fair machine learning in
health sciences. <em>NATMI</em>, <em>5</em>(5), 476–479. (<a
href="https://doi.org/10.1038/s42256-023-00651-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fairness approaches in machine learning should involve more than an assessment of performance metrics across groups. Shifting the focus away from model metrics, we reframe fairness through the lens of intersectionality, a Black feminist theoretical framework that contextualizes individuals in interacting systems of power and oppression.},
  archive      = {J_NATMI},
  author       = {Lett, Elle and La Cava, William G.},
  doi          = {10.1038/s42256-023-00651-3},
  journal      = {Nature Machine Intelligence},
  number       = {5},
  pages        = {476-479},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Translating intersectionality to fair machine learning in health sciences},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generative AI entails a credit–blame asymmetry.
<em>NATMI</em>, <em>5</em>(5), 472–475. (<a
href="https://doi.org/10.1038/s42256-023-00653-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative AI programs can produce high-quality written and visual content that may be used for good or ill. We argue that a credit–blame asymmetry arises for assigning responsibility for these outputs and discuss urgent ethical and policy implications focused on large-scale language models.},
  archive      = {J_NATMI},
  author       = {Porsdam Mann, Sebastian and Earp, Brian D. and Nyholm, Sven and Danaher, John and Møller, Nikolaj and Bowman-Smart, Hilary and Hatherley, Joshua and Koplin, Julian and Plozza, Monika and Rodger, Daniel and Treit, Peter V. and Renard, Gregory and McMillan, John and Savulescu, Julian},
  doi          = {10.1038/s42256-023-00653-1},
  journal      = {Nature Machine Intelligence},
  number       = {5},
  pages        = {472-475},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Generative AI entails a credit–blame asymmetry},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Don’t pause giant AI for the wrong reasons. <em>NATMI</em>,
<em>5</em>(5), 470–471. (<a
href="https://doi.org/10.1038/s42256-023-00649-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Ienca, Marcello},
  doi          = {10.1038/s42256-023-00649-x},
  journal      = {Nature Machine Intelligence},
  number       = {5},
  pages        = {470-471},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Don’t pause giant AI for the wrong reasons},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Writing the rules in AI-assisted writing. <em>NATMI</em>,
<em>5</em>(5), 469. (<a
href="https://doi.org/10.1038/s42256-023-00678-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As many authors are experimenting with using large language models in writing articles, some guidelines are becoming clear, but these will need to evolve as the capabilities and integration of such tools develop further.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-023-00678-6},
  journal      = {Nature Machine Intelligence},
  number       = {5},
  pages        = {469},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Writing the rules in AI-assisted writing},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning-enabled globally guaranteed evolutionary
computation. <em>NATMI</em>, <em>5</em>(4), 457–467. (<a
href="https://doi.org/10.1038/s42256-023-00642-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary computation, for example, particle swarm optimization, has impressive achievements in solving complex problems in science and industry; however, an important open problem in evolutionary computation is that there is no theoretical guarantee of reaching the global optimum and general reliability; this is due to the lack of a unified representation of diverse problem structures and a generic mechanism by which to avoid local optima. This unresolved challenge impairs trust in the applicability of evolutionary computation to a variety of problems. Here we report an evolutionary computation framework aided by machine learning, named EVOLER, which enables the theoretically guaranteed global optimization of a range of complex non-convex problems. This is achieved by: (1) learning a low-rank representation of a problem with limited samples, which helps to identify an attention subspace; and (2) exploring this small attention subspace via the evolutionary computation method, which helps to reliably avoid local optima. As validated on 20 challenging benchmarks, this method finds the global optimum with a probability approaching 1. We use EVOLER to tackle two important problems: power grid dispatch and the inverse design of nanophotonics devices. The method consistently reached optimal results that were challenging to achieve with previous state-of-the-art methods. EVOLER takes a leap forwards in globally guaranteed evolutionary computation, overcoming the uncertainty of data-driven black-box methods, and offering broad prospects for tackling complex real-world problems. Evolutionary computation methods can find useful solutions for many complex real-world science and engineering problems, but in general there is no guarantee for finding the best solution. This challenge can be tackled with a new framework incorporating machine learning that helps evolutionary methods to avoid local optima.},
  archive      = {J_NATMI},
  author       = {Li, Bin and Wei, Ziping and Wu, Jingjing and Yu, Shuai and Zhang, Tian and Zhu, Chunli and Zheng, Dezhi and Guo, Weisi and Zhao, Chenglin and Zhang, Jun},
  doi          = {10.1038/s42256-023-00642-4},
  journal      = {Nature Machine Intelligence},
  number       = {4},
  pages        = {457-467},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Machine learning-enabled globally guaranteed evolutionary computation},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multitask joint strategies of self-supervised representation
learning on biomedical networks for drug discovery. <em>NATMI</em>,
<em>5</em>(4), 445–456. (<a
href="https://doi.org/10.1038/s42256-023-00640-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised representation learning (SSL) on biomedical networks provides new opportunities for drug discovery; however, effectively combining multiple SSL models is still challenging and has been rarely explored. We therefore propose multitask joint strategies of SSL on biomedical networks for drug discovery, named MSSL2drug. We design six basic SSL tasks that are inspired by the knowledge of various modalities, inlcuding structures, semantics and attributes in heterogeneous biomedical networks. Importantly, fifteen combinations of multiple tasks are evaluated using a graph-attention-based multitask adversarial learning framework in two drug discovery scenarios. The results suggest two important findings: (1) combinations of multimodal tasks achieve better performance than other multitask joint models; (2) the local–global combination models yield higher performance than random two-task combinations when there are the same number of modalities. We thus conjecture that the multimodal and local–global combination strategies can be treated as the guideline of multitask SSL for drug discovery. Biomedical heterogeneous networks offer potentially rich information for computational drug design approaches, but fully labelled multimodal data are rare. To learn useful representations from diverse and unlabelled data, Wang et al. combine multiple self-supervised tasks to train a graph-attention-based model.},
  archive      = {J_NATMI},
  author       = {Wang, Xiaoqi and Cheng, Yingjie and Yang, Yaning and Yu, Yue and Li, Fei and Peng, Shaoliang},
  doi          = {10.1038/s42256-023-00640-6},
  journal      = {Nature Machine Intelligence},
  number       = {4},
  pages        = {445-456},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Multitask joint strategies of self-supervised representation learning on biomedical networks for drug discovery},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Regression transformer enables concurrent sequence
regression and generation for molecular language modelling.
<em>NATMI</em>, <em>5</em>(4), 432–444. (<a
href="https://doi.org/10.1038/s42256-023-00639-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite tremendous progress of generative models in the natural sciences, their controllability remains challenging. One fundamentally missing aspect of molecular or protein generative models is an inductive bias that can reflect continuous properties of interest. To that end, we propose the Regression Transformer (RT), a method that abstracts regression as a conditional sequence modelling problem. This introduces a new direction for multitask language models, seamlessly bridging sequence regression and conditional sequence generation. We demonstrate that, despite using a nominal-scale training objective, the RT matches or surpasses the performance of conventional regression models in property prediction of small molecules, proteins and chemical reactions. Critically, priming the same model with continuous properties yields a competitive conditional generative model that outperforms specialized approaches in a substructure-constrained, property-driven molecule generation benchmark. Our dichotomous approach is facilitated by an alternating training scheme that enables the model to decorate seed sequences on the basis of desired property constraints, for example, to optimize reaction yield. We expect that the RT’s capability to jointly tackle predictive and generative tasks in biochemistry can find applications in property-driven, local exploration of the chemical or protein space. Such multitask approaches will pave the road towards foundation models in materials design. Transformer models are gaining increasing popularity in modelling natural language as they can produce human-sounding text by iteratively predicting the next word in a sentence. Born and Manica apply the idea of Transformer-based text completion to property prediction of chemical compounds by providing the context of a problem and having the model complete the missing information.},
  archive      = {J_NATMI},
  author       = {Born, Jannis and Manica, Matteo},
  doi          = {10.1038/s42256-023-00639-z},
  journal      = {Nature Machine Intelligence},
  number       = {4},
  pages        = {432-444},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Regression transformer enables concurrent sequence regression and generation for molecular language modelling},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimating treatment effects for time-to-treatment
antibiotic stewardship in sepsis. <em>NATMI</em>, <em>5</em>(4),
421–431. (<a href="https://doi.org/10.1038/s42256-023-00638-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sepsis is a life-threatening condition with a high in-hospital mortality rate. The timing of antibiotic administration poses a critical problem for sepsis management. Existing work studying antibiotic timing either ignores the temporality of the observational data or the heterogeneity of the treatment effects. Here we propose a novel method (called T4) to estimate treatment effects for time-to-treatment antibiotic stewardship in sepsis. T4 estimates individual treatment effects by recurrently encoding temporal and static variables as potential confounders, and then decoding the outcomes under different treatment sequences. We propose mini-batch balancing matching that mimics the randomized controlled trial process to adjust the confounding. The model achieves interpretability through a global-level attention mechanism and a variable-level importance examination. Meanwhile, we equip T4 with an uncertainty quantification to help prevent overconfident recommendations. We demonstrate that T4 can identify effective treatment timing with estimated individual treatment effects for antibiotic stewardship on two real-world datasets. Moreover, comprehensive experiments on a synthetic dataset exhibit the outstanding performance of T4 compared with the state-of-the-art models on estimation of individual treatment effect. Sepsis treatment needs to be well timed to be effective and to avoid antibiotic resistance. Machine learning can help to predict optimal treatment timing, but confounders in the data hamper reliability. Liu and colleagues present a method to predict patient-specific treatment effects with increased accuracy, accompanied by an uncertainty estimate.},
  archive      = {J_NATMI},
  author       = {Liu, Ruoqi and Hunold, Katherine M. and Caterino, Jeffrey M. and Zhang, Ping},
  doi          = {10.1038/s42256-023-00638-0},
  journal      = {Nature Machine Intelligence},
  number       = {4},
  pages        = {421-431},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Estimating treatment effects for time-to-treatment antibiotic stewardship in sepsis},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning supported discovery of biomarkers for clinical
prognosis of liver cancer. <em>NATMI</em>, <em>5</em>(4), 408–420. (<a
href="https://doi.org/10.1038/s42256-023-00635-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tissue biomarkers are crucial for cancer diagnosis, prognosis assessment and treatment planning. However, there are few known biomarkers that are robust enough to show true analytical and clinical value. Deep learning (DL)-based computational pathology can be used as a strategy to predict survival, but the limited interpretability and generalizability prevent acceptance in clinical practice. Here we present an interpretable human-centric DL-guided framework called PathFinder (Pathological-biomarker-finder) that can help pathologists to discover new tissue biomarkers from well-performing DL models. By combining sparse multi-class tissue spatial distribution information of whole slide images with attribution methods, PathFinder can achieve localization, characterization and verification of potential biomarkers, while guaranteeing state-of-the-art prognostic performance. Using PathFinder, we discovered that spatial distribution of necrosis in liver cancer, a long-neglected factor, has a strong relationship with patient prognosis. We therefore proposed two clinically independent indicators, including necrosis area fraction and tumour necrosis distribution, for practical prognosis, and verified their potential in clinical prognosis according to criteria derived from the Reporting Recommendations for Tumor Marker Prognostic Studies. Our work demonstrates a successful example of introducing DL into clinical practice in a knowledge discovery way, and the approach may be adopted in identifying biomarkers in various cancer types and modalities. The potential of deep learning in pathological prognosis has been hampered by limited interpretability in clinical applications. Liang and colleagues present a human-centric deep learning framework that supports the discovery of prognostic biomarkers in an interpretable way.},
  archive      = {J_NATMI},
  author       = {Liang, Junhao and Zhang, Weisheng and Yang, Jianghui and Wu, Meilong and Dai, Qionghai and Yin, Hongfang and Xiao, Ying and Kong, Lingjie},
  doi          = {10.1038/s42256-023-00635-3},
  journal      = {Nature Machine Intelligence},
  number       = {4},
  pages        = {408-420},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Deep learning supported discovery of biomarkers for clinical prognosis of liver cancer},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Characterizing the interaction conformation between t-cell
receptors and epitopes with deep learning. <em>NATMI</em>,
<em>5</em>(4), 395–407. (<a
href="https://doi.org/10.1038/s42256-023-00634-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational modelling of the interactions between T-cell receptors (TCRs) and epitopes is of great importance for immunotherapy and antigen discovery. However, current TCR–epitope interaction prediction tools are still in a relatively primitive stage and have limited capacity in deciphering the underlying binding mechanisms, for example, characterizing the pairwise residue interactions between TCRs and epitopes. Here we designed a new deep-learning-based framework for modelling TCR–epitope interactions, called TCR–Epitope Interaction Modelling at Residue Level (TEIM-Res), which took the sequences of TCRs and epitopes as input and predicted both pairwise residue distances and contact sites involved in the interactions. To tackle the current bottleneck of data deficiency, we applied a few-shot learning strategy by incorporating sequence-level binding information into residue-level interaction prediction. The validation experiments and analyses indicated its good prediction performance and the effectiveness of its design. We demonstrated three potential applications: revealing the subtle conformation changes of mutant TCR–epitope pairs, uncovering the key contacts based on epitope-specific TCR pools, and mining the intrinsic binding rules and patterns. In summary, our model can serve as a useful tool for comprehensively characterizing TCR–epitope interactions and understanding the molecular basis of binding mechanisms. Computational modelling of the interactions between T-cell receptors (TCRs) and epitopes is a crucial yet challenging scientific problem. Peng and colleagues develop a deep learning model to capture TCR–epitope binding patterns, providing useful insights for understanding TCR recognition.},
  archive      = {J_NATMI},
  author       = {Peng, Xingang and Lei, Yipin and Feng, Peiyuan and Jia, Lemei and Ma, Jianzhu and Zhao, Dan and Zeng, Jianyang},
  doi          = {10.1038/s42256-023-00634-4},
  journal      = {Nature Machine Intelligence},
  number       = {4},
  pages        = {395-407},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Characterizing the interaction conformation between T-cell receptors and epitopes with deep learning},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Testing the limits of SMILES-based de novo molecular
generation with curriculum and deep reinforcement learning.
<em>NATMI</em>, <em>5</em>(4), 386–394. (<a
href="https://doi.org/10.1038/s42256-023-00636-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning methods have been shown to be potentially powerful tools for de novo design. Recurrent-neural-network-based techniques are the most widely used methods in this space. In this work we examine the behaviour of recurrent-neural-network-based methods when there are few (or no) examples of molecules with the desired properties in the training data. We find that targeted molecular generation is usually possible, but the diversity of generated molecules is often reduced and it is not possible to control the composition of generated molecular sets. To help overcome these issues, we propose a new curriculum-learning-inspired recurrent iterative optimization procedure that enables the optimization of generated molecules for seen and unseen molecular profiles, and allows the user to control whether a molecular profile is explored or exploited. Using our method, we generate specific and diverse sets of molecules with up to 18 times more scaffolds than standard methods for the same sample size; however, our results also point to substantial limitations of one-dimensional molecular representations, as used in this space. We find that the success or failure of a given molecular optimization problem depends on the choice of simplified molecular-input line-entry system (SMILES). Generative models in cheminformatics depend on molecules being representable as structured data, such as the simplified molecular-input line-entry system (SMILES). Mokaya and colleagues investigated how the choice of representation influences the quality of generated compounds, and found that string-based representations can hinder performance in a curriculum learning setting.},
  archive      = {J_NATMI},
  author       = {Mokaya, Maranga and Imrie, Fergus and van Hoorn, Willem P. and Kalisz, Aleksandra and Bradley, Anthony R. and Deane, Charlotte M.},
  doi          = {10.1038/s42256-023-00636-2},
  journal      = {Nature Machine Intelligence},
  number       = {4},
  pages        = {386-394},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Testing the limits of SMILES-based de novo molecular generation with curriculum and deep reinforcement learning},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural-network solutions to stochastic reaction networks.
<em>NATMI</em>, <em>5</em>(4), 376–385. (<a
href="https://doi.org/10.1038/s42256-023-00632-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stochastic reaction network in which chemical species evolve through a set of reactions is widely used to model stochastic processes in physics, chemistry and biology. To characterize the evolving joint probability distribution in the state space of species counts requires solving a system of ordinary differential equations, the chemical master equation, where the size of the counting state space increases exponentially with the type of species. This makes it challenging to investigate the stochastic reaction network. Here we propose a machine learning approach using a variational autoregressive network to solve the chemical master equation. Training the autoregressive network employs the policy gradient algorithm in the reinforcement learning framework, which does not require any data simulated previously by another method. In contrast with simulating single trajectories, this approach tracks the time evolution of the joint probability distribution, and supports direct sampling of configurations and computing their normalized joint probabilities. We apply the approach to representative examples in physics and biology, and demonstrate that it accurately generates the probability distribution over time. The variational autoregressive network exhibits plasticity in representing the multimodal distribution, cooperates with the conservation law, enables time-dependent reaction rates and is efficient for high-dimensional reaction networks, allowing a flexible upper count limit. The results suggest a general approach to study stochastic reaction networks based on modern machine learning. Stochastic reaction networks involve solving a system of ordinary differential equations, which becomes challenging as the number of reactive species grows, but a new approach based on evolving a variational autoregressive neural network provides an efficient way to track time evolution of the joint probability distribution for general reaction networks.},
  archive      = {J_NATMI},
  author       = {Tang, Ying and Weng, Jiayu and Zhang, Pan},
  doi          = {10.1038/s42256-023-00632-6},
  journal      = {Nature Machine Intelligence},
  number       = {4},
  pages        = {376-385},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Neural-network solutions to stochastic reaction networks},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A neuro-vector-symbolic architecture for solving raven’s
progressive matrices. <em>NATMI</em>, <em>5</em>(4), 363–375. (<a
href="https://doi.org/10.1038/s42256-023-00630-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neither deep neural networks nor symbolic artificial intelligence (AI) alone has approached the kind of intelligence expressed in humans. This is mainly because neural networks are not able to decompose joint representations to obtain distinct objects (the so-called binding problem), while symbolic AI suffers from exhaustive rule searches, among other problems. These two problems are still pronounced in neuro-symbolic AI, which aims to combine the best of the two paradigms. Here we show that the two problems can be addressed with our proposed neuro-vector-symbolic architecture (NVSA) by exploiting its powerful operators on high-dimensional distributed representations that serve as a common language between neural networks and symbolic AI. The efficacy of NVSA is demonstrated by solving Raven’s progressive matrices datasets. Compared with state-of-the-art deep neural network and neuro-symbolic approaches, end-to-end training of NVSA achieves a new record of 87.7\% average accuracy in RAVEN, and 88.1\% in I-RAVEN datasets. Moreover, compared with the symbolic reasoning within the neuro-symbolic approaches, the probabilistic reasoning of NVSA with less expensive operations on the distributed representations is two orders of magnitude faster. Neuro-symbolic artificial intelligence approaches display both perception and reasoning capabilities, but inherit the limitations of their individual deep learning and symbolic artificial intelligence components. By combining neural networks and vector-symbolic architectures, Hersche and colleagues propose a neuro-vector-symbolic framework that can solve Raven’s progressive matrices tests faster and more accurately than other state-of-the-art methods.},
  archive      = {J_NATMI},
  author       = {Hersche, Michael and Zeqiri, Mustafa and Benini, Luca and Sebastian, Abu and Rahimi, Abbas},
  doi          = {10.1038/s42256-023-00630-8},
  journal      = {Nature Machine Intelligence},
  number       = {4},
  pages        = {363-375},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A neuro-vector-symbolic architecture for solving raven’s progressive matrices},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multimodal data fusion for cancer biomarker discovery with
deep learning. <em>NATMI</em>, <em>5</em>(4), 351–362. (<a
href="https://doi.org/10.1038/s42256-023-00633-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technological advances have made it possible to study a patient from multiple angles with high-dimensional, high-throughput multiscale biomedical data. In oncology, massive amounts of data are being generated, ranging from molecular, histopathology, radiology to clinical records. The introduction of deep learning has greatly advanced the analysis of biomedical data. However, most approaches focus on single data modalities, leading to slow progress in methods to integrate complementary data types. Development of effective multimodal fusion approaches is becoming increasingly important as a single modality might not be consistent and sufficient to capture the heterogeneity of complex diseases to tailor medical care and improve personalized medicine. Many initiatives now focus on integrating these disparate modalities to unravel the biological processes involved in multifactorial diseases such as cancer. However, many obstacles remain, including lack of usable data as well as methods for clinical validation and interpretation. Here, we cover these current challenges and reflect on opportunities through deep learning to tackle data sparsity and scarcity, multimodal interpretability and standardization of datasets. Cancer diagnosis and treatment decisions often focus on one data source. Steyaert and colleagues discuss the current status and challenges of data fusion, including electronic health records, molecular data, digital pathology and radiographic images, in cancer research and translational development.},
  archive      = {J_NATMI},
  author       = {Steyaert, Sandra and Pizurica, Marija and Nagaraj, Divya and Khandelwal, Priya and Hernandez-Boussard, Tina and Gentles, Andrew J. and Gevaert, Olivier},
  doi          = {10.1038/s42256-023-00633-5},
  journal      = {Nature Machine Intelligence},
  number       = {4},
  pages        = {351-362},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Multimodal data fusion for cancer biomarker discovery with deep learning},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multimodal learning with graphs. <em>NATMI</em>,
<em>5</em>(4), 340–350. (<a
href="https://doi.org/10.1038/s42256-023-00624-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence for graphs has achieved remarkable success in modelling complex systems, ranging from dynamic networks in biology to interacting particle systems in physics. However, the increasingly heterogeneous graph datasets call for multimodal methods that can combine different inductive biases — assumptions that algorithms use to make predictions for inputs they have not encountered during training. Learning on multimodal datasets is challenging because the inductive biases can vary by data modality and graphs might not be explicitly given in the input. To address these challenges, graph artificial intelligence methods combine different modalities while leveraging cross-modal dependencies through geometric relationships. Diverse datasets are combined using graphs and fed into sophisticated multimodal architectures, specified as image-intensive, knowledge-grounded and language-intensive models. Using this categorization, we introduce a blueprint for multimodal graph learning, use it to study existing methods and provide guidelines to design new models. One of the main advances in deep learning in the past five years has been graph representation learning, which enabled applications to problems with underlying geometric relationships. Increasingly, such problems involve multiple data modalities and, examining over 160 studies in this area, Ektefaie et al. propose a general framework for multimodal graph learning for image-intensive, knowledge-grounded and language-intensive problems.},
  archive      = {J_NATMI},
  author       = {Ektefaie, Yasha and Dasoulas, George and Noori, Ayush and Farhat, Maha and Zitnik, Marinka},
  doi          = {10.1038/s42256-023-00624-6},
  journal      = {Nature Machine Intelligence},
  number       = {4},
  pages        = {340-350},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Multimodal learning with graphs},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Meta-learning for t cell receptor binding specificity and
beyond. <em>NATMI</em>, <em>5</em>(4), 337–339. (<a
href="https://doi.org/10.1038/s42256-023-00641-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting whether T cell receptors bind to specific peptides is a challenging problem because most binding examples in the training data involve only a few peptides. A new approach uses meta-learning to improve predictions for binding to peptides for which no or little binding data exists.},
  archive      = {J_NATMI},
  author       = {Wang, Duolin and He, Fei and Yu, Yang and Xu, Dong},
  doi          = {10.1038/s42256-023-00641-5},
  journal      = {Nature Machine Intelligence},
  number       = {4},
  pages        = {337-339},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Meta-learning for t cell receptor binding specificity and beyond},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving image labelling quality. <em>NATMI</em>,
<em>5</em>(4), 335–336. (<a
href="https://doi.org/10.1038/s42256-023-00645-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a continuing demand for high-quality, large-scale annotated datasets in medical imaging supported by machine learning. A new study investigates the importance of what type of instructions crowdsourced annotators receive.},
  archive      = {J_NATMI},
  author       = {Day, Thomas G. and Simpson, John M. and Razavi, Reza and Kainz, Bernhard},
  doi          = {10.1038/s42256-023-00645-1},
  journal      = {Nature Machine Intelligence},
  number       = {4},
  pages        = {335-336},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Improving image labelling quality},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Large language models challenge the future of higher
education. <em>NATMI</em>, <em>5</em>(4), 333–334. (<a
href="https://doi.org/10.1038/s42256-023-00644-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Milano, Silvia and McGrane, Joshua A. and Leonelli, Sabina},
  doi          = {10.1038/s42256-023-00644-2},
  journal      = {Nature Machine Intelligence},
  number       = {4},
  pages        = {333-334},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Large language models challenge the future of higher education},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). What’s the next word in large language models?
<em>NATMI</em>, <em>5</em>(4), 331–332. (<a
href="https://doi.org/10.1038/s42256-023-00655-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are trying to keep up with the torrent of developments and discussions in AI and language models since ChatGPT was unleashed on the world.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-023-00655-z},
  journal      = {Nature Machine Intelligence},
  number       = {4},
  pages        = {331-332},
  shortjournal = {Nat. Mach. Intell.},
  title        = {What’s the next word in large language models?},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A typology for exploring the mitigation of shortcut
behaviour. <em>NATMI</em>, <em>5</em>(3), 319–330. (<a
href="https://doi.org/10.1038/s42256-023-00612-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As machine learning models become larger, and are increasingly trained on large and uncurated datasets in weakly supervised mode, it becomes important to establish mechanisms for inspecting, interacting with and revising models. These are necessary to mitigate shortcut learning effects and to guarantee that the model’s learned knowledge is aligned with human knowledge. Recently, several explanatory interactive machine learning methods have been developed for this purpose, but each has different motivations and methodological details. In this work, we provide a unification of various explanatory interactive machine learning methods into a single typology by establishing a common set of basic modules. We discuss benchmarks and other measures for evaluating the overall abilities of explanatory interactive machine learning methods. With this extensive toolbox, we systematically and quantitatively compare several explanatory interactive machine learning methods. In our evaluations, all methods are shown to improve machine learning models in terms of accuracy and explainability. However, we found remarkable differences in individual benchmark tasks, which reveal valuable application-relevant aspects for the integration of these benchmarks in the development of future methods. Explanatory interactive machine learning methods have been developed to facilitate the learning process between the machine and the user. Friedrich et al. provide a unification of various explanatory interactive machine learning methods into a single typology, and present benchmarks for evaluating such methods.},
  archive      = {J_NATMI},
  author       = {Friedrich, Felix and Stammer, Wolfgang and Schramowski, Patrick and Kersting, Kristian},
  doi          = {10.1038/s42256-023-00612-w},
  journal      = {Nature Machine Intelligence},
  number       = {3},
  pages        = {319-330},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A typology for exploring the mitigation of shortcut behaviour},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-modal pre-training transformer for universal
transfer learning in metal–organic frameworks. <em>NATMI</em>,
<em>5</em>(3), 309–318. (<a
href="https://doi.org/10.1038/s42256-023-00628-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metal–organic frameworks (MOFs) are a class of crystalline porous materials that exhibit a vast chemical space owing to their tunable molecular building blocks with diverse topologies. An unlimited number of MOFs can, in principle, be synthesized. Machine learning approaches can help to explore this vast chemical space by identifying optimal candidates with desired properties from structure–property relationships. Here we introduce MOFTransformer, a multi-modal Transformer encoder pre-trained with 1 million hypothetical MOFs. This multi-modal model utilizes integrated atom-based graph and energy-grid embeddings to capture both local and global features of MOFs, respectively. By fine-tuning the pre-trained model with small datasets ranging from 5,000 to 20,000 MOFs, our model achieves state-of-the-art results for predicting across various properties including gas adsorption, diffusion, electronic properties, and even text-mined data. Beyond its universal transfer learning capabilities, MOFTransformer generates chemical insights by analyzing feature importance through attention scores within the self-attention layers. As such, this model can serve as a platform for other MOF researchers that seek to develop new machine learning models for their work. Metal–organic frameworks are of high interest for a range of energy and environmental applications due to their stable gas storage properties. A new machine learning approach based on a pre-trained multi-modal transformer can be fine-tuned with small datasets to predict structure-property relationships and design new metal-organic frameworks for a range of specific tasks.},
  archive      = {J_NATMI},
  author       = {Kang, Yeonghun and Park, Hyunsoo and Smit, Berend and Kim, Jihan},
  doi          = {10.1038/s42256-023-00628-2},
  journal      = {Nature Machine Intelligence},
  number       = {3},
  pages        = {309-318},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A multi-modal pre-training transformer for universal transfer learning in metal–organic frameworks},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Synthetic data accelerates the development of generalizable
learning-based algorithms for x-ray image analysis. <em>NATMI</em>,
<em>5</em>(3), 294–308. (<a
href="https://doi.org/10.1038/s42256-023-00629-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) now enables automated interpretation of medical images. However, AI’s potential use for interventional image analysis remains largely untapped. This is because the post hoc analysis of data collected during live procedures has fundamental and practical limitations, including ethical considerations, expense, scalability, data integrity and a lack of ground truth. Here we demonstrate that creating realistic simulated images from human models is a viable alternative and complement to large-scale in situ data collection. We show that training AI image analysis models on realistically synthesized data, combined with contemporary domain generalization techniques, results in machine learning models that on real data perform comparably to models trained on a precisely matched real data training set. We find that our model transfer paradigm for X-ray image analysis, which we refer to as SyntheX, can even outperform real-data-trained models due to the effectiveness of training on a larger dataset. SyntheX provides an opportunity to markedly accelerate the conception, design and evaluation of X-ray-based intelligent systems. In addition, SyntheX provides the opportunity to test novel instrumentation, design complementary surgical approaches, and envision novel techniques that improve outcomes, save time or mitigate human error, free from the ethical and practical considerations of live human data collection. Simulated data is an alternative to real data for medical applications where interventional data are needed to train AI-based systems. Gao and colleagues develop a model transfer paradigm to train deep networks on synthetic X-ray data and corresponding labels generated using simulation techniques from CT scans. The approach establishes synthetic data as a viable resource for developing machine learning models that apply to real clinical data.},
  archive      = {J_NATMI},
  author       = {Gao, Cong and Killeen, Benjamin D. and Hu, Yicheng and Grupp, Robert B. and Taylor, Russell H. and Armand, Mehran and Unberath, Mathias},
  doi          = {10.1038/s42256-023-00629-1},
  journal      = {Nature Machine Intelligence},
  number       = {3},
  pages        = {294-308},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Synthetic data accelerates the development of generalizable learning-based algorithms for X-ray image analysis},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predicting metabolomic profiles from microbial composition
through neural ordinary differential equations. <em>NATMI</em>,
<em>5</em>(3), 284–293. (<a
href="https://doi.org/10.1038/s42256-023-00627-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Characterizing the metabolic profile of a microbial community is crucial for understanding its biological function and its impact on the host or environment. Metabolomics experiments directly measuring these profiles are difficult and expensive, whereas sequencing methods quantifying the species composition of microbial communities are well developed and relatively cost-effective. Computational methods that are capable of predicting metabolomic profiles from microbial compositions can save considerable efforts needed for metabolomic profiling experimentally. Yet, despite existing efforts, we still lack a computational method with high prediction power, general applicability and great interpretability. Here we develop a method called metabolomic profile predictor using neural ordinary differential equations (mNODE), based on a state-of-the-art family of deep neural network models. We show compelling evidence that mNODE outperforms existing methods in predicting the metabolomic profiles of human microbiomes and several environmental microbiomes. Moreover, in the case of human gut microbiomes, mNODE can naturally incorporate dietary information to further enhance the prediction of metabolomic profiles. Furthermore, susceptibility analysis of mNODE enables us to reveal microbe–metabolite interactions, which can be validated using both synthetic and real data. The results demonstrate that mNODE is a powerful tool to investigate the microbiome–diet–metabolome relationship, facilitating future research on precision nutrition. Computational models can help predict metabolic profiles of microbial communities such as human gut microbiomes or environmental microbiomes, but they lack generalizability and interpretability. To address this challenge, Wang et al. report a deep learning approach for metabolic profile prediction called mNODE that incorporates a neural network module with hidden layers described by ordinary differential equations.},
  archive      = {J_NATMI},
  author       = {Wang, Tong and Wang, Xu-Wen and Lee-Sarwar, Kathleen A. and Litonjua, Augusto A. and Weiss, Scott T. and Sun, Yizhou and Maslov, Sergei and Liu, Yang-Yu},
  doi          = {10.1038/s42256-023-00627-3},
  journal      = {Nature Machine Intelligence},
  number       = {3},
  pages        = {284-293},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Predicting metabolomic profiles from microbial composition through neural ordinary differential equations},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Labelling instructions matter in biomedical image analysis.
<em>NATMI</em>, <em>5</em>(3), 273–283. (<a
href="https://doi.org/10.1038/s42256-023-00625-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biomedical image analysis algorithm validation depends on high-quality annotation of reference datasets, for which labelling instructions are key. Despite their importance, their optimization remains largely unexplored. Here we present a systematic study of labelling instructions and their impact on annotation quality in the field. Through comprehensive examination of professional practice and international competitions registered at the Medical Image Computing and Computer Assisted Intervention Society, the largest international society in the biomedical imaging field, we uncovered a discrepancy between annotators’ needs for labelling instructions and their current quality and availability. On the basis of an analysis of 14,040 images annotated by 156 annotators from four professional annotation companies and 708 Amazon Mechanical Turk crowdworkers using instructions with different information density levels, we further found that including exemplary images substantially boosts annotation performance compared with text-only descriptions, while solely extending text descriptions does not. Finally, professional annotators constantly outperform Amazon Mechanical Turk crowdworkers. Our study raises awareness for the need of quality standards in biomedical image analysis labelling instructions. High-quality annotation of datasets is critical for machine-learning-based biomedical image analysis. However, a detailed examination of recent image competitions reveals a gap between annotators’ needs and quality of labelling instructions. It is also found that annotator performance can be substantially improved by providing exemplary images.},
  archive      = {J_NATMI},
  author       = {Rädsch, Tim and Reinke, Annika and Weru, Vivienn and Tizabi, Minu D. and Schreck, Nicholas and Kavur, A. Emre and Pekdemir, Bünyamin and Roß, Tobias and Kopp-Schneider, Annette and Maier-Hein, Lena},
  doi          = {10.1038/s42256-023-00625-5},
  journal      = {Nature Machine Intelligence},
  number       = {3},
  pages        = {273-283},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Labelling instructions matter in biomedical image analysis},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stretchable e-skin and transformer enable high-resolution
morphological reconstruction for soft robots. <em>NATMI</em>,
<em>5</em>(3), 261–272. (<a
href="https://doi.org/10.1038/s42256-023-00622-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many robotic tasks require knowledge of the exact 3D robot geometry. However, this remains extremely challenging in soft robotics because of the infinite degrees of freedom of soft bodies deriving from their continuum characteristics. Previous studies have achieved only low proprioceptive geometry resolution (PGR), thus suffering from loss of geometric details (for example, local deformation and surface information) and limited applicability. Here we report an intelligent stretchable capacitive e-skin to endow soft robots with high PGR (3,900) bodily awareness. We demonstrate that the proposed e-skin can finely capture a wide range of complex 3D deformations across the entire soft body through multi-position capacitance measurements. The e-skin signals can be directly translated to high-density point clouds portraying the complete geometry via a deep architecture based on transformer. This high PGR proprioception system providing millimetre-scale, local and global geometry reconstruction (2.322 ± 0.687 mm error on a 20 × 20 × 200 mm soft manipulator) can assist in solving fundamental problems in soft robotics, such as precise closed-loop control and digital twin modelling. Developing proprioception systems for flexible structures such as soft robots is a challenge. Hu et al. report a stretchable e-skin for soft robot proprioception. Combined with deep learning, the e-skin enables high-resolution 3D geometry reconstruction of the soft robot and can be applied in many scenarios, such as human–robot interaction.},
  archive      = {J_NATMI},
  author       = {Hu, Delin and Giorgio-Serchi, Francesco and Zhang, Shiming and Yang, Yunjie},
  doi          = {10.1038/s42256-023-00622-8},
  journal      = {Nature Machine Intelligence},
  number       = {3},
  pages        = {261-272},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Stretchable e-skin and transformer enable high-resolution morphological reconstruction for soft robots},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluation of post-hoc interpretability methods in
time-series classification. <em>NATMI</em>, <em>5</em>(3), 250–260. (<a
href="https://doi.org/10.1038/s42256-023-00620-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Post-hoc interpretability methods are critical tools to explain neural-network results. Several post-hoc methods have emerged in recent years but they produce different results when applied to a given task, raising the question of which method is the most suitable to provide accurate post-hoc interpretability. To understand the performance of each method, quantitative evaluation of interpretability methods is essential; however, currently available frameworks have several drawbacks that hinder the adoption of post-hoc interpretability methods, especially in high-risk sectors. In this work we propose a framework with quantitative metrics to assess the performance of existing post-hoc interpretability methods, particularly in time-series classification. We show that several drawbacks identified in the literature are addressed, namely, the dependence on human judgement, retraining and the shift in the data distribution when occluding samples. We also design a synthetic dataset with known discriminative features and tunable complexity. The proposed methodology and quantitative metrics can be used to understand the reliability of interpretability methods results obtained in practical applications. In turn, they can be embedded within operational workflows in critical fields that require accurate interpretability results for, example, regulatory policies. Various post-hoc interpretability methods exist to evaluate the results of machine learning classification and prediction tasks. To better understand the performance and reliability of such methods, which is particularly necessary in high-risk applications, Turbe et al. have developed a framework for quantitative comparison of post-hoc interpretability approaches in time-series classification.},
  archive      = {J_NATMI},
  author       = {Turbé, Hugues and Bjelogrlic, Mina and Lovis, Christian and Mengaldo, Gianmarco},
  doi          = {10.1038/s42256-023-00620-w},
  journal      = {Nature Machine Intelligence},
  number       = {3},
  pages        = {250-260},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Evaluation of post-hoc interpretability methods in time-series classification},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pan-peptide meta learning for t-cell receptor–antigen
binding recognition. <em>NATMI</em>, <em>5</em>(3), 236–249. (<a
href="https://doi.org/10.1038/s42256-023-00619-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of the mechanisms by which T-cell receptors (TCRs) interact with human antigens provides a crucial opportunity to develop new vaccines, diagnostics and immunotherapies. However, the accurate prediction and recognition of TCR–antigen pairing represents a substantial computational challenge in immunology. Existing tools only learn the binding patterns of antigens from many known TCR binding repertoires and fail to recognize antigens that have never been presented to the immune system or for which only a few TCR binding repertoires are known. However, the binding specificity for neoantigens or exogenous peptides is crucial for immune studies and immunotherapy. Therefore, we developed Pan-Peptide Meta Learning (PanPep), a general and robust framework to recognize TCR–antigen binding, by combining the concepts of meta-learning and the neural Turing machine. The neural Turing machine adds external memory to avoid forgetting previously learned tasks, which is used here to accurately predict TCR binding specificity with any peptide, particularly unseen ones. We applied PanPep to various challenging clinical tasks, including (1) qualitatively measuring the clonal expansion of T cells; (2) efficiently sorting responsive T cells in tumour neoantigen therapy; and (3) accurately identifying immune-responsive TCRs in a large cohort from a COVID-19 study. Our comprehensive tests show that PanPep outperforms existing tools. PanPep also offers interpretability, revealing the nature of peptide and TCR interactions in 3D crystal structures. We believe PanPep can be a useful tool to decipher TCR–antigen interactions and that it has broad clinical applications. Machine learning methods can predict and recognize binding patterns between T-cell receptors and human antigens, but they struggle with antigens for which no or little data exist regarding interactions with the immune system. A new method called PanPep based on meta-learning can learn quickly on new binding prediction tasks and accurately predicts pairing between T-cell receptors and new antigens.},
  archive      = {J_NATMI},
  author       = {Gao, Yicheng and Gao, Yuli and Fan, Yuxiao and Zhu, Chengyu and Wei, Zhiting and Zhou, Chi and Chuai, Guohui and Chen, Qinchang and Zhang, He and Liu, Qi},
  doi          = {10.1038/s42256-023-00619-3},
  journal      = {Nature Machine Intelligence},
  number       = {3},
  pages        = {236-249},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Pan-peptide meta learning for T-cell receptor–antigen binding recognition},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parameter-efficient fine-tuning of large-scale pre-trained
language models. <em>NATMI</em>, <em>5</em>(3), 220–235. (<a
href="https://doi.org/10.1038/s42256-023-00626-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the prevalence of pre-trained language models (PLMs) and the pre-training–fine-tuning paradigm, it has been continuously shown that larger models tend to yield better performance. However, as PLMs scale up, fine-tuning and storing all the parameters is prohibitively costly and eventually becomes practically infeasible. This necessitates a new branch of research focusing on the parameter-efficient adaptation of PLMs, which optimizes a small portion of the model parameters while keeping the rest fixed, drastically cutting down computation and storage costs. In general, it demonstrates that large-scale models could be effectively stimulated by the optimization of a few parameters. Despite the various designs, here we discuss and analyse the approaches under a more consistent and accessible term ‘delta-tuning’, where ‘delta’ a mathematical notation often used to denote changes, is borrowed to refer to the portion of parameters that are ‘changed’ during training. We formally describe the problem and propose a unified categorization criterion for existing delta-tuning methods to explore their correlations and differences. We also discuss the theoretical principles underlying the effectiveness of delta-tuning and interpret them from the perspectives of optimization and optimal control. Furthermore, we provide a holistic empirical study on over 100 natural language processing tasks and investigate various aspects of delta-tuning. With comprehensive study and analysis, our research demonstrates the theoretical and practical properties of delta-tuning in the adaptation of PLMs. Training a deep neural network can be costly but training time is reduced when a pre-trained network can be adapted to different use cases. Ideally, only a small number of parameters needs to be changed in this process of fine-tuning, which can then be more easily distributed. In this Analysis, different methods of fine-tuning with only a small number of parameters are compared on a large set of natural language processing tasks.},
  archive      = {J_NATMI},
  author       = {Ding, Ning and Qin, Yujia and Yang, Guang and Wei, Fuchao and Yang, Zonghan and Su, Yusheng and Hu, Shengding and Chen, Yulin and Chan, Chi-Min and Chen, Weize and Yi, Jing and Zhao, Weilin and Wang, Xiaozhi and Liu, Zhiyuan and Zheng, Hai-Tao and Chen, Jianfei and Liu, Yang and Tang, Jie and Li, Juanzi and Sun, Maosong},
  doi          = {10.1038/s42256-023-00626-4},
  journal      = {Nature Machine Intelligence},
  number       = {3},
  pages        = {220-235},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Parameter-efficient fine-tuning of large-scale pre-trained language models},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Biological research and self-driving labs in deep space
supported by artificial intelligence. <em>NATMI</em>, <em>5</em>(3),
208–219. (<a href="https://doi.org/10.1038/s42256-023-00618-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Space biology research aims to understand fundamental spaceflight effects on organisms, develop foundational knowledge to support deep space exploration and, ultimately, bioengineer spacecraft and habitats to stabilize the ecosystem of plants, crops, microbes, animals and humans for sustained multi-planetary life. To advance these aims, the field leverages experiments, platforms, data and model organisms from both spaceborne and ground-analogue studies. As research is extended beyond low Earth orbit, experiments and platforms must be maximally automated, light, agile and intelligent to accelerate knowledge discovery. Here we present a summary of decadal recommendations from a workshop organized by the National Aeronautics and Space Administration on artificial intelligence, machine learning and modelling applications that offer solutions to these space biology challenges. The integration of artificial intelligence into the field of space biology will deepen the biological understanding of spaceflight effects, facilitate predictive modelling and analytics, support maximally automated and reproducible experiments, and efficiently manage spaceborne data and metadata, ultimately to enable life to thrive in deep space. Deep space exploration missions will require new technologies that can support astronaut health systems, as well as biological monitoring and research systems that can function independently from Earth-based mission control centres. A NASA workshop explored how artificial intelligence advances could help address these challenges and, in this second of two Review articles based on the findings from the workshop, the intersection between artificial intelligence and space biology is discussed.},
  archive      = {J_NATMI},
  author       = {Sanders, Lauren M. and Scott, Ryan T. and Yang, Jason H. and Qutub, Amina Ann and Garcia Martin, Hector and Berrios, Daniel C. and Hastings, Jaden J. A. and Rask, Jon and Mackintosh, Graham and Hoarfrost, Adrienne L. and Chalk, Stuart and Kalantari, John and Khezeli, Kia and Antonsen, Erik L. and Babdor, Joel and Barker, Richard and Baranzini, Sergio E. and Beheshti, Afshin and Delgado-Aparicio, Guillermo M. and Glicksberg, Benjamin S. and Greene, Casey S. and Haendel, Melissa and Hamid, Arif A. and Heller, Philip and Jamieson, Daniel and Jarvis, Katelyn J. and Komarova, Svetlana V. and Komorowski, Matthieu and Kothiyal, Prachi and Mahabal, Ashish and Manor, Uri and Mason, Christopher E. and Matar, Mona and Mias, George I. and Miller, Jack and Myers, Jerry G. and Nelson, Charlotte and Oribello, Jonathan and Park, Seung-min and Parsons-Wingerter, Patricia and Prabhu, R. K. and Reynolds, Robert J. and Saravia-Butler, Amanda and Saria, Suchi and Sawyer, Aenor and Singh, Nitin Kumar and Snyder, Michael and Soboczenski, Frank and Soman, Karthik and Theriot, Corey A. and Van Valen, David and Venkateswaran, Kasthuri and Warren, Liz and Worthey, Liz and Zitnik, Marinka and Costes, Sylvain V.},
  doi          = {10.1038/s42256-023-00618-4},
  journal      = {Nature Machine Intelligence},
  number       = {3},
  pages        = {208-219},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Biological research and self-driving labs in deep space supported by artificial intelligence},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Biomonitoring and precision health in deep space supported
by artificial intelligence. <em>NATMI</em>, <em>5</em>(3), 196–207. (<a
href="https://doi.org/10.1038/s42256-023-00617-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human exploration of deep space will involve missions of substantial distance and duration. To effectively mitigate health hazards, paradigm shifts in astronaut health systems are necessary to enable Earth-independent healthcare, rather than Earth-reliant. Here we present a summary of decadal recommendations from a workshop organized by NASA on artificial intelligence, machine learning and modelling applications that offer key solutions toward these space health challenges. The workshop recommended various biomonitoring approaches, biomarker science, spacecraft/habitat hardware, intelligent software and streamlined data management tools in need of development and integration to enable humanity to thrive in deep space. Participants recommended that these components culminate in a maximally automated, autonomous and intelligent Precision Space Health system, to monitor, aggregate and assess biomedical statuses. Deep-space exploration missions require new technologies that can support astronaut health systems as well as biological monitoring and research systems that can function independently from Earth-based mission control centres. A NASA workshop explored how artificial intelligence advances could help address these challenges and, in this first of two Review articles based on the findings from the workshop, a vision for autonomous biomonitoring and precision space health is discussed.},
  archive      = {J_NATMI},
  author       = {Scott, Ryan T. and Sanders, Lauren M. and Antonsen, Erik L. and Hastings, Jaden J. A. and Park, Seung-min and Mackintosh, Graham and Reynolds, Robert J. and Hoarfrost, Adrienne L. and Sawyer, Aenor and Greene, Casey S. and Glicksberg, Benjamin S. and Theriot, Corey A. and Berrios, Daniel C. and Miller, Jack and Babdor, Joel and Barker, Richard and Baranzini, Sergio E. and Beheshti, Afshin and Chalk, Stuart and Delgado-Aparicio, Guillermo M. and Haendel, Melissa and Hamid, Arif A. and Heller, Philip and Jamieson, Daniel and Jarvis, Katelyn J. and Kalantari, John and Khezeli, Kia and Komarova, Svetlana V. and Komorowski, Matthieu and Kothiyal, Prachi and Mahabal, Ashish and Manor, Uri and Garcia Martin, Hector and Mason, Christopher E. and Matar, Mona and Mias, George I. and Myers, Jerry G. and Nelson, Charlotte and Oribello, Jonathan and Parsons-Wingerter, Patricia and Prabhu, R. K. and Qutub, Amina Ann and Rask, Jon and Saravia-Butler, Amanda and Saria, Suchi and Singh, Nitin Kumar and Snyder, Michael and Soboczenski, Frank and Soman, Karthik and Van Valen, David and Venkateswaran, Kasthuri and Warren, Liz and Worthey, Liz and Yang, Jason H. and Zitnik, Marinka and Costes, Sylvain V.},
  doi          = {10.1038/s42256-023-00617-5},
  journal      = {Nature Machine Intelligence},
  number       = {3},
  pages        = {196-207},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Biomonitoring and precision health in deep space supported by artificial intelligence},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Introducing contextual transparency for automated decision
systems. <em>NATMI</em>, <em>5</em>(3), 187–195. (<a
href="https://doi.org/10.1038/s42256-023-00623-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As automated decision systems (ADS) get more deeply embedded into business processes worldwide, there is a growing need for practical ways to establish meaningful transparency. Here we argue that universally perfect transparency is impossible to achieve. We introduce the concept of contextual transparency as an approach that integrates social science, engineering and information design to help improve ADS transparency for specific professions, business processes and stakeholder groups. We demonstrate the applicability of the contextual transparency approach by using it for a well-established ADS transparency tool: nutritional labels that display specific information about an ADS. Empirically, it focuses on the profession of recruiting. Presenting data from an ongoing study about ADS use in recruiting alongside a typology of ADS nutritional labels, we suggest a nutritional label prototype for ADS-driven rankers such as LinkedIn Recruiter before closing with directions for future work. An increasing number of regulations demand transparency in automated decision-making processes such as in automated online recruitment. To provide meaningful transparency, Sloane et al. propose the use of ‘nutritional’ labels that display specific information about an automated decision system, depending on the context.},
  archive      = {J_NATMI},
  author       = {Sloane, Mona and Solano-Kamaiko, Ian René and Yuan, Jun and Dasgupta, Aritra and Stoyanovich, Julia},
  doi          = {10.1038/s42256-023-00623-7},
  journal      = {Nature Machine Intelligence},
  number       = {3},
  pages        = {187-195},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Introducing contextual transparency for automated decision systems},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A global south perspective for ethical algorithms and the
state. <em>NATMI</em>, <em>5</em>(3), 184–186. (<a
href="https://doi.org/10.1038/s42256-023-00621-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore the intersection between algorithms and the State from the perspectives of legislative action, public perception and the use of AI in public administration. Taking India as a case study, we discuss the potential fallout from the absence of rigorous scholarship on such questions for countries in the Global South.},
  archive      = {J_NATMI},
  author       = {Sengupta, Nandana and Subramanian, Vidya and Mukhopadhyay, Anwesh and Scaria, Arul George},
  doi          = {10.1038/s42256-023-00621-9},
  journal      = {Nature Machine Intelligence},
  number       = {3},
  pages        = {184-186},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A global south perspective for ethical algorithms and the state},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Space missions out of this world with AI. <em>NATMI</em>,
<em>5</em>(3), 183. (<a
href="https://doi.org/10.1038/s42256-023-00643-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the next phase of space exploration, human crews will be sent on missions beyond the low Earth orbit. Artificial intelligence (AI) is expected to play a main role in autonomous biomonitoring, research and Earth-independent healthcare.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-023-00643-3},
  journal      = {Nature Machine Intelligence},
  number       = {3},
  pages        = {183},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Space missions out of this world with AI},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A challenge for rounded evaluation of recommender systems.
<em>NATMI</em>, <em>5</em>(2), 181–182. (<a
href="https://doi.org/10.1038/s42256-022-00606-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The organizers of the EvalRS recommender systems competition argue that accuracy should not be the only goal and explain how they took robustness and fairness into account.},
  archive      = {J_NATMI},
  author       = {Tagliabue, Jacopo and Bianchi, Federico and Schnabel, Tobias and Attanasio, Giuseppe and Greco, Ciro and de Souza Moreira, Gabriel and Chia, Patrick John},
  doi          = {10.1038/s42256-022-00606-0},
  journal      = {Nature Machine Intelligence},
  number       = {2},
  pages        = {181-182},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A challenge for rounded evaluation of recommender systems},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mixed-modality speech recognition and interaction using a
wearable artificial throat. <em>NATMI</em>, <em>5</em>(2), 169–180. (<a
href="https://doi.org/10.1038/s42256-023-00616-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers have recently been pursuing technologies for universal speech recognition and interaction that can work well with subtle sounds or noisy environments. Multichannel acoustic sensors can improve the accuracy of recognition of sound but lead to large devices that cannot be worn. To solve this problem, we propose a graphene-based intelligent, wearable artificial throat (AT) that is sensitive to human speech and vocalization-related motions. Its perception of the mixed modalities of acoustic signals and mechanical motions enables the AT to acquire signals with a low fundamental frequency while remaining noise resistant. The experimental results showed that the mixed-modality AT can detect basic speech elements (phonemes, tones and words) with an average accuracy of 99.05\%. We further demonstrated its interactive applications for speech recognition and voice reproduction for the vocally disabled. It was able to recognize everyday words vaguely spoken by a patient with laryngectomy with an accuracy of over 90\% through an ensemble AI model. The recognized content was synthesized into speech and played on the AT to rehabilitate the capability of the patient for vocalization. Its feasible fabrication process, stable performance, resistance to noise and integrated vocalization make the AT a promising tool for next-generation speech recognition and interaction systems. The mechanical signals of the laryngeal vocal organ have not been well utilized by human speech processing technology. The authors develop a prototype of a wearable artificial throat that can sense speech- and vocalization-related actions. The results suggest a new technological pathway for speech recognition and interaction systems.},
  archive      = {J_NATMI},
  author       = {Yang, Qisheng and Jin, Weiqiu and Zhang, Qihang and Wei, Yuhong and Guo, Zhanfeng and Li, Xiaoshi and Yang, Yi and Luo, Qingquan and Tian, He and Ren, Tian-Ling},
  doi          = {10.1038/s42256-023-00616-6},
  journal      = {Nature Machine Intelligence},
  number       = {2},
  pages        = {169-180},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Mixed-modality speech recognition and interaction using a wearable artificial throat},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimating categorical counterfactuals via deep twin
networks. <em>NATMI</em>, <em>5</em>(2), 159–168. (<a
href="https://doi.org/10.1038/s42256-023-00611-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Counterfactual inference is a powerful tool, capable of solving challenging problems in high-profile sectors. To perform counterfactual inference, we require knowledge of the underlying causal mechanisms. However, causal mechanisms cannot be uniquely determined from observations and interventions alone. This raises the question of how to choose the causal mechanisms so that the resulting counterfactual inference is trustworthy in a given domain. This question has been addressed in causal models with binary variables, but for the case of categorical variables, it remains unanswered. We address this challenge by introducing for causal models with categorical variables the notion of counterfactual ordering, a principle positing desirable properties that causal mechanisms should possess and prove that it is equivalent to specific functional constraints on the causal mechanisms. To learn causal mechanisms satisfying these constraints, and perform counterfactual inference with them, we introduce deep twin networks. These are deep neural networks that, when trained, are capable of twin network counterfactual inference—an alternative to the abduction–action–prediction method. We empirically test our approach on diverse real-world and semisynthetic data from medicine, epidemiology and finance, reporting accurate estimation of counterfactual probabilities while demonstrating the issues that arise with counterfactual reasoning when counterfactual ordering is not enforced When learning a causal model from data, deriving counterfactual examples from the model can help to evaluate how plausible the mechanisms are and create hypotheses that can be tested with new data. Vlontzos and colleagues develop a deep learning-based method for answering counterfactual queries that can deal with categorical variables, rather than only binary ones, using the notion of ‘counterfactual ordering’.},
  archive      = {J_NATMI},
  author       = {Vlontzos, Athanasios and Kainz, Bernhard and Gilligan-Lee, Ciarán M.},
  doi          = {10.1038/s42256-023-00611-x},
  journal      = {Nature Machine Intelligence},
  number       = {2},
  pages        = {159-168},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Estimating categorical counterfactuals via deep twin networks},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continuous improvement of self-driving cars using dynamic
confidence-aware reinforcement learning. <em>NATMI</em>, <em>5</em>(2),
145–158. (<a href="https://doi.org/10.1038/s42256-023-00610-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today’s self-driving vehicles have achieved impressive driving capabilities, but still suffer from uncertain performance in long-tail cases. Training a reinforcement-learning-based self-driving algorithm with more data does not always lead to better performance, which is a safety concern. Here we present a dynamic confidence-aware reinforcement learning (DCARL) technology for guaranteed continuous improvement. Continuously improving means that more training always improves or maintains its current performance. Our technique enables performance improvement using the data collected during driving, and does not need a lengthy pre-training phase. We evaluate the proposed technology both using simulations and on an experimental vehicle. The results show that the proposed DCARL method enables continuous improvement in various cases, and, in the meantime, matches or outperforms the default self-driving policy at any stage. This technology was demonstrated and evaluated on the vehicle at the 2022 Beijing Winter Olympic Games. Reinforcement learning is a powerful technique to learn complex behaviours, but in the context of self-driving vehicles it might result in unsafe behaviour in previously unseen situations. Cao et al. create a confidence-aware method that improves through reinforcement learning but reverts to safe behaviour when a situation is new.},
  archive      = {J_NATMI},
  author       = {Cao, Zhong and Jiang, Kun and Zhou, Weitao and Xu, Shaobing and Peng, Huei and Yang, Diange},
  doi          = {10.1038/s42256-023-00610-y},
  journal      = {Nature Machine Intelligence},
  number       = {2},
  pages        = {145-158},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Continuous improvement of self-driving cars using dynamic confidence-aware reinforcement learning},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An ethical trajectory planning algorithm for autonomous
vehicles. <em>NATMI</em>, <em>5</em>(2), 137–144. (<a
href="https://doi.org/10.1038/s42256-022-00607-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of artificial intelligence and automation, moral decisions that were formerly the preserve of humans are being put into the hands of algorithms. In autonomous driving, a variety of such decisions with ethical implications are made by algorithms for behaviour and trajectory planning. Therefore, here we present an ethical trajectory planning algorithm with a framework that aims at a fair distribution of risk among road users. Our implementation incorporates a combination of five ethical principles: minimization of the overall risk, priority for the worst-off, equal treatment of people, responsibility and maximum acceptable risk. To the best of our knowledge, this is the first ethical algorithm for trajectory planning of autonomous vehicles in line with the 20 recommendations from the European Union Commission expert group and with general applicability to various traffic situations. We showcase the ethical behaviour of our algorithm in selected scenarios and provide an empirical analysis of the ethical principles in 2,000 scenarios. The code used in this research is available as open-source software. In situations where some risk of injury is unavoidable for self-driving vehicles, how risk is distributed becomes an ethical question. Geisslinger and colleagues have developed a planning algorithm that takes five ethical principles into account and aims to comply with the emerging EU regulatory recommendations.},
  archive      = {J_NATMI},
  author       = {Geisslinger, Maximilian and Poszler, Franziska and Lienkamp, Markus},
  doi          = {10.1038/s42256-022-00607-z},
  journal      = {Nature Machine Intelligence},
  number       = {2},
  pages        = {137-144},
  shortjournal = {Nat. Mach. Intell.},
  title        = {An ethical trajectory planning algorithm for autonomous vehicles},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpretable bilinear attention network with domain
adaptation improves drug–target prediction. <em>NATMI</em>,
<em>5</em>(2), 126–136. (<a
href="https://doi.org/10.1038/s42256-022-00605-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting drug–target interaction is key for drug discovery. Recent deep learning-based methods show promising performance, but two challenges remain: how to explicitly model and learn local interactions between drugs and targets for better prediction and interpretation and how to optimize generalization performance of predictions on novel drug–target pairs. Here, we present DrugBAN, a deep bilinear attention network (BAN) framework with domain adaptation to explicitly learn pairwise local interactions between drugs and targets, and adapt in response to out-of-distribution data. DrugBAN works on drug molecular graphs and target protein sequences to perform prediction, with conditional domain adversarial learning to align learned interaction representations across different distributions for better generalization on novel drug–target pairs. Experiments on three benchmark datasets under both in-domain and cross-domain settings show that DrugBAN achieves the best overall performance against five state-of-the-art baseline models. Moreover, visualizing the learned bilinear attention map provides interpretable insights from prediction results. Predicting drug–target interaction with computational models has attracted a lot of attention, but it is a difficult problem to generalize across domains to out-of-distribution data. Bai et al. present here a method that aims to model local interactions of proteins and drug molecules while being interpretable and provide cross-domain generalization.},
  archive      = {J_NATMI},
  author       = {Bai, Peizhen and Miljković, Filip and John, Bino and Lu, Haiping},
  doi          = {10.1038/s42256-022-00605-1},
  journal      = {Nature Machine Intelligence},
  number       = {2},
  pages        = {126-136},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Interpretable bilinear attention network with domain adaptation improves drug–target prediction},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predicting the prevalence of complex genetic diseases from
individual genotype profiles using capsule networks. <em>NATMI</em>,
<em>5</em>(2), 114–125. (<a
href="https://doi.org/10.1038/s42256-022-00604-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diseases that have a complex genetic architecture tend to suffer from considerable amounts of genetic variants that, although playing a role in the disease, have not yet been revealed as such. Two major causes for this phenomenon are genetic variants that do not stack up effects, but interact in complex ways; in addition, as recently suggested, the omnigenic model postulates that variants interact in a holistic manner to establish disease phenotypes. Here we present DiseaseCapsule, as a capsule-network-based approach that explicitly addresses to capture the hierarchical structure of the underlying genome data, and has the potential to fully capture the non-linear relationships between variants and disease. DiseaseCapsule is the first such approach to operate in a whole-genome manner when predicting disease occurrence from individual genotype profiles. In experiments, we evaluated DiseaseCapsule on amyotrophic lateral sclerosis (ALS) and Parkinson’s disease, with a particular emphasis on ALS, which is known to have a complex genetic architecture and is affected by 40\% missing heritability. On ALS, DiseaseCapsule achieves 86.9\% accuracy on hold-out test data in predicting disease occurrence, thereby outperforming all other approaches by large margins. Also, DiseaseCapsule required sufficiently less training data for reaching optimal performance. Last but not least, the systematic exploitation of the network architecture yielded 922 genes of particular interest, and 644 ‘non-additive’ genes that are crucial factors in DiseaseCapsule, but remain masked within linear schemes. Disease phenotypes can be predicted from genetic profiles, but diseases with complex, non-additive interactions between genes are hard to disentangle. An approach called DiseaseCapsule makes use of capsule networks to identify the hierarchical structure in genomic data and can predict complex diseases such as amyotrophic lateral sclerosis with high accuracy.},
  archive      = {J_NATMI},
  author       = {Luo, Xiao and Kang, Xiongbin and Schönhuth, Alexander},
  doi          = {10.1038/s42256-022-00604-2},
  journal      = {Nature Machine Intelligence},
  number       = {2},
  pages        = {114-125},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Predicting the prevalence of complex genetic diseases from individual genotype profiles using capsule networks},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Echo state graph neural networks with analogue random
resistive memory arrays. <em>NATMI</em>, <em>5</em>(2), 104–113. (<a
href="https://doi.org/10.1038/s42256-023-00609-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed a surge of interest in learning representations of graph-structured data, with applications from social networks to drug discovery. However, graph neural networks, the machine learning models for handling graph-structured data, face significant challenges when running on conventional digital hardware, including the slowdown of Moore’s law due to transistor scaling limits and the von Neumann bottleneck incurred by physically separated memory and processing units, as well as a high training cost. Here we present a hardware–software co-design to address these challenges, by designing an echo state graph neural network based on random resistive memory arrays, which are built from low-cost, nanoscale and stackable resistors for efficient in-memory computing. This approach leverages the intrinsic stochasticity of dielectric breakdown in resistive switching to implement random projections in hardware for an echo state network that effectively minimizes the training complexity thanks to its fixed and random weights. The system demonstrates state-of-the-art performance on both graph classification using the MUTAG and COLLAB datasets and node classification using the CORA dataset, achieving 2.16×, 35.42× and 40.37× improvements in energy efficiency for a projected random resistive memory-based hybrid analogue–digital system over a state-of-the-art graphics processing unit and 99.35\%, 99.99\% and 91.40\% reductions of backward pass complexity compared with conventional graph learning. The results point to a promising direction for next-generation artificial intelligence systems for graph learning. Co-designing hardware platforms and neural network software can help improve the computational efficiency and training affordability of deep learning implementations. A new approach designed for graph learning with echo state neural networks makes use of in-memory computing with resistive memory and shows up to a 35 times improvement in the energy efficiency and 99\% reduction in training cost for graph classification on large datasets.},
  archive      = {J_NATMI},
  author       = {Wang, Shaocong and Li, Yi and Wang, Dingchen and Zhang, Woyu and Chen, Xi and Dong, Danian and Wang, Songqi and Zhang, Xumeng and Lin, Peng and Gallicchio, Claudio and Xu, Xiaoxin and Liu, Qi and Cheng, Kwang-Ting and Wang, Zhongrui and Shang, Dashan and Liu, Ming},
  doi          = {10.1038/s42256-023-00609-5},
  journal      = {Nature Machine Intelligence},
  number       = {2},
  pages        = {104-113},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Echo state graph neural networks with analogue random resistive memory arrays},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Crowdsourcing to predict RNA degradation and secondary
structure. <em>NATMI</em>, <em>5</em>(2), 101–103. (<a
href="https://doi.org/10.1038/s42256-023-00615-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting RNA degradation is a fundamental task in designing RNA-based therapeutic agents. Dual crowdsourcing efforts for dataset creation and machine learning were organized to learn biological rules and strategies for predicting RNA stability.},
  archive      = {J_NATMI},
  author       = {Hendrix, David A.},
  doi          = {10.1038/s42256-023-00615-7},
  journal      = {Nature Machine Intelligence},
  number       = {2},
  pages        = {101-103},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Crowdsourcing to predict RNA degradation and secondary structure},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Medical artificial intelligence is as much social as it is
technological. <em>NATMI</em>, <em>5</em>(2), 98–100. (<a
href="https://doi.org/10.1038/s42256-022-00603-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the promise of medical artificial intelligence applications, their acceptance in real-world clinical settings is low, with lack of transparency and trust being barriers that need to be overcome. We discuss the importance of the collaborative process in medical artificial intelligence, whereby experts from various fields work together and tackle transparency issues and build trust over time.},
  archive      = {J_NATMI},
  author       = {Carusi, Annamaria and Winter, Peter D. and Armstrong, Iain and Ciravegna, Fabio and Kiely, David G. and Lawrie, Allan and Lu, Haiping and Sabroe, Ian and Swift, Andy},
  doi          = {10.1038/s42256-022-00603-3},
  journal      = {Nature Machine Intelligence},
  number       = {2},
  pages        = {98-100},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Medical artificial intelligence is as much social as it is technological},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An extension to the FDA approval process is needed to
achieve AI equity. <em>NATMI</em>, <em>5</em>(2), 96–97. (<a
href="https://doi.org/10.1038/s42256-023-00614-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Hammond, Alessandro and Jain, Bhav and Celi, Leo Anthony and Stanford, Fatima Cody},
  doi          = {10.1038/s42256-023-00614-8},
  journal      = {Nature Machine Intelligence},
  number       = {2},
  pages        = {96-97},
  shortjournal = {Nat. Mach. Intell.},
  title        = {An extension to the FDA approval process is needed to achieve AI equity},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Algorithmic recommendations, anyone? <em>NATMI</em>,
<em>5</em>(2), 95. (<a
href="https://doi.org/10.1038/s42256-023-00631-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A recent data competition steers clear from leaderboard chasing and promotes the use of a diverse range of metrics to develop rounded, practical algorithms.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-023-00631-7},
  journal      = {Nature Machine Intelligence},
  number       = {2},
  pages        = {95},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Algorithmic recommendations, anyone?},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Publisher correction: Advancing ethics review practices in
AI research. <em>NATMI</em>, <em>5</em>(1), 94. (<a
href="https://doi.org/10.1038/s42256-023-00608-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Srikumar, Madhulika and Finlay, Rebecca and Abuhamad, Grace and Ashurst, Carolyn and Campbell, Rosie and Campbell-Ratcliffe, Emily and Hongo, Hudson and Jordan, Sara R. and Lindley, Joseph and Ovadya, Aviv and Pineau, Joelle},
  doi          = {10.1038/s42256-023-00608-6},
  journal      = {Nature Machine Intelligence},
  number       = {1},
  pages        = {94},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Publisher correction: Advancing ethics review practices in AI research},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Phy-q as a measure for physical reasoning intelligence.
<em>NATMI</em>, <em>5</em>(1), 83–93. (<a
href="https://doi.org/10.1038/s42256-022-00583-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans are well versed in reasoning about the behaviours of physical objects and choosing actions accordingly to accomplish tasks, while this remains a major challenge for artificial intelligence. To facilitate research addressing this problem, we propose a new testbed that requires an agent to reason about physical scenarios and take an action appropriately. Inspired by the physical knowledge acquired in infancy and the capabilities required for robots to operate in real-world environments, we identify 15 essential physical scenarios. We create a wide variety of distinct task templates, and we ensure that all the task templates within the same scenario can be solved by using one specific strategic physical rule. By having such a design, we evaluate two distinct levels of generalization, namely local generalization and broad generalization. We conduct an extensive evaluation with human players, learning agents with various input types and architectures, and heuristic agents with different strategies. Inspired by how the human intelligence quotient is calculated, we define the physical reasoning quotient (Phy-Q score) that reflects the physical reasoning intelligence of an agent using the physical scenarios we considered. Our evaluation shows that (1) all the agents are far below human performance, and (2) learning agents, even with good local generalization ability, struggle to learn the underlying physical reasoning rules and fail to generalize broadly. We encourage the development of intelligent agents that can reach the human-level Phy-Q score. When it comes to reasoning about the motion of physical objects, humans have natural intuitive physics knowledge. To test how good artificial learning agents are in similar predictive abilities, Xue and colleagues present a benchmark based on a two-dimensional physics environment in which 15 physical reasoning skills are measured.},
  archive      = {J_NATMI},
  author       = {Xue, Cheng and Pinto, Vimukthini and Gamage, Chathura and Nikonova, Ekaterina and Zhang, Peng and Renz, Jochen},
  doi          = {10.1038/s42256-022-00583-4},
  journal      = {Nature Machine Intelligence},
  number       = {1},
  pages        = {83-93},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Phy-Q as a measure for physical reasoning intelligence},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Geometric deep learning reveals the spatiotemporal features
of microscopic motion. <em>NATMI</em>, <em>5</em>(1), 71–82. (<a
href="https://doi.org/10.1038/s42256-022-00595-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The characterization of dynamical processes in living systems provides important clues for their mechanistic interpretation and link to biological functions. Owing to recent advances in microscopy techniques, it is now possible to routinely record the motion of cells, organelles and individual molecules at multiple spatiotemporal scales in physiological conditions. However, the automated analysis of dynamics occurring in crowded and complex environments still lags behind the acquisition of microscopic image sequences. Here we present a framework based on geometric deep learning that achieves the accurate estimation of dynamical properties in various biologically relevant scenarios. This deep-learning approach relies on a graph neural network enhanced by attention-based components. By processing object features with geometric priors, the network is capable of performing multiple tasks, from linking coordinates into trajectories to inferring local and global dynamic properties. We demonstrate the flexibility and reliability of this approach by applying it to real and simulated data corresponding to a broad range of biological experiments. Despite recent improvements in microscopy acquisition methods, extracting quantitative information from biological experiments in crowded conditions is a challenging task. Pineda and colleagues propose a geometric deep-learning-based framework for automated trajectory linking and dynamical property estimation that is able to effectively deal with complex biological scenarios.},
  archive      = {J_NATMI},
  author       = {Pineda, Jesús and Midtvedt, Benjamin and Bachimanchi, Harshith and Noé, Sergio and Midtvedt, Daniel and Volpe, Giovanni and Manzo, Carlo},
  doi          = {10.1038/s42256-022-00595-0},
  journal      = {Nature Machine Intelligence},
  number       = {1},
  pages        = {71-82},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Geometric deep learning reveals the spatiotemporal features of microscopic motion},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Emergent behaviour and neural dynamics in artificial agents
tracking odour plumes. <em>NATMI</em>, <em>5</em>(1), 58–70. (<a
href="https://doi.org/10.1038/s42256-022-00599-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tracking an odour plume to locate its source under variable wind and plume statistics is a complex task. Flying insects routinely accomplish such tracking, often over long distances, in pursuit of food or mates. Several aspects of this remarkable behaviour and its underlying neural circuitry have been studied experimentally. Here we take a complementary in silico approach to develop an integrated understanding of their behaviour and neural computations. Specifically, we train artificial recurrent neural network agents using deep reinforcement learning to locate the source of simulated odour plumes that mimic features of plumes in a turbulent flow. Interestingly, the agents’ emergent behaviours resemble those of flying insects, and the recurrent neural networks learn to compute task-relevant variables with distinct dynamic structures in population activity. Our analyses put forward a testable behavioural hypothesis for tracking plumes in changing wind direction, and we provide key intuitions for memory requirements and neural dynamics in odour plume tracking. Olfactory navigation is a well-studied topic in insect behaviour, but many aspects of the challenging task of odour plume tracking are unknown. In a deep reinforcement learning approach, artificial agents are trained to produce (in silico) trajectories to localize the source of an odour plume, showing dynamics that mimic real insect behaviours.},
  archive      = {J_NATMI},
  author       = {Singh, Satpreet H. and van Breugel, Floris and Rao, Rajesh P. N. and Brunton, Bingni W.},
  doi          = {10.1038/s42256-022-00599-w},
  journal      = {Nature Machine Intelligence},
  number       = {1},
  pages        = {58-70},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Emergent behaviour and neural dynamics in artificial agents tracking odour plumes},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human–AI collaboration enables more empathic conversations
in text-based peer-to-peer mental health support. <em>NATMI</em>,
<em>5</em>(1), 46–57. (<a
href="https://doi.org/10.1038/s42256-022-00593-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in artificial intelligence (AI) are enabling systems that augment and collaborate with humans to perform simple, mechanistic tasks such as scheduling meetings and grammar-checking text. However, such human–AI collaboration poses challenges for more complex tasks, such as carrying out empathic conversations, due to the difficulties that AI systems face in navigating complex human emotions and the open-ended nature of these tasks. Here we focus on peer-to-peer mental health support, a setting in which empathy is critical for success, and examine how AI can collaborate with humans to facilitate peer empathy during textual, online supportive conversations. We develop HAILEY, an AI-in-the-loop agent that provides just-in-time feedback to help participants who provide support (peer supporters) respond more empathically to those seeking help (support seekers). We evaluate HAILEY in a non-clinical randomized controlled trial with real-world peer supporters on TalkLife (N = 300), a large online peer-to-peer support platform. We show that our human–AI collaboration approach leads to a 19.6\% increase in conversational empathy between peers overall. Furthermore, we find a larger, 38.9\% increase in empathy within the subsample of peer supporters who self-identify as experiencing difficulty providing support. We systematically analyse the human–AI collaboration patterns and find that peer supporters are able to use the AI feedback both directly and indirectly without becoming overly reliant on AI while reporting improved self-efficacy post-feedback. Our findings demonstrate the potential of feedback-driven, AI-in-the-loop writing systems to empower humans in open-ended, social and high-stakes tasks such as empathic conversations. AI language modelling and generation approaches have developed fast in the last decade, opening promising new directions in human–AI collaboration. An AI-in-the loop conversational system called HAILEY is developed to empower peer supporters in providing empathic responses to mental health support seekers.},
  archive      = {J_NATMI},
  author       = {Sharma, Ashish and Lin, Inna W. and Miner, Adam S. and Atkins, David C. and Althoff, Tim},
  doi          = {10.1038/s42256-022-00593-2},
  journal      = {Nature Machine Intelligence},
  number       = {1},
  pages        = {46-57},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Human–AI collaboration enables more empathic conversations in text-based peer-to-peer mental health support},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning based on parameterized physical forward model
for adaptive holographic imaging with unpaired data. <em>NATMI</em>,
<em>5</em>(1), 35–45. (<a
href="https://doi.org/10.1038/s42256-022-00584-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Holographic imaging poses the ill posed inverse mapping problem of retrieving complex amplitude maps from measured diffraction intensity patterns. The existing deep learning methods for holographic imaging often depend solely on the statistical relation between the given data distributions, compromising their reliability in practical imaging configurations where physical perturbations exist in various forms, such as mechanical movement and optical fluctuation. Here, we present a deep learning method based on a parameterized physical forward model that reconstructs both the complex amplitude and the range of objects under highly perturbative configurations where the object-to-sensor distance is set beyond the range of given training data. To prove reliability in practical biomedical applications, we demonstrate holographic imaging of red blood cells flowing in a cluster and diverse types of tissue section presented without any ground truth data. Our results suggest that the proposed approach permits the adaptability of deep learning methods to deterministic perturbations, and therefore extends their applicability to a wide range of inverse problems in imaging. The reconstruction of spatially resolved information of an extended object from an observed intensity diffraction pattern in holographic imaging is a challenging problem. By incorporating an explicit physical model, Lee and colleagues propose a deep learning method that can be used in holographic image reconstruction under physical perturbations and which generalizes well beyond object-to-sensor distances and pixel sizes seen during training.},
  archive      = {J_NATMI},
  author       = {Lee, Chanseok and Song, Gookho and Kim, Hyeonggeon and Ye, Jong Chul and Jang, Mooseok},
  doi          = {10.1038/s42256-022-00584-3},
  journal      = {Nature Machine Intelligence},
  number       = {1},
  pages        = {35-45},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Deep learning based on parameterized physical forward model for adaptive holographic imaging with unpaired data},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Reply to: Modern graph neural networks do worse than
classical greedy algorithms in solving combinatorial optimization
problems like maximum independent set. <em>NATMI</em>, <em>5</em>(1),
32–34. (<a href="https://doi.org/10.1038/s42256-022-00590-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Schuetz, Martin J. A. and Brubaker, J. Kyle and Katzgraber, Helmut G.},
  doi          = {10.1038/s42256-022-00590-5},
  journal      = {Nature Machine Intelligence},
  number       = {1},
  pages        = {32-34},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Reply to: Modern graph neural networks do worse than classical greedy algorithms in solving combinatorial optimization problems like maximum independent set},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modern graph neural networks do worse than classical greedy
algorithms in solving combinatorial optimization problems like maximum
independent set. <em>NATMI</em>, <em>5</em>(1), 29–31. (<a
href="https://doi.org/10.1038/s42256-022-00589-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Angelini, Maria Chiara and Ricci-Tersenghi, Federico},
  doi          = {10.1038/s42256-022-00589-y},
  journal      = {Nature Machine Intelligence},
  number       = {1},
  pages        = {29-31},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Modern graph neural networks do worse than classical greedy algorithms in solving combinatorial optimization problems like maximum independent set},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Reply to: Inability of a graph neural network heuristic to
outperform greedy algorithms in solving combinatorial optimization
problems. <em>NATMI</em>, <em>5</em>(1), 26–28. (<a
href="https://doi.org/10.1038/s42256-022-00588-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Schuetz, Martin J. A. and Brubaker, J. Kyle and Katzgraber, Helmut G.},
  doi          = {10.1038/s42256-022-00588-z},
  journal      = {Nature Machine Intelligence},
  number       = {1},
  pages        = {26-28},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Reply to: Inability of a graph neural network heuristic to outperform greedy algorithms in solving combinatorial optimization problems},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inability of a graph neural network heuristic to outperform
greedy algorithms in solving combinatorial optimization problems.
<em>NATMI</em>, <em>5</em>(1), 24–25. (<a
href="https://doi.org/10.1038/s42256-022-00587-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Boettcher, Stefan},
  doi          = {10.1038/s42256-022-00587-0},
  journal      = {Nature Machine Intelligence},
  number       = {1},
  pages        = {24-25},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Inability of a graph neural network heuristic to outperform greedy algorithms in solving combinatorial optimization problems},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning from data with structured missingness.
<em>NATMI</em>, <em>5</em>(1), 13–23. (<a
href="https://doi.org/10.1038/s42256-022-00596-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Missing data are an unavoidable complication in many machine learning tasks. When data are ‘missing at random’ there exist a range of tools and techniques to deal with the issue. However, as machine learning studies become more ambitious, and seek to learn from ever-larger volumes of heterogeneous data, an increasingly encountered problem arises in which missing values exhibit an association or structure, either explicitly or implicitly. Such ‘structured missingness’ raises a range of challenges that have not yet been systematically addressed, and presents a fundamental hindrance to machine learning at scale. Here we outline the current literature and propose a set of grand challenges in learning from data with structured missingness. Gathering big datasets has become an essential component of machine learning in many scientific areas, but it is unavoidable that some data values are missing. An important and growing effect that needs careful attention, especially when heterogeneous data sources are combined, is that of structured missingness, where data values are missing not at random, but with a specific structure.},
  archive      = {J_NATMI},
  author       = {Mitra, Robin and McGough, Sarah F. and Chakraborti, Tapabrata and Holmes, Chris and Copping, Ryan and Hagenbuch, Niels and Biedermann, Stefanie and Noonan, Jack and Lehmann, Brieuc and Shenvi, Aditi and Doan, Xuan Vinh and Leslie, David and Bianconi, Ginestra and Sanchez-Garcia, Ruben and Davies, Alisha and Mackintosh, Maxine and Andrinopoulou, Eleni-Rosalina and Basiri, Anahid and Harbron, Chris and MacArthur, Ben D.},
  doi          = {10.1038/s42256-022-00596-z},
  journal      = {Nature Machine Intelligence},
  number       = {1},
  pages        = {13-23},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Learning from data with structured missingness},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Translating single-cell genomics into cell types.
<em>NATMI</em>, <em>5</em>(1), 11–12. (<a
href="https://doi.org/10.1038/s42256-022-00600-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine translation of languages can now automatically detect different cell types from single-cell transcriptomic data. Such a feat opens the prospect of dissecting complex clinical samples such as heterogenous tumours at scale.},
  archive      = {J_NATMI},
  author       = {Tegner, Jesper N.},
  doi          = {10.1038/s42256-022-00600-6},
  journal      = {Nature Machine Intelligence},
  number       = {1},
  pages        = {11-12},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Translating single-cell genomics into cell types},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bridging the neutralization gap for unseen antibodies.
<em>NATMI</em>, <em>5</em>(1), 8–10. (<a
href="https://doi.org/10.1038/s42256-022-00594-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Antibodies are an essential class of therapeutics but low breadth or off-target binding are major concerns for antibody–drug efficiency and safety. To predict which targets an antibody can neutralize, a machine learning pipeline based on an adaptive graph convolutional network architecture is proposed that learns the binding landscape of antibodies to multiple mutated viruses at the same time.},
  archive      = {J_NATMI},
  author       = {Robert, Philippe A. and Greiff, Victor},
  doi          = {10.1038/s42256-022-00594-1},
  journal      = {Nature Machine Intelligence},
  number       = {1},
  pages        = {8-10},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Bridging the neutralization gap for unseen antibodies},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A cautionary tale about the adoption of medical AI in
sweden. <em>NATMI</em>, <em>5</em>(1), 5–7. (<a
href="https://doi.org/10.1038/s42256-022-00602-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A recent case of a flawed medical AI system that was backed by public funding provides an opportunity to discuss the impact of government policies and regulation in AI.},
  archive      = {J_NATMI},
  author       = {Niemiec, Emilia},
  doi          = {10.1038/s42256-022-00602-4},
  journal      = {Nature Machine Intelligence},
  number       = {1},
  pages        = {5-7},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A cautionary tale about the adoption of medical AI in sweden},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Federated machine learning in data-protection-compliant
research. <em>NATMI</em>, <em>5</em>(1), 2–4. (<a
href="https://doi.org/10.1038/s42256-022-00601-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To fully leverage big data, they need to be shared across institutions in a manner compliant with privacy considerations and the EU General Data Protection Regulation (GDPR). Federated machine learning is a promising option.},
  archive      = {J_NATMI},
  author       = {Brauneck, Alissa and Schmalhorst, Louisa and Kazemi Majdabadi, Mohammad Mahdi and Bakhtiari, Mohammad and Völker, Uwe and Saak, Christina Caroline and Baumbach, Jan and Baumbach, Linda and Buchholtz, Gabriele},
  doi          = {10.1038/s42256-022-00601-5},
  journal      = {Nature Machine Intelligence},
  number       = {1},
  pages        = {2-4},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Federated machine learning in data-protection-compliant research},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The AI writing on the wall. <em>NATMI</em>, <em>5</em>(1),
1. (<a href="https://doi.org/10.1038/s42256-023-00613-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Guidelines are urgently needed for the use of generative AI tools like ChatGPT in scientific writing.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-023-00613-9},
  journal      = {Nature Machine Intelligence},
  number       = {1},
  pages        = {1},
  shortjournal = {Nat. Mach. Intell.},
  title        = {The AI writing on the wall},
  volume       = {5},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
