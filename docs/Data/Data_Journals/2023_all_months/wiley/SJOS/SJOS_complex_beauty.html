<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SJOS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="sjos---79">SJOS - 79</h2>
<ul>
<li><details>
<summary>
(2023). Sparse principal component analysis for high-dimensional
stationary time series. <em>SJOS</em>, <em>50</em>(4), 1953–1983. (<a
href="https://doi.org/10.1111/sjos.12664">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the sparse principal component analysis for high-dimensional stationary processes. The standard principal component analysis performs poorly when the dimension of the process is large. We establish oracle inequalities for penalized principal component estimators for the large class of processes including heavy-tailed time series. The rate of convergence of the estimators is established. We also elucidate the theoretical rate for choosing the tuning parameter in penalized estimators. The performance of the sparse principal component analysis is demonstrated by numerical simulations. The utility of the sparse principal component analysis for time series data is exemplified by the application to average temperature data.},
  archive      = {J_SJOS},
  author       = {Kou Fujimori and Yuichi Goto and Yan Liu and Masanobu Taniguchi},
  doi          = {10.1111/sjos.12664},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1953-1983},
  shortjournal = {Scand. J. Statist.},
  title        = {Sparse principal component analysis for high-dimensional stationary time series},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A robust model averaging approach for partially linear
models with responses missing at random. <em>SJOS</em>, <em>50</em>(4),
1933–1952. (<a href="https://doi.org/10.1111/sjos.12659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, with an assumed parametric model for the selection probability function, a robust model averaging estimation method is proposed for partially linear models with responses missing at random. The method is based on a weighted Mallows-type criterion. The method is robust in the sense that the asymptotic optimality holds true as long as the true model of the selection probability function is some measurable function of its assumed model. The optimal weight vector for model averaging is obtained by minimizing the weighted Mallows-type criterion. It is shown that the robust model averaging method achieves the lowest possible squared error asymptotically. Some simulation studies were conducted to evaluate the proposed method. An application to two real examples are provided as illustration.},
  archive      = {J_SJOS},
  author       = {Zhongqi Liang and Qihua Wang},
  doi          = {10.1111/sjos.12659},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1933-1952},
  shortjournal = {Scand. J. Statist.},
  title        = {A robust model averaging approach for partially linear models with responses missing at random},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient t0<span
class="math display"><em>t</em><sub>0</sub></span>-year risk regression
using the logistic model. <em>SJOS</em>, <em>50</em>(4), 1919–1932. (<a
href="https://doi.org/10.1111/sjos.12658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In some clinical studies patient survival beyond a specific point in time, t 0 $$ {t}_0 $$ , say, may be of special interest as it may for instance indicate patient cure. To analyze the t 0 $$ {t}_0 $$ -year risk for such patients may be accomplished using logistic regression with appropriate weights (IPWCC) that may further be augmented (AIPWCC) to improve efficiency. In this paper, we derive the most efficient estimator for this problem, which is different from the AIPWCC based on the full data efficient influence function. We first give the result for a survival endpoint and then generalize to the competing risk setting. The proposed estimators superior behavior is illustrated using simulations as well as applying it to some real data concerning the survival of blood and marrow transplanted patients.},
  archive      = {J_SJOS},
  author       = {Torben Martinussen and Thomas Harder Scheike},
  doi          = {10.1111/sjos.12658},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1919-1932},
  shortjournal = {Scand. J. Statist.},
  title        = {Efficient t0$$ {t}_0 $$-year risk regression using the logistic model},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pitfalls of amateur regression: The dutch new herring
controversies. <em>SJOS</em>, <em>50</em>(4), 1901–1918. (<a
href="https://doi.org/10.1111/sjos.12662">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying simple linear regression models, an economist analyzed a published dataset from an influential annual ranking in 2016 and 2017 of consumer outlets for Dutch New Herring and concluded that the ranking was manipulated. His finding was promoted by his university in national and international media, and this led to public outrage and ensuing discontinuation of the survey. We reconstitute the dataset, correcting errors and exposing features already important in a descriptive analysis of the data. The economist has continued his investigations, and in a follow-up publication repeats the same accusations. We point out errors in his reasoning and show that alleged evidence for deliberate manipulation of the ranking could easily be an artifact of specification errors. Temporal and spatial factors are both important and complex, and their effects cannot be captured using simple models, given the small sample sizes and many factors determining perceived taste of a food product.},
  archive      = {J_SJOS},
  author       = {Fengnan Gao and Richard D. Gill},
  doi          = {10.1111/sjos.12662},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1901-1918},
  shortjournal = {Scand. J. Statist.},
  title        = {Pitfalls of amateur regression: The dutch new herring controversies},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Regularized t<span class="math display"><em>t</em></span>
distribution: Definition, properties, and applications. <em>SJOS</em>,
<em>50</em>(4), 1884–1900. (<a
href="https://doi.org/10.1111/sjos.12655">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For gene expression data analysis, an important task is to identify genes that are differentially expressed between two or more groups. Nevertheless, as biological experiments are often measured with a relatively small number of samples, how to accurately estimate the variances of gene expression becomes a challenging issue. To tackle this problem, we introduce a regularized t $$ t $$ distribution and derive its statistical properties including the probability density function and the moment generating function. The noncentral regularized t $$ t $$ distribution is also introduced for computing the statistical power of hypothesis testing. For practical applications, we apply the regularized t $$ t $$ distribution to establish the null distribution of the regularized t $$ t $$ statistic, and then formulate it as a regularized t $$ t $$ -test for detecting the differentially expressed genes. Simulation studies and real data analysis show that our regularized t $$ t $$ -test performs much better than the Bayesian t $$ t $$ -test in the “ limma ” package, in particular when the sample sizes are small.},
  archive      = {J_SJOS},
  author       = {Zongliang Hu and Yiping Yang and Gaorong Li and Tiejun Tong},
  doi          = {10.1111/sjos.12655},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1884-1900},
  shortjournal = {Scand. J. Statist.},
  title        = {Regularized t$$ t $$ distribution: Definition, properties, and applications},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Epistemic confidence in the observed confidence interval.
<em>SJOS</em>, <em>50</em>(4), 1859–1883. (<a
href="https://doi.org/10.1111/sjos.12654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We define confidence to be epistemic if it applies to an observed confidence interval. Epistemic confidence is unavailable—or even denied—in orthodox frequentist inference, as the confidence level is understood to apply to the procedure. Yet there are obvious practical and psychological needs to think about the uncertainty in the observed interval. We extend the Dutch Book argument used in the classical Bayesian justification of subjective probability to a stronger market-based version, which prevents external agents from exploiting unused information in any relevant subset. We previously showed that confidence is an extended likelihood, and the likelihood principle states that the likelihood contains all the information in the data, hence leaving no relevant subset. Intuitively, this implies that confidence associated with the full likelihood is protected from the Dutch Book, and hence is epistemic. Our goal is to validate this intuitive notion through theoretical backing and practical illustrations.},
  archive      = {J_SJOS},
  author       = {Yudi Pawitan and Hangbin Lee and Youngjo Lee},
  doi          = {10.1111/sjos.12654},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1859-1883},
  shortjournal = {Scand. J. Statist.},
  title        = {Epistemic confidence in the observed confidence interval},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dimension-independent markov chain monte carlo on the
sphere. <em>SJOS</em>, <em>50</em>(4), 1818–1858. (<a
href="https://doi.org/10.1111/sjos.12653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider Bayesian analysis on high-dimensional spheres with angular central Gaussian priors. These priors model antipodally symmetric directional data, are easily defined in Hilbert spaces and occur, for instance, in Bayesian density estimation and binary level set inversion. In this paper we derive efficient Markov chain Monte Carlo methods for approximate sampling of posteriors with respect to these priors. Our approaches rely on lifting the sampling problem to the ambient Hilbert space and exploit existing dimension-independent samplers in linear spaces. By a push-forward Markov kernel construction we then obtain Markov chains on the sphere which inherit reversibility and spectral gap properties from samplers in linear spaces. Moreover, our proposed algorithms show dimension-independent efficiency in numerical experiments.},
  archive      = {J_SJOS},
  author       = {Han Cheng Lie and Daniel Rudolf and Björn Sprungk and T. J. Sullivan},
  doi          = {10.1111/sjos.12653},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1818-1858},
  shortjournal = {Scand. J. Statist.},
  title        = {Dimension-independent markov chain monte carlo on the sphere},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Statistical inference with semiparametric nonignorable
nonresponse models. <em>SJOS</em>, <em>50</em>(4), 1795–1817. (<a
href="https://doi.org/10.1111/sjos.12652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to deal with nonignorable response is often a challenging problem encountered in statistical analysis with missing data. Parametric model assumption for the response mechanism is sensitive to model misspecification. We consider a semiparametric response model that relaxes the parametric model assumption in the response mechanism. Two types of efficient estimators, profile maximum likelihood estimator and profile calibration estimator, are proposed, and their asymptotic properties are investigated. Two extensive simulation studies are used to compare with some existing methods. We present an application of our method using data from the Korean Labor and Income Panel Survey.},
  archive      = {J_SJOS},
  author       = {Masatoshi Uehara and Danhyang Lee and Jae-Kwang Kim},
  doi          = {10.1111/sjos.12652},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1795-1817},
  shortjournal = {Scand. J. Statist.},
  title        = {Statistical inference with semiparametric nonignorable nonresponse models},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive estimation of intensity in a doubly stochastic
poisson process. <em>SJOS</em>, <em>50</em>(4), 1756–1794. (<a
href="https://doi.org/10.1111/sjos.12651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, I consider a doubly stochastic Poisson process with intensity λ t = q X t $$ {\lambda}_t=q\left({X}_t\right) $$ where X $$ X $$ is a continuous Itô semi-martingale. Both processes are observed continuously over a fixed period 0 , 1 $$ \left[0,1\right] $$ . I propose a local polynomial estimator for the function q $$ q $$ on a given interval. Next, I propose a method to select the bandwidth in a nonasymptotic framework that leads to an oracle inequality. Considering the asymptotic n $$ n $$ , and q = n q ˜ $$ q=n\tilde{q} $$ , the accuracy of the proposed estimator over the Hölder class of order β $$ \beta $$ is n − β 2 β + 1 $$ {n}^{\frac{-\beta }{2\beta +1}} $$ if the degree of the chosen polynomial is greater than ⌊ β ⌋ $$ \left\lfloor \beta \right\rfloor $$ and it is optimal in the minimax setting. I apply those results to data on French temperature and electricity spot prices from which I infer the intensity of electricity spot spikes as a function of the temperature.},
  archive      = {J_SJOS},
  author       = {Thomas Deschatre},
  doi          = {10.1111/sjos.12651},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1756-1794},
  shortjournal = {Scand. J. Statist.},
  title        = {Adaptive estimation of intensity in a doubly stochastic poisson process},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nonparametric adaptive estimation for interacting particle
systems. <em>SJOS</em>, <em>50</em>(4), 1716–1755. (<a
href="https://doi.org/10.1111/sjos.12661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a stochastic system of N $$ N $$ interacting particles with constant diffusion coefficient and drift linear in space, time-depending on two unknown deterministic functions. Our concern here is the nonparametric estimation of these functions from a continuous observation of the process on [ 0 , T ] $$ \left[0,T\right] $$ for fixed T $$ T $$ and large N $$ N $$ . We define two collections of projection estimators belonging to finite-dimensional subspaces of 𝕃 2 ( [ 0 , T ] ) . We study the 𝕃 2 -risks of these estimators, where the risk is defined either by the expectation of an empirical norm or by the expectation of a deterministic norm. Afterwards, we propose a data-driven choice of the dimensions and study the risk of the adaptive estimators. The results are illustrated by numerical experiments on simulated data.},
  archive      = {J_SJOS},
  author       = {Fabienne Comte and Valentine Genon-Catalot},
  doi          = {10.1111/sjos.12661},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1716-1755},
  shortjournal = {Scand. J. Statist.},
  title        = {Nonparametric adaptive estimation for interacting particle systems},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Time-varying β-model for dynamic directed networks.
<em>SJOS</em>, <em>50</em>(4), 1687–1715. (<a
href="https://doi.org/10.1111/sjos.12650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We extend the well-known β $$ \beta $$ -model for directed graphs to dynamic network setting, where we observe snapshots of adjacency matrices at different time points. We propose a kernel-smoothed likelihood approach for estimating 2 n $$ 2n $$ time-varying parameters in a network with n $$ n $$ nodes, from N $$ N $$ snapshots. We establish consistency and asymptotic normality properties of our kernel-smoothed estimators as either n $$ n $$ or N $$ N $$ diverges. Our results contrast their counterparts in single-network analyses, where n → ∞ $$ n\to \infty $$ is invariantly required in asymptotic studies. We conduct comprehensive simulation studies that confirm our theory&#39;s prediction and illustrate the performance of our method from various angles. We apply our method to an email dataset and obtain meaningful results.},
  archive      = {J_SJOS},
  author       = {Yuqing Du and Lianqiang Qu and Ting Yan and Yuan Zhang},
  doi          = {10.1111/sjos.12650},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1687-1715},
  shortjournal = {Scand. J. Statist.},
  title        = {Time-varying β-model for dynamic directed networks},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep neural network classifier for multidimensional
functional data. <em>SJOS</em>, <em>50</em>(4), 1667–1686. (<a
href="https://doi.org/10.1111/sjos.12660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new approach, called as functional deep neural network (FDNN), for classifying multidimensional functional data. Specifically, a deep neural network is trained based on the principal components of the training data which shall be used to predict the class label of a future data function. Unlike the popular functional discriminant analysis approaches which only work for one-dimensional functional data, the proposed FDNN approach applies to general non-Gaussian multidimensional functional data. Moreover, when the log density ratio possesses a locally connected functional modular structure, we show that FDNN achieves minimax optimality. The superiority of our approach is demonstrated through both simulated and real-world datasets.},
  archive      = {J_SJOS},
  author       = {Shuoyang Wang and Guanqun Cao and Zuofeng Shang},
  doi          = {10.1111/sjos.12660},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1667-1686},
  shortjournal = {Scand. J. Statist.},
  title        = {Deep neural network classifier for multidimensional functional data},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A historical overview of textbook presentations of
statistical science. <em>SJOS</em>, <em>50</em>(4), 1641–1666. (<a
href="https://doi.org/10.1111/sjos.12641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We discuss the evolution in the presentation of statistical science in English-language textbooks, focusing on the period 1900–1970 as the field became increasingly influenced by research contributions of R. A. Fisher and Jerzy Neyman. George Udny Yule authored an early popular book that had 14 editions. Methods books authored by Fisher and George Snedecor guided scientists in implementing modern statistical methods. In the World War 2 era, textbooks authored by Maurice Kendall, Samuel Wilks, and Harald Cramér presented a dramatically different “mathematical statistics” portrayal that centered on theoretical foundations. The textbook emergence of the Bayesian approach occurred later, influenced by books by Harold Jeffreys and Leonard J. Savage. The quarter century after World War 2 saw an explosion of books in mathematical statistics and in particular topic areas. In addition to his highly cited research contributions, Sir David Cox was a prolific author of books on a great variety of topics. Most were published after the 1900–1970 period considered in this article, but we also summarize them as part of this special issue to honor his memory. We conclude by discussing the future of textbooks on the foundations of statistical science in the emerging, ever-broader, era of data science.},
  archive      = {J_SJOS},
  author       = {Alan Agresti},
  doi          = {10.1111/sjos.12641},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1641-1666},
  shortjournal = {Scand. J. Statist.},
  title        = {A historical overview of textbook presentations of statistical science},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finite sample inference for empirical bayesian methods.
<em>SJOS</em>, <em>50</em>(4), 1616–1640. (<a
href="https://doi.org/10.1111/sjos.12643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, empirical Bayesian (EB) inference has become an attractive approach for estimation in parametric models arising in a variety of real-life problems, especially in complex and high-dimensional scientific applications. However, compared to the relative abundance of available general methods for computing point estimators in the EB framework, the construction of confidence sets and hypothesis tests with good theoretical properties remains difficult and problem specific. Motivated by the Universal Inference framework, we propose a general and universal method, based on holdout likelihood ratios, and utilizing the hierarchical structure of the specified Bayesian model for constructing confidence sets and hypothesis tests that are finite sample valid. We illustrate our method through a range of numerical studies and real data applications, which demonstrate that the approach is able to generate useful and meaningful inferential statements in the relevant contexts.},
  archive      = {J_SJOS},
  author       = {Hien Duy Nguyen and Mayetri Gupta},
  doi          = {10.1111/sjos.12643},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1616-1640},
  shortjournal = {Scand. J. Statist.},
  title        = {Finite sample inference for empirical bayesian methods},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust inference for high-dimensional single index models.
<em>SJOS</em>, <em>50</em>(4), 1590–1615. (<a
href="https://doi.org/10.1111/sjos.12638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a robust inference method for high-dimensional single index models with an unknown link function and elliptically symmetrically distributed covariates, focusing on signal recovery and inference. The proposed method is built on the Huber loss and the estimation of the unknown link function is avoided. The ℓ 1 $$ {\ell}_1 $$ and ℓ 2 $$ {\ell}_2 $$ consistency of a Lasso estimator up to a multiplicative scalar is established. When the covariance matrix of the predictors satisfies the irrepresentable condition, our method is shown to recover the signed support of the true parameter under mild conditions. Based on a debiased Lasso estimator, we study component-wise and group inference for the high-dimensional index parameter. The finite-sample performance of our method is evaluated through extensive simulation studies. An application to a riboflavin production dataset is provided to illustrate the proposed method.},
  archive      = {J_SJOS},
  author       = {Dongxiao Han and Miao Han and Jian Huang and Yuanyuan Lin},
  doi          = {10.1111/sjos.12638},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1590-1615},
  shortjournal = {Scand. J. Statist.},
  title        = {Robust inference for high-dimensional single index models},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Parameter estimation for linear parabolic SPDEs in two
space dimensions based on high frequency data. <em>SJOS</em>,
<em>50</em>(4), 1568–1589. (<a
href="https://doi.org/10.1111/sjos.12663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider parameter estimation for a linear parabolic second-order stochastic partial differential equation (SPDE) in two space dimensions driven by two types of Q $$ Q $$ -Wiener processes based on high frequency data in time and space. We first estimate the parameters which appear in the eigenfunctions of the differential operator of the SPDE using the minimum contrast estimator based on the thinned data with respect to space, and then construct an approximate coordinate process of the SPDE. Furthermore, we propose estimators of the coefficient parameters of the SPDE utilizing the approximate coordinate process based on the thinned data with respect to time. We also give some simulation results.},
  archive      = {J_SJOS},
  author       = {Yozo Tonaki and Yusuke Kaino and Masayuki Uchida},
  doi          = {10.1111/sjos.12663},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1568-1589},
  shortjournal = {Scand. J. Statist.},
  title        = {Parameter estimation for linear parabolic SPDEs in two space dimensions based on high frequency data},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Plug-in machine learning for partially linear mixed-effects
models with repeated measurements. <em>SJOS</em>, <em>50</em>(4),
1553–1567. (<a href="https://doi.org/10.1111/sjos.12639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditionally, spline or kernel approaches in combination with parametric estimation are used to infer the linear coefficient (fixed effects) in a partially linear mixed-effects model for repeated measurements. Using machine learning algorithms allows us to incorporate complex interaction structures, nonsmooth terms, and high-dimensional variables. The linear variables and the response are adjusted nonparametrically for the nonlinear variables, and these adjusted variables satisfy a linear mixed-effects model in which the linear coefficient can be estimated with standard linear mixed-effects methods. We prove that the estimated fixed effects coefficient converges at the parametric rate, is asymptotically Gaussian distributed, and semiparametrically efficient. Two simulation studies demonstrate that our method outperforms a penalized regression spline approach in terms of coverage. We also illustrate our proposed approach on a longitudinal dataset with HIV-infected individuals. Software code for our method is available in the R -package dmlalg .},
  archive      = {J_SJOS},
  author       = {Corinne Emmenegger and Peter Bühlmann},
  doi          = {10.1111/sjos.12639},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1553-1567},
  shortjournal = {Scand. J. Statist.},
  title        = {Plug-in machine learning for partially linear mixed-effects models with repeated measurements},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Errata for “a framework for covariate balance using bregman
distances.” <em>SJOS</em>, <em>50</em>(3), 1552. (<a
href="https://doi.org/10.1111/sjos.12657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SJOS},
  doi          = {10.1111/sjos.12657},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1552},
  shortjournal = {Scand. J. Statist.},
  title        = {Errata for “A framework for covariate balance using bregman distances”},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Targeted estimation of state occupation probabilities for
the non-markov illness-death model. <em>SJOS</em>, <em>50</em>(3),
1532–1551. (<a href="https://doi.org/10.1111/sjos.12644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We use semi-parametric efficiency theory to derive a class of estimators for the state occupation probabilities of the continuous-time irreversible illness-death model. We consider both the setting with and without additional baseline information available, where we impose no specific functional form on the intensity functions of the model. We show that any estimator in the class is asymptotically linear under suitable assumptions about the estimators of the intensity functions. In particular, the assumptions are weak enough to allow the use of data-adaptive methods, which is important for making the identifying assumption of coarsening at random plausible in realistic settings. We suggest a flexible method for estimating the transition intensity functions of the illness-death model based on penalized Poisson regression. We apply this method to estimate the nuisance parameters of an illness-death model in a simulation study and a real-world application.},
  archive      = {J_SJOS},
  author       = {Anders Munch and Marie Skov Breum and Torben Martinussen and Thomas A. Gerds},
  doi          = {10.1111/sjos.12644},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1532-1551},
  shortjournal = {Scand. J. Statist.},
  title        = {Targeted estimation of state occupation probabilities for the non-markov illness-death model},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Asymptotic properties of the maximum smoothed partial
likelihood estimator in the change-plane cox model. <em>SJOS</em>,
<em>50</em>(3), 1503–1531. (<a
href="https://doi.org/10.1111/sjos.12642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The change-plane Cox model is a popular tool for the subgroup analysis of survival data. Despite the rich literature on this model, there has been limited investigation into the asymptotic properties of the estimators of the finite-dimensional parameter. Particularly, the convergence rate, not to mention the asymptotic distribution, has not been fully characterized for the general model where classification is based on multiple covariates. To bridge this theoretical gap, this study proposes a maximum smoothed partial likelihood estimator and establishes the following asymptotic properties. First, it shows that the convergence rate for the classification parameter can be arbitrarily close ton−1$$ {n}^{-1} $$up to a logarithmic factor under a certain condition on covariates and the choice of tuning parameter. Given this convergence rate result, it also establishes the asymptotic normality for the regression parameter.},
  archive      = {J_SJOS},
  author       = {Shota Takeishi},
  doi          = {10.1111/sjos.12642},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1503-1531},
  shortjournal = {Scand. J. Statist.},
  title        = {Asymptotic properties of the maximum smoothed partial likelihood estimator in the change-plane cox model},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Outlier detection based on extreme value theory and
applications. <em>SJOS</em>, <em>50</em>(3), 1466–1502. (<a
href="https://doi.org/10.1111/sjos.12665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whether an extreme observation is an outlier or not depends strongly on the corresponding tail behavior of the underlying distribution. We develop an automatic, data-driven method rooted in the mathematical theory of extremes to identify observations that deviate from the intermediate and central characteristics. The proposed algorithm is an extension of a method previously proposed in the literature for the specific case of heavy tailed Pareto-type distributions to all max-domains of attraction. We propose some applications such as a tail-adjusted boxplot which yields a more accurate representation of possible outliers, and the identification of outliers in a multivariate context through an analysis of associated random variables such as local outlier factors. Several examples and simulation results illustrate the finite sample behavior of the algorithm and its applications.},
  archive      = {J_SJOS},
  author       = {Shrijita Bhattacharya and Francois Kamper and Jan Beirlant},
  doi          = {10.1111/sjos.12665},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1466-1502},
  shortjournal = {Scand. J. Statist.},
  title        = {Outlier detection based on extreme value theory and applications},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multivariate geometric anisotropic cox processes.
<em>SJOS</em>, <em>50</em>(3), 1420–1465. (<a
href="https://doi.org/10.1111/sjos.12640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new modeling and inference framework for multivariate and anisotropic point processes. Building on recent innovations in multivariate spatial statistics, we propose a new family of multivariate anisotropic random fields, and from them a family of anisotropic point processes. We give conditions that make the proposed models valid. We also propose a Palm likelihood-based inference method for this type of point process, circumventing issues of likelihood tractability. Finally we illustrate the utility of the proposed modeling framework by analyzing spatial ecological observations of plants and trees in the Barro Colorado Island data.},
  archive      = {J_SJOS},
  author       = {James S. Martin and David J. Murrell and Sofia C. Olhede},
  doi          = {10.1111/sjos.12640},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1420-1465},
  shortjournal = {Scand. J. Statist.},
  title        = {Multivariate geometric anisotropic cox processes},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatial bootstrapped microeconometrics: Forecasting for
out-of-sample geo-locations in big data. <em>SJOS</em>, <em>50</em>(3),
1391–1419. (<a href="https://doi.org/10.1111/sjos.12636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial econometric models estimated on the big geo-located point data have at least two problems: limited computational capabilities and inefficient forecasting for the new out-of-sample geo-points. This is because of spatial weights matrixWdefined for in-sample observations only and the computational complexity. Machine learning models suffer the same when using kriging for predictions; thus this problem still remains unsolved. The paper presents a novel methodology for estimating spatial models on big data and predicting in new locations. The approach uses bootstrap and tessellation to calibrate both model and space. The best bootstrapped model is selected with the PAM (Partitioning Around Medoids) algorithm by classifying the regression coefficients jointly in a nonindependent manner. Voronoi polygons for the geo-points used in the best model allow for a representative space division. New out-of-sample points are assigned to tessellation tiles and linked to the spatial weights matrix as a replacement for an original point what makes feasible usage of calibrated spatial models as a forecasting tool for new locations. There is no trade-off between forecast quality and computational efficiency in this approach. An empirical example illustrates a model for business locations and firms&#39; profitability.},
  archive      = {J_SJOS},
  author       = {Katarzyna Kopczewska},
  doi          = {10.1111/sjos.12636},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1391-1419},
  shortjournal = {Scand. J. Statist.},
  title        = {Spatial bootstrapped microeconometrics: Forecasting for out-of-sample geo-locations in big data},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new reproducing kernel-based nonlinear dimension reduction
method for survival data. <em>SJOS</em>, <em>50</em>(3), 1365–1390. (<a
href="https://doi.org/10.1111/sjos.12635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the theories of sliced inverse regression (SIR) and reproducing kernel Hilbert space (RKHS), a new approach RDSIR (RKHS-based Double SIR) to nonlinear dimension reduction for survival data is proposed. An isometric isomorphism is constructed based on the RKHS property, then the nonlinear function in the RKHS can be represented by the inner product of two elements that reside in the isomorphic feature space. Due to the censorship of survival data, double slicing is used to estimate the weight function to adjust for the censoring bias. The nonlinear sufficient dimension reduction (SDR) subspace is estimated by a generalized eigen-decomposition problem. The asymptotic property of the estimator is established based on the perturbation theory. Finally, the performance of RDSIR is illustrated on simulated and real data. The numerical results show that RDSIR is comparable with the linear SDR method. Most importantly, RDSIR can also effectively extract nonlinearity from survival data.},
  archive      = {J_SJOS},
  author       = {Wenquan Cui and Jianjun Xu and Yuehua Wu},
  doi          = {10.1111/sjos.12635},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1365-1390},
  shortjournal = {Scand. J. Statist.},
  title        = {A new reproducing kernel-based nonlinear dimension reduction method for survival data},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Frequentist model averaging for envelope models.
<em>SJOS</em>, <em>50</em>(3), 1325–1364. (<a
href="https://doi.org/10.1111/sjos.12634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The envelope method produces efficient estimation in multivariate linear regression, and is widely applied in biology, psychology, and economics. This paper estimates parameters through a model averaging methodology and promotes the predicting abilities of the envelope models. We propose a frequentist model averaging method by minimizing a cross-validation criterion. When all the candidate models are misspecified, the proposed model averaging estimator is proved to be asymptotically optimal. When correct candidate models exist, the coefficient estimator is proved to be consistent, and the sum of the weights assigned to the correct models, in probability, converges to one. Simulations and an empirical application demonstrate the effectiveness of the proposed method.},
  archive      = {J_SJOS},
  author       = {Ziwen Gao and Jiahui Zou and Xinyu Zhang and Yanyuan Ma},
  doi          = {10.1111/sjos.12634},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1325-1364},
  shortjournal = {Scand. J. Statist.},
  title        = {Frequentist model averaging for envelope models},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Daisee: Adaptive importance sampling by balancing
exploration and exploitation. <em>SJOS</em>, <em>50</em>(3), 1298–1324.
(<a href="https://doi.org/10.1111/sjos.12637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study adaptive importance sampling (AIS) as an online learning problem and argue for the importance of the trade-off between exploration and exploitation in this adaptation. Borrowing ideas from the online learning literature, we propose Daisee, a partition-based AIS algorithm. We further introduce a notion of regret for AIS and show that Daisee has𝒪⁡(T⁢◂◽˙▸(log⁡T)34)cumulative pseudo-regret, whereT$$ T $$is the number of iterations. We then extend Daisee to adaptively learn a hierarchical partitioning of the sample space for more efficient sampling and confirm the performance of both algorithms empirically.},
  archive      = {J_SJOS},
  author       = {Xiaoyu Lu and Tom Rainforth and Yee Whye Teh},
  doi          = {10.1111/sjos.12637},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1298-1324},
  shortjournal = {Scand. J. Statist.},
  title        = {Daisee: Adaptive importance sampling by balancing exploration and exploitation},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Variable selection for high-dimensional generalized linear
model with block-missing data. <em>SJOS</em>, <em>50</em>(3), 1279–1297.
(<a href="https://doi.org/10.1111/sjos.12632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern scientific research, multiblock missing data emerges with synthesizing information across multiple studies. However, existing imputation methods for handling block-wise missing data either focus on the single-block missing pattern or heavily rely on the model structure. In this study, we propose a single regression-based imputation algorithm for multiblock missing data. First, we conduct a sparse precision matrix estimation based on the structure of block-wise missing data. Second, we impute the missing blocks with their means conditional on the observed blocks. Theoretical results about variable selection and estimation consistency are established in the context of a generalized linear model. Moreover, simulation studies show that compared with existing methods, the proposed imputation procedure is robust to various missing mechanisms because of the good properties of regression imputation. An application to Alzheimer&#39;s Disease Neuroimaging Initiative data also confirms the superiority of our proposed method.},
  archive      = {J_SJOS},
  author       = {Yifan He and Yang Feng and Xinyuan Song},
  doi          = {10.1111/sjos.12632},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1279-1297},
  shortjournal = {Scand. J. Statist.},
  title        = {Variable selection for high-dimensional generalized linear model with block-missing data},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust quasi-randomization-based estimation with ensemble
learning for missing data. <em>SJOS</em>, <em>50</em>(3), 1263–1278. (<a
href="https://doi.org/10.1111/sjos.12626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Missing data analysis requires assumptions about an outcome model or a response probability model to adjust for potential bias due to nonresponse. Doubly robust (DR) estimators are consistent if at least one of the models is correctly specified. Multiply robust (MR) estimators extend DR estimators by allowing for multiple models for both the outcome and/or response probability models and are consistent if at least one of the multiple models is correctly specified. We propose a robust quasi-randomization-based model approach to bring more protection against model misspecification than the existing DR and MR estimators, where any multiple semiparametric, nonparametric or machine learning models can be used for the outcome variable. The proposed estimator achieves unbiasedness by using a subsampling Rao–Blackwell method, given cell-homogenous response, regardless of any working models for the outcome. An unbiased variance estimation formula is proposed, which does not use any replicate jackknife or bootstrap methods. A simulation study shows that our proposed method outperforms the existing multiply robust estimators.},
  archive      = {J_SJOS},
  author       = {Danhyang Lee and Li-Chun Zhang and Sixia Chen},
  doi          = {10.1111/sjos.12626},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1263-1278},
  shortjournal = {Scand. J. Statist.},
  title        = {Robust quasi-randomization-based estimation with ensemble learning for missing data},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust sure independence screening for nonpolynomial
dimensional generalized linear models. <em>SJOS</em>, <em>50</em>(3),
1232–1262. (<a href="https://doi.org/10.1111/sjos.12628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of variable screening in ultra-high-dimensional generalized linear models (GLMs) of nonpolynomial orders. Since the popular SIS approach is extremely unstable in the presence of contamination and noise, we discuss a new robust screening procedure based on the minimum density power divergence estimator (MDPDE) of the marginal regression coefficients. Our proposed screening procedure performs well under pure and contaminated data scenarios. We provide a theoretical motivation for the use of marginal MDPDEs for variable screening from both population as well as sample aspects; in particular, we prove that the marginal MDPDEs are uniformly consistent leading to the sure screening property of our proposed algorithm. Finally, we propose an appropriate MDPDE-based extension for robust conditional screening in GLMs along with the derivation of its sure screening property. Our proposed methods are illustrated through extensive numerical studies along with an interesting real data application.},
  archive      = {J_SJOS},
  author       = {Abhik Ghosh and Erica Ponzi and Torkjel Sandanger and Magne Thoresen},
  doi          = {10.1111/sjos.12628},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1232-1262},
  shortjournal = {Scand. J. Statist.},
  title        = {Robust sure independence screening for nonpolynomial dimensional generalized linear models},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Longitudinal network models and permutation-uniform markov
chains. <em>SJOS</em>, <em>50</em>(3), 1201–1231. (<a
href="https://doi.org/10.1111/sjos.12630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider longitudinal networks whose edges turn on and off according to a discrete-time Markov chain with exponential-family transition probabilities. We characterize when their joint distributions are also exponential families with the same parameter, improving data reduction. Further we show that the permutation-uniform subclass of these chains permit interpretation as an independent, identically distributed sequence on the same state space. We then apply these ideas to temporal exponential random graph models, for which permutation uniformity is well suited, and discuss mean-parameter convergence, dyadic independence, and exchangeability. Our framework facilitates our introducing a new network model; simplifies analysis of some network and autoregressive models from the literature, including by permitting closed-form expressions for maximum likelihood estimates for some models; and facilitates applying standard tools to longitudinal-network Markov chains from either asymptotics or single-observation exponential random graph models.},
  archive      = {J_SJOS},
  author       = {William K. Schwartz and Sonja Petrović and Hemanshu Kaul},
  doi          = {10.1111/sjos.12630},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1201-1231},
  shortjournal = {Scand. J. Statist.},
  title        = {Longitudinal network models and permutation-uniform markov chains},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transform orders and stochastic monotonicity of statistical
functionals. <em>SJOS</em>, <em>50</em>(3), 1183–1200. (<a
href="https://doi.org/10.1111/sjos.12629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In some inferential statistical methods, such as tests and confidence intervals, it is important to describe the stochastic behavior of statistical functionals, aside from their large sample properties. We study such a behavior in terms of the usual stochastic order. For this purpose, we introduce a generalized family of stochastic orders, which is referred to as transform orders, showing that it provides a flexible framework for deriving stochastic monotonicity results. Given that our general definition makes it possible to obtain some well known ordering relations as particular cases, we can easily apply our method to different families of functionals. These include some prominent inequality measures, such as the generalized entropy, the Gini index, and its generalizations. We also illustrate the applicability of our approach by determining the least favorable distribution, and the behavior of some bootstrap statistics, in some goodness-of-fit testing procedures.},
  archive      = {J_SJOS},
  author       = {Tommaso Lando and Idir Arab and Paulo Eduardo Oliveira},
  doi          = {10.1111/sjos.12629},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1183-1200},
  shortjournal = {Scand. J. Statist.},
  title        = {Transform orders and stochastic monotonicity of statistical functionals},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Posterior consistency for the spectral density of
non-gaussian stationary time series. <em>SJOS</em>, <em>50</em>(3),
1152–1182. (<a href="https://doi.org/10.1111/sjos.12627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various nonparametric approaches for Bayesian spectral density estimation of stationary time series have been suggested in the literature, mostly based on the Whittle likelihood approximation. A generalization of this approximation involving a nonparametric correction of a parametric likelihood has been proposed in the literature with a proof of posterior consistency for spectral density estimation in combination with the Bernstein–Dirichlet process prior for Gaussian time series. In this article, we will extend the posterior consistency result to non-Gaussian time series by employing a general consistency theorem for dependent data and misspecified models. As a special case, posterior consistency for the spectral density under the Whittle likelihood is also extended to non-Gaussian time series. Small sample properties of this approach are illustrated with several examples of non-Gaussian time series.},
  archive      = {J_SJOS},
  author       = {Yifu Tang and Claudia Kirch and Jeong Eun Lee and Renate Meyer},
  doi          = {10.1111/sjos.12627},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1152-1182},
  shortjournal = {Scand. J. Statist.},
  title        = {Posterior consistency for the spectral density of non-gaussian stationary time series},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bayesian inverse problems with heterogeneous variance.
<em>SJOS</em>, <em>50</em>(3), 1116–1151. (<a
href="https://doi.org/10.1111/sjos.12622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider inverse problems in Hilbert spaces under correlated Gaussian noise, and use a Bayesian approach to find their regularized solution. We focus on mildly ill-posed inverse problems with fractional noise, using a novel wavelet-based vaguelette–vaguelette approach. It allows us to apply sequence space methods without assuming that all operators are simultaneously diagonalizable. The results are proved for more general bases and covariance operators. Our primary aim is to study posterior contraction rate in such inverse problems over Sobolev classes and compare it to the derived minimax rate. Secondly, we study effect of plugging in a consistent estimator of variances in sequence space on the posterior contraction rate. This result is applied to the problem with error in forward operator. Thirdly, we show that empirical Bayes posterior distribution with a plugged-in maximum marginal likelihood estimator of the prior scale contracts at the optimal rate, adaptively, in the minimax sense.},
  archive      = {J_SJOS},
  author       = {Natalia Bochkina and Jenovah Rodrigues},
  doi          = {10.1111/sjos.12622},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1116-1151},
  shortjournal = {Scand. J. Statist.},
  title        = {Bayesian inverse problems with heterogeneous variance},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed inference for two-sample u-statistics in massive
data analysis. <em>SJOS</em>, <em>50</em>(3), 1090–1115. (<a
href="https://doi.org/10.1111/sjos.12620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers distributed inference for two-sampleU-statistics under the massive data setting. In order to reduce the computational complexity, this paper proposes distributed two-sampleU-statistics and blockwise linear two-sampleU-statistics. The blockwise linear two-sampleU-statistic, which requires less communication cost, is more computationally efficient especially when the data are stored in different locations. The asymptotic properties of both types of distributed two-sampleU-statistics are established. In addition, this paper proposes bootstrap algorithms to approximate the distributions of distributed two-sampleU-statistics and blockwise linear two-sampleU-statistics for both nondegenerate and degenerate cases. The distributed weighted bootstrap for the distributed two-sampleU-statistic is new in the literature. The proposed bootstrap procedures are computationally efficient and are suitable for distributed computing platforms with theoretical guarantees. Extensive numerical studies illustrate that the proposed distributed approaches are feasible and effective.},
  archive      = {J_SJOS},
  author       = {Bingyao Huang and Yanyan Liu and Liuhua Peng},
  doi          = {10.1111/sjos.12620},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1090-1115},
  shortjournal = {Scand. J. Statist.},
  title        = {Distributed inference for two-sample U-statistics in massive data analysis},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). State estimation for aoristic models. <em>SJOS</em>,
<em>50</em>(3), 1068–1089. (<a
href="https://doi.org/10.1111/sjos.12619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aoristic data can be described by a marked point process in time in which the points cannot be observed directly but are known to lie in observable intervals, the marks. We consider Bayesian state estimation for the latent points when the marks are modeled in terms of an alternating renewal process in equilibrium and the prior is a Markov point process. We derive the posterior distribution, estimate its parameters and present some examples that illustrate the influence of the prior distribution. The model is then used to estimate times of occurrence of interval censored crimes.},
  archive      = {J_SJOS},
  author       = {Maria N. M. van Lieshout and Robin L. Markwitz},
  doi          = {10.1111/sjos.12619},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1068-1089},
  shortjournal = {Scand. J. Statist.},
  title        = {State estimation for aoristic models},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalizing the information content for stepped wedge
designs: A marginal modeling approach. <em>SJOS</em>, <em>50</em>(3),
1048–1067. (<a href="https://doi.org/10.1111/sjos.12615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stepped wedge trials are increasingly adopted because practical constraints necessitate staggered roll-out. While a complete design requires clusters to collect data in all periods, resource and patient-centered considerations may call for an incomplete stepped wedge design to minimize data collection burden. To study incomplete designs, we expand the metric of information content to discrete outcomes. We operate under a marginal model with general link and variance functions, and derive information content expressions when data elements (cells, sequences, periods) are omitted. We show that the centrosymmetric patterns of information content can hold for discrete outcomes with the variance-stabilizing link function. We perform numerical studies under the canonical link function, and find that while the patterns of information content for cells are approximately centrosymmetric for all examined underlying secular trends, the patterns of information content for sequences or periods are more sensitive to the secular trend, and may be far from centrosymmetric.},
  archive      = {J_SJOS},
  author       = {Fan Li and Jessica Kasza and Elizabeth L. Turner and Paul J. Rathouz and Andrew B. Forbes and John S. Preisser},
  doi          = {10.1111/sjos.12615},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1048-1067},
  shortjournal = {Scand. J. Statist.},
  title        = {Generalizing the information content for stepped wedge designs: A marginal modeling approach},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Consistent bayesian information criterion based on a mixture
prior for possibly high-dimensional multivariate linear regression
models. <em>SJOS</em>, <em>50</em>(3), 1022–1047. (<a
href="https://doi.org/10.1111/sjos.12617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the problem of selecting variables in a multivariate linear regression model, we derive new Bayesian information criteria based on a prior mixing a smooth distribution and a delta distribution. Each of them can be interpreted as a fusion of the Akaike information criterion (AIC) and the Bayesian information criterion (BIC). Inheriting their asymptotic properties, our information criteria are consistent in variable selection in both the large-sample and the high-dimensional asymptotic frameworks. In numerical simulations, variable selection methods based on our information criteria choose the true set of variables with high probability in most cases.},
  archive      = {J_SJOS},
  author       = {Haruki Kono and Tatsuya Kubokawa},
  doi          = {10.1111/sjos.12617},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1022-1047},
  shortjournal = {Scand. J. Statist.},
  title        = {Consistent bayesian information criterion based on a mixture prior for possibly high-dimensional multivariate linear regression models},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inference for low- and high-dimensional inhomogeneous gibbs
point processes. <em>SJOS</em>, <em>50</em>(3), 993–1021. (<a
href="https://doi.org/10.1111/sjos.12616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gibbs point processes (GPPs) constitute a large and flexible class of spatial point processes with explicit dependence between the points. They can model attractive as well as repulsive point patterns. Feature selection procedures are an important topic in high-dimensional statistical modeling. In this paper, a composite likelihood (in particular pseudo-likelihood) approach regularized with convex and nonconvex penalty functions is proposed to handle statistical inference for possibly high-dimensional inhomogeneous GPPs. We particularly investigate the setting where the number of covariates diverges as the domain of observation increases. Under some conditions provided on the spatial GPP and on penalty functions, we show that the oracle property, consistency and asymptotic normality hold. Our results also cover the low-dimensional case which fills a large gap in the literature. Through simulation experiments, we validate our theoretical results and finally, an application to a tropical forestry dataset illustrates the use of the proposed approach.},
  archive      = {J_SJOS},
  author       = {Ismaïla Ba and Jean-François Coeurjolly},
  doi          = {10.1111/sjos.12616},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {993-1021},
  shortjournal = {Scand. J. Statist.},
  title        = {Inference for low- and high-dimensional inhomogeneous gibbs point processes},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sequential monitoring of high-dimensional time series.
<em>SJOS</em>, <em>50</em>(3), 962–992. (<a
href="https://doi.org/10.1111/sjos.12607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the paper we derive new types of multivariate exponentially weighted moving average (EWMA) control charts which are based on the Euclidean distance and on the distance defined by using the inverse of the diagonal matrix consisting of the variances. The design of the proposed control schemes does not involve the computation of the inverse covariance matrix and, thus, it can be used in the high-dimensional setting. The distributional properties of the control statistics are obtained and are used in the determination of the new control procedures. Within an extensive simulation study, the new approaches are compared with the multivariate EWMA control charts which are based on the Mahalanobis distance.},
  archive      = {J_SJOS},
  author       = {Rostyslav Bodnar and Taras Bodnar and Wolfgang Schmid},
  doi          = {10.1111/sjos.12607},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {962-992},
  shortjournal = {Scand. J. Statist.},
  title        = {Sequential monitoring of high-dimensional time series},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sparse concordance-based ordinal classification.
<em>SJOS</em>, <em>50</em>(3), 934–961. (<a
href="https://doi.org/10.1111/sjos.12606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ordinal classification is an important area in statistical machine learning, where labels exhibit a natural order. One of the major goals in ordinal classification is to correctly predict the relative order of instances. We develop a novel concordance-based approach to ordinal classification, where a concordance function is introduced and a penalized smoothed method for optimization is designed. Variable selection using theL1$$ {L}_1 $$penalty is incorporated for sparsity considerations. Within the set of classification rules that maximize the concordance function, we find optimal thresholds to predict labels by minimizing a loss function. After building the classifier, we derive nonparametric estimation of class conditional probabilities. The asymptotic properties of the estimators as well as the variable selection consistency are established. Extensive simulations and real data applications show the robustness and advantage of the proposed method in terms of classification accuracy, compared with other existing methods.},
  archive      = {J_SJOS},
  author       = {Yiwei Fan and Jiaqi Gu and Guosheng Yin},
  doi          = {10.1111/sjos.12606},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {934-961},
  shortjournal = {Scand. J. Statist.},
  title        = {Sparse concordance-based ordinal classification},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Discussion of “divergence vs. Decision p<span
class="math display"><em>p</em></span>-values: A distinction worth
making in theory and keeping in practice – or, how divergence p<span
class="math display"><em>p</em></span>-values measure evidence even when
decision p<span class="math display"><em>p</em></span>-values do not” by
sander greenland. <em>SJOS</em>, <em>50</em>(3), 931–933. (<a
href="https://doi.org/10.1111/sjos.12656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SJOS},
  author       = {Kenneth Rice},
  doi          = {10.1111/sjos.12656},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {931-933},
  shortjournal = {Scand. J. Statist.},
  title        = {Discussion of “Divergence vs. decision p$$ p $$-values: A distinction worth making in theory and keeping in practice – or, how divergence p$$ p $$-values measure evidence even when decision p$$ p $$-values do not” by sander greenland},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Discussion on the SJS invited paper by sander greenland
divergence vs. Decision p<span
class="math display"><em>p</em></span>-values: A distinction worth
making in theory and keeping in practice. <em>SJOS</em>, <em>50</em>(3),
929–930. (<a href="https://doi.org/10.1111/sjos.12649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SJOS},
  author       = {Dario Gasbarra},
  doi          = {10.1111/sjos.12649},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {929-930},
  shortjournal = {Scand. J. Statist.},
  title        = {Discussion on the SJS invited paper by sander greenland divergence vs. decision p$$ p $$-values: A distinction worth making in theory and keeping in practice},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Statistical evidence and surprise unified under possibility
theory. <em>SJOS</em>, <em>50</em>(3), 923–928. (<a
href="https://doi.org/10.1111/sjos.12648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sander Greenland argues that reported results of hypothesis tests should include thesurprisal, the base-2 logarithm of the reciprocal of ap-value. The surprisal measures how many bits of evidence in the data warrant rejecting the null hypothesis. A generalization of surprisal also can measure how much the evidence justifies rejecting a composite hypothesis such as the complement of a confidence interval. That extended surprisal, calledsurprise, quantifies how many bits of astonishment an agent believing a hypothesis would experience upon observing the data. While surprisal is a function of a point in hypothesis space, surprise is a function of a subset of hypothesis space. Satisfying the conditions of conditional min-plus probability, surprise inherits a wealth of tools from possibility theory. The equivalent compatibility function has been recently applied to the replication crisis, to adjustingp-values for prior information, and to comparing scientific theories.},
  archive      = {J_SJOS},
  author       = {David R. Bickel},
  doi          = {10.1111/sjos.12648},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {923-928},
  shortjournal = {Scand. J. Statist.},
  title        = {Statistical evidence and surprise unified under possibility theory},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comments on divergence vs. Decision p-values. <em>SJOS</em>,
<em>50</em>(3), 920–922. (<a
href="https://doi.org/10.1111/sjos.12647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SJOS},
  author       = {Paul W. Vos},
  doi          = {10.1111/sjos.12647},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {920-922},
  shortjournal = {Scand. J. Statist.},
  title        = {Comments on divergence vs. decision P-values},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comments on divergence vs. Decision p-values: A distinction
worth making in theory and keeping in practice – or, how divergence
p-values measure evidence even when decision p-values do not by
greenland in scandinavian journal of statistics, 2023. <em>SJOS</em>,
<em>50</em>(3), 915–919. (<a
href="https://doi.org/10.1111/sjos.12646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Greenland (2023) distinguishes betweenP-values used for data description andP-values used for declaring significance. That&#39;s a useful distinction and Greenland has advanced our field by making it. That distinction comes with the idea that describing data with statistical models is often a useful task for statisticians. Again, we agree. Along the way, Greenland also says (i) there is such a thing as a “measure …of evidence [from data] against a statistical hypothesis or model” without regard to alternatives; (ii) “a discrepancyP-value is an ordinal description …”; (iii) descriptive “P-values can be derived to provide coherent measures of refutational evidence”; and a few other things that deserve comment and discussion.},
  archive      = {J_SJOS},
  author       = {Michael Lavine},
  doi          = {10.1111/sjos.12646},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {915-919},
  shortjournal = {Scand. J. Statist.},
  title        = {Comments on divergence vs. decision P-values: A distinction worth making in theory and keeping in practice – or, how divergence P-values measure evidence even when decision P-values do not by greenland in scandinavian journal of statistics, 2023},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Connecting simple and precise p-values to complex and
ambiguous realities (includes rejoinder to comments on “divergence
vs. Decision p-values”). <em>SJOS</em>, <em>50</em>(3), 899–914. (<a
href="https://doi.org/10.1111/sjos.12645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mathematics is a limited component of solutions to real-world problems, as it expresses only what is expected to be true if all our assumptions are correct, including implicit assumptions that are omnipresent and often incorrect. Statistical methods are rife with implicit assumptions whose violation can be life-threatening when results from them are used to set policy. Among them are that there is human equipoise or unbiasedness in data generation, management, analysis, and reporting. These assumptions correspond to levels of cooperation, competence, neutrality, and integrity that are absent more often than we would like to believe. Given this harsh reality, we should ask what meaning, if any, we can assign to theP-values, “statistical significance” declarations, “confidence” intervals, and posterior probabilities that are used to decide what and how to present (or spin) discussions of analyzed data. By themselves,P-values and CI do not test any hypothesis, nor do they measure the significance of results or the confidence we should have in them. The sense otherwise is an ongoing cultural error perpetuated by large segments of the statistical and research community via misleading terminology. So-called inferential statistics can only become contextually interpretable when derived explicitly from causal stories about the real data generator (such as randomization), and can only become reliable when those stories are based on valid and public documentation of the physical mechanisms that generated the data. Absent these assurances, traditional interpretations of statistical results become pernicious fictions that need to be replaced by far more circumspect descriptions of data and model relations.},
  archive      = {J_SJOS},
  author       = {Sander Greenland},
  doi          = {10.1111/sjos.12645},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {899-914},
  shortjournal = {Scand. J. Statist.},
  title        = {Connecting simple and precise P-values to complex and ambiguous realities (includes rejoinder to comments on “Divergence vs. decision P-values”)},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Selection of linear mixed-effects models for clustered data.
<em>SJOS</em>, <em>50</em>(2), 875–897. (<a
href="https://doi.org/10.1111/sjos.12623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider model selection for linear mixed-effects models with clustered structure, where conditional Kullback–Leibler (CKL) loss is applied to measure the efficiency of the selection. We estimate the CKL loss by substituting the empirical best linear unbiased predictors (EBLUPs) into random effects with model parameters estimated by maximum likelihood. Although the BLUP approach is commonly used in predicting random effects and future observations, selecting random effects to achieve asymptotic loss efficiency concerning CKL loss is challenging and has not been well studied. In this paper, we propose addressing this difficulty using a conditional generalized information criterion (CGIC) with two tuning parameters. We further consider a challenging but practically relevant situation where the number,m$$ m $$, of clusters does not go to infinity with the sample size. Hence the random-effects variances are not consistently estimable. We show that via a novel decomposition of the CKL risk, the CGIC achieves consistency and asymptotic loss efficiency, whetherm$$ m $$is fixed or increases to infinity with the sample size. We also conduct numerical experiments to illustrate the theoretical findings.},
  archive      = {J_SJOS},
  author       = {Chih-Hao Chang and Hsin-Cheng Huang and Ching-Kang Ing},
  doi          = {10.1111/sjos.12623},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {875-897},
  shortjournal = {Scand. J. Statist.},
  title        = {Selection of linear mixed-effects models for clustered data},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Asymptotic approximation of the likelihood of stationary
determinantal point processes. <em>SJOS</em>, <em>50</em>(2), 842–874.
(<a href="https://doi.org/10.1111/sjos.12613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous determinantal point processes (DPPs) are a class of repulsive point processes onℝd$$ {\mathbb{R}}^d $$with many statistical applications. Although an explicit expression of their density is known, it is too complicated to be used directly for maximum likelihood estimation. In the stationary case, an approximation using Fourier series has been suggested, but it is limited to rectangular observation windows and no theoretical results support it. In this contribution, we investigate a different way to approximate the likelihood by looking at its asymptotic behavior when the observation window grows towardℝd$$ {\mathbb{R}}^d $$. This new approximation is not limited to rectangular windows, is faster to compute than the previous one, does not require any tuning parameter, and some theoretical justifications are provided. It moreover provides an explicit formula for estimating the asymptotic variance of the associated estimator. The performances are assessed in a simulation study on standard parametric models onℝd$$ {\mathbb{R}}^d $$and compare favorably to common alternative estimation methods for continuous DPPs.},
  archive      = {J_SJOS},
  author       = {Arnaud Poinas and Frédéric Lavancier},
  doi          = {10.1111/sjos.12613},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {842-874},
  shortjournal = {Scand. J. Statist.},
  title        = {Asymptotic approximation of the likelihood of stationary determinantal point processes},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nonparametric asymptotic confidence intervals for extreme
quantiles. <em>SJOS</em>, <em>50</em>(2), 825–841. (<a
href="https://doi.org/10.1111/sjos.12610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose new asymptotic confidence intervals for extreme quantiles, that is, for quantiles located outside the range of the available data. We restrict ourselves to the situation where the underlying distribution is heavy-tailed. While asymptotic confidence intervals are mostly constructed around a pivotal quantity, we consider here an alternative approach based on the distribution of order statistics sampled from a uniform distribution. The convergence of the coverage probability to the nominal one is established under a classical second-order condition. The finite sample behavior is also examined and our methodology is applied to a real dataset.},
  archive      = {J_SJOS},
  author       = {Laurent Gardes and Samuel Maistre},
  doi          = {10.1111/sjos.12610},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {825-841},
  shortjournal = {Scand. J. Statist.},
  title        = {Nonparametric asymptotic confidence intervals for extreme quantiles},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal designs for the development of personalized
treatment rules. <em>SJOS</em>, <em>50</em>(2), 797–824. (<a
href="https://doi.org/10.1111/sjos.12621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the design of multi-armed parallel group clinical trials to estimate personalized treatment rules that identify the best treatment for a given patient with given covariates. Assuming that the outcomes in each treatment arm are given by a homoscedastic linear model, with possibly different variances between treatment arms, and that the trial subjects form a random sample from an unselected overall population, we optimize the (possibly randomized) treatment allocation allowing the allocation rates to depend on the covariates. We find that, for the case of two treatments, the approximately optimal allocation rule does not depend on the value of the covariates but only on the variances of the responses. In contrast, for the case of three treatments or more, the optimal treatment allocation does depend on the values of the covariates as well as the true regression coefficients. The methods are illustrated with a recently published dietary clinical trial.},
  archive      = {J_SJOS},
  author       = {David Azriel and Yosef Rinott and Martin Posch},
  doi          = {10.1111/sjos.12621},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {797-824},
  shortjournal = {Scand. J. Statist.},
  title        = {Optimal designs for the development of personalized treatment rules},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Large-scale simultaneous inference under dependence.
<em>SJOS</em>, <em>50</em>(2), 750–796. (<a
href="https://doi.org/10.1111/sjos.12614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous inference allows for the exploration of data while deciding on criteria for proclaiming discoveries. It was recently proved that all admissible post hoc inference methods for the true discoveries must employ closed testing. In this paper, we investigate efficient closed testing with local tests of a special form: thresholding a function of sums of test scores for the individual hypotheses. Under this special design, we propose a new statistic that quantifies the cost of multiplicity adjustments, and we develop fast (mostly linear-time) algorithms for post hoc inference. Paired with recent advances in global null tests based on generalized means, our work instantiates a series of simultaneous inference methods that can handle many dependence structures and signal compositions. We provide guidance on the method choices via theoretical investigation of the conservativeness and sensitivity for different local tests, as well as simulations that find analogous behavior for local tests and full closed testing.},
  archive      = {J_SJOS},
  author       = {Jinjin Tian and Xu Chen and Eugene Katsevich and Jelle Goeman and Aaditya Ramdas},
  doi          = {10.1111/sjos.12614},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {750-796},
  shortjournal = {Scand. J. Statist.},
  title        = {Large-scale simultaneous inference under dependence},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the robustness to outliers of the student-t process.
<em>SJOS</em>, <em>50</em>(2), 725–749. (<a
href="https://doi.org/10.1111/sjos.12611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theory of Bayesian robustness modeling uses heavy-tailed distributions to resolve conflicts of information by rejecting automatically the outlying information in favor of the other sources of information. In particular, the Student&#39;s-t process is a natural alternative to the Gaussian process when the data might carry atypical information. Several works attest to the robustness of the Studentt$$ t $$process, however, the studies are mostly guided by intuition and focused mostly on the computational aspects rather than the mathematical properties of the involved distributions. This work uses the theory of regular variation to address the robustness of the Studentt$$ t $$process in the context of nonlinear regression, that is, the behavior of the posterior distribution in the presence of outliers in the inputs, in the outputs, or in both sources of information. In all these cases, under certain conditions, it is shown that the posterior distribution tends to a quantity that does not depend on the atypical information, then, for every case, the limiting posterior distribution as the outliers tend to infinity is provided. The impact of outliers on the predictive posterior distribution is also addressed. The theory is illustrated with a few simulated examples.},
  archive      = {J_SJOS},
  author       = {J. Ailton A. Andrade},
  doi          = {10.1111/sjos.12611},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {725-749},
  shortjournal = {Scand. J. Statist.},
  title        = {On the robustness to outliers of the student-t process},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). General purpose multiply robust data integration procedures
for handling nonprobability samples. <em>SJOS</em>, <em>50</em>(2),
697–724. (<a href="https://doi.org/10.1111/sjos.12605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been an increased interest in combining probability and nonprobability samples. Nonprobability sample are cheaper and quicker to conduct but the resulting estimators are vulnerable to bias as the participation probabilities are unknown. To adjust for the potential bias, estimation procedures based on parametric or nonparametric models have been discussed in the literature. However, the validity of the resulting estimators relies heavily on the validity of the underlying models. Also, nonparametric approaches may suffer from the curse of dimensionality and poor efficiency. We propose a data integration approach by combining multiple outcome regression models and propensity score models. The proposed approach can be used for estimating general parameters including totals, means, distribution functions, and percentiles. The resulting estimators are multiply robust in the sense that they remain consistent if all but one model are misspecified. The asymptotic properties of point and variance estimators are established. The results from a simulation study show the benefits of the proposed method in terms of bias and efficiency. Finally, we apply the proposed method using data from the Korea National Health and Nutrition Examination Survey and data from the National Health Insurance Sharing Services.},
  archive      = {J_SJOS},
  author       = {Sixia Chen and David Haziza},
  doi          = {10.1111/sjos.12605},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {697-724},
  shortjournal = {Scand. J. Statist.},
  title        = {General purpose multiply robust data integration procedures for handling nonprobability samples},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The geometry of gaussian double markovian distributions.
<em>SJOS</em>, <em>50</em>(2), 665–696. (<a
href="https://doi.org/10.1111/sjos.12604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian double Markovian models consist of covariance matrices constrained by a pair of graphs specifying zeros simultaneously in the matrix and its inverse. We study the semi-algebraic geometry of these models, in particular their dimension, smoothness, and connectedness as well as algebraic and combinatorial properties.},
  archive      = {J_SJOS},
  author       = {Tobias Boege and Thomas Kahle and Andreas Kretschmer and Frank Röttger},
  doi          = {10.1111/sjos.12604},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {665-696},
  shortjournal = {Scand. J. Statist.},
  title        = {The geometry of gaussian double markovian distributions},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continuous-time threshold autoregressions with jumps:
Properties, estimation, and application to electricity markets.
<em>SJOS</em>, <em>50</em>(2), 638–664. (<a
href="https://doi.org/10.1111/sjos.12597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous-time autoregressive processes have been applied successfully in many fields and are particularly advantageous in the modeling of irregularly spaced or high-frequency time series data. A convenient nonlinear extension of this model are continuous-time threshold autoregressions (CTAR). CTAR allow for greater flexibility in model parameters and can represent a regime switching behavior. However, so far only Gaussian CTAR processes have been defined, so that this model class could not be used for data with jumps, as frequently observed in financial applications. Hence, as a novelty, we construct CTAR processes with jumps in this paper. Existence of a unique weak solution and weak consistency of an Euler approximation scheme is proven. As a closed form expression of the likelihood is not available, we use kernel-based particle filtering for estimation. We fit our model to the Physical Electricity Index and show that it describes the data better than other comparable approaches.},
  archive      = {J_SJOS},
  author       = {Daniel Lingohr and Gernot Müller},
  doi          = {10.1111/sjos.12597},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {638-664},
  shortjournal = {Scand. J. Statist.},
  title        = {Continuous-time threshold autoregressions with jumps: Properties, estimation, and application to electricity markets},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nadaraya–watson estimator for i.i.d. Paths of diffusion
processes. <em>SJOS</em>, <em>50</em>(2), 589–637. (<a
href="https://doi.org/10.1111/sjos.12593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with a nonparametric Nadaraya–Watson (NW) estimator of the drift function computed from independent continuous observations of a diffusion process. Risk bounds on the estimator and its discrete-time approximation are established. The paper also deals with extensions of the PCO and leave-one-out cross-validation bandwidth selection methods for our NW estimator. Finally, some numerical experiments are provided.},
  archive      = {J_SJOS},
  author       = {Nicolas Marie and Amélie Rosier},
  doi          = {10.1111/sjos.12593},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {589-637},
  shortjournal = {Scand. J. Statist.},
  title        = {Nadaraya–Watson estimator for I.I.D. paths of diffusion processes},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Benchmarked linear shrinkage prediction in the fay–herriot
small area model. <em>SJOS</em>, <em>50</em>(2), 572–588. (<a
href="https://doi.org/10.1111/sjos.12596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The empirical best linear unbiased predictor (EBLUP) is a linear shrinkage of the direct estimate toward the regression estimate and useful for the small area estimation in the sense of increasing precision of estimation of small area means. However, one potential difficulty of EBLUP is that the overall estimate for a larger geographical area based on a sum of EBLUP is not necessarily identical to the corresponding direct estimate like the overall sample mean. To fix this problem, the paper suggests a new method for benchmarking EBLUP in the Fay–Herriot model without assuming normality of random effects and sampling errors. The resulting benchmarked empirical linear shrinkage (BELS) predictor has novelty in the sense that coefficients for benchmarking are adjusted based on the data from each area. To measure the uncertainty of BELS, the second-order unbiased estimator of the mean squared error is derived.},
  archive      = {J_SJOS},
  author       = {Kentaro Chikamatsu and Tatsuya Kubokawa},
  doi          = {10.1111/sjos.12596},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {572-588},
  shortjournal = {Scand. J. Statist.},
  title        = {Benchmarked linear shrinkage prediction in the Fay–Herriot small area model},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Statistical inference for cox proportional hazards models
with a diverging number of covariates. <em>SJOS</em>, <em>50</em>(2),
550–571. (<a href="https://doi.org/10.1111/sjos.12595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For statistical inference on regression models with a diverging number of covariates, the existing literature typically makes sparsity assumptions on the inverse of the Fisher information matrix. Such assumptions, however, are often violated under Cox proportion hazards models, leading to biased estimates with under-coverage confidence intervals. We propose a modified debiased lasso method, which solves a series of quadratic programming problems to approximate the inverse information matrix without posing sparse matrix assumptions. We establish asymptotic results for the estimated regression coefficients when the dimension of covariates diverges with the sample size. As demonstrated by extensive simulations, our proposed method provides consistent estimates and confidence intervals with nominal coverage probabilities. The utility of the method is further demonstrated by assessing the effects of genetic markers on patients&#39; overall survival with the Boston Lung Cancer Survival Cohort, a large-scale epidemiology study investigating mechanisms underlying the lung cancer.},
  archive      = {J_SJOS},
  author       = {Lu Xia and Bin Nan and Yi Li},
  doi          = {10.1111/sjos.12595},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {550-571},
  shortjournal = {Scand. J. Statist.},
  title        = {Statistical inference for cox proportional hazards models with a diverging number of covariates},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Regularization in dynamic random-intercepts models for
analysis of longitudinal data. <em>SJOS</em>, <em>50</em>(2), 513–549.
(<a href="https://doi.org/10.1111/sjos.12592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of simultaneous variable selection and estimation in the random-intercepts model with the first-order lag response. This type of model is commonly used for analyzing longitudinal data obtained through repeated measurements on individuals over time. This model uses random effects to cover the intra-class correlation, and the first lagged response to address the serial correlation, which are two common sources of dependency in longitudinal data. We demonstrate that the conditional likelihood approach by ignoring correlation among random effects and initial responses can lead to biased regularized estimates. Furthermore, we demonstrate that joint modeling of initial responses and subsequent observations in the structure of dynamic random-intercepts models leads to both consistency and Oracle properties of regularized estimators. We present theoretical results in both low- and high-dimensional settings and evaluate regularized estimators&#39; performances by conducting simulation studies and analyzing a real dataset. Supporting information is available online.},
  archive      = {J_SJOS},
  author       = {Amir-Abbas Mofidian Naieni and Reyhaneh Rikhtehgaran},
  doi          = {10.1111/sjos.12592},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {513-549},
  shortjournal = {Scand. J. Statist.},
  title        = {Regularization in dynamic random-intercepts models for analysis of longitudinal data},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Break point detection for functional covariance.
<em>SJOS</em>, <em>50</em>(2), 477–512. (<a
href="https://doi.org/10.1111/sjos.12589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many neuroscience experiments record sequential trajectories where each trajectory consists of oscillations and fluctuations around zero. Such trajectories can be viewed as zero-mean functional data. When there are structural breaks in higher-order moments, it is not always easy to spot these by mere visual inspection. Motivated by this challenging problem in brain signal analysis, we propose a detection and testing procedure to find the change point in functional covariance. The detection procedure is based on the cumulative sum statistics (CUSUM). The fully functional testing procedure relies on a null distribution which depends on infinitely many unknown parameters, though in practice only a finite number of these parameters can be included for the hypothesis test of the existence of change point. This paper provides some theoretical insights on the influence of the number of parameters. Meanwhile, the asymptotic properties of the estimated change point are developed. The effectiveness of the proposed method is numerically validated in simulation studies and an application to investigate changes in rat brain signals following an experimentally-induced stroke.},
  archive      = {J_SJOS},
  author       = {Shuhao Jiao and Ron D. Frostig and Hernando Ombao},
  doi          = {10.1111/sjos.12589},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {477-512},
  shortjournal = {Scand. J. Statist.},
  title        = {Break point detection for functional covariance},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prior distributions expressing ignorance about convex
increasing failure rates. <em>SJOS</em>, <em>50</em>(2), 452–476. (<a
href="https://doi.org/10.1111/sjos.12588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the specification of probability distributions expressing ignorance concerning annual or otherwise discretized failure or mortality rates, when these rates can safely be assumed to be increasing and convex, but are completely unknown otherwise. Such distributions can be used as noninformative priors for Bayesian analysis of failure data. We demonstrate why a uniform distribution used in earlier work is unsatisfactory, especially from the point of view of insensitivity with respect to the time scale that is chosen for the problem at hand. We suggest alternative distributions based on Dirichlet distributed weights for the extreme points of relevant convex sets, and discuss which consequences a requirement for scale neutrality has for the choice of Dirichlet parameters.},
  archive      = {J_SJOS},
  author       = {Jørund Gåsemyr and Aliaksandr Hubin},
  doi          = {10.1111/sjos.12588},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {452-476},
  shortjournal = {Scand. J. Statist.},
  title        = {Prior distributions expressing ignorance about convex increasing failure rates},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust optimal estimation of location from discretely
sampled functional data. <em>SJOS</em>, <em>50</em>(2), 411–451. (<a
href="https://doi.org/10.1111/sjos.12586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating location is a central problem in functional data analysis, yet most current estimation procedures either unrealistically assume completely observed trajectories or lack robustness with respect to the many kinds of anomalies one can encounter in the functional setting. To remedy these deficiencies we introduce the first class of optimal robust location estimators based on discretely sampled functional data. The proposed method is based on M-type smoothing spline estimation with repeated measurements and is suitable for both commonly and independently observed trajectories that are subject to measurement error. We show that under suitable assumptions the proposed family of estimators is minimax rate optimal both for commonly and independently observed trajectories and we illustrate its highly competitive performance and practical usefulness in a Monte-Carlo study and a real-data example involving recent Covid-19 data.},
  archive      = {J_SJOS},
  author       = {Ioannis Kalogridis and Stefan Van Aelst},
  doi          = {10.1111/sjos.12586},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {411-451},
  shortjournal = {Scand. J. Statist.},
  title        = {Robust optimal estimation of location from discretely sampled functional data},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unconditional empirical likelihood approach for analytic use
of public survey data. <em>SJOS</em>, <em>50</em>(1), 383–410. (<a
href="https://doi.org/10.1111/sjos.12590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling survey data often requires having the knowledge of design and weighting variables. With public-use survey data, some of these variables may not be available for confidentiality reasons. The proposed approach can be used in this situation, as long as calibrated weights and variables specifying the strata and primary sampling units are available. It gives consistent point estimation and a pivotal statistics for testing and confidence intervals. The proposed approach does not rely on with-replacement sampling, single-stage, negligible sampling fractions, or noninformative sampling. Adjustments based on design effects, eigenvalues, joint-inclusion probabilities or bootstrap, are not needed. The inclusion probabilities and auxiliary variables do not have to be known. Multistage designs with unequal selection of primary sampling units are considered. Nonresponse can be easily accommodated if the calibrated weights include reweighting adjustment for nonresponse. We use an unconditional approach, where the variables and sample are random variables. The design can be informative.},
  archive      = {J_SJOS},
  author       = {Yves G. Berger},
  doi          = {10.1111/sjos.12590},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {383-410},
  shortjournal = {Scand. J. Statist.},
  title        = {Unconditional empirical likelihood approach for analytic use of public survey data},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exact uniformly most powerful postselection confidence
distributions. <em>SJOS</em>, <em>50</em>(1), 358–382. (<a
href="https://doi.org/10.1111/sjos.12581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A conditioning on the event of having selected one model from a set of possibly misspecified normal linear regression models leads to the construction of uniformly optimal conditional confidence distributions. They can be used for valid postselection inference. The constructed conditional confidence distributions are finite sample exact and encompass all information regarding the focus parameter in the selected model. This includes the construction of optimal postselection confidence intervals at all significance levels and uniformly most powerful hypothesis tests.},
  archive      = {J_SJOS},
  author       = {Andrea C. Garcia-Angulo and Gerda Claeskens},
  doi          = {10.1111/sjos.12581},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {358-382},
  shortjournal = {Scand. J. Statist.},
  title        = {Exact uniformly most powerful postselection confidence distributions},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nonparametric bounds for the survivor function under general
dependent truncation. <em>SJOS</em>, <em>50</em>(1), 327–357. (<a
href="https://doi.org/10.1111/sjos.12582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Truncation occurs in cohort studies with complex sampling schemes. When truncation is ignored or incorrectly assumed to be independent of the event time in the observable region, bias can result. We derive completely nonparametric bounds for the survivor function under truncation and censoring; these extend prior nonparametric bounds derived in the absence of truncation. We also define a hazard ratio function that links the unobservable region in which event time is less than truncation time, to the observable region in which event time is greater than truncation time, under dependent truncation. When this function can be bounded, and the probability of truncation is known approximately, it yields narrower bounds than the purely nonparametric bounds. Importantly, our approach targets the true marginal survivor function over its entire support, and is not restricted to the observable region, unlike alternative estimators. We evaluate the methods in simulations and in clinical applications.},
  archive      = {J_SJOS},
  author       = {Jing Qian and Rebecca A. Betensky},
  doi          = {10.1111/sjos.12582},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {327-357},
  shortjournal = {Scand. J. Statist.},
  title        = {Nonparametric bounds for the survivor function under general dependent truncation},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Approximate reference priors for gaussian random fields.
<em>SJOS</em>, <em>50</em>(1), 296–326. (<a
href="https://doi.org/10.1111/sjos.12577">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reference priors are theoretically attractive for the analysis of geostatistical data since they enable automatic Bayesian analysis and have desirable Bayesian and frequentist properties. But their use is hindered by computational hurdles that make their application in practice challenging. In this work, we derive a new class of default priors that approximate reference priors for the parameters of some Gaussian random fields. It is based on an approximation to the integrated likelihood of the covariance parameters derived from the spectral approximation of stationary random fields. This prior depends on the structure of the mean function and the spectral density of the model evaluated at a set of spectral points associated with an auxiliary regular grid. In addition to preserving the desirable Bayesian and frequentist properties, these approximate reference priors are more stable, and their computations are much less onerous than those of exact reference priors. Unlike exact reference priors, the marginal approximate reference prior of correlation parameter is always proper, regardless of the mean function or the smoothness of the correlation function. This property has important consequences for covariance model selection. An illustration comparing default Bayesian analyses is provided with a dataset of lead pollution in Galicia, Spain.},
  archive      = {J_SJOS},
  author       = {Victor De Oliveira and Zifei Han},
  doi          = {10.1111/sjos.12577},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {296-326},
  shortjournal = {Scand. J. Statist.},
  title        = {Approximate reference priors for gaussian random fields},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Minimax powerful functional analysis of covariance tests
with application to longitudinal genome-wide association studies.
<em>SJOS</em>, <em>50</em>(1), 266–295. (<a
href="https://doi.org/10.1111/sjos.12583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We model the Alzheimer&#39;s disease-related phenotype response variables observed on irregular time points in longitudinal Genome-Wide Association Studies as sparse functional data and propose nonparametric test procedures to detect functional genotype effects while controlling the confounding effects of environmental covariates. Our new functional analysis of covariance tests are based on a seemingly unrelated kernel smoother, which takes into account the within-subject temporal correlations, and thus enjoy improved power over existing functional tests. We show that the proposed test combined with a uniformly consistent nonparametric covariance function estimator enjoys the Wilks phenomenon and is minimax most powerful. Data used in the preparation of this article were obtained from the Alzheimer&#39;s Disease Neuroimaging Initiative database, where an application of the proposed test lead to the discovery of new genes that may be related to Alzheimer&#39;s disease.},
  archive      = {J_SJOS},
  author       = {Weicheng Zhu and Sheng Xu and Catherine C. Liu and Yehua Li},
  doi          = {10.1111/sjos.12583},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {266-295},
  shortjournal = {Scand. J. Statist.},
  title        = {Minimax powerful functional analysis of covariance tests with application to longitudinal genome-wide association studies},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiply robust matching estimators of average and quantile
treatment effects. <em>SJOS</em>, <em>50</em>(1), 235–265. (<a
href="https://doi.org/10.1111/sjos.12585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Propensity score matching has been a long-standing tradition for handling confounding in causal inference, however, requiring stringent model assumptions. In this article, we propose novel double score matching (DSM) utilizing both the propensity score and prognostic score. To gain the protection of possible model misspecification, we posit multiple candidate models for each score. We show that the debiasing DSM estimator achieves the multiple robustness property in that it is consistent if any one of the score models is correctly specified. We characterize the asymptotic distribution for the DSM estimator requiring only one correct model specification based on the martingale representations of the matching estimators and theory for local normal experiments. We also provide a two-stage replication method for variance estimation and extend DSM for quantile estimation. Simulation demonstrates DSM outperforms single-score matching and prevailing multiply robust weighting estimators in the presence of extreme propensity scores.},
  archive      = {J_SJOS},
  author       = {Shu Yang and Yunshu Zhang},
  doi          = {10.1111/sjos.12585},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {235-265},
  shortjournal = {Scand. J. Statist.},
  title        = {Multiply robust matching estimators of average and quantile treatment effects},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Flexible clustering via hidden hierarchical dirichlet
priors. <em>SJOS</em>, <em>50</em>(1), 213–234. (<a
href="https://doi.org/10.1111/sjos.12578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Bayesian approach to inference stands out for naturally allowing borrowing information across heterogeneous populations, with different samples possibly sharing the same distribution. A popular Bayesian nonparametric model for clustering probability distributions is the nested Dirichlet process, which however has the drawback of grouping distributions in a single cluster when ties are observed across samples. With the goal of achieving a flexible and effective clustering method for both samples and observations, we investigate a nonparametric prior that arises as the composition of two different discrete random structures and derive a closed-form expression for the induced distribution of the random partition, the fundamental tool regulating the clustering behavior of the model. On the one hand, this allows to gain a deeper insight into the theoretical properties of the model and, on the other hand, it yields an MCMC algorithm for evaluating Bayesian inferences of interest. Moreover, we single out limitations of this algorithm when working with more than two populations and, consequently, devise an alternative more efficient sampling scheme, which as a by-product, allows testing homogeneity between different populations. Finally, we perform a comparison with the nested Dirichlet process and provide illustrative examples of both synthetic and real data.},
  archive      = {J_SJOS},
  author       = {Antonio Lijoi and Igor Prünster and Giovanni Rebaudo},
  doi          = {10.1111/sjos.12578},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {213-234},
  shortjournal = {Scand. J. Statist.},
  title        = {Flexible clustering via hidden hierarchical dirichlet priors},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Penalized angular regression for personalized predictions.
<em>SJOS</em>, <em>50</em>(1), 184–212. (<a
href="https://doi.org/10.1111/sjos.12574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalization is becoming an important aspect of many predictive applications. We introduce a penalized regression method which inherently implements personalization. Personalized angle (PAN) regression constructs regression coefficients that are specific to the covariate vector for which one is producing a prediction, thus personalizing the regression model itself. This is achieved by penalizing the normalized prediction for a given covariate vector. The method therefore penalizes the normalized regression coefficients, or the angles of the regression coefficients in a hyperspherical parametrization, introducing a new angle-based class of penalties. PAN hence combines two novel concepts: penalizing the normalized coefficients and personalization. For an orthogonal design matrix, we show that the PAN estimator is the solution to a low-dimensional eigenvector equation. Based on the hyperspherical parametrization, we construct an efficient algorithm to calculate the PAN estimator. We propose a parametric bootstrap procedure for selecting the tuning parameter, and simulations show that PAN regression can outperform ordinary least squares, ridge regression and other penalized regression methods in terms of prediction error. Finally, we demonstrate the method in a medical application.},
  archive      = {J_SJOS},
  author       = {Kristoffer H. Hellton},
  doi          = {10.1111/sjos.12574},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {184-212},
  shortjournal = {Scand. J. Statist.},
  title        = {Penalized angular regression for personalized predictions},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Estimation for change point of discretely observed ergodic
diffusion processes. <em>SJOS</em>, <em>50</em>(1), 142–183. (<a
href="https://doi.org/10.1111/sjos.12567">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We treat the change point problem in ergodic diffusion processes from discrete observations. Tonakiet al.(2021a) proposed adaptive tests for detecting changes in the diffusion and drift parameters in ergodic diffusion process models. When any change in the diffusion or drift parameter is detected by this or any other method, the next question to consider is where the change point is located. Therefore, we propose the method to estimate the change point of the parameter for two cases: the case where there is a change in the diffusion parameter, and the case where there is no change in the diffusion parameter but a change in the drift parameter. Furthermore, we present rates of convergence and distributional results of the change point estimators. Some examples and simulation results are also given.},
  archive      = {J_SJOS},
  author       = {Yozo Tonaki and Yusuke Kaino and Masayuki Uchida},
  doi          = {10.1111/sjos.12567},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {142-183},
  shortjournal = {Scand. J. Statist.},
  title        = {Estimation for change point of discretely observed ergodic diffusion processes},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning the two parameters of the poisson–dirichlet
distribution with a forensic application. <em>SJOS</em>, <em>50</em>(1),
120–141. (<a href="https://doi.org/10.1111/sjos.12575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In forensic science, the rare type match problem arises when the matching characteristic from the suspect and the crime scene is not in the reference database; hence, it is difficult to evaluate the likelihood ratio that compares the defense and prosecution hypotheses. A recent solution consists of modeling the ordered population probabilities according to the two-parameter Poisson–Dirichlet distribution, which is a well-known Bayesian nonparametric prior, and plugging the maximum likelihood estimates of the parameters into the likelihood ratio. We demonstrate that this approximation produces a systematic bias that fully Bayesian inference avoids. Motivated by this forensic application, we consider the need to learn the posterior distribution of the parameters that governs the two-parameter Poisson–Dirichlet using two sampling methods: Markov Chain Monte Carlo and approximate Bayesian computation. These methods are evaluated in terms of accuracy and efficiency. Finally, we compare the likelihood ratio that is obtained by our proposal with the existing solution using a database of Y-chromosome haplotypes.},
  archive      = {J_SJOS},
  author       = {Giulia Cereda and Fabio Corradi and Cecilia Viscardi},
  doi          = {10.1111/sjos.12575},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {120-141},
  shortjournal = {Scand. J. Statist.},
  title        = {Learning the two parameters of the Poisson–Dirichlet distribution with a forensic application},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spectral analysis of markov switching GARCH models with
statistical inference. <em>SJOS</em>, <em>50</em>(1), 102–119. (<a
href="https://doi.org/10.1111/sjos.12571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We derive matrix expressions in closed form for the autocovariance function and the spectral density of Markov switching GARCH models and their powers. For this, we apply the Riesz–Fischer theorem which defines the spectral representation as the Fourier transform of the autocovariance function. Under suitable assumptions, we prove that the sample estimator of the spectral density is consistent and asymptotically normally distributed. Further statistical implications in terms of order identification and parameter estimation are discussed. A simulation study confirms the validity of the asymptotic properties. These methods are also well suited for financial market applications, and in particular for the analysis of time series in the frequency domain, as shown in some proposed real-world examples.},
  archive      = {J_SJOS},
  author       = {Maddalena Cavicchioli},
  doi          = {10.1111/sjos.12571},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {102-119},
  shortjournal = {Scand. J. Statist.},
  title        = {Spectral analysis of markov switching GARCH models with statistical inference},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Remove unwanted variation retrieves unknown experimental
designs. <em>SJOS</em>, <em>50</em>(1), 89–101. (<a
href="https://doi.org/10.1111/sjos.12633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remove unwanted variation (RUV) is an estimation and normalization system in which the underlying correlation structure of a multivariate dataset is estimated from negative control measurements, typically gene expression values, which are assumed to stay constant across experimental conditions. In this paper we derive the weight matrix which is estimated and incorporated into the generalized least squares estimates of RUV-inverse, and show that this weight matrix estimates the average covariance matrix across negative control measurements. RUV-inverse can thus be viewed as an estimation method adjusting for an unknown experimental design. We show that for a balanced incomplete block design (BIBD), RUV-inverse recovers intra- and interblock estimates of the relevant parameters and combines them as a weighted sum just like the best linear unbiased estimator (BLUE), except that the weights are globally estimated from the negative control measurements instead of being individually optimized to each measurement as in the classical, single measurement BIBD BLUE.},
  archive      = {J_SJOS},
  author       = {Ingrid M. Lönnstedt and Terence P. Speed},
  doi          = {10.1111/sjos.12633},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {89-101},
  shortjournal = {Scand. J. Statist.},
  title        = {Remove unwanted variation retrieves unknown experimental designs},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Divergence versus decision p-values: A distinction worth
making in theory and keeping in practice: Or, how divergence p-values
measure evidence even when decision p-values do not. <em>SJOS</em>,
<em>50</em>(1), 54–88. (<a
href="https://doi.org/10.1111/sjos.12625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are two distinct definitions of “P-value” for evaluating a proposed hypothesis or model for the process generating an observed dataset. The original definition starts with a measure of the divergence of the dataset from what was expected under the model, such as a sum of squares or a deviance statistic. AP-value is then the ordinal location of the measure in a reference distribution computed from the model and the data, and is treated as a unit-scaled index of compatibility between the data and the model. In the other definition, aP-value is a random variable on the unit interval whose realizations can be compared to a cutoff α to generate a decision rule with known error rates under the model and specific alternatives. It is commonly assumed that realizations of such decisionP-values always correspond to divergenceP-values. But this need not be so: DecisionP-values can violate intuitive single-sample coherence criteria where divergenceP-values do not. It is thus argued that divergence and decisionP-values should be carefully distinguished in teaching, and that divergenceP-values are the relevant choice when the analysis goal is to summarize evidence rather than implement a decision rule.},
  archive      = {J_SJOS},
  author       = {Sander Greenland},
  doi          = {10.1111/sjos.12625},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {54-88},
  shortjournal = {Scand. J. Statist.},
  title        = {Divergence versus decision P-values: a distinction worth making in theory and keeping in practice: or, how divergence P-values measure evidence even when decision P-values do not},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Approximate exchangeability and de finetti priors in 2022.
<em>SJOS</em>, <em>50</em>(1), 38–53. (<a
href="https://doi.org/10.1111/sjos.12609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This is a review paper, beginning with de Finetti&#39;s work on partial exchangeability, continuing with his approach to approximate exchangeability, and then his (surprising) approach to assigning informative priors in nonstandard situations. Recent progress on Markov chain Monte Carlo methods for drawing conclusions is supplemented by a review of work by Gerencsér and Ottolini on getting honest bounds for rates of convergence. The paper concludes with a speculative approach to combining classical asymptotics with Monte Carlo. This promises real speed-ups and makes a nice example of how theory and computation can interact.},
  archive      = {J_SJOS},
  author       = {Persi Diaconis},
  doi          = {10.1111/sjos.12609},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {38-53},
  shortjournal = {Scand. J. Statist.},
  title        = {Approximate exchangeability and de finetti priors in 2022},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Use of multiple imputation in supersampled nested
case-control and case-cohort studies. <em>SJOS</em>, <em>50</em>(1),
13–37. (<a href="https://doi.org/10.1111/sjos.12624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nested case-control and case-cohort studies are useful for studying associations between covariates and time-to-event when some covariates are expensive to measure. Full covariate information is collected in the nested case-control or case-cohort sample only, while cheaply measured covariates are often observed for the full cohort. Standard analysis of such case-control samples ignores any full cohort data. Previous work has shown how data for the full cohort can be used efficiently by multiple imputation of the expensive covariate(s), followed by a full-cohort analysis. For large cohorts this is computationally expensive or even infeasible. An alternative is to supplement the case-control samples with additional controls on which cheaply measured covariates are observed. We show how multiple imputation can be used for analysis of such supersampled data. Simulations show that this brings efficiency gains relative to a traditional analysis and that the efficiency loss relative to using the full cohort data is not substantial.},
  archive      = {J_SJOS},
  author       = {Ørnulf Borgan and Ruth H. Keogh and Aleksander Njøs},
  doi          = {10.1111/sjos.12624},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {13-37},
  shortjournal = {Scand. J. Statist.},
  title        = {Use of multiple imputation in supersampled nested case-control and case-cohort studies},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A conversation with elja arjas (helsinki, november 2021 and
march 2022). <em>SJOS</em>, <em>50</em>(1), 3–12. (<a
href="https://doi.org/10.1111/sjos.12612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Statistics as an independent scientific discipline is relatively young in Finland. Its active history stretches back roughly a century, with the past 50 years signifying a period of growth. Few other academics such as Elja Arjas, now professor emeritus at University of Helsinki, have played a prominent role in establishing statistics in Finland. This conversation tries to illuminate how this came to happen and what was needed to push statistics as a discipline to a firmer ground. We do not have a looking glass at our disposal but will nevertheless also try make some predictions about the future.},
  archive      = {J_SJOS},
  author       = {Jukka Corander},
  doi          = {10.1111/sjos.12612},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {3-12},
  shortjournal = {Scand. J. Statist.},
  title        = {A conversation with elja arjas (Helsinki, november 2021 and march 2022)},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Professor elja arjas: A prominent figure in establishing
statistics in finland. <em>SJOS</em>, <em>50</em>(1), 1–2. (<a
href="https://doi.org/10.1111/sjos.12631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SJOS},
  author       = {Sangita Kulathinal and Jaakko Peltonen and Mikko J. Sillanpää},
  doi          = {10.1111/sjos.12631},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Scand. J. Statist.},
  title        = {Professor elja arjas: A prominent figure in establishing statistics in finland},
  volume       = {50},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
