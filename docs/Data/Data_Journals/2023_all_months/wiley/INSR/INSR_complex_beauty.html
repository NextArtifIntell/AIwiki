<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>INSR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="insr---29">INSR - 29</h2>
<ul>
<li><details>
<summary>
(2023). Mixed-effects models and small area estimation shonosuke
sugasawa and tatsuya kubokava springer nature, 2023, viii + 121 pages,
£39.99, paperback ISBN: 978-981-19-9485-2. <em>INSR</em>,
<em>91</em>(3), 536. (<a
href="https://doi.org/10.1111/insr.12560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Tapio Nummi},
  doi          = {10.1111/insr.12560},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {536},
  shortjournal = {Int. Stat. Rev.},
  title        = {Mixed-effects models and small area estimation shonosuke sugasawa and tatsuya kubokava springer nature, 2023, viii + 121 pages, £39.99, paperback ISBN: 978-981-19-9485-2},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Statistical methods for climate scientists timothy m.
DelSole and michael k. Tippett cambridge university press, 2022, 542
pages, £54.99, hardcover ISBN: 9781108472418. <em>INSR</em>,
<em>91</em>(3), 535. (<a
href="https://doi.org/10.1111/insr.12559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Fabrizio Durante},
  doi          = {10.1111/insr.12559},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {535},
  shortjournal = {Int. Stat. Rev.},
  title        = {Statistical methods for climate scientists timothy m. DelSole and michael k. tippett cambridge university press, 2022, 542 pages, £54.99, hardcover ISBN: 9781108472418},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). New randomised response models for two sensitive
characteristics: Theory and application. <em>INSR</em>, <em>91</em>(3),
511–534. (<a href="https://doi.org/10.1111/insr.12555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce two new randomised response models for estimating the prevalence of two sensitive characteristics and their overlap in a population by making use of a single deck of cards. The proposed models ensure the privacy of the respondents and also reduce the burden on the respondents as they require the random selection of only one card from a deck of cards each of which contains a pair of questions that are to be answered in order. The variance expressions of the proposed estimators are derived and matched to their Cramer–Rao lower bounds of variances. A simulation study has been carried out to compare the proposed models to each other for least protection. Lastly, a real survey application, related to the acceptability of the vaccines produced by Pfizer and Moderna is included. We had findings in Summer 2021 similar to those of the Harvard Study done in December 2021, which was based on a half-million data values, that shows the cost effectiveness of the survey design.},
  archive      = {J_INSR},
  author       = {Daryan Naatjes and Stephen A. Sedory and Sarjinder Singh},
  doi          = {10.1111/insr.12555},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {511-534},
  shortjournal = {Int. Stat. Rev.},
  title        = {New randomised response models for two sensitive characteristics: Theory and application},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A spatial variance-smoothing area level model for small area
estimation of demographic rates. <em>INSR</em>, <em>91</em>(3), 493–510.
(<a href="https://doi.org/10.1111/insr.12556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate estimates of subnational health and demographic indicators are critical for informing policy. Many countries collect relevant data using complex household surveys, but when data are limited, direct weighted estimates of small area proportions may be unreliable. Area level models treating these direct estimates as response data can improve precision but often require known sampling variances of the direct estimators for all areas. In practice, the sampling variances are estimated, so standard approaches do not account for a key source of uncertainty. To account for variability in the estimated sampling variances, we propose a hierarchical Bayesian spatial area level model for small area proportions that smooths both the estimated proportions and sampling variances to produce point and interval estimates of rates of interest. We demonstrate the performance of our approach via simulation and application to vaccination coverage and HIV prevalence data from the Demographic and Health Surveys.},
  archive      = {J_INSR},
  author       = {Peter A. Gao and Jonathan Wakefield},
  doi          = {10.1111/insr.12556},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {493-510},
  shortjournal = {Int. Stat. Rev.},
  title        = {A spatial variance-smoothing area level model for small area estimation of demographic rates},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of data-driven discovery for dynamic systems.
<em>INSR</em>, <em>91</em>(3), 464–492. (<a
href="https://doi.org/10.1111/insr.12554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world scientific processes are governed by complex non-linear dynamic systems that can be represented by differential equations. Recently, there has been an increased interest in learning, or discovering, the forms of the equations driving these complex non-linear dynamic systems using data-driven approaches. In this paper, we review the current literature on data-driven discovery for dynamic systems. We provide a categorisation to the different approaches for data-driven discovery and a unified mathematical framework to show the relationship between the approaches. Importantly, we discuss the role of statistics in the data-driven discovery field, describe a possible approach by which the problem can be cast in a statistical framework and provide avenues for future work.},
  archive      = {J_INSR},
  author       = {Joshua S. North and Christopher K. Wikle and Erin M. Schliep},
  doi          = {10.1111/insr.12554},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {464-492},
  shortjournal = {Int. Stat. Rev.},
  title        = {A review of data-driven discovery for dynamic systems},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal treatment regimes: A review and empirical
comparison. <em>INSR</em>, <em>91</em>(3), 427–463. (<a
href="https://doi.org/10.1111/insr.12536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A treatment regime is a sequence of decision rules, one per decision point, that maps accumulated patient information to a recommended intervention. An optimal treatment regime maximises expected cumulative utility if applied to select interventions in a population of interest. As a treatment regime seeks to improve the quality of healthcare by individualising treatment, it can be viewed as an approach to formalising precision medicine. Increased interest and investment in precision medicine has led to a surge of methodological research focusing on estimation and evaluation of optimal treatment regimes from observational and/or randomised studies. These methods are becoming commonplace in biomedical research, although guidance about how to choose among existing methods in practice has been somewhat limited. The purpose of this review is to describe some of the most commonly used methods for estimation of an optimal treatment regime, and to compare these estimators in a series of simulation experiments and applications to real data. The results of these simulations along with the theoretical/methodological properties of these estimators are used to form recommendations for applied researchers.},
  archive      = {J_INSR},
  author       = {Zhen Li and Jie Chen and Eric Laber and Fang Liu and Richard Baumgartner},
  doi          = {10.1111/insr.12536},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {427-463},
  shortjournal = {Int. Stat. Rev.},
  title        = {Optimal treatment regimes: A review and empirical comparison},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online evidential nearest neighbour classification for
internet of things time series. <em>INSR</em>, <em>91</em>(3), 395–426.
(<a href="https://doi.org/10.1111/insr.12540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ‘Internet of Things’ (IoT) is a rapidly developing set of technologies that leverages large numbers of networked sensors, to relay data in an online fashion. Typically, knowledge of the sensor environment is incomplete and subject to changes over time. There is a need to employ classification algorithms to understand the data. We first review of existing time series classification (TSC) approaches, with emphasis on the well-known k -nearest neighbours ( k NN) methods. We extend these to dynamical k NN classifiers, and discuss their shortcomings for handling the inherent uncertainty in IoT data. We next review evidential k NN ( E ⁢ k NN ) classifiers that leverage the well-known Dempster–Shafer theory to allow principled uncertainty quantification. We develop a dynamic E ⁢ k NN approach for classifying IoT streams via algorithms that use evidential theoretic pattern rejection rules for (i) classifying incoming patterns into a set of oracle classes, (ii) automatically pruning ambiguously labelled patterns such as aberrant streams (due to malfunctioning sensors, say), and (iii) identifying novel classes that may emerge in new subsequences over time. While these methods have wide applicability in many domains, we illustrate the dynamic and approaches for classifying a large, noisy IoT time series dataset from an insurance firm.},
  archive      = {J_INSR},
  author       = {Patrick Toman and Nalini Ravishanker and Sanguthevar Rajasekaran and Nathan Lally},
  doi          = {10.1111/insr.12540},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {395-426},
  shortjournal = {Int. Stat. Rev.},
  title        = {Online evidential nearest neighbour classification for internet of things time series},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving probabilistic record linkage using statistical
prediction models. <em>INSR</em>, <em>91</em>(3), 368–394. (<a
href="https://doi.org/10.1111/insr.12535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Record linkage brings together information from records in two or more data sources that are believed to belong to the same statistical unit based on a common set of matching variables. Matching variables, however, can appear with errors and variations and the challenge is to link statistical units that are subject to error. We provide an overview of record linkage techniques and specifically investigate the classic Fellegi and Sunter probabilistic record linkage framework to assess whether the decision rule for classifying pairs into sets of matches and non-matches can be improved by incorporating a statistical prediction model. We also study whether the enhanced linkage rule can provide better results in terms of preserving associations between variables in the linked data file that are not used in the matching procedure. A simulation study and an application based on real data are used to evaluate the methods.},
  archive      = {J_INSR},
  author       = {Angelo Moretti and Natalie Shlomo},
  doi          = {10.1111/insr.12535},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {368-394},
  shortjournal = {Int. Stat. Rev.},
  title        = {Improving probabilistic record linkage using statistical prediction models},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interview with adrian raftery. <em>INSR</em>,
<em>91</em>(3), 349–367. (<a
href="https://doi.org/10.1111/insr.12557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Professor Adrian E. Raftery is the Boeing International Professor of Statistics and Sociology and an adjunct professor of Atmospheric Sciences at the University of Washington in Seattle. He was born in Dublin, Ireland, and obtained a BA in Mathematics (1976) and an MSc in Statistics and Operations Research (1977) at Trinity College Dublin. He obtained a doctorate in mathematical statistics in 1980 from the Université Pierre et Marie Curie in Paris, France, under the supervision of Paul Deheuvels. He was a lecturer in statistics at Trinity College Dublin from 1980 to 1986, and then an associate (1986–1990) and full (1990-present) professor of statistics and sociology at the University of Washington. He was the founding Director of the Center for Statistics and Social Sciences (1999–2009). Professor Raftery has published over 200 articles in peer-reviewed statistical, sociological and other journals. His research focuses on Bayesian model selection and Bayesian model averaging, model-based clustering, inference for deterministic simulation models, and the development of new statistical methods for demography, sociology, and the environmental and health sciences. He is a member of the United States National Academy of Sciences, a Fellow of the American Academy of Arts and Sciences, an Honorary Member of the Royal Irish Academy, a member of the Washington State Academy of Sciences, a Fellow of the American Statistical Association, a Fellow of the Institute of Mathematical Statistics, and an elected Member of the Sociological Research Association. He has won the Population Association of America&#39;s Clifford C. Clogg Award, the American Sociological Association&#39;s Paul F. Lazarsfeld Award for Distinguished Contribution to Knowledge, the Jerome Sacks Award for Outstanding Cross-Disciplinary Research from the National Institute of Statistical Sciences, the Parzen Prize for Statistical Innovation, and the Science Foundation Ireland St. Patrick&#39;s Day Medal. He is also a former Coordinating and Applications Editor of the Journal of the American Statistical Association and a former Editor of Sociological Methodology. He was identified as the world&#39;s most cited researcher in mathematics for the decade 1995–2005 by Thomson-ISI. Thirty-three students have obtained PhD&#39;s working under Raftery&#39;s supervision, of whom 21 hold or have held tenure-track university faculty positions. He has over 150 academic descendants. This interview took place over two sessions in March 2023.},
  archive      = {J_INSR},
  author       = {Leontine Alkema and Thomas Brendan Murphy and Adrian E. Raftery},
  doi          = {10.1111/insr.12557},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {349-367},
  shortjournal = {Int. Stat. Rev.},
  title        = {Interview with adrian raftery},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). <em>INSR</em>, <em>91</em>(2), 348. (<a
href="https://doi.org/10.1111/insr.12550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Fabrizio Durante},
  doi          = {10.1111/insr.12550},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {348},
  shortjournal = {Int. Stat. Rev.},
  title        = {Number savvy: From the invention of numbers to the future of data george sciadas chapman &amp; Hall/CRC, 2022, 312 pages, £56.99/$74.95, hardcover ISBN 9781032362151},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data conscience: Algorithmic siege on our humanity brandeis
hill marshall wiley, 2022, xxv + 326 pages, paperback £30.99 ISBN:
978-1-119-82118-2. <em>INSR</em>, <em>91</em>(2), 347–348. (<a
href="https://doi.org/10.1111/insr.12549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Debashis Ghosh},
  doi          = {10.1111/insr.12549},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {347-348},
  shortjournal = {Int. Stat. Rev.},
  title        = {Data conscience: algorithmic siege on our humanity brandeis hill marshall wiley, 2022, xxv + 326 pages, paperback £30.99 ISBN: 978-1-119-82118-2},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). <em>INSR</em>, <em>91</em>(2), 345–347. (<a
href="https://doi.org/10.1111/insr.12548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Shuangzhe Liu},
  doi          = {10.1111/insr.12548},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {345-347},
  shortjournal = {Int. Stat. Rev.},
  title        = {Modern applied regressions: bayesian and frequentist analysis of categorical and limited response variables with r and stan jun xu chapman &amp; Hall/CRC, 2023, xv + 281 pages, £80.99/$108, hardcover ISBN: 9780367173876 (hbk); 9781032376745 (pbk); 9780429056468 (ebk)},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). <em>INSR</em>, <em>91</em>(2), 343–345. (<a
href="https://doi.org/10.1111/insr.12547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Brian W. Sloboda},
  doi          = {10.1111/insr.12547},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {343-345},
  shortjournal = {Int. Stat. Rev.},
  title        = {The effect: an introduction to research design and causality nick huntington-klein chapman &amp; Hall/CRC, 2022, xiv + 620 pages, $39.95, paperback. ISBN: 9781032125787},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A statistical review of template model builder: A flexible
tool for spatial modelling. <em>INSR</em>, <em>91</em>(2), 318–342. (<a
href="https://doi.org/10.1111/insr.12534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integrated nested Laplace approximation (INLA) is a well-known and popular technique for spatial modelling with a user-friendly interface in the R-INLA package. Unfortunately, only a certain class of latent Gaussian models are amenable to fitting with INLA. In this paper, we review template model builder ( TMB ), an existing technique and software package which is well-suited to fitting complex spatio-temporal models. TMB is relatively unknown to the spatial statistics community, but it is a flexible random effects modelling tool which allows users to define customizable and complex mixed effects models through C++ templates. After contrasting the methodology behind TMB with INLA, we provide a large-scale simulation study assessing and comparing R-INLA and TMB for continuous spatial models, fitted via the stochastic partial differential equations (SPDE) approximation. The results show that the predictive fields from both methods are comparable in most situations even though TMB estimates for fixed or random effects may have slightly larger bias than R-INLA . We also present a smaller discrete spatial simulation study, in which both approaches perform well. We conclude with a joint analysis of breast cancer incidence and mortality data implemented in TMB which requires a model which cannot be fit with R-INLA .},
  archive      = {J_INSR},
  author       = {Aaron Osgood-Zimmerman and Jon Wakefield},
  doi          = {10.1111/insr.12534},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {318-342},
  shortjournal = {Int. Stat. Rev.},
  title        = {A statistical review of template model builder: A flexible tool for spatial modelling},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A bootstrap variance procedure for the generalised
regression estimator. <em>INSR</em>, <em>91</em>(2), 294–317. (<a
href="https://doi.org/10.1111/insr.12528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generalised regression estimator (GREG) uses auxiliary data that are available from the finite population to improve the efficiency of the estimator of a total (mean). Estimators of the variance of GREG that have been proposed in the sampling literature include those based on Taylor linearisation and the jackknife techniques. Approximations based on Taylor expansions are reasonable for large samples. However, when the sample size is small, the Taylor-based variance estimator has a large negative bias. The jackknife variance estimators overestimate the variance of GREG for small sample sizes. We offset these setbacks using a bootstrap procedure for estimating the variance of the GREG. The method uses a bootstrap population constructed with the model underlying the GREG estimator. Repeated samples are selected in the bootstrap population according to the design used to select the initial sample, and the variability associated with these bootstrap samples is used to compute the proposed bootstrap variance estimator. Simulations show that the new bootstrap estimator has a small bias for samples that have few observations.},
  archive      = {J_INSR},
  author       = {Marius Stefan and Michael A. Hidiroglou},
  doi          = {10.1111/insr.12528},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {294-317},
  shortjournal = {Int. Stat. Rev.},
  title        = {A bootstrap variance procedure for the generalised regression estimator},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accounting for non-ignorable sampling and non-response in
statistical matching. <em>INSR</em>, <em>91</em>(2), 269–293. (<a
href="https://doi.org/10.1111/insr.12524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data for statistical analysis is often available from different samples, with each sample containing measurements on only some of the variables of interest. Statistical matching attempts to generate a fused database containing matched measurements on all the target variables. In this article, we consider the use of statistical matching when the samples are drawn by informative sampling designs and are subject to not missing at random non-response. The problem with ignoring the sampling process and non-response is that the distribution of the data observed for the responding units can be very different from the distribution holding for the population data, which may distort the inference process and result in a matched database that misrepresents the joint distribution in the population. Our proposed methodology employs the empirical likelihood approach and is shown to perform well in a simulation experiment and when applied to real sample data.},
  archive      = {J_INSR},
  author       = {Daniela Marella and Danny Pfeffermann},
  doi          = {10.1111/insr.12524},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {269-293},
  shortjournal = {Int. Stat. Rev.},
  title        = {Accounting for non-ignorable sampling and non-response in statistical matching},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ABC of the future. <em>INSR</em>, <em>91</em>(2), 243–268.
(<a href="https://doi.org/10.1111/insr.12522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximate Bayesian computation (ABC) has advanced in two decades from a seminal idea to a practically applicable inference tool for simulator-based statistical models, which are becoming increasingly popular in many research domains. The computational feasibility of ABC for practical applications has been recently boosted by adopting techniques from machine learning to build surrogate models for the approximate likelihood or posterior and by the introduction of a general-purpose software platform with several advanced features, including automated parallelisation. Here we demonstrate the strengths of the advances in ABC by going beyond the typical benchmark examples and considering real applications in astronomy, infectious disease epidemiology, personalised cancer therapy and financial prediction. We anticipate that the emerging success of ABC in producing actual added value and quantitative insights in the real world will continue to inspire a plethora of further applications across different fields of science, social science and technology.},
  archive      = {J_INSR},
  author       = {Henri Pesonen and Umberto Simola and Alvaro Köhn-Luque and Henri Vuollekoski and Xiaoran Lai and Arnoldo Frigessi and Samuel Kaski and David T. Frazier and Worapree Maneesoonthorn and Gael M. Martin and Jukka Corander},
  doi          = {10.1111/insr.12522},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {243-268},
  shortjournal = {Int. Stat. Rev.},
  title        = {ABC of the future},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Path algorithms for fused lasso signal approximator with
application to COVID-19 spread in korea. <em>INSR</em>, <em>91</em>(2),
218–242. (<a href="https://doi.org/10.1111/insr.12521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fused lasso signal approximator (FLSA) is a smoothing procedure for noisy observations that uses fused lasso penalty on unobserved mean levels to find sparse signal blocks. Several path algorithms have been developed to obtain the whole solution path of the FLSA. However, it is known that the FLSA has model selection inconsistency when the underlying signals have a stair-case block, where three consecutive signal blocks are either strictly increasing or decreasing. Modified path algorithms for the FLSA have been proposed to guarantee model selection consistency regardless of the stair-case block. In this paper, we provide a comprehensive review of the path algorithms for the FLSA and prove the properties of the recently modified path algorithms&#39; hitting times. Specifically, we reinterpret the modified path algorithm as the path algorithm for local FLSA problems and reveal the condition that the hitting time for the fusion of the modified path algorithm is not monotone in a tuning parameter. To recover the monotonicity of the solution path, we propose a pathwise adaptive FLSA having monotonicity with similar performance as the modified solution path algorithm. Finally, we apply the proposed method to the number of daily-confirmed cases of COVID-19 in Korea to identify the change points of its spread.},
  archive      = {J_INSR},
  author       = {Won Son and Johan Lim and Donghyeon Yu},
  doi          = {10.1111/insr.12521},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {218-242},
  shortjournal = {Int. Stat. Rev.},
  title        = {Path algorithms for fused lasso signal approximator with application to COVID-19 spread in korea},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simultaneous inference for linear mixed model parameters
with an application to small area estimation. <em>INSR</em>,
<em>91</em>(2), 193–217. (<a
href="https://doi.org/10.1111/insr.12519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decades, linear mixed models have attracted considerable attention in various fields of applied statistics. They are popular whenever clustered, hierarchical or longitudinal data are investigated. Nonetheless, statistical tools for valid simultaneous inference for mixed parameters are rare. This is surprising because one often faces inferential problems beyond the pointwise examination of fixed or mixed parameters. For example, there is an interest in a comparative analysis of cluster-level parameters or subject-specific estimates in studies with repeated measurements. We discuss methods for simultaneous inference assuming a linear mixed model. Specifically, we develop simultaneous prediction intervals as well as multiple testing procedures for mixed parameters. They are useful for joint considerations or comparisons of cluster-level parameters. We employ a consistent bootstrap approximation of the distribution of max-type statistic to construct our tools. The numerical performance of the developed methodology is studied in simulation experiments and illustrated in a data example on household incomes in small areas.},
  archive      = {J_INSR},
  author       = {Katarzyna Reluga and María-José Lombardía and Stefan Sperlich},
  doi          = {10.1111/insr.12519},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {193-217},
  shortjournal = {Int. Stat. Rev.},
  title        = {Simultaneous inference for linear mixed model parameters with an application to small area estimation},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Calibration techniques encompassing survey sampling, missing
data analysis and causal inference. <em>INSR</em>, <em>91</em>(2),
165–192. (<a href="https://doi.org/10.1111/insr.12518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a critical review on calibration methods developed in three different areas: survey sampling, missing data analysis and causal inference. We highlight the connections and variations of calibration techniques used in missing data analysis and causal inference to conventional calibration weighting and estimation in survey sampling and provide a common framework through model-calibration and empirical likelihood to unify different calibration methods proposed in recent literature. The goal is to demonstrate the success and effectiveness of calibration methods in achieving some highly desired properties for missing data analysis and causal inference.},
  archive      = {J_INSR},
  author       = {Shixiao Zhang and Peisong Han and Changbao Wu},
  doi          = {10.1111/insr.12518},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {165-192},
  shortjournal = {Int. Stat. Rev.},
  title        = {Calibration techniques encompassing survey sampling, missing data analysis and causal inference},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Social networks: Modelling and analysis niyati aggrawal and
adarsh anand CRC press, 2022, xvii + 235 pages, hardcover (<span
class="math inline">170); <em>e</em> − <em>b</em><em>o</em><em>o</em><em>k</em>(</span><!-- -->44.21).
ISBN: 978-0-367-54139-2 (hardcover), 978-0-367-54173-6 (paperback),
978-1-003-08806-6 (e-book). <em>INSR</em>, <em>91</em>(1), 162–164. (<a
href="https://doi.org/10.1111/insr.12538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Arindam Sengupta},
  doi          = {10.1111/insr.12538},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {162-164},
  shortjournal = {Int. Stat. Rev.},
  title        = {Social networks: modelling and analysis niyati aggrawal and adarsh anand CRC press, 2022, xvii + 235 pages, hardcover ($170); e-book ($44.21). ISBN: 978-0-367-54139-2 (hardcover), 978-0-367-54173-6 (paperback), 978-1-003-08806-6 (e-book)},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A computational perspective on projection pursuit in high
dimensions: Feasible or infeasible feature extraction. <em>INSR</em>,
<em>91</em>(1), 140–161. (<a
href="https://doi.org/10.1111/insr.12517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding a suitable representation of multivariate data is fundamental in many scientific disciplines. Projection pursuit ( PP ) aims to extract interesting ‘non-Gaussian’ features from multivariate data, and tends to be computationally intensive even when applied to data of low dimension. In high-dimensional settings, a recent work (Bickel et al., 2018) on PP addresses asymptotic characterization and conjectures of the feasible projections as the dimension grows with sample size. To gain practical utility of and learn theoretical insights into PP in an integral way, data analytic tools needed to evaluate the behaviour of PP in high dimensions become increasingly desirable but are less explored in the literature. This paper focuses on developing computationally fast and effective approaches central to finite sample studies for (i) visualizing the feasibility of in extracting features from high-dimensional data, as compared with alternative methods like and , and (ii) assessing the plausibility of in cases where asymptotic studies are lacking or unavailable, with the goal of better understanding the practicality, limitation and challenge of in the analysis of large data sets.},
  archive      = {J_INSR},
  author       = {Chunming Zhang and Jimin Ye and Xiaomei Wang},
  doi          = {10.1111/insr.12517},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {140-161},
  shortjournal = {Int. Stat. Rev.},
  title        = {A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Are you all normal? It depends! <em>INSR</em>,
<em>91</em>(1), 114–139. (<a
href="https://doi.org/10.1111/insr.12512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The assumption of normality has underlain much of the development of statistics, including spatial statistics, and many tests have been proposed. In this work, we focus on the multivariate setting and first review the recent advances in multivariate normality tests for i.i.d. data, with emphasis on the skewness and kurtosis approaches. We show through simulation studies that some of these tests cannot be used directly for testing normality of spatial data. We further review briefly the few existing univariate tests under dependence (time or space), and then propose a new multivariate normality test for spatial data by accounting for the spatial dependence. The new test utilises the union-intersection principle to decompose the null hypothesis into intersections of univariate normality hypotheses for projection data, and it rejects the multivariate normality if any individual hypothesis is rejected. The individual hypotheses for univariate normality are conducted using a Jarque–Bera type test statistic that accounts for the spatial dependence in the data. We also show in simulation studies that the new test has a good control of the type I error and a high empirical power, especially for large sample sizes. We further illustrate our test on bivariate wind data over the Arabian Peninsula.},
  archive      = {J_INSR},
  author       = {Wanfang Chen and Marc G. Genton},
  doi          = {10.1111/insr.12512},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {114-139},
  shortjournal = {Int. Stat. Rev.},
  title        = {Are you all normal? it depends!},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scalable bayesian multiple changepoint detection via
auxiliary uniformisation. <em>INSR</em>, <em>91</em>(1), 88–113. (<a
href="https://doi.org/10.1111/insr.12511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we perform a sparse filtering recursion for efficient changepoint detection for discrete-time observations. We attach auxiliary event times to the chronologically ordered observations and formulate multiple changepoint problems of discrete-time observations into continuous-time observations. Ideally, both the computational and memory costs of the proposed auxiliary uniformisation forward-filtering backward-sampling algorithm can be quadratically scaled down to the number of changepoints instead of the number of observations, which would otherwise be prohibitive for a long sequence of observations. To avoid model bias, a time-varying changepoint recurrence rate across different segments is assumed to characterise diverse scales of run lengths of the changepoints. We demonstrate the methods through simulation studies and real data analysis.},
  archive      = {J_INSR},
  author       = {Lu Shaochuan},
  doi          = {10.1111/insr.12511},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {88-113},
  shortjournal = {Int. Stat. Rev.},
  title        = {Scalable bayesian multiple changepoint detection via auxiliary uniformisation},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Survival modelling for data from combined cohorts: Opening
the door to meta survival analyses and survival analysis using
electronic health records. <em>INSR</em>, <em>91</em>(1), 72–87. (<a
href="https://doi.org/10.1111/insr.12510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-parametric estimation of the survival function using observed failure time data depends on the underlying data generating mechanism, including the ways in which the data may be censored and/or truncated. For data arising from a single source or collected from a single cohort, a wide range of estimators have been proposed and compared in the literature. Often, however, it may be possible, and indeed advantageous, to combine and then analyse survival data that have been collected under different study designs. We review non-parametric survival analysis for data obtained by combining the most common types of cohort. We have two main goals: (i) to clarify the differences in the model assumptions and (ii) to provide a single lens through which some of the proposed estimators may be viewed. Our discussion is relevant to the meta-analysis of survival data obtained from different types of study, and to the modern era of electronic health records.},
  archive      = {J_INSR},
  author       = {James H. McVittie and Ana F. Best and David B. Wolfson and David A. Stephens and Julian Wolfson and David L. Buckeridge and Shahinaz M. Gadalla},
  doi          = {10.1111/insr.12510},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {72-87},
  shortjournal = {Int. Stat. Rev.},
  title        = {Survival modelling for data from combined cohorts: Opening the door to meta survival analyses and survival analysis using electronic health records},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diagnostic tests for the necessity of weight in regression
with survey data. <em>INSR</em>, <em>91</em>(1), 55–71. (<a
href="https://doi.org/10.1111/insr.12509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To weight or not to weight in regression analyses with survey data has been debated in the literature. The problem is essentially a tradeoff between the bias and the variance of the regression coefficient estimator. An array of diagnostic tests for informative weights have been developed. Nonetheless, studies comparing the performance of the tests, especially for finite samples, are scarce, and the theoretical equivalence of some tests has not been investigated. Focusing on the linear regression setting, we review a collection of such tests and propose enhanced versions of some of them that require an auxiliary regression model for the weight. Further, the equivalence of two popular tests is established which has not been reported before. In contrast to existing reviews with no empirical comparison, we compare the sizes and powers of the tests in simulation studies. The reviewed tests are applied to a regression analysis of the family expenditure using the data from the China Family Panel Study.},
  archive      = {J_INSR},
  author       = {Feng Wang and HaiYing Wang and Jun Yan},
  doi          = {10.1111/insr.12509},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {55-71},
  shortjournal = {Int. Stat. Rev.},
  title        = {Diagnostic tests for the necessity of weight in regression with survey data},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). From pareto to weibull – a constructive review of
distributions on ℝ+. <em>INSR</em>, <em>91</em>(1), 35–54. (<a
href="https://doi.org/10.1111/insr.12508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Power laws and power laws with exponential cut-off are two distinct families of distributions on the positive real half-line. In the present paper, we propose a unified treatment of both families by building a family of distributions that interpolates between them, which we call Interpolating Family (IF) of distributions. Our original construction, which relies on techniques from statistical physics, provides a connection for hitherto unrelated distributions like the Pareto and Weibull distributions, and sheds new light on them. The IF also contains several distributions that are neither of power law nor of power law with exponential cut-off type. We calculate quantile-based properties, moments and modes for the IF. This allows us to review known properties of famous distributions on and to provide in a single sweep these characteristics for various less known (and new) special cases of our Interpolating Family.},
  archive      = {J_INSR},
  author       = {Corinne Sinner and Yves Dominicy and Julien Trufin and Wout Waterschoot and Patrick Weber and Christophe Ley},
  doi          = {10.1111/insr.12508},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {35-54},
  shortjournal = {Int. Stat. Rev.},
  title        = {From pareto to weibull – a constructive review of distributions on ℝ+},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using survey sampling algorithms for exact inference in
logistic regression. <em>INSR</em>, <em>91</em>(1), 18–34. (<a
href="https://doi.org/10.1111/insr.12507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several exact inference procedures for logistic regression require the simulation of a 0-1 dependent vector according to its conditional distribution, given the sufficient statistics for some nuisance parameters. This is viewed, in this work, as a sampling problem involving a population of n units, unequal selection probabilities and balancing constraints. The basis for this reformulation of exact inference is a proposition deriving the limit, as n goes to infinity, of the conditional distribution of the dependent vector given the logistic regression sufficient statistics. It is proposed to sample from this distribution using the cube sampling algorithm. The interest of this approach to exact inference is illustrated by tackling new problems. First it allows to carry out exact inference with continuous covariates. It is also useful for the investigation of a partial correlation between several 0-1 vectors. This is illustrated in an example dealing with presence-absence data in ecology.},
  archive      = {J_INSR},
  author       = {Louis-Paul Rivest and Serigne Abib Gaye},
  doi          = {10.1111/insr.12507},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {18-34},
  shortjournal = {Int. Stat. Rev.},
  title        = {Using survey sampling algorithms for exact inference in logistic regression},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An interview with luis raúl pericchi. <em>INSR</em>,
<em>91</em>(1), 1–17. (<a
href="https://doi.org/10.1111/insr.12537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Luis Raúl Pericchi Guerra was born in Caracas, Venezuela, on 11 March 1952. He completed a B.S. in Mathematics in 1975 at the Universidad Simón Bolívar in Caracas, an M.S. in Statistics at the University of California Berkeley in 1978 and a Ph.D. in Statistics at Imperial College London in 1981. After graduating from Imperial College, Luis Raúl went back to Universidad Simón Bolívar. There, he played a key role in the developing of graduate programmes in Statistics and single handedly built an internationally recognised group focused on Bayesian statistics. In 2001, he moved to the Universidad de Puerto Rico in Rio Piedras to become the Chair of the Mathematics Department. At Universidad de Puerto Rico, he was instrumental in the establishment of a Ph.D. track in Computational Mathematics and Statistics. Luis Raúl has published over 120 papers in statistical and domain-specific journals, making significant contributions to several areas of Bayesian statistics (especially in the areas of model selection and Bayesian robustness) and their application (especially in hydrology). He is a Fellow of the American Statistical Association, the International Society for Bayesian Analysis, the John Simon Guggenheim Memorial Foundation and an Elected Member of the International Statistical Institute. This conversation took place over multiple sessions during the 2022 O&#39;Bayes meeting in Santa Cruz, California, and the months that followed.},
  archive      = {J_INSR},
  author       = {Abel Rodríguez and Bruno Sansó},
  doi          = {10.1111/insr.12537},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Int. Stat. Rev.},
  title        = {An interview with luis raúl pericchi},
  volume       = {91},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
