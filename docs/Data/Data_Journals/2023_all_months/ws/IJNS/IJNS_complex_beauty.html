<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJNS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijns---73">IJNS - 73</h2>
<ul>
<li><details>
<summary>
(2023). Self-supervised EEG representation learning with contrastive
predictive coding for post-stroke patients. <em>IJNS</em>,
<em>33</em>(12), 2350066. (<a
href="https://doi.org/10.1142/S0129065723500661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stroke patients are prone to fatigue during the EEG acquisition procedure, and experiments have high requirements on cognition and physical limitations of subjects. Therefore, how to learn effective feature representation is very important. Deep learning networks have been widely used in motor imagery (MI) based brain-computer interface (BCI). This paper proposes a contrast predictive coding (CPC) framework based on the modified s-transform (MST) to generate MST-CPC feature representations. MST is used to acquire the temporal-frequency feature to improve the decoding performance for MI task recognition. EEG2Image is used to convert multi-channel one-dimensional EEG into two-dimensional EEG topography. High-level feature representations are generated by CPC which consists of an encoder and autoregressive model. Finally, the effectiveness of generated features is verified by the k -means clustering algorithm. It can be found that our model generates features with high efficiency and a good clustering effect. After classification performance evaluation, the average classification accuracy of MI tasks is 89% based on 40 subjects. The proposed method can obtain effective feature representations and improve the performance of MI-BCI systems. By comparing several self-supervised methods on the public dataset, it can be concluded that the MST-CPC model has the highest average accuracy. This is a breakthrough in the combination of self-supervised learning and image processing of EEG signals. It is helpful to provide effective rehabilitation training for stroke patients to promote motor function recovery.},
  archive      = {J_IJNS},
  author       = {Fangzhou Xu and Yihao Yan and Jianqun Zhu and Xinyi Chen and Licai Gao and Yanbing Liu and Weiyou Shi and Yitai Lou and Wei Wang and Jiancai Leng and Yang Zhang},
  doi          = {10.1142/S0129065723500661},
  journal      = {International Journal of Neural Systems},
  number       = {12},
  pages        = {2350066},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Self-supervised EEG representation learning with contrastive predictive coding for post-stroke patients},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid online off-policy reinforcement learning agent
framework supported by transformers. <em>IJNS</em>, <em>33</em>(12),
2350065. (<a href="https://doi.org/10.1142/S012906572350065X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) is a powerful technique that allows agents to learn optimal decision-making policies through interactions with an environment. However, traditional RL algorithms suffer from several limitations such as the need for large amounts of data and long-term credit assignment, i.e. the problem of determining which actions actually produce a certain reward. Recently, Transformers have shown their capacity to address these constraints in this area of learning in an offline setting. This paper proposes a framework that uses Transformers to enhance the training of online off-policy RL agents and address the challenges described above through self-attention. The proposal introduces a hybrid agent with a mixed policy that combines an online off-policy agent with an offline Transformer agent using the Decision Transformer architecture. By sequentially exchanging the experience replay buffer between the agents, the agent’s learning training efficiency is improved in the first iterations and so is the training of Transformer-based RL agents in situations with limited data availability or unknown environments.},
  archive      = {J_IJNS},
  author       = {Enrique Adrian Villarrubia-Martin and Luis Rodriguez-Benitez and Luis Jimenez-Linares and David Muñoz-Valero and Jun Liu},
  doi          = {10.1142/S012906572350065X},
  journal      = {International Journal of Neural Systems},
  number       = {12},
  pages        = {2350065},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A hybrid online off-policy reinforcement learning agent framework supported by transformers},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning-based classification of epileptic
electroencephalography signals using a concentrated time-frequency
approach. <em>IJNS</em>, <em>33</em>(12), 2350064. (<a
href="https://doi.org/10.1142/S0129065723500648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ConceFT (concentration of frequency and time) is a new time-frequency (TF) analysis method which combines multitaper technique and synchrosqueezing transform (SST). This combination produces highly concentrated TF representations with approximately perfect time and frequency resolutions. In this paper, it is aimed to show the TF representation performance and robustness of ConceFT by using it for the classification of the epileptic electroencephalography (EEG) signals. Therefore, a signal classification algorithm which uses TF images obtained with ConceFT to feed the transfer learning structure has been presented. Epilepsy is a common neurological disorder that millions of people suffer worldwide. Daily lives of the patients are quite difficult because of the unpredictable time of seizures. EEG signals monitoring the electrical activity of the brain can be used to detect approaching seizures and make possible to warn the patient before the attack. GoogLeNet which is a well-known deep learning model has been preferred to classify TF images. Classification performance is directly related to the TF representation accuracy of the ConceFT. The proposed method has been tested for various classification scenarios and obtained accuracies between 95.83% and 99.58% for two and three-class classification scenarios. High results show that ConceFT is a successful and promising TF analysis method for non-stationary biomedical signals.},
  archive      = {J_IJNS},
  author       = {Mosab A. A. Yousif and Mahmut Ozturk},
  doi          = {10.1142/S0129065723500648},
  journal      = {International Journal of Neural Systems},
  number       = {12},
  pages        = {2350064},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Deep learning-based classification of epileptic electroencephalography signals using a concentrated time-frequency approach},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Eye state detection using frequency features from 1 or
2-channel EEG. <em>IJNS</em>, <em>33</em>(12), 2350062. (<a
href="https://doi.org/10.1142/S0129065723500624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain–computer interfaces (BCIs) establish a direct communication channel between the human brain and external devices. Among various methods, electroencephalography (EEG) stands out as the most popular choice for BCI design due to its non-invasiveness, ease of use, and cost-effectiveness. This paper aims to present and compare the accuracy and robustness of an EEG system employing one or two channels. We present both hardware and algorithms for the detection of open and closed eyes. Firstly, we utilize a low-cost hardware device to capture EEG activity from one or two channels. Next, we apply the discrete Fourier transform to analyze the signals in the frequency domain, extracting features from each channel. For classification, we test various well-known techniques, including Linear Discriminant Analysis (LDA), Support Vector Machine (SVM), Decision Tree (DT), or Logistic Regression (LR). To evaluate the system, we conduct experiments, acquiring signals associated with open and closed eyes, and compare the performance between one and two channels. The results demonstrate that employing a system with two channels and using SVM, DT, or LR classifiers enhances robustness compared to a single-channel setup and allows us to achieve an accuracy percentage greater than 95% for both eye states.},
  archive      = {J_IJNS},
  author       = {Francisco Laport and Adriana Dapena and Paula M. Castro and Daniel I. Iglesias and Francisco J. Vazquez-Araujo},
  doi          = {10.1142/S0129065723500624},
  journal      = {International Journal of Neural Systems},
  number       = {12},
  pages        = {2350062},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Eye state detection using frequency features from 1 or 2-channel EEG},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lightweight seizure detection based on multi-scale channel
attention. <em>IJNS</em>, <em>33</em>(12), 2350061. (<a
href="https://doi.org/10.1142/S0129065723500612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is one kind of neurological disease characterized by recurring seizures. Recurrent seizures can cause ongoing negative mental and cognitive damage to the patient. Therefore, timely diagnosis and treatment of epilepsy are crucial for patients. Manual electroencephalography (EEG) signals analysis is time and energy consuming, making automatic detection using EEG signals particularly important. Many deep learning algorithms have thus been proposed to detect seizures. These methods rely on expensive and bulky hardware, which makes them unsuitable for deployment on devices with limited resources due to their high demands on computer resources. In this paper, we propose a novel lightweight neural network for seizure detection using pure convolutions, which is composed of inverted residual structure and multi-scale channel attention mechanism. Compared with other methods, our approach significantly reduces the computational complexity, making it possible to deploy on low-cost portable devices for seizures detection. We conduct experiments on the CHB-MIT dataset and achieves 98.7% accuracy, 98.3% sensitivity and 99.1% specificity with 2.68 M multiply-accumulate operations (MACs) and only 88 K parameters.},
  archive      = {J_IJNS},
  author       = {Ziwei Wang and Sujuan Hou and Tiantian Xiao and Yongfeng Zhang and Hongbin Lv and Jiacheng Li and Shanshan Zhao and Yanna Zhao},
  doi          = {10.1142/S0129065723500612},
  journal      = {International Journal of Neural Systems},
  number       = {12},
  pages        = {2350061},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Lightweight seizure detection based on multi-scale channel attention},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing robustness of medical image segmentation model
with neural memory ordinary differential equation. <em>IJNS</em>,
<em>33</em>(12), 2350060. (<a
href="https://doi.org/10.1142/S0129065723500600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have emerged as a prominent model in medical image segmentation, achieving remarkable advancements in clinical practice. Despite the promising results reported in the literature, the effectiveness of DNNs necessitates substantial quantities of high-quality annotated training data. During experiments, we observe a significant decline in the performance of DNNs on the test set when there exists disruption in the labels of the training dataset, revealing inherent limitations in the robustness of DNNs. In this paper, we find that the neural memory ordinary differential equation (nmODE), a recently proposed model based on ordinary differential equations (ODEs), not only addresses the robustness limitation but also enhances performance when trained by the clean training dataset. However, it is acknowledged that the ODE-based model tends to be less computationally efficient compared to the conventional discrete models due to the multiple function evaluations required by the ODE solver. Recognizing the efficiency limitation of the ODE-based model, we propose a novel approach called the nmODE-based knowledge distillation (nmODE-KD). The proposed method aims to transfer knowledge from the continuous nmODE to a discrete layer, simultaneously enhancing the model’s robustness and efficiency. The core concept of nmODE-KD revolves around enforcing the discrete layer to mimic the continuous nmODE by minimizing the KL divergence between them. Experimental results on 18 organs-at-risk segmentation tasks demonstrate that nmODE-KD exhibits improved robustness compared to ODE-based models while also mitigating the efficiency limitation.},
  archive      = {J_IJNS},
  author       = {Junjie Hu and Chengrong Yu and Zhang Yi and Haixian Zhang},
  doi          = {10.1142/S0129065723500600},
  journal      = {International Journal of Neural Systems},
  number       = {12},
  pages        = {2350060},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Enhancing robustness of medical image segmentation model with neural memory ordinary differential equation},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An integrated neurorobotics model of the cerebellar-basal
ganglia circuitry. <em>IJNS</em>, <em>33</em>(11), 2350059. (<a
href="https://doi.org/10.1142/S0129065723500594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a neurorobotics model of the brain that integrates the cerebellum and the basal ganglia regions to coordinate movements in a humanoid robot. This cerebellar-basal ganglia circuitry is well known for its relevance to the motor control used by most mammals. Other computational models have been designed for similar applications in the robotics field. However, most of them completely ignore the interplay between neurons from the basal ganglia and cerebellum. Recently, neuroscientists indicated that neurons from both regions communicate not only at the level of the cerebral cortex but also at the subcortical level. In this work, we built an integrated neurorobotics model to assess the capacity of the network to predict and adjust the motion of the hands of a robot in real time. Our model was capable of performing different movements in a humanoid robot by respecting the sensorimotor loop of the robot and the biophysical features of the neuronal circuitry. The experiments were executed in simulation and the real world. We believe that our proposed neurorobotics model can be an important tool for new studies on the brain and a reference toward new robot motor controllers.},
  archive      = {J_IJNS},
  author       = {Jhielson M. Pimentel and Renan C. Moioli and Mariana F. P. De Araujo and Patricia A. Vargas},
  doi          = {10.1142/S0129065723500594},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2350059},
  shortjournal = {Int. J. Neural Syst.},
  title        = {An integrated neurorobotics model of the cerebellar-basal ganglia circuitry},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human gait activity recognition using multimodal sensors.
<em>IJNS</em>, <em>33</em>(11), 2350058. (<a
href="https://doi.org/10.1142/S0129065723500582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition is an application of machine learning with the aim of identifying activities from the gathered activity raw data acquired by different sensors. In medicine, human gait is commonly analyzed by doctors to detect abnormalities and determine possible treatments for the patient. Monitoring the patient’s activity is paramount in evaluating the treatment’s evolution. This type of classification is still not enough precise, which may lead to unfavorable reactions and responses. A novel methodology that reduces the complexity of extracting features from multimodal sensors is proposed to improve human activity classification based on accelerometer data. A sliding window technique is used to demarcate the first dominant spectral amplitude, decreasing dimensionality and improving feature extraction. In this work, we compared several state-of-art machine learning classifiers evaluated on the HuGaDB dataset and validated on our dataset. Several configurations to reduce features and training time were analyzed using multimodal sensors: all-axis spectrum, single-axis spectrum, and sensor reduction.},
  archive      = {J_IJNS},
  author       = {Diego Teran-Pineda and Karl Thurnhofer-Hemsi and Enrique Domínguez},
  doi          = {10.1142/S0129065723500582},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2350058},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Human gait activity recognition using multimodal sensors},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised domain adaptive dose prediction via
cross-attention transformer and target-specific knowledge preservation.
<em>IJNS</em>, <em>33</em>(11), 2350057. (<a
href="https://doi.org/10.1142/S0129065723500570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiotherapy is one of the leading treatments for cancer. To accelerate the implementation of radiotherapy in clinic, various deep learning-based methods have been developed for automatic dose prediction. However, the effectiveness of these methods heavily relies on the availability of a substantial amount of data with labels, i.e. the dose distribution maps, which cost dosimetrists considerable time and effort to acquire. For cancers of low-incidence, such as cervical cancer, it is often a luxury to collect an adequate amount of labeled data to train a well-performing deep learning (DL) model. To mitigate this problem, in this paper, we resort to the unsupervised domain adaptation (UDA) strategy to achieve accurate dose prediction for cervical cancer (target domain) by leveraging the well-labeled high-incidence rectal cancer (source domain). Specifically, we introduce the cross-attention mechanism to learn the domain-invariant features and develop a cross-attention transformer-based encoder to align the two different cancer domains. Meanwhile, to preserve the target-specific knowledge, we employ multiple domain classifiers to enforce the network to extract more discriminative target features. In addition, we employ two independent convolutional neural network (CNN) decoders to compensate for the lack of spatial inductive bias in the pure transformer and generate accurate dose maps for both domains. Furthermore, to enhance the performance, two additional losses, i.e. a knowledge distillation loss (KDL) and a domain classification loss (DCL), are incorporated to transfer the domain-invariant features while preserving domain-specific information. Experimental results on a rectal cancer dataset and a cervical cancer dataset have demonstrated that our method achieves the best quantitative results with Δ D 9 8 , Δ D 9 5 , and HI of 1.446, 1.231, and 0.082, respectively, and outperforms other methods in terms of qualitative assessment.},
  archive      = {J_IJNS},
  author       = {Jiaqi Cui and Jianghong Xiao and Yun Hou and Xi Wu and Jiliu Zhou and Xingchen Peng and Yan Wang},
  doi          = {10.1142/S0129065723500570},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2350057},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Unsupervised domain adaptive dose prediction via cross-attention transformer and target-specific knowledge preservation},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid network for patient-specific seizure prediction from
EEG data. <em>IJNS</em>, <em>33</em>(11), 2350056. (<a
href="https://doi.org/10.1142/S0129065723500569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Seizure prediction can improve the quality of life for patients with drug-resistant epilepsy. With the rapid development of deep learning, lots of seizure prediction methods have been proposed. However, seizure prediction based on single convolution models is limited by the inherent defects of convolution itself. Convolution pays attention to the local features while underestimates the global features. The long-term dependence of the electroencephalogram (EEG) data cannot be captured. In view of these defects, a hybrid model called STCNN based on Swin transformer (ST) and 2D convolutional neural network (2DCNN) is proposed. Time-frequency features extracted by short-term Fourier transform (STFT) are taken as the input of STCNN. ST blocks are used in STCNN to capture the global information and long-term dependencies of EEGs. Meanwhile, the 2DCNN blocks are adopted to capture the local information and short-term dependent features. The combination of the two blocks can fully exploit the seizure-related information thus improve the prediction performance. Comprehensive experiments are performed on the CHB-MIT scalp EEG dataset. The average seizure prediction sensitivity, the area under the ROC curve (AUC) and the false positive rate (FPR) are 92.94%, 95.56% and 0.073, respectively.},
  archive      = {J_IJNS},
  author       = {Yongfeng Zhang and Tiantian Xiao and Ziwei Wang and Hongbin Lv and Shuai Wang and Hailing Feng and Shanshan Zhao and Yanna Zhao},
  doi          = {10.1142/S0129065723500569},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2350056},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Hybrid network for patient-specific seizure prediction from EEG data},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-view graph contrastive learning via adaptive channel
optimization for depression detection in EEG signals. <em>IJNS</em>,
<em>33</em>(11), 2350055. (<a
href="https://doi.org/10.1142/S0129065723500557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated detection of depression using Electroencephalogram (EEG) signals has become a promising application in advanced bioinformatics technology. Although current methods have achieved high detection performance, several challenges still need to be addressed: (1) Previous studies do not consider data redundancy when modeling multi-channel EEG signals, resulting in some unrecognized noise channels remaining. (2) Most works focus on the functional connection of EEG signals, ignoring their spatial proximity. The spatial topological structure of EEG signals has not been fully utilized to capture more fine-grained features. (3) Prior depression detection models fail to provide interpretability. To address these challenges, this paper proposes a new model, M ulti-view G raph C ontrastive L earning via A daptive C hannel O ptimization (MGCL-ACO) for depression detection in EEG signals. Specifically, the proposed model first selects the critical channels by maximizing the mutual information between tracks and labels of EEG signals to eliminate data redundancy. Then, the MGCL-ACO model builds two similarity metric views based on functional connectivity and spatial proximity. MGCL-ACO constructs the feature extraction module by graph convolutions and contrastive learning to capture more fine-grained features of different perspectives. Finally, our model provides interpretability by visualizing a brain map related to the significance scores of the selected channels. Extensive experiments have been performed on public datasets, and the results show that our proposed model outperforms the most advanced baselines. Our proposed model not only provides a promising approach for automated depression detection using optimal EEG signals but also has the potential to improve the accuracy and interpretability of depression diagnosis in clinical practice.},
  archive      = {J_IJNS},
  author       = {Shuangyong Zhang and Hong Wang and Zixi Zheng and Tianyu Liu and Weixin Li and Zishan Zhang and Yanshen Sun},
  doi          = {10.1142/S0129065723500557},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2350055},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Multi-view graph contrastive learning via adaptive channel optimization for depression detection in EEG signals},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Epileptic seizure prediction using attention augmented
convolutional network. <em>IJNS</em>, <em>33</em>(11), 2350054. (<a
href="https://doi.org/10.1142/S0129065723500545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early seizure prediction is crucial for epilepsy patients to reduce accidental injuries and improve their quality of life. Identifying pre-ictal EEG from the inter-ictal state is particularly challenging due to their nonictal nature and remarkable similarities. In this study, a novel epileptic seizure prediction method is proposed based on multi-head attention (MHA) augmented convolutional neural network (CNN) to address the issue of CNN’s limit of capturing global information of input signals. First, data enhancement is performed on original EEG recordings to balance the pre-ictal and inter-ictal EEG data, and the EEG recordings are sliced into 6-second-long EEG segments. Subsequently, EEG time-frequency distribution is obtained using Stockwell transform (ST), and the attention augmented convolutional network is employed for feature extraction and classification. Finally, post-processing is utilized to reduce the false prediction rate (FPR). The CHB-MIT EEG database was used to evaluate the system. The validation results showed a segment-based sensitivity of 98.24% and an event-based sensitivity of 94.78% with a FPR of 0.05/h were yielded, respectively. The satisfying results of the proposed method demonstrate its possible potential for clinical applications.},
  archive      = {J_IJNS},
  author       = {Dongsheng Liu and Xingchen Dong and Dong Bian and Weidong Zhou},
  doi          = {10.1142/S0129065723500545},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2350054},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Epileptic seizure prediction using attention augmented convolutional network},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Effect of action units, viewpoint and immersion on emotion
recognition using dynamic virtual faces. <em>IJNS</em>, <em>33</em>(10),
2350053. (<a href="https://doi.org/10.1142/S0129065723500533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial affect recognition is a critical skill in human interactions that is often impaired in psychiatric disorders. To address this challenge, tests have been developed to measure and train this skill. Recently, virtual human (VH) and virtual reality (VR) technologies have emerged as novel tools for this purpose. This study investigates the unique contributions of different factors in the communication and perception of emotions conveyed by VHs. Specifically, it examines the effects of the use of action units (AUs) in virtual faces, the positioning of the VH (frontal or mid-profile), and the level of immersion in the VR environment (desktop screen versus immersive VR). Thirty-six healthy subjects participated in each condition. Dynamic virtual faces (DVFs), VHs with facial animations, were used to represent the six basic emotions and the neutral expression. The results highlight the important role of the accurate implementation of AUs in virtual faces for emotion recognition. Furthermore, it is observed that frontal views outperform mid-profile views in both test conditions, while immersive VR shows a slight improvement in emotion recognition. This study provides novel insights into the influence of these factors on emotion perception and advances the understanding and application of these technologies for effective facial emotion recognition training.},
  archive      = {J_IJNS},
  author       = {Miguel A. Vicente-Querol and Antonio Fernández-Caballero and Pascual González and Luz M. González-Gualda and Patricia Fernández-Sotos and José P. Molina and Arturo S. García},
  doi          = {10.1142/S0129065723500533},
  journal      = {International Journal of Neural Systems},
  number       = {10},
  pages        = {2350053},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Effect of action units, viewpoint and immersion on emotion recognition using dynamic virtual faces},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Few-shot pixel-precise document layout segmentation via
dynamic instance generation and local thresholding. <em>IJNS</em>,
<em>33</em>(10), 2350052. (<a
href="https://doi.org/10.1142/S0129065723500521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the years, the humanities community has increasingly requested the creation of artificial intelligence frameworks to help the study of cultural heritage. Document Layout segmentation, which aims at identifying the different structural components of a document page, is a particularly interesting task connected to this trend, specifically when it comes to handwritten texts. While there are many effective approaches to this problem, they all rely on large amounts of data for the training of the underlying models, which is rarely possible in a real-world scenario, as the process of producing the ground truth segmentation task with the required precision to the pixel level is a very time-consuming task and often requires a certain degree of domain knowledge regarding the documents at hand. For this reason, in this paper, we propose an effective few-shot learning framework for document layout segmentation relying on two novel components, namely a dynamic instance generation and a segmentation refinement module. This approach is able of achieving performances comparable to the current state of the art on the popular Diva-HisDB dataset, while relying on just a fraction of the available data.},
  archive      = {J_IJNS},
  author       = {Axel De Nardin and Silvia Zottin and Claudio Piciarelli and Emanuela Colombi and Gian Luca Foresti},
  doi          = {10.1142/S0129065723500521},
  journal      = {International Journal of Neural Systems},
  number       = {10},
  pages        = {2350052},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Few-shot pixel-precise document layout segmentation via dynamic instance generation and local thresholding},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing prediction of forelimb movement trajectory through
a calibrating-feedback paradigm incorporating RAT primary motor and
agranular cortical ensemble activity in the goal-directed reaching task.
<em>IJNS</em>, <em>33</em>(10), 2350051. (<a
href="https://doi.org/10.1142/S012906572350051X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complete reaching movements involve target sensing, motor planning, and arm movement execution, and this process requires the integration and communication of various brain regions. Previously, reaching movements have been decoded successfully from the motor cortex (M1) and applied to prosthetic control. However, most studies attempted to decode neural activities from a single brain region, resulting in reduced decoding accuracy during visually guided reaching motions. To enhance the decoding accuracy of visually guided forelimb reaching movements, we propose a parallel computing neural network using both M1 and medial agranular cortex (AGm) neural activities of rats to predict forelimb-reaching movements. The proposed network decodes M1 neural activities into the primary components of the forelimb movement and decodes AGm neural activities into internal feedforward information to calibrate the forelimb movement in a goal-reaching movement. We demonstrate that using AGm neural activity to calibrate M1 predicted forelimb movement can improve decoding performance significantly compared to neural decoders without calibration. We also show that the M1 and AGm neural activities contribute to controlling forelimb movement during goal-reaching movements, and we report an increase in the power of the local field potential (LFP) in beta and gamma bands over AGm in response to a change in the target distance, which may involve sensorimotor transformation and communication between the visual cortex and AGm when preparing for an upcoming reaching movement. The proposed parallel computing neural network with the internal feedback model improves prediction accuracy for goal-reaching movements.},
  archive      = {J_IJNS},
  author       = {Han-Lin Wang and Yun-Ting Kuo and Yu-Chun Lo and Chao-Hung Kuo and Bo-Wei Chen and Ching-Fu Wang and Zu-Yu Wu and Chi-En Lee and Shih-Hung Yang and Sheng-Huang Lin and Po-Chuan Chen and You-Yin Chen},
  doi          = {10.1142/S012906572350051X},
  journal      = {International Journal of Neural Systems},
  number       = {10},
  pages        = {2350051},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Enhancing prediction of forelimb movement trajectory through a calibrating-feedback paradigm incorporating RAT primary motor and agranular cortical ensemble activity in the goal-directed reaching task},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Localization of epileptic brain responses to single-pulse
electrical stimulation by developing an adaptive iterative linearly
constrained minimum variance beamformer. <em>IJNS</em>, <em>33</em>(10),
2350050. (<a href="https://doi.org/10.1142/S0129065723500508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Delayed responses (DRs) to single pulse electrical stimulation (SPES) in patients with severe refractory epilepsy, from their intracranial recordings, can help to identify regions associated with epileptogenicity. Automatic DR localization is a large step in speeding up the identification of epileptogenic focus. Here, for the first time, an adaptive iterative linearly constrained minimum variance beamformer (AI-LCMV) is developed and employed to localize the DR sources from intracranial electroencephalogram (EEG) recorded using subdural electrodes. The prime objective here is to accurately localize the regions for the corresponding DRs using an adaptive localization method that exploits the morphology of DRs as the desired sources. The traditional closed-form linearly constrained minimum variance (CF-LCMV) solution is meant for tracking the sources with dominating power. Here, by incorporating the morphology of DRs, as a constraint, to an iterative linearly constrained minimum variance (LCMV) solution, the array of subdural electrodes is used to localize the low-power DRs, some not even visible in any of the electrode signals. The results from the cases included in this study also indicate more distinctive locations compared to those achievable by conventional beamformers. Most importantly, the proposed AI-LCMV is able to localize the DRs invisible over other electrodes.},
  archive      = {J_IJNS},
  author       = {Sepehr Shirani and Antonio Valentin and Bahman Abdi-Sargezeh and Gonzalo Alarcon and Saeid Sanei},
  doi          = {10.1142/S0129065723500508},
  journal      = {International Journal of Neural Systems},
  number       = {10},
  pages        = {2350050},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Localization of epileptic brain responses to single-pulse electrical stimulation by developing an adaptive iterative linearly constrained minimum variance beamformer},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Decoupled edge guidance network for automatic checkout.
<em>IJNS</em>, <em>33</em>(10), 2350049. (<a
href="https://doi.org/10.1142/S0129065723500491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic checkout (ACO) aims at correctly generating complete shopping lists from checkout images. However, the domain gap between the single product in training data and multiple products in checkout images endows ACO tasks with a major difficulty. Despite remarkable advancements in recent years, resolving the significant domain gap remains challenging. It is possibly because networks trained solely on synthesized images may struggle to generalize well to realistic checkout scenarios. To this end, we propose a decoupled edge guidance network (DEGNet), which integrates synthesized and checkout images via a supervised domain adaptation approach and further learns common domain representations using a domain adapter. Specifically, an edge embedding module is designed for generating edge embedding images to introduce edge information. On this basis, we develop a decoupled feature extractor that takes original images and edge embedding images as input to jointly utilize image information and edge information. Furthermore, a novel proposal divide-and-conquer strategy (PDS) is proposed for the purpose of augmenting high-quality samples. Through experimental evaluation, DEGNet achieves state-of-the-art performance on the retail product checkout (RPC) dataset, with checkout accuracy (cAcc) results of 93.47% and 95.25% in the average mode of faster RCNN and cascade RCNN frameworks, respectively. Codes are available at https://github.com/yourbikun/DEGNet.},
  archive      = {J_IJNS},
  author       = {Rongbiao You and Fuxiong He and Weiming Lin},
  doi          = {10.1142/S0129065723500491},
  journal      = {International Journal of Neural Systems},
  number       = {10},
  pages        = {2350049},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Decoupled edge guidance network for automatic checkout},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Response to the discussion on s. Shirani, a. Valentin, g.
Alarcon, f. Kazi and s. Sanei, separating inhibitory and excitatory
responses of epileptic brain to single-pulse electrical stimulation,
international journal of neural systems, vol. 33, no. 2 (2023) 2350008.
<em>IJNS</em>, <em>33</em>(9), 2375002. (<a
href="https://doi.org/10.1142/S0129065723750023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJNS},
  author       = {Sepehr Shirani and Antonio Valentin and Gonzalo Alarcon and Farhana Kazi and Saeid Sanei},
  doi          = {10.1142/S0129065723750023},
  journal      = {International Journal of Neural Systems},
  number       = {9},
  pages        = {2375002},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Response to the discussion on s. shirani, a. valentin, g. alarcon, f. kazi and s. sanei, separating inhibitory and excitatory responses of epileptic brain to single-pulse electrical stimulation, international journal of neural systems, vol. 33, no. 2 (2023) 2350008},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Discussion on s. Shirani, a. Valentin, g. Alarcon, f. Kazi
and s. Sanei, separating inhibitory and excitatory responses of
epileptic brain to single-pulse electrical stimulation, international
journal of neural systems, vol. 33, no. 2 (2023) 2350008. <em>IJNS</em>,
<em>33</em>(9), 2375001. (<a
href="https://doi.org/10.1142/S0129065723750011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJNS},
  author       = {Olivier Darbin},
  doi          = {10.1142/S0129065723750011},
  journal      = {International Journal of Neural Systems},
  number       = {9},
  pages        = {2375001},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Discussion on s. shirani, a. valentin, g. alarcon, f. kazi and s. sanei, separating inhibitory and excitatory responses of epileptic brain to single-pulse electrical stimulation, international journal of neural systems, vol. 33, no. 2 (2023) 2350008},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online ternary classification of covert speech by leveraging
the passive perception of speech. <em>IJNS</em>, <em>33</em>(9),
2350048. (<a href="https://doi.org/10.1142/S012906572350048X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain–computer interfaces (BCIs) provide communicative alternatives to those without functional speech. Covert speech (CS)-based BCIs enable communication simply by thinking of words and thus have intuitive appeal. However, an elusive barrier to their clinical translation is the collection of voluminous examples of high-quality CS signals, as iteratively rehearsing words for long durations is mentally fatiguing. Research on CS and speech perception (SP) identifies common spatiotemporal patterns in their respective electroencephalographic (EEG) signals, pointing towards shared encoding mechanisms. The goal of this study was to investigate whether a model that leverages the signal similarities between SP and CS can differentiate speech-related EEG signals online. Ten participants completed a dyadic protocol where in each trial, they listened to a randomly selected word and then subsequently mentally rehearsed the word. In the offline sessions, eight words were presented to participants. For the subsequent online sessions, the two most distinct words (most separable in terms of their EEG signals) were chosen to form a ternary classification problem (two words and rest). The model comprised a functional mapping derived from SP and CS signals of the same speech token (features are extracted via a Riemannian approach). An average ternary online accuracy of 75.3% (60% chance level) was achieved across participants, with individual accuracies as high as 93%. Moreover, we observed that the signal-to-noise ratio (SNR) of CS signals was enhanced by perception-covert modeling according to the level of high-frequency ( γ -band) correspondence between CS and SP. These findings may lead to less burdensome data collection for training speech BCIs, which could eventually enhance the rate at which the vocabulary can grow.},
  archive      = {J_IJNS},
  author       = {Jae Moon and Tom Chau},
  doi          = {10.1142/S012906572350048X},
  journal      = {International Journal of Neural Systems},
  number       = {9},
  pages        = {2350048},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Online ternary classification of covert speech by leveraging the passive perception of speech},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep regression approach for human activity recognition
under partial occlusion. <em>IJNS</em>, <em>33</em>(9), 2350047. (<a
href="https://doi.org/10.1142/S0129065723500478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-life scenarios, Human Activity Recognition (HAR) from video data is prone to occlusion of one or more body parts of the human subjects involved. Although it is common sense that the recognition of the majority of activities strongly depends on the motion of some body parts, which when occluded compromise the performance of recognition approaches, this problem is often underestimated in contemporary research works. Currently, training and evaluation is based on datasets that have been shot under laboratory (ideal) conditions, i.e. without any kind of occlusion. In this work, we propose an approach for HAR in the presence of partial occlusion, in cases wherein up to two body parts are involved. We assume that human motion is modeled using a set of 3D skeletal joints and also that occluded body parts remain occluded during the whole duration of the activity. We solve this problem using regression, performed by a novel deep Convolutional Recurrent Neural Network (CRNN). Specifically, given a partially occluded skeleton, we attempt to reconstruct the missing information regarding the motion of its occluded part(s). We evaluate our approach using four publicly available human motion datasets. Our experimental results indicate a significant increase of performance, when compared to baseline approaches, wherein networks that have been trained using only nonoccluded or both occluded and nonoccluded samples are evaluated using occluded samples. To the best of our knowledge, this is the first research work that formulates and copes with the problem of HAR under occlusion as a regression task.},
  archive      = {J_IJNS},
  author       = {Ioannis Vernikos and Evaggelos Spyrou and Ioannis-Aris Kostis and Eirini Mathe and Phivos Mylonas},
  doi          = {10.1142/S0129065723500478},
  journal      = {International Journal of Neural Systems},
  number       = {9},
  pages        = {2350047},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A deep regression approach for human activity recognition under partial occlusion},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A class-imbalance aware and explainable spatio-temporal
graph attention network for neonatal seizure detection. <em>IJNS</em>,
<em>33</em>(9), 2350046. (<a
href="https://doi.org/10.1142/S0129065723500466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Seizures are the most prevalent clinical indication of neurological disorders in neonates. In this study, a class-imbalance aware and explainable deep learning approach based on Convolutional Neural Networks (CNNs) and Graph Attention Networks (GATs) is proposed for the accurate automated detection of neonatal seizures. The proposed model integrates the temporal information of EEG signals with the spatial information on the EEG channels through the graph representation of the multi-channel EEG segments. One-dimensional CNNs are used to automatically develop a feature set that accurately represents the differences between seizure and nonseizure epochs in the time domain. By employing GAT, the attention mechanism is utilized to emphasize the critical channel pairs and information flow among brain regions. GAT coefficients were then used to empirically visualize the important regions during the seizure and nonseizure epochs, which can provide valuable insight into the location of seizures in the neonatal brain. Additionally, to tackle the severe class imbalance in the neonatal seizure dataset using under-sampling and focal loss techniques are used. Overall, the final Spatio-Temporal Graph Attention Network (ST-GAT) outperformed previous benchmarked methods with a mean AUC of 96.6% and Kappa of 0.88, demonstrating its high accuracy and potential for clinical applications.},
  archive      = {J_IJNS},
  author       = {Khadijeh Raeisi and Mohammad Khazaei and Gabriella Tamburro and Pierpaolo Croce and Silvia Comani and Filippo Zappasodi},
  doi          = {10.1142/S0129065723500466},
  journal      = {International Journal of Neural Systems},
  number       = {9},
  pages        = {2350046},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A class-imbalance aware and explainable spatio-temporal graph attention network for neonatal seizure detection},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classification of epileptic and psychogenic nonepileptic
seizures via time–frequency features of EEG data. <em>IJNS</em>,
<em>33</em>(9), 2350045. (<a
href="https://doi.org/10.1142/S0129065723500454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The majority of psychogenic nonepileptic seizures (PNESs) are brought on by psychogenic causes, but because their symptoms resemble those of epilepsy, they are frequently misdiagnosed. Although EEG signals are normal in PNES cases, electroencephalography (EEG) recordings alone are not sufficient to identify the illness. Hence, accurate diagnosis and effective treatment depend on long-term video EEG data and a complete patient history. Video EEG setup, however, is more expensive than using standard EEG equipment. To distinguish PNES signals from conventional epileptic seizure (ES) signals, it is crucial to develop methods solely based on EEG recordings. The proposed study presents a technique utilizing short-term EEG data for the classification of inter-PNES, PNES, and ES segments using time–frequency methods such as the Continuous Wavelet transform (CWT), Short-Time Fourier transform (STFT), CWT-based synchrosqueezed transform (WSST), and STFT-based SST (FSST), which provide high-resolution time–frequency representations (TFRs). TFRs of EEG segments are utilized to generate 13 joint TF (J-TF)-based features, four gray-level co-occurrence matrix (GLCM)-based features, and 16 higher-order joint TF moment (HOJ-Mom)-based features. These features are then employed in the classification procedure. Both three-class (inter-PNES versus PNES versus ES: ACC: 80.9%, SEN: 81.8%, and PRE: 84.7%) and two-class (Inter-PNES versus PNES: ACC: 88.2%, SEN: 87.2%, and PRE: 86.1%; PNES versus ES: ACC: 98.5%, SEN: 99.3%, and PRE: 98.9%) classification algorithms performed well, according to the experimental results. The STFT and FSST strategies surpass the CWT and WSST strategies in terms of classification accuracy, sensitivity, and precision. Moreover, the J-TF-based feature sets often perform better than the other two.},
  archive      = {J_IJNS},
  author       = {Ozlem Karabiber Cura and Aydin Akan and Hatice Sabiha Ture},
  doi          = {10.1142/S0129065723500454},
  journal      = {International Journal of Neural Systems},
  number       = {9},
  pages        = {2350045},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Classification of epileptic and psychogenic nonepileptic seizures via Time–Frequency features of EEG data},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluation of spiking neural nets-based image classification
using the runtime simulator RAVSim. <em>IJNS</em>, <em>33</em>(9),
2350044. (<a href="https://doi.org/10.1142/S0129065723500442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs) help achieve brain-like efficiency and functionality by building neurons and synapses that mimic the human brain’s transmission of electrical signals. However, optimal SNN implementation requires a precise balance of parametric values. To design such ubiquitous neural networks, a graphical tool for visualizing, analyzing, and explaining the internal behavior of spikes is crucial. Although some popular SNN simulators are available, these tools do not allow users to interact with the neural network during simulation. To this end, we have introduced the first runtime interactive simulator, called Runtime Analyzing and Visualization Simulator ( RAVSim ), a developed to analyze and dynamically visualize the behavior of SNNs, allowing end-users to interact, observe output concentration reactions, and make changes directly during the simulation. In this paper, we present RAVSim with the current implementation of runtime interaction using the LIF neural model with different connectivity schemes, an image classification model using SNNs, and a dataset creation feature. Our main objective is to primarily investigate binary classification using SNNs with RGB images. We created a feed-forward network using the LIF neural model for an image classification algorithm and evaluated it by using RAVSim . The algorithm classifies faces with and without masks, achieving an accuracy of 91.8% using 1000 neurons in a hidden layer, 0.0758 MSE, and an execution time of ∼10 min on the CPU. The experimental results show that using RAVSim not only increases network design speed but also accelerates user learning capability.},
  archive      = {J_IJNS},
  author       = {Sanaullah and Shamini Koravuna and Ulrich Rückert and Thorsten Jungeblut},
  doi          = {10.1142/S0129065723500442},
  journal      = {International Journal of Neural Systems},
  number       = {9},
  pages        = {2350044},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Evaluation of spiking neural nets-based image classification using the runtime simulator RAVSim},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A transformer-embedded multi-task model for dose
distribution prediction. <em>IJNS</em>, <em>33</em>(8), 2350043. (<a
href="https://doi.org/10.1142/S0129065723500430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiation therapy is a fundamental cancer treatment in the clinic. However, to satisfy the clinical requirements, radiologists have to iteratively adjust the radiotherapy plan based on experience, causing it extremely subjective and time-consuming to obtain a clinically acceptable plan. To this end, we introduce a transformer-embedded multi-task dose prediction (TransMTDP) network to automatically predict the dose distribution in radiotherapy. Specifically, to achieve more stable and accurate dose predictions, three highly correlated tasks are included in our TransMTDP network, i.e. a main dose prediction task to provide each pixel with a fine-grained dose value, an auxiliary isodose lines prediction task to produce coarse-grained dose ranges, and an auxiliary gradient prediction task to learn subtle gradient information such as radiation patterns and edges in the dose maps. The three correlated tasks are integrated through a shared encoder, following the multi-task learning strategy. To strengthen the connection of the output layers for different tasks, we further use two additional constraints, i.e. isodose consistency loss and gradient consistency loss, to reinforce the match between the dose distribution features generated by the auxiliary tasks and the main task. Additionally, considering many organs in the human body are symmetrical and the dose maps present abundant global features, we embed the transformer into our framework to capture the long-range dependencies of the dose maps. Evaluated on an in-house rectum cancer dataset and a public head and neck cancer dataset, our method gains superior performance compared with the state-of-the-art ones. Code is available at https://github.com/luuuwen/TransMTDP.},
  archive      = {J_IJNS},
  author       = {Lu Wen and Jianghong Xiao and Shuai Tan and Xi Wu and Jiliu Zhou and Xingchen Peng and Yan Wang},
  doi          = {10.1142/S0129065723500430},
  journal      = {International Journal of Neural Systems},
  number       = {8},
  pages        = {2350043},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A transformer-embedded multi-task model for dose distribution prediction},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Epileptic EEG classification via graph transformer network.
<em>IJNS</em>, <em>33</em>(8), 2350042. (<a
href="https://doi.org/10.1142/S0129065723500429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based epileptic seizure recognition via electroencephalogram signals has shown considerable potential for clinical practice. Although deep learning algorithms can enhance epilepsy identification accuracy compared with classical machine learning techniques, classifying epileptic activities based on the association between multichannel signals in electroencephalogram recordings is still challenging in automated seizure classification from electroencephalogram signals. Furthermore, the performance of generalization is hardly maintained by the fact that existing deep learning models were constructed using just one architecture. This study focuses on addressing this challenge using a hybrid framework. Alternatively put, a hybrid deep learning model, which is based on the ground-breaking graph neural network and transformer architectures, was proposed. The proposed deep architecture consists of a graph model to discover the inner relationship between multichannel signals and a transformer to reveal the heterogeneous associations between the channels. To evaluate the performance of the proposed approach, the comparison experiments were conducted on a publicly available dataset between the state-of-the-art algorithms and ours. Experimental results demonstrate that the proposed method is a potentially valuable instrument for epoch-based epileptic EEG classification.},
  archive      = {J_IJNS},
  author       = {Jian Lian and Fangzhou Xu},
  doi          = {10.1142/S0129065723500429},
  journal      = {International Journal of Neural Systems},
  number       = {8},
  pages        = {2350042},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Epileptic EEG classification via graph transformer network},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nonlinear weighting ensemble learning model to diagnose
parkinson’s disease using multimodal data. <em>IJNS</em>,
<em>33</em>(8), 2350041. (<a
href="https://doi.org/10.1142/S0129065723500417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s Disease (PD) is the second most prevalent neurodegenerative disorder among adults. Although its triggers are still not clear, they may be due to a combination of different types of biomarkers measured through medical imaging, metabolomics, proteomics or genetics, among others. In this context, we have proposed a Computer-Aided Diagnosis (CAD) system that combines structural and functional imaging data from subjects in Parkinson’s Progression Markers Initiative dataset by means of an Ensemble Learning methodology trained to identify and penalize input sources with low classification rates and/ or high-variability. This proposal improves results published in recent years and provides an accurate solution not only from the point of view of image preprocessing (including a comparison between different intensity preservation techniques), but also in terms of dimensionality reduction methods (Isomap). In addition, we have also introduced a bagging classification schema for scenarios with unbalanced data. As shown by our results, the CAD proposal is able to detect PD with 9 6 . 4 8 % of balanced accuracy, and opens up the possibility of combining any number of input data sources relevant for PD.},
  archive      = {J_IJNS},
  author       = {D. Castillo-Barnes and F. J. Martinez-Murcia and C. Jimenez-Mesa and J. E. Arco and D. Salas-Gonzalez and J. Ramírez and J. M. Górriz},
  doi          = {10.1142/S0129065723500417},
  journal      = {International Journal of Neural Systems},
  number       = {8},
  pages        = {2350041},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Nonlinear weighting ensemble learning model to diagnose parkinson’s disease using multimodal data},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An attention-aware long short-term memory-like spiking
neural model for sentiment analysis. <em>IJNS</em>, <em>33</em>(8),
2350037. (<a href="https://doi.org/10.1142/S0129065723500375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LSTM-SNP model is a recently developed long short-term memory (LSTM) network, which is inspired from the mechanisms of spiking neural P (SNP) systems. In this paper, LSTM-SNP is utilized to propose a novel model for aspect-level sentiment analysis, termed as ALS model. The LSTM-SNP model has three gates: reset gate, consumption gate and generation gate. Moreover, attention mechanism is integrated with LSTM-SNP model. The ALS model can better capture the sentiment features in the text to compute the correlation between context and aspect words. To validate the effectiveness of the ALS model for aspect-level sentiment analysis, comparison experiments with 17 baseline models are conducted on three real-life data sets. The experimental results demonstrate that the ALS model has a simpler structure and can achieve better performance compared to these baseline models.},
  archive      = {J_IJNS},
  author       = {Qian Liu and Yanping Huang and Qian Yang and Hong Peng and Jun Wang},
  doi          = {10.1142/S0129065723500375},
  journal      = {International Journal of Neural Systems},
  number       = {8},
  pages        = {2350037},
  shortjournal = {Int. J. Neural Syst.},
  title        = {An attention-aware long short-term memory-like spiking neural model for sentiment analysis},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A shared hippocampal network in retrieving science-related
semantic memories. <em>IJNS</em>, <em>33</em>(8), 2350034. (<a
href="https://doi.org/10.1142/S012906572350034X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In responding to the calls for revisiting the role that hippocampus (HIP) plays in semantic memory retrieval, this study used functional neuroimaging-based connectivity technique to elucidate the functional brain network involved in retrieving the correct and incorrect science-related semantic memories. Unlike episodic memory retrieval, the 40 scientific concepts learned during middle and high school were selected to assess 46 science majors’ semantic memory retrieval and correctness monitoring, which requires neither the support of spatial information nor events to retrieve the memory. Our results demonstrated that HIP was significantly and robustly engaged in the semantic memory retrieval of correct scientific concepts than incorrect ones. Importantly, the Granger causality analysis indicated that effective connectivity of INS → HIP and MTG → HIP was shared by the semantic memory retrieval of both correct and incorrect scientific concepts. On the other hand, the strengths of connectivity in the MTG → HIP and INS → ACC → HIP brain networks appeared more pronounced during the processing of correct scientific concepts than of incorrect ones. The shared hippocampal networks highlight the role of the HIP as a hub to coordinate the INS, ACC, and MTG, in turn, support the semantic memory retrieval of scientific concepts.},
  archive      = {J_IJNS},
  author       = {Hsiao-Ching She and Li-Yu Huang and Jeng-Ren Duann},
  doi          = {10.1142/S012906572350034X},
  journal      = {International Journal of Neural Systems},
  number       = {8},
  pages        = {2350034},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A shared hippocampal network in retrieving science-related semantic memories},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Swarm-FHE: Fully homomorphic encryption-based swarm learning
for malicious clients. <em>IJNS</em>, <em>33</em>(8), 2350033. (<a
href="https://doi.org/10.1142/S0129065723500338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Swarm Learning (SL) is a promising approach to perform the distributed and collaborative model training without any central server. However, data sensitivity is the main concern for privacy when collaborative training requires data sharing. A neural network, especially Generative Adversarial Network (GAN), is able to reproduce the original data from model parameters, i.e. gradient leakage problem. To solve this problem, SL provides a framework for secure aggregation using blockchain methods. In this paper, we consider the scenario of compromised and malicious participants in the SL environment, where a participant can manipulate the privacy of other participant in collaborative training. We propose a method, Swarm-FHE, Swarm Learning with Fully Homomorphic Encryption (FHE), to encrypt the model parameters before sharing with the participants which are registered and authenticated by blockchain technology. Each participant shares the encrypted parameters (i.e. ciphertexts) with other participants in SL training. We evaluate our method with training of the convolutional neural networks on the CIFAR-10 and MNIST datasets. On the basis of a considerable number of experiments and results with different hyperparameter settings, our method performs better as compared to other existing methods.},
  archive      = {J_IJNS},
  author       = {Hussain Ahmad Madni and Rao Muhammad Umer and Gian Luca Foresti},
  doi          = {10.1142/S0129065723500338},
  journal      = {International Journal of Neural Systems},
  number       = {8},
  pages        = {2350033},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Swarm-FHE: Fully homomorphic encryption-based swarm learning for malicious clients},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evolving a pipeline approach for abstract meaning
representation parsing towards dynamic neural networks. <em>IJNS</em>,
<em>33</em>(7), 2350040. (<a
href="https://doi.org/10.1142/S0129065723500405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract Meaning Representation parsing aims to represent a sentence as a structured, Directed, Acyclic Graph (DAG), in an attempt to extract meaning from text. This paper extends an existing 2-stage pipeline AMR parser with state-of-the-art techniques in dependency parsing. First, Pointer-Generator Networks are used for out-of-vocabulary words in the concept identification stage, with an improved initialization via the use of word-and character-level embeddings. Second, the performance of the Relation Identification module is improved by jointly training the Heads Selection and the Arcs Labeling components. Last, we underline the difficulty of end-to-end training with recurrent modules in a static deep neural network construction approach and explore a dynamic construction implementation, which continuously adapts the computation graph, thus potentially enabling end-to-end training in the proposed pipeline solution.},
  archive      = {J_IJNS},
  author       = {Florin Macicasan and Alexandru Frasie and Nicoleta-Teodora Vezan and Camelia Lemnaru and Rodica Potolea},
  doi          = {10.1142/S0129065723500405},
  journal      = {International Journal of Neural Systems},
  number       = {7},
  pages        = {2350040},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Evolving a pipeline approach for abstract meaning representation parsing towards dynamic neural networks},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A modified long short-term memory cell. <em>IJNS</em>,
<em>33</em>(7), 2350039. (<a
href="https://doi.org/10.1142/S0129065723500399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Learning (ML), among other things, facilitates Text Classification, the task of assigning classes to textual items. Classification performance in ML has been significantly improved due to recent developments, including the rise of Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM), Gated Recurrent Units (GRUs), and Transformer Models. Internal memory states with dynamic temporal behavior can be found in these kinds of cells. This temporal behavior in the LSTM cell is stored in two different states: “Current” and “Hidden”. In this work, we define a modification layer within the LSTM cell which allows us to perform additional state adjustments for either state, or even simultaneously alter both. We perform 17 state alterations. Out of these 17 single-state alteration experiments, 12 involve the Current state whereas five involve the Hidden one. These alterations are evaluated using seven datasets related to sentiment analysis, document classification, hate speech detection, and human-to-robot interaction. Our results showed that the highest performing alteration for Current and Hidden state can achieve an average F 1 improvement of 0.5% and 0.3%, respectively. We also compare our modified cell performance to two Transformer models, where our modified LSTM cell is outperformed in classification metrics in 4/6 datasets, but improves upon the simple Transformer model and clearly has a better cost efficiency than both Transformer models.},
  archive      = {J_IJNS},
  author       = {Giannis Haralabopoulos and Gerasimos Razis and Ioannis Anagnostopoulos},
  doi          = {10.1142/S0129065723500399},
  journal      = {International Journal of Neural Systems},
  number       = {7},
  pages        = {2350039},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A modified long short-term memory cell},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modeling emerging interpersonal synchrony and its related
adaptive short-term affiliation and long-term bonding: A second-order
multi-adaptive neural agent model. <em>IJNS</em>, <em>33</em>(7),
2350038. (<a href="https://doi.org/10.1142/S0129065723500387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When people interact, their behavior tends to become synchronized, a mutual coordination process that fosters short-term adaptations, like increased affiliation, and long-term adaptations, like increased bonding. This paper addresses for the first time how such short-term and long-term adaptivity induced by synchronization can be modeled computationally by a second-order multi-adaptive neural agent model. It addresses movement, affect and verbal modalities and both intrapersonal synchrony and interpersonal synchrony. The behavior of the introduced neural agent model was evaluated in a simulation paradigm with different stimuli and communication-enabling conditions. Moreover, in this paper, mathematical analysis is also addressed for adaptive network models and their positioning within the landscape of adaptive dynamical systems. The first type of analysis addressed shows that any smooth adaptive dynamical system has a canonical representation by a self-modeling network. This implies theoretically that the self-modeling network format is widely applicable, which also has been found in many practical applications using this approach. Furthermore, stationary point and equilibrium analysis was addressed and applied to the introduced self-modeling network model. It was used to obtain verification of the model providing evidence that the implemented model is correct with respect to its design specifications.},
  archive      = {J_IJNS},
  author       = {Sophie C. F. Hendrikse and Jan Treur and Sander L. Koole},
  doi          = {10.1142/S0129065723500387},
  journal      = {International Journal of Neural Systems},
  number       = {7},
  pages        = {2350038},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Modeling emerging interpersonal synchrony and its related adaptive short-term affiliation and long-term bonding: A second-order multi-adaptive neural agent model},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integrating nearest neighbors with neural network models for
treatment effect estimation. <em>IJNS</em>, <em>33</em>(7), 2350036. (<a
href="https://doi.org/10.1142/S0129065723500363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Treatment effect estimation is of high-importance for both researchers and practitioners across many scientific and industrial domains. The abundance of observational data makes them increasingly used by researchers for the estimation of causal effects. However, these data suffer from several weaknesses, leading to inaccurate causal effect estimations, if not handled properly. Therefore, several machine learning techniques have been proposed, most of them focusing on leveraging the predictive power of neural network models to attain more precise estimation of causal effects. In this work, we propose a new methodology, named Nearest Neighboring Information for Causal Inference (NNCI), for integrating valuable nearest neighboring information on neural network-based models for estimating treatment effects. The proposed NNCI methodology is applied to some of the most well established neural network-based models for treatment effect estimation with the use of observational data. Numerical experiments and analysis provide empirical and statistical evidence that the integration of NNCI with state-of-the-art neural network models leads to considerably improved treatment effect estimations on a variety of well-known challenging benchmarks.},
  archive      = {J_IJNS},
  author       = {Niki Kiriakidou and Christos Diou},
  doi          = {10.1142/S0129065723500363},
  journal      = {International Journal of Neural Systems},
  number       = {7},
  pages        = {2350036},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Integrating nearest neighbors with neural network models for treatment effect estimation},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transformer-based approach via contrastive learning for
zero-shot detection. <em>IJNS</em>, <em>33</em>(7), 2350035. (<a
href="https://doi.org/10.1142/S0129065723500351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot detection (ZSD) aims to locate and classify unseen objects in pictures or videos by semantic auxiliary information without additional training examples. Most of the existing ZSD methods are based on two-stage models, which achieve the detection of unseen classes by aligning object region proposals with semantic embeddings. However, these methods have several limitations, including poor region proposals for unseen classes, lack of consideration of semantic representations of unseen classes or their inter-class correlations, and domain bias towards seen classes, which can degrade overall performance. To address these issues, the Trans-ZSD framework is proposed, which is a transformer-based multi-scale contextual detection framework that explicitly exploits inter-class correlations between seen and unseen classes and optimizes feature distribution to learn discriminative features. Trans-ZSD is a single-stage approach that skips proposal generation and performs detection directly, allowing the encoding of long-term dependencies at multiple scales to learn contextual features while requiring fewer inductive biases. Trans-ZSD also introduces a foreground–background separation branch to alleviate the confusion of unseen classes and backgrounds, contrastive learning to learn inter-class uniqueness and reduce misclassification between similar classes, and explicit inter-class commonality learning to facilitate generalization between related classes. Trans-ZSD addresses the domain bias problem in end-to-end generalized zero-shot detection (GZSD) models by using balance loss to maximize response consistency between seen and unseen predictions, ensuring that the model does not bias towards seen classes. The Trans-ZSD framework is evaluated on the PASCAL VOC and MS COCO datasets, demonstrating significant improvements over existing ZSD models.},
  archive      = {J_IJNS},
  author       = {Wei Liu and Hui Chen and Yongqiang Ma and Jianji Wang and Nanning Zheng},
  doi          = {10.1142/S0129065723500351},
  journal      = {International Journal of Neural Systems},
  number       = {7},
  pages        = {2350035},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Transformer-based approach via contrastive learning for zero-shot detection},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Introduction. <em>IJNS</em>, <em>33</em>(7), 2303002. (<a
href="https://doi.org/10.1142/S0129065723030028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJNS},
  author       = {Lazaros Iliadis},
  doi          = {10.1142/S0129065723030028},
  journal      = {International Journal of Neural Systems},
  number       = {7},
  pages        = {2303002},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Introduction},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Facial expression recognition with contrastive learning and
uncertainty-guided relabeling. <em>IJNS</em>, <em>33</em>(6), 2350032.
(<a href="https://doi.org/10.1142/S0129065723500326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expression recognition (FER) plays a vital role in the field of human-computer interaction. To achieve automatic FER, various approaches based on deep learning (DL) have been presented. However, most of them lack for the extraction of discriminative expression semantic information and suffer from the problem of annotation ambiguity. In this paper, we propose an elaborately designed end-to-end recognition network with contrastive learning and uncertainty-guided relabeling, to recognize facial expressions efficiently and accurately, as well as to alleviate the impact of annotation ambiguity. Specifically, a supervised contrastive loss (SCL) is introduced to promote inter-class separability and intra-class compactness, thus helping the network extract fine-grained discriminative expression features. As for the annotation ambiguity problem, we present an uncertainty estimation-based relabeling module (UERM) to estimate the uncertainty of each sample and relabel the unreliable ones. In addition, to deal with the padding erosion problem, we embed an amending representation module (ARM) into the recognition network. Experimental results on three public benchmarks demonstrate that our proposed method facilitates the recognition performance remarkably with 90.91% on RAF-DB, 88.59% on FERPlus and 61.00% on AffectNet, outperforming current state-of-the-art (SOTA) FER methods. Code will be available at http//github.com/xiaohu-run/fer_supCon .},
  archive      = {J_IJNS},
  author       = {Yujie Yang and Lin Hu and Chen Zu and Qizheng Zhou and Xi Wu and Jiliu Zhou and Yan Wang},
  doi          = {10.1142/S0129065723500326},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2350032},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Facial expression recognition with contrastive learning and uncertainty-guided relabeling},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid attention network for epileptic EEG classification.
<em>IJNS</em>, <em>33</em>(6), 2350031. (<a
href="https://doi.org/10.1142/S0129065723500314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic seizure detection from electroencephalography (EEG) based on deep learning has been significantly improved. However, existing works have not adequately excavate the spatial-temporal information between EEG channels. Besides, most works mainly focus on patient-specific scenarios while cross-patient seizure detection is more challenging and meaningful. Regarding the above problems, we propose a hybrid attention network (HAN) for automatic seizure detection. Specifically, the graph attention network (GAT) extracts spatial features at the front end, and Transformer gets time features as the back end. HAN leverages the attention mechanism and fully extracts the spatial-temporal correlation of EEG signals. The focal loss function is introduced to HAN to deal with the imbalance of the dataset accompanied by seizure detection based on EEG. Both patient-specific and patient-independent experiments are carried out on the public CHB-MIT database. Experimental results demonstrate the efficacy of HAN in both experimental settings.},
  archive      = {J_IJNS},
  author       = {Yanna Zhao and Jiatong He and Fenglin Zhu and Tiantian Xiao and Yongfeng Zhang and Ziwei Wang and Fangzhou Xu and Yi Niu},
  doi          = {10.1142/S0129065723500314},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2350031},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Hybrid attention network for epileptic EEG classification},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). One-dimensional local binary pattern and common spatial
pattern feature fusion brain network for central neuropathic pain.
<em>IJNS</em>, <em>33</em>(6), 2350030. (<a
href="https://doi.org/10.1142/S0129065723500302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Central neuropathic pain (CNP) after spinal cord injury (SCI) is related to the plasticity of cerebral cortex. The plasticity of cortex recorded by electroencephalogram (EEG) signal can be used as a biomarker of CNP. To analyze changes in the brain network mechanism under the combined effect of injury and pain or under the effect of pain, this paper mainly studies the changes of brain network functional connectivity in patients with neuropathic pain and without neuropathic pain after SCI. This paper has recorded the EEG with the CNP group after SCI, without the CNP group after SCI, and a healthy control group. Phase-locking value has been used to construct brain network topological connectivity maps. By comparing the brain networks of the two groups of SCI with the healthy group, it has been found that in the β and γ frequency bands, the injury increases the functional connectivity between the frontal lobe and occipital lobes, temporal, and parietal of the patients. Furthermore, the comparison of brain networks between the group with CNP and the group without CNP after SCI has found that pain has a greater effect on the increased connectivity within the patients’ frontal lobes. Motor imagery (MI) data of CNP patients have been used to extract one-dimensional local binary pattern (1D-LBP) and common spatial pattern (CSP) features, the left and right hand movements of the patients’ MI have been classified. The proposed LBP-CSP feature method has achieved the highest accuracy of 98.6% and the average accuracy of 91.5%. The results of this study have great clinical significance for the neural rehabilitation and brain–computer interface of CNP patients.},
  archive      = {J_IJNS},
  author       = {Fangzhou Xu and Chongfeng Wang and Xin Yu and Jinzhao Zhao and Ming Liu and Jiaqi Zhao and Licai Gao and Xiuquan Jiang and Zhaoxin Zhu and Yongjian Wu and Dezheng Wang and Shanxin Feng and Sen Yin and Yang Zhang and Jiancai Leng},
  doi          = {10.1142/S0129065723500302},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2350030},
  shortjournal = {Int. J. Neural Syst.},
  title        = {One-dimensional local binary pattern and common spatial pattern feature fusion brain network for central neuropathic pain},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A prediction model based on gated nonlinear spiking neural
systems. <em>IJNS</em>, <em>33</em>(6), 2350029. (<a
href="https://doi.org/10.1142/S0129065723500296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinear spiking neural P (NSNP) systems are one of neural-like membrane computing models, abstracted by nonlinear spiking mechanisms of biological neurons. NSNP systems have a nonlinear structure and can show rich nonlinear dynamics. In this paper, we introduce a variant of NSNP systems, called gated nonlinear spiking neural P systems or GNSNP systems. Based on GNSNP systems, a recurrent-like model is investigated, called GNSNP model. Moreover, exchange rate forecasting tasks are used as the application background to verify its ability. For the purpose, we develop a prediction model based on GNSNP model, called ERF-GNSNP model. In ERF-GNSNP model, the GNSNP model is followed by a “dense” layer, which is used to capture the correlation between different sub-series in multivariate time series. To evaluate the prediction performance, nine groups of exchange rate data sets are utilized to compare the proposed ERF-GNSNP model with 25 baseline prediction models. The comparison results demonstrate the effectiveness of the proposed ERF-GNSNP model for exchange rate forecasting tasks.},
  archive      = {J_IJNS},
  author       = {Yujie Zhang and Qian Yang and Zhicai Liu and Hong Peng and Jun Wang},
  doi          = {10.1142/S0129065723500296},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2350029},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A prediction model based on gated nonlinear spiking neural systems},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A pilot study on the functional stability of phonation in
EEG bands after repetitive transcranial magnetic stimulation in
parkinson’s disease. <em>IJNS</em>, <em>33</em>(6), 2350028. (<a
href="https://doi.org/10.1142/S0129065723500284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease (PD) is a neurodegenerative condition with constantly increasing prevalence rates, affecting strongly life quality in terms of neuromotor and cognitive performance. PD symptoms include voice and speech alterations, known as hypokinetic dysarthria (HD). Unstable phonation is one of the manifestations of HD. Repetitive transcranial magnetic stimulation (rTMS) is a rehabilitative treatment thathas been shown to improve some motor and non-motor symptoms of persons with PD (PwP). This study analyzed the phonation functional behavior of 18 participants (13 males, 5 females) with PD diagnosis before (one pre-stimulus) and after (four post-stimulus) evaluation sessions of rTMS treatment, to assess the extent of changes in their phonation stability. Participants were randomized 1:1 to receive either rTMS or sham stimulation. Voice recordings of a sustained vowel [a:] taken immediately before and after the treatment, and at follow-up evaluation sessions (immediately after, at six, ten, and fourteen weeks after the baseline assessment) were processed by inverse filtering to estimate a biomechanical correlate of vocal fold tension. This estimate was further band-pass filtered into EEG-related frequency bands. Log-likelihood ratios (LLRs) between pre- and post-stimulus amplitude distributions of each frequency band showed significant differences in five cases actively stimulated. Seven cases submitted to the sham protocol did not show relevant improvements in phonation instability. Conversely, four active cases did not show phonation improvements, whereas two sham cases did. The study provides early preliminary insights into the capability of phonation quality assessment by monitoring neuromechanical activity from acoustic signals in frequency bands aligned with EEG ones.},
  archive      = {J_IJNS},
  author       = {Andrés Gómez-Rodellar and Jiří Mekyska and Pedro Gómez-Vilda and Luboš Brabenec and Patrik Šimko and Irena Rektorová},
  doi          = {10.1142/S0129065723500284},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2350028},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A pilot study on the functional stability of phonation in EEG bands after repetitive transcranial magnetic stimulation in parkinson’s disease},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). First longitudinal study using binaural beats on parkinson
disease. <em>IJNS</em>, <em>33</em>(6), 2350027. (<a
href="https://doi.org/10.1142/S0129065723500272">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes a longitudinal study to analyze the effects of acoustic stimulation with Binaural Beats (BBs) at 14 Hz (beta band) in patients with Parkinson’s Disease (PD). Participants ( n = 1 2 , age 5 8 . 7 5 ± 1 0 . 7 1 , stage 2 . 1 7 ± 0 . 7 5 Hoehn and Yahr scale) listened to binaural stimulation for 10 min a day, 3 days a week, during six months and were assessed 3 times during this period using electroencephalography (EEG), cognitive (PD-CRS), quality of life (PDQ-39) and wearing-off (WOQ-19) tests. During each assessment (basal, and after 3 and 6 months), the relative power in theta band was analyzed before, during and after the stimulation. Focusing the analysis on the motor cortex, the results obtained have confirmed the initial hypothesis for the first session, but they have shown a habituation effect which decreases its efficiency with time. Also, different reactions have been detected among individuals, with some reacting as expected from the beginning, while others would react in an opposite way at the beginning but they have shown afterwards a tendency towards the expected outcome. Anyhow, the relative power of the theta band was reduced between the first and the last session for more than half of the participants, although with very different values. Subtle changes have also been observed in some items of the PD-CRS, PDQ-39 and WOQ-19 tests.},
  archive      = {J_IJNS},
  author       = {David González and Ricardo Bruña and Juan Carlos Martínez-Castrillo and Juan Manuel López and Guillermo de Arcas},
  doi          = {10.1142/S0129065723500272},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2350027},
  shortjournal = {Int. J. Neural Syst.},
  title        = {First longitudinal study using binaural beats on parkinson disease},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A method based on evolutionary algorithms and channel
attention mechanism to enhance cycle generative adversarial network
performance for image translation. <em>IJNS</em>, <em>33</em>(5),
2350026. (<a href="https://doi.org/10.1142/S0129065723500260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Generative Adversarial Network (GAN) can learn the relationship between two image domains and achieve unpaired image-to-image translation. One of the breakthroughs was Cycle-consistent Generative Adversarial Networks (CycleGAN), which is a popular method to transfer the content representations from the source domain to the target domain. Existing studies have gradually improved the performance of CycleGAN models by modifying the network structure or loss function of CycleGAN. However, these methods tend to suffer from training instability and the generators lack the ability to acquire the most discriminating features between the source and target domains, thus making the generated images of low fidelity and few texture details. To overcome these issues, this paper proposes a new method that combines Evolutionary Algorithms (EAs) and Attention Mechanisms to train GANs. Specifically, from an initial CycleGAN, binary vectors indicating the activation of the weights of the generators are progressively improved upon by means of an EA. At the end of this process, the best-performing configurations of generators can be retained for image generation. In addition, to address the issues of low fidelity and lack of texture details on generated images, we make use of the channel attention mechanism. The latter component allows the candidate generators to learn important features of real images and thus generate images with higher quality. The experiments demonstrate qualitatively and quantitatively that the proposed method, namely, Attention evolutionary GAN (AevoGAN) alleviates the training instability problems of CycleGAN training. In the test results, the proposed method can generate higher quality images and obtain better results than the CycleGAN training methods present in the literature, in terms of Inception Score (IS), Fréchet Inception Distance (FID) and Kernel Inception Distance (KID).},
  archive      = {J_IJNS},
  author       = {Yu Xue and Yixia Zhang and Ferrante Neri},
  doi          = {10.1142/S0129065723500260},
  journal      = {International Journal of Neural Systems},
  number       = {5},
  pages        = {2350026},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A method based on evolutionary algorithms and channel attention mechanism to enhance cycle generative adversarial network performance for image translation},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Convolutional neural network classification of topographic
electroencephalographic maps on alcoholism. <em>IJNS</em>,
<em>33</em>(5), 2350025. (<a
href="https://doi.org/10.1142/S0129065723500259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alcohol use is a leading risk factor for substantial health loss, disability, and death. Thus, there is a general interest in developing computational tools to classify electroencephalographic (EEG) signals in alcoholism, but there are a limited number of studies on convolutional neural network (CNN) classification of alcoholism using topographic EEG signals. We produced an original dataset recorded from Brazilian subjects performing a language recognition task. Then, we transformed the Event-Related Potentials (ERPs) into topographic maps by using the ERP’s statistical parameters across time, and used a CNN network to classify the topographic dataset. We tested the effect of the size of the dataset in the accuracy of the CNNs and proposed a data augmentation approach to increase the size of the topographic dataset to improve the accuracies. Our results encourage the use of CNNs to classify abnormal topographic EEG patterns associated with alcohol abuse.},
  archive      = {J_IJNS},
  author       = {Victor Borghi Gimenez and Suelen Lorenzato Dos Reis and Fábio M. Simões de Souza},
  doi          = {10.1142/S0129065723500259},
  journal      = {International Journal of Neural Systems},
  number       = {5},
  pages        = {2350025},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Convolutional neural network classification of topographic electroencephalographic maps on alcoholism},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved neurophysiological process imaging through
optimization of kalman filter initial conditions. <em>IJNS</em>,
<em>33</em>(5), 2350024. (<a
href="https://doi.org/10.1142/S0129065723500247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent work presented a framework for space-time-resolved neurophysiological process imaging that augments existing electromagnetic source imaging techniques. In particular, a nonlinear Analytic Kalman filter (AKF) has been developed to efficiently infer the states and parameters of neural mass models believed to underlie the generation of electromagnetic source currents. Unfortunately, as the initialization determines the performance of the Kalman filter, and the ground truth is typically unavailable for initialization, this framework might produce suboptimal results unless significant effort is spent on tuning the initialization. Notably, the relation between the initialization and overall filter performance is only given implicitly and is expensive to evaluate; implying that conventional optimization techniques, e.g. gradient or sampling based, are inapplicable. To address this problem, a novel efficient framework based on blackbox optimization has been developed to find the optimal initialization by reducing the signal prediction error. Multiple state-of-the-art optimization methods were compared and distinctively, Gaussian process optimization decreased the objective function by 82.1% and parameter estimation error by 62.5% on average with the simulation data compared to no optimization applied. The framework took only 1.6 h and reduced the objective function by an average of 13.2% on 3.75 min 4714-source channel magnetoencephalography data. This yields an improved method of neurophysiological process imaging that can be used to uncover complex underpinnings of brain dynamics.},
  archive      = {J_IJNS},
  author       = {Yun Zhao and Felix Luong and Simon Teshuva and Andria Pelentritou and William Woods and David Liley and Daniel F. Schmidt and Mario Boley and Levin Kuhlmann},
  doi          = {10.1142/S0129065723500247},
  journal      = {International Journal of Neural Systems},
  number       = {5},
  pages        = {2350024},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Improved neurophysiological process imaging through optimization of kalman filter initial conditions},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using virus machines to compute pairing functions.
<em>IJNS</em>, <em>33</em>(5), 2350023. (<a
href="https://doi.org/10.1142/S0129065723500235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virus machines are computational devices inspired by the movement of viruses between hosts and their capacity to replicate using the resources of the hosts. This behavior is controlled by an external graph of instructions that opens different channels of the system to make viruses capable of moving. This model of computation has been demonstrated to be as powerful as turing machines by different methods: by generating Diophantine sets, by computing partial recursive functions and by simulating register machines. It is interesting to investigate the practical use cases of this model in terms of possibilities and efficiency. In this work, we give the basic modules to create an arithmetic calculator. As a practical application, two pairing functions are calculated by means of two different virus machines. Pairing functions are important resources in the field of cryptography. The functions calculated are the Cantor pairing function and the Gödel pairing function.},
  archive      = {J_IJNS},
  author       = {Antonio Ramírez-de-Arellano and David Orellana-Martín and Mario J. Pérez-Jiménez},
  doi          = {10.1142/S0129065723500235},
  journal      = {International Journal of Neural Systems},
  number       = {5},
  pages        = {2350023},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Using virus machines to compute pairing functions},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human brain dynamics and coordination reflect the task
difficulty of optical image relational reasoning. <em>IJNS</em>,
<em>33</em>(5), 2350018. (<a
href="https://doi.org/10.1142/S0129065723500181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite advances in neuroscience, the mechanisms by which human brain resolve optical image formation through relational reasoning remain unclear, particularly its relationships with task difficulty. Therefore, this study explores the underlying brain dynamics involved in optical image formation tasks at various difficulty levels, including those with a single convex lens and a single mirror. Compared to single convex lens relational reasoning with high task difficulty, the single mirror relational reasoning exhibited significantly higher response accuracy and shorter latency. As compared to single mirror tasks, single convex tasks exhibited greater frontal midline theta augmentation and right parietal alpha suppression during phase I and earlier phase II, and augmentation of frontal midline theta, right parietal-occipital alpha, and left mu alpha suppression during late phase II. Moreover, the frontal midline theta power in late phase II predicts the likelihood of solving single convex tasks the best, while the parietal alpha power in phase I is most predictive. In addition, frontal midline theta power exhibited stronger synchronization with right parietal alpha, right occipital alpha, and mu alpha power when solving single convex tasks than single mirror tasks. In summary, having stronger brain dynamics and coordination is vital for achieving optical image formation with greater difficulty.},
  archive      = {J_IJNS},
  author       = {Wen-Chi Chou and Hsiao-Ching She and Tzyy-Ping Jung},
  doi          = {10.1142/S0129065723500181},
  journal      = {International Journal of Neural Systems},
  number       = {5},
  pages        = {2350018},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Human brain dynamics and coordination reflect the task difficulty of optical image relational reasoning},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient multi-objective evolutionary zero-shot neural
architecture search framework for image classification. <em>IJNS</em>,
<em>33</em>(5), 2350016. (<a
href="https://doi.org/10.1142/S0129065723500168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Architecture Search (NAS) has recently shown a powerful ability to engineer networks automatically on various tasks. Most current approaches navigate the search direction with the validation performance-based architecture evaluation methodology, which estimates an architecture’s quality by training and validating on a specific large dataset. However, for small-scale datasets, the model’s performance on the validation set cannot precisely estimate that on the test set. The imprecise architecture evaluation can mislead the search to sub-optima. To address the above problem, we propose an efficient multi-objective evolutionary zero-shot NAS framework by evaluating architectures with zero-cost metrics, which can be calculated with randomly initialized models in a training-free manner. Specifically, a general zero-cost metric design principle is proposed to unify the current metrics and help develop several new metrics. Then, we offer an efficient computational method for multi-zero-cost metrics by calculating them in one forward and backward pass. Finally, comprehensive experiments have been conducted on NAS-Bench-201 and MedMNIST. The results have shown that the proposed method can achieve sufficiently accurate, high-throughput performance on MedMNIST and 20 × faster than the previous best method.},
  archive      = {J_IJNS},
  author       = {Jianwei Zhang and Lei Zhang and Yan Wang and Junyou Wang and Xin Wei and Wenjie Liu},
  doi          = {10.1142/S0129065723500168},
  journal      = {International Journal of Neural Systems},
  number       = {5},
  pages        = {2350016},
  shortjournal = {Int. J. Neural Syst.},
  title        = {An efficient multi-objective evolutionary zero-shot neural architecture search framework for image classification},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Electrical stimulation induced current distribution in
peripheral nerves varies significantly with the extent of nerve damage:
A computational study utilizing convolutional neural network and
realistic nerve models. <em>IJNS</em>, <em>33</em>(4), 2350022. (<a
href="https://doi.org/10.1142/S0129065723500223">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrical stimulation of the peripheral nervous system is a promising therapeutic option for several conditions; however, its effects on tissue and the safety of the stimulation remain poorly understood. In order to devise stimulation protocols that enhance therapeutic efficacy without the risk of causing tissue damage, we constructed computational models of peripheral nerve and stimulation cuffs based on extremely high-resolution cross-sectional images of the nerves using the most recent advances in computing power and machine learning techniques. We developed nerve models using nonstimulated (healthy) and over-stimulated (damaged) rat sciatic nerves to explore how nerve damage affects the induced current density distribution. Using our in-house computational, quasi-static, platform, and the Admittance Method (AM), we estimated the induced current distribution within the nerves and compared it for healthy and damaged nerves. We also estimated the extent of localized cell damage in both healthy and damaged nerve samples. When the nerve is damaged, as demonstrated principally by the decreased nerve fiber packing, the current penetrates deeper into the over-stimulated nerve than in the healthy sample. As safety limits for electrical stimulation of peripheral nerves still refer to the Shannon criterion to distinguish between safe and unsafe stimulation, the capability this work demonstrated is an important step toward the development of safety criteria that are specific to peripheral nerve and make use of the latest advances in computational bioelectromagnetics and machine learning, such as Python-based AM and CNN-based nerve image segmentation.},
  archive      = {J_IJNS},
  author       = {Jinze Du and Andres Morales and Pragya Kosta and Jean-Marie C. Bouteiller and Gema Martinez-Navarrete and David J. Warren and Eduardo Fernandez and Gianluca Lazzi},
  doi          = {10.1142/S0129065723500223},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2350022},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Electrical stimulation induced current distribution in peripheral nerves varies significantly with the extent of nerve damage: A computational study utilizing convolutional neural network and realistic nerve models},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Supporting the detection of early alzheimer’s disease with a
four-channel EEG analysis. <em>IJNS</em>, <em>33</em>(4), 2350021. (<a
href="https://doi.org/10.1142/S0129065723500211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) is the most prevalent form of dementia. Although there is no current cure, medical treatment can help to control its progression. Hence, early-stage diagnosis is crucial to maximize the living standards of the patients. Biochemical markers and medical imaging in combination with neuropsychological tests represent the most extended diagnosis procedure. However, these techniques require specialized personnel and long processing time. Furthermore, the access to some of these techniques is often limited in crowded healthcare systems and rural areas. In this context, electroencephalography (EEG), a non-invasive technique to obtain endogenous brain information, has been proposed for the diagnosis of early-stage AD. Despite the valuable information provided by clinical EEG and high density montages, these approaches are impractical in conditions such as those described above. Consequently, in this study, we evaluated the feasibly of using a reduced EEG montage with only four channels to detect early-stage AD. For this purpose, we involved eight clinically diagnosed AD patients and eight healthy controls. The results we obtained reveal similar accuracies ( p -value = 0.66) for the reduced montage (0.86) and a 16-channel montage (0.87). This suggests that a four-channel wearable EEG system could be an effective tool for supporting early-stage AD detection.},
  archive      = {J_IJNS},
  author       = {Eduardo Perez-Valero and Christian Morillas and Miguel A. Lopez-Gordo and Jesus Minguillon},
  doi          = {10.1142/S0129065723500211},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2350021},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Supporting the detection of early alzheimer’s disease with a four-channel EEG analysis},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EEG interchannel causality to identify source/sink phase
connectivity patterns in developmental dyslexia. <em>IJNS</em>,
<em>33</em>(4), 2350020. (<a
href="https://doi.org/10.1142/S012906572350020X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the brain connectivity network can inform the understanding and diagnosis of developmental dyslexia, its cause–effect relationships have not yet enough been examined. Employing electroencephalography signals and band-limited white noise stimulus at 4.8 Hz (prosodic-syllabic frequency), we measure the phase Granger causalities among channels to identify differences between dyslexic learners and controls, thereby proposing a method to calculate directional connectivity. As causal relationships run in both directions, we explore three scenarios, namely channels’ activity as sources, as sinks, and in total. Our proposed method can be used for both classification and exploratory analysis. In all scenarios, we find confirmation of the established right-lateralized Theta sampling network anomaly, in line with the assumption of the temporal sampling framework of oscillatory differences in the Theta and Gamma bands. Further, we show that this anomaly primarily occurs in the causal relationships of channels acting as sinks, where it is significantly more pronounced than when only total activity is observed. In the sink scenario, our classifier obtains 0.84 and 0.88 accuracy and 0.87 and 0.93 AUC for the Theta and Gamma bands, respectively.},
  archive      = {J_IJNS},
  author       = {I. Rodríguez-Rodríguez and A. Ortiz and N. J. Gallego-Molina and M. A. Formoso and W. L. Woo},
  doi          = {10.1142/S012906572350020X},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2350020},
  shortjournal = {Int. J. Neural Syst.},
  title        = {EEG interchannel causality to identify Source/Sink phase connectivity patterns in developmental dyslexia},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing multimodal patterns in neuroimaging by siamese
neural networks with self-attention mechanism. <em>IJNS</em>,
<em>33</em>(4), 2350019. (<a
href="https://doi.org/10.1142/S0129065723500193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The combination of different sources of information is currently one of the most relevant aspects in the diagnostic process of several diseases. In the field of neurological disorders, different imaging modalities providing structural and functional information are frequently available. Those modalities are usually analyzed separately, although a joint of the features extracted from both sources can improve the classification performance of Computer-Aided Diagnosis (CAD) tools. Previous studies have computed independent models from each individual modality and combined them in a subsequent stage, which is not an optimum solution. In this work, we propose a method based on the principles of siamese neural networks to fuse information from Magnetic Resonance Imaging (MRI) and Positron Emission Tomography (PET). This framework quantifies the similarities between both modalities and relates them with the diagnostic label during the training process. The resulting latent space at the output of this network is then entered into an attention module in order to evaluate the relevance of each brain region at different stages of the development of Alzheimer’s disease. The excellent results obtained and the high flexibility of the method proposed allow fusing more than two modalities, leading to a scalable methodology that can be used in a wide range of contexts.},
  archive      = {J_IJNS},
  author       = {Juan E. Arco and Andrés Ortiz and Nicolás J. Gallego-Molina and Juan M. Górriz and Javier Ramírez},
  doi          = {10.1142/S0129065723500193},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2350019},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Enhancing multimodal patterns in neuroimaging by siamese neural networks with self-attention mechanism},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Assessing functional brain network dynamics in dyslexia from
fNIRS data. <em>IJNS</em>, <em>33</em>(4), 2350017. (<a
href="https://doi.org/10.1142/S012906572350017X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developmental dyslexia is characterized by a deficit of phonological awareness whose origin is related to atypical neural processing of speech streams. This can lead to differences in the neural networks that encode audio information for dyslexics. In this work, we investigate whether such differences exist using functional near-infrared spectroscopy (fNIRS) and complex network analysis. We have explored functional brain networks derived from low-level auditory processing of nonspeech stimuli related to speech units such as stress, syllables or phonemes of skilled and dyslexic seven-year-old readers. A complex network analysis was performed to examine the properties of functional brain networks and their temporal evolution. We characterized aspects of brain connectivity such as functional segregation, functional integration or small-worldness. These properties are used as features to extract differential patterns in controls and dyslexic subjects. The results corroborate the presence of discrepancies in the topological organizations of functional brain networks and their dynamics that differentiate between control and dyslexic subjects, reaching an Area Under ROC Curve (AUC) up to 0.89 in classification experiments.},
  archive      = {J_IJNS},
  author       = {Nicolás J. Gallego-Molina and Andrés Ortiz and Francisco J. Martínez-Murcia and Ignacio Rodríguez-Rodríguez and Juan L. Luque},
  doi          = {10.1142/S012906572350017X},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2350017},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Assessing functional brain network dynamics in dyslexia from fNIRS data},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using explainable artificial intelligence in the clock
drawing test to reveal the cognitive impairment pattern. <em>IJNS</em>,
<em>33</em>(4), 2350015. (<a
href="https://doi.org/10.1142/S0129065723500156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevalence of dementia is currently increasing worldwide. This syndrome produces a deterioration in cognitive function that cannot be reverted. However, an early diagnosis can be crucial for slowing its progress. The Clock Drawing Test (CDT) is a widely used paper-and-pencil test for cognitive assessment in which an individual has to manually draw a clock on a paper. There are a lot of scoring systems for this test and most of them depend on the subjective assessment of the expert. This study proposes a computer-aided diagnosis (CAD) system based on artificial intelligence (AI) methods to analyze the CDT and obtain an automatic diagnosis of cognitive impairment (CI). This system employs a preprocessing pipeline in which the clock is detected, centered and binarized to decrease the computational burden. Then, the resulting image is fed into a Convolutional Neural Network (CNN) to identify the informative patterns within the CDT drawings that are relevant for the assessment of the patient’s cognitive status. Performance is evaluated in a real context where patients with CI and controls have been classified by clinical experts in a balanced sample size of 3 2 8 2 drawings. The proposed method provides an accuracy of 7 5 . 6 5 % in the binary case-control classification task, with an AUC of 0 . 8 3 . These results are indeed relevant considering the use of the classic version of the CDT. The large size of the sample suggests that the method proposed has a high reliability to be used in clinical contexts and demonstrates the suitability of CAD systems in the CDT assessment process. Explainable artificial intelligence (XAI) methods are applied to identify the most relevant regions during classification. Finding these patterns is extremely helpful to understand the brain damage caused by CI. A validation method using resubstitution with upper bound correction in a machine learning approach is also discussed.},
  archive      = {J_IJNS},
  author       = {Carmen Jiménez-Mesa and Juan E. Arco and Meritxell Valentí-Soler and Belén Frades-Payo and María A. Zea-Sevilla and Andrés Ortiz and Marina Ávila-Villanueva and Diego Castillo-Barnes and Javier Ramírez and Teodoro Del Ser-Quijano and Cristóbal Carnero-Pardo and Juan M. Górriz},
  doi          = {10.1142/S0129065723500156},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2350015},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Using explainable artificial intelligence in the clock drawing test to reveal the cognitive impairment pattern},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Introduction. <em>IJNS</em>, <em>33</em>(4), 2303001. (<a
href="https://doi.org/10.1142/S0129065723030016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJNS},
  author       = {José Manuel Ferrández and Eduardo Fernandez and Juan Manuel Gorriz},
  doi          = {10.1142/S0129065723030016},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2303001},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Introduction},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Compact convolutional neural network with multi-headed
attention mechanism for seizure prediction. <em>IJNS</em>,
<em>33</em>(3), 2350014. (<a
href="https://doi.org/10.1142/S0129065723500144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is a neurological disorder related to frequent seizures. Automatic seizure prediction is crucial for the prevention and treatment of epilepsy. In this paper, we propose a novel model for seizure prediction that incorporates a convolutional neural network (CNN) with multi-head attention mechanism. In this model, the shallow CNN automatically captures the EEG features, and the multi-headed attention focuses on discriminating the effective information among these features for identifying pre-ictal EEG segments. Compared with current CNN models for seizure prediction, the embedded multi-headed attention empowers the shallow CNN to be more flexible, and enables improvement of the training efficiency. Hence, this compact model is more resistant to being trapped in overfitting. The proposed method was evaluated over the scalp EEG data from the two publicly available epileptic EEG databases, and achieved outperforming values of event-level sensitivity, false prediction rate (FPR), and epoch-level F1. Furthermore, our method achieved the stable length of seizure prediction time that was between 14 and 15 min. The experimental comparisons showed that our method outperformed other prediction methods in terms of prediction and generalization performance.},
  archive      = {J_IJNS},
  author       = {Xin Ding and Weiwei Nie and Xinyu Liu and Xiuying Wang and Qi Yuan},
  doi          = {10.1142/S0129065723500144},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2350014},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Compact convolutional neural network with multi-headed attention mechanism for seizure prediction},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Large-scale image retrieval with deep attentive global
features. <em>IJNS</em>, <em>33</em>(3), 2350013. (<a
href="https://doi.org/10.1142/S0129065723500132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to obtain discriminative features has proved to be a core problem for image retrieval. Many recent works use convolutional neural networks to extract features. However, clutter and occlusion will interfere with the distinguishability of features when using convolutional neural network (CNN) for feature extraction. To address this problem, we intend to obtain high-response activations in the feature map based on the attention mechanism. We propose two attention modules, a spatial attention module and a channel attention module. For the spatial attention module, we first capture the global information and model the relation between channels as a region evaluator, which evaluates and assigns new weights to local features. For the channel attention module, we use a vector with trainable parameters to weight the importance of each feature map. The two attention modules are cascaded to adjust the weight distribution for the feature map, which makes the extracted features more discriminative. Furthermore, we present a scale and mask scheme to scale the major components and filter out the meaningless local features. This scheme can reduce the disadvantages of the various scales of the major components in images by applying multiple scale filters, and filter out the redundant features with the MAX-Mask . Exhaustive experiments demonstrate that the two attention modules are complementary to improve performance, and our network with the three modules outperforms the state-of-the-art methods on four well-known image retrieval datasets.},
  archive      = {J_IJNS},
  author       = {Yingying Zhu and Yinghao Wang and Haonan Chen and Zemian Guo and Qiang Huang},
  doi          = {10.1142/S0129065723500132},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2350013},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Large-scale image retrieval with deep attentive global features},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Six-center assessment of CNN-transformer with belief
matching loss for patient-independent seizure detection in EEG.
<em>IJNS</em>, <em>33</em>(3), 2350012. (<a
href="https://doi.org/10.1142/S0129065723500120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurologists typically identify epileptic seizures from electroencephalograms (EEGs) by visual inspection. This process is often time-consuming, especially for EEG recordings that last hours or days. To expedite the process, a reliable, automated, and patient-independent seizure detector is essential. However, developing a patient-independent seizure detector is challenging as seizures exhibit diverse characteristics across patients and recording devices. In this study, we propose a patient-independent seizure detector to automatically detect seizures in both scalp EEG and intracranial EEG (iEEG). First, we deploy a convolutional neural network with transformers and belief matching loss to detect seizures in single-channel EEG segments. Next, we extract regional features from the channel-level outputs to detect seizures in multi-channel EEG segments. At last, we apply post-processing filters to the segment-level outputs to determine seizures’ start and end points in multi-channel EEGs. Finally, we introduce the minimum overlap evaluation scoring as an evaluation metric that accounts for minimum overlap between the detection and seizure, improving upon existing assessment metrics. We trained the seizure detector on the Temple University Hospital Seizure (TUH-SZ) dataset and evaluated it on five independent EEG datasets. We evaluate the systems with the following metrics: sensitivity (SEN), precision (PRE), and average and median false positive rate per hour (aFPR/h and mFPR/h). Across four adult scalp EEG and iEEG datasets, we obtained SEN of 0.617–1.00, PRE of 0.534–1.00, aFPR/h of 0.425–2.002, and mFPR/h of 0–1.003. The proposed seizure detector can detect seizures in adult EEGs and takes less than 15 s for a 30 min EEG. Hence, this system could aid clinicians in reliably identifying seizures expeditiously, allocating more time for devising proper treatment.},
  archive      = {J_IJNS},
  author       = {Wei Yan Peh and Prasanth Thangavel and Yuanyuan Yao and John Thomas and Yee-Leng Tan and Justin Dauwels},
  doi          = {10.1142/S0129065723500120},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2350012},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Six-center assessment of CNN-transformer with belief matching loss for patient-independent seizure detection in EEG},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Algorithm recommendation and performance prediction using
meta-learning. <em>IJNS</em>, <em>33</em>(3), 2350011. (<a
href="https://doi.org/10.1142/S0129065723500119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last years, the number of machine learning algorithms and their parameters has increased significantly. On the one hand, this increases the chances of finding better models. On the other hand, it increases the complexity of the task of training a model, as the search space expands significantly. As the size of datasets also grows, traditional approaches based on extensive search start to become prohibitively expensive in terms of computational resources and time, especially in data streaming scenarios. This paper describes an approach based on meta-learning that tackles two main challenges. The first is to predict key performance indicators of machine learning models. The second is to recommend the best algorithm/configuration for training a model for a given machine learning problem. When compared to a state-of-the-art method (AutoML), the proposed approach is up to 130x faster and only 4% worse in terms of average model quality. Hence, it is especially suited for scenarios in which models need to be updated regularly, such as in streaming scenarios with big data, in which some accuracy can be traded for a much shorter model training time.},
  archive      = {J_IJNS},
  author       = {Guilherme Palumbo and Davide Carneiro and Miguel Guimares and Victor Alves and Paulo Novais},
  doi          = {10.1142/S0129065723500119},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2350011},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Algorithm recommendation and performance prediction using meta-learning},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An evolutionary attention-based network for medical image
classification. <em>IJNS</em>, <em>33</em>(3), 2350010. (<a
href="https://doi.org/10.1142/S0129065723500107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has become a primary choice in medical image analysis due to its powerful representation capability. However, most existing deep learning models designed for medical image classification can only perform well on a specific disease. The performance drops dramatically when it comes to other diseases. Generalizability remains a challenging problem. In this paper, we propose an evolutionary attention-based network (EDCA-Net), which is an effective and robust network for medical image classification tasks. To extract task-related features from a given medical dataset, we first propose the densely connected attentional network (DCA-Net) where feature maps are automatically channel-wise weighted, and the dense connectivity pattern is introduced to improve the efficiency of information flow. To improve the model capability and generalizability, we introduce two types of evolution: intra- and inter-evolution. The intra-evolution optimizes the weights of DCA-Net, while the inter-evolution allows two instances of DCA-Net to exchange training experience during training. The evolutionary DCA-Net is referred to as EDCA-Net. The EDCA-Net is evaluated on four publicly accessible medical datasets of different diseases. Experiments showed that the EDCA-Net outperforms the state-of-the-art methods on three datasets and achieves comparable performance on the last dataset, demonstrating good generalizability for medical image classification.},
  archive      = {J_IJNS},
  author       = {Hengde Zhu and Jian Wang and Shui-Hua Wang and Rajeev Raman and Juan M. Górriz and Yu-Dong Zhang},
  doi          = {10.1142/S0129065723500107},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2350010},
  shortjournal = {Int. J. Neural Syst.},
  title        = {An evolutionary attention-based network for medical image classification},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Driver drowsiness EEG detection based on tree federated
learning and interpretable network. <em>IJNS</em>, <em>33</em>(3),
2350009. (<a href="https://doi.org/10.1142/S0129065723500090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification of driver’s drowsiness state through Electroencephalogram (EEG) signals can effectively reduce traffic accidents, but EEG signals are usually stored in various clients in the form of small samples. This study attempts to construct an efficient and accurate privacy-preserving drowsiness monitoring system, and proposes a fusion model based on tree Federated Learning (FL) and Convolutional Neural Network (CNN), which can not only identify and explain the driver’s drowsiness state, but also integrate the information of different clients under the premise of privacy protection. Each client uses CNN with the Global Average Pooling (GAP) layer and shares model parameters. The tree FL transforms communication relationships into a graph structure, and model parameters are transmitted in parallel along connected branches of the graph. Moreover, the Class Activation Mapping (CAM) is used to find distinctive EEG features for representing specific classes. On EEG data of 11 subjects, it is found that this method has higher average accuracy, F1-score and AUC than the traditional classification method, reaching 73.56%, 73.26% and 78.23%, respectively. Compared with the traditional FL algorithm, this method better protects the driver’s privacy and improves communication efficiency.},
  archive      = {J_IJNS},
  author       = {Xue Qin and Yi Niu and Huiyu Zhou and Xiaojie Li and Weikuan Jia and Yuanjie Zheng},
  doi          = {10.1142/S0129065723500090},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2350009},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Driver drowsiness EEG detection based on tree federated learning and interpretable network},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Separating inhibitory and excitatory responses of epileptic
brain to single-pulse electrical stimulation. <em>IJNS</em>,
<em>33</em>(2), 2350008. (<a
href="https://doi.org/10.1142/S0129065723500089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enable an accurate recognition of neuronal excitability in an epileptic brain for modeling or localization of epileptic zone, here the brain response to single-pulse electrical stimulation (SPES) has been decomposed into its constituent components using adaptive singular spectrum analysis (SSA). Given the response at neuronal level, these components are expected to be the inhibitory and excitatory components. The prime objective is to thoroughly investigate the nature of delayed responses (elicited between 100 ms–1 s after SPES) for localization of the epileptic zone. SSA is a powerful subspace signal analysis method for separation of single channel signals into their constituent uncorrelated components. The consistency in the results for both early and delayed brain responses verifies the usability of the approach.},
  archive      = {J_IJNS},
  author       = {Sepehr Shirani and Antonio Valentin and Gonzalo Alarcon and Farhana Kazi and Saeid Sanei},
  doi          = {10.1142/S0129065723500089},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2350008},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Separating inhibitory and excitatory responses of epileptic brain to single-pulse electrical stimulation},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attention-based convolutional recurrent deep neural networks
for the prediction of response to repetitive transcranial magnetic
stimulation for major depressive disorder. <em>IJNS</em>,
<em>33</em>(2), 2350007. (<a
href="https://doi.org/10.1142/S0129065723500077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Repetitive Transcranial Magnetic Stimulation (rTMS) is proposed as an effective treatment for major depressive disorder (MDD). However, because of the suboptimal treatment outcome of rTMS, the prediction of response to this technique is a crucial task. We developed a deep learning (DL) model to classify responders (R) and non-responders (NR). With this aim, we assessed the pre-treatment EEG signal of 34 MDD patients and extracted effective connectivity (EC) among all electrodes in four frequency bands of EEG signal. Two-dimensional EC maps are put together to create a rich connectivity image and a sequence of these images is fed to the DL model. Then, the DL framework was constructed based on transfer learning (TL) models which are pre-trained convolutional neural networks (CNN) named VGG16, Xception, and EfficientNetB0. Then, long short-term memory (LSTM) cells are equipped with an attention mechanism added on top of TL models to fully exploit the spatiotemporal information of EEG signal. Using leave-one subject out cross validation (LOSO CV), Xception-BLSTM-Attention acquired the highest performance with 98.86% of accuracy and 97.73% of specificity. Fusion of these models as an ensemble model based on optimized majority voting gained 99.32% accuracy and 98.34% of specificity. Therefore, the ensemble of TL-LSTM-Attention models can predict accurately the treatment outcome.},
  archive      = {J_IJNS},
  author       = {Mohsen Sadat Shahabi and Ahmad Shalbaf and Behrooz Nobakhsh and Reza Rostami and Reza Kazemi},
  doi          = {10.1142/S0129065723500077},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2350007},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Attention-based convolutional recurrent deep neural networks for the prediction of response to repetitive transcranial magnetic stimulation for major depressive disorder},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Impulsivity classification using EEG power and explainable
machine learning. <em>IJNS</em>, <em>33</em>(2), 2350006. (<a
href="https://doi.org/10.1142/S0129065723500065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Impulsivity is a multidimensional construct often associated with unfavorable outcomes. Previous studies have implicated several electroencephalography (EEG) indices to impulsiveness, but results are heterogeneous and inconsistent. Using a data-driven approach, we identified EEG power features for the prediction of self-reported impulsiveness. To this end, EEG signals of 56 individuals (18 low impulsive, 20 intermediate impulsive, 18 high impulsive) were recorded during a risk-taking task. Extracted EEG power features from 62 electrodes were fed into various machine learning classifiers to identify the most relevant band. Robustness of the classifier was varied by stratified k -fold cross validation. Alpha and beta band power showed best performance in the classification of impulsiveness (accuracy = 95.18% and 95.11%, respectively) using a random forest classifier. Subsequently, a sequential bidirectional feature selection algorithm was used to estimate the most relevant electrode sites. Results show that as little as 10 electrodes are sufficient to reliably classify impulsiveness using alpha band power ( f -measure = 94.50%). Finally, the Shapley Additive exPlanations (SHAP) analysis approach was employed to reveal the individual EEG features that contributed most to the model’s output. Results indicate that frontal as well as posterior midline alpha power seems to be of most importance for the classification of impulsiveness.},
  archive      = {J_IJNS},
  author       = {Philippa Hüpen and Himanshu Kumar and Aliaksandra Shymanskaya and Ramakrishnan Swaminathan and Ute Habel},
  doi          = {10.1142/S0129065723500065},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2350006},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Impulsivity classification using EEG power and explainable machine learning},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A prediction model for normal variation of somatosensory
evoked potential during scoliosis surgery. <em>IJNS</em>,
<em>33</em>(2), 2350005. (<a
href="https://doi.org/10.1142/S0129065723500053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Somatosensory evoked potential (SEP) has been commonly used as intraoperative monitoring to detect the presence of neurological deficits during scoliosis surgery. However, SEP usually presents an enormous variation in response to patient-specific factors such as physiological parameters leading to the false warning. This study proposes a prediction model to quantify SEP amplitude variation due to noninjury-related physiological changes of the patient undergoing scoliosis surgery. Based on a hybrid network of attention-based long-short-term memory (LSTM) and convolutional neural networks (CNNs), we develop a deep learning-based framework for predicting the SEP value in response to variation of physiological variables. The training and selection of model parameters were based on a 5-fold cross-validation scheme using mean square error (MSE) as evaluation metrics. The proposed model obtained MSE of 0.027 μ V 2 on left cortical SEP, MSE of 0.024 μ V 2 on left subcortical SEP, MSE of 0.031 μ V 2 on right cortical SEP, and MSE of 0.025 μ V 2 on right subcortical SEP based on the test set. The proposed model could quantify the affection from physiological parameters to the SEP amplitude in response to normal variation of physiology during scoliosis surgery. The prediction of SEP amplitude provides a potential varying reference for intraoperative SEP monitoring.},
  archive      = {J_IJNS},
  author       = {Ningbo Fei and Rong Li and Hongyan Cui and Yong Hu},
  doi          = {10.1142/S0129065723500053},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2350005},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A prediction model for normal variation of somatosensory evoked potential during scoliosis surgery},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Performance evaluation of error-correcting output coding
based on noisy and noiseless binary classifiers. <em>IJNS</em>,
<em>33</em>(2), 2350004. (<a
href="https://doi.org/10.1142/S0129065723500041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Error-correcting output coding (ECOC) is a method for constructing a multi-valued classifier using a combination of given binary classifiers. ECOC can estimate the correct category by other binary classifiers even if the output of some binary classifiers is incorrect based on the framework of the coding theory. The code word table representing the combination of these binary classifiers is important in ECOC. ECOC is known to perform well experimentally on real data. However, the complexity of the classification problem makes it difficult to analyze the classification performance in detail. For this reason, theoretical analysis of ECOC has not been conducted. In this study, if a binary classifier outputs the estimated posterior probability with errors, then this binary classifier is said to be noisy. In contrast, if a binary classifier outputs the true posterior probability, then this binary classifier is said to be noiseless. For a theoretical analysis of ECOC, we discuss the optimality for the code word table with noiseless binary classifiers and the error rate for one with noisy binary classifiers. This evaluation result shows that the Hamming distance of the code word table is an important indicator.},
  archive      = {J_IJNS},
  author       = {Gendo Kumoi and Hideki Yagi and Manabu Kobayashi and Masayuki Goto and Shigeichi Hirasawa},
  doi          = {10.1142/S0129065723500041},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2350004},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Performance evaluation of error-correcting output coding based on noisy and noiseless binary classifiers},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A sentiment analysis anomaly detection system for cyber
intelligence. <em>IJNS</em>, <em>33</em>(2), 2350003. (<a
href="https://doi.org/10.1142/S012906572350003X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the 2030 United Nations intent of world connection, Cyber Intelligence becomes the main area of the human dimension able of inflicting changes in geopolitical dynamics. In cyberspace, the new battlefield is the mind of people including new weapons like abuse of social media with information manipulation, deception by activists and misinformation. In this paper, a Sentiment Analysis system with Anomaly Detection (SAAD) capability is proposed. The system, scalable and modular, uses an OSINT-Deep Learning approach to investigate on social media sentiment in order to predict suspicious anomaly trend in Twitter posts. Anomaly detection is investigated with a new semi-supervised process that is able to detect potentially dangerous situations in critical areas. The main contributions of the paper are the system suitability for working in different areas and domains, the anomaly detection procedure in sentiment context and a time-dependent confusion matrix to address model evaluation with unbalanced dataset. Real experiments and tests were performed on Sahel Region. The detected anomalies in negative sentiment have been checked by experts of Sahel area, proving true links between the models results and real situations observable from the tweets.},
  archive      = {J_IJNS},
  author       = {Roberta Maisano and Gian Luca Foresti},
  doi          = {10.1142/S012906572350003X},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2350003},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A sentiment analysis anomaly detection system for cyber intelligence},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multimodal fusion approach for human activity recognition.
<em>IJNS</em>, <em>33</em>(1), 2350002. (<a
href="https://doi.org/10.1142/S0129065723500028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of human activity recognition (HAR) has been increasingly attracting the efforts of the research community, having several applications. It consists of recognizing human motion and/or behavior within a given image or a video sequence, using as input raw sensor measurements. In this paper, a multimodal approach addressing the task of video-based HAR is proposed. It is based on 3D visual data that are collected using an RGB + depth camera, resulting to both raw video and 3D skeletal sequences. These data are transformed into six different 2D image representations; four of them are in the spectral domain, another is a pseudo-colored image. The aforementioned representations are based on skeletal data. The last representation is a “dynamic” image which is actually an artificially created image that summarizes RGB data of the whole video sequence, in a visually comprehensible way. In order to classify a given activity video, first, all the aforementioned 2D images are extracted and then six trained convolutional neural networks are used so as to extract visual features. The latter are fused so as to form a single feature vector and are fed into a support vector machine for classification into human activities. For evaluation purposes, a challenging motion activity recognition dataset is used, while single-view, cross-view and cross-subject experiments are performed. Moreover, the proposed approach is compared to three other state-of-the-art methods, demonstrating superior performance in most experiments.},
  archive      = {J_IJNS},
  author       = {Dimitrios Koutrintzes and Evaggelos Spyrou and Eirini Mathe and Phivos Mylonas},
  doi          = {10.1142/S0129065723500028},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2350002},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A multimodal fusion approach for human activity recognition},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated interictal epileptiform discharge detection from
scalp EEG using scalable time-series classification approaches.
<em>IJNS</em>, <em>33</em>(1), 2350001. (<a
href="https://doi.org/10.1142/S0129065723500016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning for automated interictal epileptiform discharge (IED) detection has been topical with many published papers in recent years. All existing works viewed EEG signals as time-series and developed specific models for IED classification; however, general time-series classification (TSC) methods were not considered. Moreover, none of these methods were evaluated on any public datasets, making direct comparisons challenging. This paper explored two state-of-the-art convolutional-based TSC algorithms, InceptionTime and Minirocket, on IED detection. We fine-tuned and cross-evaluated them on a public (Temple University Events — TUEV) and two private datasets and provided ready metrics for benchmarking future work. We observed that the optimal parameters correlated with the clinical duration of an IED and achieved the best area under precision-recall curve (AUPRC) of 0.98 and F1 of 0.80 on the private datasets, respectively. The AUPRC and F1 on the TUEV dataset were 0.99 and 0.97, respectively. While algorithms trained on the private sets maintained their performance when tested on the TUEV data, those trained on TUEV could not generalize well to the private data. These results emerge from differences in the class distributions across datasets and indicate a need for public datasets with a better diversity of IED waveforms, background activities and artifacts to facilitate standardization and benchmarking of algorithms.},
  archive      = {J_IJNS},
  author       = {D. Nhu and M. Janmohamed and L. Shakhatreh and O. Gonen and P. Perucca and A. Gilligan and P. Kwan and T. J. O’Brien and C. W. Tan and L. Kuhlmann},
  doi          = {10.1142/S0129065723500016},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2350001},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Automated interictal epileptiform discharge detection from scalp EEG using scalable time-series classification approaches},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual-modal information bottleneck network for seizure
detection. <em>IJNS</em>, <em>33</em>(1), 2250061. (<a
href="https://doi.org/10.1142/S0129065722500617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning has shown very competitive performance in seizure detection. However, most of the currently used methods either convert electroencephalogram (EEG) signals into spectral images and employ 2D-CNNs, or split the one-dimensional (1D) features of EEG signals into many segments and employ 1D-CNNs. Moreover, these investigations are further constrained by the absence of consideration for temporal links between time series segments or spectrogram images. Therefore, we propose a Dual-Modal Information Bottleneck (Dual-modal IB) network for EEG seizure detection. The network extracts EEG features from both time series and spectrogram dimensions, allowing information from different modalities to pass through the Dual-modal IB, requiring the model to gather and condense the most pertinent information in each modality and only share what is necessary. Specifically, we make full use of the information shared between the two modality representations to obtain key information for seizure detection and to remove irrelevant feature between the two modalities. In addition, to explore the intrinsic temporal dependencies, we further introduce a bidirectional long-short-term memory (BiLSTM) for Dual-modal IB model, which is used to model the temporal relationships between the information after each modality is extracted by convolutional neural network (CNN). For CHB-MIT dataset, the proposed framework can achieve an average segment-based sensitivity of 97.42%, specificity of 99.32%, accuracy of 98.29%, and an average event-based sensitivity of 96.02%, false detection rate (FDR) of 0.70/h. We release our code at https://github.com/LLLL1021/Dual-modal-IB .},
  archive      = {J_IJNS},
  author       = {Jiale Wang and Xinting Ge and Yunfeng Shi and Mengxue Sun and Qingtao Gong and Haipeng Wang and Wenhui Huang},
  doi          = {10.1142/S0129065722500617},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2250061},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Dual-modal information bottleneck network for seizure detection},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Edge detection method based on nonlinear spiking neural
systems. <em>IJNS</em>, <em>33</em>(1), 2250060. (<a
href="https://doi.org/10.1142/S0129065722500605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinear spiking neural P (NSNP) systems are a class of neural-like computational models inspired from the nonlinear mechanism of spiking neurons. NSNP systems have a distinguishing feature: nonlinear spiking mechanism. To handle edge detection of images, this paper proposes a variant, nonlinear spiking neural P (NSNP) systems with two outputs (TO), termed as NSNP-TO systems. Based on NSNP-TO system, an edge detection framework is developed, termed as ED-NSNP detector. The detection ability of ED-NSNP detector relies on two convolutional kernels. To obtain good detection performance, particle swarm optimization (PSO) is used to optimize the parameters of the two convolutional kernels. The proposed ED-NSNP detector is evaluated on several open benchmark images and compared with seven baseline edge detection methods. The comparison results indicate the availability and effectiveness of the proposed ED-NSNP detector.},
  archive      = {J_IJNS},
  author       = {Ronghao Xian and Rikong Lugu and Hong Peng and Qian Yang and Xiaohui Luo and Jun Wang},
  doi          = {10.1142/S0129065722500605},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2250060},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Edge detection method based on nonlinear spiking neural systems},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mixture 2D convolutions for 3D medical image segmentation.
<em>IJNS</em>, <em>33</em>(1), 2250059. (<a
href="https://doi.org/10.1142/S0129065722500599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional (3D) medical image segmentation plays a crucial role in medical care applications. Although various two-dimensional (2D) and 3D neural network models have been applied to 3D medical image segmentation and achieved impressive results, a trade-off remains between efficiency and accuracy. To address this issue, a novel mixture convolutional network (MixConvNet) is proposed, in which traditional 2D/3D convolutional blocks are replaced with novel MixConv blocks. In the MixConv block, 3D convolution is decomposed into a mixture of 2D convolutions from different views. Therefore, the MixConv block fully utilizes the advantages of 2D convolution and maintains the learning ability of 3D convolution. It acts as 3D convolutions and thus can process volumetric input directly and learn intra-slice features, which are absent in the traditional 2D convolutional block. By contrast, the proposed MixConv block only contains 2D convolutions; hence, it has significantly fewer trainable parameters and less computation budget than a block containing 3D convolutions. Furthermore, the proposed MixConvNet is pre-trained with small input patches and fine-tuned with large input patches to improve segmentation performance further. In experiments on the Decathlon Heart dataset and Sliver07 dataset, the proposed MixConvNet outperformed the state-of-the-art methods such as UNet3D, VNet, and nnUnet.},
  archive      = {J_IJNS},
  author       = {Jianyong Wang and Lei Zhang and Yi Zhang},
  doi          = {10.1142/S0129065722500599},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2250059},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Mixture 2D convolutions for 3D medical image segmentation},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unraveling the development of an algorithm for recognizing
primary emotions through electroencephalography. <em>IJNS</em>,
<em>33</em>(1), 2250057. (<a
href="https://doi.org/10.1142/S0129065722500575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The large range of potential applications, not only for patients but also for healthy people, that could be achieved by affective brain–computer interface (aBCI) makes more latent the necessity of finding a commonly accepted protocol for real-time EEG-based emotion recognition. Based on wavelet package for spectral feature extraction, attending to the nature of the EEG signal, we have specified some of the main parameters needed for the implementation of robust positive and negative emotion classification. Twelve seconds has resulted as the most appropriate sliding window size; from that, a set of 20 target frequency-location variables have been proposed as the most relevant features that carry the emotional information. Lastly, QDA and KNN classifiers and population rating criterion for stimuli labeling have been suggested as the most suitable approaches for EEG-based emotion recognition. The proposed model reached a mean accuracy of 98% (s.d. 1.4) and 98.96% (s.d. 1.28) in a subject-dependent (SD) approach for QDA and KNN classifier, respectively. This new model represents a step forward towards real-time classification. Moreover, new insights regarding subject-independent (SI) approximation have been discussed, although the results were not conclusive.},
  archive      = {J_IJNS},
  author       = {Jennifer Sorinas and Juan C. Fernandez Troyano and Jose Manuel Ferrández and Eduardo Fernandez},
  doi          = {10.1142/S0129065722500575},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2250057},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Unraveling the development of an algorithm for recognizing primary emotions through electroencephalography},
  volume       = {33},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
