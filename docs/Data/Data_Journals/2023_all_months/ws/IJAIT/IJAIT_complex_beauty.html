<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJAIT_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijait---84">IJAIT - 84</h2>
<ul>
<li><details>
<summary>
(2023). A deep stacked ensemble model for microarray data
classification with boosted meta classifier. <em>IJAIT</em>,
<em>32</em>(8), 2350074. (<a
href="https://doi.org/10.1142/S0218213023500744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification of microarray data is one of the major research interests in the biomedical field. It allows physicians for early detection of cancer through analysis of the Deoxyribonucleic acid (DNA). Classification of these sensitive data is still challenging due to the small sample and more feature size. In this paper, the authors have used an ensemble model for classifying two types of leukemia as Acute lymphocytic leukemia (ALL) and Acute myelocytic leukemia (AML). The work is carried out with other types of genetic data such as Leukemia, lung tumor, liver cancer, and liver Cirrhosis. The biomedical data are imbalanced. The ensemble classifier is based on a stacked approach where deep neural network (DNN) classifiers are used as the base classifier. The structure of each DNN is chosen as the homogenous type for the same training process for all classifiers. Because of the adaptive nature and random weight initialization, it provides different results for each classifier. The outputs of the base classifiers are again fed to a gradient boosting ensemble model termed a meta classifier. The meta classifier provides the final classification output. For comparison purposes, two types of meta-classifiers such as support vector machine (SVM) and ensemble gradient boosting are used in the proposed work. The performance of the model is verified well and the results are provided in the result section. From the experimental result, it is observed that the classification accuracy is 96% with SVM and 98% with boosted meta classifier for leukemia data, whereas 99.04% for lung tumor and 99.03% for liver Cirrhosis.},
  archive      = {J_IJAIT},
  author       = {Mihir Narayan Mohanty and Saumendra Kumar Mohapatra and Abhishek Das},
  doi          = {10.1142/S0218213023500744},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {8},
  pages        = {2350074},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {A deep stacked ensemble model for microarray data classification with boosted meta classifier},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Image enhancement approach for the underwater images using
the optimized color balancing model. <em>IJAIT</em>, <em>32</em>(8),
2350050. (<a href="https://doi.org/10.1142/S0218213023500501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Marine resources are one of the valuable resources that need to be explored and protected, but are affected due to environmental factors. The underwater images are distorted due to the light scattering and absorption phenomenon, which draws the attention of the researcher to restoring the underwater images which is a challenging task. High-quality underwater images help us to learn and study deep-sea environments, and also help in gaining deep knowledge about the ocean resources. In this research, deep learning methods are used for obtaining high-quality underwater images. Accordingly, a channel-based white balancing and social situation-aware guard optimization (WBSSGO) dependent multi-variant balancing color correction model is proposed by integrating the grouping behavior and adaptability nature of the guards and flocks, which acts as the search agents in the proposed optimization. A multi-variant-based white balancing model is employed for balancing the channels and correcting the distorted underwater images. The performance of the developed model is validated using PIQE, BRISQUE, and UCIQE, which acquired minimal values of 27.202, 24.692, and 29.725, respectively with comparative methods, while the higher value of SDME is 64.049 dB for the proposed method, which is reported to acquire the higher visual quality of underwater images.},
  archive      = {J_IJAIT},
  author       = {Lyernisha S. R. and C. Seldev Christopher and Fernisha S. R.},
  doi          = {10.1142/S0218213023500501},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {8},
  pages        = {2350050},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Image enhancement approach for the underwater images using the optimized color balancing model},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). COVID-attention: Efficient COVID19 detection using
pre-trained deep models based on vision transformers and x-ray images.
<em>IJAIT</em>, <em>32</em>(8), 2350046. (<a
href="https://doi.org/10.1142/S021821302350046X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID19 is becoming more and more threatening to human life since the appearance of many variants like Alpha, Omicron and Delta. These variants have dozens of mutations that can make their diagnosis more challenging. Despite the recent success of Convolutional Neural Networks (CNN) to detect COVID19 automatically using transfer learning techniques, they are not the most robust to accomplish this task since some translation, scale and hyperparameter variations can affect the accuracy. Newly, Vision Transformers (ViT) are becoming increasingly popular to handle similar tasks and to deal with the aforementioned variations. In this paper, we propose an enhanced ViT architecture for COVID19 detection referred to as COVID-Attention. The proposed ViT-based models are robust due to their capability to capture long-range dependencies within images thanks to the attention mechanism, which is the core of the transformer block. We compare the efficiency of our proposed method to top-performing CNN baselines using two different transfer learning modes. We further show in our experiments that adding a convolution block to the top of the ViT model (i.e. as an initial block) can avoid the collapse issue and enhance the ViT performance using the recent ViT C model. We finally show that ViT-based models give more explainable visualization compared to CNN models using the Grad-CAM technique in order to highlight the attention map that affects the classification decision. Our experiments have been conducted on two recent databases of X-ray images and show high performance compared to the state-of-the-art methods in three-class classifications.},
  archive      = {J_IJAIT},
  author       = {Imed-Eddine Haouli and Walid Hariri and Hassina Seridi-Bouchelaghem},
  doi          = {10.1142/S021821302350046X},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {8},
  pages        = {2350046},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {COVID-attention: Efficient COVID19 detection using pre-trained deep models based on vision transformers and X-ray images},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Epileptic seizure detection in EEG signal using optimized
convolutional neural network with selected feature set. <em>IJAIT</em>,
<em>32</em>(8), 2350045. (<a
href="https://doi.org/10.1142/S0218213023500458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article implements novel epileptic seizure detection by EEG signal that includes various phases: Feature extraction, Feature selection, and Classification. Originally, the input EEG signal is subjected to the preprocessing phase, and from the preprocessed signal, certain features are extracted in which the features like TDFs, FDFs, and TFDFs are extracted. Here, the Time Domain Features (TDFs) include Non-linear energy (NE), Permutation Entropy (PE), and Weighted Permutation Entropy (WPE); the Frequency Domain Features (FDFs) consists of Intensity Weighted Mean Frequency (IWMF); and the Time-Frequency Domain Features (TFDFs) consists of the “Weighted Multi-scale Rényi Permutation Entropy (WMRPE)”. Moreover, the extracted features are subjected to the feature selection phase. An improved chi-square model is proposed for selecting the appropriate features. Then, the chosen features are subjected to the classification process. Here, the classification is performed using an Optimized Convolutional Neural Network (CNN). To make the detection more precise, the CNN weights are tuned optimally through a Weighting Factor Based Shark Smell Optimization (IWFSSO) model. The MCC of the implemented CNN+IWFSSO method achieved a better value for a learning percentage 90%; nevertheless, the compared existing models accomplish a smaller value for dataset 2.},
  archive      = {J_IJAIT},
  author       = {Nusrat Fatma and Pawan Singh and Mohammad Khubeb Siddiqui},
  doi          = {10.1142/S0218213023500458},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {8},
  pages        = {2350045},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Epileptic seizure detection in EEG signal using optimized convolutional neural network with selected feature set},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Minimization of makespan and total completion time for
hybrid job shop scheduling problem using genetic approaches.
<em>IJAIT</em>, <em>32</em>(8), 2350041. (<a
href="https://doi.org/10.1142/S0218213023500410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with two different versions of Hybrid Job Shop Scheduling Problems (HJSP); the minimization of the maximum completion time (makespan) and the minimization of the total completion time. State of the art shows that the literature on HJSP is rather scarce and that the majority of works concern the general problem called Flexible Job Shop Scheduling Problem (FJSP) in which parallel machines of a stage may have different speeds or yields. We propose the use of a genetic algorithm (GA) and a hybrid version of a GA (HGA) that applies a stochastic local search with two operators, specifically adapted to the HJSP. To conduct a clear statistical study based on the GA, HGA, and other state-of-the-art approaches, we extended our testbed to cover many existing benchmarks. The results of our experimental study show that our proposed algorithms improve the best-known results on a large set of benchmarks found in the literature. The scalability study shows that the proposed algorithm scales better and can deal with larger instances in the literature.},
  archive      = {J_IJAIT},
  author       = {Seifeddine Abdelhak and Issam Nouaouri and Saoussen Krichen and Gilles Goncalves},
  doi          = {10.1142/S0218213023500410},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {8},
  pages        = {2350041},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Minimization of makespan and total completion time for hybrid job shop scheduling problem using genetic approaches},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient method for video object detection in automatic
scoring of physical experimental operations. <em>IJAIT</em>,
<em>32</em>(8), 2350040. (<a
href="https://doi.org/10.1142/S0218213023500409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic scoring of students’ physical experimental operations is a very practical application which has not been researched deeply. The common method for automatic scoring of students’ experimental operations is to infer the behavior of experimental operations through the state of experimental instruments. Video object detection is the basic task of detecting the state of experimental instruments, and the problem of missed detection or false detection in video multi-object detection is one of the main reasons leading to the error of automatic scoring results. However, existing methods of video object detection mainly improve the accuracy of the model in public datasets, which has the disadvantage of not correcting false detection while improving accuracy. Therefore, an efficient video object detection method composed of YOLOv5 and a logical reasoning post-processing method was proposed to fill this gap. We compared our method with other state-of-the-art methods on three independent datasets of physical experimental instruments. We established a pipeline for automatic scoring of students’ experimental operations, designed flow charts and state score tables of three physics experiments, and compared the automatic scoring results with the average scores of six experimental teachers. The results show that our method is more robust and efficient in this application scenario. We hope this report can promote the application of logical reasoning methods in video object detection.},
  archive      = {J_IJAIT},
  author       = {Wenbin Zeng and Jichang Guo and Luguo Hao and Jianfei Liu},
  doi          = {10.1142/S0218213023500409},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {8},
  pages        = {2350040},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {An efficient method for video object detection in automatic scoring of physical experimental operations},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid CNN model for deep feature extraction for diabetic
retinopathy detection and gradation. <em>IJAIT</em>, <em>32</em>(8),
2350036. (<a href="https://doi.org/10.1142/S0218213023500367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy (DR) is a complication of prolonged diabetic mellitus causing damage to the micro-vascular system in retina. Computer-aided detection of DR can significantly reduce time, effort, and cost in early diagnosis and thereby restrict further complications. In this paper, we present a deep learning based framework for automated DR stage classification from fundus retinal images.We design and develop a custom build Convolutional Neural Network (CNN) model named Model-IVS to extract meaningful and discriminative features from the retinal fundus images. The proposed hybrid-CNN combines the multi-scale pyramidal feature processing concept of inception model with the convolutional pipeline based feature extraction concept of VGG-Nets and adopts multi-scale feature concatenation based short-cut connections of DenseNet with learnable convolutions. For the binary classification tasks, we employ Model-IVS as a feature extractor and use Support Vector Machine (SVM) classifier on the reduced features obtained through principal component analysis. The proposed hybrid model is end-to-end trained incrementally on a class-balanced dataset curated from the train set of EyePACS dataset. The cross-dataset generalization of the proposed hybrid CNN based DR classification framework is evaluated on APTOS, MESSIDOR-1 and MESSIDOR-2 datasets. Experimental results demonstrate that our model has outperformed all the existing state-of-the-art methods for DR severity grading task on APTOS dataset. The proposed Model-IVS has achieved best accuracy, AUC-ROC, and kappa score of 84.33%, 0.978 and 0.899, respectively in DR severity grading task. In binary classification tasks like DR screening and referable DR predictions, our Model-IVS feature extraction network with SVM classifier on PCA features has also achieved comparable performance results w.r.t. the state-of-the-art methods. In DR screening task, we recorded an accuracy of 97.84%, 87.42%, and 89.67% on APTOS, MESSIDOR-1, and MESSIDOR-2 datasets, respectively. In referable DR prediction, we achieved AUC-ROC score of 0.987, 0.928, and 0.873 on APTOS, MESSIDOR-1, and MESSIDOR-2 datasets, respectively.},
  archive      = {J_IJAIT},
  author       = {Nilarun Mukherjee and Souvik Sengupta},
  doi          = {10.1142/S0218213023500367},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {8},
  pages        = {2350036},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {A hybrid CNN model for deep feature extraction for diabetic retinopathy detection and gradation},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transfer learning-based drowsiness detection system for
driver assistance and classification of traffic signs employing a deep
convolutional neural network. <em>IJAIT</em>, <em>32</em>(8), 2350035.
(<a href="https://doi.org/10.1142/S0218213023500355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research paper, a comparative analysis of various image enhancements in the spatial domain techniques was performed based on three-dimensional image quality statistics such as mean squared error (MSE), peak signal-to-noise ratio (PSNR), and structural similarity for measuring the image quality (SSIM). The conditions for choosing the best method are low mean square error (MSE) and high peak signal-to-noise ratio as well as the structural similarity for measuring the image quality. The pre-processed image was subjected to a classification task using a stepwise version of pre-trained deep convolutional neural networks. The problem of driver drowsiness caused by fatigue, lack of sleep, medication, etc. will have to be solved by improving the efficiency of driver drowsiness detection. Many traffic accidents are largely caused by drowsy drivers. Driver fatigue and distraction can cause a lack of alertness, which can lead to driver inattention. In this paper, we proposed a new deep-learning technique for driver drowsiness detection. Two methods using convolutional deep neural network and GoogleNet transfer learning are compared to achieve a better accuracy of 99%.},
  archive      = {J_IJAIT},
  author       = {Abhinav V. Deshpande and M. Monica Subashini},
  doi          = {10.1142/S0218213023500355},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {8},
  pages        = {2350035},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Transfer learning-based drowsiness detection system for driver assistance and classification of traffic signs employing a deep convolutional neural network},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development of optimal hyperparameter tuning-cycle GAN for
photo-realistic face age progression model. <em>IJAIT</em>,
<em>32</em>(7), 2350068. (<a
href="https://doi.org/10.1142/S0218213023500689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face age progression aims to change an individual’s face from a provided face image to forecast how that image will look in the future. Face aging is gaining much attention in today’s environment, which needs better security and a touchless unique identification mechanism. Researchers are focused on creating face processing algorithms to address the difficulty of producing realistic aged faces for smart system applications over the earlier decades. In the literature, the two basic needs of face age progression, aging accuracy, and identity preservation are not thoroughly addressed. According to the extraordinary gains in image synthesis made by deep generative methods and their significant influence on a wide variety of practical applications such as identifying missing persons using entertainment, childhood images, and so on, face age progression/regression has reawakened attention. The majority of present techniques concentrate on face age progression and is beneficial and productive in learning the transition across age groups utilizing paired data, i.e., face images of the similar individual at various ages. Through the motivation of the important success attained by Generative Adversarial Networks (GANs), this paper uses tactics to implement the improved Cycle GAN-based intelligent face age progression model. Initially, the standard datasets for the face progression are gathered, and the face is detected using the Viola-Jones object detection algorithm. Then, the pre-processing of the facial image is performed by median filtering and contrast enhancement techniques. Once the image is pre-processed, the Hyperparameter Tuning-Cycle GAN (HT-Cycle GAN) is adopted for face age progression. As an improvement, the hyperparameters of the Cycle GAN are optimized or tuned by the modified Galactic Swarm Optimization (GSO), known as Best Fitness-based Galactic Swarm Optimization (BF-GSO). From the evaluation of statistical analysis, the similarity score of BF-GSO-HT-CycleGAN is 0.80%, 3.33%, and 2.86% higher than cGAN, CycleGAN, and Dubbed FaceGAN, respectively. Here, the Dubbed FaceGAN is the 2nd greatest network. Furthermore, compared to traditional models utilizing distinct standard datasets, the experimental findings show that the suggested technique attains efficiency, accuracy, and flexibility.},
  archive      = {J_IJAIT},
  author       = {Tejaswini Yadav and Rajneeshkaur Sachdeo},
  doi          = {10.1142/S0218213023500689},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {7},
  pages        = {2350068},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Development of optimal hyperparameter tuning-cycle GAN for photo-realistic face age progression model},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient prediction of seasonal infectious diseases using
hybrid machine learning algorithms with feature selection techniques.
<em>IJAIT</em>, <em>32</em>(7), 2350044. (<a
href="https://doi.org/10.1142/S0218213023500446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early seasonal disease risk identification is the most challenging task in the medical industry. The capacity to detect patients at risk of improvement throughout their hospital stay is critical for effective patient allocation and care among patients with seasonal diseases. Patient risk factor prediction is the most important issue in reducing victim mortality. Machine learning plays a vital role in identifying the risk level of patients. In this research, we consider four seasonal diseases such as dengue, malaria, typhoid, and pneumonia. In this research, the researcher finds the dangerous symptoms of victims based on their age group. The real-time dataset was used in this study. The dataset for this study was gathered from hospitals in the Madurai district between 2019 and 2020. Feature selection is the prime element of patient risk recognition. It is used to pick the most accurate attributes for prediction. The dataset is divided into 70% training data and 30% testing data. This research proposes the feature selection method Boruta-XGBoost for improving accuracy. In this research, we discuss various attribute selection algorithms, including the Boruta algorithm, the XGBoost algorithm, the recursive feature elimination method (RFE), and the PRF-BXGBoost (Patient Risk Factor-Boruta-XGBoost) algorithm. The proposed method provides greater accuracy when compared to other variable selection methods. The time complexity of the proposed method is low when compared to other algorithms.},
  archive      = {J_IJAIT},
  author       = {K. Indhumathi and K. Sathesh Kumar},
  doi          = {10.1142/S0218213023500446},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {7},
  pages        = {2350044},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Efficient prediction of seasonal infectious diseases using hybrid machine learning algorithms with feature selection techniques},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep ensemble classification with self improved optimization
for attack detection towards secured virtualization in cloud.
<em>IJAIT</em>, <em>32</em>(7), 2350038. (<a
href="https://doi.org/10.1142/S0218213023500380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the extraordinary advances in tech companies and development in cloud computing, it has turned out to be ever more familiar for companies to integrate virtualization in data centers to entirely exploit their hardware sources. Accordingly, virtualization and security have gone under varied changes recently. Virtualization and its exceptional design have numerous advantages and characteristics over conventional non-virtualized technologies. Nevertheless, these novel characters form novel vulnerabilities and probable attacks in virtualized systems. Many recent studies have developed to detect those attacks, but they still have challenges like, need to invest more, if it must be done fast, data security could be at danger and scalability could be difficult. As a result, the primary goal of this study is to detect attack for getting secured virtualization in cloud. Therefore, the purpose of this research is to suggest a new, two-stage, protected virtualization paradigm for the cloud. At first, the “higher-order statistical features, flow-based features, mutual information (MI) based features and improved correlation features” are derived. Deep convolutional neural network (DCNN) 1 and 2 are then used to classify the derived features. To detect network assaults, LSTM 1 and 2 are applied to the outputs from DCNN 1 and 2. Here, the Self Customized Aquila Optimizer is used to adjust the DCNN weights to their optimum level (SC-AO). Additionally, analysis is performed using a range of metrics. Particularly, the proposed HC + SC-AO scheme attained improved accuracy of 0.938108 and 0.958249 for both the datasets respectively.},
  archive      = {J_IJAIT},
  author       = {Bhavana Gupta and Nishchol Mishra},
  doi          = {10.1142/S0218213023500380},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {7},
  pages        = {2350038},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Deep ensemble classification with self improved optimization for attack detection towards secured virtualization in cloud},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predictive learning methods to price european options using
ensemble model and multi-asset data. <em>IJAIT</em>, <em>32</em>(7),
2350034. (<a href="https://doi.org/10.1142/S0218213023500343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Option contracts are financial instruments that serve economic purposes for various institutions and individuals. Option plays a crucial role in developing the financial market due to the high innovation and liquidity associated with it. However, due to option contract’s increased adaptability and responsiveness, its pricing mechanism has become complicated. The conventional parametric models suffer from various computing restrictions and implausible economic and statistical presumptions leading to deviations from real-world dynamics. Thus, data-driven strategies built upon non-parametric models seems compelling. Machine Learning (ML) serves as a powerful tool that can increase efficiency and productivity by automated processes, decreasing human biases and errors caused by psychological or emotional factors. Most of the existing literature involves only neural networks, whereas alternative algorithms remain undiscovered. This study explores the effectiveness of various ML algorithms through different experimentation. The ML algorithms harnessed for the study are Artificial Neural Networks (ANN), XGBoost, Decision Tree Regression, Support Vector Regression, Random Forest Regression, Long short-term memory (LSTM) Network and Gated recurrent unit (GRU) Network. Furthermore, multi-asset training and ensemble modelling are carried out to enhance predictive performance. A comparison is carried out with the seminal Black-Scholes model to highlight the advantages of the ML approach. The models are evaluated for European option contracts. The underlying assets used are NIFTY50 and BANKNIFTY indices from India’s National Stock Exchange (NSE). ML algorithms performed superior to the Black-Scholes model by a significant margin. Additionally, the models are evaluated on data collected following the outbreak of the COVID epidemic to get insight into the effects of abrupt changes in market sentiment.},
  archive      = {J_IJAIT},
  author       = {Kumar Shubham and Vivek Tiwari and Kuldip Singh Patel},
  doi          = {10.1142/S0218213023500343},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {7},
  pages        = {2350034},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Predictive learning methods to price european options using ensemble model and multi-asset data},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning approach for multi-class semantic segmentation
of UAV images. <em>IJAIT</em>, <em>32</em>(7), 2350033. (<a
href="https://doi.org/10.1142/S0218213023500331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image understanding plays a very crucial role in remote sensing applications. For this, image semantic segmentation is one of the approaches where each pixel of an image is assigned to particular classes based on various features. Aerial semantic segmentation suffers from the class imbalance problem. Proper differentiation of least represented categories is challenging and a goal for the state-of-art approach. In this work, we present a novel deep learning method to perform this task. We proposed a lightweight encoder-decoder network residual depth separable UNet (RDS-UNet) and conditional random field for effective segmentation on very high-resolution aerial images. We proposed patch-with-multi-class sampling to handle the class imbalance problem without increasing the computational overhead during the training process. We created a semi-precise annotated UAV dataset named NESAC UAV Seg for the aerial semantic segmentation task. We demonstrated the efficacy of our model using the publicly available benchmark Drone Deploy dataset and our NESAC UAV Seg dataset. Our model required approximately half the number of trainable parameters and floating point operations compared to other methods. A detailed ablation study is presented to showcase the effectiveness of various modules utilized in our network.},
  archive      = {J_IJAIT},
  author       = {Avinash Chouhan and Dibyajyoti Chutia and Shiv Prasad Aggarwal},
  doi          = {10.1142/S0218213023500331},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {7},
  pages        = {2350033},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Deep learning approach for multi-class semantic segmentation of UAV images},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Metaheuristic algorithms in optimal power flow analysis: A
qualitative systematic review. <em>IJAIT</em>, <em>32</em>(7), 2350032.
(<a href="https://doi.org/10.1142/S021821302350032X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimal operation of any electrical power system is considered a crucial aspect in modern day optimization. The optimal power flow problem is widely known as an effective tool to plan the operation of these systems. However, due to the nonlinearity of variables such as generation cost and power losses, computation is difficult with conventional optimization methods. Therefore, various metaheuristic algorithms are implemented to solve the Optimal Power Flow (OPF) problem and overcome the possible drawback of conventional methods. This systematic review will explore various popular metaheuristic techniques that are employed to solve the optimal power flow problem such as Artificial Bee Colony (ABC), Ant Colony Optimization (ACO), Particle Swarm Optimization (PSO), and Genetic Algorithm (GA) along with various newly introduced and emerging optimization techniques. Diverse techniques were reviewed for optimizing the OPF problem, however, deployment of artificial bee colony optimization algorithm has proved its popularity due to its fast computational speed and rate of convergence as compared to the previously established algorithms based on the reported qualitative data from existing studies. Furthermore, the qualitative data analyzed presented a higher frequency of studies adopting artificial bee colony optimization algorithm, presenting accurate results in critical power system aspects such as generation cost, real power losses, and total emissions. Additionally, this research provides the pathway for future research in improving the performance of metaheuristics when applied to the optimal power flow problem.},
  archive      = {J_IJAIT},
  author       = {Mena Maurice Farag and Razan Adnan Alhamad and Ali Bou Nassif},
  doi          = {10.1142/S021821302350032X},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {7},
  pages        = {2350032},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Metaheuristic algorithms in optimal power flow analysis: A qualitative systematic review},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An explainable AI model for ICU admission prediction of
COVID-19 patients. <em>IJAIT</em>, <em>32</em>(7), 2350031. (<a
href="https://doi.org/10.1142/S0218213023500318">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 has overwhelmed hospitals all around the world, because of the very high number of patients requiring intubation. Predicting and anticipating which patients will be intubated can help hospitals better allocate their resources. For this, we created an explainable AI model that receives some medical data for each patient and returns a prediction on whether they will be intubated later on, while also explaining the argumentation process that led to that conclusion. This model can help medical professionals better manage the ICU beds and the patients between hospitals and warn them on the symptoms and signs to look for in patients worsening. To obtain the model, we first trained various ML algorithms on a dataset of COVID ICU admissions. Then, using the most accurate of the models, we obtained the sum of the most important rules, using R’s inTrees framework. With the rules obtained, we produced a program in Gorgias written in Prolog. We added some more rules and changed the ordering to come up with a program that requires some patient vitals and blood results as inputs and then returns the prediction along with its reasoning.},
  archive      = {J_IJAIT},
  author       = {Eleni Dazea and Petros Stefaneas},
  doi          = {10.1142/S0218213023500318},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {7},
  pages        = {2350031},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {An explainable AI model for ICU admission prediction of COVID-19 patients},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Alternative to buy-and-hold: Predicting indices direction
and improving returns using a novel hybrid LSTM model. <em>IJAIT</em>,
<em>32</em>(7), 2350028. (<a
href="https://doi.org/10.1142/S0218213023500288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting stock direction is challenging as stock price time series are extremely noisy. Moreover, the widely accepted efficient market hypothesis states that it is impossible to consistently generate excess returns than the market over a long-term horizon. Hence, the best approach for investors is thought to be the passive buy-and-hold strategy in indices. However, some researchers suggest that the market does have a predictable component. This paper’s objective is to provide investors with an alternative predictive system that generates an excess return over the classical buy-and-hold strategy and reduces risk. The authors propose an alternative investing model, Average True Range (ATR) and Momentum-based Long Short-Term Memory online (a-m-LSTM-o), that innovatively uses the technical indicators with Long Short-Term Memory (LSTM). Further, this study experiments with multiple other LSTM investing models using daily indices data of the world’s top five economies. Based on the prediction, the proposed model’s return is 172%, which is significantly higher than the buy-and-hold return of 139%, and it also has a lower drawdown of −49% compared to −51% for the buy-and-hold strategy. Hence, the authors suggest that the proposed model may be a good alternative to the passive approach of the investors.},
  archive      = {J_IJAIT},
  author       = {Mohit Beniwal and Archana Singh and Nand Kumar},
  doi          = {10.1142/S0218213023500288},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {7},
  pages        = {2350028},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Alternative to buy-and-hold: Predicting indices direction and improving returns using a novel hybrid LSTM model},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Trust and energy-aware multipath selection in MANET for
ensuring quality-of-service using the optimization protocol.
<em>IJAIT</em>, <em>32</em>(7), 2350023. (<a
href="https://doi.org/10.1142/S0218213023500239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile ad hoc networks (MANET) is a wireless sensor network with high dynamic topologies that provides reliable routing for data packet transmission. Determining the optimal routing multipath along with the energy efficient multipath is a challenging task among the researchers and multiple routing protocols are initiated but have some limitations such as increased delay, high energy consumption and low reliability. Though recent studies highlight the working of the multipath routing protocols, the complexity of the protocols increases when there is an increase in the number of paths and hence, the selection of the path is a tedious and challenging task. In this research, the optimal multipath is determined using Gallus livia bird optimization (GLBO)-based routing, that helps in the determination of the more efficient, trustworthy and energy efficient path. The GLBO algorithm is developed by the standard hybridization of the characteristics of the Gallus and livia birds, where the foraging speed of the Gallus is enhanced that helps in obtaining an optimized routing path. The efficiency of the research is proved by measuring the number of alive nodes in final iterations, where the GLBO method consists of 44 alive nodes during the iteration 100, which tend to be more efficient. Similarly reduced delay of 0.557 sec is obtained during the transmission, which tends to reduce the energy and maximizes the lifetime of the network. The energy remained during the final iterations is measured in Joule, where the proposed method attained 0.073 Joules with the reliability of 48.520%. The overall analysis of the network shows that the GLBO based routing method works more efficiently compared to some state of art methods.},
  archive      = {J_IJAIT},
  author       = {Pradeep Karanje and Ravindra Eklarker},
  doi          = {10.1142/S0218213023500239},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {7},
  pages        = {2350023},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Trust and energy-aware multipath selection in MANET for ensuring quality-of-service using the optimization protocol},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Extracting pseudocode from digital block diagram in
technical documents. <em>IJAIT</em>, <em>32</em>(6), 2350043. (<a
href="https://doi.org/10.1142/S0218213023500434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The technical document is an entity that consists of several essential and interconnected parts, often referred to as modalities. Despite the extensive attention that certain modalities have already received, say per the textual information, there are several aspects that get disproportional attention throughout the bibliography. An instance of such a modality is the block diagrams found in the technical document, as they can provide crucial information about the functionality and the technical details of both their related parts and the technical document as a whole. This paper deals with the automatic understanding of block diagrams and the extraction of pseudocode associated with the functionality of a given diagram. In particular we present a complete methodology for the formal modelling of digital block diagrams and their elements, then we develop a generative framework and three novel annotated datasets on diagrams classification and captioning. After mapping the initial problem to a block diagram description task, we present several original predictive setups derived from image segmentation, analyze the inference capabilities, and we offer illustrative examples justifying our approach.},
  archive      = {J_IJAIT},
  author       = {Nikolaos Gkorgkolis and Nikolaos G. Bourbakis},
  doi          = {10.1142/S0218213023500434},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {6},
  pages        = {2350043},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Extracting pseudocode from digital block diagram in technical documents},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving McDiarmid tree performance for predicting heart
disease from data streams with missing and meaningless values.
<em>IJAIT</em>, <em>32</em>(6), 2350029. (<a
href="https://doi.org/10.1142/S021821302350029X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building machine learning algorithms for real-time clinical decision support systems has become a current research hotspot. The success of these algorithms depends on their ability to handle data stream characteristics. For example, we cite as characteristics the large amounts of data, the high speed and rate of incoming data, and the change in data nature and distribution over time. The Very Fast Decision Tree (VFDT) is a method for incrementally building decision trees. Since its proposition in the literature, it has become one of the most popular tools for data stream classification. This paper aims to optimize a new version of VFDT called McDiarmid Tree (MT) for the early prediction of heart diseases in real-time clinical decision support systems. The proposed method for improving MT performance consists of two main mechanisms: detecting the presence of missing and meaningless values in data attributes and handling the impact of this presence. The proposed MT has been compared with MT and VFDT. Simulation results show that the proposed MT attains significantly higher prediction accuracy with less time and model cost (RAM-Hours) than the other two algorithms.},
  archive      = {J_IJAIT},
  author       = {Mariam Benllarch and Salah El Hadaj and Meriem Benhaddi},
  doi          = {10.1142/S021821302350029X},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {6},
  pages        = {2350029},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Improving McDiarmid tree performance for predicting heart disease from data streams with missing and meaningless values},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Text2Color networks: Deep learning models for color
generation from compositional color descriptions. <em>IJAIT</em>,
<em>32</em>(6), 2350026. (<a
href="https://doi.org/10.1142/S0218213023500264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Color serves as an important cue in graphics, arts and in many computer vision applications. We reliably and effortlessly name colors and communicate them with their names. However, many applications such as graphics, color design, palette generation and color selection tools demand numerical values of colors. Predicting and communicating colors by their numerical values is less intuitive and difficult task as it is a mapping of millions of colors for a specific color space. To bridge the gap between linguistic color names and numerical color values, in this paper, we present neural network architectures that predict a point in color space for a given color name. Proposed models provide user interface between colors and names by learning the language semantics and mimic human level comprehension of color descriptions to predict colors and modify them with respect to linguistic adjectives of color names. We consider color prediction as a regression problem and solve it as a language modeling task. Color descriptions are taken as text sequences and each sentence is represented with word-level tokenization. Each token is transformed into a word vector in the latent space using CBOW word embeddings model. Word vectors representing color names are fed as input to neural networks and trained with normalized R, G, B values as supervision information. Trained models are capable of predicting color for a given color name and modify colors for different nouns and adjectives associated with color names. We also built color generation models based on pre-trained word embeddings to overcome the limited availability of large linguistic color name datasets. These pre-trained models perform well with datasets containing few thousand color names. We then present two recommendation engines that suggest similar color palette to user given color name. These recommendation engines enhance the color vocabulary and assist users in the color selection process.},
  archive      = {J_IJAIT},
  author       = {Kondalarao Jyothi and Manish Okade},
  doi          = {10.1142/S0218213023500264},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {6},
  pages        = {2350026},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Text2Color networks: Deep learning models for color generation from compositional color descriptions},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Smart IoT application in soil moisture and heat level
prediction using sine cosine-horse herd optimized deep learning.
<em>IJAIT</em>, <em>32</em>(6), 2350025. (<a
href="https://doi.org/10.1142/S0218213023500252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agriculture assisted by Internet of Things (IoT) is termed as smart agriculture, which offers an increase in precision farming. Soil monitoring with IoT technology helps in the increase of agriculture by growing the yield through measuring accurate soil content information, like temperature, nutrition content, humidity, potential of hydrogen (PH), moisture and so on. In this research, the soil moisture and heat level is measured through an optimized deep learning technique namely, Sine Cosine Horse Herd optimization-based Deep Recurrent Neural Network (SCHHO-based Deep RNN). Here, the moisture and heat level is predicted using Deep RNN in which its weights are trained using SCHHO. In order to progress the effectiveness of prediction, the feature selection is done prior to prediction for choosing the appropriate features using weighted correlation coefficient. In addition, the gathered soil information is transmitted to the IoT nodes using SCHHO routing algorithm by considering fitness measures. Besides, the experimental outcome proves that the SCHHO-based Deep RNN algorithm provides better performance with the accuracy and precision of 0.918 and 0.908, respectively.},
  archive      = {J_IJAIT},
  author       = {Kishore Bhamidipati and G. Anuradha and B. Swaminathan and Satish Muppidi},
  doi          = {10.1142/S0218213023500252},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {6},
  pages        = {2350025},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Smart IoT application in soil moisture and heat level prediction using sine cosine-horse herd optimized deep learning},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CAN-net: A multi-hidden layer attention deep learning method
for surface roughness prediction during abrasive belt grinding of
superalloy with local weights. <em>IJAIT</em>, <em>32</em>(6), 2350024.
(<a href="https://doi.org/10.1142/S0218213023500240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nickel-based superalloys are widely employed in aerospace due to their excellent high-temperature strength, good oxidation resistance, and hot corrosion resistance. Abrasive belt grinding can effectively solve the problems of excessive residual stress and tool wear during the processing of superalloys. However, due to the grinding process being complex and changeable, and a wide range of affecting factors, the surface roughness prediction of abrasive belt grinding has become a challenging topic. In this study, a CAN-Net multi-hidden layer deep learning prediction model is established. The concatenate path is utilized to fuse local weights to optimize the intermediate weights of network training. To increase the predictability of the model, the attention mechanism is included to distribute the weights of the grinding parameters, and the impact of the attention mechanism on the prediction is then carefully analyzed. The results demonstrate that the CAN-Net network model has outstanding parameter flexibility and prediction accuracy, with accuracy reaching 0.984 and a correlation coefficient of 0.981 between the anticipated value and the true value.},
  archive      = {J_IJAIT},
  author       = {Guijian Xiao and Bao Zhu and Youdong Zhang and Hui Gao and Kun Li},
  doi          = {10.1142/S0218213023500240},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {6},
  pages        = {2350024},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {CAN-net: A multi-hidden layer attention deep learning method for surface roughness prediction during abrasive belt grinding of superalloy with local weights},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A state-of-the-art association rule mining survey and its
rare application, challenges, progress. <em>IJAIT</em>, <em>32</em>(6),
2350021. (<a href="https://doi.org/10.1142/S0218213023500215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, association rule mining is exploring its popularity in the rule mining research communities. In this paper, we present the taxonomy of association patterns analysis approaches in depth. The association patterns analysis is based on support constraints, interestingness, and patterns dimension from different levels of abstraction. An in-depth research statistical view is presented in each category of the association patterns analysis research. Among the identified association rule mining research categories, we have selected rare pattern mining for further exploration of our study. Analysis of rare patterns is very much helpful in determining the rare relationships between patterns. Also, we will identify novel rare data patterns analysis techniques to solve the various problems in real-life applications. The overall research impact in the association rule mining research domain can be found in this review article. It will focus on various research scopes and the future directions of rule mining as well as rare pattern mining research.},
  archive      = {J_IJAIT},
  author       = {Sudarsan Biswas and Diganta Saha and Rajat Pandit},
  doi          = {10.1142/S0218213023500215},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {6},
  pages        = {2350021},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {A state-of-the-art association rule mining survey and its rare application, challenges, progress},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep learning approach to imputation of dynamic pupil size
data and prediction of ADHD. <em>IJAIT</em>, <em>32</em>(6), 2350020.
(<a href="https://doi.org/10.1142/S0218213023500203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attention-deficit/hyperactivity disorder (ADHD) is a common neurodevelopmental disorder in children and adolescents. Traditional diagnosis methods of ADHD focus on observed behavior and reported symptoms, which may lead to a misdiagnosis. Studies have focused on computer-aided systems to improve the objectivity and accuracy of ADHD diagnosis by utilizing psychophysiological data measured from devices such as EEG and MRI. Despite their performance, their low accessibility has prevented their widespread adoption. We propose a novel ADHD prediction method based on the pupil size dynamics measured using eye tracking. Such data typically contain missing values owing to anomalies including blinking or outliers, which negatively impact the classification. We therefore applied an end-to-end deep learning model designed to impute the dynamic pupil size data and predict ADHD simultaneously. We used the recorded dataset of an experiment involving 28 children with ADHD and 22 children as a control group. Each subject conducted an eight-second visuospatial working memory task 160 times. We treated each trial as an independent data sample. The proposed model effectively imputes missing values and outperforms other models in predicting ADHD (AUC of 0.863). Thus, given its high accessibility and low cost, the proposed approach is promising for objective ADHD diagnosis.},
  archive      = {J_IJAIT},
  author       = {Seongyune Choi and Yeonju Jang and Hyeoncheol Kim},
  doi          = {10.1142/S0218213023500203},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {6},
  pages        = {2350020},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {A deep learning approach to imputation of dynamic pupil size data and prediction of ADHD},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An enhanced spotted hyena optimization algorithm and its
application to engineering design scenario. <em>IJAIT</em>,
<em>32</em>(6), 2350019. (<a
href="https://doi.org/10.1142/S0218213023500197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Spotted Hyena Optimization (SHO) algorithm is inspired by simulating the predatory behavior of spotted hyenas. While the mathematical model of the SHO algorithm is simple and optimal, it is easy to fall into local optimization and causes premature convergence compared to some metaheuristic algorithms. To the end, we propose an enhanced Spotted Hyena Optimization algorithm, a hybrid SHO algorithm using Elite Opposition-Based Learning coupled with the Simplex Method called EOBL-SM-SHO. The EOBL-SM-SHO algorithm combines the characteristics of the simplex method’s geometric transformations (reflection, inside contraction, expansion, and outside contraction) with more practical information on elite opposition-based learning strategy. They can significantly strengthen the SHO algorithm’s search range and augment the hyena population’s diversity. Furthermore, we employ eleven benchmark functions and three engineering design issues to gauge the effectiveness of the EOBL-SM-SHO algorithm. Our extensive experimental results unveil that EOBL-SM-SHO achieves better accuracy and convergence rate than the state-of-the-art algorithms (e.g., Artificial Gorilla Troops Optimizer (GTO), Cuckoo Search (CS), Farmland Fertility Algorithm (FFA), Particle Swarm Optimization (PSO), Grey Wolf Optimizer (GWO), Spotted Hyena Optimizer (SHO)).},
  archive      = {J_IJAIT},
  author       = {Luna Fan and Jie Li and Jingxin Liu},
  doi          = {10.1142/S0218213023500197},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {6},
  pages        = {2350019},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {An enhanced spotted hyena optimization algorithm and its application to engineering design scenario},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Traffic prediction and signal controlling using mode-search
optimization based deep long short term memory classifier.
<em>IJAIT</em>, <em>32</em>(6), 2350018. (<a
href="https://doi.org/10.1142/S0218213023500185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aim : The research aims at developing a traffic prediction and signal controlling model based on deep learning technique in order to provide congestion-free transportation in Intelligent Transport System (ITS). Need for the Research : Recent technical advancements in the ITS, industrialization, and urbanization increase traffic congestion, which leads to high fuel consumption and health issues. This signifies the need for a dynamic traffic management system to handle the traffic congestion issues that negatively affect the transportation service. Methods : For promoting congestion-free transportation in the ITS, this research aims to devise a traffic prediction and control system based on deep learning techniques that effectively controls the traffic during peak hours. The proposed mode-search optimization effectively clusters the vehicles based on the necessity. In addition, the mode-search optimization tunes the optimal hyperparameters of the deep Long Short Term Memory classifier, which minimizes the training loss. Further, the traffic signal control system is developed through the mode-search-based deep LSTM classifier for predicting the path of the vehicles by analyzing the attributes, such as velocity, acceleration, jitter, and priority of the vehicles. Result : The experimental results evaluate the efficacy of the traffic prediction model in terms of quadratic mean of acceleration (QMA), jitter, standard deviation of travel time (SDTT), and throughput, for which the values are found to be 37.43, 0.23, 8.75, and 100 respectively. Achievements : The proposed method attains the performance improvement of 5% to 42% when compared with the conventional methods.},
  archive      = {J_IJAIT},
  author       = {Shishir Singh Chauhan and Dilip Kumar},
  doi          = {10.1142/S0218213023500185},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {6},
  pages        = {2350018},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Traffic prediction and signal controlling using mode-search optimization based deep long short term memory classifier},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Annotated OpenAPI descriptions and ontology for REST
services. <em>IJAIT</em>, <em>32</em>(6), 2350017. (<a
href="https://doi.org/10.1142/S0218213023500173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leveraging the latest research results on hypermedia-driven Web APIs and the newest update of the OpenAPI Specification, we propose a reference ontology for REST services along with a formal procedure for converting OpenAPI service descriptions to instances of this ontology. At the heart of the approach is a model for enhancing the meaning of Schema properties (i.e. re-usable JSON Schema properties that clarify the meaning of service components). Schema properties are semantically annotated (i.e. their meaning is mapped to a semantic model) and existing properties are combined to form composed or polymorphic expressions. The algorithm for mapping service descriptions to the OpenAPI ontology is implemented and is available as a Web Application.},
  archive      = {J_IJAIT},
  author       = {Nikolaos Mainas and Fotios Bouraimis and Aikaterini Karavisileiou and Euripides G. M. Petrakis},
  doi          = {10.1142/S0218213023500173},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {6},
  pages        = {2350017},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Annotated OpenAPI descriptions and ontology for REST services},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive learning environment for programming based on
fuzzy logic and machine learning. <em>IJAIT</em>, <em>32</em>(5),
2360011. (<a href="https://doi.org/10.1142/S0218213023600114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an Intelligent Tutoring System (ITS), for use in teaching the logic of computer programming and the programming language ‘C’. The aim of the ITS is to adapt the delivered learning material and the lesson sequence to the knowledge level and learning needs of each individual student. The adaptation of the presented ITS is based on fuzzy logic and a machine learning technique. Particularly, the system uses the distance weighted k-nearest neighbor algorithm to detect the learner’s knowledge level and abilities concerning computer programming during her/ his first interaction with the system. Next and during subsequent interactions of the learner with the system, fuzzy logic is used to identify the learner’s current knowledge level and potential misconceptions. The system takes into consideration the knowledge dependencies that exist among the domain concepts of the learning material and, applying fuzzy rules, decides about the learning material that has to be delivered to the learner as well as the lesson sequence. The system has been fully implemented and evaluated through t-tests. The evaluation results show that the combination of machine learning (for initially identifying the student’s learning abilities and needs) with fuzzy logic (for the continuous identification of the learner’s current knowledge level and misconceptions) provides more personalized learning experience, promotes the active participation of students in the learning process and results in decrease in the number of dropouts.},
  archive      = {J_IJAIT},
  author       = {Konstantina Chrysafiadi and Maria Virvou and George A. Tsihrintzis and Ioannis Hatzilygeroudis},
  doi          = {10.1142/S0218213023600114},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {5},
  pages        = {2360011},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {An adaptive learning environment for programming based on fuzzy logic and machine learning},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural adversarial attacks with random noises.
<em>IJAIT</em>, <em>32</em>(5), 2360010. (<a
href="https://doi.org/10.1142/S0218213023600102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an approach which relies on the use of random noises to generate adversarial examples of deep neural network classifiers. We argue that existing deterministic attacks, which perform by sequentially applying maximal perturbations on selected components of the input, fail at reaching accurate adversarial examples on real-world large scale datasets. By exploiting a simple Taylor expansion of the expected output probability under the noise perturbation, we introduce noise-based sparse (or L 0 ) targeted and untargeted attacks. Our proposed method, called Voting Folded Gaussian Attack (VFGA), achieves significantly better L 0 scores than state-of-the-art L 0 attacks (such as SparseFool and Sparse-RS) while being faster on both CIFAR-10 and ImageNet. Moreover, we show that VFGA is also applicable as an L ∞ attack and outperforms the state-of-the-art projected gradient attack (PGD) method.},
  archive      = {J_IJAIT},
  author       = {Hatem Hajri and Manon Césaire and Lucas Schott and Sylvain Lamprier and Patrick Gallinari},
  doi          = {10.1142/S0218213023600102},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {5},
  pages        = {2360010},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Neural adversarial attacks with random noises},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). QHAN: Quantum-inspired hierarchical attention mechanism
network for question answering. <em>IJAIT</em>, <em>32</em>(5), 2360009.
(<a href="https://doi.org/10.1142/S0218213023600096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The approach to question answering is challenging because it usually requires finding useful information from within and between question and answer sentences for sentence semantic matching. The key information mined from existing question and answer sentences, as a supplement to semantic information, maybe helpful for this task. However, capturing the intra-sentence and inter-sentence semantic interactions is somewhat difficult given the implicit interrelationships between question and answer sentences. Although the learning effect of multi-layer neural network is good, it lacks explanatory and theoretical support. This paper mainly studies how to select the best answer sentence from a set of question and answer sentences, mine information more effectively, perform semantic matching, and have a certain interpretability. Therefore, we propose a hierarchical attention network (QHAN) based on the mathematical framework of quantum theory, which integrates the attention mechanism under quantum measurement and density matrix (DMATT) and the attention mechanism under quantum weak measurement and weak value (WMATT) in one in a unified model framework. QHAN can not only discover key sentences in a set of question and answer sentences and key words in a sentence, but also perform sentence semantic matching quickly and accurately. Furthermore, QHAN has the advantage of interpretability in terms of models due to the physical meaning and attentional full weight distribution implied by quantum theory. Extensive experiments on the question answering dataset show that our method is comparable to the baselines and can explain why the selected question and answer sentence is the best option in terms of intra-sentence and inter-sentence attention distributions.},
  archive      = {J_IJAIT},
  author       = {Peng Guo and Panpan Wang},
  doi          = {10.1142/S0218213023600096},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {5},
  pages        = {2360009},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {QHAN: Quantum-inspired hierarchical attention mechanism network for question answering},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Incorporating normalized l1 penalty and eigenvalue
constraint for causal structure learning. <em>IJAIT</em>,
<em>32</em>(5), 2360008. (<a
href="https://doi.org/10.1142/S0218213023600084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inferring causal relationships is key to data science. Learning causal structures in the form of directed acyclic graphs (DAGs) has been widely adopted for uncovering causal relationships, nonetheless, it is a challenging task owing to its exponential search space. A recent approach formulates the structure learning problem as a continuous constrained optimization task that aims to learn causal relation matrix. Following it are nonlinear variants that can uncover nonlinear causal relationships. However, the nonlinear variant which considers the ℓ 1 penalty as part of its optimization objective may not effectively eliminate false predictions. In this paper, we investigate the defect of the model that the ℓ 1 penalty cannot effectively make the relation matrix sparse, thus introduces false predictions. Besides, the acyclicity constraint is unable to identify large circles within the margin of identification error, thus is unable to guarantee acyclicity of inferred causal relationships. Based on the theoretical and empirical analysis of the defects, we propose the normalized ℓ 1 penalty which replaces the original ℓ 1 penalty with a normalized first-order matrix norm, and propose a constraint based on eigenvalue to substitute the original acyclicity constraint. We then compare our proposed model NEC with three models to show considerable performance improvement. We further conduct experiments to show the effectiveness of the normalized ℓ 1 penalty and the eigenvalue constraint.},
  archive      = {J_IJAIT},
  author       = {Yunfeng Wang and Yuelong Zhu and Tingting Hang and Jiamin Lu and Jun Feng},
  doi          = {10.1142/S0218213023600084},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {5},
  pages        = {2360008},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Incorporating normalized l1 penalty and eigenvalue constraint for causal structure learning},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving peer assessment by incorporating grading
behaviors: Models and practices. <em>IJAIT</em>, <em>32</em>(5),
2360007. (<a href="https://doi.org/10.1142/S0218213023600072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Peer assessment, which requires students to evaluate their peers’ submissions, has become the paradigm for solving the grading challenge of large-scale open-ended assignments teachers face in MOOCs. Since peer grades may be biased and unreliable, a group of probabilistic graph models are proposed to improve the estimation of true scores for assignments based on peer grades, by explicitly modeling the bias and reliability of each grader. However, these models assume that graders’ reliability are only impacted by their knowledge/ ability levels while ignoring their grading behaviors. In real life, graders’ grading behaviors (e.g., the time consumed for reviewing an assignment) reflect the seriousness of the graders in the assessment and greatly affect their reliability. Following this intuition, we propose two novel probabilistic graph models, named BPG 6 and BPG 7 , for cardinal peer assessment, which optimize the modeling of the reliability of graders by incorporating various grading behaviors of them. Besides, we develop a peer assessment system, named BPA, which collects abundant grading behaviors of graders and thus facilitates the evaluation of the proposed models and our teaching practices. Experimental results on the collected datasets show the superiority of the proposed models in improving the estimation accuracy of the true scores of assignments by leveraging graders’ grading behaviors. Finally, by analyzing the feedback from teaching practices of peer assessment using the BPA system, we not only prove the usability of the BPA system but also once again demonstrate the effectiveness of the proposed model in peer assessment.},
  archive      = {J_IJAIT},
  author       = {Jia Xu and Jing Liu and Panyuan Yang and Pin Lv},
  doi          = {10.1142/S0218213023600072},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {5},
  pages        = {2360007},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Improving peer assessment by incorporating grading behaviors: Models and practices},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction quality meta regression and error meta
classification for segmented lidar point clouds. <em>IJAIT</em>,
<em>32</em>(5), 2360006. (<a
href="https://doi.org/10.1142/S0218213023600060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a post-processing tool for semantic segmentation of Lidar point clouds, called LidarMetaSeg, which estimates the prediction quality segmentwise and classifies prediction errors. For this purpose, we compute dispersion measures based on network probability outputs as well as feature measures based on point cloud input features and aggregate them on segment level. These aggregated measures are used to train a meta classification model to predict whether a predicted segment is an error, i.e., it is a false positive or not. We also train a meta regression model to predict the segmentwise prediction quality in terms of intersection over union. Both models can then be applied to semantic segmentation inferences without knowing the ground truth. In our experiments we use different Lidar segmentation models and datasets and analyze the power of our method. We show that our results outperform other standard approaches based on single uncertainty measures like entropy. Furthermore, we present an in-depth evaluation of our method on predicted classes as well as on predicted categories.},
  archive      = {J_IJAIT},
  author       = {Pascal Colling and Matthias Rottmann and Lutz Roese-Koerner and Hanno Gottschalk},
  doi          = {10.1142/S0218213023600060},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {5},
  pages        = {2360006},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Prediction quality meta regression and error meta classification for segmented lidar point clouds},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ensemble learning based gene regulatory network inference.
<em>IJAIT</em>, <em>32</em>(5), 2360005. (<a
href="https://doi.org/10.1142/S0218213023600059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the machine learning field, the technique known as ensemble learning aims at combining different base learners in order to increase the quality and the robustness of the predictions. Indeed, this approach has widely been applied to tackle, with success, real world problems from different domains, including computational biology. Nevertheless, despite their potential, ensembles combining results from different base learners have been understudied in the context of gene regulatory network inference. In this paper we applied genetic algorithms and frequent itemset mining, to design small but effective ensembles of gene regulatory network inference methods. These ensembles were evaluated and compared to well-established single and ensemble methods, on both real and synthetic datasets. Results showed that small ensembles, consisting of few but diverse base learners, enhance the exploration of the solution space, and compensate base learners biases, outperforming state-of-the-art methods. Results advocate for the use of such methods as gene regulatory network inference tools.},
  archive      = {J_IJAIT},
  author       = {Sergio Peignier and Baptiste Sorin and Federica Calevro},
  doi          = {10.1142/S0218213023600059},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {5},
  pages        = {2360005},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Ensemble learning based gene regulatory network inference},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A human body infrared image recognition approach via DCA-net
deep learning models. <em>IJAIT</em>, <em>32</em>(5), 2360004. (<a
href="https://doi.org/10.1142/S0218213023600047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous exploitation of coal resources, human safety has been seriously threatened during the mining process. Therefore, it is of great significance to establish an efficient human infrared image recognition system. In this paper, three classes of infrared image data of the human body are collected by a thermal imager, namely Human, Human others and None. According to the characteristics of downhole infrared images, a distributed channel feature extraction module (DCFE) is designed, and DCA-Net is proposed based on this module. The experimental results show that the recognition rate of the network reaches 98%. Compared with other networks, this network has better recognition performance. Among them, the recognition rate of DCA-Net50 reaches 98.214%, the amount of parameters and calculations are relatively small, and the cost-effectiveness is the highest. It is suitable for the human body infrared image recognition system that requires high accuracy and high real-time performance.},
  archive      = {J_IJAIT},
  author       = {Huiqiang Zhang and Ji Li and Shengqi Liu and Wei Wang},
  doi          = {10.1142/S0218213023600047},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {5},
  pages        = {2360004},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {A human body infrared image recognition approach via DCA-net deep learning models},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning from highly imbalanced big data with label noise.
<em>IJAIT</em>, <em>32</em>(5), 2360003. (<a
href="https://doi.org/10.1142/S0218213023600035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the effects of class label noise on detecting fraud within three highly imbalanced healthcare fraud data sets containing millions of claims and minority class sizes as small as 0.1%. For each data set, 29 noise distributions are simulated by varying the level of class noise and the distribution of noise between the fraudulent and non-fraudulent classes. Four popular machine learning algorithms are evaluated on each noise distribution using six rounds of five-fold cross-validation. Performance is measured using the area under the precision-recall curve (AUPRC), true positive rate (TPR), and true negative rate (TNR) in order to understand the effect of the noise level, noise distribution, and their interactions. AUPRC results show that negative class noise, i.e. fraudulent samples incorrectly labeled as non-fraudulent, is the most detrimental to model performance. TPR and TNR results show that there are significant trade-offs in class-wise performance as noise transitions between the positive and the negative class. Finally, results reveal how overfitting negatively impacts the classification performance of some learners, and how simple regularization can be used to combat this overfitting and improve classification performance across all noise distributions.},
  archive      = {J_IJAIT},
  author       = {Justin M. Johnson and Robert K. L. Kennedy and Taghi M. Khoshgoftaar},
  doi          = {10.1142/S0218213023600035},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {5},
  pages        = {2360003},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Learning from highly imbalanced big data with label noise},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Keyboard layout optimization and adaptation. <em>IJAIT</em>,
<em>32</em>(5), 2360002. (<a
href="https://doi.org/10.1142/S0218213023600023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the keyboard is the most common method for text input on computers today, the design of the keyboard layout is very significant. Despite the fact that the QWERTY keyboard layout was designed more than 100 years ago, it is still the predominant layout in use today. There have been several attempts to design better layouts, both manually and automatically. In this paper we improve on previous works on automatic keyboard layout optimization, by using a deep neural network to assist in a genetic search algorithm, which enables the use of a sophisticated keyboard evaluation function that would otherwise take a prohibitive amount of time. We also show that a better choice of crossover routine greatly improves the genetic search. Finally, in order to test how users with different levels of experience adapt to new keyboard layouts, we conduct some layout adaptation experiments with 300 participants to examine how users adapt to new keyboard layouts.},
  archive      = {J_IJAIT},
  author       = {Keren Nivasch and Amos Azaria},
  doi          = {10.1142/S0218213023600023},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {5},
  pages        = {2360002},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Keyboard layout optimization and adaptation},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differential evolution algorithm with dual information
guidance. <em>IJAIT</em>, <em>32</em>(5), 2360001. (<a
href="https://doi.org/10.1142/S0218213023600011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an effective tool to solve continuous optimization problems, differential evolution (DE) algorithm has been widely used in numerous fields. To enhance the performance, in recent years, many DE variants have been developed based on the idea of multiple strategies. However, there still exists an issue for them that the strategy selection method relies on the historical search experience. The experience may be suitable for the problems with smooth fitness landscapes, but not for the problems with rugged fitness landscapes. To alleviate this issue, in this work, a new multiple strategies-based DE variant with dual information guidance is proposed, called DIGDE. In the DIGDE, to avoid the unreliable historical search experience, the fitness information and spatial information are utilized simultaneously as a guidance to estimate the evolutionary states for each individual, and then the most appropriate strategy can be chosen correspondingly. To verify the effectiveness of the DIGDE, 52 test functions are included in the experiments, and three well-established DE variants and four other evolutionary algorithms are involved in the performance comparison. The results show that the DIGDE achieves competitive performance on not only the result accuracy but also the convergence rate.},
  archive      = {J_IJAIT},
  author       = {Xinyu Zhou and Yanlin Wu and Hu Peng and Shuixiu Wu and Mingwen Wang},
  doi          = {10.1142/S0218213023600011},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {5},
  pages        = {2360001},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Differential evolution algorithm with dual information guidance},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Special issue on selected papers from the 33rd
annual IEEE international conference on tools with artificial
intelligence (ICTAI-2021). <em>IJAIT</em>, <em>32</em>(5), 2302003. (<a
href="https://doi.org/10.1142/S0218213023020037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJAIT},
  author       = {George A. Tsihrintzis and Maria Virvou and Ioannis Hatzilygeroudis},
  doi          = {10.1142/S0218213023020037},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {5},
  pages        = {2302003},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Editorial: Special issue on selected papers from the 33rd annual IEEE international conference on tools with artificial intelligence (ICTAI-2021)},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural network-based tool for survivability assessment of
k-variant systems. <em>IJAIT</em>, <em>32</em>(4), 2350049. (<a
href="https://doi.org/10.1142/S0218213023500495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The K-variant is a multi-variant architecture to enhance the security of the time-bounded mission and safety-critical systems. Variants in the K-variant architecture are generated by controlled source program transformations. Previous experimental studies showed that the K-variant architecture might improve the security of systems against memory exploitation attacks. In order to estimate the survivability of K-variant systems, simulation techniques are utilized. However, these techniques are slow and may not be practical for the design of K-variant systems. Therefore, fast and highly accurate estimations of the survivability of K-variant systems are necessary for developers. The neural networks may allow quick and accurate estimation of the survivability of K-variant systems. The developed neural network-based tool can make quick and precise estimations of the survivability of K-variant systems under different conditions. In this paper, the accuracy of the neural network-based tool is investigated in an experimental study. The neural network-based tool estimations are compared with a K-variant attack emulator in three programs for up to ten variant systems under four attack types and three attack durations. The experimental study demonstrates that the neural network-based tool makes fast and accurate estimations of the survivability of K-variant systems under all the conditions investigated.},
  archive      = {J_IJAIT},
  author       = {Berk Bekiroglu and Bogdan Korel},
  doi          = {10.1142/S0218213023500495},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {4},
  pages        = {2350049},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Neural network-based tool for survivability assessment of K-variant systems},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pinakas: A methodology for deep analysis of tables in
technical documents. <em>IJAIT</em>, <em>32</em>(4), 2350042. (<a
href="https://doi.org/10.1142/S0218213023500422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The holistic understanding of the information contained in technical documents depends on the understanding of the document’s individual modalities. These modalities are tables, graphics, diagrams, formulas, etc. and each of them is a standalone research topic that requires a different way of processing and understanding. These modalities, processed and combined with the document text, can introduce new techniques for visual question answering in documents. Thus, in this paper we present Pinakas, a methodology for automatic analysis of the internal tabular information that appears in technical documents and its modeling to stochastic Petri-net graphs. We focus only on tables that strictly abide by the IEEE format rules. The methodology presented here is divided into the following steps: (1) table detection, (2) table recognition, (3) table understanding. Qualitative results of Pinakas are demonstrated as proof of concept for the accurate extraction of information from three different types of tables.},
  archive      = {J_IJAIT},
  author       = {Michail S. Alexiou and Nikolaos G. Bourbakis},
  doi          = {10.1142/S0218213023500422},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {4},
  pages        = {2350042},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Pinakas: A methodology for deep analysis of tables in technical documents},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing dynamic multi-objective optimization using
opposition-based learning and simulated annealing. <em>IJAIT</em>,
<em>32</em>(4), 2350037. (<a
href="https://doi.org/10.1142/S0218213023500379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are many dynamic real-life optimization problems in which objectives increase or decrease over time, which usually leads to variations in the dimensions of a Pareto front. Dynamic multi-objective optimization (DyMO) approaches aim to keep track of the updated Pareto front to tackle the changes which are caused by the dynamic environment. However, the current DyMO approaches do not handle dynamic environments effectively. In this study, a new hybrid dynamic two-archive evolutionary algorithm with a newly added simulated annealing and opposition-based learning strategy is proposed. The proposed method helps to preserve solutions with reasonable diversity and improve convergence by searching for promising solutions within acceptable computational time and effort. To evaluate the efficacy of the suggested method, comprehensive experiments using different multi-objective quality measures such as generational distance, and inverted generational distance have been performed on several benchmark problems with varying numbers of objectives over time. The results of the experiments show that the suggested method outperforms the strategies already in use.},
  archive      = {J_IJAIT},
  author       = {Kiran Ilyas and Irfan Younas},
  doi          = {10.1142/S0218213023500379},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {4},
  pages        = {2350037},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Enhancing dynamic multi-objective optimization using opposition-based learning and simulated annealing},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Effective segmentation and brain tumor classification using
sparse bayesian ELM in MRI images. <em>IJAIT</em>, <em>32</em>(4),
2350022. (<a href="https://doi.org/10.1142/S0218213023500227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification of tumors from MRI plays very important role for diagnosing various diseases. But, it consumes an enormous amount of time for classification. Due to the similar structure of anomalous and typical tissues in the brain, it is difficult to complete the detection process successfully. Many researchers have developed new methods for detection and classification of tumors. But most of them failed at some point due to these limitations. Therefore in our work, we introduced a new machine learning algorithm for detection and classification of tumors. In addition to this, an intellectual segmentation technique known as Improved Binomial Thresholding technique is also introduced in this paper. This newly developed approach is used to differentiate the normal and abnormal slices from brain MRI. We can extract different features from the segmented image. The extracted features may be Wavelet Transform based (WT) or Scattering Wavelet Transform based (SWT). Feature selection process is achieved using a hybrid algorithm known as CS-FS (Hybrid Cuckoo Search with Fish Swarm) to minimize the dimension of extracted features. Finally, feature classification process is performed using Sparse Bayesian Extreme Learning Machine (SBELM) classifier. The proposed method is executed with the help of BRATS (Brain Tumor Image Segmentation) 2015 dataset. The result of the proposed method is evaluated on different parameters like accuracy, specificity, and sensitivity. The values of these parameters are obtained by computing four factors such as TP, TN, FN and FP. The final evaluation results showed that, our proposed SBELM classifier has attained 97.2% accuracy, which is better than the other existing method like state-of-the-art method.},
  archive      = {J_IJAIT},
  author       = {V. V. S. Sasank and S. Venkateswarlu},
  doi          = {10.1142/S0218213023500227},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {4},
  pages        = {2350022},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Effective segmentation and brain tumor classification using sparse bayesian ELM in MRI images},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel YOLOv5 deep learning model for handwriting detection
and recognition. <em>IJAIT</em>, <em>32</em>(4), 2350016. (<a
href="https://doi.org/10.1142/S0218213023500161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer Vision (CV) has become an essential field in Artificial Intelligence applications. Object detection and recognition (ODR) is one of the fundamental tasks of computer vision implementations. However, developing an efficient ODR model is still a significant problem. The model’s execution time and speed are the most critical features during the inference or detection and recognition process, which need to be improved using the latest object detection architectures. In this paper, the handwritten detection and recognition (HDR) model is developed based on previously known algorithms with their efficiency, such as Faster R-CNN and YOLOv4 in the first hand. On the other hand, two new models capable of detecting and recognizing handwritten digits using the latest ODR algorithm are proposed, one based on the latest YOLO family architecture (YOLOv5-HDR) with high speed and accuracy and the other using the transformers architecture (DETR). To the best of our knowledge, this is the first study to achieve a details comparison between YOLOv5 and transformers-based models in handwritten digit detection. Finally, the detailed performance analysis achieved by the paper proves that the YOLOv4-based model achieved the testing inference 13% faster than Faster R-CNN. However, the proposed YOLOv5-based model outperformed the YOLOv4 and the transformers-based one as it increased the testing execution time 25% faster than the YOLOv4, three times faster than the DETR model. A further adversarial attack test has been conducted to ensure the robust performance of the proposed model. Furthermore, numerical experiment results and their analyses demonstrate the robustness and effectiveness of the proposed YOLOv5-based model being the most stable for handwritten digit detection and recognition tasks.},
  archive      = {J_IJAIT},
  author       = {Maliki Moustapha and Murat Tasyurek and Celal Ozturk},
  doi          = {10.1142/S0218213023500161},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {4},
  pages        = {2350016},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {A novel YOLOv5 deep learning model for handwriting detection and recognition},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The dead-reckoning navigation guidance law based on neural
network collaborative forecasting. <em>IJAIT</em>, <em>32</em>(4),
2350015. (<a href="https://doi.org/10.1142/S021821302350015X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For predicting missile’s interception point, the current guidance law based on neural networks avoids to model the strong nonlinear motion of a missile and simultaneously improve the anti-jamming ability of the guidance law. Although the advantages of solving the predicted intercept point problem based on neural networks are obvious, the difficulty in obtaining the target missile information still exists. In this work, we propose a dead-reckoning navigation guidance (DRNG) law. First, a neural network-based collaborative forecast scheme is proposed and utilize the advantages of different neural networks to greatly reduce the difficulty in acquiring the target information. Second, we construct an approximate realistic aerodynamic characteristics environment to simulate the motion parameters of missiles and targets. We also introduce real-time error correction for increasing the prediction accuracy of the network and improve the robustness of the proposed DRNG by using the model self-update algorithm. Finally, through a large number of simulation experiments, results show that the proposed DRNG completes the interception task in a noisy environment, when only the position parameters of a target missile are known. Moreover, it has a more optimized ballistic trajectory as compared with the traditional guidance law.},
  archive      = {J_IJAIT},
  author       = {Guochuan Yu and Tao Zhao and Bicong Ren},
  doi          = {10.1142/S021821302350015X},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {4},
  pages        = {2350015},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {The dead-reckoning navigation guidance law based on neural network collaborative forecasting},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fatigue detection system in construction site using
extension based equilibrium with capsule autoencoder network.
<em>IJAIT</em>, <em>32</em>(4), 2350014. (<a
href="https://doi.org/10.1142/S0218213023500148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fatigue detection of workers is an important factor in construction site monitoring. Nowadays, worker exhaustion on construction sites causes tiredness and drowsiness. The prediction of mental exhaustion is critical because the job has increased over the years. Accurate fatigue detection is important for analyzing the stress level of work on construction sites. However, recording worker activities and detecting fatigue is critical for site supervisors. Over the last century, there has been an increasing trend towards vision-based action recognition. The identification of worker activities in far-field surveillance video has received good attention. Henceforth, this research proposed a hierarchical statistical approach for detecting worker activity in far-field security footage. In this paper, extension based equilibrium with capsule autoencoder network is proposed for fatigue detection. To improve the prediction performance, video data is collected for monitoring. Initially, the video dataset is converted into frames, and these frames are pre-processed using normalization. Afterwards, statistical feature extraction techniques are extracted from the normalized frames to improve the prediction performance. It helps to identify the symptoms of fatigue detection. The persons with the symptoms are identified from the extraction. Feature selection is performed using hybrid Battle Royale Optimization and Particle Swarm Optimization algorithms (hybrid BRO-PSO). Finally, based on the selected features, fatigue classification is performed using extended equilibrium optimization with Capsule Autoencoder (EECAEN). The performance of the proposed scheme is compared with different existing approaches. The performance of fatigue detection is analyzed with real time video dataset. The performance of the proposed approach is compared with different existing techniques such as Convolution Neural Network (CNN), Long Short-Term Memory (LSTM), and Recurrent Neural Network (RNN). The proposed method outperforms the existing approaches in terms of F1-score, accuracy, recall, precision, specificity, and sensitivity.},
  archive      = {J_IJAIT},
  author       = {Ashish Sharma and Gaurav Sethi},
  doi          = {10.1142/S0218213023500148},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {4},
  pages        = {2350014},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Fatigue detection system in construction site using extension based equilibrium with capsule autoencoder network},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RetU-net: An enhanced u-net architecture for retinal lesion
segmentation. <em>IJAIT</em>, <em>32</em>(4), 2350013. (<a
href="https://doi.org/10.1142/S0218213023500136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy is a predominant vision-threatening disease affecting working-aged people specifically. Timely diagnosis through early detection and prevention helps to reduce the risk of severe vision loss. Computer-aided diagnosis in retinal image analysis through Machine Learning techniques will help medical professionals perform their analysis better. Automated image processing through Convolutional Neural Networks has proven to be a promising technique, mainly in medical image segmentation. Convolutional Neural Network techniques like 3D CNN, Deep CNN and architectures like U-Net, V-Net, SegNet, and DeepMedic have outperformed medical image analysis results. However, the baseline CNN architectures struggle to retain high-quality information at the output and thus affect the performance. This work focuses on addressing the issue of translational variance and overfitting scenarios of U-Net architecture by experimenting with adaptable window sizes, pretrained weights and linear interpolation technique. A novel U-Net based architecture called RetU-Net that segments abnormal retinopathy lesion structures by retaining higher-level feature is proposed. The experiments are conducted using Indian Diabetic Retinopathy Image Dataset provided in “Diabetic Retinopathy: Segmentation and Grading Challenge” initially. The results have been compared with other state-of-art CNN architectures. Further evaluation is carried out on public datasets: STARE and DRIVE, and the performance is compared with U-Net based architectures used for retinal image segmentation. The proposed approach is efficient in terms of precision, sensitivity, specificity and accuracy. It received accuracy scores of 0.9612, 0.9712 while experimenting with STARE and DRIVE datasets respectively.},
  archive      = {J_IJAIT},
  author       = {Sumod Sundar and S Sumathy},
  doi          = {10.1142/S0218213023500136},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {4},
  pages        = {2350013},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {RetU-net: An enhanced U-net architecture for retinal lesion segmentation},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning with game theory assisted vertical handover
optimization in a heterogeneous network. <em>IJAIT</em>, <em>32</em>(4),
2350012. (<a href="https://doi.org/10.1142/S0218213023500124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problem : In next-generation networks, users can optimize or tune their preferences with a seamless transfer of diverse access methodologies for maximizing the Quality of Service (QoS) and cost savings. In these heterogeneous wireless environments, users are prepared with several multimode wireless devices for maximizing media services through several access networks. Such networks may vary regarding energy usage, available bandwidth, technology, coverage range, monetary cost, etc. In recent days, vertical handover has attained higher performance owing to the improvements in mobility models through adopting the Fourth Generation (4G) technologies. On the other hand, these improvements are restricted to some cases, so, it does not offer support for generic mobility. Consequently, diverse strategies were implemented by considering these mobility models. However, it suffers from improper network selection, late and too-early handovers, repeated handovers, high packet loss, etc. Aim : This paper tackles the problem of vertical handover problem in the heterogeneous network using deep learning with game theory. Methods : The proposed model develops a non-cooperative game approach, in which all base stations compete selfishly to transmit at higher power. The overall performance in terms of throughput, handover, energy consumption, and load balancing is attained by optimizing the transmission power by the game theory. For performing this model, the required data like path loss, SINR, data rate, load, etc are generated by the deep learning called Recurrent Neural Network (RNN). Results : From the simulation findings, the handoff probability of the recommended RNN+Game Theory is correspondingly secured at 6.9%, 22.6%, and 8.2% superior to TOPSIS, ABC-PSO, and game theory when taking the time like 5 secs for user velocity as 30 km/h. Conclusion : Results show that the proposed game theoretical approach with deep learning provides a throughput enhancement while reducing the power consumption, in addition, to minimizing the unnecessary handover and balancing the load between base stations.},
  archive      = {J_IJAIT},
  author       = {Safak Kayikci and Nazeer Unnisa and Anupam Das and S. K. Rajesh Kanna and Mantripragada Yaswanth Bhanu Murthy and N. S. Ninu Preetha and G. Brammya},
  doi          = {10.1142/S0218213023500124},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {4},
  pages        = {2350012},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Deep learning with game theory assisted vertical handover optimization in a heterogeneous network},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DSM-IDM-YOLO: Depth-wise separable module and inception
depth-wise module based YOLO for pedestrian detection. <em>IJAIT</em>,
<em>32</em>(4), 2350011. (<a
href="https://doi.org/10.1142/S0218213023500112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian detection is one of the most challenging research areas in computer vision. Compared to traditional hand-crafted methods, convolutional neural networks (CNNs) have superior detection results. The single-stage detection networks, particularly the state-of-the-art You Only Look Once (YOLO) network, have attained a satisfactory performance without compromising the computation speed in object detection. YOLO framework can be leveraged in pedestrian detection as well. In this work, we propose an improved YOLOv2, called DSM-IDM-YOLO. The proposed model uses a modified DarkNet19 integrated with three new modules, two depth-wise separable convolution modules and one inception depth-wise convolution module, leading to a comprehensive feature of an object in the image. The modules are integrated on top of features from multiple levels of the network. The proposed framework is computationally less expensive owing to its convolution design and a moderate number of layers. It aims to improve performance with minimal computational overhead. The proposed method is compared with state-of-the-art detection methods, i.e., Faster R-CNN, YOLOv2, YOLOv3, YOLOv4-tiny and Single Shot Multibox Detector (SSD). The performance results attest that the proposed method has effectively improved the detection. Three benchmark pedestrian datasets are used for experimental analysis: INRIA, PASCAL VOC 2012 and Caltech.},
  archive      = {J_IJAIT},
  author       = {Sweta Panigrahi and U. S. N. Raju},
  doi          = {10.1142/S0218213023500112},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {4},
  pages        = {2350011},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {DSM-IDM-YOLO: Depth-wise separable module and inception depth-wise module based YOLO for pedestrian detection},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Winners of nikolaos bourbakis award for 2022.
<em>IJAIT</em>, <em>32</em>(3), 2382001. (<a
href="https://doi.org/10.1142/S0218213023820018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJAIT},
  doi          = {10.1142/S0218213023820018},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {3},
  pages        = {2382001},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Winners of nikolaos bourbakis award for 2022},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast violence recognition in video surveillance by
integrating object detection and conv-LSTM. <em>IJAIT</em>,
<em>32</em>(3), 2340018. (<a
href="https://doi.org/10.1142/S0218213023400183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video surveillance involves petabytes of data storage requiring expensive hardware, which might also be time-inefficient. The aim of this article is, therefore, to develop an intelligent system capable of analyzing long sequences of videos captured from CCTV, helping to mitigate catastrophe and mitigate the violent threats faced by citizens every day, economically and efficiently. Existing models have achieved high accuracy on available datasets, the primary focus is to improve speed (time-efficient) of violence detection and use very little storage (economical) such that the system can be used in real-time. The paper presents an end-to-end hybrid solution for detecting violence in real-time video frames incorporating both human and weapon detection algorithms applied in a synchronized way. The focus of this article is to propose a generic HWVd (Human Weapon Violence detection) model to detect all kinds of public violence. HWVd is a three-tier ensemble model to detect violence in videos. The first tier is human detection, which uses a LightTrack framework. In the second tier, a Fast Region-based Convolutional Neural Network (F-RCNN) to detect any weapon in videos is used. The third tier uses a pre-trained VGG 19 (a pre-trained model of CNN) for spatial feature extraction and Long Short Term Memory (LSTM) to detect violent activity. Lastly, the output of this framework is sent to the Support Vector Machine to classify the activity as (i) violence not involving weapon, (ii) violence involving weapon and (iii) non-violent. The accuracy obtained using the proposed model is 98%.},
  archive      = {J_IJAIT},
  author       = {Nikita Jain and Vedika Gupta and Usman Tariq and D. Jude Hemanth},
  doi          = {10.1142/S0218213023400183},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {3},
  pages        = {2340018},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Fast violence recognition in video surveillance by integrating object detection and conv-LSTM},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient multimodal biometric recognition for secure
authentication based on deep learning approach. <em>IJAIT</em>,
<em>32</em>(3), 2340017. (<a
href="https://doi.org/10.1142/S0218213023400171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biometric identification technology has become increasingly common in our daily lives as the requirement for information protection and control legislation has grown around the world. The unimodal biometric systems use only biometric traits to authenticate the user which is trustworthy but it possesses various limitations such as susceptibility to attacks, noise occurring in a dataset, non-universality challenges, etc. Multimodal biometrics technology has the potential to avoid the various fundamental constraints of unimodal biometric systems and also it has garnered interest and popularity in this respect. In this research, an efficient multimodal biometric recognition system based on a deep learning approach is proposed. The structure is implemented around convolutional neural networks (CNN) in which feature extraction and Softmax classifier are used to identify images. This method employs three CNN models for iris, face, and fingerprint were integrated to create the system. The two levels of fusion strategy such as feature level fusion and score level fusion were employed. The efficiency of the proposed model is evaluated based on the two most popular multimodal datasets as SDUMLA-HMT and BiosecureID biometric dataset. The result analysis demonstrates that the proposed multimodal biometric recognition provides the enhanced result with higher accuracy of 99.92%, a lower equal error rate of 0.10% on feature level, and 0.08% on score level fusion. Similarly, the average FAR is 0.09% and the average FRR is 0.06%. Because of this enhanced result, the proposed approach is computationally efficient.},
  archive      = {J_IJAIT},
  author       = {Vani Rajasekar and Muzafer Saracevic and Mahmoud Hassaballah and Darjan Karabasevic and Dragisa Stanujkic and Mahir Zajmovic and Usman Tariq and Premalatha Jayapaul},
  doi          = {10.1142/S0218213023400171},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {3},
  pages        = {2340017},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Efficient multimodal biometric recognition for secure authentication based on deep learning approach},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classification of visually evoked potential EEG using hybrid
anchoring-based particle swarm optimized scaled conjugate gradient
multi-layer perceptron classifier. <em>IJAIT</em>, <em>32</em>(3),
2340016. (<a href="https://doi.org/10.1142/S021821302340016X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain-Computer Interface is an emerging field that focuses on transforming brain data into machine commands. EEG-based BCI is widely used due to the non-invasive nature of Electroencephalogram. Classification of EEG signals is one of the primary components in BCI applications. Steady-State Visually Evoked Potential (SSVEP) paradigms have gained importance because of lesser training time, higher precision, and improved information transfer rate compared to P300 and motor imagery paradigms. In this paper, a novel hybrid Anchoring-based Particle Swarm Optimized Scaled Conjugate Gradient Multi-Layer Perceptron classifier (APS-MLP) is proposed to improve the classification accuracy of SSVEP five classes viz. 6.66, 7.5, 8.57, 10 and 12 Hz, signals. Scaled Conjugate Gradient descent anchors the initial position of Particle Swarm Optimization. The best position, Pbest, of each particle initializes an SCG-MLP, the accuracy of APS-MLP is obtained by averaging the accuracies of each SCG-MLP. The proposed method is compared with standard classifiers namely, k -NN, SVM, LDA and MLP. In which, the proposed algorithm achieves improved training and testing accuracies of 88.69% and 95.4% respectively, which is 12–15% higher than the standard EEG-based BCI classifiers. The proposed algorithm is robust, with a Cohen’s kappa coefficient of 0.96, and will be used in applications such as motion control and improving the quality of life for people with disabilities.},
  archive      = {J_IJAIT},
  author       = {Ravichander Janapati and Vishwas Dalal and Usha Desai and Rakesh Sengupta and Shrirang A. Kulkarni and D. Jude Hemanth},
  doi          = {10.1142/S021821302340016X},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {3},
  pages        = {2340016},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Classification of visually evoked potential EEG using hybrid anchoring-based particle swarm optimized scaled conjugate gradient multi-layer perceptron classifier},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An approach for gesture recognition based on a lightweight
convolutional neural network. <em>IJAIT</em>, <em>32</em>(3), 2340014.
(<a href="https://doi.org/10.1142/S0218213023400146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gesture recognition, which plays an important role to understand meaningful movements of human bodies, is one of the most effective approaches for humans to interact. Sign language is a fundamental and innate means of communication for hearing-impaired individuals. Though significant progress has been made, the state-of-the-art gesture recognition methods yield week performance for conditions with dynamic gestures in videos. Thus, robust gesture recognition remains a challenging issue because of many barriers of gesture-irrelevant factors. The key to robust gesture recognition is to learn effective and concise spatiotemporal information. Inspired by the great promise of the convolutional neural network (CNN) and its breakthroughs, we introduce an approach for identifying static alphabet gestures in the American Sign Language (ASL). The proposed CNN-based approach has been developed to classify letters of the alphabet from A to Z. It composes of three phases: a preprocessing phase for extracted of the region of interest, a feature extraction, and a classification phase. The performance of proposed gesture recognition approach is evaluated on the common ASL dataset and it achieves 94.83% accuracy, which is good enough to develop a strong translator from gesture-based ASL to spoken language as it is capable to handle a variety of 24 hand gestures.},
  archive      = {J_IJAIT},
  author       = {M. Ravinder and Kiran Malik and M. Hassaballah and Usman Tariq and Kashif Javed and Mohamed Ghoneimy},
  doi          = {10.1142/S0218213023400146},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {3},
  pages        = {2340014},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {An approach for gesture recognition based on a lightweight convolutional neural network},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multimodal biometrics authentication in healthcare using
improved convolution deep learning model. <em>IJAIT</em>,
<em>32</em>(3), 2340013. (<a
href="https://doi.org/10.1142/S0218213023400134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In healthcare applications, biometric authentication is crucial in managing patient credential details. The limited usage of biometric traits causes personal details theft, treatment hacking, and payment hijacking. Multimodal biometrics should incorporate into the healthcare system to maintain security and privacy in healthcare applications. Previous methods ensure authentication and security consume high computation complexity and fail to maintain system reliability and scalability. Therefore, in this work, an improved convolution deep learning model (ICDLM) is applied to manage the patient traits in the healthcare center. Initially, Experimentation is conducted with SWAN DATASET, which consists of face, voice, and periocular biometric features. The biometric characteristics are investigated according to the super point convolution neural model. The model analyzes the trait descriptors and interest points to identify the patterns. The extracted patterns are utilized to match the patient while accessing the information in healthcare applications. This process uses template pattern matching (TPM), which minimizes the absolute difference while authenticating the users. The system’s efficiency implemented using Python and excellency is compared with traditional approaches. The system attains 98.31% and 98.67% accuracy on the number of users and attempts with a minimum false identification rate of 0.0125 and 0.0128 for several users and attempts.},
  archive      = {J_IJAIT},
  author       = {S Balaji and U Rahamathunnisa},
  doi          = {10.1142/S0218213023400134},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {3},
  pages        = {2340013},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Multimodal biometrics authentication in healthcare using improved convolution deep learning model},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Breast masses segmentation: A framework of skip dilated
semantic network and machine learning. <em>IJAIT</em>, <em>32</em>(3),
2340012. (<a href="https://doi.org/10.1142/S0218213023400122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many medical specialists used Computer Aided Diagnostic (CAD) systems as a second opinion to detect breast masses. The poor visualization of mass images makes it difficult to identify precisely. To segment the lesions from the mammograms is a difficult task due to different shapes, sizes, and locations of the masses. The motivation of this study is to develop a method that can segment breast mass lesions from mammogram images. The objective is to perform the segmentation of the breast mass mammogram images more precisely at an early stage. Breast mass segmentation is always a basic requirement in computer-aided diagnosis systems. In this study segmentation of the masses abnormalities from the mammogram images is performed by using the Skipping Dilated semantic segmentation approach. The study uses class weights and Dilation factor using semantic Convolutional Neural Network (CNN). It overcomes the class misbalance in tumors and background class, that affect the mean Intersection over Union (MIOU), and weighted-IOU (WIOU) by using class weights. Secondly, dilation convolution magnifies the receptive field exposure that enriches the convolutional operation with context attentiveness. Two public datasets of mammography INbreast and CBIS-DDSM are used. The WIOU of Skipping Dilated Semantic CNN for INbreast is 98.51% and CBIS-DDSM is 94.82% achieved.},
  archive      = {J_IJAIT},
  author       = {Saliha Zahoor and Umar Shoaib and Ikram Ullah Lali},
  doi          = {10.1142/S0218213023400122},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {3},
  pages        = {2340012},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Breast masses segmentation: A framework of skip dilated semantic network and machine learning},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Special issue on emerging techniques in trusted
and reliable machine learning. <em>IJAIT</em>, <em>32</em>(3), 2302002.
(<a href="https://doi.org/10.1142/S0218213023020025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJAIT},
  author       = {Muhammad Attique Khan and Ioannis Hatzilygeroudis},
  doi          = {10.1142/S0218213023020025},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {3},
  pages        = {2302002},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Editorial: Special issue on emerging techniques in trusted and reliable machine learning},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Traffic prediction system using IoT cluster based
evolutionary under sampling approach. <em>IJAIT</em>, <em>32</em>(3),
2240024. (<a href="https://doi.org/10.1142/S0218213022400243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Road traffic is increasing nowadays due to the rapid growth of vehicle usage, which necessitates highly accurate traffic prediction systems. The traffic data is time-series data which identifies different pattern during low, moderate and high traffic time. Moving weighted average model that captures this phenomenon by assigning different weights for the different traffic classes to calculate the threshold values. This paper addresses the class imbalance in the traffic dataset due to which has the high impact on precision. The class imbalance problem can be handled by various data-level and algorithm-level techniques. Hybrid methods show better results while handling skewed class distribution in binary class problems. But the multiclass imbalance is a rarely focused research area. In this work, Cluster Based Evolutionary Undersampling with Correlation Relation (CBEUS_CR) is proposed to handle the multiclass imbalance problem of the traffic prediction system. The proposed system uses multiple regression as a fitness function on traffic parameters of an evolutionary algorithm in the majority classes on Apache spark environment. As a result, the sensitivity, and specificity of traffic prediction is improved and achieves 97% accuracy as it balances the number of instances between majority and minority classes.},
  archive      = {J_IJAIT},
  author       = {M. Prathilothamai and V. Viswanathan},
  doi          = {10.1142/S0218213022400243},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {3},
  pages        = {2240024},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Traffic prediction system using IoT cluster based evolutionary under sampling approach},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Preprocessing and artificial intelligence for increasing
explainability in mental health. <em>IJAIT</em>, <em>32</em>(2),
2340011. (<a href="https://doi.org/10.1142/S0218213023400110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper shows the added value of using the existing specific domain knowledge to generate new derivated variables to complement a target dataset and the benefits of including these new variables into further data analysis methods. The main contribution of the paper is to propose a methodology to generate these new variables as a part of preprocessing, under a double approach: creating 2nd generation knowledge-driven variables, catching the experts criteria used for reasoning on the field or 3rd generation data-driven indicators, these created by clustering original variables. And Data Mining and Artificial Intelligence techniques like Clustering or Traffic light Panels help to obtain successful results. Some results of the project INSESS-COVID19 are presented, basic descriptive analysis gives simple results that even though they are useful to support basic policy-making, especially in health, a much richer global perspective is acquired after including derivated variables. When 2nd generation variables are available and can be introduced in the method for creating 3rd generation data, added value is obtained from both basic analysis and building new data-driven indicators.},
  archive      = {J_IJAIT},
  author       = {X. Angerri and Karina Gibert},
  doi          = {10.1142/S0218213023400110},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {2},
  pages        = {2340011},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Preprocessing and artificial intelligence for increasing explainability in mental health},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vision and audio-based methods for first impression
recognition using machine learning algorithms: A review. <em>IJAIT</em>,
<em>32</em>(2), 2340010. (<a
href="https://doi.org/10.1142/S0218213023400109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personality is a psychological construct that embodies the unique characteristics of an individual. Automatic personality computing enables the assessment of personality elements with the help of machines. Over the last few decades, a lot of researchers have focussed on computing aspects of personality, emotions, and behavior with the help of machine learning. Efficient personality recognition using machine learning can provide inroads to almost every field of human advancement. However, we found out there are not enough good surveys to consolidate the progress of the growing field. In our effort, we have taken a sub-field of personality computation known as apparent personality perception or First Impressions. In addition to providing an exhaustive compilation of available First Impression research, we have classified the existing literature according to the data modalities and machine learning techniques they have utilized. Our work also lists various limitations and gaps within the existing literary works with possible measures to address them. The paper concludes with our comments on the future work in the field of first impressions.},
  archive      = {J_IJAIT},
  author       = {Sumiya Mushtaq and Neerendra Kumar and Yashwant Singh and Pradeep Kumar Singh},
  doi          = {10.1142/S0218213023400109},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {2},
  pages        = {2340010},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Vision and audio-based methods for first impression recognition using machine learning algorithms: A review},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of heart disease using a hybrid XGBoost-GA
algorithm with principal component analysis: A real case study.
<em>IJAIT</em>, <em>32</em>(2), 2340009. (<a
href="https://doi.org/10.1142/S0218213023400092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular diseases are one of the most common causes of death in the world. At this point, early diagnosis of heart diseases is critically important. The aim of this study is to predict the heart disease using feature selection, classification and optimization algorithms. Firstly, principal component analysis (PCA) is used to create the feature selection model and to determine the effective attributes. Then, Extreme Gradient Boosting (XGBoost) classification model is proposed to predict the heart disease. Finally, genetic algorithm (GA) is applied to optimize the parameters of XGBoost to improve the classification accuracy. The developed hybrid PCA-XGBoost-GA approach is compared with XGBoost, PCA-XGBoost, XGBoost-GA, artificial neural network (ANN) and support vector machine (SVM). The effectiveness of these approaches is illustrated with a case study with the actual data taken from a university hospital in Turkey. The numerical results show that the proposed PCA-XGBoost-GA model outperforms the other classification models in terms of accuracy rate, recall, precision and F-measure. Moreover, feature selection and parameter optimization improve the classification performance of the XGBoost model.},
  archive      = {J_IJAIT},
  author       = {Tuncay Ozcan and Ebru Pekel Ozmen},
  doi          = {10.1142/S0218213023400092},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {2},
  pages        = {2340009},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Prediction of heart disease using a hybrid XGBoost-GA algorithm with principal component analysis: A real case study},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multimodal depression detection: Using fusion strategies
with smart phone usage and audio-visual behavior. <em>IJAIT</em>,
<em>32</em>(2), 2340008. (<a
href="https://doi.org/10.1142/S0218213023400080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of detecting depression is multi-faceted because of variability in depressive symptoms caused by individual differences. The variations can be seen in historical information (like decreased physical activity etc.) and also in verbal/non-verbal behaviors (like lower pitch, downward eye gaze etc.). The primary goal of this research is to develop a novel classification system for diagnosing depression that considers both historical information and also verbal/non-verbal behaviors. For this purpose, we created a realworld multimodal dataset of depressed and non-depressed subjects with fourteen-day real-time smartphone usage records and audio-visual recordings. We extracted numerous features related to physiological/physical activity from smartphone usage records to capture historical information and features like pitch and eye gaze (verbal and non-verbal manifestations) from audio-visual clues. We experimented with early fusion using Decision trees classifier (along with several feature selection strategies) and Support Vector Machine (SVM) classifier with several late fusion methods. Then, we conducted a comparative study among both fusion strategies. Our findings showed that SVM classifier using late fusion strategy achieves best accuracy of 89%. In addition, a popular benchmarking multimodal dataset (DAIC-WOZ database) is used to further validate the effectiveness of our approach by fusing multi-faceted feature vectors for depression detection.},
  archive      = {J_IJAIT},
  author       = {Ravi Prasad Thati and Abhishek Singh Dhadwal and Praveen Kumar and P Sainaba},
  doi          = {10.1142/S0218213023400080},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {2},
  pages        = {2340008},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Multimodal depression detection: Using fusion strategies with smart phone usage and audio-visual behavior},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Selecting the best health care systems: An approach based on
opinion mining and simplified neutrosophic sets. <em>IJAIT</em>,
<em>32</em>(2), 2340007. (<a
href="https://doi.org/10.1142/S0218213023400079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring what hospital offers the best services is very difficult, for that reason, the opinions from previous patients have become an essential tool for the new possible clients to decide which services they must select. Many online platforms deal with opinions to analyze their services/products, primarily, by means of aspect-based sentiment analysis techniques. These techniques are mainly based on the detection of features from services/products to model the feelings toward them. Most models primarily cope with positiveness, negativeness and neutrality; nevertheless, these do not reflect other situations in which there are positive and negative aspects, but the overall sentiment is not neutral, but indeterminate. To face this issue, simplified neutrosophic sets can be a useful tool. Therefore, this study presents a novel application of the simplified neutrosophic sets to hospital ranking. The application, first, detects the hospital features, second, models the feelings toward them using simplified neutrosophic sets, and finally, ranks the hospitals according to the patients’ preferences. It has been tested using opinions from a real website and compared against other fuzzy logic-based approaches. The achieved results outperform the ones obtained by other proposals, revealing that simplified neutrosophic sets can be an interesting solution to model feelings.},
  archive      = {J_IJAIT},
  author       = {Jesus Serrano-Guerrero and Mohammad Bani-Doumi and Francisco P. Romero and Jose A. Olivas},
  doi          = {10.1142/S0218213023400079},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {2},
  pages        = {2340007},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Selecting the best health care systems: An approach based on opinion mining and simplified neutrosophic sets},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Blockchain and artificial intelligence-based solutions for
healthcare management: Liver disease detection as a case study.
<em>IJAIT</em>, <em>32</em>(2), 2340006. (<a
href="https://doi.org/10.1142/S0218213023400067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The issue of privacy in clinical data restricts data sharing among various organizations because of legal and ethical concerns. Every medical organization (hospital, research center, testing lab, etc.) needs to protect personal and medical data privacy and confidentiality while also sharing data with efficient and accurate learning models for various diseases. This paper addresses a method that combines machine learning approaches on blockchain network for classification of patients with liver disease or not, while maintaining the privacy and enabling data sharing. The contribution of this paper is five-folds: (i) To deal with the liver disease dataset, data preprocessing phases are utilized (i.e., missing data treatment, data normalization, and data transformation). (ii) For feature reduction, two feature selection models are used: correlation feature selection (CFS) and wrapper metaheuristic (PSO+KNN). For training the proposed global model, the selected features (10, 4, 3) from the three models (all features, CFS, PSO+KNN) are distributed to the shared blockchain network. (iii) To detect liver disease in the preprocessed dataset, three machine learning methods are proposed: random forest, decision tree (J48), and Naïve Bayes. (iv) The distributed network (blockchain) will publish the results of the liver disease diagnosis on the network. (v) The smart contract shares the data and diagnosis between the medical organizations for future processing. An empirical study is executed to validate the relevance of our suggested framework for early diagnosis of liver disease using blockchain and machine learning models. The experimental results showed that feature selection using the wrapper metaheuristic (PSO+KNN) with a random forest model achieves the best performance with the minor features for detecting liver disease with an accuracy of 99.9 compared to 99.2, 89.2 for Naïve Bayes, and J48, respectively.},
  archive      = {J_IJAIT},
  author       = {Zahraa Tarek and Mohamed Elhoseny and Ibrahim M. El-Hasnony},
  doi          = {10.1142/S0218213023400067},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {2},
  pages        = {2340006},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Blockchain and artificial intelligence-based solutions for healthcare management: Liver disease detection as a case study},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AutoFPR: An efficient automatic approach for facial
paralysis recognition using facial features. <em>IJAIT</em>,
<em>32</em>(2), 2340005. (<a
href="https://doi.org/10.1142/S0218213023400055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial paralysis (FP) is the most common illness. Nerve damage can cause the affected muscles of the face to lose control. Most FP diagnosis systems heavily depend on skilled clinicians and lack automatic quantitative assessment. This paper introduces a novel automatic facial paralysis recognition (autoFPR) approach, a four-stage machine learning solution, for classifying FP and healthy subjects. Our solution includes the creation of the dataset, feature extraction, dimensionality reduction, and classification. The FP and healthy subject videos are collected from the publicly available YouTube Facial Palsy database and the 300VW database, respectively. Facial features are extracted from the collected facial videos using landmarks, action units, eye gaze, and head pose. Five different experiments were performed to find the best facial paralysis recognition technique. autoFPR can distinguish subjects with facial paralysis and healthy individuals by using movement changes in their eyebrows, eyes, and corners of the mouth. Our goal is to prove that machine learning classifiers are capable of diagnosing FP. We evaluate system performance using accuracy, precision, recall, and F1. Feature selection plus principal component analysis with support vector machine achieved the highest accuracy, with 97.3% for the extracted features.},
  archive      = {J_IJAIT},
  author       = {Sridhar Reddy Gogu and Shailesh R. Sathe},
  doi          = {10.1142/S0218213023400055},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {2},
  pages        = {2340005},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {AutoFPR: An efficient automatic approach for facial paralysis recognition using facial features},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An effective depression diagnostic system using speech
signal analysis through deep learning methods. <em>IJAIT</em>,
<em>32</em>(2), 2340004. (<a
href="https://doi.org/10.1142/S0218213023400043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to the World Health Organization (WHO), depression is one of the largest contributors to the burden of mental and psychological diseases with more than 300 million people being affected; however a huge portion of this does not receive effective diagnosis. Traditional techniques to diagnose depression were based on clinical interviews. These techniques had several limitations based on duration and variety of symptoms, due to which these methods lacked subjectivity and accuracy. Speech is tested to be an important tool in diagnosis as they carry the impression of one’s thoughts and emotions. Speech signals not only carry the linguistic feature but they also contain several other features (paralinguistic features) which can reflect the emotional state of the speaker. The analysis of these features can be used for the diagnosis of depression. With the advancement of artificial techniques and algorithms, they have become popular and are widely used in tasks of pattern recognition and signal processing. These algorithms can easily extract the features from the data and learn to recognize patterns from them. Although these algorithms can successfully recognize emotions, their efficiency is often argued. The main objective of this paper is to propose a strategy to efficiently diagnose depression from the analysis of speech signals. The analysis is performed in the following two ways: First, by considering the male and female emotions combined (gender-neutral) where they are classified into two classes, and second, separately for the male and female emotions (gender-based) for a total of four classes. Experiments conducted show the advantages and shortcomings of paralinguistic features for diagnosis of depression. During experimentation we tested several architectures by efficiently tuning the hyperparameters. For K-nearest neighbors (KNN), best attained accuracy was 86%, whereas for Multi-Layer Perceptron (MLP) architecture the accuracy attained was 87.8%. Best results were obtained from hybrid 1D-Convolutional Neural Networks (CNN) and Long Short Term Memory (LSTM) architecture with the accuracy of 88.33% and 90.07% for gender-neutral and gender-based respectively.},
  archive      = {J_IJAIT},
  author       = {Aman Verma and Pooja Jain and Tapan Kumar},
  doi          = {10.1142/S0218213023400043},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {2},
  pages        = {2340004},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {An effective depression diagnostic system using speech signal analysis through deep learning methods},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ultrasound image segmentation and classification of benign
and malignant thyroid nodules on the basis of deep learning.
<em>IJAIT</em>, <em>32</em>(2), 2340003. (<a
href="https://doi.org/10.1142/S0218213023400031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aimed to investigate the effect of an image denoising algorithm based on weighted low-rank matrix restoration on thyroid nodule ultrasound images. A total of 1000 original ultrasound image data sets of thyroid nodules were selected as the study samples. The nodule segmentation data set of thyroid ultrasound region of interest (ROI) images was drawn and acquired. By introducing multiscale features and an attention mechanism to optimize the U-Net model, an ultrasound image segmentation model (F-U-Net) was constructed. The performance of the traditional U network model and full convolutional neural network model (FCN) was analyzed and compared by simulation experiments. The results showed that the dice coefficient, accuracy, and recall of the improved loss function in this study were significantly higher than those of the traditional cross entropy loss function and dice coefficient loss function, and the differences were statistically significant ( P &lt; 0.05). The Dice coefficient, accuracy, and recall of the F-U-net model were significantly higher than those of the traditional FCN model and U-net model ( P &lt; 0.05). The diagnostic sensitivity, specificity, accuracy, and positive predictive value of the F-U-net model for benign and malignant thyroid nodules were significantly higher than those of the FCN model and U-net model ( P &lt; 0.05). In summary, the proposed F-U network can effectively process the ultrasound images of thyroid nodules, improve the image quality, and help to improve the diagnostic effect of benign and malignant thyroid nodules. It provides a data reference for segmentation and reconstruction of benign and malignant ultrasound images of thyroid nodules.},
  archive      = {J_IJAIT},
  author       = {Min Yang and Austin Lin Yee and Jiafeng Yu},
  doi          = {10.1142/S0218213023400031},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {2},
  pages        = {2340003},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Ultrasound image segmentation and classification of benign and malignant thyroid nodules on the basis of deep learning},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An integrated framework with deep learning for segmentation
and classification of cancer disease. <em>IJAIT</em>, <em>32</em>(2),
2340002. (<a href="https://doi.org/10.1142/S021821302340002X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses radiologists’ specific diagnosis of cancer disease effectively using integrated framework of deep learning model. Although several existing diagnosis systems have been adopted by a physician, in few cases, it is not so practical to see the infected area from images in the normal eye. Thus, a fully integrated diagnosis framework for disease detection is proposed to find out the infected area from image using deep learning approaches in this paper. In this proposed framework, various components are designed through deep learning approaches such as detection, segmentation, classification etc. based on mass region. The classification technique is used to classify the disease as either benign or malignant. The vital part of this framework is developed by using a full resolution convolutional network (FrCN) that supports different stages of image processing, especially breast cancer disease. Different experimental evaluation is taken to perform on the accuracy, cross-validation tests, and the comparative testing. Since we have taken 4-fold evaluation, the FrCN performs with an average 98.7% Dice index, 97.8% TS/CSI coefficient, 99.1% overall accuracy, and 98.15% MCC. Our experiments demonstrated that the proposed diagnosis system performs on the deep learning approaches at each segmentation stage and classification with good results.},
  archive      = {J_IJAIT},
  author       = {Hemanta Kumar Bhuyan and Vinayakumar Ravi},
  doi          = {10.1142/S021821302340002X},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {2},
  pages        = {2340002},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {An integrated framework with deep learning for segmentation and classification of cancer disease},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Glaucoma detection in retinal fundus images based on deep
transfer learning and fuzzy aggregation operators. <em>IJAIT</em>,
<em>32</em>(2), 2340001. (<a
href="https://doi.org/10.1142/S0218213023400018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The early diagnosis of the glaucoma disease in the eye is crucial to avoid vision loss. This paper proposes an efficient computer-aided detection (CAD) system for diagnosing glaucoma based on fundus images, deep transfer learning and fuzzy aggregation operators. Specifically, the proposed CAD system includes three stages: (1) Detection of the region of interest of the optic disc using an efficient deep learning network, (2) Classification of images based on different pre-trained deep convolutional neural networks and support vector machines, and (3) Use of fuzzy aggregation operators to fuse the predictions of glaucoma classifiers. We used three popular yet robust aggregators: ordered weighted averaging (OWA) operator, weighted power mean (WPM), and exponential mean (EXM). We assessed the efficacy of the proposed glaucoma CAD system on three public datasets: DRISHTI-GS1, RIM-ONE, and REFUGE. The proposed conjunctive OWA aggregation method (Conj-OWA) achieves the best glaucoma classification results. Specifically, it achieves accuracy values of 90.2%, 97.8%, and 94.3% and area under the curve (AUC) values of 95.3%, 99.8%, and 96.2%, respectively, on DRISHTI-GS1, RIM-ONE, and REFUGE databases.},
  archive      = {J_IJAIT},
  author       = {Mohammed Yousef Salem Ali and Mohammad Jabreel and Aida Valls and Marc Baget and Mohamed Abdel-Nasser},
  doi          = {10.1142/S0218213023400018},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {2},
  pages        = {2340001},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Glaucoma detection in retinal fundus images based on deep transfer learning and fuzzy aggregation operators},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Special issue on data mining, machine learning
and decision support systems in health care. <em>IJAIT</em>,
<em>32</em>(2), 2302001. (<a
href="https://doi.org/10.1142/S0218213023020013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJAIT},
  author       = {Aida Valls and Teresa Alsinet and Antonio Moreno},
  doi          = {10.1142/S0218213023020013},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {2},
  pages        = {2302001},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Editorial: Special issue on data mining, machine learning and decision support systems in health care},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reservoir computing for solving ordinary differential
equations. <em>IJAIT</em>, <em>32</em>(1), 2350030. (<a
href="https://doi.org/10.1142/S0218213023500306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a wave of interest in using physics-informed neural networks for solving differential equations. Most of the existing methods are based on feed-forward networks, while recurrent neural networks solvers have not been extensively explored. We introduce a reservoir computing (RC) architecture, an echo-state recurrent neural network capable of discovering approximate solutions that satisfy ordinary differential equations (ODEs). We suggest an approach to calculate time derivatives of recurrent neural network outputs without using back-propagation. The internal weights of an RC are fixed, while only a linear output layer is trained, yielding efficient training. However, RC performance strongly depends on finding the optimal hyper-parameters, which is a computationally expensive process. We use Bayesian optimization to discover optimal sets in a high-dimensional hyper-parameter space efficiently and numerically show that one set is robust and can be transferred to solve an ODE for different initial conditions and time ranges. A closed-form formula for the optimal output weights is derived to solve first-order linear equations in a one-shot backpropagation-free learning process. We extend the RC approach by solving nonlinear systems of ODEs using a hybrid optimization method consisting of gradient descent and Bayesian optimization. Evaluation of linear and nonlinear systems of equations demonstrates the efficiency of the RC ODE solver.},
  archive      = {J_IJAIT},
  author       = {Marios Mattheakis and Hayden Joy and Pavlos Protopapas},
  doi          = {10.1142/S0218213023500306},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {1},
  pages        = {2350030},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Reservoir computing for solving ordinary differential equations},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data expansion approach with attention mechanism for
learning with noisy labels. <em>IJAIT</em>, <em>32</em>(1), 2350027. (<a
href="https://doi.org/10.1142/S0218213023500276">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the development of deep learning has contributed to various areas of machine learning. However, deep learning requires a huge amount of data to train the model, and data collection techniques such as web crawling can easily generate incorrect labels. If a training dataset has noisy labels, the generalization performance of deep learning significantly decreases. Some recent works have successfully divided the dataset into samples with clean labels and ones with noisy labels. In light of these studies, we propose a novel data expansion framework to robustly train the models on noisy labels with the attention mechanisms. First, our method trains a deep learning model with the sample selection approach and saves the samples selected as clean at the end of training. The original noisy dataset is then extended with the selected samples and the model is trained on the dataset again. To prevent over-fitting and allow the model to learn different patterns of the selected samples, we leverage the attention mechanism of deep learning to modify the representation of the selected samples. We evaluated our method with synthetic noisy labels on CIFAR-10 and CUB-200-2011 and real-world dataset Clothing1M. Our method obtained comparable results to baseline CNNs and state-of-the-art methods.},
  archive      = {J_IJAIT},
  author       = {Yuichiro Nomura and Takio Kurita},
  doi          = {10.1142/S0218213023500276},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {1},
  pages        = {2350027},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Data expansion approach with attention mechanism for learning with noisy labels},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Double-inputs illumination pattern recognizing model with
automatic shadow detection network in a single face image.
<em>IJAIT</em>, <em>32</em>(1), 2350010. (<a
href="https://doi.org/10.1142/S0218213023500100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Illumination pattern recognition of face image has always been a hot research topic in the field of human-computer interaction, and has been widely used in lighting recovery, virtual scene construction and other multimedia fields. Most of the traditional methods achieve this task by analyzing the illumination components from the image texture and structure information, which is often considered to be indirect, complex and time-consuming. This paper introduces a Double-inputs Illumination Pattern Recognizing Model (DIPRM) with Automatic Shadow Detection Network (ASDN) based on Convolution Neural Networks (CNNs). In the proposed coherent system framework, we first annotate the shadow regions of face images with uneven illumination to obtain the face shadow detection dataset. Second, an ASDN which has the encoder-decoder structure is designed. The main architecture of the ASDN is based on the nested U-Net, and for this nesting, the attention mechanism is applied to fuse the output of each sublayer. Third, a double-inputs Facial Illumination Pattern Recognizing Network (FIPRN) following the ASDN is organized, which consists of AlexNet and the attention module. As the double-inputs, the binary image after the shadow segmentation from the ASDN and the original image are input into the FIPRN to make the whole network converge to a good collaboration state eventually. For shadow detection task, the ASDN was evaluated in comparisons with U-Net and UNet++. Experimental results demonstrated that the ASDN achieved an average IoU and Dice gains of 1.9 and 1.2 points over the base-line model with best results. Moreover, the FIPRN was tested in comparison with some baseline models in illumination pattern recognizing task, where the results demonstrated that it achieved an accuracy rate gain of 1.0 points than the AlexNet with a signal-input.},
  archive      = {J_IJAIT},
  author       = {Jiaqi Liu and Jizheng Yi and Aibin Chen},
  doi          = {10.1142/S0218213023500100},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {1},
  pages        = {2350010},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Double-inputs illumination pattern recognizing model with automatic shadow detection network in a single face image},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A RERNN-SGO technique for improved quasi-z-source cascaded
multilevel inverter topology for interfacing three phase grid-tie
photovoltaic system. <em>IJAIT</em>, <em>32</em>(1), 2350009. (<a
href="https://doi.org/10.1142/S0218213023500094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this manuscript, a proficient control strategy-based improved Quasi-Z-Source Cascaded Multilevel Inverter (QZS-CMI) topology for interfacing photovoltaic (PV) system is proposed. The control strategy is joint execution of both recalling-enhanced recurrent neural network (RERNN) and Shell Game Optimization (SGO), therefore it is called RERNN-SGO technique. The major intention of proposed system determined the photovoltaic system efficiency and maximize the power extraction. The interface among load and PV dc source is to accomplish by the QZSI. At first, the objective function is determined depending on the control constraint and parameters, like current, voltage, modulation index, power. These parameters are utilized to propose RERNN-SGO method. The RERNN-SGO method is used to improve the power delivery, voltage profile and minimum power oscillation for power distribution with load. The maximal power delivered the load is to ensure the artificial intelligence (AI) strategy with the help of maximal power point tracking (MPPT). To regulate shoot through duty ratio and modulation load, the proposed AI method is used. The proposed system is inspired on MATLAB/Simulink site, and then efficiency is related with existing systems under various load conditions. The efficiency of proposed system in Case 1 and Case 2 is 87.363% and 85.3904%.},
  archive      = {J_IJAIT},
  author       = {M. Bhavani and P. S. Manoharan},
  doi          = {10.1142/S0218213023500094},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {1},
  pages        = {2350009},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {A RERNN-SGO technique for improved quasi-Z-source cascaded multilevel inverter topology for interfacing three phase grid-tie photovoltaic system},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Novel sparse feature regression method for traffic
forecasting. <em>IJAIT</em>, <em>32</em>(1), 2350008. (<a
href="https://doi.org/10.1142/S0218213023500082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic forecasting is an integral part of modern intelligent transportation systems. Although many techniques have been proposed in the literature to address the problem, most of them focus almost exclusively on forecasting accuracy and ignore other important aspects of the problem. In the paper at hand, a new method for both accurate and fast large-scale traffic forecasting, named “sparse feature regression”, is presented. Initially, a set of carefully selected features is extracted from the available traffic data. Then, some of the initial features are sparsified, namely they are transformed into sets of sparse features. Finally, a linear regression model is designed using the sparse feature set, which is trained by solving an optimization problem using a sparse approximate pseudoinverse as a preconditioner. We evaluated the proposed method by conducting experiments on two real-world traffic datasets, and the experimental results showed that the method presents the best balance between accuracy of predictions and time required for achieving them, in comparison with a set of benchmark models.},
  archive      = {J_IJAIT},
  author       = {Athanasios I. Salamanis and George A. Gravvanis and Sotiris B. Kotsiantis and Michael N. Vrahatis},
  doi          = {10.1142/S0218213023500082},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {1},
  pages        = {2350008},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Novel sparse feature regression method for traffic forecasting},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unexpectedness as a measure of semantic learning when
training transformer models. <em>IJAIT</em>, <em>32</em>(1), 2350007.
(<a href="https://doi.org/10.1142/S0218213023500070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many problems in NLP such as language translation and sentiment analysis have shown a lot of improvement in recent years. As simpler language problems are solved or better understood, the focus shifts to more complex problems such as semantic analysis and understanding. Unfortunately, a lot of studies in the literature suffer from a too much specificity problem. The algorithms and datasets are too domain specific. In this study, we analyze and elaborate on this notion of generality. Instead of selecting a highly specialized data set for semantic analysis, we take a generic and possibly dry data set, and we study how a plain vanilla Transformer performs in learning higher level semantic patterns beyond what was obvious or expected. We tune our Transformer model on a classic language task to ensure correct performance. Once tuned, the goal is to select sentences with specific key words and study whether higher level semantic patterns may have been learned by our model. We believe that we obtained promising results. The average BLEU score for sentences less than 25 words is equal to 39.79. Our initial qualitative analysis of possible semantic content of interest shows a 17 percent rate in finding interesting semantic patterns. We provide discussion of data driven results of unexpectedness as a measure of semantic learning.},
  archive      = {J_IJAIT},
  author       = {Ricardo A. Calix and Leili Javadpour},
  doi          = {10.1142/S0218213023500070},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {1},
  pages        = {2350007},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Unexpectedness as a measure of semantic learning when training transformer models},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the inverse frequent itemset mining problem for condensed
representations of itemsets. <em>IJAIT</em>, <em>32</em>(1), 2350006.
(<a href="https://doi.org/10.1142/S0218213023500069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverse frequent itemset mining can be successfully modelled as an instance of the Probabilistic Satisfiability problem. Given a transaction database we can perform a frequent itemset mining algorithm, like the Apriori algorithm, to obtain useful itemset collections such as frequent or closed itemsets. We then use these itemset collections as frequency constraints in order to reconstruct the original database by solving a linear programming problem. There are cases however, where the reconstructed database is not in direct agreement with the original one. In this study, we analyse the degree of similarity between the original database and the reconstructed one, when different variations of condensed itemset representations are used as the initial frequency constraints. We examine how much the initial database properties and itemset relations have been preserved when we emphasize on the frequent itemset border and assess database quality by measuring database distance metrics. As this solution framework presents increased computational cost, we also consider a heuristic approach that is based on the notion that a transaction can be also considered as an itemset and compare the strengths and weaknesses of each framework when the same conditions apply. We manage to improve the efficiency of existing heuristic based approaches to the problem by utilizing smaller initial itemset collections. Our work contributes in (a) privacy preserving data mining and (b) gain in transaction database storage memory savings.},
  archive      = {J_IJAIT},
  author       = {Petros N. Tamvakis and Evangelos Sakkopoulos and Vassilios S. Verykios},
  doi          = {10.1142/S0218213023500069},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {1},
  pages        = {2350006},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {On the inverse frequent itemset mining problem for condensed representations of itemsets},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated generation of discrete event simulation models for
the economic assessment of interventions for rare diseases using the
RaDiOS ontology. <em>IJAIT</em>, <em>32</em>(1), 2350005. (<a
href="https://doi.org/10.1142/S0218213023500057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collection and synthesis of evidence is a key task in the development of the simulation models required for health technology assessment (HTA). The implementation of some of these models, such as discrete event simulation (DES) models, presents technical difficulties and requires higher technical skills. This work presents a method to extract the knowledge stored in an ontology, Rare Disease Ontology for Simulation (RaDiOS), to generate a DES model. RaDiOS is a domain ontology focused on collecting evidence on rare diseases for simulation models. We reviewed and enhanced the ontology to increase its semantic expressiveness. Besides, we developed a transformation tool (RaDiOS-MTT) to automatically generate DES models from the knowledge stored in the ontology. We defined a set of “synthetic” diseases, with simple natural histories, represented them in RaDiOS, and compared the results of the automatically generated simulation models with their manually created counterparts. Afterwards, we used a case study on a real intervention (newborn screening for profound biotinidase deficiency) to validate our approach. The automatically generated models for the synthetic diseases mimicked their programmatic counterparts in structure and results. The same happened to the model for profound biotinidase deficiency.},
  archive      = {J_IJAIT},
  author       = {David Prieto-González and Iván Castilla-Rodríguez and Evelio José González-González and María de la Luz Couce-Pico},
  doi          = {10.1142/S0218213023500057},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {1},
  pages        = {2350005},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Automated generation of discrete event simulation models for the economic assessment of interventions for rare diseases using the RaDiOS ontology},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of incident solar radiation using a hybrid kernel
based extreme learning machine. <em>IJAIT</em>, <em>32</em>(1), 2350004.
(<a href="https://doi.org/10.1142/S0218213023500045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting solar radiation for a given region is an emerging field of study. It will help to identify the places for installing large-scale photovoltaic-systems, designing energy-efficient buildings and energy estimation. The different machine learning kernel-based approaches for prediction problems uses either a local or global kernel. These models can provide either strong training capability or good generalization performance. In this paper, a new hybrid kernel is proposed using the combination of a local and global kernel. A novel algorithm Hybrid Kernel-based Extreme Learning Machine is proposed for predictive modelling of Incident Solar Radiation ( ISR ) time series using new hybrid kernel. The proposed algorithm uses the surface, atmospheric, cloud properties obtained from the MODIS instrument and observed ISR at time t – 1 to predict ISR at time t . This study is conducted for 41 diverse sites of Australia for the period of 2012–2015. Further, the proposed model is experimented with other time series datasets to prove its efficacy. It is shown that the proposed methodology outperforms five other benchmarking methods in terms of MAE and Willmott’s Index ( WI ). Therefore, the suggested approach can be used for modelling solar energy at a national scale using remotely-sensed satellite footprints.},
  archive      = {J_IJAIT},
  author       = {Preeti and Rajni Bala and Ram Pal Singh},
  doi          = {10.1142/S0218213023500045},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {1},
  pages        = {2350004},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Prediction of incident solar radiation using a hybrid kernel based extreme learning machine},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Top-k learned clauses for modern SAT solvers.
<em>IJAIT</em>, <em>32</em>(1), 2350003. (<a
href="https://doi.org/10.1142/S0218213023500033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clause Learning is one of the most important components of a conflict driven clause learning (CDCL) SAT solver that is effective on industrial SAT instances. Since the number of learned clauses is proved to be exponential in the worst case, it is necessary to identify the most relevant clauses to maintain and delete the irrelevant ones. As reported in the literature, several learned clauses deletion strategies have been proposed. However the diversity in both the number of clauses to be removed at each step of reduction and the results obtained with each strategy increase the difficulty to determine which criterion is better. Thus, the problem to select which learned clauses are to be removed during the search step remains very challenging. In this paper, we propose a novel approach to identify the most relevant learned clauses without favoring or excluding any of the proposed measures, but by adopting the notion of dominance relationship among those measures. Our approach bypasses the problem of difference in the results obtained with different measures and reaches a compromise between the measures assessments. Furthermore, the proposed approach also reduces the non-trivial problem of choosing the number of clauses to delete at each reduction of the learned clause database.},
  archive      = {J_IJAIT},
  author       = {Jerry Lonlac and Engelbert Mephu Nguifo},
  doi          = {10.1142/S0218213023500033},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {1},
  pages        = {2350003},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Top-k learned clauses for modern SAT solvers},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning student intents and named entities in the education
domain. <em>IJAIT</em>, <em>32</em>(1), 2350002. (<a
href="https://doi.org/10.1142/S0218213023500021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting intents and extracting necessary contextual information (aka named entities) in input utterances are two fundamental tasks in understanding what the users say in chatbot systems. While most work in this field has been dedicated to high-resource languages in popular domains like business and home automation, little research has been done for low-resource languages, especially in a less popular domain like education. To narrow this gap, this paper presents the first study on learning to detect student intents and to recognize named entities in the education domain targeted to the Vietnamese language. Specifically, we first introduce a complete corpus consisting of 3690 utterances of students. It was manually annotated with both named entities and intent information at two levels of granularity: the fine-grained and the coarse-grained levels. We then systematically investigate different approaches to deal with the two tasks using not only independent but also joint learning architectures. The experimental results show that the joint architectures based on pre-trained language models are superior in boosting the performance of both tasks. They outperformed the conventional independent learning architectures which looked at the two tasks separately. Moreover, to further enhance the final performance, this paper proposes a technique to enrich the models with more useful linguistic features. Compared to the standard approaches, we achieve considerably better results for two tasks in both architectures. Overall, for the named entity recognition task, the best model yielded an F 1 score of 88.61%. For the intent detection task, it yielded F 1 scores of 94.36% and 91.62% at the coarse-grained and fine-grained levels, respectively.},
  archive      = {J_IJAIT},
  author       = {Oanh Thi Tran and Thang Van Nguyen and Tu Anh Nguyen and Ngo Xuan Bach},
  doi          = {10.1142/S0218213023500021},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {1},
  pages        = {2350002},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Learning student intents and named entities in the education domain},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An information extraction and thorough understanding method
for test-question graph of junior high school physical mechanical
motion. <em>IJAIT</em>, <em>32</em>(1), 2350001. (<a
href="https://doi.org/10.1142/S021821302350001X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent problem-solving technology is a typical application of artificial intelligence in the educational field. The purpose of intelligent problem-solving is to enable machine to solve problems like human beings and help people to find useful and accurate information in the test-questions. Correct understanding of test-questions is one of the key techniques of intelligent problem-solving. The existing methods are mainly to extract simple relations from text and graphs of test-questions. In the absence of text, deep understanding of graph elements and complex relationships are difficult, which is a challenge for machines. However, the information contained in motion test-question graphs is more abundant than that in the text, which is more beneficial for machine to solve problems. To solve this problem, based on the graph classification and characteristics analysis on test-questions, a novel automatic and weak text-dependent information extraction and thorough understanding method for test-question graph of junior high school physical mechanical motion is proposed (TQGIEU). It can extract information and understand regarding to test-question graphs based on several image preprocessing techniques and neural network topologies combined with the characteristics of test-question graphs, without relying on text processing. It will generate a readable mechanical motion solution at last. It fills the blank of automatic information extraction and thorough understanding for the test-question research of physical mechanical motion. The experimental results show that the accuracy of graph classification and line segmentation model are 99.60% and 90.87% respectively. The average accuracy of TQGIEU on test dataset is 83.08%, and the total F1 score of TQGIEU is 0.859, indicating that TQGIEU can provide a good information extraction and thorough understanding service for test-question graphs of junior high school physical mechanical motion with high performance.},
  archive      = {J_IJAIT},
  author       = {Gang Zhao and Jie Chu and Shufan Jiang and Hui He},
  doi          = {10.1142/S021821302350001X},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {1},
  pages        = {2350001},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {An information extraction and thorough understanding method for test-question graph of junior high school physical mechanical motion},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual stream conditional generative adversarial network
fusion for video abnormal behavior detection. <em>IJAIT</em>,
<em>32</em>(1), 2250046. (<a
href="https://doi.org/10.1142/S0218213022500464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been successfully applied to video anomaly detection. However, the way that deep network learn spatio-temporal features autonomously will ignore the specificity of different pattern features. Therefore, this paper focuses on how to efficiently learn deep appearance feature, introduces the idea of learning appearance information by predicting future frame, and proposes dual stream conditional generative adversarial network fusion for video abnormal behavior detection. The video frame and its corresponding optical flow image are transferred to the conditional generative adversarial network to learn the motion feature representation. In addition, inputting the video frame and its corresponding future frame to the network to generate the appearance representation complementary to motion feature. The model is only trained with normal events, therefore it is not able to generate abnormal events accurately. During the test, for the foreground moving targets, the images generated by the model are compared with the ground truth to obtain a two-stream anomaly probability distribution model based on the mean square error used to achieve the purpose of region anomaly detection. Experiments on the public datasets show that the proposed method can effectively detect and locate abnormal behaviors in the video.},
  archive      = {J_IJAIT},
  author       = {Mengyao Zhao and Zhengping Hu and Shufang Li and Zhe Sun},
  doi          = {10.1142/S0218213022500464},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {1},
  pages        = {2250046},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Dual stream conditional generative adversarial network fusion for video abnormal behavior detection},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Entropy weighted and kernalized power k-means clustering
based lesion segmentation and optimized deep learning for diabetic
retinopathy detection. <em>IJAIT</em>, <em>32</em>(1), 2250044. (<a
href="https://doi.org/10.1142/S0218213022500440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy (DR), a common complication of diabetes, is one of the leading causes of visual loss in a growing population. Thus, it is essential to identify DR at an early stage in order to minimize the problem of vision loss. As a result, the Henry Gas SailFish Optimizer (HGSO) algorithm and a successful lesion segmentation method based on Entropy Weighted and Kernalized Power K-Means Clustering (EWKPC) are developed for the DR detection. However, the SailFish Optimizer (SFO) and Henry Gas Solubility Optimization (HGSO) were combined to form the novel approach known as HGSO. Here, noise from the image is removed during pre-processing using the Region of Interest (ROI) approach and median filtering. Another use of the suggested EWKPC approach is lesion segmentation. Based on the outcomes of the data augmentation phase, Deep Convolutional Neural Network (DCNN)-based DR detection is carried out using the created HGSO algorithm. Along with effective performance, the created HGSO-based DCNN also displayed higher accuracy (0.910), specificity (0.929), and sensitivity (0.909).},
  archive      = {J_IJAIT},
  author       = {J. Granty Regina Elwin and K. Suresh Kumar and J. P. Ananth and R. Ramesh Kumar},
  doi          = {10.1142/S0218213022500440},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {1},
  pages        = {2250044},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Entropy weighted and kernalized power K-means clustering based lesion segmentation and optimized deep learning for diabetic retinopathy detection},
  volume       = {32},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
