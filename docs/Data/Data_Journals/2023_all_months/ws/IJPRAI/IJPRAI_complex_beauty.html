<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJPRAI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijprai---198">IJPRAI - 198</h2>
<ul>
<li><details>
<summary>
(2023). A design and intelligent recommendation method for ballistic
missile early warning operation plan. <em>IJPRAI</em>, <em>37</em>(16),
2359024. (<a href="https://doi.org/10.1142/S0218001423590243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ballistic missile attack-defense confrontation is a typical system-of-systems confrontation process. Ballistic missile early warning operations have the characteristics of high time-sensitivity, high complexity and high dynamic. It is impossible to deal with complex battlefield situations at the moment of decision. It is necessary to develop a detection plan in advance for possible battlefield situations, and intelligently recommend the optimal detection plan for the commander to make decisions based on the battlefield situation. The ballistic missile early warning detection plan is designed from three aspects: the design of search screen parameters, the determination of search data rate, and the allocation strategy of search resources in different airspace; Establish the evaluation indicator system and evaluation model of the ballistic missile early warning detection plan, evaluate and optimize multiple detection plans, and automatically recommend them to the commander according to the advantages and disadvantages of the operational effectiveness, connect the auxiliary decision-making chain of “design evaluation recommendation decision”, providing support for the intelligent decision-making of the ballistic missile early warning operation.},
  archive      = {J_IJPRAI},
  author       = {Shi Qu and Cangzhen Meng and Hongbin Jin and Yi Zheng and Xiaobo Li},
  doi          = {10.1142/S0218001423590243},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2359024},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A design and intelligent recommendation method for ballistic missile early warning operation plan},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent target classification algorithm for 77G radar
based on correction data set. <em>IJPRAI</em>, <em>37</em>(16), 2359023.
(<a href="https://doi.org/10.1142/S0218001423590231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic participant classification is crucial in autonomous driving perception. Millimeter wave radio detection and ranging radar is a cost-effective and powerful method to perform the task in adverse traffic scenarios, especially in bad inclement weather (e.g. fog, snow and rain) and poor lighting conditions. This paper presents an intelligent target classification algorithm for 77G radar based on correction data set. First, in order to handle the problem that the original data set may easily be interfered by obstacles, the angle information is filtered by analyzing the spatial information of radar signals, which means the interference clutter of obstacles can be effectively removed. Second, the primary data set is corrected using the significant difference between the micro-Doppler of the human body and car. Finally, the characteristic information of the radar signal is extracted, including distance, speed, orientation, micro-Doppler and reflection intensity, and the obtained data sets containing three types of targets (vehicles, human bodies and obstacles) are generated. The generated dynamic and static data sets are collected by sufficient experiments to construct deep learning classification models. The results show that the classification accuracy is improved by the measure of data set correction.},
  archive      = {J_IJPRAI},
  author       = {Jing Zhang and Qing Jiang and Maosheng Fu and Xiancun Zhou and Chaochuan Jia and Cuicui Cai and Quan Zhou and Yu Liu and Xiuhai Wu and Xiyuan Shen},
  doi          = {10.1142/S0218001423590231},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2359023},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Intelligent target classification algorithm for 77G radar based on correction data set},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Denoised non-local means with BDDU-net architecture for
robust retinal blood vessel segmentation. <em>IJPRAI</em>,
<em>37</em>(16), 2357016. (<a
href="https://doi.org/10.1142/S0218001423570161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal blood vessels can be obtained by image segmentation. This study proposes combining image enhancement and segmentation to obtain retinal blood vessels. The image enhancement stages use CLAHE and Denoised Non-Local Means to increase contrast and reduce noise on the original image, and Bottom-Hat (BTH) filtering is used to lighten dark features in the image so the features become lighter and darken the bright features in the image. Bottom Hat is applied to make the features of the blood vessels in the retinal image more visible. The segmentation architecture proposes BDDU-Net architecture which combines U-Net in the encoder part, DenseNet in the bridge part, and Bi-ConvLSTM in the decoder part. Image enhancement performance results are PSNR and SSIM. The PSNR is more than 40 dB on both the DRIVE and STARE datasets. The SSIM results are close to 1 on the DRIVE and STARE datasets. These results show that the image enhancement stages in the proposed method can enhance the quality of the original image. The segmentation performance results of BDDU-Net architecture are measured based on accuracy, sensitivity, specificity, IoU, and F1-Score. The DRIVE dataset obtained 95.578% for accuracy, 85.75% for sensitivity, 96.75% for specificity, 67.407% for IoU, and 80.53% for F1-Score. The STARE dataset obtained 97.63% for accuracy, 84.33% for sensitivity, 98.66% for specificity, 75.67% for IoU, and 86.15% for F1-Score. Based on the image enhancement and image segmentation results, these results show that the proposed method is great for enhancing image quality and excellent for blood vessel segmentation in retinal images, although IoU results on the DRIVE dataset need to be improved.},
  archive      = {J_IJPRAI},
  author       = {Anita Desiani and Erwin and Bambang Suprihatin and Dwiza Riana and Muhammad Arhami and Indri Ramayanti and Yadi Utama},
  doi          = {10.1142/S0218001423570161},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2357016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Denoised non-local means with BDDU-net architecture for robust retinal blood vessel segmentation},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Person identification system using periocular biometrics
based on hybrid optimal dense capsule network. <em>IJPRAI</em>,
<em>37</em>(16), 2356026. (<a
href="https://doi.org/10.1142/S0218001423560268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person identification using periocular images has emerged as a challenging scenario in efficient biometric analysis, particularly under less constrained environments. Accurate recognition is significant in rendering effective measures during the COVID-19 pandemic. In this research paper, the person identification process is performed based on a deep learning model. Several effectual methods have already been developed, but certain drawbacks still exist, like deteriorated image quality, high computational cost, increased error, less training ability, a requirement of high storage space and accuracy rate degradation. Hence, the proposed work introduces a Hybrid Optimal Dense Capsule network-based Periocular biometric system (HodCP) to conquer these demerits. The proposed work involves pre-processing, dimensionality reduction, hybrid feature extraction and Image matching. The pre-processing step is undertaken using Parabolic Contrast Enhancement (PCE) to balance the image contrast and enhance the image quality. Then the Two-Dimensional Principal Component Analysis (2D_PCA) is employed to minimize the image dimensionality. Deep features are extracted in the hybrid feature extraction process using Dense Convolutional-121 Capsule Network (DenseCapsNet). The net loss and hyperparameter tuning are performed through African Vultures Optimization (AVO) algorithm. Finally, image matching is performed using Weighted Distance Similarity (WDS), which identifies the similarity between the query image and a set of image samples based on the distance score. The simulation tool used for analyzing better performance is PYTHON. The data required to process the proposed work are collected from four benchmark datasets. The proposed work provides a better accuracy rate of CASIA-Iris-Mobile-V1.0 (99.01%), UBIPr (99.12%), Facemask detection dataset (98.67%) and Glasses versus without glasses dataset (98.83%), which is superior to the existing methods.},
  archive      = {J_IJPRAI},
  author       = {Deepali R. Bhamare and Pravin S. Patil},
  doi          = {10.1142/S0218001423560268},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2356026},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Person identification system using periocular biometrics based on hybrid optimal dense capsule network},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). WiFi-based lightweight gesture recognition for coal miners.
<em>IJPRAI</em>, <em>37</em>(16), 2356012. (<a
href="https://doi.org/10.1142/S0218001423560128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of smart mines, the need for gesture recognition for remote interaction between underground workers and machines has become crucial. However, traditional gesture recognition techniques require complex models that are very difficult to be deployed to the edge. To address this challenge, a gesture recognition method based on knowledge distillation is proposed in this study. First, the CSI ratio model is used to eliminate phase error and environmental noise, followed by the application of discrete wavelet transform to eliminate hardware noise interference. Then, the processed data is adaptively segmented using the principal component analysis and local anomaly factor algorithm to eliminate redundant static components. After that the processed CSI data is transformed into images using the relative position matrix method. Finally, knowledge distillation is employed to migrate knowledge from a teacher model to a student model, reducing the number of model parameters. Experiments conducted on the proposed method showed that it can achieve a recognition accuracy of 94.2% for hand gesture detection, which meets the requirement for gesture recognition in the mining industry.},
  archive      = {J_IJPRAI},
  author       = {Lei Zhang and Xiao Liang and Jiawei Shan and Lingbo Ran and Yonghong Zhu},
  doi          = {10.1142/S0218001423560128},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2356012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {WiFi-based lightweight gesture recognition for coal miners},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Research on visual recognition and localization methods for
different feature parts. <em>IJPRAI</em>, <em>37</em>(16), 2355015. (<a
href="https://doi.org/10.1142/S0218001423550157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aimed at the problems of complex industrial site environment, difficult identification of assembly features and low positioning accuracy, a new visual identification and positioning method is proposed, which can well identify and locate parts and products with different characteristics. First, combined filtering is used in preprocessing to repair low-quality images. Then, edge detection and contour finding are performed on the preprocessed image. Finally, the internal and external parameters of the camera are calculated through the camera calibration, and the acquired pixel coordinates are converted into world coordinates. The results show that the combined filtering algorithm has good noise reduction effect and can remove image surface noise, which improves the recognition accuracy for the identification and positioning of different feature parts by the subsequent contour search method, and the algorithm can meet the requirements of the actual positioning accuracy of the assembly.},
  archive      = {J_IJPRAI},
  author       = {Zhikai Zhou and Wenxian Tang and Sheng Guo},
  doi          = {10.1142/S0218001423550157},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2355015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Research on visual recognition and localization methods for different feature parts},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). OIPNet: Multimodal network with orthogonal information
processing for semantic segmentation in indoor scenes. <em>IJPRAI</em>,
<em>37</em>(16), 2354027. (<a
href="https://doi.org/10.1142/S0218001423540277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation in indoor environments is a crucial task for artificial intelligence-driven visual robotics, enabling pixel-level classification results to facilitate robot path planning. Inspired by the success of multimodal models, we propose an end-to-end multimodal semantic segmentation model for image segmentation tasks in indoor scenes, which we call OIPNet. We design the OIP module to enhance the network’s ability to extract global information and enable information interaction in different directions. We have validated on NYUv2 and Sun RGB-D datasets, and the experiments show the generality and effectiveness of the proposed model. Our code is available at https://github.com/Mantee0810/OIP.},
  archive      = {J_IJPRAI},
  author       = {Mengting Ye and Kaili Yu and Zhenxue Chen and Yixin Guo and Longcheng Liu},
  doi          = {10.1142/S0218001423540277},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2354027},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {OIPNet: Multimodal network with orthogonal information processing for semantic segmentation in indoor scenes},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Image steganography using optimized twin attention-based
convolutional capsule network. <em>IJPRAI</em>, <em>37</em>(16),
2354026. (<a href="https://doi.org/10.1142/S0218001423540265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The secret information hiding inside the cover image is termed image steganography, in which the secret information may be either in visual or text format. The concealment of secret information inside the cover image is devised by converting the information into the standard form using conventional image steganography. Here, the cover image is usually systematically altered to carry the secret binary bits after the translation of secret data into binary bits. The cover image may get distorted due to overload, making the hidden information obvious. As a result, the conventional image steganography approaches have a limited ability to conceal. Hence, this research introduces a novel image steganography using the optimized deep learning technique. For novel image steganography, an improved archerfish hunting optimization-based twin attention convolution capsule network (ImAho-TACCNet) is introduced for image steganography. Here, the proposed ImAho is utilized for modifying the tunable parameters of the TACCNet to enhance the efficiency of the image steganography process in terms of minimum mean square error (MSE) and maximal peak signal-to-noise ratio (PSNR). Besides, secret information compression and recursive encryption techniques further enhance the security of secret information. The analysis of ImAho-TACCNet based on various assessment measures like PSNR, SSIM and MSE accomplished enhanced outcomes with the values of 62.37, 0.9923, and 0.0165 for the hidden network model and 64.23, 0.9989, and 0.0125 for the extraction network model.},
  archive      = {J_IJPRAI},
  author       = {Sachin Allwadhi and Kamaldeep Joshi and Ashok Kumar Yadav and Rainu Nandal and Prince Allawadhi and Gargi Khurana and Deepika Kumari},
  doi          = {10.1142/S0218001423540265},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2354026},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Image steganography using optimized twin attention-based convolutional capsule network},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient and scalable RFID anti-collision algorithm on
optimal partition and collided block bit-mapping. <em>IJPRAI</em>,
<em>37</em>(16), 2351020. (<a
href="https://doi.org/10.1142/S0218001423510205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In RFID systems, many anti-collision algorithms, driven by the concept of rescheduling the response sequence between the reader and unidentified tags, have been put forward to solve tag collision problem, including ALOHA-based, tree-based and hybrid algorithms. In this paper, we propose a novel RFID anti-collision algorithm called EAQ-CBB, which adopts three main approaches: tag population estimation based on collided bit detection method, optimal partitions and trimmed query tree based on the strategy of collided block bit-mapping (QTCBB). The relatively accurate estimation of tag backlog and optimal partition ensure a great reduction of collisions in the initial phase. For each collided partition, a QTCBB process is introduced immediately, which eliminates all the empty slots and significantly reduces the collided slots. Simulation results show that EAQ-CBB performs good stability and scalability when the key parameters change. Compared with the existing algorithms, such as DFSA, QTI, T-GDFSA and CT, EAQ-CBB outperforms the others with high system throughput, low normalized latency and low normalized overhead at a low cost of energy, which makes it easier to be used widely in the efficient-aware and energy-aware applications.},
  archive      = {J_IJPRAI},
  author       = {Jian Yang and Yonghua Wang and Shuting Cai},
  doi          = {10.1142/S0218001423510205},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2351020},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An efficient and scalable RFID anti-collision algorithm on optimal partition and collided block bit-mapping},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Kernel-induced matriarch path tracking elephant herding
optimization technique for identification and classification of cancer
types using support vector machines. <em>IJPRAI</em>, <em>37</em>(16),
2350034. (<a href="https://doi.org/10.1142/S0218001423500349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abnormal cells in the human body that keep on mutating are termed to be cancer in medical terms. There are multiple types of cancer identified in human beings. It is very much essential to identify and classify the type of cancer in its earlier stage. This objective can be satisfied by artificial intelligence which has a subfield of machine learning to create a generalized model that could identify and classify cancer with increased performance. To perform the identification and classification of various cancer types, in this paper, two techniques are adopted. The optimized feature set computation was done using the Kernel-Induced Matriarch path tracking Elephant Herding Optimization (KIM-EHO) and the classification for the given samples was done using the Support Vector Machines (SVM). The proposed techniques are implemented with the benchmark datasets and the results proved that the proposed methodologies outperformed the existing methods in terms of accuracy, specificity, sensitivity and time complexity.},
  archive      = {J_IJPRAI},
  author       = {L. Senbagamalar and S. Logeswari},
  doi          = {10.1142/S0218001423500349},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2350034},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Kernel-induced matriarch path tracking elephant herding optimization technique for identification and classification of cancer types using support vector machines},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GCNet: Ground collapse prediction based on the
ground-penetrating radar and deep learning technique. <em>IJPRAI</em>,
<em>37</em>(16), 2350032. (<a
href="https://doi.org/10.1142/S0218001423500325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manual methods to detect and identify potential ground collapse hazards have a high volume of workload and rely on manual skills and experience strongly, with substantial inconsistencies. This paper proposes an automatic recognition method of potential underground hazards and designs an object detection-based algorithm to predict the hidden danger of ground collapse, called GCNet. The GCNet is a ground collapse hazard detection network, which is developed to detect underground hazards, including cavities, poor soil quality, pipelines, and soil background. The GCNet uses the deep residual network ResNet101 and feature pyramid network (FPN) to extract features and a task coordination network (TCN) to identify the category and location of hidden underground hazards. Further, a feature enhancement method based on the regional binary pattern is proposed to improve the accuracy of the proposed model by expanding the ground-penetrating radar (GPR) data by adding multi-level features to GPR images. The experiments are conducted on a large amount of real GPR data and experiment results show that the proposed automatic recognition method can surpass the existing deep learning-based methods in hidden underground hazard recognition and identification.},
  archive      = {J_IJPRAI},
  author       = {Wei Yao and Xu Zhou and Guanghua Tan and Shenghong Yang and Kenli Li},
  doi          = {10.1142/S0218001423500325},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2350032},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {GCNet: Ground collapse prediction based on the ground-penetrating radar and deep learning technique},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep multi-layer neural network with variable-depth output.
<em>IJPRAI</em>, <em>37</em>(15), 2359022. (<a
href="https://doi.org/10.1142/S021800142359022X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a deep multi-layer neural network (DMLNN) with variable-depth output (VDO), called VDO-DMLNN, is proposed for classification. Unlike the traditional DMLNN, for which a user must define the network architecture in advance, VDO-DMLNN is produced from the top–down, layer by layer, until the classification error rate of VDO-DMLNN no longer decreases. The user thus does not need to define the depth of VDO-DMLNN in advance. The combination of the genetic algorithm (GA) and the self-organizing feature map (SOFM), called GA–SOFM, is proposed to automatically generate the weights and proper number of nodes for each layer in VDO-DMLNN. In addition, the output nodes can be at different levels in VDO-DMLNN rather than all being at the last layer, as in the traditional DMLNN. Thus, the average of computing time required for the recognition of an input sample in VDO-DMLNN is less than that in traditional DMLNN when they have the same classification error rate. Finally, VDO-DMLNN is compared with some state-of-the-art neural networks in the experiments.},
  archive      = {J_IJPRAI},
  author       = {Shiueng-Bien Yang and Ting-Wen Liang},
  doi          = {10.1142/S021800142359022X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2359022},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Deep multi-layer neural network with variable-depth output},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A refined combined grid model for characterizing concealed
microcracks with various geometric shapes based on radar signal
processing. <em>IJPRAI</em>, <em>37</em>(15), 2358004. (<a
href="https://doi.org/10.1142/S0218001423580041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concealed microcracks in shield tunnel lining present the characteristics of being of small size, unknown shape, and are difficult to detect. Based on the finite-difference time domain (FDTD) approach, this study proposed a new construction method of a refined grid accommodating and combining the variable shapes of microcracks, and capable of designing cross type, mesh type, and wave type microcrack models. The proposed new method also configured steel bars in the models to simulate actual engineering conditions, and characteristic response images of the models under different working conditions were obtained using ground penetrating radar (GPR) technology, which were then compared and analyzed to identify the imaging characteristics and differences of microcracks with variable geometric shapes. The waveform, amplitude, and time span of the characteristic single channel signal were furthermore studied. The results showed that the new method could successfully simulate the GPR characteristic response images of 0.5 mm microcracks of diverse geometric shapes. When the microcracks were wavy, their real shape could only be determined after signal pre-processing; the density and quantity of steel bars directly affected the appearance of microcrack characteristic signals; the greater the density and quantity of steel bars, the greater the interference on the waveform, amplitude, and time-frequency range of electromagnetic wave signals; a special correlation existed between the maximum mean root square value of the amplitude and the single channel signal of the cracks. Moreover, the finding that the extension in time and distance in the GPR time distance profile intersected with the cracks was deemed potentially to provide fresh insights into identifying the characteristic points of the cracks in the GPR images. The new method proposed in this study successfully obtained the GPR numerical simulation images and characteristic signals of microcracks with variable geometric shapes. Through the processing and analysis of the characteristic response signals of microcracks, the conclusions obtained were considered to provide an interpretation basis for the detection of microcracks in practical engineering.},
  archive      = {J_IJPRAI},
  author       = {Fei Hua and Tonghua Ling and Wenchao He and Xianjun Liu},
  doi          = {10.1142/S0218001423580041},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2358004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A refined combined grid model for characterizing concealed microcracks with various geometric shapes based on radar signal processing},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Research on lightweight network segmentation of lung
parenchyma CT image based on FPGA platform. <em>IJPRAI</em>,
<em>37</em>(15), 2357018. (<a
href="https://doi.org/10.1142/S0218001423570185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation algorithms for medical embedded vision devices usually require a light and low latency model. In this study, a novel lightweight DepthWise U-shape network (DWU-net) is proposed to address this issue, which implements the task of lung parenchyma image segmentation. In the contracting path and expanding path of segmentation network, we introduce a separable convolution unit to replace standard convolution for image feature extraction, which can learn the unique features of each layer of the image from multiple perspectives, and has more advantages in feature expression. Our algorithm has better flexibility, comparing to the original model, the model parameters’ number has been greatly reduced and the time efficiency is fully improved. The proposed architecture achieves good performance in FPGA implementation.},
  archive      = {J_IJPRAI},
  author       = {Yumin Dou and Xuezhuan Zhao},
  doi          = {10.1142/S0218001423570185},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2357018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Research on lightweight network segmentation of lung parenchyma CT image based on FPGA platform},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid d-OCapNet: Automated multi-class alzheimer’s disease
classification in brain MRI using hybrid dense optimal capsule network.
<em>IJPRAI</em>, <em>37</em>(15), 2356025. (<a
href="https://doi.org/10.1142/S0218001423560256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient detection of Alzheimer’s disease (AD) is challenging in medical image processing. Different methodologies are proposed for detecting AD at earlier stages, but certain demerits emerge, like less robust, less convergent, time-consuming, and lead over maximized losses. Hence the proposed research paper develops an efficient and automated deep learning-based AD detection using MRI image data. The initial step in AD classification is data acquisition which focuses on collecting brain MRI images from Alzheimer’s disease Neuroimaging Initiative (ADNI) Extracted Axial dataset and OASIS dataset. The gathered data are pre-processed through an Improved Median Filter (IMF), normalization is performed using the [0, 1] rescaling method, and skull stripping is done using Morphological Thresholding (MoT). The pre-processed images are fed into Multiview Fuzzy Clustering (MvFC) algorithm to segment the brain tissues as Gray Matter (GM), Cerebrospinal Fluid (CSF) and White Matter (WM) effectively. The process of Deep Feature Extraction, Multi-class Classification and loss optimization is performed using the Hybrid Dense Optimal Capsule Network (Hybrid D-OCapNet). The loss evaluated in the proposed Hybrid D-OCapNet model is optimized using the Modified Bald Eagle Search (M-BES) optimization algorithm. The simulation outcomes of training, testing and validation in AD classification are analyzed using MATLAB. The overall accuracy in classifying AD is 99.32%, sensitivity is 98.42%, specificity is 98.90%, precision is 98.93%, and F1 score is 98.44 for the ADNI dataset. The accuracy of 98.97%, the sensitivity of 98.31% and the F1 score of 98.39% are obtained for the OASIS dataset.},
  archive      = {J_IJPRAI},
  author       = {A. V. Nisha and M. Pallikonda Rajasekaran and R. Kottaimalai and G. Vishnuvarthanan and T. Arunprasath and V. Muneeswaran},
  doi          = {10.1142/S0218001423560256},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2356025},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Hybrid D-OCapNet: Automated multi-class alzheimer’s disease classification in brain MRI using hybrid dense optimal capsule network},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evolutionary gravitational neocognitron neural network-based
blood flow velocity prediction using multi-exposure laser speckle
contrast imaging. <em>IJPRAI</em>, <em>37</em>(15), 2356023. (<a
href="https://doi.org/10.1142/S0218001423560232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wide-field and noncontact imaging technique called laser speckle contrast imaging (LSCI) is utilized to map blood flow. To greatly improve prediction accuracy, the block-matching along 3-dimensional transform domain collaborative filtering-dependent denoising technique is developed. To implement real-time denoising, the processing time makes complexity. Due to the existence of considerable noise and artifacts, this is challenging to achieve the acceptable level with less raw speckle images. Notwithstanding, it acts poorly while learning from the original LSCI speckle contrast images because of the uneven noise distribution. To overcome this issue, an evolutionary gravitational neocognitron neural network-based blood flow velocity prediction using multiple exposure laser speckle contrast imaging (EGNNN-BFVP-MeLSCI) is proposed. Initially, the input MeLSCI datasets are collected from real-time dataset. The input picture is enhanced and noise is removed using pre-processing technique called altered phase preserving dynamic range compression (APPDRC). Gray level co-occurrence matrix (GLCM) window adaptive approach-dependent feature extraction approach is used for the preprocessed pictures. Using GLCM window adaptive method, the picture characteristics, such as intensity information, images derivative, geodesic information, contrasts, energy, correlations, homogeneity, and entropy, are retrieved. Then, the extracted features are transferred into the EGNNN classifier for accurately predicting the blood flow velocity. The performance of proposed method is executed at python and evaluated under certain performance metrics, such as accuracy, precision, sensitivity, specificity, F -measure, ROC, computation time, mean squared error, root mean squared error, predicted velocity. The proposed EGNNN-BFVP-MeLSCI method attains higher accuracy of 96.31%, 97.06%, and 93.52%, lower computational time of 97.22%, 91.39%, 96.41% compared with existing approaches, like DnCNN-BFVP-MeLSCI, CFD-BFVP-MeLSCI, DLS-BFVP-MeLSCI, CNN-BFVP-MeLSCI, DBN-BFVP-MeLSCI, CGAN-BFVP-MeLSCI and MVN-BFVP-MeLSCI, respectively.},
  archive      = {J_IJPRAI},
  author       = {Pankaj Jain and Saurabh Gupta},
  doi          = {10.1142/S0218001423560232},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2356023},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Evolutionary gravitational neocognitron neural network-based blood flow velocity prediction using multi-exposure laser speckle contrast imaging},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analysis and improvement of channel equalization for
underwater acoustic communication based on variational mode
decomposition and CNN-BiLSTM. <em>IJPRAI</em>, <em>37</em>(15), 2354028.
(<a href="https://doi.org/10.1142/S0218001423540289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks, including conventional neural networks (CNNs) and long- and short-term memory (LSTM) networks, have gained considerable attention in recent years due to their remarkable ability to recognize signals, which make them an ideal option for communication applications in aquatic environments. Despite the promising results achieved through the integration of various algorithms and CNN-LSTM networks, the utilization of these networks necessitates a significant amount of data for training which results in increased complexity of recognition systems. Therefore, it is crucial to explore new solutions that can mitigate these issues while also enhancing the overall performance of underwater acoustic communication systems. Therefore, this paper proposes a VCB framework that integrates the variational modal decomposition (VMD) algorithm, CNN and Bidirectional LSTM (BiLSTM) networks. This framework employs the VMD algorithm to extract energy characteristics from signals that are modulated by filter bank multi-carrier (FBMC) technologies. One-dimensional convolution (Conv1D) is then employed to extract the abstract features, which are subsequently fed into LSTM for time correlation analysis, from the energy values at each time step. Experimental results indicate that the neural network framework utilized in this study significantly diminishes data volume and enhances the recognition rate of FBMC signals, resulting in a lower bit error rate (BER).},
  archive      = {J_IJPRAI},
  author       = {Yuanjie Jiang and Xuefeng Xing},
  doi          = {10.1142/S0218001423540289},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2354028},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Analysis and improvement of channel equalization for underwater acoustic communication based on variational mode decomposition and CNN-BiLSTM},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BIM-based building performance simulation analysis: A
multi-parameter-driven approach to building energy efficiency and carbon
reduction. <em>IJPRAI</em>, <em>37</em>(15), 2354019. (<a
href="https://doi.org/10.1142/S0218001423540198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global warming and other environmental problems are increasing the demand for high-performance buildings. The development of high-performance computers and building information models has a significant impact on buildings’ energy simulation. High-performance building design needs to comprehensively consider geography, climate, material, cost and other factors which is a highly complex multidisciplinary research problem. Therefore, it is urgent to use advanced modeling and simulation technology to realize it, involving Building Information Modelling (BIM), parametric design and cloud platform. Comprehensive simulation of building performance refers to a multidisciplinary collaborative design, and the correlation between research objects and parameters should be achieved by complex programming design. This study integrates BIM, computer, cloud computing and other technologies to simulate BIM-based building energy consumption performance. Based on project information, geometry information and physical properties exhibited by materials stored in BIM model, the energy analysis model is created. Revit–Dynamo API functions are employed to generate a novel BIM model in Revit after automatically changing and transferring user-defined parameters. BIM energy consumption model is converted into Green Building eXtended Markup Language (GBXML) file and uploaded to Green Building Studio (GBS) cloud server. The optimal project solution is yielded by retrieving the energy consumption simulation results of BIM models with a range of parameters. The case study shows that building volume, glass material, window-wall ratio and window height have significant influence on energy consumption targets of buildings. In hot-summer and cold-winter areas, the total energy consumption of glass materials with high insulation and reflection coefficient is small. The window size slightly impacts the annual lighting energy consumption, but it has significant influence on the annual air conditioning energy consumption, with a maximum increase of about 22%. Finally, the application advantages and limitations of the framework in high-performance building design and its application prospects in energy-saving building design are discussed.},
  archive      = {J_IJPRAI},
  author       = {Wu Sun and Liang Zhao},
  doi          = {10.1142/S0218001423540198},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2354019},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {BIM-based building performance simulation analysis: A multi-parameter-driven approach to building energy efficiency and carbon reduction},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised network distillation for exploration.
<em>IJPRAI</em>, <em>37</em>(15), 2351021. (<a
href="https://doi.org/10.1142/S0218001423510217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning is currently applicable across a range of domains, including robotics, gaming, and natural language processing. However, the approach faces difficulties in environments with sparse rewards. Random network distillation (RND) is a good intrinsic reward solution to this problem. Nevertheless, the RND method’s effectiveness hinges on excellent initialization, and the reliance on random features somewhat constrains the agent’s exploration capabilities. This paper proposes a self-supervised network distillation (SSND) exploration method, addressing the drawbacks of RND’s reliance on initializing random networks while enhancing the agent’s exploration capability in sparse reward environments. The method uses distillation error as intrinsic rewards, with the target network trained using self-supervised learning. During the training of the predictor network, we noticed fluctuations in both loss values and intrinsic rewards, which have a detrimental impact on the performance of the intelligent agent. To resolve this issue, we introduce batch normalization layers to the target network, which helps mitigate intrinsic reward anomalies stemming from the target network’s instability. Experiments show that the self-supervised network distillation is better than RND in terms of exploration speed and performance.},
  archive      = {J_IJPRAI},
  author       = {Xu Zhang and Ruiyu Dai and Weisi Chen and Jiguang Qiu},
  doi          = {10.1142/S0218001423510217},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2351021},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Self-supervised network distillation for exploration},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weighted two-hidden-layer extreme learning machine method
with improved gray wolf optimization for complex data classification.
<em>IJPRAI</em>, <em>37</em>(15), 2351018. (<a
href="https://doi.org/10.1142/S0218001423510187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extreme Learning Machine (ELM) is widely popular for its advantages such as fast training speed and good generalization performance. However, the randomness of hidden layer parameters in ELM leads to unstable prediction performance of the model. We propose a novel two-hidden-layer extreme learning machine (TELM) for complex data classification. Firstly, the idea of weighting is introduced into TELM, and a weighted two-hidden-layer extreme learning machine (WTELM) model is proposed to improve the classification accuracy of the model. Secondly, the convergence factor and position update formula in gray wolf optimization algorithm (GWO) are adjusted to enhance the optimization algorithm’s ability to search for optimal parameters. Finally, an improved gray wolf optimization (IGWO) is utilized to search for the optimal parameters of the WTELM model. The impact of different intelligent optimization algorithms on the model’s classification results is compared. The experimental results demonstrate that the classification accuracy of the WTELM model has been improved by about 11–18% compared to traditional ELM models. Moreover, compared to the WTELM model, the classification accuracy of the IGWO-WTELM model has improved by about 1–19%. This indicates that the method proposed in this paper is significantly superior to traditional ELM methods and their variants, improving the stability, training speed and classification accuracy of the model.},
  archive      = {J_IJPRAI},
  author       = {Xiwen Qin and Liping Yuan and Yonghua Ma and Xiaogang Dong and Siqi Zhang},
  doi          = {10.1142/S0218001423510187},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2351018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Weighted two-hidden-layer extreme learning machine method with improved gray wolf optimization for complex data classification},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adversarial detection from derived models. <em>IJPRAI</em>,
<em>37</em>(15), 2350031. (<a
href="https://doi.org/10.1142/S0218001423500313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) can be easily fooled by inputs that are crafted by adversaries. For example, an adversarial image can be forged by adding to an image a tiny perturbation which is often unnoticeable by human eyes, though the semantic interpretations of the original image and the adversarial image, which are represented as outputs of a DNN, may be drastically different. This weakness can potentially lead to serious consequences in security-critical applications such as medical diagnostic tests and self-driving vehicles. Most existing approaches for adversarial detection only have satisfactory performance for specific types of attacks. These methods do not generalize their performances when applied to a broad range of attacks, models or datasets. In this work, we propose a new adversarial detection method called Adversarial Detection from Derived Models (ADDM), which applies derived models to “simulate” the functionality of a DNN, and analyzes the distribution for the neuron activation values in the derived models as indicators for adversarial inputs. In order to further enhance performance, we propose a heuristic that selects neurons from the derived models that are sensitive to perturbations. We compare our approach with six existing adversarial detection approaches of different methodologies, and the experimental result confirms that the proposed approach has generally better performance regarding stability over different types of adversarial attacks on a variety of tested DNN models and datasets.},
  archive      = {J_IJPRAI},
  author       = {Fangzhen Zhao and Chenyi Zhang and Naipeng Dong and Ming Li},
  doi          = {10.1142/S0218001423500313},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2350031},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Adversarial detection from derived models},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A robust kernel least mean square algorithm and its
quantization. <em>IJPRAI</em>, <em>37</em>(14), 2359020. (<a
href="https://doi.org/10.1142/S0218001423590206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To further improve the performance of the kernel adaptive filtering algorithm in a non-Gaussian environment, a robust kernel least mean square algorithm is proposed, and the effectiveness of the root cost function and the convergence of the algorithm is theoretically analyzed. An improved online vector quantization criterion is then applied to the proposed algorithm to suppress the linearly growing network size. Finally, the different performances of the algorithm of this paper and other kernel adaptive filtering algorithms as well as this paper’s algorithm before and after quantization are compared in Mackey Glass chaotic time series as well as in system identification, confirming the superiority of the algorithm of this paper and the improved online vector quantization criterion.},
  archive      = {J_IJPRAI},
  author       = {Yuan-Lian Huo and Jie Liu and Yong-Feng Qi and Zhi-Ling Hu and Kuo-Jian Yang},
  doi          = {10.1142/S0218001423590206},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2359020},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A robust kernel least mean square algorithm and its quantization},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A lightweight multimodal footprint recognition network based
on progressive multi-granularity feature fusion. <em>IJPRAI</em>,
<em>37</em>(14), 2357012. (<a
href="https://doi.org/10.1142/S0218001423570124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main differences in images of footprints are the proportion of the parts of foot and the distribution of pressure, which can be considered as fine-grained image classification. Moreover, the deviation of human body weight and muscle strength increases the difficulty of identifying the left and right feet. While using a fine-grained image classification network to solve the footprint image classification problem is certainly a feasible approach, the number of parameters in a fine-grained image classification network is generally large, and therefore we would like to build a lightweight classification network that is suitable for several small footprint datasets. In this paper, a multimodal footprint recognition algorithm based on progressive multi-granularity feature fusion is proposed. First, the shallow dense connection network is used to extract features. The feature extraction ability of the model is improved with the help of channel splicing and feature multiplexing. Second, to learn footprint images of different granularities, the progressive training strategy and puzzle scrambler are applied to the model. Finally, factorized bilinear coding can aggregate local features to obtain more discriminative global representation features. Experiments show that our network achieves comparable classification accuracy to some fine-grained image classification models (PMG, MSEC) on the complete pressure footprint dataset, but the number of parameters in our network is greatly reduced. Meanwhile, our network also achieves good classification results on several other footprint datasets, which demonstrates the effectiveness of our network. At the same time, an ablation experiment was carried out to verify the effectiveness of the progressive strategy and the factorized bilinear coding.},
  archive      = {J_IJPRAI},
  author       = {Ruike Cao and Luowei Li and Yan Zhang and Jun Wu and Xinyu Zhao},
  doi          = {10.1142/S0218001423570124},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2357012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A lightweight multimodal footprint recognition network based on progressive multi-granularity feature fusion},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cancer prediction using feature fusion and taylor-TSA-based
GAN with gene expression data. <em>IJPRAI</em>, <em>37</em>(14),
2357008. (<a href="https://doi.org/10.1142/S0218001423570082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research paper develops an efficient model, named Taylor-Tunicate Swarm Algorithm-based Generative Adversarial Networks (Taylor-TSA-based GANs) for cancer prediction. The developed Taylor-TSA incorporates the Taylor series with Tunicate Swarm Algorithm (TSA) algorithm. The Yeo–Johnson (YJ) transformation is employed for the data transformation. The feature fusion is evaluated by Deep Stacked Autoencoder (Deep SAE). The fused feature is given as input to the cancer prediction done by GAN trained by Taylor-TSA. The developed model is an effective and efficient use of information with clinical data. The Taylor-TSA-based GAN is analyzed in terms of accuracy, False Positive Rate (FPR), and True Positive Rate (TPR) with the values of 0.9184, 0.1782, and 0.9246.},
  archive      = {J_IJPRAI},
  author       = {J. Jeyabharathi and S. Velliangiri and S. Iwin Thanakumar Joseph and C. Sorna Chandra Devadass},
  doi          = {10.1142/S0218001423570082},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2357008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Cancer prediction using feature fusion and taylor-TSA-based GAN with gene expression data},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A convolutional neural network based on soft attention
mechanism and multi-scale fusion for skin cancer classification.
<em>IJPRAI</em>, <em>37</em>(14), 2356024. (<a
href="https://doi.org/10.1142/S0218001423560244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The seven most common skin diseases are melanocytic nevus, melanoma, benign keratosis, basal cell carcinoma, actinic keratosis, vascular lesions, and dermatofibroma. Among them, melanoma has been identified as one of the deadliest cancers based on medical studies and research. The current trend in disease detection revolves around the use of machine learning and deep learning models. Regardless of the model used, the crucial aspect is achieving accurate classification for these diseases. With the emergence of powerful convolutional neural networks (CNNs), significant progress has been made in classification of skin cancer lesions in recent years. However, various challenges hinder the development of practical and effective solutions. First, due to the specific nature of skin cancer lesion images, the current deep neural network architectures and training strategies have poor adaptability to medical images. They are also prone to gradient vanishing issues during network iteration, which hinders the construction of high-performance deep learning models that leverage distinctive characteristics of skin lesion images. Second, there exists a discordance between skin lesion images and deep learning network structures. To address these issues, this study introduces a soft attention mechanism to enhance adaptability to skin cancer lesion images and improve the extraction of informative features from medical images. Additionally, a novel multi-scale fusion convolutional neural network model is proposed to overcome the mismatch between deep learning CNN architectures and skin lesion images. This model autonomously extracts appearance features from raw dermatological medical images. Comparisons with other popular techniques demonstrate the effectiveness of the proposed model, which can achieve an accuracy of 93.9% on HAM10000 dataset. There is ongoing research to overcome the remaining challenges and further enhance the performance of skin cancer classification algorithms.},
  archive      = {J_IJPRAI},
  author       = {Qiwei Bao and Hua Han and Li Huang and A. A. M. Muzahid},
  doi          = {10.1142/S0218001423560244},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2356024},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A convolutional neural network based on soft attention mechanism and multi-scale fusion for skin cancer classification},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 3D surface reconstruction based on dynamic graph
convolutional occupancy network. <em>IJPRAI</em>, <em>37</em>(14),
2354022. (<a href="https://doi.org/10.1142/S0218001423540228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A 3D reconstruction method based on dynamic graph convolutional occupancy networks is proposed to address the issues of texture information loss, geometric information loss after voxelization, and lack of object completeness constraints in the process of 3D reconstruction using voxel representation in a block-wise manner. By constructing a dynamic graph structure for feature extraction, the method aims at restore 3D models with fewer holes and local details. In the feature extraction stage, local pooling is employed within each point cloud block to address the problem of nonsignificant texture feature loss. To tackle the issues of geometric constraint loss and insufficient scene semantic information caused by block-wise processing, a feature fusion method between adjacent blocks is proposed to learn richer scene semantic information and long-range dependencies between points. By learning features within and between blocks, each point retains as much geometric information as possible, mitigating the problem of geometric information loss due to voxelization. During the surface generation, interpolation is used to infer the occupancy value for each point, and the Marching Cubes algorithm is employed for three-dimensional surface reconstruction. Experimental validation on object-level (ShapeNet dataset) and scene-level (Synthetic Rooms dataset, MatterPort3D dataset for real-world scenes) datasets demonstrates the effectiveness and advancement of the proposed method.},
  archive      = {J_IJPRAI},
  author       = {Yaoyu Jiang and Lijuan Song},
  doi          = {10.1142/S0218001423540228},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2354022},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {3D surface reconstruction based on dynamic graph convolutional occupancy network},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A CNN-SVM study based on the fusion of spectrogram and
thermal imaging heterogeneous features for pig cough recognition in
field situation. <em>IJPRAI</em>, <em>37</em>(14), 2354021. (<a
href="https://doi.org/10.1142/S0218001423540216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification of pig cough is essential for comprehensive monitoring and diagnosis of the respiratory health status of pigs. It contributes to stress-free animal health management, reduces pig mortality and improves the economics of farming. Creating a representative multisource signal signature of pig cough is a critical step in achieving automatic recognition of pig cough. For this reason, in this paper, we propose a feature fusion classification method that combines the spectrogram deep features and thermal image deep features to be fed into a support vector machine (SVM) classifier to accomplish cough classification. First, we use a time–frequency transformation algorithm to convert a one-dimensional cough sound signal into a two-dimensional acoustic spectrogram. Then, the corresponding heterogeneous deep features are extracted from the cough spectrogram and thermal image by fine-tuning Lenet-5 and a customized CoughRNet shallow convolutional neural network. Finally, we employ an early fusion technique to align and splice the extracted heterogeneous deep features and feed them into an SVM for the automatic classification task of pig cough. Our study evaluates the classification performance, recognition speed and model size of the proposed deep feature fusion classification network with satisfactory results. Experimental results show that the method achieves 99.77% accuracy in pig cough recognition. This further demonstrates the effectiveness of combining abstract heterogeneous sound and thermal image deep features as a method for automated detection of pig respiratory health.},
  archive      = {J_IJPRAI},
  author       = {Buyu Wang and Weijun Duan and Na Liu and Jingwei Qi},
  doi          = {10.1142/S0218001423540216},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2354021},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A CNN-SVM study based on the fusion of spectrogram and thermal imaging heterogeneous features for pig cough recognition in field situation},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph convolutional neural network with multi-scale
attention mechanism for EEG-based motion imagery classification.
<em>IJPRAI</em>, <em>37</em>(14), 2354020. (<a
href="https://doi.org/10.1142/S0218001423540204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep learning has been widely used in the classification of EEG signals and achieved satisfactory results. However, the correlation between EEG electrodes is rarely considered, which has been proved that there are indeed connections between different brain regions. After considering the connections between EEG electrodes, the graph convolutional neural network is applied to detect human motor intents from EEG signals, where EEG data are transformed into graph data through phase lag index, time-domain and frequency-domain features with different signal bands. Meanwhile, a multi-scale attention mechanism is proposed to the network to improve the accuracy of classification. By using the multi-scale attention-based graph convolutional neural network, the accuracy of 93.22% is achieved with 10-fold cross-validation, which is higher than the compared methods which ignore the spatial correlations of EEG signals.},
  archive      = {J_IJPRAI},
  author       = {Jun Zhu and Qingshan Liu and Chentao Xu},
  doi          = {10.1142/S0218001423540204},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2354020},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Graph convolutional neural network with multi-scale attention mechanism for EEG-based motion imagery classification},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tomato production prediction based on deep learning
algorithm-cascade-PSPNET and bayes. <em>IJPRAI</em>, <em>37</em>(14),
2352018. (<a href="https://doi.org/10.1142/S0218001423520183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accounting the problem of small sample size in tomato yield statistics, a dual-fusion prediction analysis model based on Bayes theory and deep learning algorithm Cascade-PSPNET is proposed. The tomato yield prediction is conducted based on remote sensing image time series analysis and multi-source information fusion theory with Bayesian theory and credibility weighting. First, the area of tomato planting is analyzed through semantic segmentation algorithms of remote sensing images during the tomato planting process. The yield is predicted by variables such as planting area fluctuation, disaster cycle fluctuation, etc. Through analyzing the reduced yield affected by disasters in different time periods of remote sensing images during planting process, the value chain of tomato industry is calculated by comprehensively analyzing price-value system, inflation coefficient, and unit area yield. At the same time, the annual patent application volume is used to predict the change of tomato yield year by year according to Bayesian theory, and the relationship between annual patent application volume and tomato yield year by year under different confidence levels is analyzed. The results show that it is feasible to use the Bayes method with semantic segmentation algorithms of remote sensing images to predict tomato yield. Next, the experiment of fusion prediction between two prediction models in the same target area will be carried out for verification.},
  archive      = {J_IJPRAI},
  author       = {Chenchen Qi and Weizhong Liu},
  doi          = {10.1142/S0218001423520183},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2352018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Tomato production prediction based on deep learning algorithm-cascade-PSPNET and bayes},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CA-YOLOX: Deep learning-guided road intersection location
from high-resolution remote sensing images. <em>IJPRAI</em>,
<em>37</em>(14), 2351017. (<a
href="https://doi.org/10.1142/S0218001423510175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The location of road intersection from high resolution remote sensing (HRRS) images can be automatically obtained by deep learning. This has become one of the current data sources in urban smart transportation. However, limited by the small size, diverse types, complex distribution, and missing sample labels of road intersections in actual scenarios, it is difficult to accurately represent key features of road intersection by deep neural network (DNN) model. A new coordinate attention (CA) module-YOLOX (CA-YOLOX) method for accurately locating road intersections from HRRS images is presented. First, the spatial pyramid pooling (SPP) module is introduced into the backbone convolution network between the Darknet-53’ last feature layer and feature pyramid networks (FPN) structure. Second, the CA module is embedded into the feature fusion structure in FPN to focus more on the spatial shape distribution and texture features of road intersections. Third, we use focal loss to replace the traditional binary cross entropy (BCE) loss in the confidence loss to improve the iteration speed of the CA-YOLOX network. Finally, an extensive empirical experiment on Potsdam, IKONOS datasets, and ablation study is then implemented and tested. The results show that the presented CA-YOLOX method can promote the location accuracy of road intersection from HRRS images compared to the traditional You only look once (YOLO) model.},
  archive      = {J_IJPRAI},
  author       = {Chengfan Li and Zixuan Zhang and Lan Liu and Shengnan Wang and Junjuan Zhao and Xuefeng Liu},
  doi          = {10.1142/S0218001423510175},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2351017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {CA-YOLOX: Deep learning-guided road intersection location from high-resolution remote sensing images},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Boruta feature selection method for optimizing a case-based
reasoning model to predict heart disease. <em>IJPRAI</em>,
<em>37</em>(14), 2351016. (<a
href="https://doi.org/10.1142/S0218001423510163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, heart diseases are becoming a major problem, with which a significant part of the world population is affected. The field of medicine may significantly benefit from prediction systems using artificial intelligence techniques by making the disease prediction more accurate and faster. This paper aims to improve the predictive performance of cardiac disease diagnosis through the use of the case-based reasoning (CBR) approach, specifically focusing on its two phases: retrieval and reuse. Additionally, we aim to optimize the selection of attributes in cardiac dataset by using the Boruta method. Our approach uses various models including machine learning and deep learning models, in addition to hybrid models in the retrieval phase to accurately predict the presence or absence of a cardiac disease among patients. A robust reuse measure is used to verify the validity of the retrieved solutions and determine the necessity of applying the reuse algorithm. The results showed a significant improvement in predictive precision, with the highest accuracy achieved by the hybrid 1D CNN–SVM model on cardiac datasets. The effectiveness of the suggested approach is discussed by comparing the results with different search methods.},
  archive      = {J_IJPRAI},
  author       = {Safa Gasmi and Akila Djebbar and Hayet Farida Merouani},
  doi          = {10.1142/S0218001423510163},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2351016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Boruta feature selection method for optimizing a case-based reasoning model to predict heart disease},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transparent component defect detection method based on
improved YOLOv7 algorithm. <em>IJPRAI</em>, <em>37</em>(14), 2350030.
(<a href="https://doi.org/10.1142/S0218001423500301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transparent components such as glass and fiber-reinforced plastics are widely used in engineering practice, which are prone to generate defects, and change its surface and internal structure, and cause great risks to the performance and stability of products. To solve the above problems, firstly, we studied the defect detection of transparent components, proposed an improved YOLOv7 (You Only Look Once V7) algorithm, replaced the Loss function CIoU (Complete-Intersection over Union) of the network model with Wise-IoU (Wise-Integration Over Union), and raised its convergence performance. Secondly, Global Attention Mechanism (GAM) is embedded in the backbone, and a dynamic target head frame is used in the output layer to generate the standard head frame and the attention function, improving the network’s attention to micro defects and ensuring the detection accuracy of micro defects. Thirdly, an intelligent defect detection platform was designed by combining mechanical engineering, visual perception, information processing and other technologies, and 150 rounds of comparative ablation experiments were conducted on typical transparent components. The improved algorithm has raised 2.6% in Mean Average Precision (MAP) value compared to the original algorithm. The improved model has better detection performance for micro defects and higher recognition accuracy. It can effectively screen out the location and category of defects, and eliminate defective components, which is consistent with the actual engineering situation. It satisfies the actual needs of product quality testing in the production process and provides reference experience for the industrial use of defect detection methods.},
  archive      = {J_IJPRAI},
  author       = {Qixun Xiao and Jingde Huang and Zhangyu Huang and Chenyu Li and Jie Xu},
  doi          = {10.1142/S0218001423500301},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2350030},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Transparent component defect detection method based on improved YOLOv7 algorithm},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Medical image segmentation and classification using modified
DoubleU-net and PolyNet deep neural networks. <em>IJPRAI</em>,
<em>37</em>(13), 2357013. (<a
href="https://doi.org/10.1142/S0218001423570136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of deep neural networks, medical image analysis is able to predict results in advance in early detection and diagnosis of diseases found in the human body. Several deep neural network methodologies have been implemented for a quick and efficient analysis of medical images that detect and diagnose cancerous cell growth in any part of the human body. For improving the segmentation and classification accuracy, the paper has proposed a framework comprising modified DoubleU-Net for image segmentation and PolyNet architecture for image classification. The modified DoubleU-Net is composed of two U-Net architectures, in which U-Net1 makes use of ResNet-50 as an encoder in the place of VGG-16 (existing) and Atrous Spatial Pyramid Pooling (ASPP) is replaced by Waterfall Atrous Spatial Pooling (WASP) architecture in both U-Nets to improve the semantic image segmentation. For classifying the segmented medical images as benign or malignant, PolyNet architecture is implemented in the research. The research involves experiments on the brain tumor dataset and lung cancer dataset to analyze the performance of the proposed approach. The processing of the DoubleU-Net and modified DoubleU-Net is evaluated based on precision, Recall, Intersection over Union (IoU), and Dice Score as the performance metrics. Experimental findings indicate that the modified DoubleU-Net design outperformed the existing DoubleU-Net architecture in terms of performance parameters for segmentation. The efficiency of the PolyNet classifier has been evaluated against VGG-16 and Inception-V3 classifiers, in terms of accuracy, specificity, sensitivity, error rate, and computation time as the performance metrics. From the experimental results, it has been proved that the PolyNet classifier performs better than VGG-16 and Inception-V3 with improved accuracy, specificity, sensitivity, and computation time.},
  archive      = {J_IJPRAI},
  author       = {S. Sasikumar and R. Pugalenthi and G. M. Sasikala and M. P. Rajakumar},
  doi          = {10.1142/S0218001423570136},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2357013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Medical image segmentation and classification using modified DoubleU-net and PolyNet deep neural networks},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Query preference analysis on cascade inference human–object
interaction detection transformer. <em>IJPRAI</em>, <em>37</em>(13),
2356021. (<a href="https://doi.org/10.1142/S0218001423560219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection transformers (DETR) have provided a novel solution to human–object interaction detection in a set-prediction manner, thanks to expressive learnable queries. However, few studies covered how queries implicitly affect model behaviors, which might contain clues for model improvement. Therefore, we propose two dataset-based analysis tools: score state space and query preference map. They provide data on the distribution of model predictions, which can reveal overall-level and query-level model properties. Starting with our baseline model, we find the model naturally regresses object boxes to overlap human boxes in the edge case of no-object verbs (stand, etc.), even without a related loss. We encourage this by patching the supervision with virtual objects, resulting in more stable query preference. Moreover, we show that two-stage decoders designed for cascade inference do not decouple tasks as intended. We infer this is caused by the empty instances used as negative samples, which suggests a redesign in the matching scheme. Further, we reveal how adding an oracle-query-based teacher model affects query roles with a tiny gain, indicating room for refinement. Our findings demonstrate how a simple focus on query behaviors can provide insights for improving models.},
  archive      = {J_IJPRAI},
  author       = {Weizhe Jia and Shiwei Ma},
  doi          = {10.1142/S0218001423560219},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2356021},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Query preference analysis on cascade inference Human–Object interaction detection transformer},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Few-shot person re-identification based on meta-learning
with a compression and stimulation module. <em>IJPRAI</em>,
<em>37</em>(13), 2356020. (<a
href="https://doi.org/10.1142/S0218001423560207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a few-shot pedestrian re-identification (Re-ID) model based on an improved ResNet50 with a compression and stimulation module, which is named CS-ResNet50. It combines the meta-learning framework with metric learning. This method first compresses residual network channels, then stimulates them to achieve the effect of feature weighting, ultimately making feature extraction more accurate. The research makes the model learn how to finish new tasks efficiently from its experience that it has obtained in the training process of former subtasks. In each subtask, the dataset is divided into a gallery set and a query set, where the model parameters are trained. In this way, the model can be trained efficiently and adopted to new tasks rapidly, which could solve few-shot Re-ID problems. Compared with the baseline, the proposed model improves two indicators efficiently on two Re-ID datasets and achieves better Re-ID effect in few-shot mode.},
  archive      = {J_IJPRAI},
  author       = {Jinying Cao and Hua Han and Li Huang},
  doi          = {10.1142/S0218001423560207},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2356020},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Few-shot person re-identification based on meta-learning with a compression and stimulation module},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Construction of multi-label personality trait recognition
model in chinese text based on emotional features. <em>IJPRAI</em>,
<em>37</em>(13), 2356018. (<a
href="https://doi.org/10.1142/S0218001423560189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key to improve the service effect of virtual digital human is the personality trait recognition technology of users. However, the complexity of Chinese and the sparsity of short texts limit the accuracy of personality trait recognition. Therefore, we applied emotional features to the research of personality trait recognition and constructed a deep learning model for Chinese corpus personality trait recognition to improve the accuracy of personality trait recognition. The model ( R-B e ) extracted semantic features and embedded emotional features through RoBERTa-wwm-ext Chinese pre-training model, BiLSTM neural network, and attention mechanism. Some experiments were carried out using two Chinese datasets with different scenes. The comparative experiments and ablation experiments showed that the overall effect of the personality trait recognition model ( R-B e ) is the best, and the Macro-F1 value reaches 75.3%, which is significantly better than the existing models. The results showed that emotional features can significantly improve the accuracy of multi-label personality trait classification in both Chinese daily life scenarios and online scenarios. The proposed model can integrate emotional features and Chinese semantic features to improve the accuracy of personality traits recognition. These findings support the development of personality trait recognition and the application of virtual digital human.},
  archive      = {J_IJPRAI},
  author       = {Yan Gu and Miao Wang and Liuqian Zhu and Yongjun Hu and Yutong Zou},
  doi          = {10.1142/S0218001423560189},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2356018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Construction of multi-label personality trait recognition model in chinese text based on emotional features},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Aerial gaze target recognition based on head and eye
movements. <em>IJPRAI</em>, <em>37</em>(13), 2356015. (<a
href="https://doi.org/10.1142/S0218001423560153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aerial gaze target recognition is an important step in aerial eye control interaction. In order to achieve accurate aerial gaze target recognition, the VT4LM recognition algorithm was constructed in this paper. By this algorithm, the facial images containing the eyes of the flight operators were first inputted into Vision Transformer (ViT) to extract the local features, and the head posture of the flight operators was inputted into four LSTMs to extract the global features. Then, the local and global features of the flight operators were inputted into three fully connected layers, two dropout layers and one softmax classifier. Finally, the recognition result of aerial gaze target was obtained. In this paper the effectiveness of the VT4LM recognition algorithm was verified through the identification of four aerial line-of-sight gaze targets named Head-up display, Accelerator push rod, Control lever and Rudder by four flight operators during simulated flight. The experimental results showed that the accuracy of the VT4LM algorithm for aerial gaze target recognition reached 89.29% and the Cross Entropy Loss was 1.45. Compared to the other three recognition methods, the VT4LM algorithm had the highest recognition accuracy and minimum loss. When using the VT4LM algorithm to detect four simulated flight operators staring at four aerial gaze targets, the recognition accuracy was all higher than 85.00%. It could be seen that the VT4LM algorithm had a good performance in aerial gaze target recognition.},
  archive      = {J_IJPRAI},
  author       = {Yawen Wang and Changyuan Wang and Pengxiang Xue and Yu Zhang and Guangyi Jiang and Yining Yao},
  doi          = {10.1142/S0218001423560153},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2356015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Aerial gaze target recognition based on head and eye movements},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A robust and imperceptible dark frame selection using
advanced squeezed convoluted ebola neural network-based video
watermarking scheme with all phase discrete cosine biorthogonal
transform. <em>IJPRAI</em>, <em>37</em>(13), 2355011. (<a
href="https://doi.org/10.1142/S021800142355011X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Watermarking has been developed as a beneficial approach to resolve security problems such as copyright defense, legitimate ownership, and authenticity of digital data. Grayscale or binary images and color images are the most important types of embedded watermarks in the existing video watermarking schemes, while dark frame watermarking is barely used. A new robust blind video watermarking system with an Advanced Squeezed Convoluted Ebola Neural Network (ASCENN) approach is suggested to secure copyright, reduce noise, and authenticate the authenticity of dark frames. The proposed method selects the dark frames from the extracted input video. Then the selected dark frames are embedded and extracted using Finite Ridgelet Transform (FRT), All Phase Discrete Cosine Biorthogonal Transform (APDCBT), and Singular Value Decomposition (SVD) techniques. The robustness of the introduced approach is established by evaluating it through various image watermarking techniques and evaluating its performance against geometric, nongeometric, and combinational attacks. While comparing with the other existing video watermarking approaches, the proposed method has obtained a maximum correlation coefficient of 1, and the signal-to-noise ratio of 75 dB, at minimum error rate of 0.0215, respectively.},
  archive      = {J_IJPRAI},
  author       = {Haweez Showkat and Rohun Nissa and Asifa Baba},
  doi          = {10.1142/S021800142355011X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2355011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A robust and imperceptible dark frame selection using advanced squeezed convoluted ebola neural network-based video watermarking scheme with all phase discrete cosine biorthogonal transform},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient approach of assessing quality of blurred image.
<em>IJPRAI</em>, <em>37</em>(13), 2354018. (<a
href="https://doi.org/10.1142/S0218001423540186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a method for evaluating the quality of images altered by Gaussian blur. The method is based on the observation of bokeh mode images where the region of interest (foreground) is sharp, while the remaining parts (background) are intentionally blurred to enhance the perceptual quality of the image. The blurriness of the background increases attention towards the foreground part of the image. The proposed quality metric is obtained by combining the attention factor and the sharpness of the region of interest. The accuracy, in terms of Spearman’s-rank-order correlation-coefficient (SROCC), for popular and publicly available databases such as LIVE, VCL, TID2008, CSIQ, and TID2013, is 0.963, 0.925, 0.900, 0.930, and 0.930, respectively. The proposed method achieves high and consistent Spearman’s rank-order correlation coefficient (SROCC) values compared to the majority of state-of-the-art algorithms. Furthermore, in terms of speed, the proposed method surpasses other state-of-the-art methods. The MATLAB code of the proposed metric is publicly available at https://drive.google.com/drive/folders/1SRmUp0N157Ati9l3kV13uoCxw5PhMgQn?usp=sharing .},
  archive      = {J_IJPRAI},
  author       = {Md Amir Baig and Athar A. Moinuddin and Ekram Khan and Mohammed Ghanbari},
  doi          = {10.1142/S0218001423540186},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2354018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An efficient approach of assessing quality of blurred image},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A two-stage three-dimensional attention network for
lightweight image super-resolution. <em>IJPRAI</em>, <em>37</em>(13),
2354017. (<a href="https://doi.org/10.1142/S0218001423540174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, single image super-resolution (SISR) methods using convolutional neural networks (CNN) have achieved satisfactory performance. Nevertheless, the large model scale and the slow inference speed of these methods greatly limit the application scenarios. In this paper, we propose a two-stage three-dimensional attention network (ATTNet) for lightweight image super-resolution. First, we put forward the spatial feature encoder–decoder (SFE-D) with a spatial attention mechanism. Next, the channel transposed attention module (CTAM) with a channel self-attention mechanism is designed. Both the modules are used for fine feature extraction in the low-resolution stage. Finally, the content-based pixel recombination module (CPRM) is proposed to reconstruct the detailed content with a joint attention mechanism in the high-resolution stage. According to our experimental results, significant performance in terms of the quantitative metrics and the subjective visual quality can be achieved on average compared with the state-of-the-art lightweight SISR algorithms.},
  archive      = {J_IJPRAI},
  author       = {Lei Chen and Yanjie Yang and Xu Zhuang and Jason Wang and Qin Mao and Hong Yue and Xuekai Wei and Fei Cheng and Xuemei Zong and Mingliang Zhou},
  doi          = {10.1142/S0218001423540174},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2354017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A two-stage three-dimensional attention network for lightweight image super-resolution},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new lightweight script independent scene text style
transfer network. <em>IJPRAI</em>, <em>37</em>(13), 2353003. (<a
href="https://doi.org/10.1142/S0218001423530038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene text style transfer without a language barrier is an open challenge for the video and scene text recognition community because this plays a vital role in poster, web design, augmenting character images, and editing characters to improve scene text recognition performance and usability. This work presents a new model, called Script Independent Scene Text Style Transfer Network (SISTSTNet), for extracting scene characters and transferring text style simultaneously. The SISTSTNet performs mapping in language-independent feature space for transferring style. It is designed based on a Style Parameter Network and Target Encoder Network through lightweight MobileNetv3 convolutional and residual blocks to capture the style and shape to generate target characters. Similarly, a generative model is explored through the Visual Geometry Group (VGG) network for character replacement. The SISTSTNet is flexible and works on different languages and arbitrary examples in a neat and unified fashion. The experimental results on images in various languages, namely, English, Chinese, Hindi, Russian, Japanese, Arabic, Greek, and Bengali and cross-language validation demonstrate the effectiveness of the proposed method. The performance of the method is superior compared to the state-of-the-art methods in terms of quality measures, language independence, shape-preserving, and efficiency. The code and dataset will be released to the public to support reproducibility.},
  archive      = {J_IJPRAI},
  author       = {Palaiahnakote Shivakumara and Ayush Roy and Lokesh Nandanwar and Umapada Pal and Yue Lu and Cheng-Lin Liu},
  doi          = {10.1142/S0218001423530038},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2353003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A new lightweight script independent scene text style transfer network},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vehicle trajectory completion for automatic number plate
recognition data: A temporal knowledge graph-based method.
<em>IJPRAI</em>, <em>37</em>(13), 2350029. (<a
href="https://doi.org/10.1142/S0218001423500295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle trajectories represent an essential information source in intelligent transportation systems. Prior trajectory completion models based on Automatic Number Plate Recognition (ANPR) data have typically depended on vehicle re-identification results or road network information or have employed static knowledge graphs to integrate the two information sources. However, these methods have not taken into account the implicit temporal characteristics of trajectories in ANPR data and have neglected individual vehicle preferences. To address this void, this study proposes a Temporal Knowledge Graph-based Vehicle Trajectory Completion Model (TKG-VTC). The model implementation comprises three stages: first, ANPR data are converted into a temporal trajectory knowledge graph; second, knowledge representation learning is conducted using nontemporal relations, a biased temporal regularizer and multivector embeddings to embed the knowledge on the graph; and finally, the embedded results are employed to perform link prediction for incomplete trajectories, thereby restoring vehicle trajectories in ANPR data. Through model evaluation metrics and dimensionality reduction experiments, TKG-VTC is observed to demonstrate the best performance in completing trajectories when compared to TComplEx, TNTComplEx, and TeLM. This research introduces an innovative application of employing temporal knowledge graphs for trajectory reconstruction, which eliminates dependence on vehicle re-identification and road network information in previous methodologies. This is advantageous for enhancing the performance and dependability of vehicle trajectory data in intelligent transportation systems, as well as facilitating the implementation of trajectory prediction, demand analysis, and accident warning applications.},
  archive      = {J_IJPRAI},
  author       = {Zhe Long and Jinjin Chen and Zuping Zhang},
  doi          = {10.1142/S0218001423500295},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2350029},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Vehicle trajectory completion for automatic number plate recognition data: A temporal knowledge graph-based method},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Depth edge and structure optimization-based end-to-end
self-supervised stereo matching. <em>IJPRAI</em>, <em>37</em>(13),
2350022. (<a href="https://doi.org/10.1142/S0218001423500222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the challenge of poor cross-domain generalization performance in deep learning methods for stereo matching, particularly when dealing with unseen scenes or disparity maps lacking ground-truth information. To overcome this issue, we propose a self-supervised network called SANet. The network integrates a lightweight algorithm, AANet_Edge, which is based on depth edges optimization. In SANet, we combine AANet_Edge with a novel algorithm called SDCO, which efficiently extracts depth edges using a segment structure and employs a two-layer optimization framework to generate accurate dense disparity maps. These maps are then utilized for pixel-by-pixel supervised training. Furthermore, SANet incorporates multi-scale reconstructed left maps and multi-scale edges-aware modules to learn the structural features of the input image. To evaluate the effectiveness of SANet, comprehensive experiments are conducted on two standard benchmark datasets, namely KITTI 2012 and KITTI 2015. The experimental results demonstrate that SANet produces accurate disparity maps for unseen scenes or limited images and achieves high cross-domain generalization performance.},
  archive      = {J_IJPRAI},
  author       = {Wenbang Yang and Xianjing Cheng and Yong Zhao and Ren Qian and Jianhua Li},
  doi          = {10.1142/S0218001423500222},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2350022},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Depth edge and structure optimization-based end-to-end self-supervised stereo matching},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-balancing and position control of a balancer system
using a pattern-based intelligent optimization method. <em>IJPRAI</em>,
<em>37</em>(12), 2357011. (<a
href="https://doi.org/10.1142/S0218001423570112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new Data-Driven Teaching Learning-Based Optimization (DDTLBO) method used to improve the self-balancing and position control of a two-degree of freedom ball and balancer (2DOFBB) system. DDTLBO is a modified version of teaching learning-based optimization (TLBO) method, based on the natural pattern followed by “learners” in an academic class to improve their knowledge. In this, an intelligent algorithm is used on MATLAB platform to handle the nonlinearities and un-stability of the ball and balancer system. A ball-balancer is a highly nonlinear, electromechanical, multivariable and underactuated system. A sophisticated automated intelligent control approach is used to handle these complications. In the proposed approach, the pattern followed by inclination angle of balancer plate is traced after observing the control dynamics of 2DOFBB system. Modeling of ball balancer system is accomplished with the help of proportional integral and derivative (PID) controller. Further, an intelligent data-driven computational approach is implemented, which improves the execution of TLBO optimization method. This improved optimization is used to tune the performance of proportional integral derivative controller employed on the ball balancer system. This approach addresses the major challenge of unknown disturbances on the closed loop system of the considered problem. The dominance of proposed intelligent approach is verified over other optimization techniques using benchmark CEC functions. The optimized parameters of PID controllers hence obtained are implemented on 2DOFBB system. Results obtained are validated using real-time response analysis on the MATLAB/Simulation platform, which demonstrates the dominance of DDTLBO-PID controller over traditional controllers.},
  archive      = {J_IJPRAI},
  author       = {Abhishek Chaudhary and Bharat Bhushan},
  doi          = {10.1142/S0218001423570112},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2357011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Self-balancing and position control of a balancer system using a pattern-based intelligent optimization method},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classification of retinal vascular diseases using ensemble
decision tree in thermal images. <em>IJPRAI</em>, <em>37</em>(12),
2357010. (<a href="https://doi.org/10.1142/S0218001423570100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of medicine, thermal image processing and analysis play a significant role in the diagnosis, monitoring, and treatment of diseases. For example, during the last decade, several studies have been performed based on thermal image processing for ocular disease diagnosis. This research proposes a unique approach for the classification of subgroups of two retinal vascular diseases, namely diabetic eye disease and age-related macular degeneration (AMD). The class imbalance problem is a well-known issue when working with medical data, where one class is significantly less represented than another class in the dataset. To deal with the class imbalance issue, an ensemble decision tree classifier with a random under-sampling and adaptive boosting (RUSBoost) technique is proposed. The performance of the proposed classifier is compared with various traditional machine learning-based classifiers. Experimental results show that the proposed ensemble tree outperforms other classifiers through high accuracy, F -score, and Mathews correlation coefficient (MCC) values in classifying diabetic eye diseases and AMD diseases. The proposed ensemble decision tree distinguishes dry AMD and wet AMD over healthy controls with 95% average accuracy. Also, it classifies diabetic retinopathy (DR) with diabetic macular edema (DME) and DR without DME with 94% average accuracy. The classifier could distinguish dry and wet AMD which did not work around in temperature analysis on the manual temperature measurement. The performance of the automated classification model is on par with the performance of the temperature analysis of OST for DME and DR without DME.},
  archive      = {J_IJPRAI},
  author       = {R. Madura Meenakshi and N. Padmapriya and N. Venkateswaran and Shany Shperling and Ari Leshno},
  doi          = {10.1142/S0218001423570100},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2357010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Classification of retinal vascular diseases using ensemble decision tree in thermal images},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DNA chromatogram classification using entropy-based features
and supervised dimension reduction based on global and local pattern
information. <em>IJPRAI</em>, <em>37</em>(12), 2356019. (<a
href="https://doi.org/10.1142/S0218001423560190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gene sequence classification can be seen as a challenging task due to the nonstationary, noisy and nonlinear characteristics of sequential data. The primary goal of this research is to develop a general solution approach for supervised DNA chromatogram (DNAC) classification in the absence of sufficient training data. Today, deep learning comes to the fore with its achievements, however this requires a lot of training data. Finding enough training data can be exceedingly challenging, particularly in the medical area and for rare disorders. In this paper, a novel supervised DNAC classification method is proposed, which combines three techniques to classify hepatitis virus DNA trace files as HBV and HCV. The features that are capable of reflecting the complex-structured sequential data are extracted based on both embedding and spectral entropies. After the supervised dimension reduction step, not only global behavior of the entropy features but also local behavior of the entropy features is taken into account for classification purpose. A memory-based learning, which cannot lose any information coming from training data as its nature, is being used as a classifier. Experimental results show that the proposed method achieves good results that although 19% training data is used, a performance of 92% is obtained.},
  archive      = {J_IJPRAI},
  author       = {Ersoy Öz and Öyküm Esra Yiğit and Ufuk Sakarya},
  doi          = {10.1142/S0218001423560190},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2356019},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {DNA chromatogram classification using entropy-based features and supervised dimension reduction based on global and local pattern information},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An intelligent diagnosis approach combining resampling and
CWGAN-GP of single-to-mixed faults of rolling bearings under unbalanced
small samples. <em>IJPRAI</em>, <em>37</em>(12), 2356017. (<a
href="https://doi.org/10.1142/S0218001423560177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rolling bearing is a key component with the high fault rate in the rotary machines, and its fault diagnosis is important for the safe and healthy operation of the entire machine. In recent years, the deep learning has been widely used for the mechanical fault diagnosis. However, in the process of equipment operation, its state data always presents unbalanced. Number of effective data in different states is different and usually the gap is large, which makes it difficult to directly conduct deep learning. This paper proposes a new data enhancement method combining the resampling and Conditional Wasserstein Generative Adversarial Networks-Gradient Penalty (CWGAN-GP), and uses the gray images-based Convolutional Neural Network (CNN) to realize the intelligent fault diagnosis of rolling bearings. First, the resampling is used to expand the small number of samples to a large level. Second, the conditional label in Conditional Generative Adversarial Networks (CGAN) is combined with WGAN-GP to control the generated samples. Meanwhile, the Maximum Mean Discrepancy (MMD) is used to filter the samples to obtain the high-quality expanded data set. Finally, CNN is used to train the obtained dataset and carry out the fault classification. In the experiment, a single, compound and mixed fault cases of rolling bearings are successively simulated. For each case, the different sets considering the imbalance ratio of data are constructed, respectively. The results show that the method proposed significantly improves the fault diagnosis accuracy of rolling bearings, which provides a feasible way for the intelligent diagnosis of mechanical component with the complex fault modes and unbalanced small data.},
  archive      = {J_IJPRAI},
  author       = {Hongwei fan and Jiateng Ma and Xiangang Cao and Xuhui Zhang and Qinghua Mao},
  doi          = {10.1142/S0218001423560177},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2356017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An intelligent diagnosis approach combining resampling and CWGAN-GP of single-to-mixed faults of rolling bearings under unbalanced small samples},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LHFNet: A fast and accurate object detector based on
CenterNet. <em>IJPRAI</em>, <em>37</em>(12), 2355014. (<a
href="https://doi.org/10.1142/S0218001423550145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes LHFNet, an improved object detection method based on CenterNet, which achieves a better speed-accuracy trade-off. The main contributions of this paper are as follows: We design a lightweight Hourglass network to reduce the number of parameters and computations of CenterNet, thus improving the detection speed. We introduce an intermediate feature map fusion module to enhance the feature extraction capability of Hourglass, which compensates for the possible performance degradation caused by the network simplification. We apply an attention module to the final heat map to improve the image feature representation. We design and optimize a series of loss functions to train LHFNet effectively. Through the research in this paper, we demonstrate that the feature map fusion and the attention module greatly improve the performance of LHFNet. We evaluate our method on the COCO dataset and achieve a high accuracy at a fast speed (Tesla V100), which outperforms other object detection methods in terms of both accuracy and efficiency.},
  archive      = {J_IJPRAI},
  author       = {Xianrang Shi and Yang Su and Yan Ti and Tinglun Song},
  doi          = {10.1142/S0218001423550145},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2355014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {LHFNet: A fast and accurate object detector based on CenterNet},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Constraint-based adversarial networks for unsupervised
abstract text summarization. <em>IJPRAI</em>, <em>37</em>(12), 2353002.
(<a href="https://doi.org/10.1142/S0218001423530026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract text summarization is a classic sequence-to-sequence natural language generation task. In order to improve the quality of unsupervised abstract text summarization in unsupervised mode, we propose two constraints for training text summarization model, embedding space constraint and information ratio constraint. We construct a generative adversarial network with two discriminators based on these two constraints (TC-SUM-GAN). We use unsupervised and supervised methods to train the model in the experiment. Experimental results show that the ROUGE-1 value of the unsupervised TC-SUM-GAN increases by 1 2 . 5 7 points compared with the basic model and at least 1.96 points compared with other comparative models. The ROUGE scores of the supervised TC-SUM-GAN are also improved. TC-SUM-GAN achieves very competitive results for the metrics of ROUGE-1 and ROUGE-2. In addition, the abstracts generated by our model are closer to those generated manually.},
  archive      = {J_IJPRAI},
  author       = {Liwei Jing and Lina Yang and Yujian Yuan and Zuqiang Meng and Yifeng Tan and Patrick Shen-Pei Wang and Xichun Li},
  doi          = {10.1142/S0218001423530026},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2353002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Constraint-based adversarial networks for unsupervised abstract text summarization},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhanced graph neural network with multi-task learning and
data augmentation for semi-supervised node classification.
<em>IJPRAI</em>, <em>37</em>(12), 2351008. (<a
href="https://doi.org/10.1142/S0218001423510084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have achieved impressive success in various applications. However, training dedicated GNNs for small-scale graphs still faces many problems such as over-fitting and deficiencies in performance improvements. Traditional methods such as data augmentation are commonly used in computer vision (CV) but are barely applied to graph structure data to solve these problems. In this paper, we propose a training framework named MTDA ( M ulti- T ask learning with D ata A ugmentation)-GNN, which combines data augmentation and multi-task learning to improve the node classification performance of GNN on small-scale graph data. First, we use Graph Auto-Encoders (GAE) as a link predictor, modifying the original graphs’ topological structure by promoting intra-class edges and demoting interclass edges, in this way to denoise the original graph and realize data augmentation. Then the modified graph is used as the input of the node classification model. Besides defining the node pair classification as an auxiliary task, we introduce multi-task learning during the training process, forcing the predicted labels to conform to the observed pairwise relationships and improving the model’s classification ability. In addition, we conduct an adaptive dynamic weighting strategy to distribute the weight of different tasks automatically. Experiments on benchmark data sets demonstrate that the proposed MTDA-GNN outperforms traditional GNNs in graph-based semi-supervised node classification.},
  archive      = {J_IJPRAI},
  author       = {Cheng Fan and Buhong Wang and Zhen Wang},
  doi          = {10.1142/S0218001423510084},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2351008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Enhanced graph neural network with multi-task learning and data augmentation for semi-supervised node classification},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MCA-NER: Multi-contextualized adversarial-based attentional
deep neural network for named entity recognition. <em>IJPRAI</em>,
<em>37</em>(12), 2350028. (<a
href="https://doi.org/10.1142/S0218001423500283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-contextualized representations learning is vital for named entity recognition (NER), which is a fundamental task for effectively extracting structured information from unstructured text, and forming knowledge bases. This task is particularly challenging when dealing with Chinese text given the absence of evident word boundaries. Chinese word segmentation (CWS) can be leveraged to recognize word boundaries, but named entities often encompass multiple segmented words, making it crucial to use boundary information to correctly recognize and distinguish the relationships between these words. In this paper, we propose MCA-NER, a multi-contextualized adversarial-based attentional deep learning approach for Chinese NER, which combines CWS and part-of-speech (POS) tagging information with the classic BiLSTM-CRF NER model, using adversarial multi-task learning. The model incorporates several self-attention components for adversarial and multi-task learning, effectively synthesizing task-specific and common information attribution while improving performance across all three tasks. Experimental results on the three datasets provide compelling evidence that supports the effectiveness and performance of our model.},
  archive      = {J_IJPRAI},
  author       = {Shufeng He and Peng Zhu and Yanxia Zhao and Dianqi Sun},
  doi          = {10.1142/S0218001423500283},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2350028},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {MCA-NER: Multi-contextualized adversarial-based attentional deep neural network for named entity recognition},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SCADefender: An autoencoder-based defense for CNN-based
image classifiers. <em>IJPRAI</em>, <em>37</em>(12), 2350027. (<a
href="https://doi.org/10.1142/S0218001423500271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have been enormously successful in a variety of image recognition tasks. Robustness is an important metric to evaluate the quality of CNNs. However, recent research shows that CNNs are particularly vulnerable to adversarial attacks. This paper proposes an adversarial defense method to increase the robustness of CNNs, namely, SCADefender. The proposed method trains a reformer on adversarial examples and the training set of a target classifier. The architecture of the reformer is stacked convolutional autoencoder. The adversarial examples are generated by using various adversarial attacks such as untargeted FGSM, untargeted CW L 2 and untargeted BIS. Given an input image, the trained reformer could remove the adversarial perturbations with a low computational cost. To demonstrate the effectiveness, the proposed method is compared with PuVAE, MagNet, and adversarial training on three well-known datasets including MNIST, Fashion-MNIST, and CIFAR-10. In terms of the average detection rate, the proposed method outperforms other methods. While the proposed method achieves an average detection rate of 97.78% for MNIST, 90.43% for Fashion-MNIST, and 80.64% for CIFAR-10, the comparable methods achieve only 23.69- 86.18% for MNIST, 63.90-79.70% for Fashion-MNIST, and 25.55-77.36% for CIFAR-10.},
  archive      = {J_IJPRAI},
  author       = {Duc-Anh Nguyen and Kha Do Minh and Ngoc Nguyen Nhu and Pham Ngoc Hung},
  doi          = {10.1142/S0218001423500271},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2350027},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {SCADefender: An autoencoder-based defense for CNN-based image classifiers},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Infrared thermal imaging face expression recognition based
on harris algorithm. <em>IJPRAI</em>, <em>37</em>(12), 2350021. (<a
href="https://doi.org/10.1142/S0218001423500210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of human–computer interaction, there is a trend toward using emotional interaction and putting emotions at the center. However, traditional facial expression recognition is greatly affected by lighting, skin color and make-up, and is not well recognized. This paper addresses these shortcomings in the following areas: (1) The algorithm of infrared face feature localization is studied, using a combination of region growing algorithm to highlight the organ features of infrared faces, and the Harris corner point detection algorithm to detect the organ features of human beings and locate the location of the large organs related to expressions, such as eyes, nose and mouth. (2) The algorithm for feature extraction is investigated, and the local binarization LBP algorithm is proposed to extract the texture features of the infrared face. The LBP algorithm is synthesized to extract the overall LBP features by applying the innovation of chunking and layering of features. By analyzing and processing the infrared face image data from both visible and infrared face expression data, feature detection, feature extraction and effective classification of the four basic face expressions — happy, angry, disgusted and sad — are performed on the infrared images. The application of the algorithm is processed and improved accordingly to the characteristics of infrared face images, which improves the accuracy of recognition and classification compared to traditional methods.},
  archive      = {J_IJPRAI},
  author       = {Wentong Wang and Changyuan Wang and Lipeng Si},
  doi          = {10.1142/S0218001423500210},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2350021},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Infrared thermal imaging face expression recognition based on harris algorithm},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Performance optimization of feature extraction for palm and
wrist in multimodal biometrics: A systematic literature review.
<em>IJPRAI</em>, <em>37</em>(12), 2336001. (<a
href="https://doi.org/10.1142/S021800142336001X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a systematic literature review on optimizing feature extraction for palm and wrist multimodal biometrics. Identifying informative features across different modalities can be computationally expensive and time-consuming in such complex systems. Optimization techniques can streamline this process, making it more efficient thereby improving accuracy and reliability. The paper frames four research questions on input traits, approaches for feature extraction, classification approaches, and performance metrics of image data. The search query is generated based on the research questions that help retrieve the information on the above parameters. The focus of this paper is to provide the comprehensive and exhaustive gestalt of the appropriate input traits for image data from the information retrieved as well as optimal feature extraction and selection. However, the paper also intends to highlight the various classification approaches taken as well as the performance indicators against those classifiers. Further, the paper aims to analyze the effectiveness of various filtering techniques in eliminating image noise and improving overall system performance using MATLAB 2018. The paper concludes that a combination of palm and wrist biometrics could be a good input-trait combination. This work is novel as it covers multi-faceted processing, addressing various aspects of optimizing feature extraction and selection for palm and wrist multimodal biometrics.},
  archive      = {J_IJPRAI},
  author       = {Kumari Deepika and Deepika Punj and Jyoti Verma and Anuradha Pillai},
  doi          = {10.1142/S021800142336001X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2336001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Performance optimization of feature extraction for palm and wrist in multimodal biometrics: A systematic literature review},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Forecasting of the short-term electricity load based on
WOA-BILSTM. <em>IJPRAI</em>, <em>37</em>(11), 2359018. (<a
href="https://doi.org/10.1142/S0218001423590188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the biggest difficulties, which China’s power infrastructure is now experiencing, is the capacity to estimate demand of short-term electricity. It can accurately estimate changes in the total power load in particular locations. Accurate forecasting results, which also serve as a dependable guide for power system operation, may increase the flexibility and resource usage of the contemporary power market. Power load characteristics are impacted by several things. This study presents an estimate method for short-term demand of electricity based on WOA-BILSTM in order to comprehensively evaluate the time series features presented in the power load data and improve the accuracy of power load forecasting. After extracting features for the variables that influence power load, this method uses the bidirectional long-term and short-term memory (BILSTM) neural network layer for bidirectional time series feature learning. Using the local electricity load data from Quanzhou from 2018 as the data set, the prediction model is constructed by screening the multi-dimensional input parameters and selecting the feature vectors with good association as the input carefully. By comparing the outcomes of three popular load forecasting models, including LSTM network, BILSTM network, and WOA-BILSTM, it is demonstrated that the WOA-BILSTM neural network method is more accurate and effective than others two. By building an optimal combination model, this technique could increase the accuracy of power load data’s short-term predictions. At the same time, it also reduces the time of personnel debugging.},
  archive      = {J_IJPRAI},
  author       = {Huaxin Zhao and Zhenliu Zhou and Pizhen Zhang},
  doi          = {10.1142/S0218001423590188},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2359018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Forecasting of the short-term electricity load based on WOA-BILSTM},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Confirmation method for flight operators’ interaction based
on the improved lightweight DenseNet. <em>IJPRAI</em>, <em>37</em>(11),
2358007. (<a href="https://doi.org/10.1142/S0218001423580077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid and accurate confirmation of operational intent can improve the efficiency of flight operators in handling sudden emergencies. A lightweight DenseNet flight operator blink interaction confirmation method based on visual gaze is proposed to address the issues of low accuracy and long-time consumption in traditional methods for confirming operational intentions. After determining whether the visual gaze of the flight operator is located at the confirmation button, this method uses two consecutive blinks to confirm the intention of the operation. When performing blink recognition, an improved lightweight DenseNet network model is used, which only uses one block and introduces attention SEBlocks in its L 1 and L 2 layers. Through testing experiments on our own dataset with open and closed eye images, it has been shown that this method has higher accuracy and lower loss compared to the classical DenseNet for open and closed eye recognition. The interactive experiment of flight operation intention confirmation showed that this method requires a shorter time for operation intention confirmation.},
  archive      = {J_IJPRAI},
  author       = {Yawen Wang and Yining Yao and Changyuan Wang and Guangyi Jiang and Pengxiang Xue and Yu Zhang},
  doi          = {10.1142/S0218001423580077},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2358007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Confirmation method for flight operators’ interaction based on the improved lightweight DenseNet},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-OCDTNet: A novel multi-scale object context dilated
transformer network for retinal blood vessel segmentation.
<em>IJPRAI</em>, <em>37</em>(11), 2357009. (<a
href="https://doi.org/10.1142/S0218001423570094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation is an essential part of medical image processing, which plays a significant role in adjunctive therapy, disease diagnosis, and medical assessment. To solve the problem of insufficient extracting context information, especially for medical image segmentation, this paper proposes a novel network architecture of multi-scale object context dilated transformer network (Multi-OCDTNet) to improve the utilization and segmentation accuracy for context information. The multi-scale object context transformer module can extract the multi-scale context information of the image through a three-layer transformer structure in a parallel way. The dilated convolution self-aware module can enhance the awareness of multi-scale context information in the feature map through layering transformer block groups and a set of transformer layers. In addition, we propose a composite weight-assigned-based loss function based on DDCLoss and Focal Tversky Loss to improve the stability of the segmentation performance of Multi-OCDTNet by adjusting the weight. The performance of Multi-OCDTNet is validated on the DRIVE and STARE datasets with segmentation accuracy of 97.17% and 97.84%, respectively, indicating the Multi-OCDTNet network possesses a significant competitive advantage in improving the segmentation performance of retinal vessel images.},
  archive      = {J_IJPRAI},
  author       = {Chengwei Wu and Min Guo and Miao Ma and Kaiguang Wang},
  doi          = {10.1142/S0218001423570094},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2357009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-OCDTNet: A novel multi-scale object context dilated transformer network for retinal blood vessel segmentation},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast 3D object measurement based on point cloud modeling.
<em>IJPRAI</em>, <em>37</em>(11), 2355013. (<a
href="https://doi.org/10.1142/S0218001423550133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated object measurement is becoming increasingly important due to its ability to reduce manual costs, increase production efficiency, and minimize errors in various fields. In this paper, we present a novel approach to three-dimensional (3D) object measurement based on point cloud modeling. Our method introduces a fast point cloud modeling computation framework consisting of five stages: coordinate centralization, rotation and translation, noise filtering, plane projection, and geometric computation. Furthermore, we propose a fast convex hull optimization algorithm to reduce the high complexity problem of traditional convex hull calculation. Our extensive experiments demonstrate that our approach outperforms existing methods in terms of measurement error rate and time savings, with a maximum time saving of 31.03% under certain error conditions.},
  archive      = {J_IJPRAI},
  author       = {Gang Wang and Mingliang Zhou and Bin Fang and Yugui Zhang and Shouqin Guan and Bin Ruan and Zelin Li},
  doi          = {10.1142/S0218001423550133},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2355013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Fast 3D object measurement based on point cloud modeling},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Full-reference image quality assessment via low-level and
high-level feature fusion. <em>IJPRAI</em>, <em>37</em>(11), 2354016.
(<a href="https://doi.org/10.1142/S0218001423540162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a full-reference image quality assessment (FR-IQA) method by incorporating low-level and high-level image features. First, in contrast to the preexisting deep IQA methods, which only use the features extracted by the deep network, we not only use the image gradient to replace the low-level features in the first two stages of the deep network, but also combine them with the middle-stage features of the deep network to construct the new low-level features. The deep features of shallow layers contain some unwanted noise and further result in a decline in IQA performance. Second, we combine the global features extracted by the self-attention-based model with the semantic features extracted by the convolutional neural network to form the high-level features. Instead of directly using the self-attention-based model trained on the classification task, we first train a no-reference (NR) IQA regression model on a larger dataset and then use the global features of this NR-IQA model. The self-attention-based model can capture the internal connections of the image and is more effective in extracting global information due to its larger perceptual field. In the final pooling stage, we combine the average pooling and the standard deviation pooling to obtain the dispersion and concentration of the similarity maps for a more comprehensive description of quality. Experiments show that our FR-IQA method is able to obtain competitive results on three standard IQA datasets.},
  archive      = {J_IJPRAI},
  author       = {Chao Wu and Xiaofeng Liao and Hong Yue and Xueyong Xu and Xuekai Wei and Dingcheng Wu and Mingliang Zhou},
  doi          = {10.1142/S0218001423540162},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2354016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Full-reference image quality assessment via low-level and high-level feature fusion},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FPA-net: Frequency-guided position-based attention network
for land cover image segmentation. <em>IJPRAI</em>, <em>37</em>(11),
2354015. (<a href="https://doi.org/10.1142/S0218001423540150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Land cover segmentation has been a significant research area because of its multiple applications including the infrastructure development, forestry, agriculture, urban planning, and climate change research. In this paper, we propose a novel segmentation method, called Frequency-guided Position-based Attention Network (FPA-Net), for land cover image segmentation. Our method is based on encoder–decoder improved U-Net architecture with position-based attention mechanism and frequency-guided component. The position-based attention block is used to capture the spatial dependency among different feature maps and obtain the relationship among relevant patterns across the image. The frequency-guided component provides additional support with high-frequency features. Our model is simple and efficient in terms of time and space complexities. Experimental results on the Deep Globe, GID-15, and Land Cover AI datasets show that the proposed FPA-Net can achieve the best performance in both quantitative and qualitative measures as compared against other existing approaches.},
  archive      = {J_IJPRAI},
  author       = {Al Shahriar Rubel and Frank Y. Shih},
  doi          = {10.1142/S0218001423540150},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2354015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {FPA-net: Frequency-guided position-based attention network for land cover image segmentation},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application improvement of deep learning algorithm in
small-sized fittings, voltage balancing ring and bare conductor
detection of transmission lines. <em>IJPRAI</em>, <em>37</em>(11),
2352017. (<a href="https://doi.org/10.1142/S0218001423520171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As technological advancements progress and energy conservation and emission reduction policies gain traction, an increasing amount of clean energy is being integrated into the power grid system. This influx of new energy imposes stringent demands on the transmission lines within the power grid system. In recent years, the State Grid has implemented a plethora of intelligent transmission line inspection strategies, with the intelligent inspection of Unmanned Aerial Vehicle (UAV) transmission lines receiving significant promotion and widespread application. However, practical application has revealed that the prevalent transmission line detection algorithms yield a substantial quantity of false detections, particularly in the detection of nut defects in small-sized metallic fittings, voltage balancing ring defects, and defects in uninsulated conductors. To address these issues, this paper employs deep learning algorithms for target detection, critical point detection, and instance segmentation, focusing on aspects such as algorithmic logic, algorithmic models, and data processing. The aim is to enhance the precision of these three types of defect detection, diminish the rate of false detections, and augment the practicality of intelligent grid inspection.},
  archive      = {J_IJPRAI},
  author       = {Shengcheng Zhou and Shujie Tai and Longji Zhang and Dan Cheng and Lina Zhu and Yujie Li and Xuwei Ye},
  doi          = {10.1142/S0218001423520171},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2352017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Application improvement of deep learning algorithm in small-sized fittings, voltage balancing ring and bare conductor detection of transmission lines},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A digital simulation and re-editing method for clothing
patterns based on deep learning and somatosensory interaction.
<em>IJPRAI</em>, <em>37</em>(11), 2352016. (<a
href="https://doi.org/10.1142/S021800142352016X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the issues in clothing pattern style migration, this paper proposes a digital simulation and re-editing method for clothing patterns based on deep learning and somatosensory interaction. First, the proposed method encodes the black-and-white line drawing image, generating random noise images through a diffusion process, introducing color information for synthesis, and using a decoder to reconstruct a colored image. Afterwards, an improved VGG19 model is used to reconstruct content features and perform linear color transformation on style images, enabling pattern style migration through the construction of a Gram matrix and resulting in colored clothing texture patterns. Finally, a KinectV2 is utilized for fabric simulation, overlaying colorful clothing texture patterns to achieve 3D virtual dressing. The experimental results show that the proposed method improves the structural similarity index measure (SSIM) by 9–11% and the peak signal-to-noise ratio (PSNR) by 3–8% when compared to existing algorithms. The experiments provide evidence that the proposed method effectively mitigates color overflow, delivers precise image coloring, and accomplishes realistic restoration of clothing texture. Furthermore, the method offers an improved garment fit to fulfill the user’s interaction requirements.},
  archive      = {J_IJPRAI},
  author       = {Haiyan Sun and Jiali Yao and Haoyu Zhang and Zhijun Li and Xingquan Cai},
  doi          = {10.1142/S021800142352016X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2352016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A digital simulation and re-editing method for clothing patterns based on deep learning and somatosensory interaction},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Welding defect classification based on lightweight CNN.
<em>IJPRAI</em>, <em>37</em>(11), 2350026. (<a
href="https://doi.org/10.1142/S021800142350026X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The welding defect classification method based on deep learning often faces problems such as insufficient training data and complex model structures, which affect its real-time performance. Therefore, a welding defect classification method based on lightweight convolutional neural network (CNN) is proposed. The problems of insufficient and unbalanced welding defect image are solved by using the generative adversarial networks (GANs) data augmentation method. A lightweight CNN model is developed, which reduces the structural parameters under the premise of ensuring classification accuracy. The feature data of each convolution layer are visualized to verify the feasibility of the model and improve the interpretability of the model. By comparing the accuracy and real-time performance with other lightweight models, the excellent performance of the proposed model in welding defect classification is verified. Additionally, our model achieves 98.25% accuracy on the MNIST dataset.},
  archive      = {J_IJPRAI},
  author       = {Bo Guo and Youtao Wang and Xu Li and Yeping Zhou and Jianmin Li and Lanxiang Rao},
  doi          = {10.1142/S021800142350026X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2350026},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Welding defect classification based on lightweight CNN},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A framework for personalized human activity recognition.
<em>IJPRAI</em>, <em>37</em>(10), 2356016. (<a
href="https://doi.org/10.1142/S0218001423560165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s world, Human Activity Recognition (HAR) through video streams is actively used in every aspect of our life, such as automated surveillance systems and sports statistics are computed according to the videos with the help of HAR. Activity detection is not a new subject, and several methods are available. However, the most recent and most promising techniques rely on Convolutional Neural Networks (CNNs). CNNs primary usage is based on a single image frame to perform logical or categorical identification of an object, scene, or activity. We exploit this feature to adapt CNN on video streams to achieve HAR. In this study, we present a Personalized HAR (PHAR) framework that increases activity recognition accuracy with Object Detection (OD). First, we demonstrate the state-of-the-art HAR and OD methods in the literature. Then we illustrate our framework with two new Single Person Human Activity Recognition models. Finally, the performance of the new framework is evaluated with the well-known activity detection methods. Results show that our new PHAR model with 95% accuracy ratio outperforms the CNN-LSTM-based reference model (90%). Moreover, a new metric Average Accuracy Score (AAS) is described in this study, PHAR models approximately have 94% AAS, which is better than the reference model with 89% AAS.},
  archive      = {J_IJPRAI},
  author       = {Hasan Ali Eri̇ş and Mehmet Ali Ertürk and Muhammed Ali Aydın},
  doi          = {10.1142/S0218001423560165},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2356016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A framework for personalized human activity recognition},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An extended labanotation generation method based on 3D human
pose estimation for intangible cultural heritage dance videos.
<em>IJPRAI</em>, <em>37</em>(10), 2355012. (<a
href="https://doi.org/10.1142/S0218001423550121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the issues of low accuracy in existing 3D human pose estimation (HPE) methods and the limited level of details in Labanotation, we propose an extended Labanotation generation method for intangible cultural heritage dance videos based on 3D HPE. First, a 2D human pose sequence of the performer is inputted along with spatial location embeddings, where multiple spatial transformer modules are employed to extract spatial features of human joints and generate cross-joint multiple hypotheses. Afterward, temporal features are extracted by a self-attentive module and the correlation between different hypotheses is learned using bilinear pooling. Finally, the 3D joint coordinates of the performer are predicted, which are matched with the corresponding extended Labanotation symbols using the Laban template matching method to generate extended Labanotation. Experimental results show that, compared with VideoPose and CrossFormer algorithms, the Mean Per Joint Position Error (MPJPE) of the proposed method is reduced by 3.7 mm and 0.6 mm, respectively on Human3.6M dataset, and the generated extended Labanotation can better describe the movement details compared with the basic Labanotation.},
  archive      = {J_IJPRAI},
  author       = {Xingquan Cai and Rui Lu and Pengyan Cheng and Jiali Yao and Yan Hu},
  doi          = {10.1142/S0218001423550121},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2355012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An extended labanotation generation method based on 3D human pose estimation for intangible cultural heritage dance videos},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Counting with self-weighted multi-scale fusion networks.
<em>IJPRAI</em>, <em>37</em>(10), 2355007. (<a
href="https://doi.org/10.1142/S0218001423550078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of the large-scale variation, counting in scenes of different densities is an extremely difficult task. In this paper, based on the attention mechanism, we propose a new self-weighted multi-scale fusion network structure named SMFNet to solve the problem of multi-scale changes and can significantly improve the effect of crowd counting in monitoring scene. The proposed SMFNet uses VGG as the backbone network to extract multi-scale features, uses a SMFNet as the neck to fuse multiple-scale features, and uses the atrous spatial pyramid pooling (ASPP) network and ordinary convolution as the head to generate both the attention map and the density map. The attention map highlighting crowd regions in the image contributes to a high-quality density map, and the density map records the crowd distribution. The number of crowd in the image can be obtained by summing the pixel values of the density map. We conduct experiments on three crowd counting datasets and one vehicle counting dataset to show that our proposed SMFNet can improve the state-of-the-art counting methods.},
  archive      = {J_IJPRAI},
  author       = {Xin Xiong and Jie Shen and Ying Li and Wei He and Peng Li and Wenjie Yan},
  doi          = {10.1142/S0218001423550078},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2355007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Counting with self-weighted multi-scale fusion networks},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel thanka image inpainting method with euler’s elastica
and iterative denoising and backward projections. <em>IJPRAI</em>,
<em>37</em>(10), 2354014. (<a
href="https://doi.org/10.1142/S0218001423540149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a brand-new Thanka picture inpainting technique based on Euler’s elastica, iterative denoising, and backward projections (EEIDBP). Specifically, a model of Euler’s elastica is introduced to estimate the original observation due to its lower staircasing effects and better approximation of natural images. A method for backward projection and iterative denoising is applied to achieve a more accurate estimate of the original signal by alternating iterations between the estimation of the original signal and the estimation of the original observation. The experimental findings demonstrate that, in terms of a subjective assessment, the quantitative peak signal-to-noise ratio (PSNR), and the structural similarity (SSIM), the proposed technique outperforms the state-of-the-art picture inpainting methods.},
  archive      = {J_IJPRAI},
  author       = {Qiaoqiao Li and Weilan Wang},
  doi          = {10.1142/S0218001423540149},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2354014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A novel thanka image inpainting method with euler’s elastica and iterative denoising and backward projections},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-network-based ensemble deep learning model to forecast
ross river virus outbreak in australia. <em>IJPRAI</em>,
<em>37</em>(10), 2352015. (<a
href="https://doi.org/10.1142/S0218001423520158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ross River virus (RRV) disease is one of the most epidemiological mosquito-borne diseases in Australia. Its major consequences on public health require building a precise and accurate model for predicting any forthcoming outbreaks. Several models have been developed by machine learning (ML) researchers, and many studies have been published as a result. Later, deep learning models have been introduced and shown tremendous success in forecasting, mainly the long short-term memory (LSTM), which performs significantly better than the traditional machine learning approaches. There are four common problems that previously developed models need to solve. They are exploding gradient, vanishing gradient, uncertainty and parameter bias. LSTM has already solved the first two problems, i.e. exploding and vanishing gradient problems, and the remaining two are overcome by n -LSTM. However, developing a prediction model for the RRV disease is a challenging task because it presents a wide range of symptoms, and there needs to be more accurate information available on the disease. To address these challenges, we propose a data-driven ensemble deep learning model using multi-networks of LSTM neural network for RRV disease forecasting in Australia. Data is collected between 1993 and 2020 from the Health Department of the Government of Australia. Data from 1993 to 2016 is taken to train the model, while the data of 2016–2020 is used as a test dataset. Previous research has demonstrated the efficacy of both ARIMA and exponential smoothing techniques in the field of time-series forecasting. As a result, our study sought to evaluate the performance of our proposed model in comparison to these established parametric methods, including ARIMA and ARMA, as well as the more recent deep learning approaches such as encoder–decoder and attention mechanism models. The results show that n -LSTM achieves higher accuracy and has a less mean-square error. We have also discussed the comparison of the models in detail. Such forecasting gives an insight into being well prepared and handling the situation of the outbreak.},
  archive      = {J_IJPRAI},
  author       = {Mohd Sakib and Tamanna Siddiqui},
  doi          = {10.1142/S0218001423520158},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2352015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-network-based ensemble deep learning model to forecast ross river virus outbreak in australia},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Welding groove edge detection method using lightweight
fusion model based on transfer learning. <em>IJPRAI</em>,
<em>37</em>(10), 2351014. (<a
href="https://doi.org/10.1142/S021800142351014X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Groove edge detection is the prerequisite for weld seam deviation identification. A welding groove edge detection method based on transfer learning is presented as a solution to the inaccuracy of the conventional image processing method for extracting the edge of the welding groove. DenseNet and MobileNetV2 are used as feature extractors for transfer learning. Dense-Mobile Net is constructed using the skip connections structure and depthwise separable convolution. The Dense-Mobile Net training procedure consists of two stages: pre-training and model fusion fine-tuning. Experiments demonstrate that the proposed model accurately detects groove edges in MAG welding images. Using MIG welding images and the Pascal VOC2012 dataset to evaluate the generalization ability of the model, the relevant indicators are greater than those of Support Vector Machine (SVM), Fully Convolutional Networks (FCN), and UNet. The average single-frame detection time of the proposed model is 0.14 s, which meets the requirements of industrial real-time performance.},
  archive      = {J_IJPRAI},
  author       = {Bo Guo and Lanxiang Rao and Xu Li and Yuwen Li and Wen Yang and Jianmin Li},
  doi          = {10.1142/S021800142351014X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2351014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Welding groove edge detection method using lightweight fusion model based on transfer learning},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Drug toxicity prediction by machine learning approaches.
<em>IJPRAI</em>, <em>37</em>(10), 2351013. (<a
href="https://doi.org/10.1142/S0218001423510138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug property prediction, especially toxicity, helps reduce risks in a range of real-world applications. In this paper, we aim to apply various machine-learning models for solving the drug toxicity prediction problem. Among various machine-learning approaches, we select five suitable representatives: random forest, multi-layer perceptron, logistic regression, graph convolutional neural network, and graph isomorphism network (GIN) for conducting experiments on six datasets for toxicity prediction, including Tox 21, ClinTox, ToxCast, SIDER, HIV, and BACE. We design the GIN with four hidden layers and select the Adam optimizer with the learning rate 1 0 − 4 and the batch size 2 5 6 . Furthermore, we use a batch norm layer inside each of the GIN hidden layers. Experimental results show that the designed GIN model is most efficient in distinguishing between safe and toxic drugs and outperforms the others under the supervision of ROC AUC score and recall.},
  archive      = {J_IJPRAI},
  author       = {Yucong Shen and Frank Y. Shih and Hao Chen},
  doi          = {10.1142/S0218001423510138},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2351013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Drug toxicity prediction by machine learning approaches},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An offline EP test tube positioning tilt correction
algorithm based on lightweight yolov4. <em>IJPRAI</em>, <em>37</em>(10),
2351011. (<a href="https://doi.org/10.1142/S0218001423510114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an infrastructure of biochemical laboratories, EP tube label plays a significant role in information extraction to meet the limitations of computing power in offline devices and solve the problem that the EP tube label cannot be accurately identified before identification because the label belongs to multi-angle random placement. This paper proposes a light-weight neural network YOLOv4-tiny-ECA to position tubes and a tilt correction method based on Hough transform. First, the EP tube rack is roughly positioned based on the diffuse filling algorithm combined with digital morphological corrosion, and then the EP tubes in the rack are precisely positioned using the light-weight YOLO target detection algorithm combined with the attention mechanism. Next, the baseline is added to the label as the basis for determining the tilt angle. For the valid target, the baseline is extracted using the Hough transform and the tilt angle is calculated by vector fork multiplication. Finally, baseline is removed using image processing algorithm for better recognition results. Our results show that the light-weight YOLO algorithm reduces the network parameters by 56% and computation by 55% while keeping the accuracy rate largely unchanged, the offline positioning tilt correction method can achieve 98.8% accuracy and 0.076 s processing speed for a single test tube on average, which meets the real-time requirement.},
  archive      = {J_IJPRAI},
  author       = {Heng Luo and Wenxuan Huang and Qidong Ni},
  doi          = {10.1142/S0218001423510114},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2351011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An offline EP test tube positioning tilt correction algorithm based on lightweight yolov4},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TCNN architecture for partial occlusion handling in
pedestrian classification. <em>IJPRAI</em>, <em>37</em>(10), 2350025.
(<a href="https://doi.org/10.1142/S0218001423500258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian classification is of increased interest to autonomous transportation systems due to the development of deep convolutional neural networks. Despite recent progress on pedestrian classification, it is still challenging to identify individuals who are partially occluded because of the diversity of the occluded parts, variation in pose, and appearance. This causes a significant performance reduction when pedestrians are covered by other objects, and feature information is lost due to the occluded parts. To solve this problem, we propose two network architectures using tree structure convolutional neural networks (T-CNN). They use the structural representation of multi-branch deep convolutional features, with the advantages of its end-to-end learning process. The high-level tree structure CNN (HT-CNN) architecture aims to concatenate the output of the classification layer from multi-segmented patches of pedestrians to handle partially occluded problems. The low-level tree structure CNN (LT-CNN) concatenates the discriminative features from each multi-segmented patch and global features. Our T-CNN architecture with a high-level tree structure performed with 94.64% accuracy on the INRIA dataset without occlusions, and with 70.78% accuracy on the Prince of Songkla University (PSU) dataset with occlusions, outperforming a baseline CNN architecture. This indicates that our proposed architecture can be used in a real-world environment to classify the occluded part of pedestrians with the visual information of multi-segmented patches using tree-structured multi-branched CNN.},
  archive      = {J_IJPRAI},
  author       = {May Thu and Nikom Suvonvorn},
  doi          = {10.1142/S0218001423500258},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2350025},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {TCNN architecture for partial occlusion handling in pedestrian classification},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MSFE-PANet: Improved YOLOv4-based small object detection
method in complex scenes. <em>IJPRAI</em>, <em>37</em>(10), 2350024. (<a
href="https://doi.org/10.1142/S0218001423500246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of computer vision and artificial intelligence technology, visual object detection has made unprecedented progress, and small object detection in complex scenes has attracted more and more attention. To solve the problems of ambiguity, overlap and occlusion in small object detection in complex scenes. In this paper, a multi-scale fusion feature enhanced path aggregation network MSFE-PANet is proposed. By adding attention mechanism and feature fusion, the fusion of strong positioning information of deep feature map and strong semantic information of shallow feature map is enhanced, which helps the network to find interesting areas in complex scenes and improve its sensitivity to small objects. The rejection loss function and network prediction scale are designed to solve the problems of missing detection and false detection of overlapping and blocking small objects in complex backgrounds. The proposed method achieves an accuracy of 40.7% on the VisDrone2021 dataset and 89.7% on the PASCAL VOC dataset. Comparative analysis with mainstream object detection algorithms proves the superiority of this method in detecting small objects in complex scenes.},
  archive      = {J_IJPRAI},
  author       = {Xiaoying Pan and Ningxin Jia and Yuanzhen Mu and Weidong Bai},
  doi          = {10.1142/S0218001423500246},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2350024},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {MSFE-PANet: Improved YOLOv4-based small object detection method in complex scenes},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Depth-constrained network for multi-scale object detection.
<em>IJPRAI</em>, <em>37</em>(10), 2350023. (<a
href="https://doi.org/10.1142/S0218001423500234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Challenges such as complex backgrounds, drastic variations in target scales, and dense distributions exist in natural scenes. Some algorithms optimize multi-scale object detection performance by combining low-level and high-level information through feature fusion strategies. However, these methods overlook the inherent spatial properties of objects and the relationships between foreground and background. To fundamentally enhance the multi-scale detection capability, we propose a depth-constrained multi-scale object detection network that simultaneously learns object detection and depth estimation through a unified framework. In this network, depth features are merged into the detection branch as auxiliary information and constrained and guided to obtain better spatial representations, which enhances discrimination between multi-scale objects. We also introduce a novel cross-modal fusion (CmF) strategy that utilizes depth awareness and low-level detail clues to supplement edge information and adjust attention weight preferences. We find complementary information from RGB and high-quality depth features to achieve better multi-modal information fusion. Experimental results demonstrate that our method outperforms state-of-the-art methods on the KINS dataset, with an improvement of 3.0% in AP score over the baseline network. Furthermore, we validate the effectiveness of our proposed method on the KITTI dataset.},
  archive      = {J_IJPRAI},
  author       = {Guohua Liu and Yijun Li},
  doi          = {10.1142/S0218001423500234},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2350023},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Depth-constrained network for multi-scale object detection},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Video action recognition by combining spatial-temporal cues
with graph convolutional networks. <em>IJPRAI</em>, <em>37</em>(10),
2350009. (<a href="https://doi.org/10.1142/S021800142350009X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video action recognition relies heavily on the way spatio-temporal cues are combined in order to enhance recognition accuracy. This issue can be addressed with explicit modeling of interactions among objects within or between videos, such as the graph neural network, which has been shown to accurately model and represent complicated spatial- temporal object relations for video action classification. However, the visual objects in the video are diversified, whereas the nodes in the graphs are fixed. This may result in information overload or loss if the visual objects are too redundant or insufficient for graph construction. Segment level graph convolutional networks (SLGCNs) are proposed as a method for recognizing actions in videos. The SLGCN consists of a segment-level spatial graph and a segment-level temporal graph, both of which are capable of simultaneously processing spatial and temporal information. Specifically, the segment-level spatial graph and the segment-level temporal graph are constructed using 2D and 3D CNNs to extract appearance and motion features from video segments. Graph convolutions are applied in order to obtain informative segment-level spatial-temporal features. A variety of challenging video datasets, such as EPIC-Kitchens, FCVID, HMDB51 and UCF101, are used to evaluate our method. In experiments, it is demonstrated that the SLGCN can achieve performance comparable to the state-of-the-art models in terms of obtaining spatial-temporal features.},
  archive      = {J_IJPRAI},
  author       = {Tao Li and Wenjun Xiong and Zheng Zhang and Lishen Pei},
  doi          = {10.1142/S021800142350009X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2350009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Video action recognition by combining spatial-temporal cues with graph convolutional networks},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-scale orthogonal model CNN–transformer for medical
image segmentation. <em>IJPRAI</em>, <em>37</em>(10), 2337001. (<a
href="https://doi.org/10.1142/S0218001423370016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of the limitations of convolution kernel, the traditional image segmentation network is not sufficient to obtain the context information, but the image segmentation task is very dependent on the context information. Transformer’s linear input can just get enough context information. In this paper, we propose a transformer segmentation network hyperfusion transformer based on a pyramid structure. First, the model divides the single-scale coding form into several-different-scale coding forms, and then fuses the decoding results. Second, in order to ensure the specificity of the output characteristics of each branch, we orthogonalize the results of a variety of different scales. By orthogonalizing in pairs, we can ensure that the results obtained by different branches are not completely similar to a certain extent, and reduce the redundancy of branch information. On the two datasets, the method in this paper surpasses a variety of classical models under multiple evaluation indexes, confirming that it is an effective segmentation method.},
  archive      = {J_IJPRAI},
  author       = {Wuyi Zhou and Xianhua Zeng and Mingkun Zhou},
  doi          = {10.1142/S0218001423370016},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2337001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-scale orthogonal model CNN–Transformer for medical image segmentation},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Super-resolution reconstruction based on adaptive weight
adjustment. <em>IJPRAI</em>, <em>37</em>(10), 2334001. (<a
href="https://doi.org/10.1142/S0218001423340017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In image super-resolution, the existing convolution neural network methods increase the number of network layers and filters to achieve better performance, and seldom consider the influence of different branches in feature extraction on the reconstruction effect, which leads to the problems of blurred details and unclear visual perception. Therefore, we propose an adaptive weight adjustment super-resolution (AWSR) reconstruction model in this paper. The model includes Shallow Feature Extraction (SFE), Information Extraction Enhancement Block (IDEB) and Reconstruction Block (RB). IDEB composed of Adaptive Weight Blocks (AWB) and Channel Linking Layers (CLL) learns a deeper mapping relationship between LR image and HR image by adaptively adjusting the proportions of different branches. It not only saves computational cost, but also improves the expression ability of the model. Meanwhile, the performance of the model is further improved by dimension change in the up-sample block. Especially, the image edge and texture reconstruction effects are obviously improved. Compared with SRNHARB algorithm proposed in 2021, the PSNR values are increased by 0.23 dB, 0.19 dB and 0.02 dB at × 2 , × 3 , × 4 on the Set5 dataset. Moreover, the proposed model has a strong generalization ability, and the reconstructed SR images can achieve satisfactory results.},
  archive      = {J_IJPRAI},
  author       = {Xiaoqiang Zhao and Wei Cheng},
  doi          = {10.1142/S0218001423340017},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2334001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Super-resolution reconstruction based on adaptive weight adjustment},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive ant colony algorithm based on local information
entropy to solve distributed constraint optimization problems.
<em>IJPRAI</em>, <em>37</em>(9), 2359013. (<a
href="https://doi.org/10.1142/S0218001423590139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a meta-heuristic algorithm, the ant colony algorithm has been successfully used to solve various combinatorial optimization problems. However, the existing algorithm that takes the power of ants to solve distributed constraint optimization problems (ACO_DCOP) is easy to fall into local optima. To deal with this issue, this paper presents an adaptive ant colony algorithm based on local information entropy to solve distributed constraint optimization problems, named LIEAD. In LIEAD, the local information entropy is introduced to help agents adaptively select the pheromone update strategy and value selection strategy, which improves the convergence speed and the quality of the solution. Moreover, a restart mechanism is designed to break the accumulation state of pheromone, which increases the population diversity and helps the algorithm jump out of the local optima. The extensive experimental results indicate that LIEAD can significantly outperform ACO_DCOP and is competitive with the state-of-the-art DCOPs algorithms.},
  archive      = {J_IJPRAI},
  author       = {Meifeng Shi and Shichuan Xiao and Xin Feng},
  doi          = {10.1142/S0218001423590139},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2359013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An adaptive ant colony algorithm based on local information entropy to solve distributed constraint optimization problems},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent inversion of coastal earth resistivity.
<em>IJPRAI</em>, <em>37</em>(9), 2359008. (<a
href="https://doi.org/10.1142/S0218001423590085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coastal grounding electrodes are currently an important means to alleviate land grounding electrode land constraints. In order to better invert the terrestrial geodesic resistivity in the coastal region, this paper proposes a complete set of inversion technology schemes. First, this paper proposes a layered land model for the coastal region, and a composite geodetic model is modeled by the fold junction of the land model and the ocean. Based on this, an adaptive subdivision boundary element method is proposed for solving the composite soil grounding calculation problem, and the accuracy and advantages of the method are demonstrated by examples. Finally, the paper uses the differential evolutionary algorithm to invert the exploration data of the four-point method in the coastal area, and obtains the parameters of the terrestrial layered geodetic model that meet the engineering requirements. The comparison with the grounding software CDEGS illustrates the effectiveness of the method. This paper carries out the research on the modeling and inversion methods of composite layered soil model, combining advanced numerical calculation methods and artificial intelligence algorithms to provide the support of computational tools for coastal resistivity inversion.},
  archive      = {J_IJPRAI},
  author       = {Bo Tan and Zhuohong Pan and Xuefang Tong and Yan Wang and Xianghan Wang and Lei Gao},
  doi          = {10.1142/S0218001423590085},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2359008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Intelligent inversion of coastal earth resistivity},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel sentimental analysis for response to natural
disaster on twitter data. <em>IJPRAI</em>, <em>37</em>(9), 2357007. (<a
href="https://doi.org/10.1142/S0218001423570070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The response to a natural disaster ultimately depends on credible and real-time information regarding impacted people and areas. Nowadays, social media platforms such as Twitter have emerged as the primary and fastest means of disseminating information. Due to the massive, imprecise, and redundant information on Twitter, efficient automatic sentiment analysis (SA) plays a crucial role in enhancing disaster response. This paper proposes a novel methodology to efficiently perform SA of Twitter data during a natural disaster. The tweets during a natural calamity are biased toward the negative polarity, producing imbalanced data. The proposed methodology has reduced the misclassification of minority class samples through the adaptive synthetic sampling technique. A binary modified equilibrium optimizer has been used to remove irrelevant and redundant features. The k -nearest neighbor has been used for sentiment classification with the optimized value of k . The nine datasets on natural disasters have been used for evaluation. The performance of the proposed methodology has been validated using the Friedman mean rank test against nine state-of-the-art techniques, including two optimized, one transfer learning, one deep learning, two ensemble learning, and three baseline classifiers. The results show the significance of the proposed methodology through the average improvement of 6.9%, 13.3%, 20.2%, and 18% for accuracy, precision, recall, and F1-score, respectively, as compared to nine state-of-the-art techniques.},
  archive      = {J_IJPRAI},
  author       = {Sachin Minocha and Birmohan Singh},
  doi          = {10.1142/S0218001423570070},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2357007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A novel sentimental analysis for response to natural disaster on twitter data},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DOMOPT: A detection-based online multi-object pedestrian
tracking network for videos. <em>IJPRAI</em>, <em>37</em>(9), 2356013.
(<a href="https://doi.org/10.1142/S021800142356013X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the problem of low tracking accuracy and weak tracking stability of current multi-object pedestrian tracking algorithms in complex scenes for videos, a Detection-based Online Multi-Object Pedestrian Tracking (DOMOPT) network is proposed. First, a Multi-Level Feature Fusion (MLFF) pedestrian detection network is proposed based on the Center and Scale Prediction (CSP) algorithm. The pyramid convolutional neural network is used as the backbone to enhance the feature extraction capability for small objects. The shallow features and deep features at multiple levels are integrated to fully obtain the position and semantic information to further improve the detection performance for small objects. Then, on the basis of Joint Detection and Embedding (JDE) architecture, a Multi-Branch Pedestrian Appearance (MBPA) feature extraction network is proposed and added into the pedestrian detection network to extract the appearance feature vector corresponding to each pedestrian. The pedestrian appearance feature extraction is treated as a classification task jointly training with the pedestrian detection task, using the multi-task learning strategy. Experimental results show that the proposed network has better tracking accuracy and stability compared with state-of-the-art algorithms.},
  archive      = {J_IJPRAI},
  author       = {Ruohong Huan and Shuaishuai Zheng and Chaojie Xie and Peng Chen and Ronghua Liang},
  doi          = {10.1142/S021800142356013X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2356013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {DOMOPT: A detection-based online multi-object pedestrian tracking network for videos},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quality inspection of 3D printed tubular tissue based on
machine vision. <em>IJPRAI</em>, <em>37</em>(9), 2355009. (<a
href="https://doi.org/10.1142/S0218001423550091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigated the three-dimensional (3D) printing of tubular tissue, especially vascular tissue, using a self-developed 3D bioprinter platform and tubular tissue support frame system based on machine vision technology. A 3D printing quality inspection scheme for tubular tissue based on machine vision was proposed by combining the current advanced image acquisition sensor device and theoretical and experimental analysis to measure the printing area in real time. A quantitative relationship between the quality of the tissue profile and the angle and brightness of tissue printed by hydrogel was established by changing the process parameters. A mathematical model for the visual inspection of tissue contour quality was established to realize its visual inspection and evaluation. This method can monitor the quality status of the printing target in real time and provide a basis for improving the accuracy of 3D bioprinting of tubular tissue and shortening the printing time.},
  archive      = {J_IJPRAI},
  author       = {Xiaoyan Wu and Shu Wang},
  doi          = {10.1142/S0218001423550091},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2355009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Quality inspection of 3D printed tubular tissue based on machine vision},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Customized information extraction and processing pipeline
for commercial invoices. <em>IJPRAI</em>, <em>37</em>(9), 2354013. (<a
href="https://doi.org/10.1142/S0218001423540137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting information from scanned invoices and other commercial documents, a critical component of corporate function, typically requires significant manual processing. Much research has been conducted in the field of automated information extraction and document processing to alleviate the manual resources used for document analysis, but resultant literature and commercially available products have demonstrated limitations in customizability for identifying specific information. In this paper, we propose a customized machine learning-based pipeline for extracting and tabulating relevant key–value pairs from commercial invoice documents. Specifically, the pipeline combines general document understanding, OCR extraction, and key–value matching with custom rules pertaining to a provided invoice dataset. Then, we demonstrate that the pipeline greatly outperforms a commercially available product and can significantly reduce the amount of manual labor required to process invoice documents. Future work will focus on generalizing the pipeline, so as to apply it on more varied datasets.},
  archive      = {J_IJPRAI},
  author       = {Pierce Lai and Abhishek Mohan and Seok Kim and Jung Soo Victor Chu and Samuel Lee and Prabhakar Kafle and Patrick Wang},
  doi          = {10.1142/S0218001423540137},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2354013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Customized information extraction and processing pipeline for commercial invoices},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep active recognition through online cognitive learning.
<em>IJPRAI</em>, <em>37</em>(9), 2352013. (<a
href="https://doi.org/10.1142/S0218001423520134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep models need a large number of labeled samples to be trained. Furthermore, in practical application settings where objects’ features are added or changed over time, it is difficult and expensive to get enough labeled samples in the beginning. Cognitive learning mechanism can actively raise the deep models’ proficiency online with a few training labels gradually. In this paper, inspired by human being’s cognition procedure to acquire new knowledge stage by stage, we develop a novel deep active recognition framework based on the analysis of models’ cognitive error knowledge to fine-tune the deep models online. The transformation of the cognitive errors is defined, and the corresponding knowledge is obtained to identify the models’ cognitive information. Based on the cognitive knowledge, the sensitive samples are selected to finely tune the models online. To avoid forgetting the previous learned knowledge, the selected prior training samples are used as the refreshening samples at the same time. The experiments demonstrate that the sensitive samples can benefit the target recognition and the cognitive learning mechanism can boost the deep models’ performance efficiently. The characterization of cognitive information can restrain the other samples’ disturbance to the models’ cognition effectively and the online training method can save mass of the time evidently. In conclusion, we introduce this work to provide a trial of thought about the cognitive lifelong learning used in deep learning scenarios.},
  archive      = {J_IJPRAI},
  author       = {Jing Yang and Wencang Zhao and Minghua Lu and Jincai Huang},
  doi          = {10.1142/S0218001423520134},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2352013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Deep active recognition through online cognitive learning},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Copy-move forgery detection and localization using deep
learning. <em>IJPRAI</em>, <em>37</em>(9), 2352012. (<a
href="https://doi.org/10.1142/S0218001423520122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forgery detection is one of the challenging subjects in computer vision. Forgery is performed using image manipulation with editor tools. Image manipulation tries to change the concept of the image but preserves the integrity of the texture and structure of the image as much as possible. Images are used as evidence in some applications, so if the images are manipulated, they will not be reliable. The copy-move forgery is one of the simplest image manipulation methods. This method removes or inserts information into the image with the least clue by copying a part of the image and pasting it into other places of the same image. Recently, traditional (block-based and keypoint-based) and deep learning methods have been proposed to detect forgery images. Traditional methods include two main steps, feature extraction, and feature matching. Unlike the traditional methods, the deep learning method performs the forgery detection automatically by extracting hierarchical features directly from the data. This paper presents a deep learning method for forgery detection at both image and pixel levels. In this method, we used a pre-trained deep model with a global average pooling (GAP) layer instead of default fully connected layers to detect forgery. The GAP layer creates a good dependency between the feature maps and the classes. In pixel forgery detection, a visualization technique called heatmap activation is used in forgery images. This technique identifies parts of the image that are candidates for forgery. Then, the best candidate is selected and the location of the forgery is determined. The proposed method is performed on the CoMoFod and MICC datasets. The extensive experiments showed the satisfactory performance of the proposed method.},
  archive      = {J_IJPRAI},
  author       = {Fatemeh Zare Mehrjardi and Ali Mohammad Latif and Mohsen Sardari Zarchi},
  doi          = {10.1142/S0218001423520122},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2352012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Copy-move forgery detection and localization using deep learning},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A method on classification and recognition of noisy plant
images based on visual domain perception. <em>IJPRAI</em>,
<em>37</em>(9), 2350020. (<a
href="https://doi.org/10.1142/S0218001423500209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, some achievements have been made in the research of plant leaf classification such as the introduction of artificial intelligence algorithm. But there are still some problems. First, the existing achievements do not consider the subjective perception mechanism and role of human visual system in leaf classification data labels. Second, the implementation of the deep learning algorithm completely depends on the computing power level of the high-cost machine hardware and the large-scale image database. Finally, these research results rarely consider the noise pollution of leaf image samples. In order to solve the above problems, the paper fully considered the subjective perception principle and characteristics of human vision system (HVS), and proposed a lightweight classification method of noisy plant leaves (LCM-NPLs) based on visual domain perception. First, the most suitable HVS front-end perception characteristics were applied to the physical visual processing of leaves. Then the plant leaves were denoised through the information processing mechanism of HVS back-end. The visual effect of regular and orderly plant leaves is obtained. Finally, the classification is realized by principal component analysis (PCA) and third-order nearest neighbor algorithm. The results of ablation contrast experiments show that the classification accuracy of the method in this paper is 82.50% for plant leaves in the presence of serious noise interference with PSNR of 10.2421, more than 90% for plant leaves with general noise pollution transmission with PSNR of more than 15.3759, and 98.33% for plant leaves of light pollution with PSNR of 20.5659. The proposed method has achieved very good results. The proposed method can not only accurately classify plant leaves in different growth periods, but also maintain a high classification accuracy rate in the presence of serious noise interference.},
  archive      = {J_IJPRAI},
  author       = {Hongbiao Xie and Mingkun Feng and Zhijie Lin and Jiyi Wu and Zhe Feng},
  doi          = {10.1142/S0218001423500209},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2350020},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A method on classification and recognition of noisy plant images based on visual domain perception},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Deepfake speech recognition and detection. <em>IJPRAI</em>,
<em>37</em>(9), 2350015. (<a
href="https://doi.org/10.1142/S0218001423500155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deepfake technology, especially deep voice, which has been derived from artificial intelligence in recent years, is potentially harmful, and the public is not yet wary. However, many speech synthesis models measure the degree of true restitution by Mean Opinion Rating (MOS), a subjective assessment of naturalness and quality of speech by human subjects, but in future it will be difficult to distinguish the interlocutor’s identity through the screen. For this reason, this study addresses the threat posed by this new technology by combining representational learning and 0transfer learning in two sub-systems: a recognition system and a voice print system. The recognition system is responsible for the detection of which voice is a fake voice generated by speech conversion or speech synthesis techniques, while the acoustic system is responsible for the verification of the speaker’s identity through acoustic features. In the speech recognition system, we use the representation learning method and the transfer classification method. We use X-vector data for training, and then fine-tune the model using four types of marker data to learn the representation vectors of real and fake voice, and use support vector machine to classify real and fake voice in the back-end to reduce the negative effect of the new technique.},
  archive      = {J_IJPRAI},
  author       = {Hung-Chang Chang},
  doi          = {10.1142/S0218001423500155},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2350015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Deepfake speech recognition and detection},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A wavelet basis ANN and 5-class decision factor AI
algorithm. <em>IJPRAI</em>, <em>37</em>(8), 2359017. (<a
href="https://doi.org/10.1142/S0218001423590176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accuracy and reliability of continuous space curve estimation is the key to global exploration. An improved artificial intelligence algorithm is proposed for continuous space analysis. First, a wavelet basis ANN algorithm is proposed to determine the discretization strategy in continuous space. The hidden layer node transfer function in a BP neural network is replaced by a wavelet basis function, and the modified BP neural network is composed of a wavelet neural network. Second, an improved wolf algorithm is established. The core wolf system ensures the precision of the whole exploration task. Finally, main and auxiliary double cores and a five-class decision factor are used to establish a population classification model to solve the convergence of the algorithm.},
  archive      = {J_IJPRAI},
  author       = {Xuepeng Liu and Dongmei Zhao and Yihang Peng and Jianping Li},
  doi          = {10.1142/S0218001423590176},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2359017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A wavelet basis ANN and 5-class decision factor AI algorithm},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluation quality of chinese baijiu using GC–MS based on
SPCA and neural network. <em>IJPRAI</em>, <em>37</em>(8), 2359016. (<a
href="https://doi.org/10.1142/S0218001423590164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, evaluating the quality of strong-flavor Baijiu (SFB) heavily relies on subjective sensory analysis, resulting in large deviations in evaluation. However, as there are no existing evaluation criteria for SFB quality, this study aimed to extract trace components and design an evaluation model using gas chromatography–mass spectrometry (GC–MS). First, the key component data was analyzed using principal component analysis (PCA) and sparse principal component analysis (SPCA) to identify the most important principal components that represent the SFB samples. Second, KNN, DT, SVM, and BP analyses were then employed on the principal component data to determine the grade of the SFB samples. Finally, a price prediction model based on SPCA+BP was established to objectively evaluate the quality and price of SFB. The experimental results show that the proposed method can effectively realize the distinction and price prediction of SFB.},
  archive      = {J_IJPRAI},
  author       = {Mingju Chen and Anle Cui and Zhengxu Duan and Xingzhong Xiong},
  doi          = {10.1142/S0218001423590164},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2359016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Evaluation quality of chinese baijiu using GC–MS based on SPCA and neural network},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 3D PET/CT tumor co-segmentation based on background
subtraction hybrid active contour model. <em>IJPRAI</em>,
<em>37</em>(8), 2357006. (<a
href="https://doi.org/10.1142/S0218001423570069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate tumor segmentation in medical images plays an important role in clinical diagnosis and disease analysis. However, medical images usually have great complexity, such as low contrast of computed tomography (CT) or low spatial resolution of positron emission tomography (PET). In the actual radiotherapy plan, multimodal imaging technology, such as PET/CT, is often used. PET images provide basic metabolic information and CT images provide anatomical details. In this paper, we propose a 3D PET/CT tumor co-segmentation framework based on active contour model. First, a new edge stop function (ESF) based on PET image and CT image is defined, which combines the grayscale standard deviation information of the image and is more effective for blurry medical image edges. Second, we propose a background subtraction model to solve the problem of uneven grayscale level in medical images. Apart from that, the calculation format adopts the level set algorithm based on the additive operator splitting (AOS) format. The solution is unconditionally stable and eliminates the dependence on time step size. Experimental results on a dataset of 50 pairs of PET/CT images of non-small cell lung cancer patients show that the proposed method has a good performance for tumor segmentation.},
  archive      = {J_IJPRAI},
  author       = {Laquan Li and Chuangbo Jiang and Patrick Shen-Pei Wang and Shenhai Zheng},
  doi          = {10.1142/S0218001423570069},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2357006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {3D PET/CT tumor co-segmentation based on background subtraction hybrid active contour model},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-angle models and lightweight unbiased decoding-based
algorithm for human pose estimation. <em>IJPRAI</em>, <em>37</em>(8),
2356014. (<a href="https://doi.org/10.1142/S0218001423560141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When a top-down method is taken to the task of human pose estimation, the accuracy of joint point localization is often limited by the accuracy of human detection. In addition, conventional algorithms commonly encode the image to generate a heat map before processing, but the systematic error in decoding the heat map back to the original image has an impact on the positioning. Therefore, to address the two problems, we propose an algorithm that uses multiple angle models to generate the human boxes and then performs lightweight decoding to recover the image. The new boxes can better fit humans and the recovery error can be reduced. First, we split the backbone network into three sub-networks, the first sub-network is responsible for generating the original human box, the second sub-network is responsible for generating a coarse pose estimation in the boxes, and the third sub-network is responsible for a high-precision pose estimation. In order to make the human box fit the human body better, with only a small number of interfering pixels inside the box, models of the human boxes with multiple rotation angles are generated. The results from the second sub-network are used to select the best human box. Using this human box as input to the third sub-network can significantly improve the accuracy of the pose estimation. Then to reduce the errors arising from image decoding, we propose a lightweight unbiased decoding strategy that differs from traditional methods by combining multiple possible offsets to select the direction and size of the final offset. On the MPII dataset and the COCO dataset, we compare the proposed algorithm with 11 state-of-the-art algorithms. The experimental results show that the algorithm achieves a large improvement in accuracy for a wide range of image sizes and different metrics.},
  archive      = {J_IJPRAI},
  author       = {Jianghai He and Weitong Zhang and Ronghua Shang and Jie Feng and Licheng Jiao},
  doi          = {10.1142/S0218001423560141},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2356014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-angle models and lightweight unbiased decoding-based algorithm for human pose estimation},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CLS-net: An action recognition algorithm based on
channel-temporal information modeling. <em>IJPRAI</em>, <em>37</em>(8),
2356011. (<a href="https://doi.org/10.1142/S0218001423560116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The modeling of channel and temporal information is of crucial importance for action recognition tasks. To build a high-performance action recognition network by effectively capturing channel and temporal information, we propose CLS-Net : an action recognition algorithm based on channel-temporal information modeling. The proposed CLS-Net characterizes channel and temporal information by inserting multiple modules to an end-to-end backbone network, including a channel attention module ( C A module) for modeling channel information, a long-term temporal module ( L T module) and a short-term temporal module ( S T module) for modeling temporal information. Specifically, the CA module extracts the correlation between feature channels so the network can learn to selectively strengthen the features containing useful information and suppress the useless features through global information. The LT module moves some channels in the temporal dimension to realize information interaction across time domains and model global temporal information. The ST module enhances the motion-sensitive features by calculating the feature-level frame difference information and realizes the representation of local motion information. Since the multi-module insertion mode directly affects the whole model’s final performance, we propose a novel multi-module insertion mode instead of a simple series or parallel connection to ensure that the multiple modules can complement one another and cooperate with each other more efficiently. CLS-Net achieves SOTA performance on the EgoGesture and Jester dataset in the same type of network and achieves competitive results on the Something-Something V2 dataset.},
  archive      = {J_IJPRAI},
  author       = {Mengfan Xue and Jiannan Zheng and Tao Li and Dongliang Peng},
  doi          = {10.1142/S0218001423560116},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2356011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {CLS-net: An action recognition algorithm based on channel-temporal information modeling},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Emotion recognition from facial expression using hybrid
CNN–LSTM network. <em>IJPRAI</em>, <em>37</em>(8), 2356008. (<a
href="https://doi.org/10.1142/S0218001423560086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial Expression Recognition (FER) is a prominent research area in Computer Vision and Artificial Intelligence that has been playing a crucial role in human–computer interaction. The existing FER system focuses on spatial features for identifying the emotion, which suffers when recognizing emotions from a dynamic sequence of facial expressions in real time. Deep learning techniques based on the fusion of convolutional neural networks (CNN) and long short-term memory (LSTM) are presented in this paper for recognizing emotion and identifying the relationship between the sequence of facial expressions. In this approach, a hyperparameter tweaked VGG-19 skeleton is employed to extract the spatial features automatically from a sequence of images, which avoids the shortcoming of the conventional feature extraction methods. Second, these features are given into bidirectional LSTM (Bi-LSTM) for extracting spatiotemporal features of time series in two directions, which recognize emotion from a sequence of expressions. The proposed method’s performance is evaluated using the CK+ benchmark as well as an in-house dataset captured from the designed IoT kit. Finally, this approach has been verified through hold-out cross-validation techniques. The proposed techniques show an accuracy of 0.92% on CK+, and 0.84% on the in-house dataset. The experimental results reveal that the proposed method outperforms compared to baseline methods and state-of-the-art approaches. Furthermore, precision, recall, F 1-score, and ROC curve metrics have been used to evaluate the performance of the proposed system.},
  archive      = {J_IJPRAI},
  author       = {M. Mohana and P. Subashini and M. Krishnaveni},
  doi          = {10.1142/S0218001423560086},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2356008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Emotion recognition from facial expression using hybrid CNN–LSTM network},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-modal interaction network for video moment retrieval.
<em>IJPRAI</em>, <em>37</em>(8), 2355010. (<a
href="https://doi.org/10.1142/S0218001423550108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The video moment retrieval task aims to fetch a target moment in an untrimmed video, which best matches the semantics of a sentence query. Existing methods mainly focus on utilizing two separate modules: one learns intra-modal relations to understand video and query contents, and the other explores inter-modal interactions to build a semantic bridge between video and language. However, intra-modal relations information can be easily overlooked when capturing inter-modal interactions. In fact, intra-modal relations and inter-modal interactions can be learned simultaneously within a unified module to make video and sentence guide each other. Towards this end, we propose a Cross-Modal Interaction Network (CMIN) for video moment retrieval by jointly exploring the intra-modal relations and inter-modal interactions between video frames and query words. In CMIN, a query-guided channel attention module is designed to suppress query-irrelevant visual features and enhance crucial contents; then a cross-attention module simultaneously considers intra-modal relations within each modality and fine-grained inter-modal interactions between frames and words, to enhance the semantic relevance between video and sentence query. Compared to the state-of-the-art methods, the experiments on two public datasets (Charades-STA and TACoS) demonstrate the superiority of our method.},
  archive      = {J_IJPRAI},
  author       = {Shen Ping and Xiao Jiang and Zean Tian and Ronghui Cao and Weiming Chi and Shenghong Yang},
  doi          = {10.1142/S0218001423550108},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2355010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Cross-modal interaction network for video moment retrieval},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Research on defect detection method of nonwoven fabric mask
based on machine vision. <em>IJPRAI</em>, <em>37</em>(8), 2355008. (<a
href="https://doi.org/10.1142/S021800142355008X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the production, transportation and storage of nonwoven fabric mask, there are many damages caused by human or nonhuman factors. Therefore, checking the defects of nonwoven fabric mask in a timely manner to ensure the reliability and integrity, which plays a positive role in the safe use of nonwoven fabric mask. At present, the wide application of machine vision technology provides a technical mean for the defect detection of nonwoven fabric mask. On the basis of the pre-treatment of the defect images, it can effectively simulate the contour fluctuation grading and gray value change of the defect images, which is helpful to realize the segmentation, classification and recognition of nonwoven fabric mask defect features. First, in order to accurately obtain the image information of the nonwoven fabric mask, the binocular vision calibration method of the defect detection system is discussed. On this basis, the defect detection mechanism of the nonwoven fabric mask is analyzed, and the model of image processing based on spatial domain and Hough transform is established, respectively. The original image of the nonwoven fabric mask is processed by region processing and edge extraction. Second, the defect detection algorithm of nonwoven fabric mask is established and the detection process is designed. Finally, a fast defect detection system for nonwoven fabric mask is designed, and the effectiveness of the detection method for nonwoven fabric mask is analyzed with an example. The results show that this detection method has positive engineering significance for improving the detection efficiency of defects in nonwoven fabric mask.},
  archive      = {J_IJPRAI},
  author       = {Jingde Huang and Zhangyu Huang and Xin Zhan},
  doi          = {10.1142/S021800142355008X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2355008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Research on defect detection method of nonwoven fabric mask based on machine vision},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid method for enhancement of both contrast distorted
and low-light images. <em>IJPRAI</em>, <em>37</em>(8), 2354012. (<a
href="https://doi.org/10.1142/S0218001423540125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many different histogram equalization (HE)-based image enhancement methods have been developed to overcome the problems of low or high image brightness, contrast sensitivity, and difficulty in revealing details of dark areas under low-light environments. In this paper, a novel image enhancement method based on HE and adaptive gamma correction with weight distribution (AGCWD) is proposed for natural and effective image enhancement. In this method, histogram stretching is performed on Red–Green–Blue (RGB) color components of image, and then the color space of RGB image is converted to Hue–Saturation–Intensity (HSI) color space. The histograms of S and I components are divided into sub-histograms according to the exposure threshold. The underexposure regions are enhanced with a new AGCWD. Then, the color space of HSI image is converted to RGB color space. Finally, the HE is applied to the input image with the obtained image histogram map. Thus, the method has not only effectively prevented the over-enhancement of the contrast but also obtained the quality and natural enhanced image. The proposed method is compared with the most known contrast enhancement methods and low-light enhancement methods. Experimental results have supported that the proposed method outperforms other methods in terms of both visual perception and objective evaluation.},
  archive      = {J_IJPRAI},
  author       = {Nurullah Ozturk and Serkan Ozturk},
  doi          = {10.1142/S0218001423540125},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2354012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A hybrid method for enhancement of both contrast distorted and low-light images},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Image resizing for object detection: A learnable
downsampler–upsampler pair with differentiable image entropy estimation.
<em>IJPRAI</em>, <em>37</em>(8), 2354011. (<a
href="https://doi.org/10.1142/S0218001423540113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, super-resolution neural networks have achieved good results in restoring super-resolution images from low-resolution ones. However, most subsequent tasks based on super-resolution images such as object detection are done by the computer. Considering this situation, we propose a learnable downsampler–upsampler pair, which can realize both the downscaling process and the upscaling process by neural networks, and is jointly trained with the YOLOV5 network to optimize the object detection task. Thus, different from existing super-resolution networks, the entire downsampler–upsampler pair is optimized for machine perception. In addition, to further reduce the size of the downsampled images, we also propose a differentiable method for estimating image entropy and add it to the loss function. We verify the effectiveness of our method on the pothole dataset and use scale factors 2× and 4× to prove that our method is capable of diverse resizing levels. The experimental results show that using our learnable downsampler–upsampler pair as a resizing method can highly improve the detection performance compared with other resizing techniques.},
  archive      = {J_IJPRAI},
  author       = {Chengjie Dai and Qiang Chen and Jingchao Xu and Hanshen Gong and Guanghua Song and Bowei Yang},
  doi          = {10.1142/S0218001423540113},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2354011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Image resizing for object detection: A learnable Downsampler–Upsampler pair with differentiable image entropy estimation},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Energy-saving strategy based on image super-resolution for
wireless image sensor networks assisted by cloud. <em>IJPRAI</em>,
<em>37</em>(8), 2354010. (<a
href="https://doi.org/10.1142/S0218001423540101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless image sensor networks (WISNs) collect surveillance images, resulting in copious quantities of data requiring processing and transmission within the network. To reduce and balance energy expenditure during in-network image data processing and transmission, this study introduces an energy-saving strategy based on image super-resolution for WISNs assisted by cloud. The strategy constructs an image data processing and transmission system for WISNs, leveraging cloud infrastructure. By utilizing image quality feedback, the adaptive adjustment of image node sensing resolution is facilitated, minimizing image data transmission volume while ensuring high-quality super-resolution reconstructed image. The establishment of low-overhead, multipath transmission routes enables image nodes to transmit data in blocks, contingent upon neighboring transmission node statuses, thereby equalizing energy consumption for image data transmission. Cloud servers are employed to reconstruct high-resolution images and provide users with surveillance images that satisfy quality requisites. Empirical findings demonstrate that the proposed approach extends the lifetime of WISNs, furnishes users with superior-quality surveillance images, and markedly enhances network monitoring efficacy.},
  archive      = {J_IJPRAI},
  author       = {Yalin Nie and Lei Gong and Zeyu Sun},
  doi          = {10.1142/S0218001423540101},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2354010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Energy-saving strategy based on image super-resolution for wireless image sensor networks assisted by cloud},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nondestructive detection of coal–rock interface under mining
environment using ground penetrating radar image. <em>IJPRAI</em>,
<em>37</em>(8), 2354009. (<a
href="https://doi.org/10.1142/S0218001423540095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shearer drum automatic height adjustment strategy under mining environment is based on the recognition of coal–rock interface and the ground penetrating radar (GPR) was used for coal–rock interface recognition in the study. First, a model was built to study the radar echo in complex coal seam and some simulations were made to study the influence of radar parameters. Second, the experiment study was implemented in the coal mine working face in Tengzhou city, Shandong province, China. In this study, it was applied for radar image creation, including the start time correction, filtering technique, Hilbert transform, A-scan, and B-scan. The support vector machine (SVM) method was used for searching the coal–rock interface echo in lots of waveforms. The coal–rock interface could be found clearly and intuitively in the radar images by the above method in unknown complex coal seam structure and the error is less than 2% in A-scan mode. The results show that the method can stably and reliably find the coal–rock interface even in dynamic scenarios with the accuracy of 95%, where the root mean square error (RMSE) is and the 0.1. The radar antenna can be fixed to the shearer rocker arm in real time during mining to detect the thickness of coal seam in looking-ahead, top/bottom and shear moving direction.},
  archive      = {J_IJPRAI},
  author       = {Xin Wang and Duan Zhao and Yikun Wang},
  doi          = {10.1142/S0218001423540095},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2354009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Nondestructive detection of Coal–Rock interface under mining environment using ground penetrating radar image},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integration of deep direction distribution feature
extraction and optimized attention based double hidden layer GRNN models
for robust cursive handwriting recognition. <em>IJPRAI</em>,
<em>37</em>(8), 2350019. (<a
href="https://doi.org/10.1142/S0218001423500192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cursive handwriting recognition (CHWR) is an interesting area of research as it has a wide range of applications but lacks an accurate approach to provide better results due to its character shapes, the non-uniform spacing between words and within a word, diverse placements of dots, and diacritics, and very low inter-class variation among individual classes. A novel CHWR model is proposed to enhance the recognition accuracy with high global stability. The proposed model introduces three major phases: pre-processing, feature extraction and classification. In the pre-processing stage, the noise removal and binarization are adapted with the intrusion of improved adaptive wiener filtering (IAWF) and structural symmetric pixels. A hybrid deep direction distribution feature extraction (HDDDFE) approach is proposed to extract directional Local gradient histogram (LGH), column gradient histogram (CGH) features and a wavelet convolutional neural network with Block Attention Module (WCNN-BAM) is proposed to extract deep global features (GF), profile features (PF) and dynamic features (DF). A novel double hidden layer gated recurrent neural network with a feature attention mechanism (ODHL-GRNN-FAM) is proposed to offer handwritten classification results. The developed model is evaluated with the IAM database and attains an overall recognition accuracy of 98%, precision of 97%, f-measure of 97.99%, character error rate (CER) of 1.23%, word error rate (WER) of 4.8%, respectively.},
  archive      = {J_IJPRAI},
  author       = {D. Manibharathi and C. Vasanthanayaki},
  doi          = {10.1142/S0218001423500192},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2350019},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Integration of deep direction distribution feature extraction and optimized attention based double hidden layer GRNN models for robust cursive handwriting recognition},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent control knowledge-based system for cleaning
device of rice–wheat combine harvester. <em>IJPRAI</em>, <em>37</em>(7),
2359015. (<a href="https://doi.org/10.1142/S0218001423590152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the operation process of cleaning of intelligent rice–wheat combine harvester is divided into two key steps: initial setting of cleaning device operation parameters and dynamic control of cleaning device operation parameters. Combined with the operation experience of cleaning control of agricultural machinery operators, the dynamic control knowledge-based system of cleaning device operation parameters was built based on production rule reasoning. The cleaning device of the rice–wheat combine harvester is intelligently controlled based on the dynamic monitoring and control system of the cleaning device operation quality and operation parameters, so as to achieve the purpose of controlling the cleaning operation quality of the rice–wheat combine harvester in the normal range. Through the field experiment results and analysis, it is proved that the intelligent control system of the cleaning device operation parameters based on the dynamic control knowledge-based system of cleaning device operation parameters can effectively keep the cleaning impurity content and loss rate of intelligent rice–wheat combine harvester in the normal range, so as to verify the effectiveness of the intelligent control knowledge-based system of the cleaning device operation parameters.},
  archive      = {J_IJPRAI},
  author       = {Qing Jiang and Yang Liu and Xiancun Zhou and Yadong Yang and Jing Zhang and Bin Jiang and Demei Mao and Yang Yang and Yuan Fu},
  doi          = {10.1142/S0218001423590152},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2359015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Intelligent control knowledge-based system for cleaning device of Rice–Wheat combine harvester},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A framework for distributed feature selection.
<em>IJPRAI</em>, <em>37</em>(7), 2359014. (<a
href="https://doi.org/10.1142/S0218001423590140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many current multivariate filter feature selection approaches consider redundancy and relevance between features and class vectors simultaneously. However, these multivariate filter algorithms calculate the suitability of features by only the intrinsic characteristics of the data. In this paper, we suggest a new distributed framework to offset the multivariate feature selection problem. We propose the interaction with classifiers in multivariate filter feature selection. Our proposed framework calculates the relevance of each feature to class labels by embedded algorithms. Then, this technique examines redundancy among features through multivariate filter algorithms. In addition, in the proposed framework, we use horizontal distribution of data instead of using all them once. This approach reduces the runtime of the process in datasets with many samples and environments without centralized data. The results of the evaluation show that the proposed framework can improve classification accuracy compared with the methods just based on multivariate filters. In addition, the experimental results demonstrate that our algorithm outperforms compared approaches in precision, recall, and runtime.},
  archive      = {J_IJPRAI},
  author       = {Mona Sharifnezhad and Mohsen Rahmani and Hossein Ghaffarian},
  doi          = {10.1142/S0218001423590140},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2359014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A framework for distributed feature selection},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Home-based real-time abnormal movement detection system
deployed on on-device artificial intelligence. <em>IJPRAI</em>,
<em>37</em>(7), 2359012. (<a
href="https://doi.org/10.1142/S0218001423590127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the aging trend in society and to Human Augmentation beings for home-based activities, this paper proposes an Abnormal Movement Detection system, using the common at-home movements of standing up and hand tremors while picking up items for abnormal movement verification. This can be easily applied in ordinary homes or long-term care institutions; for those living alone with limited resources, there is no longer any need to purchase expensive monitoring equipment to achieve improved quality of life. Therefore, this research collected and built the own dataset as the first important step of the study. The proposed Abnormal Movement Detection system is implemented by designing a deep learning network. Several issues, including the network architecture, the novel method of data augmentation and the scoring method of expanding the intervals between abnormality levels, are studied. For achieving the home-based real-time detection, there are four main contributions of this paper. The first is that a training dataset was collected and established: From this, the pathognomonic movement categories are easy to observe in home activities and geometric data augmentation can be used to improve the related home activity video collection. The second is the abnormal behavior detection architecture: This architecture has several important function blocks including detecting object, detecting action, inspecting abnormal movement and reminding event, using Convolutional Neural Network combined with Long Short-Term Memory ( CNN + LSTM ) as the core network for abnormal motion detection. With movement abnormality evaluation based on different levels, it can judge abnormal behaviors and conduct model training, performance evaluation and architecture optimization with both public domain datasets and the movement dataset collected in this research project. The third is the proliferation of new attributes in the videos: New attributes are added to the original videos through a Generative Adversarial Network (GAN), producing new training videos; the effectiveness of two different generation methods is evaluated. Finally, the algorithms developed in this paper are deployed on resource-constrained On-device Artificial Intelligence (AI). Activity videos from a total of 20 people were collected; in all, 53 videos of StandUp and 60 videos of PickUpItems were obtained to establish the training dataset. When CNN and LSTM network were added to Batch Normalization (BN), and Global Average Pooling (GAP) replaced Fully Connected (FC) layers, the accuracy rate reached 98.4%. In terms of data augmentation, geometric transformations and GAN were used to estimate the performance. The experimental results showed that the geometric transformation using brightness adjustment had the highest accuracy rate of 98.6%. Finally, the Softmax layer using Phi-Softmax–tan(⋅) function was shown to be the best method to expand the intervals between abnormality levels.},
  archive      = {J_IJPRAI},
  author       = {Li-Hong Yan and Chiao-Wen Kao and Bor-Jiunn Hwang and Hui-Hui Chen and Hui-Chia Huang},
  doi          = {10.1142/S0218001423590127},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2359012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Home-based real-time abnormal movement detection system deployed on on-device artificial intelligence},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Noise reduction method of pipeline infrasonic leakage signal
based on improved prony algorithm and difference energy model.
<em>IJPRAI</em>, <em>37</em>(7), 2358006. (<a
href="https://doi.org/10.1142/S0218001423580065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve the difficult problem of low-frequency noise processing in pipeline infrasonic leakage detection signals, a pipeline infrasonic leakage signal denoising method based on improved Prony algorithm and differential energy model was proposed to reduce the low-frequency interference noise in the signal and to improve the signal denoising effect. First, the frequency window of the effective signal is obtained according to the spectrogram of the infrasound signal. Aiming at the problem that the Prony algorithm is affected by noise, a difference energy model is proposed. The difference energy model is used to filter out the part of the frequency domain signal with large energy fluctuation, and a relatively stable preprocessing signal is obtained. In view of the instability of the traditional Prony algorithm, a Hankel matrix is established in the operation process. The stability is improved by extracting the extremum and residue of the signal instead of directly solving the sampling data points, and the extremum and residue of the effective signal are selected by combining the frequency window of the active ingredient. Finally, the effective signal is reconstructed to obtain a relatively stable infrasound leakage noise reduction signal. Experimental results show that the noise reduction technology based on the improved Prony algorithm and differential energy model can effectively reduce the noise of pipeline leakage signals. Compared with the traditional Prony algorithm, the noise reduction effect of the proposed method is up to 38.01% higher. Compared with the empirical mode decomposition method, the noise reduction effect of this method is improved by 9.25% at least, which opens up a new idea for pipeline leakage signal noise reduction.},
  archive      = {J_IJPRAI},
  author       = {Min Li and Yongmei Hao and Zhixiang Xing and Qiang Yao and Xu Ning},
  doi          = {10.1142/S0218001423580065},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2358006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Noise reduction method of pipeline infrasonic leakage signal based on improved prony algorithm and difference energy model},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A study on the application of sentiment-support words on
aspect-based sentiment analysis. <em>IJPRAI</em>, <em>37</em>(7),
2357004. (<a href="https://doi.org/10.1142/S0218001423570045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment classification is currently an important research direction to identify the sentiment expressed by sentences in different aspects. The primary approach for performing aspect-level sentiment analysis involves extracting both grammatical and semantic information. However, analyzing the grammatical connection between aspect words and other words within a review sentence using morphological features like part of speech can be exceedingly complex. This paper proposes the concept of sentiment-supporting words, dividing sentences into aspectual words, sentiment-supporting words and non-sentiment-supporting words, which simplifies the core task of sentiment analysis. Three rules are designed for determining the “sentiment-support words” of the text in different aspects. Subsequently, the application of sentiment-support words in sentiment analysis models is given, and five classical sentiment analysis models are improved accordingly. According to the experimental outcomes on two publicly available datasets, the “sentiment-support words” and corresponding sentiment support rules proposed in this paper are capable of significantly enhancing aspect-based sentiment analysis.},
  archive      = {J_IJPRAI},
  author       = {Lei Jiang and Ziwei Zou and Jing Liao and Yuan Li},
  doi          = {10.1142/S0218001423570045},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2357004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A study on the application of sentiment-support words on aspect-based sentiment analysis},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Echo state network-enabled intelligent smart sensor design
for creating a robotic nervous system. <em>IJPRAI</em>, <em>37</em>(7),
2356010. (<a href="https://doi.org/10.1142/S0218001423560104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: The echo states that networks in the Internet of Things (IoT) are currently being implemented in the widest sense. Echo state networks are fast and efficient recurrent neural networks. This consists of an input layer, a reservoir with many sparsely connected neurons, and an output layer. Issues: In the existing wireless sensor networks, strong mobility may disrupt an existing link between two communicating nodes. There is an inconvenience in data communication, and then it searches for a new node to build a better connection. Methods: To overcome these issues, the recently introduced echo state network (ESN) model opened the way to an extremely efficient approach for designing neural networks for temporal data. The study focuses on the ESN-enabled Intelligent Smart Sensor Design (IS2D) for creating the robotic nervous system with a smart healthcare Digital Nervous System (DNS) using the techniques of IoT, DNS, and Smart Sensor Design and Strain Sensor Fabrication (SSF). Results: Experimental results demonstrate the training set testing against the IS2D, the confusion matrix for ESN outcome, the real-time healthcare monitoring for the DNS, the IS2D sensor accuracy, and the DNS intensity calculation. Discussion: The performance analysis of the proposed model in realistic environments attests to the benefits of energy-centric metrics such as energy consumption, network lifetime, delay, and throughput. Finally, we discuss the challenges and opportunities by summarizing the study and proposing possible future works. The training set testing against the IS2D is based on time count, and the voltage result is estimated. The first portion of the data set should be 11.46% at the initial level. Further, this will increase from 1% to 5%, from 6% to 10%, and from 16% to 28% at the consecutive data set. The confusion matrix for ESN outcome is based on accuracy 28.45% higher than the existing strategies. In this part, the initial accuracy is 8.45% while accessing the initial stage. This value should increase with consecutive data sets from 18.45% to 28.45%.},
  archive      = {J_IJPRAI},
  author       = {Dawei Ye and Bingxin Cao and Weiping Zhou},
  doi          = {10.1142/S0218001423560104},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2356010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Echo state network-enabled intelligent smart sensor design for creating a robotic nervous system},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vision-based global localization of points of gaze in sport
climbing. <em>IJPRAI</em>, <em>37</em>(7), 2355005. (<a
href="https://doi.org/10.1142/S0218001423550054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Investigating realistic visual exploration is quite challenging in sport climbing, but it promises a deeper understanding of how performers adjust their perception-action couplings during task completion. However, the samples of participants and the number of trials analyzed in such experiments are often reduced to a minimum because of the time-consuming treatments of the eye-tracking data. Notably, mapping successive points of gaze from local views to the global scene is generally performed manually by watching eye-tracking video data frame by frame. This manual procedure is not suitable for processing a large number of datasets. Consequently, this study developed an automatic method for solving this global point of gaze localization in indoor sport climbing. Particularly, an eye-tracking device was used for acquiring local image frames and points of gaze from a climber’s local views. Artificial landmarks, designed as four-color-disk groups, were distributed on the wall to facilitate localization. Global points of gaze were computed based on planar homography transforms between the local and global positions of the detected landmarks. Thirty climbing trials were recorded and processed by the proposed methods. The success rates (Mean ± SD) were up to 85.72% ± 13.90%, and the errors (Mean ± SD) were up to 0 . 1 3 0 2 ± 0 . 2 0 5 1 m. The proposed method will be employed for computing global points of gaze in our current climbing dataset for understanding the dynamics intertwining of gaze and motor behaviors during the climbs.},
  archive      = {J_IJPRAI},
  author       = {Tan-Nhu Nguyen and Ludovic Seifert and Guillaume Hacques and Maroua Hammami Kölbl and Youssef Chahir},
  doi          = {10.1142/S0218001423550054},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2355005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Vision-based global localization of points of gaze in sport climbing},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The lightweight count system of intensive jellyfish based on
deep learning. <em>IJPRAI</em>, <em>37</em>(7), 2352011. (<a
href="https://doi.org/10.1142/S0218001423520110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The number of jellyfish outbreaks is on the rise around the world, and they have been considered a serious ecological disaster. As part of the emergency response plan for jellyfish disasters, in-situ detection research that can distinguish jellyfish species and quantities is urgently required to support accurate data collection. As a typical fully supervised regression task, counting is usually regarded as requiring a large number of labeled datasets in conventional counting methods. To treat counting as a few-shot regression task that is semi-supervised, a novel adaptation strategy based on deep learning is presented in this paper. The method combines the test image with several example objects from the test image and takes advantage of the strong similarities present in the test image and the example objects contained in the image. Effective counting can be achieved without training the target object. Prediction of the density map of the test image’s objects of interest is the objective of the test. This method has been shown to be more robust than the method of detection first and counting later, and its accuracy can exceed 95%.},
  archive      = {J_IJPRAI},
  author       = {Yun Jin and Haidong Zhang and Jiaxin Li and Weihong Bi},
  doi          = {10.1142/S0218001423520110},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2352011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {The lightweight count system of intensive jellyfish based on deep learning},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A robust framework for severity detection of knee
osteoarthritis using an efficient deep learning model. <em>IJPRAI</em>,
<em>37</em>(7), 2352010. (<a
href="https://doi.org/10.1142/S0218001423520109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the changing lifestyle, a large population suffers from a bone disease known as an osteoarthritis affecting the knee, spine, and hip. Therefore, timely detection and classification of the disease are necessary to minimize the loss, however, it is a time-consuming task and requires various tests and physicians’ in-depth analysis. Thus, an accurate automated technique, timely detection and classification are needed to cope with the aforementioned challenges. This study proposes a technique based on an efficient DenseNet that uses the knee image’ features to identify the Knee Osteoarthritis (KOA) and determine its severity level according to the KL grading system such as Grade-I, Grade-II, Grade-III, and Grade-IV. We introduced the reweighted cross-entropy loss function which makes our proposed algorithm more robust as the training data is imbalanced. The dense connections of efficient DenseNet with regularization power help to reduce the overfitting during the training of small knee sample training sets. The proposed algorithm is an efficient approach that can identify the early symptoms of KOA and classify the severity level of the disease for better decision making by orthopedics. The algorithm is a pre-trained network that does not require a huge training set, therefore, the existing dataset i.e. Mendeley VI has been utilized for the training and testing. Additionally, cross-validation has been employed using the OAI dataset to assess the performance of the proposed model. The algorithm achieved 98.22% accuracy over the testing set and 98.08% accuracy over cross-validation. Various experiments have been performed to confirm that our proposed algorithm is more consistent and capable of detecting and classifying the KOA disease than existing state of the art.},
  archive      = {J_IJPRAI},
  author       = {Rabbia Mahum and Aun Irtaza and Mohammed A. El-Meligy and Mohamed Sharaf and Iskander Tlili and Saamia Butt and Asad Mahmood and Muhammad Awais},
  doi          = {10.1142/S0218001423520109},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2352010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A robust framework for severity detection of knee osteoarthritis using an efficient deep learning model},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Key–value pair identification from tables using multimodal
learning. <em>IJPRAI</em>, <em>37</em>(7), 2352009. (<a
href="https://doi.org/10.1142/S0218001423520092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer vision and optical character recognition techniques have rapidly advanced in order to accurately capture text and other features from paper documents. While state-of-the-art tools in these fields now yield high accuracy, analyzing their outputs requires more research. Since tables are common in such documents, a new pipeline, based on multimodal learning, is proposed to better extract key–value pairs from tables. Its performance is evaluated with a synthetically generated dataset with randomly generated tables and a dataset of mechanical part documents provided by SiliconExpert Technologies. Its performance is also compared with another state-of-the-art model built for similar tasks, LayoutLM. The proposed pipeline provides a fully automated, end-to-end scalable solution, beginning with image processing and computer vision components to a machine learning model that uses data from optical character recognition and natural language processing to make the final decisions. In the best configuration, the pipeline achieved a 96.26% accuracy on a large, synthetically generated training and test set. When comparing the proposed pipeline with LayoutLM, the proposed pipeline performed similarly on the synthetic dataset and better on the real dataset. These results show the potential of the multimodal approach in extracting key–value pairs from tables from real paper documents.},
  archive      = {J_IJPRAI},
  author       = {Jung Soo Chu and Bryan Pyo and Vik Parth and Ahmed Hussein and Patrick Wang},
  doi          = {10.1142/S0218001423520092},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2352009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Key–Value pair identification from tables using multimodal learning},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of photovoltaic output power based on match
degree and entropy weight method. <em>IJPRAI</em>, <em>37</em>(7),
2350018. (<a href="https://doi.org/10.1142/S0218001423500180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, an algorithm, which had combined the match degree and entropy weighting method, was proposed to predict the efficiency of the photovoltaic output power. First, the key characteristic quantities were selected by the correlation analyses of output power history data and meteorological data of the photovoltaic power generation system. Second, according to the Euclidean distances between the predicted points and the historical data points, a method for the selections of similar sample points was proposed based on point-to-point theory. Finally, the match degrees between each characteristic quantity of the prediction points and the similar sample points were determined using the Mamdani reasoning method in fuzzy mathematics. The fitting weighting was then solved using the entropy weighting method, which was applied to fit the match degrees of the same characteristic quantities between the similar sample points. Next, the correlation coefficients were utilized as the weighting to fit the match degrees of the different characteristic quantities, resulting in a total match degree. This total match degree was then used to fit the photovoltaic output power of the similar sample points to the prediction points. We had proven that this method could have effective predictions and good adaptabilities in various weather statuses with high accuracy and real-time performance, especially, in the case of sudden weather change.},
  archive      = {J_IJPRAI},
  author       = {Weiqiang Liao and Shixian Lin},
  doi          = {10.1142/S0218001423500180},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2350018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Prediction of photovoltaic output power based on match degree and entropy weight method},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ConNet: Designing a fast, efficient, and robust crowd
counting model through composite compression. <em>IJPRAI</em>,
<em>37</em>(7), 2350017. (<a
href="https://doi.org/10.1142/S0218001423500179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Counting the number of people in a specific area is crucial in maintaining proper crowd safety and management especially in highly-congested indoor scenarios. Recent convolutional neural network (CNN) approaches integrate auxiliary sub-networks to increase the accuracy of the model in estimating crowd size. However, these models require large computational costs due to additional calculations, resulting in an impractically slow inference speed for real-world applications. In this paper, we propose a fast, efficient, and robust crowd counting model called Condensed Network or ConNet. We utilize a composite technique composed of multiple compression methods to reduce the number of parameters of our proposed model. ConNet attains counting accuracy on par with state-of-the-art crowd counting methods on benchmark datasets featuring indoor scenes, while significantly reducing parameter count and increasing inference speed. Moreover, ConNet still performs accurately even with extreme changes in lighting conditions, image resolutions, and camera orientations. Our smallest model ConNet-04 has 61.0× less parameters and is at most 9.0× faster than the baseline approach. Our code and trained models are publicly available at https://github.com/mikatej/ConNet .},
  archive      = {J_IJPRAI},
  author       = {Regina Marie A. Masilang and Bianca Joy R. Benedictos and Mikayla M. Tejada and Giann Jericho Mari F. Marasigan and Arren Matthew C. Antioquia},
  doi          = {10.1142/S0218001423500179},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2350017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {ConNet: Designing a fast, efficient, and robust crowd counting model through composite compression},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient and accurate cross-domain object detection
method using one-level feature and domain adaptation. <em>IJPRAI</em>,
<em>37</em>(7), 2350016. (<a
href="https://doi.org/10.1142/S0218001423500167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the accuracy of cross-domain object detection, the existing unsupervised domain adaptation (UDA) object detection methods mostly use Feature Pyramid Network (FPN), multiple Region Proposal Network (RPN), and multiple domain classifier, but these methods lead to complex network structures, slow model convergence, and low detection efficiency. To solve the above problems, this paper proposes an Efficient and Accurate Cross-domain Object Detection Method Using One-level Feature and Domain Adaptation (OFDA). This method realizes one-level feature object detection through feature fusion and divide-and-conquer technology; realizes overfitting feature suppression and unsupervised domain adaptation through domain-specific suppression and domain feature alignment technology; realizes background feature suppression through the Objectness branch, which replaces the time-consuming Region Proposal Network (RPN) structure and improves the efficiency of unsupervised adaptive detection. The paper verifies the feasibility and superiority of the proposed method by the comparative experiments and ablation experiments of multiple datasets. The proposed OFDA method not only improves the efficiency of object detection, but also ensures the accuracy of cross-domain detection.},
  archive      = {J_IJPRAI},
  author       = {Tianyuan Zhang and Xudong Song and Chen Zhu and Pan Liang and Jialiang Sun and Shuo Wang and Yunxian Cui and Changxian Li},
  doi          = {10.1142/S0218001423500167},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2350016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An efficient and accurate cross-domain object detection method using one-level feature and domain adaptation},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Noncontact lie detection system involving
photoplethysmography and heart rate variability. <em>IJPRAI</em>,
<em>37</em>(7), 2350006. (<a
href="https://doi.org/10.1142/S0218001423500064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heart rate variability (HRV) has been used to determine whether patients have latent illnesses and as an assessment indicator of the autonomic nervous system. Studies have also employed HRV for lie detection, which is commonly performed in the law system. However, several studies have concluded that due to environmental and procedure-related problems, lie detectors may yield inconsistent results. This study used smart recognition technology and proposed a systemized method of lie detection. To verify the reliability of the noncontact lie detection approach, empirical lie detection studies were conducted and the relevant literature was searched for item selection techniques. This study employed a noncontact HRV lie detection system. By experimenting on 15 participants split into four groups, this study verified the reliability of using the physiological characteristic of HRV for lie detection.},
  archive      = {J_IJPRAI},
  author       = {Hung-Chang Chang},
  doi          = {10.1142/S0218001423500064},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2350006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Noncontact lie detection system involving photoplethysmography and heart rate variability},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A GRU-CNN algorithm leveraging on user reviews.
<em>IJPRAI</em>, <em>37</em>(6), 2359011. (<a
href="https://doi.org/10.1142/S0218001423590115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized recommendation systems learn user preference characteristics by analyzing behavioral data such as ratings and comments generated by users in the Internet, and provide precise recommendations for individual users accordingly. However, in real life, users often conduct group activities like group buying and traveling together. How to recommend for groups has become a heated research topic in recent years. Most existing group recommendation algorithms are recommended for given divided groups by collectively combining the preferences of members in the group. However, in most cases, users’ group properties are fickle. As the results of group detection are decisive to the performance of group recommendation, group detection is particularly important to the group recommendation algorithm. After analyzing problems of existing group recommendation algorithms, this paper proposes the density peak clustering group detection algorithm based on GRU-CNN and the group recommendation algorithm based on the mechanism. With respect to group detection, most of the existing group detection algorithms suffer from certain deficiencies: First, depending solely on the users’ static preference features while ignoring the variation of users’ interest over time when finding the group structure in the network; second, group division based on users’ topic features extracted from reviews is difficult to support further digging of the in-depth features in reviews. To address the above-mentioned problems, this paper proposes a density peak clustering group detection algorithm based on CNN-GRU. It would first extract representative keywords in the reviews with LDA topic model, and then model time series information based on GRU attaining users’ dynamic topic features. Coupling with deeper characteristics cored out by CNN, density peak clustering algorithm completes its group detection finally. Experiments on real dataset indicate that the features mined by the fusion depth neural network model effectively capture users’ dynamic preferences, and yield better results of group detection than that of existing algorithms.},
  archive      = {J_IJPRAI},
  author       = {Chao Chen and Yongsheng Xia and Zhaoli Wu and Yandong Liu and Xin Wang},
  doi          = {10.1142/S0218001423590115},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2359011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A GRU-CNN algorithm leveraging on user reviews},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analysis of the influence of grid-connected photovoltaic
power stations with virtual inertia on low-frequency oscillation of
power system based on small signal and prony analysis methods.
<em>IJPRAI</em>, <em>37</em>(6), 2358005. (<a
href="https://doi.org/10.1142/S0218001423580053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the virtual synchronous generator (VSG) technology gradually becoming an emerging technology for new energy consumption, its introduction has solved the problems of weak support and weak anti-interference of traditional new energy stations. However, the practice shows that the grid-connected characteristics of VSG limit its large-scale utilization, and there is little research on the interaction between VSG and a multi-machine system. In this paper, small signal models and time domain simulation models of each link of a photovoltaic(PV) power station with the PV virtual synchronous generator (PV-VSG) are first conducted, and then the influence of the grid-connected PV power station with the PV-VSG on the low-frequency oscillation of power system and its interaction mechanism with the multi-machine system are qualitatively obtained based on the small signal analysis method and prony analysis method from two dimensions of frequency domain and time domain, respectively. The analysis and simulation show that the PV power station based on VSG technology affects the dynamic characteristics of the system by changing the electromagnetic torque of each synchronous generator. Unreasonable operating conditions and parameter settings will aggravate the phenomenon of low-frequency oscillation of the system. Before the grid connection of PV power station, the operating parameters shall be reasonably set to ensure their safe and stable grid connection.},
  archive      = {J_IJPRAI},
  author       = {Shengyang Lu and Zhenhong Yan and Kaibo Zhang and Yu Zhu and Jinbo Yu and Meng Wu and Yan Lu and Dongqi Liu and Yuqiu Sui and Junyou Yang},
  doi          = {10.1142/S0218001423580053},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2358005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Analysis of the influence of grid-connected photovoltaic power stations with virtual inertia on low-frequency oscillation of power system based on small signal and prony analysis methods},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classification of COVID-19 patient based on multilayer
perceptron neural networks optimized with garra rufa fish optimization
using CT scan images. <em>IJPRAI</em>, <em>37</em>(6), 2357003. (<a
href="https://doi.org/10.1142/S0218001423570033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 is known in recent times as a severe syndrome of respiratory organ (Lungs) and has gradually produced pneumonia, a lung disorder all around the world. As coronavirus is continually spreading rapidly globally, the computed tomography (CT) technique has been made important and essential for quick diagnosis of this dangerous syndrome. Hence, it is necessitated to develop a precise computer-based technique for assisting medical clinicians in identifying the COVID-19 influenced patients with the help of CT scan images. Therefore, the multilayer perceptron neural networks optimized with Garra Rufa Fish optimization using images of CT scan is proposed in this paper for the classification of COVID-19 patients (COV-19-MPNN-GRF-CTI). The input images are taken from SARS-COV-2 CT-scan dataset. Initially, the input images are pre-processed utilizing convolutional auto-encoder (CAE) to enhance the quality of the input images by eliminating noises. The pre-processed images are fed to Residual Network (ResNet-50) for extracting the global and statistical features. The extraction over the features of CT scan images is made through ResNet-50 and subsequently input to multilayer perceptron neural networks (MPNN) for CT images classification as COVID-19 and Non-COVID-19 patients. Here, the layer of Batch Normalization of the MPNN is separated and added with ResNet-50 layer. Generally, MPNN classifier does not divulge any adoption of optimization approach for calculating the optimal parameters and accurately classifying the extracted features of CT images. The Garra Rufa Fish (GRF) optimization algorithm performs to optimize the weight parameters of MPNN classifiers. The proposed approach is executed in MATLAB. The performance metrics, such as sensitivity, precision, specificity, F -measure, accuracy and error rate, are examined. Then the performance of the proposed COV-19-MPNN-GRF-CTI method provides 22.08%, 24.03%, 34.76% higher accuracy, 23.34%, 26.45%, 34.44% higher precision, 33.98%, 21.95%, 34.78% lower error rate compared with the existing methods, like multi-task deep learning using CT image analysis for COVID-19 pneumonia classification and segmentation (COV-19-MDP-CTI), COVID-19 classification utilizing CT scan depending on meta-classifier approach (COV-19-SEMC-CTI) and deep learning-based COVID-19 prediction utilizing CT scan images (COV-19-CNN-CTI), respectively.},
  archive      = {J_IJPRAI},
  author       = {Vairaprakash Selvaraj and Manjunathan Alagarsamy and Dineshkumar Thangaraju and Dinesh Paramathi Mani},
  doi          = {10.1142/S0218001423570033},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2357003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Classification of COVID-19 patient based on multilayer perceptron neural networks optimized with garra rufa fish optimization using CT scan images},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Blockchain-based e-medical record and data security service
management based on IoMT resource. <em>IJPRAI</em>, <em>37</em>(6),
2357001. (<a href="https://doi.org/10.1142/S021800142357001X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electronic health records are essential and sensitive since they include vital information and are routinely exchanged across several parties, such as hospitals and private clinics. These data must remain accurate, current, secret, and available only to authorized parties. Integrating these data improves the accuracy and cost-effectiveness of the present health data administration framework. Electronic Medical Records (EMRs) are now kept utilizing the structure of the client/server via whom patient data information is maintained in the hospital. Multiple hospitals use the same database to track a single patient. These limitations prevent a custom health system from providing various associated experts and patients with a cohesive, integrated, secure, and confidential medical history. Modern healthcare systems are distinguished by their complexity and expense. However, this may be mitigated by enhanced health record management and Blockchain technology. The Blockchain’s data availability, confidence, and security characteristics have a bright future in healthcare services, giving solutions to the issues of the traditional customer/server architecture EMR management platform: intricacy, confidence, dependability, compatibility, and anonymity. An e-health record management based on Internet of Medical Things (EHRM-IoMT) is proposed in this paper. This paper explores and analyzes Blockchain efficiency and customer/server paradigms. The findings show that a patient-centred strategy may achieve remarkable success utilizing Blockchain. Moreover, the immutable and accurate data of persons in Blockchain may enable healthcare practitioners to better forecast and aid with diagnosis utilizing the IoMT via machine learning and artificial intelligence.},
  archive      = {J_IJPRAI},
  author       = {Mustafa Qahtan Alsudani and Mustafa Musa Jaber and R. Q. Malik and Sura Khalil Abd and Mohammed Hasan Ali and Ahmed Alkhayyat and G. A. Khalaf},
  doi          = {10.1142/S021800142357001X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2357001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Blockchain-based E-medical record and data security service management based on IoMT resource},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Low-quality face recognition using an index-based super
resolution technique. <em>IJPRAI</em>, <em>37</em>(6), 2356009. (<a
href="https://doi.org/10.1142/S0218001423560098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-quality face recognition (LQFR), unlike high-quality face recognition is very challenging. This is due to the standoff between the subject and the camera and small face size. The most common way to overcome the mentioned problems is using super-resolution (SR) techniques. In this paper, we show that the efficiency of a FR system degrades significantly in low-resolution images. We propose a novel FR approach using an index-based super-resolution method to improve performance and computational load of a FR system. To achieve this goal, first we apply face quality assessment (FQA) to select appropriate face images with high quality from sequence of images. Then, we introduce Blind/Reference-less Image Spatial Quality Evaluator (BRISQUE) as an index based on which we decided whether or not to use super-resolution in a LQFR system. We also conduct experiments to explore factors which affect FR performance including super-resolution methods, face image size (pixels), face quality and change of the sequence of the conventional LQFR stages. To demonstrate the efficiency of the proposed approach, we compare face identification rate on various deep CNN face recognition. Experimental results show that the proposed method increases the average identification rate to 71.20% on SCFace dataset.},
  archive      = {J_IJPRAI},
  author       = {Maryam Tahmasebi and Shahram Mohammadi and Hossein Hassanpoor},
  doi          = {10.1142/S0218001423560098},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2356009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Low-quality face recognition using an index-based super resolution technique},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatio-temporal video denoising based on attention
mechanism. <em>IJPRAI</em>, <em>37</em>(6), 2355006. (<a
href="https://doi.org/10.1142/S0218001423550066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The demands of high-quality videos captured by camera become bigger due to the rapid development of pattern recognition and artificial intelligence. Video denoising is the key technology to obtain clear videos. However, the research on video denoising is far from enough now. In this paper, we propose a video denoising method based on convolutional neural network architecture to reduce the noise from the sensor system. We improve the loss function of noise estimation by imposing adaptive penalty on under-estimation error of noise level which makes our method perform robustly. Furthermore, we make use of multi-level features to guide the spatial denoising, where multilayer semantic information of the image is regarded as the perceptual loss. Instead of relying on Optical Flow solving the characterization of inter-frame information, we utilize U-Net-like structure to handle motion implicitly. It is less computationally expensive and avoids distortions caused by inaccurate flow and object occlusion. In order to locate temporal features and suppress useless information, the attention mechanism is introduced to the skip connections of the U-Net-like structure. Experimental results demonstrate that the proposed algorithm outputs more convincing results in both peak signal-to-noise ratio (PSNR) and structural similarity index measure (SSIM) indexes when processing Gaussian noise, synthetic real noise, and real noise compared with selected approaches.},
  archive      = {J_IJPRAI},
  author       = {Kai Ji and Weimin Lei and Wei Zhang},
  doi          = {10.1142/S0218001423550066},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2355006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Spatio-temporal video denoising based on attention mechanism},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep-learning-based precision visual tracking.
<em>IJPRAI</em>, <em>37</em>(6), 2352008. (<a
href="https://doi.org/10.1142/S0218001423520080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we target the “precision visual tracking” problem, which is the precise tracking of a target point on a moving object. Compared with the abundant efforts in object-level tracking, which aims at accurately predicting the bounding box (or the mask) of the object, much less attention has been drawn to precision visual tracking. To this end, we present a template tracking framework that consists of two parts, template matching and template updating. For template matching, we trained a deep architecture to directly estimate the projective transformation that deforms the template to the search image. For template updating, we came up with a systematic strategy to update the initial and new templates. To avoid drift build-ups, we incorporate a fast-running dense correspondence matching module into the template update step. The proposed method was extensively tested on both synthetic and real data. To generate the synthetic data, we created a dataset of 480 image sequences. Each image sequence comes with the trajectory ground truth of a target point moving across all the frames. We compared the proposed method with six comparative approaches on this dataset. The tracking accuracy achieved by the proposed method was as follows: around 44% of the tracking errors were less than one pixel, about 78% of them were less than three pixels, and only about 14% of them exceeded five pixels. The proposed method is fast, running at 14 frames-per-second (fps) on 9 6 0 × 5 4 0 image sequences on a workstation equipped with a Nvidia RTX 2080Ti graphic card. Qualitative results also show that the proposed method is applicable to real-world image sequences. The related code, pre-trained models, and the test data will be made publicly available at https://github.com/XM-Peng/Precision-Visual-Tracking/ .},
  archive      = {J_IJPRAI},
  author       = {Xiaoming Peng and Zhiyong Xu and Xiang Ji and Yufan Peng and Jianlin Zhang and Haorui Zuo and Yuxing Wei},
  doi          = {10.1142/S0218001423520080},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2352008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Deep-learning-based precision visual tracking},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CRMNet: Development of a deep-learning-based anchor-free
detection method for illegal building objects. <em>IJPRAI</em>,
<em>37</em>(6), 2352007. (<a
href="https://doi.org/10.1142/S0218001423520079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Illegal construction poses a safety hazard to both cities and people and affects the social stability and long-term stability of the country. Therefore, it is important to detect illegal buildings as early as possible. However, current illegal building detection methods generally suffer from either detection cycles or low detection accuracies. To solve these challenges, this study adopts an unusual method that detects illegal building objects to prevent illegal building behavior. A detection model, CRMNet, which is based on the anchor-free detection model CenterNet, and dataset for illegal building objects are proposed. ResNet50 is selected as the backbone for extracting futures after weighing the computational cost and detection accuracy. Furthermore, Mish, a new activation function, is used to improve the identification accuracy of illegal building objects. Experimental results show that the mean average precision (mAP) of the proposed detector on the illegal building object dataset reached 88.16%, which is higher than that of other popular object detection methods. Additionally, in contrast to mainstream target detection methods, the proposed detection method has fewer parameters and a higher detection accuracy, which can be better applied to mobile devices and smart devices.},
  archive      = {J_IJPRAI},
  author       = {Lijuan Zhou and Wenjin Liu and Shudong Zhang and Ning Luo and Min Xu},
  doi          = {10.1142/S0218001423520079},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2352007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {CRMNet: Development of a deep-learning-based anchor-free detection method for illegal building objects},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Security evaluation method of smart home cloud platform.
<em>IJPRAI</em>, <em>37</em>(6), 2351012. (<a
href="https://doi.org/10.1142/S0218001423510126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of artificial intelligence of things (AIoT) is becoming increasingly widespread. With its rapid development, it has raised many complex network security issues. These have brought crushing security threats and risks to all stakeholders. AIoT cloud platform in the smart home plays a vital role in the security management of devices and is the current research hotspot. This paper discusses the security of the AIoT cloud platform, represented by the smart home. The indicator system describing the protection of the smart home cloud platform is proposed, and the security risk evaluation method of the cloud service is formed. Based on the evaluation method, a lightweight security evaluation framework for smart home cloud service is designed to evaluate the typical cloud platform’s security. The evaluation identifies some technical and administrative issues. Finally, to improve the security of the cloud console of AIoT and discover potential security risks in time, a security self-test model of the scalable cloud console is proposed.},
  archive      = {J_IJPRAI},
  author       = {Chensi Wu and Lulin Yang and Maobin Cai and Xiaoying Zhao and Qifeng Sun},
  doi          = {10.1142/S0218001423510126},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2351012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Security evaluation method of smart home cloud platform},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design and implementation of an intelligent searching robot
for radioactive sources based on edge computing. <em>IJPRAI</em>,
<em>37</em>(6), 2351005. (<a
href="https://doi.org/10.1142/S0218001423510059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the worldwide nuclear industry has developed vigorously. At the same time, incidents of radioactive source loss have also occurred frequently. At present, most of the search for radioactive sources uses manual search, which is inefficient and the search personnel are vulnerable to radiation damage. Sending the robot into the area where the uncontrolled radioactive source may be located for search is different. Not only the efficiency can be improved, but the personnel are also prevented from being exposed to radiation. Therefore, designing a radioactive source search robot has great practical significance. This paper mainly introduces the design and implementation of an intelligent search robot for radioactive sources based on edge computing, and intends to provide some ideas and directions for the research of intelligent robots for searching for radioactive sources. This paper proposes a research method for the design and implementation of a radioactive source intelligent search robot based on edge computing, including intelligent edge computing and gamma ray imaging algorithms, which are used to carry out related experiments on the design and implementation of a radioactive source intelligent search robot based on edge computing. The experimental results in this paper show that the average resolution of the radioactive source search robot is 90.55%, and the resolution results are more prominent.},
  archive      = {J_IJPRAI},
  author       = {Wei Zhang and Chao Shi and Lang Bai and Zhi Hui Zhang},
  doi          = {10.1142/S0218001423510059},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2351005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Design and implementation of an intelligent searching robot for radioactive sources based on edge computing},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive fusion risk-zone detection network and its
application. <em>IJPRAI</em>, <em>37</em>(6), 2350014. (<a
href="https://doi.org/10.1142/S0218001423500143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 has caused a pandemic and adverse effects in many fields on a global scale. The city scale quarantine has demonstrated its effectiveness in controlling the epidemic. Conversely, it is costly and risky in inducing economic and social challenges. A compromised solution is to place quarantine measures at high-risk zones on a local scale. Therefore, it is important to investigate risk zones for conducting cost insensitive precautionary measures. The urban data depict the characteristics of different city zones, which offers an opportunity for detecting the high-risk zones. Yet, the high noise-to-signal ratio requires an efficient procedure to rule out irrelevant information in the informative raw urban data and adapt to the risk detection task. In this paper, we propose an Adaptive Fusion Risk-zone Detection Network (AFRDN), which fuses the static and dynamic multi-sourced urban data in an adaptive manner. Specifically, AFRDN first extracts diverse information-rich features from raw urban data with various encoders in the embedding learning module. Then, the AFRDN takes a hierarchical late fusion strategy by fusing the static embedding and the attentive hidden state of dynamic features in the deep latent space. To capture the most relevant information for risk-zone detection, the AFRDN adapts each dimension in the fused embedding with multi-head self-attention blocks. We have collected a real-world dataset including six Chinese cities and conducted extensive experiments to evaluate our framework. Simulation experiments and comparative analysis results show that the AFRDN is effective and feasible for early detection of infectious diseases high-risk zones.},
  archive      = {J_IJPRAI},
  author       = {Junyi Ma and Xuanliang Wang and Yasha Wang and Xu Chu and Junfeng Zhao},
  doi          = {10.1142/S0218001423500143},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2350014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An adaptive fusion risk-zone detection network and its application},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel overlapping community detection algorithm combing
interest topic and local density. <em>IJPRAI</em>, <em>37</em>(6),
2350013. (<a href="https://doi.org/10.1142/S0218001423500131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ontology user portraits describe the semantic structure of users’ interests. It is very important to study the similar relationship between user portraits to find the communities with overlapping interests. The hierarchical characteristics of user interest can generate multiple similarity relations, which is conducive to the formation of interest clusters. This paper proposed a method of overlapping community detection combining the hierarchical characteristics of user interest and the module distribution entropy of node. First, a hierarchical user interest model was constructed based on the ontology knowledge base to measure the multi-granularity topic similarity of users. Then, a heterogeneous hypergraph was established by using the multi-granularity topic similarity and the following similarity of users to represent the interest network. Based on the mechanism of module distribution entropy of nodes, the community detection algorithm was applied to identify the interested community. The real performance of the proposed algorithm on multiple networks was verified by experiments. The experimental results show that the proposed algorithm is better than the typical overlapping community detection algorithm in terms of accuracy and recall rate.},
  archive      = {J_IJPRAI},
  author       = {Yanyan Chen and Pengfei Hou and Hui Li and Zixuan Yang and Ying Zheng and Juan Yang},
  doi          = {10.1142/S0218001423500131},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2350013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A novel overlapping community detection algorithm combing interest topic and local density},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improve session-based recommendation with triplet mining and
dynamic perturbations graph neural networks. <em>IJPRAI</em>,
<em>37</em>(6), 2350012. (<a
href="https://doi.org/10.1142/S021800142350012X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation (SBR) emphasizes mining user interests to predict the next click based on recent interactions within sessions. Most current SBR methods suffer from insufficient interactive information problems and fail to distinguish session representations with high similarities, which can neglect the inherent features within sessions. To fill the gap, we propose a triplet mining enhanced graph neural networks (TME-GNN) approach to enhance the recommendation systems by mining structural and inherent information. Technically, we first generate anchor, positive and negative embeddings based on the given session and set a triplet mining task to improve the recommendation task with subtle features by pushing positive pairs close and pulling negative pairs away. Second, to robust the model, we employ a self-supervised auxiliary task by adding dynamic perturbations to the embedding space. We conduct extensive experiments to demonstrate the superiority of our method against other state-of-the-art algorithms. Our implementations are available on the following site https://github.com/Info4Rec/TME-GNN .},
  archive      = {J_IJPRAI},
  author       = {Jiayi Zhu and Yong Feng and Mingliang Zhou and Xiancai Xiong and Yongheng Wang and Yu Xia and Baohua Qiang and Qin Mao and Bin Fang},
  doi          = {10.1142/S021800142350012X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2350012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Improve session-based recommendation with triplet mining and dynamic perturbations graph neural networks},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel copy–move forgery detection algorithm via
gradient-hash matching and simplified cluster-based filtering.
<em>IJPRAI</em>, <em>37</em>(6), 2350011. (<a
href="https://doi.org/10.1142/S0218001423500118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Copy–move forgery is one of the most frequently used methods for producing fake digital images. Current algorithms for copy–move forgery detection (CMFD) cannot combine high accuracy and fast speed. Motivated by the observation, we propose a novel CMFD algorithm whose workflow is as follows. First, we use a keypoint-extraction method with the lowest contrast threshold to extract more keypoints from the input image. Second, a new technique, gradient-hash matching, finds pairs of similar keypoints quickly and effectively using a hash table, where the hash value is computed using gradients of keypoints. Subsequently, a new method called simplified cluster-based filtering exploits the density pattern of keypoints in the copy–move regions to remove false matching keypoint pairs. Finally, image matting is applied to indicate the forgery regions vividly. Extensive experiments show that not only the new algorithm is better than the state-of-the-art algorithms in terms of computation correctness, but also its computation time is drastically less. Commonly only about half time is needed. The relative time saving is even higher when images are larger. Different algorithms modules are compared through experiments to choose the best combination.},
  archive      = {J_IJPRAI},
  author       = {Jixiang Yang and Zhiyao Liang and Jianqing Li and Yanfen Gan and Junliu Zhong},
  doi          = {10.1142/S0218001423500118},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2350011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A novel Copy–Move forgery detection algorithm via gradient-hash matching and simplified cluster-based filtering},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence-aided SLA planning via reverse
engineering the QoE/QoS relations. <em>IJPRAI</em>, <em>37</em>(5),
2359010. (<a href="https://doi.org/10.1142/S0218001423590103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Along with the growth of the Internet comes a competitive environment among Internet service providers. In this regard, quality of service (QoS) and customer’s quality of experience (QoE) are introduced as the two main criteria of satisfaction for network users/regulators. In this paper, we evaluate these two criteria for one of the largest Internet service communication networks in Iran. By providing a predictive model, we propose a solution to improve the quality of the communication. Our model predicts the quality of experience from the quality-of-service parameters with an accuracy of roughly 90%. Next, we reverse-engineer the relationship between the quality of experience and quality of service to develop a service level agreement (SLA) contract. The relationship between quality of experience and quality of service is then compiled into a set of if-then rules. By using a decision tree classifier, we were able to set the quality-of-service parameter thresholds for the gold, silver, and bronze SLAs.},
  archive      = {J_IJPRAI},
  author       = {A. S. Mousavi Rineh and J. Kazemitabar and A. Zadeh},
  doi          = {10.1142/S0218001423590103},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2359010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Artificial intelligence-aided SLA planning via reverse engineering the QoE/QoS relations},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An automatic music-driven folk dance movements generation
method based on sequence-to-sequence network. <em>IJPRAI</em>,
<em>37</em>(5), 2358003. (<a
href="https://doi.org/10.1142/S021800142358003X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Music-driven automatic dance movement generation has become a hot research topic in the field of computer vision and internet of things in the recent past. To address the problems of increasing loss of Chinese folk dance culture, high cost of manual choreography methods and requirements for professional background, this paper proposes an automatic generation method for folk dance movements. Firstly, the proposed method collects paired folk music and dance videos to construct a synchronized folk music–dance dataset, extracting music and dance features using a feature extraction tool and a multi-scale fusion high-resolution network, respectively. Afterward, a sequence-to-sequence network model is constructed and then trained based on music features and dance features to synthesize rhythmically matched dance sequences for new music clips. Finally, an easy-to-use and effective automatic folk dance choreography method is implemented. Experimental data show that the proposed method performs well in automatic folk dance generation and the generated dances have folk characteristics and match the rhythm of the given music.},
  archive      = {J_IJPRAI},
  author       = {Xingquan Cai and Mengyao Xi and Sichen Jia and Xiaowei Xu and Yijie Wu and Haiyan Sun},
  doi          = {10.1142/S021800142358003X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2358003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An automatic music-driven folk dance movements generation method based on sequence-to-sequence network},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cancelable multibiometrics template security using deep
binarization and secure hashing. <em>IJPRAI</em>, <em>37</em>(5),
2356007. (<a href="https://doi.org/10.1142/S0218001423560074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Template security and privacy is of utmost significance while designing a biometric system. Several biometric template protection systems have been presented in the past, but none of them have succeeded in striking a compromise between matching performance and security. This paper proposes a hybrid template protection technique for a multibiometric system based on deep binarization and secure hashing. The technique is employed at different stages of multibiometric fusion. In particular, the proposed technique of multibiometric fusion for template protection is tested using face and electrocardiogram (ECG) biometrics. The pre-trained deep CNN model utilizes transfer learning to analyze both the biometrics and prepare multimodal templates at different stages of biometric fusion e.g. sensors, features, and matchers. The templates obtained from different states of fusion are mapped to their corresponding classes, which are represented as binary codes that are unique and randomly generated. The binary codes are further encrypted for noninvertibility using a cryptographic hash, and thus the information of fused templates is hidden. Finally, hash codes are used to perform matching. The evaluation of the proposed technique using database for face (Multi-PIE) and ECG (PTB) biometrics reports high accuracy satisfying the requirements of unlinkability, cancelability, and irreversibility for template protection.},
  archive      = {J_IJPRAI},
  author       = {Ashutosh Singh and Yogendra Narain Singh},
  doi          = {10.1142/S0218001423560074},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2356007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Cancelable multibiometrics template security using deep binarization and secure hashing},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-class facial emotion recognition using hybrid dense
squeeze network. <em>IJPRAI</em>, <em>37</em>(5), 2356005. (<a
href="https://doi.org/10.1142/S0218001423560050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic facial expression recognition (FER) is utilized in various applications like psychoanalysis, intelligent driving, robot manufacturing, etc. Numerous researchers have been looking for better techniques to improve the accuracy of FER. In fact, FER under laboratory conditions has almost achieved top accuracy. Besides, label deviations or errors caused by annotators’ subjectivity also make the FER task much tougher. Thus, more and more researchers begin to find new ways to handle with the FER problems. In this work, a new deep learning (DL) model called dense squeeze network with improved red deer optimization (DenseSNet_IRDO) is proposed for the recognition of facial emotions. The steps used for FER are pre-processing, fused deep feature extraction-selection and classification. Initially, the facial images are pre-processed using improved trilateral filter (ITF) for improving the quality of images. Next, the fusion of feature extraction and selection is performed using the DenseSNet. Here the extraction of deep features is done with the dense network and the relevant features are selected with the squeeze network. Finally, the last layer of squeeze network performs the classification of various facial emotions. Here, the loss in the classification is optimized using IRDO. This DenseSNet_IRDO architecture is more robust and avoids overfitting that occurs while training the small dataset. The datasets used in this work are CK + , JAFEE and FERFIN. The proposed FER classification using datasets CK + , JAFEE and FERFIN with DenseSNet_IRDO model achieved the accuracy of 99.91%, 99.90% and 99.89%, respectively. Thus, the proposed DenseSNet_IRDO classifier model obtained higher accuracy in the detection of FER than other methods.},
  archive      = {J_IJPRAI},
  author       = {Kalimuthu M. and S. Sreethar and Ramya Murugesan and N. Nandhagopal},
  doi          = {10.1142/S0218001423560050},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2356005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-class facial emotion recognition using hybrid dense squeeze network},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Algorithm analysis of face recognition robot based on deep
learning. <em>IJPRAI</em>, <em>37</em>(5), 2356004. (<a
href="https://doi.org/10.1142/S0218001423560049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous improvement of computer software and hardware performance, a large amount of image and video data can be easily collected and quickly transmitted, and new recognition methods that introduce deep learning are emerging, making the application and research of face recognition technology. The value is also increasingly prominent. The purpose of this paper is to study the face recognition robot implementation algorithm based on deep learning. The research background and significance of face recognition and expression recognition, which are the core of facial biological information extraction, are introduced. The face feature extraction network structure of Inception-ResNet-V1 has been improved, and high recognition features of faces can be obtained. At the same time, the training of the feature extraction model of the self-built training set and the adjustment of hyperparameters are completed. Finally, the effectiveness of the improved network in this paper is fully verified in the LFW test set and the actual robot environment. It is verified by experiments that the proposed optimization method can improve the performance of the network. It also verified the significant research significance of the current deep learning direction through practice.},
  archive      = {J_IJPRAI},
  author       = {Zehui Mu and Leijie Feng and Yanzi Shang and Qingyang Liu and Libing Hu and Fei Zhou and Xianjun Fu},
  doi          = {10.1142/S0218001423560049},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2356004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Algorithm analysis of face recognition robot based on deep learning},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural network-based method for early diagnosis of autism
spectral disorder head-banging behavior from recorded videos.
<em>IJPRAI</em>, <em>37</em>(5), 2356003. (<a
href="https://doi.org/10.1142/S0218001423560037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism spectrum disorder (ASD) is a mental developmental disorder associated with social and communicational defects and Stereotypical Motor Movements (SMM). SMM is a set of repetitive motor activities associated with several mental developmental disorders like Autism. SMM has several forms like arm flapping, head banging, ear covering, and spinning with various degrees of severity that might lead to self-injury in severe cases. Developing a computer-vision-based technology to detect noticeable SMM behaviors can help in the early diagnosis of autism. In this paper, a computer vision-based neural network model was proposed to detect and recognize repetitive motor behaviors. The proposed model went through three main stages: First, data preparation. Second, human body features extraction using deep learning pose estimation and the skeleton representation model, and finally, multiclass classification to distinguish between several classes of headbanging. The proposed solution was evaluated using the Self Stimulatory Behavior Dataset (SSBD) which is a public dataset of three classes of repetitive motor behaviors associated with autism. We also collected a set of 40 videos of autistic children exhibiting headbanging from public domains like YouTube. In addition to that, we captured 25 videos of typically developing subjects mimicking headbanging. The collected and the videoed videos were used to evaluate the proposed model. This work proves the applicability of diagnosing mental developmental syndrome symptoms using vision-based techniques in cooperation with neural networks. The produced results prove that the used techniques can operate well in real-world challenging applications. The proposed model achieved 85.5% accuracy on SSBD and 93% on the collected and recorded videos.},
  archive      = {J_IJPRAI},
  author       = {Esraa T. Sadek and Noha A. Seada and Said Ghoniemy},
  doi          = {10.1142/S0218001423560037},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2356003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Neural network-based method for early diagnosis of autism spectral disorder head-banging behavior from recorded videos},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A social distance monitoring method based on improved YOLOv4
for surveillance videos. <em>IJPRAI</em>, <em>37</em>(5), 2354007. (<a
href="https://doi.org/10.1142/S0218001423540071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social distance monitoring is of great significance for public health in the era of COVID-19 pandemic. However, existing monitoring methods cannot effectively detect social distance in terms of efficiency, accuracy, and robustness. In this paper, we proposed a social distance monitoring method based on an improved YOLOv4 algorithm. Specifically, our method constructs and pre-processes a dataset. Afterwards, our method screens the valid samples and improves the K-means clustering algorithm based on the IoU distance. Then, our method detects the target pedestrians using a trained improved YOLOv4 algorithm and gets the pedestrian target detection frame location information. Finally, our method defines the observation depth parameters, generates the 3D feature space, and clusters the offending aggregation groups based on the L2 parametric distance to finally realize the pedestrian social distance monitoring of 2D video. Experiments show that the proposed social distance monitoring method based on improved YOLOv4 can accurately detect pedestrian target locations in video images, where the pre-processing operation and improved K-means algorithm can improve the pedestrian target detection accuracy. Our method can cluster the offending groups without going through calibration mapping transformation to realize the pedestrian social distance monitoring of 2D videos.},
  archive      = {J_IJPRAI},
  author       = {Xingquan Cai and Shun Zhou and Pengyan Cheng and Dingwei Feng and Haiyan Sun and Jiaqi Ji},
  doi          = {10.1142/S0218001423540071},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2354007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A social distance monitoring method based on improved YOLOv4 for surveillance videos},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scene text detection based on multi-dimensional feature
fusion with instance-wise loss. <em>IJPRAI</em>, <em>37</em>(5),
2353001. (<a href="https://doi.org/10.1142/S0218001423530014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past few years, scene text detection has witnessed rapid progress due to the development of deep neural networks. However, segmentation-based methods may fail to detect pixels near boundary well, and scale variations of text instances may lead to small text missing. To tackle these problems, we propose a novel segmentation-based detector for scene text detection, which can improve the quality of the detected texts. Specifically, a Multi-dimensional Feature Fusion module is used to extract structural and spatial text features from the perspective of height, width and channel, which helps to improve the representation ability of the network. In order to obtain more accurate boundaries of the detected text instances, a Boundary Refinement Branch is introduced to strengthen the supervision for pixels adjacent to boundary. Meanwhile, we propose an Instance-wise Loss to deal with text instances of different scales. Extensive ablation studies validate the effectiveness of these proposed modules. Experiments on several benchmark datasets show that our method achieves better results compared with the state-of-the-art methods.},
  archive      = {J_IJPRAI},
  author       = {Qin Wu and Peiwen Zhu and Guodong Guo},
  doi          = {10.1142/S0218001423530014},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2353001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Scene text detection based on multi-dimensional feature fusion with instance-wise loss},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep CRNN-based sentiment analysis system with hybrid BERT
embedding. <em>IJPRAI</em>, <em>37</em>(5), 2352006. (<a
href="https://doi.org/10.1142/S0218001423520067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel hybrid embedding to enhance scope of word embeddings by augmenting these with natural language processing operations. We primarily focus on the proposal of new hybrid word embedding generated by augmenting BERT embedding vectors with polarity score. The paper further proposes a new deep learning architecture inspired by the use of convolutional neural network for feature extraction and a bidirectional recurrent network for contextual and temporal feature exploitation. Use of CNN with hybrid embedding allowed the network to extract even the higher-level styles in writing, while bidirectional RNN helped in understanding context. The paper justifies that the proposed architecture and hybrid embedding improves performance of sentiment classification system by performing a large number of experiments and testing on a number of deep learning architectures. The architecture on new hybrid embeddings incurred an accuracy of 96%, which is a significant improvement when compared with recent studies in the literature.},
  archive      = {J_IJPRAI},
  author       = {Khaled Hamed Alyoubi and Akashdeep Sharma},
  doi          = {10.1142/S0218001423520067},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2352006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A deep CRNN-based sentiment analysis system with hybrid BERT embedding},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Age prediction for energy-aware communication in WSN using
hybrid optimization-enabled deep belief network. <em>IJPRAI</em>,
<em>37</em>(5), 2352001. (<a
href="https://doi.org/10.1142/S0218001423520018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To perceive the data utilizing sensor nodes, wireless sensor network (WSN) consists of several nodes connected to a wireless channel. However, the sink node, also known as a base station (BS), provides power to the WSN and acts as an access node for a number of the network’s sensor devices. Weather monitoring, field surveillance, and the collection of meteorological data are just a few of the various uses for WSN. The energy of each node directly affects how long a wireless network will last. So, to increase the lifespan of WSN, effective routing is required. Using the suggested Taylor sea lion optimization-based deep belief network (TSLnO-based DBN), the ultimate purpose of this research is to build a method for energy-aware communication in WSN. In the setup stage, cluster head (CH) is chosen using a hybrid optimization technique called ant lion whale optimization (ALWO), which is created by fusing the whale optimization algorithm (WOA) and ant lion optimizer (ALO). It is important to note that CH’s selection criteria are solely based on fitness factors such as energy and distance. The second phase, known as the steady state step, is when the updating of energy and trust takes place. In the prediction phase, the network classifier is trained using a newly created optimization method called TSLnO, and the age of neighbor nodes is predicted by estimating the energy of neighbors using DBN. By combining the Taylor Series and the sea lion optimization (SLnO) method, the proposed TSLnO is produced. The communication/route discovery phase, which occurs in the fourth phase, is where the path through nearby nodes is chosen. The maintenance phase of the route is the fifth phase.},
  archive      = {J_IJPRAI},
  author       = {K. Suresh Kumar and P. Vimala},
  doi          = {10.1142/S0218001423520018},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2352001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Age prediction for energy-aware communication in WSN using hybrid optimization-enabled deep belief network},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Masked visual transformer for efficient training with small
dataset. <em>IJPRAI</em>, <em>37</em>(5), 2351010. (<a
href="https://doi.org/10.1142/S0218001423510102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision Transformers (ViTs) are becoming an architectural paradigm replacing the convolutional neural networks (CNNs) in computer vision. ViTs offer competitive performances with respect to CNNs, but they, especially the vanilla ViTs, are hungrier for data than the typical CNNs as the short of the common inductive bias of convolution. Recently, few works focused on training vanilla ViTs efficiently with small datasets. In this paper, we perform research on training vanilla ViTs with small dataset containing thousands of images, and propose a method that is applied to self-supervised pretraining stage. The proposed method combines parametric instance discrimination with CutMix and Multi-crop. Furthermore, we introduce image masking to reduce the overfitting of pretraining on small dataset. State-of-the-art results are achieved by our method for training from scratch based on vanilla ViT backbones on seven small-scale datasets. The transferring performance of our method is also tested on small datasets, and results show that it is improved significantly.},
  archive      = {J_IJPRAI},
  author       = {Chen-Zhi Guan},
  doi          = {10.1142/S0218001423510102},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2351010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Masked visual transformer for efficient training with small dataset},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Md-pred: A multidimensional hybrid prediction model based on
machine learning for hotel booking cancellation prediction.
<em>IJPRAI</em>, <em>37</em>(5), 2351009. (<a
href="https://doi.org/10.1142/S0218001423510096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hotel order cancellation prediction has always been an influential part of hotel management. A better prediction model can optimize the accuracy of the prediction and thus enhance the value of subsequent business analysis and operational optimization. In this paper, a multidimensional hybrid evaluation prediction model Md-Pred is proposed for the first time. It combines the CatBoost, LGBM classifier, and SARIMAX time series algorithm, which can more effectively balance the influence of various features on classification problems as well as differentiate between objective features and subjective features. Results indicate that the performance of the prototype is significant, a new level of accuracy in predicting hotel order cancellations and future guest flow has been achieved.},
  archive      = {J_IJPRAI},
  author       = {Xinyuan Tian and Bingqin Pan and Liping Bai and Deyun Mo},
  doi          = {10.1142/S0218001423510096},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2351009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Md-pred: A multidimensional hybrid prediction model based on machine learning for hotel booking cancellation prediction},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Edge-labeled and node-aggregated graph neural networks for
few-shot relation classification. <em>IJPRAI</em>, <em>37</em>(5),
2350010. (<a href="https://doi.org/10.1142/S0218001423500106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation classification as a core technique for building knowledge graphs becomes a critical task in natural language processing. The fact that humans can learn by summarizing and generalizing limited knowledge motivates scholars to explore few-shot learning. Graph neural networks provide a method to measure the distance between nodes, which improves the model effect in the problem of few-shot relation classification. However, graph neural network methods focus only on node information and ignore edge information which implies inter-class and intra-class relations. This paper proposes edge-labeled and node-aggregated graph neural networks (ENGNNs) for few-shot relation classification: edge labels are encoded and used for node information aggregation. In addition, a process of semi-supervised learning is designed to discover a better solution for one-shot learning. Compared with previous methods, experimental results show that the proposed ENGNN model improves the performance of the graph neural network on the FewRel dataset.},
  archive      = {J_IJPRAI},
  author       = {Jiayi Wang and Lina Yang and Xichun Li and Patrick Shen-Pei Wang and Zuqiang Meng},
  doi          = {10.1142/S0218001423500106},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2350010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Edge-labeled and node-aggregated graph neural networks for few-shot relation classification},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AACO: Aquila anti-coronavirus optimization-based deep LSTM
network for road accident and severity detection. <em>IJPRAI</em>,
<em>37</em>(5), 2252030. (<a
href="https://doi.org/10.1142/S0218001422520309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Globally, traffic accidents are of main concern because of more death rates and economic losses every year. Thus, road accident severity is the most important issue of concern, mainly in the undeveloped countries. Generally, traffic accidents result in severe human fatalities and large economic losses in real-world circumstances. Moreover, appropriate, precise prediction of traffic accidents has a high probability with regard to safeguarding public security as well as decreasing economic losses. Hence, the conventional accident prediction techniques are usually devised with statistical evaluations, which identify and evaluate the fundamental relationships among human variability, environmental aspects, traffic accidents and road geometry. However, the conventional approaches have major restrictions based on the assumptions regarding function kind and data distribution. In this paper, Aquila Anti-Coronavirus Optimization-based Deep Long Short-Term Memory (AACO-based Deep LSTM) is developed for road accident severity detection. Spearman’s rank correlation coefficient and Deep Recurrent Neural Network (DRNN) are utilized for the feature fusion process. Data augmentation method is carried out to improve the detection performance. Deep LSTM detects the road accident and its severity, where Deep LSTM is trained by the designed AACO algorithm for better performance. The developed AACO-based Deep LSTM model outperformed other existing methods with the Mean Square Error (MSE), Root-Mean-Square Error (RMSE) and Mean Absolute Percentage Error (MAPE) of 0.0145, 0.1204 and 0.075%, respectively.},
  archive      = {J_IJPRAI},
  author       = {Pendela Kanchanamala and Ramanathan Lakshmanan and B. Muthu Kumar and Balajee Maram},
  doi          = {10.1142/S0218001422520309},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2252030},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {AACO: Aquila anti-coronavirus optimization-based deep LSTM network for road accident and severity detection},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent indoor localization algorithm based on channel
state information. <em>IJPRAI</em>, <em>37</em>(4), 2359009. (<a
href="https://doi.org/10.1142/S0218001423590097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the deepening application of wearable devices in the field of indoor positioning, the mining and application of human behavior patterns based on new technologies such as mobile terminals, channel technologies and intelligent algorithms have gradually become a research hotspot in the field of intelligent positioning. At this stage, outdoor positioning satellite technology has been gradually improved, but it cannot work effectively in indoor environment, and indoor positioning technology has not formed a set of standard and effective scheme at this stage, which leads to a scene of a hundred contentions for indoor positioning technology. This paper proposes an indoor intelligent localization algorithm based on channel state information, which first forms the measurements of antenna subarrays by the fixed antenna subset arrays located in different paths to achieve the phase estimation based on channel state; then determines the AoA of the direct path from the target to the AP using ToF information and eliminates the STO noise of channel state information by unfolding the best linear fit of CSI phase; again the AoA and ToF estimates from multiple measurements are plotted in two-dimensional space, and the direct path possibility estimation is achieved by identifying the estimates through five clusters of Gaussian-averaged clustering algorithm; finally the coordinates of the target to be located are obtained by coupling direct propagation path, estimation clustering and least-squares estimation using three APs as the receiver and the target to be located as the transmitter. The simulation results show that the intelligent localization algorithm proposed in this paper is able to lack the localization accuracy at the decimeter level in the indoor localization environment with three fixed APs, and the average error is better than the localization algorithms of support vector machine, deep learning and limit learning.},
  archive      = {J_IJPRAI},
  author       = {Chao Chen and Zhaoli Wu and Xin Wang},
  doi          = {10.1142/S0218001423590097},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2359009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Intelligent indoor localization algorithm based on channel state information},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent positioning algorithm based on CSI channel mode.
<em>IJPRAI</em>, <em>37</em>(4), 2359006. (<a
href="https://doi.org/10.1142/S0218001423590061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using wearable devices to realize the mining and application of human behavior patterns has become a hotspot in the field of intelligent positioning. Wearable devices provide an analyzable data foundation for indoor spatial distribution and human behavior pattern prediction. The development of the intelligent positioning system based on RSSI has encountered a bottleneck that it is difficult to improve the positioning accuracy. Therefore, some research works started emphasizing location technology based on channel state information (CSI). In this paper, the principle used by Wi-Fi channel state information to realize intelligent positioning is described, the characteristics of CSI are analyzed, and an intelligent positioning algorithm based on CSI is proposed. Specifically, the algorithm first estimates the angle of arrival (AoA) based on the MUSIC algorithm, separates the reflected paths in the multipath components, and accurately estimates the AoA of each path. Second, phase estimation with channel state information is achieved by forming different antenna subarray measurements under the consideration of a subset of antennas and subcarriers. Then, the phase response linear fitting of the data packet CSI is eliminated using the ToF purification algorithm to obtain the corrected phase response and realize the elimination of the STO noise of the channel state information. Finally, the target position is calculated by effectively filtering the reflection path through the likelihood value, and the accurate target positioning function is achieved. The experimental results demonstrate that the intelligent positioning algorithm proposed in this paper can achieve decimeter-level positioning accuracy under the condition of a fixed number of APs, and the average error is better than that of deep learning-based and SVM-based positioning algorithms. In other words, the accuracy of intelligent positioning is improved.},
  archive      = {J_IJPRAI},
  author       = {Wenjie Wang and Zhenzhen Huang and Zongqian Gao},
  doi          = {10.1142/S0218001423590061},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2359006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Intelligent positioning algorithm based on CSI channel mode},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimized convolutional neural network for robust crop/weed
classification. <em>IJPRAI</em>, <em>37</em>(4), 2359005. (<a
href="https://doi.org/10.1142/S021800142359005X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precision farming makes extensive use of information technology, which also aids agronomists in their work. Weeds typically grow alongside crops, lowering the production of those crops. Weeds are eliminated with the aid of herbicides. Without knowing what kind of weed it is, the pesticide may also harm the crop. The weeds from the farms must be categorized and identified in order to be controlled. Automatic control of weeds is essential to enlarge crop production and also to avoid rigorous hand weeding as labor scarcity has led to a surge in food manufacturing costs, especially in the developed countries such as India. On the other hand, the advancement of an intelligent, reliable automatic system for weed control in real time is still challenging. This paper intends to introduce a new crop/ weed classification model that includes three main phases like pre-processing, feature extraction and classification. In the first phase, the input image is subjected to pre-processing, which deploys a contrast enhancement process. Subsequent to this, feature extraction takes place, where “the features based on gray-level co-occurrence matrix (GLCM) as well as gray-level run-length matrix (GLRM)” are extracted. Then, these extracted features along with the RGB image (totally five channels) are subjected to classification, where “optimized convolutional neural network” (CNN) is employed. In order to make the classification more accurate, the weight and the activation function of CNN are optimally chosen by a new hybrid model termed as the hybridized whale and sea lion algorithm (HW–SLA) model. Finally, the superiority of the adopted scheme is validated over other conventional models in terms of various measures.},
  archive      = {J_IJPRAI},
  author       = {Bikramaditya Panda and Manoj Kumar Mishra and Bhabani Shankar Prasad Mishra and Abhinandan Kumar Tiwari},
  doi          = {10.1142/S021800142359005X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2359005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Optimized convolutional neural network for robust Crop/Weed classification},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reliability analysis of deep-water explosion test vessel
based on fuzzy interval. <em>IJPRAI</em>, <em>37</em>(4), 2358002. (<a
href="https://doi.org/10.1142/S0218001423580028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The safety of such a high-security structure as a deep-water explosion test vessel in service is still in the exploration stage. The reliability of the vessel needs to be analyzed in order to prevent the underwater explosion shock wave and other explosion products on the test equipment causing great damage to the experimental personnel. The safety of such a high-security structure as a deep-water explosion test vessel in service has gradually attracted the attention of scholars. The reliability of the vessel needs to be analyzed in order to prevent the shock wave of underwater explosion and other explosion products on the test equipment causing great damage to the experimental personnel. In this paper, the dynamic response test data of a deepwater explosion test vessel in service under different conditions and the Elman neural network are used to establish the dynamic response prediction model of the deepwater explosion test vessel, and using the established model to make dynamic response prediction in the next experiment; the vessel yield strength and modulus of elasticity are taken as random variables, and the container dynamic strain prediction interval is the interval variable, the random-interval reliability model is established by using the interval variable and random variable. The random variables of the model are transformed into interval variables, and the interval variables are fuzzified using the affiliation function to calculate the reliability index. Since the interval variable obtained from the model will change with the change of the container dynamic test data, the interval reliability index calculated by the stochastic-interval reliability analysis model can quantify the reliability of the container and can be used as a reference for the subsequent use of the container by reducing the reliability index to calculate the service life and drug filling amount.},
  archive      = {J_IJPRAI},
  author       = {Linna Li and Lian Guo and Dongwang Zhong and Xiaowu Huang and Jing Zhang},
  doi          = {10.1142/S0218001423580028},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2358002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Reliability analysis of deep-water explosion test vessel based on fuzzy interval},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A method for 3D human pose estimation and similarity
calculation in tai chi videos. <em>IJPRAI</em>, <em>37</em>(4), 2356006.
(<a href="https://doi.org/10.1142/S0218001423560062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human pose estimation from video sequences has become a hot research topic in the domain of robotics and computer vision. However, existing three-dimensional (3D) pose estimation methods usually analyze individual frames, which have a low accuracy due to various human movement speed, limiting its practical application. In this paper, we propose a method for estimating 3D pose and calculating similarity from Tai Chi video sequences based on Seq2Seq network. Specifically, using 2D joint point coordinate sequence of the original image as input, our method constructs an encoder and a decoder to build a Seq2Seq network. Our method introduces an attention mechanism for weighing the input data to obtain an intermediate vector and decode it to estimate the 3D joint point sequence. Afterwards, using a template video and a target video as input, our method calculates the cost of passing through each point within the constraints to construct a cost matrix for video similarity. With the cost matrix, our method can determine the optimal path and use the correspondence of the video sequence to calculate the image similarity of the corresponding frame. The experimental data show that the proposed method can effectively improve the accuracy of 3D pose estimation, and increase the speed for video similarity calculation.},
  archive      = {J_IJPRAI},
  author       = {Xingquan Cai and Rui Lu and Haoyu Zhang and Yuqing Huo and Haiyan Sun and Jiaqi Ji},
  doi          = {10.1142/S0218001423560062},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2356006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A method for 3D human pose estimation and similarity calculation in tai chi videos},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic multi-class brain tumor classification using
residual network-152 based deep convolutional neural network.
<em>IJPRAI</em>, <em>37</em>(4), 2356001. (<a
href="https://doi.org/10.1142/S0218001423560013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor is one of the leading causes of death in humans worldwide. Image recognition or computer vision uses deep learning based approaches for automatic tumor detection by classifying brain images. It is difficult to analyze the similarity between brain tissues while processing the magnetic resonance imaging (MRI) brain images for tumor classification. In this paper, residual network-152 (ResNet-152) with softmax layer is proposed for accurate detection of brain tumor with low complexity. Initially, the brain images are pre-processed and segmented with adaptive canny mayfly algorithm (ACMA). More discriminative features are extracted from the pre-processed image with spatial gray level dependence matrix (SGLDM), and optimal features are selected with modified chimpanzee optimization algorithm (MChOA). The optimal feature selection and optimal performance of classification are obtained by eliminating poor generalization and over specialization. After eliminating redundancies, the features are fed to residual classification. The overall performance of the proposed tumor classification method is evaluated using various parameters such as accuracy, precision, recall, F-score, MCC and balanced accuracy. The evaluation results indicate that our proposed method reached the accuracy level of 98.85%, which is efficient than other conventional approaches such as convolutional neural network (CNN), ResNet, recurrent neural network (RNN), random belief network (RBN), liner support vector machine (LSVM) and poly-SVM.},
  archive      = {J_IJPRAI},
  author       = {Mahesh Pandurang Potadar and Raghunath Sambhaji Holambe},
  doi          = {10.1142/S0218001423560013},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2356001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Automatic multi-class brain tumor classification using residual network-152 based deep convolutional neural network},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatiotemporal detection and localization of object removal
video forgery with multiple feature extraction and optimized residual
network. <em>IJPRAI</em>, <em>37</em>(4), 2355002. (<a
href="https://doi.org/10.1142/S0218001423550029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video forgery detection and localization is one of the most important issue due to the advanced editing software that provides strengthen to tools for manipulating the videos. Object based video tampering destroys the originality of the video. The main aim of the video forensic is to eradicate the forgeries from the original video that are useful in various applications. However, the research on detecting and localizing the object based video forgery with advanced techniques still remains the open and challenging issue. Many of the existing techniques have focused only on detecting the forged video under static background that cannot be applicable for detecting the forgery in tampered video. In addition to this, conventional techniques fail to extract the essential features in order to investigate the depth of the video forgery. Hence, this paper brings a novel technique for detecting and localizing the forged video with multiple features. The steps involved in this research are keyframe extraction, pre-processing, feature extraction and finally detection and localization of forged video. Initially, keyframe extraction uses the Gaussian mixture model (GMM) to extract frames from the forged videos. Then, the pre-processing stage is manipulated to convert the RGB frame into a grayscale image. Multi-features need to be extracted from the pre-processed frames to study the nature of the forged videos. In our proposed study, speeded up robust features (SURF), principal compound analysis histogram oriented gradients (PCA-HOG), model based fast digit feature (MBFDF), correlation of adjacent frames (CAF), the prediction residual gradient (PRG) and optical flow gradient (OFG) features are extracted. The dataset used for the proposed approach is collected from REWIND of about 40 forged and 40 authenticated videos. With the help of the DL approach, video forgery can be detected and localized. Thus, this research mainly focuses on detecting and localization of forged video based on the ResNet152V2 model hybrid with the bidirectional gated recurrent unit (Bi-GRU) to attain maximum accuracy and efficiency. The performance of this approach is finally compared with existing approaches in terms of accuracy, precision, F-measure, sensitivity, specificity, false-negative rate (FNR), false discovery rate (FDR), false-positive rate (FPR), Mathew’s correlation coefficient (MCC) and negative predictive value (NPV). The proposed approach assures the performance of 96.17% accuracy, 96% precision, 96.14% F-measure, 96.58% sensitivity, 96.5% specificity, 0.034 FNR, 0.04 FDR, 0.034 FPR, 0.92 MCC and 96% NPV, respectively. Along with is, the mean square error (MSE) and peak-to-signal-noise ratio (PSNR) for the GMM model attained about 104 and 27.95, respectively.},
  archive      = {J_IJPRAI},
  author       = {Lakshmi Kumari CH and K. V. Prasad},
  doi          = {10.1142/S0218001423550029},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2355002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Spatiotemporal detection and localization of object removal video forgery with multiple feature extraction and optimized residual network},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Maximum gradient autofocus technology of microsporidia
images based on color feature. <em>IJPRAI</em>, <em>37</em>(4), 2354006.
(<a href="https://doi.org/10.1142/S021800142354006X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are many impurities in the microscopic images of extracted microsporidia samples of Bombyx mori pebrine, and Bombyx mori pebrine with elliptical symmetric shape has certain fluidity and obvious stratification. Traditional focusing methods cannot accurately locate the main regions of microsporidia images, and the focusing effect is poor. On this basis, an automatic focusing method combining the microsporidia image features and the evaluation and determination of maximum gradient direction is proposed. First, the HSV color space with stable color information is used to extract the suspected positions of microsporidia targets, so that the interference of some impurities under complex backgrounds is removed and the redundancy of image content calculation is reduced. Then, combined with the light green features of Bombyx mori pebrine, the G-component gray image of microsporidia in the RGB color space is used to extract the significant gradient region. A dynamic focus window is constructed to accurately locate the target region and reduce the influence of microsporidia flow on the focus evaluation function and the bimodal interference caused by impurities. Finally, the maximum second-order difference is obtained through the four-dimensional gradient distribution, and the focus sharpness evaluation function is formulated to adapt to the microsporidia shape and improve the sensitivity of the focus function. The experiments show that under the dynamic window of microsporidia color gradient of different samples, the sharpness ratio and the highest sensitivity factor of the focus evaluation function proposed in this paper can reach 0.06341 and 0.95, respectively. It can meet the accurate and sensitive autofocus of microscopic images of color microsporidia samples under complex backgrounds.},
  archive      = {J_IJPRAI},
  author       = {Xinyu Hu and Xinwei Xiong and Youlin Bai and Anqi He and Jia Ai and Qi Chen},
  doi          = {10.1142/S021800142354006X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2354006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Maximum gradient autofocus technology of microsporidia images based on color feature},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modified GAN with proposed feature set for text-to-image
synthesis. <em>IJPRAI</em>, <em>37</em>(4), 2354004. (<a
href="https://doi.org/10.1142/S0218001423540046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated synthesis of practical images from the text could be useful and interesting; however, present AI systems are yet far from this objective. Nevertheless, in current years, powerful and generic Recurrent Neural Network (RNN) structures were introduced to train discriminative text feature representation. In the meantime, Deep Convolutional GANs have started producing highly convincing images of specified categories, like room interiors, album covers, and faces. In this research work, we plan to develop a new model for text-to-image synthesis, which contains three important phases: (i) feature extraction, (ii) text encoding, and (iii) optimal image synthesis. Initially, the text features such as improved TF–IDF, bag of words, and N -gram are extracted from the text and they are trained by Bi-LSTM. During the encoding of an image from text, cross-modal feature grouping is performed. Further, the image is synthesized using modified GAN (MGAN) with a new loss function. Here, for precise synthesis of images, the weights of GAN are optimized using Self-improved Social Ski-Driver (SI-SSD) optimization algorithm. Eventually, the superiority of the suggested model is examined via an assessment over existing schemes.},
  archive      = {J_IJPRAI},
  author       = {Vamsidhar Talasila and M. R. Narasingarao and V. Murali Mohan},
  doi          = {10.1142/S0218001423540046},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2354004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Modified GAN with proposed feature set for text-to-image synthesis},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning for drawing numbering in engineering drawing
management: A case study for refrigerated compartment product.
<em>IJPRAI</em>, <em>37</em>(4), 2352005. (<a
href="https://doi.org/10.1142/S0218001423520055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Engineering drawing numbering (DN) is one of the most essential procedures for seamless platform integration towards intelligent manufacturing. In spite of this, it is difficult to handle the numbering work in an appropriate and effective manner. This is due to the unpredictability of the names of the manufactured parts and the ineffable relationship between the number and the shape of the parts. This paper proposes a method for numbering items based on historical numbering records based on deep learning. First, name-number (NN) duplexes are generated by retrieving the records. K -means + + is then used to cluster these NN duplexes. Second, it involves looking up the names of the newly designed items using KNN in order to generate an initial numbering system. Third, a modified multi-view convolutional neural network (MVCNN) is utilized for numbering in situations where the same name is different from the previous number (SNDN). Finally, the most recent sequence numbers are appended to complete the numbering. When the system based on the proposed scheme for authentic engineering application is implemented on a refrigerated compartment, the correctness obtained is over 95%, and the efficiency is increased by 5–6 times.},
  archive      = {J_IJPRAI},
  author       = {Hui Zhang and Ruixv Luo and Lanzhen Luo and Kun Li and Xifeng Fang and Shengwen Zhang},
  doi          = {10.1142/S0218001423520055},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2352005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Deep learning for drawing numbering in engineering drawing management: A case study for refrigerated compartment product},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A semi-supervised learning using tri-classifier model with
voting for COVID-19 cough classification. <em>IJPRAI</em>,
<em>37</em>(4), 2352004. (<a
href="https://doi.org/10.1142/S0218001423520043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the increasing severity of the COVID-19 pandemic, timely screening and diagnosis of infections are essential. Since cough is a common symptom of COVID-19, an AI-assisted cough classification scheme is designed in this paper to diagnose COVID-19 infection. To reduce the labeling efforts by human experts, a semi-supervised learning with voting scheme using a triple-classifier model is proposed for the COVID-19 cough classification. This work aims to improve the accuracy of the classification. Initially, the data pre-processing scheme is executed by performing data cleaning, resampling, and data enhancement so as to improve the audio quality before training. The pre-training scheme is then performed by using a few numbers of COVID-19 cough data with labeling. Then we modify a well-known self-supervised learning model, SimCLR, to a semi-supervised learning-based SimCLR-like model, which uses three different loss functions to fine-tune three training models for cough classification. Finally, a voting scheme is performed based on the classification results of the three cough classifiers so as to enhance the accuracy of the cough classification for COVID-19. The experiment results illustrate that the proposed scheme can achieve 85% accuracy, which outperforms the existing semi-supervised learning-based classification schemes.},
  archive      = {J_IJPRAI},
  author       = {Yuh-Shyan Chen and Kuang-Hung Cheng and Chih-Shun Hsu and Tzu-Hung Lin},
  doi          = {10.1142/S0218001423520043},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2352004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A semi-supervised learning using tri-classifier model with voting for COVID-19 cough classification},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised texture image anomaly detection by fusing
normalizing flow and dictionary learning. <em>IJPRAI</em>,
<em>37</em>(4), 2351007. (<a
href="https://doi.org/10.1142/S0218001423510072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A common study area in anomaly identification is industrial images anomaly detection based on texture background. The interference of texture images and the minuteness of texture anomalies are the main reasons why many existing models fail to detect anomalies. We propose a strategy for anomaly detection that combines dictionary learning and normalizing flow based on the aforementioned questions. The two-stage anomaly detection approach that is already in use is enhanced by our method. In order to improve baseline method, this research adds normalizing flow in representation learning and combines deep learning and dictionary learning. Improved algorithms have exceeded 95 % detection accuracy on all MVTec AD texture type data after experimental validation. It shows strong robustness. The baseline method’s detection accuracy for the Carpet data was 67.9 % . The paper was upgraded, raising the detection accuracy to 99.7 % .},
  archive      = {J_IJPRAI},
  author       = {Yaohua Guo and Lijuan Song and Zirui Ma},
  doi          = {10.1142/S0218001423510072},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2351007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Self-supervised texture image anomaly detection by fusing normalizing flow and dictionary learning},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved low-rank matrix fitting method based on weighted
l1,p norm minimization for matrix completion. <em>IJPRAI</em>,
<em>37</em>(4), 2350007. (<a
href="https://doi.org/10.1142/S0218001423500076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-rank matrix completion, which aims to recover a matrix with many missing values, has attracted much attention in many fields of computer science. A low-rank matrix fitting (LMaFit) method has been proposed for fast matrix completion recently. However, this method cannot converge accurately on matrices of real-world images. For improving the accuracy of LMaFit method, an improved low-rank matrix fitting (ILMF) method based on the weighted L 1 , p norm minimization is proposed in this paper, where the L 1 , p norm is the summation of the p -power ( 0 &lt; p &lt; 2 ) of L 1 norms of rows in a matrix. In the proposed method, i.e. the ILMF method, the incomplete matrix that may be corrupted by noises is decomposed into the summation of a low-rank matrix and a noise matrix at first. Then, a weighted L 1 , p norm minimization problem is solved by using an alternating direction method for improving the accuracy of matrix completion. Experimental results on real-world images show that the ILMF method has much better performances in terms of both the convergence accuracy and convergence speed than the compared methods.},
  archive      = {J_IJPRAI},
  author       = {Qing Liu and Qing Jiang and Jing Zhang and Bin Jiang and Zhengyu Liu},
  doi          = {10.1142/S0218001423500076},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2350007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An improved low-rank matrix fitting method based on weighted l1,p norm minimization for matrix completion},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). QBGA–SVM for face recognition of livable cities.
<em>IJPRAI</em>, <em>37</em>(4), 2256014. (<a
href="https://doi.org/10.1142/S0218001422560146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous expansion of urbanization, the problem of human settlements has become increasingly prominent. Green, economical, intelligent and livable cities have become the urgent needs of future urban planning. The evaluation of urban livability is not only one of the judgment criteria of urban competitiveness, but also an important factor affecting the speed of urban development. Among them, the safety factor of the city is the important guarantee of other aspects, so this paper intends to design a high-precision face recognition algorithm to make efforts for the safety construction of livable cities. Aiming at the shortcomings of the standard support vector machine (SVM), combined with the quantum-behaved mechanism, a quantum-behaved genetic algorithm–SVM (QBGA–SVM) is proposed in the paper. The experimental results for the human face databases show that QBGA–SVM is superior to the comparison algorithms in both accuracy and stability. Finally, QBGA–SVM is applied to face images of the real world, and the results are better than the other algorithms.},
  archive      = {J_IJPRAI},
  author       = {Qizhen Li and Aijia Ouyang and Xuyu Peng and Xijun Hu},
  doi          = {10.1142/S0218001422560146},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2256014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {QBGA–SVM for face recognition of livable cities},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Model-rebuilt disturbance observer of a tracking system
based on acceleration fusion for laser power transmission.
<em>IJPRAI</em>, <em>37</em>(3), 2359007. (<a
href="https://doi.org/10.1142/S0218001423590073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When using laser energy to power long-distance and fast-moving targets, it requires a fast-response and high-precision acquisition, pointing and tracking (APT) system. A fast-steering mirror (FSM) system was used in this paper to track the solar cell array as laser power receiver. The disturbance suppression performance is a key indicator for the FSM stabilization. Generally, a fiber-optic gyroscope (FOG) is employed in the high-sampling-rate velocity loop to enhance the anti-interference ability. However, with the expansion of miniaturized applications, a relatively large, heavy, and high-power FOG is hard to be installed on the small mirror. With this case, this paper used a small-size and high-bandwidth MEMS linear accelerometer in the acceleration loop, substituting the gyroscope. However, the drift and high-frequency noise of the MEMS accelerometer in low frequency will cause APT disturbance. Therefore, an acceleration fusion method with a modified complementary filter was proposed to blend signals of the charge-coupled device and the accelerometers. The fused virtual acceleration can eliminate drift and reduce noise in low frequency and was eventually used in the model-rebuilt disturbance observer loop. At last, the measured results show that the disturbance suppression performance is improved using the presented method, and low-price and small-size MEMS accelerometer can be applied in the APT system.},
  archive      = {J_IJPRAI},
  author       = {Li Zheng and Wenbin Zheng and Jiekai Pan},
  doi          = {10.1142/S0218001423590073},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2359007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Model-rebuilt disturbance observer of a tracking system based on acceleration fusion for laser power transmission},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Control algorithm and realization of adaptive two-wheeled
robot. <em>IJPRAI</em>, <em>37</em>(3), 2359003. (<a
href="https://doi.org/10.1142/S0218001423590036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This system selects STC12C5A60S2 single chip microcomputer as the core processor to control the algorithm and balance state of the balance robot. The robot body is loaded with a gyroscope accelerometer sensor mpu6050 and a magnetoelectric encoder motor 330. The single chip microcomputer filters the data collected by the gyroscope and accelerometer, and processes the upper limit of the integral of the motor output value. Through the conditioning circuit, the sensor collects the horizontal offset angle of the robot body and the wheel rotation speed, and corrects the signal noise and zero offset, so as to complete the attitude monitoring. Using proportional integral differential algorithm, the positive feedback of speed loop and the negative feedback of angle loop are adjusted comprehensively to realize the robot body attitude correction. After debugging, the trolley can achieve self-regulation and balance without the severe impact of the external environment.},
  archive      = {J_IJPRAI},
  author       = {Jianlin Zhao},
  doi          = {10.1142/S0218001423590036},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2359003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Control algorithm and realization of adaptive two-wheeled robot},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FERNET: An integrated hybrid DCNN model for driver stress
monitoring via facial expressions. <em>IJPRAI</em>, <em>37</em>(3),
2357002. (<a href="https://doi.org/10.1142/S0218001423570021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drivers undergo a lot of stress that might cause distraction and might lead to an unfortunate incident. Emotional recognition via facial expressions is one of the most important field in the human–machine interface. The goal of this paper is to analyze the drivers’ facial expressions in order to monitor their stress levels. In this paper, we propose FERNET — a hybrid deep convolutional neural network model for driver stress recognition through facial emotion recognition. FERNET is an integration of two DCNNs, pre-trained ResNet101V2 CNN and a custom CNN, ConvNet4. The experiments were carried out on the widely used public datasets CK + , FER2013 and AffectNet, achieving the accuracies of 99.70%, 74.86% and 70.46%, respectively, for facial emotion recognition. These results outperform the recent state-of-the-art methods. Furthermore, since a few specific isolated emotions lead to higher stress levels, we analyze the results for stress- and nonstress-related emotions for each individual dataset. FERNET achieves stress prediction accuracies of 98.17%, 90.16% and 84.49% for CK + , FER2013 and AffectNet datasets, respectively.},
  archive      = {J_IJPRAI},
  author       = {Chinmay Gupta and Mohit Kumar and Arun Kumar Yadav and Divakar Yadav},
  doi          = {10.1142/S0218001423570021},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2357002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {FERNET: An integrated hybrid DCNN model for driver stress monitoring via facial expressions},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application of three-dimensional fluorescence spectroscopy
in smart agriculture — detection of oil pollutants in water.
<em>IJPRAI</em>, <em>37</em>(3), 2355004. (<a
href="https://doi.org/10.1142/S0218001423550042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional fluorescence spectroscopy is a fast, nondestructive analysis method with good selectivity and high precision, which provides a foundation for the development of the current smart agriculture system. In modern agriculture, where agricultural information is fully perceived, it is still very difficult to quickly and destructively detect the internal chemical composition of soil, crops and agricultural products. Accurate determination of oil pollutants in water by using three-dimensional fluorescence spectroscopy technology can provide a basis for crop irrigation and is of great significance for improving agricultural benefits. The fluorescence spectrum analysis method is adopted to distinguish three kinds of mineral oil-gasoline, kerosene and diesel. In order to make the distinguishment more intuitive and convenient, a new identification method for mineral oil is proposed. The three-dimensional fluorescence spectra of the experimental dimension are reduced into two-dimensional fluorescence spectra. The concrete operations are as follows: adopting the method of end-to-end data matrix to constitute a large Ex image, and then figuring out the envelope curve, processing and analyzing the envelope image. Four factors, such as the ranges of excitation wavelength when the relative fluorescence intensity is greater than 0.5, the optimal excitation wavelengths, their kurtosis coefficients and skewness coefficients, are to be selected as the distinguishing feature parameters of mineral oil, and thus different kinds of mineral oil can be distinguished directly according to the feature parameters. The experimental results show that the proposed method has a high resolution for different kinds of mineral oil. Accurate and fast spectral data analysis methods can make up for the deficiencies of other agricultural information perception methods, provide a basis for the application of smart agriculture in many aspects and have a positive significance for promoting the comprehensive intelligent development of agriculture.},
  archive      = {J_IJPRAI},
  author       = {Pengfei Cheng and Shuchen Wang and Yanping Zhu and Chuanjin Cui and Jinyan Pan},
  doi          = {10.1142/S0218001423550042},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2355004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Application of three-dimensional fluorescence spectroscopy in smart agriculture — detection of oil pollutants in water},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel interactive image segmentation algorithm based on
maximization of submodular function. <em>IJPRAI</em>, <em>37</em>(3),
2354005. (<a href="https://doi.org/10.1142/S0218001423540058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an efficient interactive image segmentation method based on maximization of submodular function under user’s scribble constraint is presented. The problem of interactive image segmentation is formulated as the maximum entropy rate under user’s constraints. The objective function is submodular, and we solve the constrained submodular function maximization by incorporating a new data structure and some aggregating rules into the greedy algorithm. The main steps of our algorithm are as follows. First, the pixels scribbled by the user are clustered separately as target foreground and background clusters. Second, in the process of greedy algorithm, unscribbled pixels are aggregated to the corresponding target cluster according to the proposed aggregating rules. Finally, the segmentation result is presented by the two target clusters. The experiments and comparisons on three standard benchmarks show that our method has good performance. Our method is straightforward and efficient, and the time complexity of our method is between linear and polynomial. Furthermore, we analyze the influence of different scribbles, and propose some optimal scribble strategies.},
  archive      = {J_IJPRAI},
  author       = {Huang Tan and Qiaoliang Li and Zili Peng},
  doi          = {10.1142/S0218001423540058},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2354005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A novel interactive image segmentation algorithm based on maximization of submodular function},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Low-light image enhancement with contrast increase and
illumination smooth. <em>IJPRAI</em>, <em>37</em>(3), 2354003. (<a
href="https://doi.org/10.1142/S0218001423540034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In image enhancement, maintaining the texture and attenuating noise are worth discussing. To address these problems, we propose a low-light image enhancement method with contrast increase and illumination smooth. First, we calculate the maximum map and the minimum map of RGB channels, and then we set maximum map as the initial value for illumination and introduce minimum map to smooth illumination. Second, we use the histogram-equalized version of the input image to construct the weight for the illumination map. Third, we propose an optimization problem to obtain the smooth illumination and refined reflectance. Experimental results show that our method can achieve better performance compared to the state-of-the-art methods.},
  archive      = {J_IJPRAI},
  author       = {Hongyue Leng and Bin Fang and Mingliang Zhou and Bin Wu and Qin Mao},
  doi          = {10.1142/S0218001423540034},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2354003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Low-light image enhancement with contrast increase and illumination smooth},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic segmentation using deep convolutional neural
networks for tumor CT images. <em>IJPRAI</em>, <em>37</em>(3), 2352003.
(<a href="https://doi.org/10.1142/S0218001423520031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tumor computed tomography (CT) image segmentation can provide a basis for the determination of tumor location and type. Therefore, it is of great significance to study the automatic segmentation method of tumor CT images. To address the problem of poor segmentation effect of traditional automatic tumor CT images segmentation methods, we propose an automatic segmentation method for tumor CT images using deep convolutional neural networks (DCNNs). First, the CT tumor image is simplified. According to the features of the target region and the background region, the distribution features of the tumor region in the CT images are obtained by convolution calculation, and the feature extraction is completed by feature fusion. Second, based on the feature extraction results, a deep supervised network is constructed to determine the image depth, which lays a solid foundation for accurate segmentation of tumor regions. Finally, DCNN was used to construct automatic segmentation for tumor CT images, which achieves the automatic segmentation of tumor CT images by mode calculation. The results show that the segmented tumor region is close to the actual region and the maximum pixel loss coefficient is 0.07, the maximum segmentation sensitivity is 7865 kbps/s, the pixel segmentation specific coefficient and the segmentation edge distance are kept at a low level, which has a certain application value in the field of tumor CT images.},
  archive      = {J_IJPRAI},
  author       = {Yunbo Li and Xiaofeng Li},
  doi          = {10.1142/S0218001423520031},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2352003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Automatic segmentation using deep convolutional neural networks for tumor CT images},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Characteristics and optimization strategies of a* algorithm
and ant colony optimization in global path planning algorithm.
<em>IJPRAI</em>, <em>37</em>(3), 2351006. (<a
href="https://doi.org/10.1142/S0218001423510060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A* algorithm and ant colony optimization (ACO) are more widely used in path planning among global path planning algorithms. The optimization process is analyzed and summarized from the principles and characteristics of the two algorithms, A* algorithm is mainly optimized in terms of point selection and improvement of heuristic function; and ACO is mainly investigated in terms of transfer probability and pheromone positive feedback for improvement and optimization. Taking a single algorithm solving complex optimization problems difficulties into consideration, a splitting strategy can be used. So that local path or intelligent path optimization algorithms are incorporated in global path planning to improve search efficiency and optimization quality.},
  archive      = {J_IJPRAI},
  author       = {Yun Ni and Qinghua Zhuo and Ning Li and Kaihuan Yu and Miao He and Xinlong Gao},
  doi          = {10.1142/S0218001423510060},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2351006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Characteristics and optimization strategies of a* algorithm and ant colony optimization in global path planning algorithm},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CWD2GAN: Generative adversarial network of chronic wound
depth detection for predicting chronic wound depth. <em>IJPRAI</em>,
<em>37</em>(3), 2351004. (<a
href="https://doi.org/10.1142/S0218001423510047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinically, for observing the healing of the patient’s wound, doctors need to insert a cotton swab into the deepest part of the wound to detect the depth of the wound. This measurement method will cause discomfort to the patient. Therefore, obtaining wound depth information directly from wound images is very important for doctors to understand the degree of wound healing. In this paper, we propose the generative adversarial network of chronic wound depth detection (CWD 2 GAN) to generate wound depth maps of four different shades of color according to the changes of the wound area in the chronic wound image. In CWD 2 GAN, the generator, which can generate the wound depth map, is composed of three parts: encoder, decoder, and concatenation. And, the discriminator uses the concept of cGAN. It can not only judge whether the generator produces an image but also know that this image is a depth map. In experimental results, the accuracy, sensitivity, specificity, and precision of CWD 2 GAN are 84.8%, 84.6%, 84.9%, and 86.3%, respectively. The results indicate that our proposed method can accurately generate the different depths layer in a chronic wound image, and reduce the pain caused by invasive testing for patients.},
  archive      = {J_IJPRAI},
  author       = {Chiun-Li Chin and Chieh-Yu Li and Yan-Ming Lai and Ting Chen and Tzu-Yu Sun and Jun-Cheng Lin},
  doi          = {10.1142/S0218001423510047},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2351004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {CWD2GAN: Generative adversarial network of chronic wound depth detection for predicting chronic wound depth},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Representation learning method based on improved random walk
for influence maximization. <em>IJPRAI</em>, <em>37</em>(3), 2351003.
(<a href="https://doi.org/10.1142/S0218001423510035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of the influence maximization problem is to determine a subset to maximize the number of affected users. This problem is very crucial for information dissemination in social networks. Most traditional influence maximization methods usually focus too heavily on the information diffusion model and randomly set influence parameters, resulting in inaccurate final outcomes. Driven by the recent criticisms of the diffusion model and the rapid development of representation learning, this paper proposes a representation learning method based on improved random walk for influence maximization (IRWIM) to maximize the influence spread. The IRWIM algorithm improves the traditional random walk and adopts multi-task neural network architecture to predict the propagation ability of nodes more accurately. Moreover, the greedy strategy is utilized to continuously optimize the marginal gain while retaining the theoretical guarantee. IRWIM is tested on four genuine datasets. Experimental results show that the accuracy of the proposed algorithm is superior to various competitive algorithms in the field of influence maximization.},
  archive      = {J_IJPRAI},
  author       = {Yuying Liu and Liqing Qiu and Xiaodan Zhou},
  doi          = {10.1142/S0218001423510035},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2351003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Representation learning method based on improved random walk for influence maximization},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Domain-invariant feature learning for domain adaptation.
<em>IJPRAI</em>, <em>37</em>(3), 2351002. (<a
href="https://doi.org/10.1142/S0218001423510023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) mainly explores how to learn domain-invariant features from the source domain when the target domain label is unknown. To learn domain-invariant features requires aligning the distribution of samples from two domains in the feature space, which can be achieved by minimizing the maximum mean discrepancy (MMD) of samples from the two domains. However, there is still no effective way to find the best parameter values of MMD. Such a problem is addressed in the MMD with deep kernels (MMD-D), whose optimal parameters can be obtained through training. This study proposes a method of domain-invariant feature learning for UDA, whose architecture, named MMDDCDA, comprises an MMD-D module and a cross domain adaptation (CDA) module. MMDDCDA performs alternating training similar to adversarial training to alternately boost the power of the two modules. To our knowledge, this is the first UDA method that performs such alternating training on a UDA architecture using MMD with deep kernels. Experimental validation showed that the proposed method yields state-of-the-art results among UDA methods using other MMD variants and some UDA benchmarks.},
  archive      = {J_IJPRAI},
  author       = {Ching-Ting Tu and Hsiau-Wen Lin and Hwei Jen Lin and Yoshimasa Tokuyama and Chia-Hung Chu},
  doi          = {10.1142/S0218001423510023},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2351002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Domain-invariant feature learning for domain adaptation},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature selection based on the discriminative significance
for sparse binary-valued and imbalanced dataset. <em>IJPRAI</em>,
<em>37</em>(3), 2350008. (<a
href="https://doi.org/10.1142/S0218001423500088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying the significant, or dominant, features is important to reveal the cause-and-effect relations in many pattern recognition applications, such as medical diagnosis, gene analysis, cyber security, finance and insurance fraud detection, etc. Samples that are sparsely populated and binary-valued in highly imbalanced datasets pose a challenge to the identification of these features. This paper explores an approach based on the confusion matrix measurement of the feature values with respect to their potential classification outcomes. The approach is able to compute the Discriminative Significances of the features and rank the features unbiasedly with respect to the imbalance ratios of the datasets. Experiment results on real-world and experimental datasets show that the approach made consistent evaluations of the features and identified the most significant ones accordingly on the sparse and binary-valued samples of the class-imbalanced datasets.},
  archive      = {J_IJPRAI},
  author       = {Qiuming Zhu},
  doi          = {10.1142/S0218001423500088},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2350008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Feature selection based on the discriminative significance for sparse binary-valued and imbalanced dataset},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Information and disseminator features influences online
negative information recognition and dissemination. <em>IJPRAI</em>,
<em>37</em>(3), 2350005. (<a
href="https://doi.org/10.1142/S0218001423500052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Negative information on the Internet is a sticky problem for pattern recognition, especially that factors which influence its dissemination pattern remain uncertain. Combined with the elaboration likelihood model, this paper analyzes the factors that affect the negative information dissemination and its correlation mechanism, subdivides the influencing factors into negative information and disseminator features, introduces the interest degree as the mediator variable, and defines the identity of the receiver as the moderator variable. Through the questionnaire survey and data analysis by SPSS, we found that interest degree has a significant impact on the negative information dissemination intention, with the path coefficient of 0.74. The emotionality of negative information, as well as the activity and credibility of the disseminator have a significant impact on the degree of interest, while the completeness and harmfulness of negative information have a negative effect on user interest. Based on this, we put forward two management enlightenments for a better cybersecurity environment. First, take more computing methods to find out the emotionality, exhaustivity and damageability of negative information; second, use forms of artificial intelligence to respond to negative information in a timely manner and enhance the credibility of antagonistic information.},
  archive      = {J_IJPRAI},
  author       = {Fei Meng and Liqin Chen and Paola Herring and Jianliang Wei},
  doi          = {10.1142/S0218001423500052},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2350005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Information and disseminator features influences online negative information recognition and dissemination},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Channel correlation distillation for compact semantic
segmentation. <em>IJPRAI</em>, <em>37</em>(3), 2350004. (<a
href="https://doi.org/10.1142/S0218001423500040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation has been widely applied in semantic segmentation to reduce the model size and computational complexity. The prior knowledge distillation methods for semantic segmentation mainly focus on transferring the spatial relation knowledge, neglecting to transfer the channel correlation knowledge in the feature space, which is vital for semantic segmentation. We propose a novel Channel Correlation Distillation (CCD) method for semantic segmentation to solve this issue. The correlation between channels tells how likely these channels belong to the same categories. We force the student to mimic the teacher by minimizing the distance between the channel correlation maps of the student and the teacher. Furthermore, we propose the multi-scale discriminators to sufficiently distinguish the multi-scale differences between the teacher and student segmentation outputs. Extensive experiments on three popular datasets: Cityscapes, CamVid, and Pascal VOC 2012 validate the superiority of our CCD. Experimental results show that our CCD could consistently improve the state-of-the-art methods with various network structures for semantic segmentation.},
  archive      = {J_IJPRAI},
  author       = {Chen Wang and Jiang Zhong and Qizhu Dai and Yafei Qi and Qien Yu and Fengyuan Shi and Rongzhen Li and Xue Li and Bin Fang},
  doi          = {10.1142/S0218001423500040},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2350004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Channel correlation distillation for compact semantic segmentation},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A local area network-based insect intelligent building
platform. <em>IJPRAI</em>, <em>37</em>(2), 2359004. (<a
href="https://doi.org/10.1142/S0218001423590048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Insect Intelligent Building (I 2 B) platform is one kind of new architecture of building control and management systems based on a computing process node (CPN) network. To construct an I 2 B platform more conveniently, a new kind of I 2 B Platform based on a local area network is presented in this paper. In the local area network-based I 2 B Platform, the database describing the adjacency of building space units is deployed in building process unit (BPU) and central information node. And with BPU and central information node, the local area network-based I 2 B Platform can perceive the local topology of each building space unit and each build facility unit even if the CPN network is not deployed. Furthermore, the evaluation method for communication performance of the local area network-based I 2 B is also presented in this paper. Experiment results show that the network performance of the local area network-based I 2 B platform can meet the requirements of the I 2 B platform on communication time.},
  archive      = {J_IJPRAI},
  author       = {Zhen-Ya Zhang and Bo Fang and Ping Wang and Hong-Mei Cheng},
  doi          = {10.1142/S0218001423590048},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2359004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A local area network-based insect intelligent building platform},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Effective community search on large attributed bipartite
graphs. <em>IJPRAI</em>, <em>37</em>(2), 2359002. (<a
href="https://doi.org/10.1142/S0218001423590024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community search over bipartite graphs has attracted significant interest recently. In many applications such as the user–item bipartite graph in e-commerce and customer–movie bipartite graph in movie rating website, nodes tend to have attributes. However, the previous community search algorithms on bipartite graphs ignore attributes, thus making them to return results with poor cohesion with respect to their node attributes. In this paper, we study the community search problem on attributed bipartite graphs. Given a query vertex q , we aim to find the attributed ( α , β ) -communities of G , where the structure cohesiveness of the community is described by the ( α , β ) -core model, and the attribute similarity of two groups of nodes in the subgraph is maximized. In order to retrieve attributed communities from bipartite graphs, we first propose a basic algorithm composed of two steps: the generation and verification of candidate keyword sets, and then two improved query algorithms Inc and Dec are proposed. Inc is proposed considering the anti-monotonicity property of attributed bipartite graphs, then we adopt different generating methods and verify the order of candidate keyword sets and propose the Dec algorithm. After evaluating our solutions on eight large graphs, the experimental results demonstrate that our methods are effective and efficient in querying the attributed communities on bipartite graphs.},
  archive      = {J_IJPRAI},
  author       = {Zongyu Xu and Yihao Zhang and Long Yuan and Yuwen Qian and Zi Chen and Mingliang Zhou and Qin Mao and Weibin Pan},
  doi          = {10.1142/S0218001423590024},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2359002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Effective community search on large attributed bipartite graphs},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved DE algorithm for solving multi-furnace optimal
scheduling of single crystal silicon production. <em>IJPRAI</em>,
<em>37</em>(2), 2359001. (<a
href="https://doi.org/10.1142/S0218001423590012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-furnace scheduling simultaneously is an important part to increase productivity and reduce the production cost in single crystal silicon enterprises. In the restrained power consumption requirements environment, the optimal sequencing of process operation start-time for single crystal furnaces is a challenging problem. To solve this problem, the scheduling model of multi-furnace scheduling is established in this paper to minimize the maximum completion time. Then, an improved DE algorithm called the multi-strategy individual adaptive mutation differential evolution algorithm (MSIADE) is presented to address the scheduling model. In the improved DE algorithm, the different dimensional and multi-strategy mutation operations are adopted to refrain the algorithm from the local optimal, then the different mutation factors are assigned to each individual through the rank of fitness function value to strengthen the exploration ability of the MSIADE algorithm. Simulation experiments results based on the standard test functions and the established scheduling model show the feasibility in the established model and the effectiveness in the proposed algorithm.},
  archive      = {J_IJPRAI},
  author       = {Lu Kang and Ding Liu and Yali Wu and Guozheng Ping},
  doi          = {10.1142/S0218001423590012},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2359001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An improved DE algorithm for solving multi-furnace optimal scheduling of single crystal silicon production},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A course controller with finite-time stability for unmanned
surface vehicle thruster system. <em>IJPRAI</em>, <em>37</em>(2),
2358001. (<a href="https://doi.org/10.1142/S0218001423580016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the situation that small unmanned surface vehicle (USV) encounters unknown disturbance during low speed sailing, a course controller with finite time stability is designed. To solve this problem, we construct an undisturbed ideal navigation model which simply meets the stability requirements, and constructs an adaptive sliding mode surface. The control under finite time approach law is also introduced. The model under perturbation can land on the sliding mode surface in finite time and then synchronize with the ideal navigation model. The adaptive control was applied in the implementation of power control for the thruster structure, so as to ensure the tracking of the desired course within the finite time, and satisfy the needs for the stable system performance. Lyapunov direct method is used to strictly prove that the designed controller can ensure the system which converges to the steady state value in a given time period. Simulation results show that the designed adaptive finite-time controller can ensure the stable course tracking of the USV with thruster structure at low speed, and meet the requirements of the course robustness of the USV under dynamic conditions.},
  archive      = {J_IJPRAI},
  author       = {Yan Li and Jianqiang Zhang and Yi Li and Hongbin Wang and Jianjing Qu},
  doi          = {10.1142/S0218001423580016},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2358001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A course controller with finite-time stability for unmanned surface vehicle thruster system},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IoT-enabled healthcare data analysis in virtual hospital
systems using industry 4.0 smart manufacturing. <em>IJPRAI</em>,
<em>37</em>(2), 2356002. (<a
href="https://doi.org/10.1142/S0218001423560025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background : The world is transitioning to Industry 4.0, representing the transition to digital, fully machine-driven environments and cyberphysical systems. Industry 4.0 comprises various technologies and innovations that enable development in multiple perspectives, which are implemented in many different sectors. Problem : The major challenges are the high cost, high rate of failure, security and privacy issues, and there is a need for highly skilled labor for applying healthcare data analysis. Aim : To resolve these issues, we employ the proposed system of Industry 4.0 smart manufacturing for IoT-enabled healthcare data analysis in virtual hospital systems with machine learning (ML) techniques. Methods : The proposed system contains five alternative solutions under smart manufacturing. First, the healthcare data analysis is applied for Weber’s syndrome. That is, this will be used to analyze Weber’s syndrome during its consistent treatment. Second, the IoT-enabled healthcare data handling system works based on edge-assisted edge computing that is used to apply IoT to the healthcare data handling system. The healthcare data analysis in virtual hospital systems uses machine learning for driving data synthesis. Finally, the Industry 4.0 smart manufacturing is applied to the IoT-enabled healthcare data analysis to realize efficient data digitization, especially in smart hospitals with smart sensors for virtual IoT-enabled devices surveillance of Weber’s syndrome. Result : The data digitization based on Industry 4.0 smart manufacturing analysis is considered for data processing, storage and transmission. The proposed system is 62% more efficient than the other analyzed methods. The identification of Weber’s syndrome is 69.8% more efficient than the existing midbrain stroke syndrome identification. The processing and storage of data results are 45.78% more efficient than the current encryption method. Finally, the priority-aware healthcare data analysis based on ML provides 63.4% efficient, faster and more accurate diagnoses in the personalized treatment.},
  archive      = {J_IJPRAI},
  author       = {S. Phani Praveen and Mohammed Hasan Ali and Mustafa Musa Jaber and Dharam Buddhi and Chander Prakash and Deevi Radha Rani and Tamizharasi Thirugnanam},
  doi          = {10.1142/S0218001423560025},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2356002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {IoT-enabled healthcare data analysis in virtual hospital systems using industry 4.0 smart manufacturing},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weakly supervised salient object detection by hierarchically
enhanced scribbles. <em>IJPRAI</em>, <em>37</em>(2), 2355003. (<a
href="https://doi.org/10.1142/S0218001423550030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of salient object detection (SOD) has been significantly advanced by using deep convolutional networks. However, it largely depends on the high cost of pixel-level annotations. To reduce human effort while improving the prediction accuracy, we propose a novel two-phase learning framework. The weakly supervised information in terms of scribbles is provided as initial labels. Then, as the first phase, high-quality pseudo-labels are generated by mapping scribbles onto object/object-part contours. These contour maps are predicted by the hierarchical contour detection algorithm, providing superior accuracy and smoothness. In the second phase, a deep neural network is alternately trained and predicted. The pseudo-labels are refined in an iterated process, where a conditional random field (CRF) model and a filter module are designed to promote the performance. Extensive experiments on five benchmarks show that our framework can achieve comparable results with the state-of-the-art fully and weakly supervised methods.},
  archive      = {J_IJPRAI},
  author       = {Xiongying Wang and Zaid Al-Huda and Bo Peng and Xin Tang},
  doi          = {10.1142/S0218001423550030},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2355003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Weakly supervised salient object detection by hierarchically enhanced scribbles},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time 3D reconstruction of large-scale scenes with LOD
representation. <em>IJPRAI</em>, <em>37</em>(2), 2355001. (<a
href="https://doi.org/10.1142/S0218001423550017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time 3D reconstruction of static scenes can be achieved based on the RGB-D image sequence fusion. It is a popular practice to divide the space into uniform voxels and use a truncated signed distance function to represent surface information. In order to represent a scene of large scale, the voxel hash algorithm which stores voxels compressively can be used, but most of the conventional methods do not consider the complexity and roughness of the object surface in the scene, so the scene is represented with a uniform resolution. It somewhat limits the range of scene representation and the speed of real-time reconstruction. In this paper, a large-scale scene reconstruction algorithm based on voxel hashing storage with LOD representation is proposed. The main contributions include the following two aspects: (1) By preprocessing the depth image with smooth filtering, which ensures the accuracy of the data, it can effectively reduce the distortion caused by the sensor itself and violent motion and provide better support for the stages of voxel hashing, model rendering, and frame-to-model camera position tracking. (2) The 3D reconstruction with LOD representation is realized. We take the view distance and the roughness of the model surface as criteria to control the adaptive division and representation of spatial voxel blocks. Finally, we carried out qualitative and quantitative evaluations of the algorithm, and confirmed that the algorithm can achieve real-time reconstruction with different levels of detail in the commercial graphics processing hardware environment, and achieve a good fusion effect in large-scale scenes.},
  archive      = {J_IJPRAI},
  author       = {Haohai Fu and Huamin Yang and Chunyi Chen},
  doi          = {10.1142/S0218001423550017},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2355001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Real-time 3D reconstruction of large-scale scenes with LOD representation},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved PoinTr point cloud completion method based on
feature enhancement. <em>IJPRAI</em>, <em>37</em>(2), 2354002. (<a
href="https://doi.org/10.1142/S0218001423540022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the issue that point cloud data is often incomplete and difficult to obtain, we propose a point cloud completion method to improve the PoinTr method based on feature enhancement. In dataset preprocessing, the farthest point of the original point cloud is sampled to obtain the central point coordinates. Our method constructs an MLP network, where the local information of these central points is obtained and the location embedding is performed. Combining network and SENet network, the local features of the point cloud are extracted and enhanced, and the location embedding and local features are added to obtain the point proxies of the original point cloud. Afterward, our method predicts the missing part of the point cloud by using an Encoder to model the relationship between the point cloud structure information and points, and then using a Decoder to learn the relationship between the missing and existing parts of the point cloud and reconstruct the missing point cloud. Our method also modifies the attention mechanism to make the features more global and enhance the network expression. Finally, the point cloud is refined, and is realized by predicting multiple points around each point of the coarse point cloud through the FoldingNet network, and the final output is the complete point cloud. Experimental results show that the proposed method can not only reduce the performance overhead, but also improve the effects of point cloud completion.},
  archive      = {J_IJPRAI},
  author       = {Haiyan Sun and Zaichao Lin and Qingtao Lu and Sichen Jia and Xingquan Cai},
  doi          = {10.1142/S0218001423540022},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2354002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An improved PoinTr point cloud completion method based on feature enhancement},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual-channel capsule generative adversarial network
optimized with golden eagle optimization for pediatric bone age
assessment from hand x-ray image. <em>IJPRAI</em>, <em>37</em>(2),
2354001. (<a href="https://doi.org/10.1142/S0218001423540010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bone age assessment (BAA) is mainly utilized for detecting the growth of pediatrics because a large number of bone diseases occur at young age. Several algorithms related to BAAs were used for detecting the maturity of bones, but it does not provide sufficient accuracy, and also increased the error rate. To deal with these problems, the dual-channel capsule generative adversarial network optimized with Golden eagle optimization (GEO) is proposed in this paper for pediatric BAA from hand X-ray image (DCCGAN-GEO-BAA-HX-ray). Initially, the input hand X-ray imageries are collected from the dataset of Radiological Society of North America (RSNA) pediatric bone age (BA). Then, region of interest (RoI) of input hand X-ray imageries is segmented based on Tsallis entropy-based multilevel 3D Otsu thresholding (TE-3D-Otsu). Here, TE-3D-Otsu method segments the RoI region of wrist, thumb, middle finger, little finger, which enhance the classification accuracy. Moreover, the segmented RoI is given to DCCGAN that predicts the BAA. Generally, the DCCGAN does not reveal any adoption of optimization methods to scale the optimum parameters to ensure accurate classification. Therefore, GEO is used for optimizing the weight parameters of DCCGAN. The proposed DCCGAN-GEO-BAA-HX-ray method is executed in MATLAB and its performance is examined under performance metrics such as accuracy, precision, sensitivity, F-scores, specificity, concordance correlation coefficient (CCC) and computational time. Finally, the proposed DCCGAN-GEO-BAA-HX-ray approach attains 14.68%, 7.142%, 9.23% and 4.65% higher accuracy, 38.18%, 12.02%, 11.56% and 7.59% lower computational time is compared with existing FRCNN-AF-SFO-BAA-HX-ray, DCNN-W-CTO-BAA-HX-ray, CNN-MLP-BAA-HX-ray and CNN-BAA-HX-ray methods.},
  archive      = {J_IJPRAI},
  author       = {J. Jasper Gnana Chandran and R. Karthick and R. Rajagopal and P. Meenalochini},
  doi          = {10.1142/S0218001423540010},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2354001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Dual-channel capsule generative adversarial network optimized with golden eagle optimization for pediatric bone age assessment from hand X-ray image},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Video recommendation method based on deep learning of group
evaluation behavior sequences. <em>IJPRAI</em>, <em>37</em>(2), 2352002.
(<a href="https://doi.org/10.1142/S021800142352002X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Massive video resources satisfy the interests of users on online video platforms but have led to the problem of the “explosion” of video resources. Meanwhile, some problems will also occur such as the sparse data, difficulty in extracting deep features and dynamic changes in user interests in video recommendation. Aiming at the problems, a video recommendation method is proposed based on the deep learning of group evaluation behavior. Using the Word2Vec word vector model, a video is mapped into a high-dimensional feature vector in an evaluation behavior sequence, a video feature vector library is generated, and a feature vector model of the video sequence is established. The convolutional neural networks (CNN), residual networks, and attention mechanisms are integrated to learn the deep connections between video feature vectors and to predict the candidate video sets. The candidate set is expanded by cosine similarity, and a dynamic interest model is established to filter and sort it. Experiments on the Movie-1M dataset show that this method can effectively improve the accuracy and recall rate of video recommendation, which verifies the feasibility and effectiveness of the method.},
  archive      = {J_IJPRAI},
  author       = {Shenquan Huang and Gao Liu and Yarong Chen and Hongming Zhou and Yujie Wang},
  doi          = {10.1142/S021800142352002X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2352002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Video recommendation method based on deep learning of group evaluation behavior sequences},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantum-inspired owl search algorithm with ensembles of
filter methods for gene subset selection from microarray data.
<em>IJPRAI</em>, <em>37</em>(2), 2351001. (<a
href="https://doi.org/10.1142/S0218001423510011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding the optimum subset of genes for microarray classification is laborious because microarray data are often high-dimensional and contain many irrelevant and redundant genes. To overcome this problem, we have proposed a two-step technique. In the first step, to reduce the vast number of genes or features, an ensemble of popular rank-based feature selection algorithms with filter evaluation metrics are used to select a group of top-ranking genes. In the next step, the quantum-inspired owl search algorithm ( QIOSA f ), a new filter fitness function-based metaheuristic search technique incorporating concepts from quantum computing, is developed to identify the best subset of genes from the predetermined list. The experimental findings reveal that the ensemble approach in the first step can select more dominant groups of genes than each of the individual filters. Furthermore, it has been found that QIOSA f can reduce the cardinality of the selected optimum gene subset with comparable classification accuracy and requires lesser computational time than our earlier proposed QIOSA-based wrapper approach (i.e. QIOSA w ). Besides, compared with three popular evolutionary feature subset selection algorithms, QIOSA f efficiently reduces the optimum cardinality of the gene subset while maintaining acceptable classification accuracy.},
  archive      = {J_IJPRAI},
  author       = {Ashis Kumar Mandal and Rikta Sen and Basabi Chakraborty},
  doi          = {10.1142/S0218001423510011},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2351001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Quantum-inspired owl search algorithm with ensembles of filter methods for gene subset selection from microarray data},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An algorithm for single view occlusion area detection in
binocular stereo matching. <em>IJPRAI</em>, <em>37</em>(2), 2350003. (<a
href="https://doi.org/10.1142/S0218001423500039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Occlusion area detection is a crucial step affecting the performance of the binocular stereo matching algorithm, but the traditional method of occlusion area detection has two major problems, including left–right consistency detection (LRC). First, these algorithms must obtain the left and right disparity maps with precision. Second, these algorithms cannot detect the occlusion region at the image’s borders. We propose the single view occlusion area detective (SVOAD) algorithm to detect these occlusion areas and better deal with them. The SVOAD can detect the area of occlusion from a single image, thereby reducing the computational cost. Additionally, the algorithm can detect the occlusion region in all image regions. This paper also improves the guided filter so that it works better with the end-to-end neural network and makes the SVOAD algorithm work better.},
  archive      = {J_IJPRAI},
  author       = {Ren Qian and Yong Zhao and Renyan Feng and Wenbang Yang and Zaijun Zhang},
  doi          = {10.1142/S0218001423500039},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2350003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An algorithm for single view occlusion area detection in binocular stereo matching},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Small object detection methods in complex background: An
overview. <em>IJPRAI</em>, <em>37</em>(2), 2350002. (<a
href="https://doi.org/10.1142/S0218001423500027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small object detection has been a research hotspot in the field of computer vision. Especially in complex backgrounds (CBs), SOD faces various challenges, including inconspicuous small object features, object distortion due to CBs interference, and inaccurate object localization due to various noises. So far, many methods have been proposed to improve the SOD content in CBs. In this paper, based on an extensive study of related literature, we first outline the current challenges and some cutting-edge solutions for SOD, and then introduce the complex background interference types present in small object images and the imaging characteristics of different types of images, as well as the characteristics of small objects. Next, the image pre-processing methods are summarized. Based on this, machine learning-based SOD methods and traditional SOD methods are focused on. Finally, the future development direction is given.},
  archive      = {J_IJPRAI},
  author       = {Zhigang Li and Qimei Guo and Bo Sun and Difei Cao and Yingqi Li and Xiaochuan Sun},
  doi          = {10.1142/S0218001423500027},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2350002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Small object detection methods in complex background: An overview},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An algorithm for network security situation assessment based
on deep learning. <em>IJPRAI</em>, <em>37</em>(2), 2252031. (<a
href="https://doi.org/10.1142/S0218001422520310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problems that the existing assessment methods are difficult to solve, such as the low efficiency and uncertainty of network security situation assessment in complex network environment, by constructing the characteristic elements of network security big data, a typical model based on deep learning, long short-term memory (LSTM), is established to assess the network security situation in time series. The hidden relationship and change trend of network security situation are automatically mined and analyzed through the deep learning algorithm of big data, which greatly improves the prediction accuracy of security situation. Experimental analysis shows that this method has a better assessment effect on network threats, has higher learning efficiency than the traditional network situation assessment methods, and has strong representation ability in the face of network threats. It can more accurately and effectively assess the changing trend of big data security situation in the future.},
  archive      = {J_IJPRAI},
  author       = {Zhicheng Wen and Linhua Peng and Weiqing Wan and Jing Ou},
  doi          = {10.1142/S0218001422520310},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2252031},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An algorithm for network security situation assessment based on deep learning},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Synthetic minority oversampling technique based on adaptive
noise optimization and fast search for local sets for random forest.
<em>IJPRAI</em>, <em>37</em>(1), 2259038. (<a
href="https://doi.org/10.1142/S0218001422590388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification is usually degraded due to the imbalanced class distribution. Synthetic minority oversampling technique (SMOTE) has been successful in improving imbalanced classification and has received great praise. Overgeneralization is one of the most challenges in SMOTE. Although multiple SMOTE-based variations are proposed against overgeneralization, they still have the following shortcomings: (a) creating too many synthetic samples in high-density regions; (b) removing suspicious noise directly instead of modifying them; (c) relying on many parameters. This paper proposes a new SMOTE based on adaptive noise optimization and fast search for local sets (SMOTE-ANO-FLS) to overcome the overgeneralization and the shortcomings of existing works. First, SMOTE-ANO-FLS uses the k -D tree to fast search the local sets for each sample. Second, a new noise detection method based on local sets and the imbalanced ratio is proposed to detect suspicious noise. Third, a new adaptive noise optimization method is proposed to modify detected suspicious noise instead of removing them. Finally, a new probability weight based on local sets is proposed to help create more synthetic minority class samples in borderline and sparse regions. The effectiveness of SMOTE-ANO-FLS is proven by employing 7 oversampling methods and random forest on the extensive synthetic and real data sets.},
  archive      = {J_IJPRAI},
  author       = {Shaofu Luo},
  doi          = {10.1142/S0218001422590388},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2259038},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Synthetic minority oversampling technique based on adaptive noise optimization and fast search for local sets for random forest},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exponential stability of stochastic inertial cohen–grossberg
neural networks. <em>IJPRAI</em>, <em>37</em>(1), 2259032. (<a
href="https://doi.org/10.1142/S0218001422590327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we adopt two methods to study the problem. Initially, directly from the second-order differential equation, we obtain a sufficient condition (SC) for the mean square exponential stability (MSES) of the system at the equilibrium point by constructing a suitable function and applying some properties of calculus. Thereafter, the system is transformed into a vector form, using the basic solution matrix of linear differential equation, constructing a piecewise function and using the generalized Halanay one-dimensional delay differential inequality, another SC is given for the P-moment exponential stability (PMES) of the system at the equilibrium point. Finally, two examples are used to investigate the correctness and demonstrate that each SC has own advantage, the suitable theorem can be selected according to the parameters.},
  archive      = {J_IJPRAI},
  author       = {Yuehong Zhang and Zhiying Li and Wangdong Jiang and Wei Liu},
  doi          = {10.1142/S0218001422590327},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2259032},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Exponential stability of stochastic inertial Cohen–Grossberg neural networks},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature extraction and pattern recognition algorithm of
power cable partial discharge signal. <em>IJPRAI</em>, <em>37</em>(1),
2258010. (<a href="https://doi.org/10.1142/S0218001422580101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The degree of insulation aging of power cables is closely related to their partial discharge (PD) level, so the analysis of PD signals can be used to realize the cable condition detection. However, after performing online detection of PDs on power cables, the collected signals always contain interference signals due to the influence of electromagnetic interference in the field. In order to identify each type of local discharge signal from the interference signal, this paper proposes a clustering identification algorithm for local discharge signals, which mainly involves pulse extraction, feature parameter extraction and clustering identification process. The algorithm first extracts the pulse signal by combining the amplitude–time threshold method and the time domain energy method, then obtains the feature vector of the signal according to the synchronous multi-channel method, designs a fuzzy C-mean clustering algorithm based on subtractive clustering to determine the initial clustering center to cluster the samples and finally analyzes and checks the clustering results according to the phase resolved PD (PRPD) of a single class of signals and the fit of the two-parameter Weibull distribution function. The clustering results were analyzed and examined. The experimental results show that the proposed algorithm can extract pulse signals efficiently and accurately, and the synchronous multi-channel method can characterize pulse signals better. Meanwhile, the algorithm can determine the optimal number of classes adaptively according to the clustering effectiveness function and adopt subtractive clustering to initialize the clustering center, which can approach the optimal solution faster, and can effectively cluster a variety of discharge signals, so as to realize the type identification of single-class discharge signals.},
  archive      = {J_IJPRAI},
  author       = {Jie Du and Jianwei Mi and Zhanpeng Jia and Jiaxiang Mei},
  doi          = {10.1142/S0218001422580101},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2258010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Feature extraction and pattern recognition algorithm of power cable partial discharge signal},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A balanced triplet loss for person re-identification.
<em>IJPRAI</em>, <em>37</em>(1), 2256022. (<a
href="https://doi.org/10.1142/S0218001422560225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to cross-entropy in deep learning, triplet loss is less affected by the biased label information and widely used in fine-grained visual tasks. Especially in person re-identification (re-ID), triplet loss is improved with batch-hard sampling which only selects the hardest samples during the training process to reduce invalid triplets involved in the loss computation. The hardest samples’ loss computation can provide a more intense gradient descent than raw samples. However, the batch-hard triplet loss discards multiple samples with important information, which can negatively impact feature learning. Besides, the hardest samples cause loss stuck problems frequently in training. In this work, we propose a balanced triplet loss for comprehensive feature learning and stable model convergence. The balanced triplet loss only mines the hardest negative samples of each category within a mini-batch. Compared with batch-hard triplet loss, it preserves the features of all the negative categories rather than one negative category with the hardest negative sample. It achieves a balance between triplet selection and information loss. The experiments show that our method can produce competitive results in re-ID tasks. In addition, we analyze the correlation between the intensity of data mining and the granularity of feature learning and further adapt the balanced triplet loss to general fine-grained image classification. The experiments prove the adapted balanced triplet loss also outperforms cross-entropy in multiple datasets of different scales.},
  archive      = {J_IJPRAI},
  author       = {Zhenyu Lu and Yonggang Lu},
  doi          = {10.1142/S0218001422560225},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2256022},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A balanced triplet loss for person re-identification},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-object detection method based on adaptive feature
adjustment of 3D point cloud in indoor scenes. <em>IJPRAI</em>,
<em>37</em>(1), 2255021. (<a
href="https://doi.org/10.1142/S0218001422550217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the complexity and diversity of indoor environment objects and interference occlusions, the accuracy of multi-object target detection based on 3D point cloud is limited. To address this issue, we present a multi-target detection method based on adaptive feature adjustment (AFA) of 3D point cloud. First, our method preprocesses the dataset and constructs a backbone module. Afterwards, our method uses an improved PointNet + + network for feature adaptive learning, where an AFA module is added to learn the influence relationship between point pairs. The proposed method then establishes the relationship between contexts in the local point set area and extracts the feature of point cloud. Using the idea of Hough voting, our method can generate some votes close to the particle. Using these votes to generate proposal, the proposed method adds CBAM attention mechanisms to both modules of voting and proposal, which can fuse the feature information of the channel and expand the receptive field in space. Our method can enhance the important features and weaken the unimportant features, making the extracted features more directional and enhancing the expressiveness of the network. Finally, the generated results are visualized to complete the multi-target detection of 3D point cloud. To verify the effectiveness of our proposed method, two large datasets with real 3D scanning, scanNet2 and SunRGB-D, are used for training the network. The experimental results show that the proposed method can improve the effectiveness of point cloud target detection in indoor scenes, getting a higher detection accuracy.},
  archive      = {J_IJPRAI},
  author       = {Haiyan Sun and Keng Chen and Shun Zhou and Sichen Jia and Xingquan Cai},
  doi          = {10.1142/S0218001422550217},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2255021},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A multi-object detection method based on adaptive feature adjustment of 3D point cloud in indoor scenes},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Political improved invasive weed optimization-driven hybrid
exemplar technique for video inpainting process. <em>IJPRAI</em>,
<em>37</em>(1), 2255018. (<a
href="https://doi.org/10.1142/S0218001422550187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video inpainting aspires to fill the Spatio-temporal holes in videos with probable and coherent content. This process recovers the missing content of corrupted video effectively, which is useful in many fields, including removal of watermarking and video restoration. The difficulties of creating video contents with exquisite detail while maintaining spatiotemporal coherence in the missing areas is the main difficulty in the video inpainting process. Modern studies ignore semantic structural coherence maintenance between frames in favor of using flow information to synthesize temporally smooth pixels. In this paper, Political Improved Invasive Weed Optimization (PIIWO)-based optimal exemplar is designed for the productive video inpainting process. Accordingly, the developed PIIWO algorithm is newly designed by combining Political Optimizer (PO) and Improved Invasive Weed Optimization (IIWO). Here, the inpainting results obtained from context-aware Ant Lion Gray Wolf Optimization (ALGWO)-based Markov Random Field (MRF) modeling, Whale Monarch Butterfly Optimization (Whale MBO)-based Deep Convolutional Neural Network (DCNN), K-Nearest Neighbors (KNN) with Bhattacharya distance, Bi-harmonic function modules and developed PIIWO-based exemplar model are fused using Bayes probabilistic fusion for producing the final result. Three metrics, peak signal-to-noise ratio (PSNR), second derivative like the measure of enhancement (SDME) and structural similarity (SSIM) of 40.19 dB, 78.07 dB and 0.9857, respectively, are used to assess the performance of the developed video inpainting technique.},
  archive      = {J_IJPRAI},
  author       = {Manjunath R Hudagi and Shridevi Soma and Rajkumar L Biradar},
  doi          = {10.1142/S0218001422550187},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2255018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Political improved invasive weed optimization-driven hybrid exemplar technique for video inpainting process},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Remote sensing image instance segmentation based on
attention balanced feature pyramid. <em>IJPRAI</em>, <em>37</em>(1),
2254020. (<a href="https://doi.org/10.1142/S0218001422540209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the development of remote sensing technology and the enhancement of the value of remote sensing images in military and civil fields, remote sensing image object segmentation has also received more and more attention. This paper mainly studies the application of instance segmentation based on deep convolutional neural network in the remote sensing image. This paper proposes an attention balanced feature pyramid module, which strengthens multi-level features and uses the attention module to suppress the interference features of noise in the complex background. In addiction, Soft-NMS is introduced to improve the performance of the network, and GIoU loss is introduced to improve the effect of object detection. The proposed network improves the average detection and segmentation accuracy (mAP) values from 4 1 . 7 5 % and 3 5 . 3 4 % to 4 3 . 0 5 % and 3 6 . 0 2 % , respectively.},
  archive      = {J_IJPRAI},
  author       = {Xuan Nie and Hailin Wang and Bosong Chai and Mengyang Duan},
  doi          = {10.1142/S0218001422540209},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2254020},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Remote sensing image instance segmentation based on attention balanced feature pyramid},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Leveraging deep learning to fingerprint spoof detectors:
Hitherto and futuristic perspectives. <em>IJPRAI</em>, <em>37</em>(1),
2252029. (<a href="https://doi.org/10.1142/S0218001422520292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fingerprints being the most widely employed biometric trait, due to their high acceptability and low sensing cost, have replaced the traditional methods of human authentication. Although, the deployment of these biometrics-based recognition systems is accelerating, they are still susceptible to spoofing attacks where an attacker presents a fake artifact generated from silicone, candle wax, gelatin, etc. To safeguard sensor modules from these attacks, there is a requirement of an anti-deception mechanism known as fingerprint spoof detectors (FSD) also known as anti-spoofing mechanisms. A lot of research work has been carried out to design fingerprint anti-spoofing techniques in the past decades and currently, it is oriented towards deep learning (DL)-based modeling. In the field of fingerprint anti-spoofing, since the 2014, the paradigm has shifted from manually crafted features to deep features engineering. Hence, in this study, we present a detailed analysis of the recent developments in DL based FSDs. Additionally, we provide a brief comparative study of standard evaluation protocols that include benchmark anti-spoofing datasets as well as performance evaluation metrics. Although significant progress has been witnessed in the field of DL-based FSDs, still challenges are manifold. Therefore, we investigated these techniques critically to list open research issues along with their viable remedies that may put forward a future direction for the research community. The majority of the research work reveals that deep feature extraction for fingerprint liveness detection demonstrates promising performance in the case of cross-sensor scenarios. Though convolution neural network (CNN) models extract deep-level features to improve the classification accuracy, their increased complexity and training overhead is a tradeoff between both the parameters. Furthermore, enhancing the performance of presentation attack detection (PAD) techniques in the cross-material scenario is still an open challenge for researchers.},
  archive      = {J_IJPRAI},
  author       = {Samridhi Singh and Arvind Selwal and Deepika Sharma},
  doi          = {10.1142/S0218001422520292},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2252029},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Leveraging deep learning to fingerprint spoof detectors: Hitherto and futuristic perspectives},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated SAR image segmentation and classification using
modified deep learning. <em>IJPRAI</em>, <em>37</em>(1), 2252027. (<a
href="https://doi.org/10.1142/S0218001422520279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthetic Aperture Radar (SAR) represents a type of active remote sensing technology that uses microwave electromagnetic radiation to produce and send data to the surface of a target location. SAR imaging is frequently used in national security applications since it is unaffected by weather, geographical location, or time. In this system, many approaches are examined, to improve automation for segmentation and classification. The utilization of Deep Neural Networks (DNNs) to classify SAR images has gotten a lot of attention, and it usually requires several layers of deep models for feature learning. With insufficient training data, however, the DNN will get affected by the overfitting issue. The major purpose of this work is to make a development on introducing a new framework for SAR image segmentation and categorization using deep learning. Owing to the coherent nature of the backscattering signal, SARs create speckle noise in their images. If the image has noisy material, classification becomes more challenging. Hence, the pre-processing of the images is employed by linear spatial filtering to remove the noise. Further, the Optimized U-Net is used for the segmentation. For the segmented images, the Binary Robust Independent Elementary Features (BRIEF) concept is adopted as the feature descriptor. These features are inputted to the Convolutional Neural Network (CNN) with Tuned Weight DNN (C-TWDNN) for the classification. In both segmentation and classification, the parameter tuning is employed by the combination of Galactic Swarm Optimization (GSO) and Deer Hunting Optimization Algorithm (DHOA) called the Self-adaptive-Galactic Deer Hunting Optimization (SA-GDHO). Experiments are conducted on a variety of public datasets, demonstrating that our method is capable of outperforming various expert systems and deep structured architectures.},
  archive      = {J_IJPRAI},
  author       = {G. Srinitya and D. Sharmila and S. Logeswari and S. Daniel Madan Raja},
  doi          = {10.1142/S0218001422520279},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2252027},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Automated SAR image segmentation and classification using modified deep learning},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A network security situation awareness method based on GRU
in big data environment. <em>IJPRAI</em>, <em>37</em>(1), 2251018. (<a
href="https://doi.org/10.1142/S0218001422510181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the “bottleneck” problems of the traditional network security situation awareness model, such as large equipment limitations, single data source and poor integration ability, weak level of autonomous learning and data mining, a network security situation awareness framework suitable for big data is constructed. A gate recurrent unit (GRU) model is established to effectively extract features from the situation data set through the deep learning algorithm of big data. It is a method to automatically mine and analyze the hidden relationship and change trend of network security situation, realize the high-speed acquisition and fusion of massive multi-source heterogeneous data, and perceive the network security situation from an all-round perspective. The experimental results show that this method has a good awareness effect on network threats, and has strong representation ability in the face of network threats. It can effectively perceive the network threat situation without relying on data labels, which verifies that this method can effectively improve the efficiency and accuracy of security situation awareness.},
  archive      = {J_IJPRAI},
  author       = {Zhicheng Wen and Longxin Zhang and Qinlan Wu and Wengui Deng},
  doi          = {10.1142/S0218001422510181},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2251018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A network security situation awareness method based on GRU in big data environment},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Few-shot directed meta-learning for image classification.
<em>IJPRAI</em>, <em>37</em>(1), 2251017. (<a
href="https://doi.org/10.1142/S021800142251017X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from only few samples is a challenging problem and meta-learning is an effective approach to solve it. Meta-learning model aims to learn by training a large number of other samples. When encountering target task, the model can quickly adapt and obtain better performance with only few labeled samples. However, general meta-learning only provides a universal model that has certain generalization ability for all unknown tasks, which causes limited effects on specific target tasks. In this paper, we propose a Few-shot Directed Meta-learning (FSDML) model to specialize and solve the target task by using few labeled samples of the target task to direct the meta-learning process. FSDML divides model parameters into shared parameters and target adaptation parameters to store prior knowledge and determine the update direction. These two parts of the parameters are updated in different stages of training. We conduct experiments of image classification task on miniImageNet and Omniglot and the results show that FSDML has better performance.},
  archive      = {J_IJPRAI},
  author       = {Jihong Ouyang and Ganghai Duan and Siguang Liu},
  doi          = {10.1142/S021800142251017X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2251017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Few-shot directed meta-learning for image classification},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved traffic sign recognition algorithm based on
YOLOV4-tiny. <em>IJPRAI</em>, <em>37</em>(1), 2250048. (<a
href="https://doi.org/10.1142/S0218001422500483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an improved YOLOV4-tiny traffic sign recognition algorithm for easy deployment on mobile or embedded devices to address the problems of a large number of parameters, low recognition accuracy in complex scenarios. The model uses the YOLOV4-tiny network as the basic framework. First, Octave Convolution is introduced into the backbone network to reduce the redundancy of low-frequency features. Second, the convolutional block attention module is used to strengthen the weights of traffic sign regions and reduce the weights of invalid features. Finally, the Feature Pyramid Network structure is replaced by the Simplified Path Aggregation Network structure in the feature fusion stage to enhance the feature information and further reduce the miss detection rate. The experiment proves that our method outperforms YOLOV4-tiny in recognition accuracy and detection speed on the TT100 K dataset, and can easily meet the requirements of traffic sign recognition.},
  archive      = {J_IJPRAI},
  author       = {Haile Zong and Chengming Qi},
  doi          = {10.1142/S0218001422500483},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2250048},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Improved traffic sign recognition algorithm based on YOLOV4-tiny},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fast and accurate human pose estimation method based on
multi-scale feature fusion grid structure. <em>IJPRAI</em>,
<em>37</em>(1), 2250044. (<a
href="https://doi.org/10.1142/S0218001422500446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human pose estimation (HPE) is a research hotspot in the field of computer vision. Most of the existing approaches first generate low-resolution representation from high-resolution representation through continuous serial downsampling, and then reconstruct high-resolution results from low-resolution features through continuous serial upsampling, which loses a lot of effective feature information and leads to slow model inference. In this paper, the Fast Accuracy Network (FANet), a framework that enables fast and high-accuracy HPE, is proposed. The innovation lies in that, first of all, a grid structure is proposed and adopted, which can be regarded as a set of deep paths and shallow paths. The structure uses multiple high-resolution and low-resolution branch pairs to perform skip-level connections at different scale-space levels so that the information can be exchanged between different resolution representations for many times. The feature information fusion of multi-scale space is realized to obtain more abundant feature information. Second, an improved bottleneck block is proposed to extract effective feature information with fewer parameters, ensuring that the computational burden is reduced without sacrificing accuracy performance. The experimental results show that, compared with other current models, FANet has faster inference speed on the premise of a slight improvement in accuracy performance.},
  archive      = {J_IJPRAI},
  author       = {Qiming Li and Daizong Wan and Xiaoyan Yang},
  doi          = {10.1142/S0218001422500446},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2250044},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A fast and accurate human pose estimation method based on multi-scale feature fusion grid structure},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). YOLO-f: YOLO for flame detection. <em>IJPRAI</em>,
<em>37</em>(1), 2250043. (<a
href="https://doi.org/10.1142/S0218001422500434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flame detection is of great significance in a fire prevention system. YOLOv4 has poor real-time performance on flame detection caused by the complex structure and high parameter size. To address this problem, a novel flame detection framework, YOLO for flame (YOLO-F), is proposed in this paper. The backbone of YOLOv4 is simplified from the original 53 convolutional layers to 34 convolutional layers to reduce the number of parameters by simplifying the structure of the CSPBlock. Based on the FPN, an effective and light-weight feature pyramid architecture, namely FPNs-SE, is then proposed and the neck part of YOLOv4 is replaced by FPNs-SE to enhance the feature extraction ability of different scales. In addition, the CIoU loss in the YOLOv4 ignores the similarity measure of the area between the predicted bounding box and the ground-truth bounding box. An effective loss named ACIoU is proposed in this paper in order to handle the above issue and further improve the detection accuracy. The proposed methods are tested on FLAME dataset and network crawled dataset, respectively. The mAP, recall, and precision of YOLO-F are higher by 2.01%, 4.0%, 2.0% on average than those of YOLOv4. With input size of 4 1 6 × 4 1 6 and on a single GTX 1660, the operating speed of our method can reach 24.53 fps, which is improved by 38.04% compared with YOLOv4. The experimental results show that our method is more robust to the small flame and flame-like objects and can achieve the best balance of detection speed and accuracy. The code is made available at https://github.com/Windxy/YOLO-F .},
  archive      = {J_IJPRAI},
  author       = {Kun Xu and Yuan Xu and Yuanxin Xing and Zhanwen Liu},
  doi          = {10.1142/S0218001422500434},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2250043},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {YOLO-F: YOLO for flame detection},
  volume       = {37},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
