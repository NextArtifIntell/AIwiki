<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TEVC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tevc---14">TEVC - 14</h2>
<ul>
<li><details>
<summary>
(2025). Adaptive similarity feature construction for ontology
matching via multi-layer hybrid genetic programming. <em>TEVC</em>, 1.
(<a href="https://doi.org/10.1109/TEVC.2025.3547578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ontology is a kernel technique of the semantic web, which defines concepts, properties, and their relationships to establish a shared understanding of domain knowledge. Ontology matching identifies semantically similar entities across different ontologies, which uses similarity features to measure their similarity from different perspectives. However, due to the complexity of the entity heterogeneity, no single similarity feature is universally effective. In recent years, genetic algorithms have proven effective in constructing similarity features for ontology matching, but their potential is limited by the reliance on default classification strategies, empirical determination of the number of high-level features, the requirement for manually selecting, combining these features, and tuning the associated combination parameters. To overcome these drawbacks, we propose a multi-layer hybrid genetic programming approach to automatically construct high-level similarity features. This approach includes three novel components. First, a new multi-layer individual representation is designed, which faciliates the algorithm to adaptively explore the search space of constructing high-level similarity features. Second, to enhance the search effectiveness, a new initialization method and a mutation operator are developed, which use a weight-based strategy to adaptively select and construct a more diverse set of similarity features. Third, a compact genetic algorithm-based optimizer is designed to refine the tree structures of elite individuals. The experimental results on the ontology alignment evaluation initiative’s benchmark show that our algorithm can generate high-quality ontology matching results across various matching tasks, significantly outperforming the state-of-the-art ontology matching methods.},
  archive      = {J_TEVC},
  author       = {Xingsi Xue and Yi Mei and Baozhong Zhao and Mengjie Zhang},
  doi          = {10.1109/TEVC.2025.3547578},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {3},
  pages        = {1},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Adaptive similarity feature construction for ontology matching via multi-layer hybrid genetic programming},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the performance-reproducibility trade-off in
quality-diversity. <em>TEVC</em>, 1. (<a
href="https://doi.org/10.1109/TEVC.2025.3548438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality-Diversity (QD) algorithms have exhibited promising results across many domains and applications. However, uncertainty in fitness and behaviour estimations of solutions remains a major challenge when QD is used in complex real-world applications. While several approaches have been proposed to improve the performance in uncertain applications, many fail to address a key challenge: determining how to prioritise solutions that perform consistently under uncertainty, in other words, solutions that are reproducible. Most prior methods improve fitness and reproducibility jointly, ignoring the possibility that they could be contradictory objectives. For example, in robotics, solutions may reliably walk at 90% of the maximum velocity in uncertain environments, while solutions that walk faster are also more prone to falling over. As this is a trade-off, neither one of these two solutions is “better&quot; than the other. Thus, algorithms cannot intrinsically select one solution over the other, but can only enforce given preferences over these two contradictory objectives. In this paper, we formalise this problem as the performance-reproducibility trade-off for uncertain QD. We propose two new a-priori QD algorithms that find efficient solutions for given preferences over the trade-offs. We also propose an a-posteriori QD algorithm for when these preferences cannot be defined in advance. Our results show that our approaches successfully find solutions that satisfy given preferences. Importantly, by simply accounting for this trade-off, our approaches perform better than existing uncertain QD methods. This suggests that considering the performance-reproducibility trade-off unlocks important stepping stones that are usually missed when only performance is optimised.},
  archive      = {J_TEVC},
  author       = {Manon Flageat and Hannah Janmohamed and Bryan Lim and Antoine Cully},
  doi          = {10.1109/TEVC.2025.3548438},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {3},
  pages        = {1},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Exploring the performance-reproducibility trade-off in quality-diversity},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Runtime analysis of the compact genetic algorithm on the
LeadingOnes benchmark. <em>TEVC</em>, 1. (<a
href="https://doi.org/10.1109/TEVC.2025.3549929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The compact genetic algorithm (cGA) is one of the simplest estimation-of-distribution algorithms (EDAs). Next to the univariate marginal distribution algorithm (UMDA)– another simple EDA–, the cGA has been subject to extensive mathematical runtime analyses, often showcasing a similar or even superior performance to competing approaches. Surprisingly though, up to date and in contrast to the UMDA and many other heuristics, we lack a rigorous runtime analysis of the cGA on the LEADINGONES benchmark–one of the most studied theory benchmarks in the domain of evolutionary computation. We fill this gap in the literature by conducting a formal runtime analysis of the cGA on LEADINGONES. For the cGA’s single parameter–called the hypothetical population size–at least polylogarithmically larger than the problem size, we prove that the cGA samples the optimum of LEADINGONES with high probability within a number of function evaluations quasi-linear in the problem size and linear in the hypothetical population size. For the best hypothetical population size, our result matches, up to polylogarithmic factors, the typical quadratic runtime that many randomized search heuristics exhibit on LEADINGONES. Our analysis exhibits some noteworthy differences in the working principles of the two algorithms which were not visible in previous works.},
  archive      = {J_TEVC},
  author       = {Marcel Chwiałkowski and Benjamin Doerr and Martin S. Krejca},
  doi          = {10.1109/TEVC.2025.3549929},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {3},
  pages        = {1},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Runtime analysis of the compact genetic algorithm on the LeadingOnes benchmark},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning-assisted search path reconstruction empowers
evolution algorithm for optimization. <em>TEVC</em>, 1. (<a
href="https://doi.org/10.1109/TEVC.2025.3550259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms serve as a pivotal tool in addressing black-box problems, finding widespread applications across diverse academic disciplines and engineering domains. Despite their utility, these algorithms often confront challenges when navigating complex search spaces, impeding a comprehensive exploration of potential solutions. Solely depending on the algorithm’s exploration abilities falls short of fully harnessing the rich information contained within search spaces. To unlock the full potential of solution spaces, we introduce a deep learning method for the reconstruction of the search path. Specifically, discrete data sampled by evolutionary operators during the exploration process are collected, and a uniquely designed fully connected neural network is employed to reconstruct the exploration paths. The neural network’s robust fitting capability facilitates the transformation of initially discrete sampled information into a continuous form. By capitalizing on the reconstructed solution space information, the algorithm excels in identifying superior solutions. We refer to this method of deep learning-based search path reconstruction evolution strategy algorithm (DLES). The effectiveness of DLES is validated across multiple datasets, including CEC 2014, CEC 2018, CEC 2022 and BBOB. Experimental results, compared to several state-of-the-art algorithms, affirm the superiority of the DLES algorithm.},
  archive      = {J_TEVC},
  author       = {Yaotong Song and Kaiyu Wang and Zhi-Hui Zhan and Zhenyu Lei and Shangce Gao},
  doi          = {10.1109/TEVC.2025.3550259},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {3},
  pages        = {1},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Learning-assisted search path reconstruction empowers evolution algorithm for optimization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multisource and hidden source-based knowledge transfer for
solving dynamic multiobjective optimization problems. <em>TEVC</em>, 1.
(<a href="https://doi.org/10.1109/TEVC.2025.3550557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, transfer learning-based dynamic multiobjective optimization algorithms (TL-DMOAs) have been shown to be very promising in solving dynamic multiobjective optimization problems (DMOPs). However, it is difficult for them to model knowledge capable of delineating the Pareto optimal solutions (POSs) found in each historical environment, because the POSs’ distribution cannot be adequately reflected. Besides, existing TL-DMOAs normally focus on acquiring knowledge from historical environments, but neglect correlations behind them for excavating potential knowledge, restricting the performance in generating high-quality initial populations (HIPs). To address these issues, herein a DMOA with multisource and hidden source-based knowledge transfer (DMOA-MHKT) is proposed. First, we design a knowledge extraction strategy by introducing mean shift, a nonparametric clustering method, to cluster the historical POSs. As clusters’ representatives, the cluster centers are considered to represent environmental knowledge, because they can adequately reflect the POSs’ distribution. Second, the most similar historical environment through environmental match and the last one are selected as two explicit sources. In the former source the POSs’ cluster centers are treated as its knowledge. By contrast, based on the POSs’ cluster centers and knee points in the latter source, a scoring method is designed to generate environmental knowledge by depicting the dynamics between two continuous environments. Third, after aligning knowledge of the explicit sources, a hidden source is learned by excavating correlations and potential knowledge behind them, facilitating the generalization enhancement in generating HIPs. The experimental results especially performance comparisons with seven state-of-the-art DMOAs demonstrate that DMOA-MHKT brings significant improvements in solving DMOPs.},
  archive      = {J_TEVC},
  author       = {Wei Song and Zhi Liu and Jian Yu and Xiaoyan Sun and Yaochu Jin and Khin Wee Lai},
  doi          = {10.1109/TEVC.2025.3550557},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {3},
  pages        = {1},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multisource and hidden source-based knowledge transfer for solving dynamic multiobjective optimization problems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Light-EvoOPT: A lightweight evolutionary optimization
framework for ultra-large-scale mixed integer linear programs.
<em>TEVC</em>, 1. (<a
href="https://doi.org/10.1109/TEVC.2025.3550668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Learning (ML)-based optimization frameworks emerge as a promising technique for solving large-scale Mixed Integer Linear Programs (MILPs), as they can capture the mapping between problem structures and optimal solutions to expedite their solution process. However, existing solution frameworks often suffer from high model computation costs, incomplete problem reduction, and reliance on large-scale solvers, leading to performance bottlenecks in ultra-large-scale problems with complex constraints. To address these issues, this paper proposes Light-EvoOPT, a Lightweight Evolutionary Optimization Framework for Ultra-Large-Scale Mixed Integer Linear Programs, which can be divided into four stages: (1) Problem Formulation for problem division to reduce model computational costs, (2) Model-based Initial Solution Prediction for predicting and constructing the initial solution using a small-scale training dataset, (3) Problem Reduction for both variable and constraint reduction, and (4) Evolutionary Optimization for current solution improvement employing a lightweight optimizer. Experiments on four benchmark datasets with tens of millions of variables and constraints and a real-world problem show that the proposed framework based on the sole use of a lightweight optimizer, trained on only one-thousandth of the scale of ultra-large-scale problems, is able to outperform state-of-the-art ML-based frameworks and advanced solvers (e.g. Gurobi) within a specified computational time, validating the feasibility and effectiveness of our proposed ML-based evolutionary optimization framework for ultra-large-scale MILPs.},
  archive      = {J_TEVC},
  author       = {Huigen Ye and Hua Xu and Carlos A. Coello Coello},
  doi          = {10.1109/TEVC.2025.3550668},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {3},
  pages        = {1},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Light-EvoOPT: A lightweight evolutionary optimization framework for ultra-large-scale mixed integer linear programs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tree structured cooperative coevolutionary genetic algorithm
for fragment reconstruction. <em>TEVC</em>, 1. (<a
href="https://doi.org/10.1109/TEVC.2025.3550742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fragment reconstruction problem aims to assemble the original object from a collection of fragmented pieces. Traditional manual reconstruction techniques heavily rely on expert knowledge and can potentially damage fragile fragments, necessitating the development of automated reconstruction methods. Current reconstruction algorithms often suffer from the curse of dimensionality, compromising both accuracy and efficiency as the number of fragments increases. These algorithms primarily rely on fragment content, limiting their adaptability and scalability. To address these challenges, this paper introduces a novel reconstruction method grounded in a cooperative coevolutionary (CC) optimization framework. This approach encompasses both the formalization of the fragment reconstruction problem and the development of a tailored algorithm to solve it. Notably, our modeling approach is content-independent, relying solely on the edge shapes of the fragments. With this modeling approach, the solution itself represents the reconstruction process of the fragments. To encode candidate solutions efficiently, we employ a tree structure. This encoding scheme renders traditional CC processes and genetic algorithm operators, such as crossover and mutation, inapplicable. Therefore, this paper proposes a tree-structured CC genetic algorithm (T-CCGA) specifically tailored to our reconstruction task. We aim to overcome the limitations of current reconstruction algorithms and pave the way for more accurate and efficient fragment reconstruction methods. To evaluate the effectiveness of the proposed method, we conducted a series of comprehensive experiments. The results demonstrate that T-CCGA achieves promising outcomes in terms of solution quality, convergence speed, and robustness.},
  archive      = {J_TEVC},
  author       = {Xin-Yuan Zhang and Jin-Hao Yang and Yue-Jiao Gong and Zhi-Hui Zhan and Jun Zhang},
  doi          = {10.1109/TEVC.2025.3550742},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {3},
  pages        = {1},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Tree structured cooperative coevolutionary genetic algorithm for fragment reconstruction},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adapting rule representation with four-parameter beta
distribution for learning classifier systems. <em>TEVC</em>, 1. (<a
href="https://doi.org/10.1109/TEVC.2025.3550915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rule representations significantly influence the search capabilities and decision boundaries within the search space of Learning Classifier Systems (LCSs). However, it is very difficult to choose an appropriate rule representation for each problem. Additionally, some problems benefit from using different representations for different subspaces within the input space. Thus, an adaptive mechanism is needed to choose an appropriate rule representation for each rule in LCSs. This article introduces a flexible rule representation using a four-parameter beta distribution and integrates it into a fuzzy-style LCS. The four-parameter beta distribution can form various function shapes, and this flexibility enables our LCS to automatically select appropriate representations for different subspaces. Our rule representation can represent crisp/fuzzy decision boundaries in various boundary shapes, such as rectangles and bells, by controlling four parameters, compared to the standard representations such as trapezoidal ones. Leveraging this flexibility, our LCS is designed to adapt the appropriate rule representation for each subspace. Moreover, our LCS has a generalization bias to produce as many crisp rules as possible. Experimental results on real-world classification tasks show that our LCS significantly outperformed LCSs with popular rule representations in test classification accuracy on up to 17 of the 25 datasets tested.},
  archive      = {J_TEVC},
  author       = {Hiroki Shiraishi and Yohei Hayamizu and Tomonori Hashiyama and Keiki Takadama and Hisao Ishibuchi and Masaya Nakata},
  doi          = {10.1109/TEVC.2025.3550915},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {3},
  pages        = {1},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Adapting rule representation with four-parameter beta distribution for learning classifier systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dynamic interval multi-objective evolutionary algorithm
based on multi-task learning and inverse mapping. <em>TEVC</em>, 1. (<a
href="https://doi.org/10.1109/TEVC.2025.3551355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic interval multi-objective optimization problems, such as those encountered in wireless sensor network scheduling and portfolio selection, are increasingly prevalent. However, they present significant challenges due to the inherent uncertainty and variability of their parameters. This paper proposes a dynamic interval multi-objective evolutionary algorithm in terms of multi-task learning and inverse mapping. The algorithm employs an interval-based MOEA/D as its foundational framework. Upon encountering environmental changes, prediction models for the midpoints and widths of intervals are developed using multi-task learning combined with a self-evolving fuzzy system. These models generate a predicted Pareto front (PF) in the objective space. Subsequently, inverse mappings of the objective functions at the new time are established to identify solutions that correspond to the predicted PF in the decision space. Finally, these solutions are expanded to form an initial population at the new time. Testing on eighteen benchmark optimization problems and an uncertain scheduling of underwater wireless sensor networks, the proposed algorithm demonstrates both competitiveness and superiority when compared to five state-of-the-art algorithms.},
  archive      = {J_TEVC},
  author       = {Feimeng Wang and Jing Sun and Xingjia Gan and Dunwei Gong and Gaige Wang and Yongde Guo},
  doi          = {10.1109/TEVC.2025.3551355},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {3},
  pages        = {1},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A dynamic interval multi-objective evolutionary algorithm based on multi-task learning and inverse mapping},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new prediction strategy for dynamic multi-objective
optimization using diffusion model. <em>TEVC</em>, 1. (<a
href="https://doi.org/10.1109/TEVC.2025.3551323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve dynamic multi-objective optimization problems (DMOPs), the optimization algorithms are required to track the movement of the Pareto set after the environmental changes effectively. Many prediction-based dynamic multi-objective evolutionary algorithms (DMOEAs) have been proposed to address this challenge by utilizing environmental information for population reinitialization. However, when environmental changes are complex, irregular, and severe, the solutions and information during the evolution process often contain noise, making it difficult for prediction-based DMOEAs to accurately predict and reinitialize the population. To address this issue, we propose a novel dynamic multi-objective evolutionary algorithm (DM-DMOEA) which uses a diffusion model based prediction strategy. In DM-DMOEA, to improve the prediction accuracy, the diffusion model is introduced to extract the relationships of high-quality solutions and reinitialize the population, and a PS estimation method is employed to integrate both historical and new environmental information, providing a set of high-quality solutions for diffusion model training. To speed up the response time, a variational autoencoder (VAE) is used to map the decision space to a latent space, which can reduce the diffusion model size and accelerate the diffusion process. To evaluate the effectiveness of the proposed DM-DMOEA on DMOPs, comprehensive experiments are conducted on several benchmarks and a practical problem. The results show that the DM-DMOEA outperforms other four state-of-the-art DMOEAs in most cases.},
  archive      = {J_TEVC},
  author       = {Feng Wang and Jinsong Xie and Aimin Zhou and Ke Tang},
  doi          = {10.1109/TEVC.2025.3551323},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {3},
  pages        = {1},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A new prediction strategy for dynamic multi-objective optimization using diffusion model},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing dynamic constrained multi-objective optimization
with multi-centers based prediction. <em>TEVC</em>, 1. (<a
href="https://doi.org/10.1109/TEVC.2025.3551399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic constrained multi-objective optimization problems (DCMOPs) involve complex changes in objective functions and constraints over time. These changes challenge most existing algorithms to quickly cross infeasible regions and accurately track the changing Pareto optimal set (POS) and Pareto optimal front (POF). To address this issue, this paper presents a multi-centers based prediction strategy, termed FCP, for solving DCMOPs more effectively. First, we introduce a penalty function to cluster the historical optimal solutions, thereby obtaining multi-centers of these solutions. These centers can roughly represent the distribution of different clusters in POS. Then, we predict cluster centers of the new environment’s POS by calculating the distance of centers from the preceding two environments. The prediction strategy can handle the change of POS caused by constraints thereby improving the accuracy of prediction. Finally, a proposed population generator calculates the distances between new centers and utilizes information from these centers to predict a well-distributed initial population. Comprehensive studies on widely used benchmark problems demonstrate that our proposed algorithm is very competitive in dealing with DCMOPs compared with seven state-of-the-art algorithms. Meanwhile, to validate the proposed prediction strategy, it is embedded into the static constraints handling techniques from other DCMOEAs to solving DCMOPs and the experimental results indicate that FCP is superior in generating initial population.},
  archive      = {J_TEVC},
  author       = {Quan Gong and Yizhang Xia and Juan Zou and Zhanglu Hou and Yuan Liu},
  doi          = {10.1109/TEVC.2025.3551399},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {3},
  pages        = {1},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Enhancing dynamic constrained multi-objective optimization with multi-centers based prediction},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary multi-task framework with bi-knowledge transfer
for multimodal optimization problems. <em>TEVC</em>, 1. (<a
href="https://doi.org/10.1109/TEVC.2025.3551728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving multimodal optimization problems (MMOPs) is a challenging task which needs locating multiple global optimal solutions simultaneously with high accuracy. Current popular niching-based evolutionary algorithms (EAs) for solving MMOPs usually divide the population into several separate species to search for different optimal solutions. However, achieving effective information exchange between species to enhance the performance of overall algorithm remains a challenge in current niching-based EAs, which will directly affect the efficiency of the multimodal optimization algorithm. In this paper, the process of the different species locating peaks in MMOPs is regarded as an evolutionary multitask (EMT) optimization problem and an EMT framework with bi-knowledge transfer for MMOPs is proposed. An explicit knowledge transfer (E-KT) strategy is designed to transfer the optimal individual of the species with the fastest convergence speed to other species, thereby facilitating the acceleration their convergence. Moreover, in order to further improve the information exchange between species, a species center-based implicit knowledge transfer (I-SCKT) strategy is designed to improve the diversity of the population. The performance of MTBKTMMOP is tested on the widely used CEC’2013 benchmark and five practical flexible job shop problems. The experimental results of MTBKTMMOP are compared with 9 state-of-the-art MMOPs algorithms and show that our MTBKTMMOP is superior to all of them. Besides, the experimental results also show that the MTBKTMMOP achieves breakthroughs in handling with a large number of optimal solutions or high-dimensional MMOPs, which provides a new and effective method for dealing with MMOPs.},
  archive      = {J_TEVC},
  author       = {Hong Zhao and Xu-Hui Ning and Jian-Yu Li and Jing Liu},
  doi          = {10.1109/TEVC.2025.3551728},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {3},
  pages        = {1},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary multi-task framework with bi-knowledge transfer for multimodal optimization problems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gradual innovative transitional solutions improving current
to a desired target: Innovation path. <em>TEVC</em>, 1. (<a
href="https://doi.org/10.1109/TEVC.2025.3552685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practice, there is often a need to update the currently implemented (CI) solution to achieve better performance goals catering to new demands or adoption of new technologies. However, the new optimal solution, found by re-optimizing the problem, may be quite different from the CI solution implicating large costs, major changes, and laborious efforts, causing an apathy for its adoption. For such scenarios, we propose a concept of an “innovation path” (IP), containing a sequence of transitional solutions from the existing to the new target solution with gradual and controlled change from one to the next. To discover such intermediate solutions of the IP, we propose a bi-objective formulation with dynamic step-constraints as an IP Problem (IPP), such that a finite set of Pareto-optimal solutions of the resulting IPP become the desired intermediate IP solutions. Due to required gradual discovery of IP solutions, the IP-seeking task happens to be a non-trivial task. We demonstrate the working of the proposed approach on a number of single, two-objective, and many-objective test and engineering problems. The paper concludes with a number of extensions of this study, but the results of this study clearly indicate the usefulness of the proposed approach to other practical problems.},
  archive      = {J_TEVC},
  author       = {Ahmer Khan and Kalyanmoy Deb},
  doi          = {10.1109/TEVC.2025.3552685},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {3},
  pages        = {1},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Gradual innovative transitional solutions improving current to a desired target: Innovation path},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging evolutionary multiobjective optimization and GPU
acceleration via tensorization. <em>TEVC</em>, 1. (<a
href="https://doi.org/10.1109/TEVC.2025.3555605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary multiobjective optimization (EMO) has made significant strides over the past two decades. However, as problem scales and complexities increase, traditional EMO algorithms face substantial performance limitations due to insufficient parallelism and scalability. While most work has focused on algorithm design to address these challenges, little attention has been given to hardware acceleration, thereby leaving a clear gap between EMO algorithms and advanced computing devices, such as GPUs. To bridge the gap, we propose to parallelize EMO algorithms on GPUs via the tensorization methodology. By employing tensorization, the data structures and operations of EMO algorithms are transformed into concise tensor representations, which seamlessly enables automatic utilization of GPU computing. We demonstrate the effectiveness of our approach by applying it to three representative EMO algorithms: NSGA-III, MOEA/D, and HypE. To comprehensively assess our methodology, we introduce a multiobjective robot control benchmark using a GPU-accelerated physics engine. Our experiments show that the tensorized EMO algorithms achieve speedups of up to 1113× compared to their CPU-based counterparts, while maintaining solution quality and effectively scaling population sizes to hundreds of thousands. Furthermore, the tensorized EMO algorithms efficiently tackle complex multiobjective robot control tasks, producing high-quality solutions with diverse behaviors. Source codes are available at https://github.com/EMI-Group/evomo.},
  archive      = {J_TEVC},
  author       = {Zhenyu Liang and Hao Li and Naiwei Yu and Kebin Sun and Ran Cheng},
  doi          = {10.1109/TEVC.2025.3555605},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {3},
  pages        = {1},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Bridging evolutionary multiobjective optimization and GPU acceleration via tensorization},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
