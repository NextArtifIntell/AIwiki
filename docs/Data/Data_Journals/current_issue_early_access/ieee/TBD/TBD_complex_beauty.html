<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TBD_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tbd---13">TBD - 13</h2>
<ul>
<li><details>
<summary>
(2025). Robust semi-supervised deep nonnegative matrix factorization
with constraint propagation for data representation. <em>IEEE
Transactions on Big Data</em>, 1–14. (<a
href="https://doi.org/10.1109/TBDATA.2025.3547174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Deep nonnegative matrix factorization (DNMF) technique has attached much great attention in recent year, since it can effectively discover the underlying hierarchical structure of complex data. However, most existing unsupervised and semi-supervised DNMF approaches not only suffer from the noisy data seriously, but also fail to enhance the decomposition quality of DNMF obviously by using the obtained supervisory information. To overcome these drawbacks, a robust semi-supervised DNMF method, called the correntropy based semi-supervised DNMF with constraint propagation (CSDCP), is proposed in this paper for learning a compact and meaningful data representation from the original data. Particularly, instead of adopting the traditional Frobenius norm, CSDCP employs the nonlinear and local similarity measure (e.g., correntropy) as the loss function in DNMF to enhance the robustness of DNMF for the noisy data. In addition, the hypergraph based constraint propagation (HCP) algorithm is adopted in CSDCP to exploit the limited supervisory information fully for capturing good data representation. Moreover, algorithm analysis of CSDCP is presented in this paper, including convergence analysis, robustness analysis supervised information analysis, and computational complexity. Extensive experimental results have illustrated that, in comparison to the most related DNMF approaches, CSDCP usually has better clustering results on six nonnegative datasets in clustering tasks.},
  archive  = {J},
  author   = {Siyuan Peng and Jingxing Yin and Zhijing Yang and Feiping Nie and Badong Chen},
  doi      = {10.1109/TBDATA.2025.3547174},
  journal  = {IEEE Transactions on Big Data},
  month    = {3},
  pages    = {1-14},
  title    = {Robust semi-supervised deep nonnegative matrix factorization with constraint propagation for data representation},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal subdata selection for prediction based on the
distribution of the covariates. <em>IEEE Transactions on Big Data</em>,
1–14. (<a href="https://doi.org/10.1109/TBDATA.2025.3552343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Huge data sets are widely available now and there is growing interest in selecting an optimal subsample from the full data set to improve inference efficiency and reduce labeling costs. We propose a new criterion called J–optimality, that builds upon a popular optimal selection criterion that minimizes the Random–X prediction error by additionally incorporating the joint distribution of the covariates. A key advantage of our approach is that we can relate the subsampling selection problem to that of finding an optimal approximate design under a convex criterion, where analytical tools for finding and studying them are already available. Consequently, the J–optimal subsampling method comes with theoretical results and theory-based algorithms for finding them. Simulation results and real data analysis show our proposed methods outperform current subsampling methods and the proposed algorithms can also adapt efficiently to select an optimal subsample from streaming data.},
  archive  = {J},
  author   = {Alvaro Cia-Mina and Jesus Lopez-Fidalgo and Weng Kee Wong},
  doi      = {10.1109/TBDATA.2025.3552343},
  journal  = {IEEE Transactions on Big Data},
  month    = {3},
  pages    = {1-14},
  title    = {Optimal subdata selection for prediction based on the distribution of the covariates},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Residual learning for self-knowledge distillation: Enhancing
neural networks through consistency across layers. <em>IEEE Transactions
on Big Data</em>, 1–13. (<a
href="https://doi.org/10.1109/TBDATA.2025.3552326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Knowledge distillation is widely used technique to transfer knowledge from a large pretrained teacher network to a small student network. However, training complex teacher models requires significant computational resources and storage. To address this, a growing area of research, known as self-knowledge distillation (Self-KD), aims to enhance the performance of a neural network by leveraging its own latent knowledge. Despite its potential, existing Self-KD methods often struggle to effectively extract and utilize the model&#39;s dark knowledge. In this work, we identify a consistency problem between feature layer and output layer, and propose a novel Self-KD approach called Residual Learning for Self-Knowledge Distillation (RSKD). Our method addresses this issue by enabling the last feature layer of the student model learn the residual gap between the outputs of the pseudo-teacher and the student. Additionally, we extend RSKD by allowing each intermediate feature layer of the student model to learn the residual gap between the corresponding deeper features of the pseudo-teacher and the student. Extensive experiments on various visual datasets demonstrate the effectiveness of the proposed method, which outperforms the state-of-the-art baselines.},
  archive  = {J},
  author   = {Hanpeng Liu and Shuoxi Zhang and Kun He},
  doi      = {10.1109/TBDATA.2025.3552326},
  journal  = {IEEE Transactions on Big Data},
  month    = {3},
  pages    = {1-13},
  title    = {Residual learning for self-knowledge distillation: Enhancing neural networks through consistency across layers},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient antagonistic <span
class="math inline"><em>k</em></span>-plex enumeration in signed graphs.
<em>IEEE Transactions on Big Data</em>, 1–14. (<a
href="https://doi.org/10.1109/TBDATA.2025.3552335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {A signed graph is a graph where each edge receives a sign, positive or negative. The signed graph model has been used in many real applications, such as protein complex discovery and social network analysis. Finding cohesive subgraphs in signed graphs is a fundamental problem. A $k$-plex is a common model for cohesive subgraphs in which every vertex is adjacent to all but at most $k$ vertices within the subgraph. In this paper, we propose the model of size-constrained antagonistic $k$-plex in a signed graph. The proposed model guarantees that the resulting subgraph is a $k$-plex and can be divided into two sub-$k$-plexes, both of which have positive inner edges and negative outer edges. This paper aims to identify all maximal antagonistic $k$-plexes in a signed graph. Through rigorous analysis, we show that the problem is NP-Hardness. We propose a novel framework for maximal antagonistic $k$-plexes utilizing set enumeration. Efficiency is improved through pivot pruning and early termination based on the color bound. Preprocessing techniques based on degree and dichromatic graphs effectively narrow the search space before enumeration. Extensive experiments on real-world datasets demonstrate our algorithm&#39;s efficiency, effectiveness, and scalability.},
  archive  = {J},
  author   = {Lantian Xu and Rong-Hua Li and Dong Wen and Qiangqiang Dai and Guoren Wang},
  doi      = {10.1109/TBDATA.2025.3552335},
  journal  = {IEEE Transactions on Big Data},
  month    = {3},
  pages    = {1-14},
  title    = {Efficient antagonistic $k$-plex enumeration in signed graphs},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing weak supervision for concept prerequisite relation
learning. <em>IEEE Transactions on Big Data</em>, 1–14. (<a
href="https://doi.org/10.1109/TBDATA.2025.3552330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Concept prerequisite relation learning is used to identify dependency relations between knowledge concepts, which helps learners choose effective learning paths. Currently, most of the mainstream methods utilise deep learning algorithms to capture the prerequisite relations between concepts through supervised or semi-supervised learning. However, these methods are highly dependent on labelled data, which is scarce and costly to annotate in reality. To address this problem, we propose a framework called Weakly Supervised Enhanced Concept Prerequisite Relation Learning (WSECPRL). Specifically, we first generate an enhanced concept pseudo-relation graph without labeled data using the pre-trained language model and the large knowledge base as auxiliary information. Second, we propose an improved variational graph auto-encoder model to correctly determine the concept prerequisite relations. We incorporate a multi-head attention mechanism to enhance the representation learning capability of weakly supervised learning. The model reconstructs a directed graph into multiple undirected graphs by splitting the adjacency matrix and determines the direction of the concept prerequisite relation based on the strength of the dependency relation between concepts. Finally, experimental results on several publicly available datasets demonstrate the effectiveness of our proposed framework, with WSECPRL outperforming existing baseline models in terms of F1 scores and AUC.},
  archive  = {J},
  author   = {Miao Zhang and Jiawei Wang and Kui Xiao and Zhifang Huang and Zhifei Li and Yan Zhang},
  doi      = {10.1109/TBDATA.2025.3552330},
  journal  = {IEEE Transactions on Big Data},
  month    = {3},
  pages    = {1-14},
  title    = {Enhancing weak supervision for concept prerequisite relation learning},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NetPrompt: Neural network prompting enhances event
extraction in large language models. <em>IEEE Transactions on Big
Data</em>, 1–15. (<a
href="https://doi.org/10.1109/TBDATA.2025.3552333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Event Extraction involves extracting event-related information such as event types and event arguments from context, which has long been tackled through well-designed neural networks or fine-tuned pre-trained language models. These approaches require substantial annotated data for tuning parameters and are resource-intensive. Recently, Prompting strategies with frozen parameters, such as Chain-of-Thought and Self-Consistency, have delivered success in NLP using LLMs by generating intermediate thought steps. However, they suffer from the challenge of error propagation and lack of interaction between different thoughts. In this paper, we propose Neural Network-based Prompting (NetPrompt), a novel network-structured prompting strategy for event extraction. The core idea behind NetPrompt is to imitate the excellent information integration capabilities of neural network structures. Specifically, we first decompose the event extraction problem into diverse intermediate subtasks, and each subtask is represented as a node in different layers of the network, the output of the nodes in the preceding layer is fed into the subsequent layer. Secondly, we propose pruning strategies to adapt the reasoning overhead to different problems. Finally, we have conducted extensive experiments on two widely used event extraction benchmarks to evaluate NetPrompt. The results demonstrated that NetPrompt significantly improved the event extraction performance compared to previous methods.},
  archive  = {J},
  author   = {Lin Mu and Yide Cheng and Jun Shen and Yiwen Zhang and Hong Zhong},
  doi      = {10.1109/TBDATA.2025.3552333},
  journal  = {IEEE Transactions on Big Data},
  month    = {3},
  pages    = {1-15},
  title    = {NetPrompt: Neural network prompting enhances event extraction in large language models},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comprehensive architecture search for deep graph neural
networks. <em>IEEE Transactions on Big Data</em>, 1–15. (<a
href="https://doi.org/10.1109/TBDATA.2025.3552336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In recent years, Neural Architecture Search (NAS) has emerged as a promising approach for automatically discovering superior model architectures for deep Graph Neural Networks (GNNs). Different methods have paid attention to different types of search spaces. However, due to the time-consuming nature of training deep GNNs, existing NAS methods often fail to explore diverse search spaces sufficiently, which constrains their effectiveness. To crack this hard nut, we propose CAS-DGNN, a novel comprehensive architecture search method for deep GNNs. It encompasses four kinds of search spaces that are the composition of aggregate and update operators, different types of aggregate operators, residual connections, and hyper-parameters. To meet the needs of such a complex situation, a phased and hybrid search strategy is proposed to accommodate the diverse characteristics of different search spaces. Specifically, we divide the search process into four phases, utilizing evolutionary algorithms and Bayesian optimization. Meanwhile, we design two distinct search methods for residual connections (All-connected search and Initial Residual search) to streamline the search space, which enhances the scalability of CAS-DGNN. The experimental results show that CAS-DGNN achieves higher accuracy with competitive search costs across ten public datasets compared to existing methods.},
  archive  = {J},
  author   = {Yukang Dong and Fanxing Pan and Yi Gui and Wenbin Jiang and Yao Wan and Ran Zheng and Hai Jin},
  doi      = {10.1109/TBDATA.2025.3552336},
  journal  = {IEEE Transactions on Big Data},
  month    = {3},
  pages    = {1-15},
  title    = {Comprehensive architecture search for deep graph neural networks},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSST: Multi-scale spatial-temporal representation learning
for trajectory similarity computation. <em>IEEE Transactions on Big
Data</em>, 1–12. (<a
href="https://doi.org/10.1109/TBDATA.2025.3552340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Computing trajectory similarity is a fundamental task in trajectory analysis. Traditional heuristic methods suffer from quadratic computational complexity, which limits their scalability to large datasets. Recently, Trajectory Representation Learning (TRL) has been extensively studied to address this limitation. However, most existing TRL algorithms face two key challenges. First, they prioritize spatial similarity while neglecting the intricate spatio-temporal dynamics of trajectories, particularly temporal regularities. Second, these methods are often constrained by predefined single spatial or temporal scales, which can significantly impact performance, since the measurement of trajectory similarity depends on spatial and temporal resolution. To address these issues, we propose MSST, a Multi-Scale Self-supervised Trajectory Representation Learning framework. MSST simultaneously processes spatial and temporal information by generating 3D spatial-temporal tokens, thereby capturing spatio-temporal characteristics of trajectories more effectively. Further, MSST explore the multi-scale characteristics of trajectories. Finally, self-supervised contrastive learning is employed to enhance the consistency between the trajectory representations from different views. Experimental results on three real-world datasets for similarity trajectory computation provide insight into the design properties of our approach and demonstrate the superiority of our approach over existing TRL methods. MSST significantly surpasses all state-of-the-art competitors in terms of effectiveness, efficiency, and robustness.},
  archive  = {J},
  author   = {Li Li and Junjun Si and Jinna Lv and Junting Lu and Jianyu Zhang and Shuaifu Dai},
  doi      = {10.1109/TBDATA.2025.3552340},
  journal  = {IEEE Transactions on Big Data},
  month    = {3},
  pages    = {1-12},
  title    = {MSST: Multi-scale spatial-temporal representation learning for trajectory similarity computation},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MHT-net: A matching-based hierarchical transfer network for
glaucoma detection from fundus images. <em>IEEE Transactions on Big
Data</em>, 1–15. (<a
href="https://doi.org/10.1109/TBDATA.2025.3552342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Glaucoma is a chronic and irreversible eye disease. Early detection and treatment can effectively prevent severe consequences. Deep transfer learning is widely used in fundus imaging analysis to remedy the shortage of training data of glaucoma. The model trained on the source domain may struggle to predict glaucoma in the target domain due to distribution differences. Several limitations cannot be ignored: (1) Image matching: enhancing global and local image consistency through bidirectional matching; (2) Hierarchical transfer: developing a strategy for transferring different hierarchical features. To this end, we propose a novel Matched Hierarchical Transfer Network (MHT-Net) to achieve automatic glaucoma detection. We initially create a fundus structure detector to match global and local images using intermediate layers of a pre-trained diagnostic model with source domain data. Next, a hierarchical transfer network is implemented, sharing parameters for general features and using a domain discriminator for specific features. By integrating adversarial and classification losses, the model acquires domain-invariant features, facilitating precise and seamless transfer of fundus information from source to target domains. Extensive experiments demonstrate the effectiveness of our proposed method, outperforming existing glaucoma detection methods. These advantages endow our algorithm as a promising efficient assisted tool in the glaucoma screening.},
  archive  = {J},
  author   = {Linna Zhao and Jiangiang Li and Li Li and Xi Xu},
  doi      = {10.1109/TBDATA.2025.3552342},
  journal  = {IEEE Transactions on Big Data},
  month    = {3},
  pages    = {1-15},
  title    = {MHT-net: A matching-based hierarchical transfer network for glaucoma detection from fundus images},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-guided graph refinement with progressive fusion for
multiplex graph contrastive representation learning. <em>IEEE
Transactions on Big Data</em>, 1–12. (<a
href="https://doi.org/10.1109/TBDATA.2025.3552331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Multiplex Graph Contrastive Learning (MGCL) has attracted significant attention. However, existing MGCL methods often struggle with suboptimal graph structures and fail to fully capture intricate interdependencies across multiplex views. To address these issues, we propose a novel self-supervised framework, Multiplex Graph Refinement with progressive fusion (MGRefine), for multiplex graph contrastive representation learning. Specifically, MGRefine introduces a multi-view learning module to extract a structural guidance matrix by exploring the underlying relationships between nodes. Then, a progressive fusion module is employed to progressively enhance and fuse representations from different views, capturing and leveraging nuanced interdependencies and comprehensive information across the multiplex graphs. The fused representation is then used to construct a consensus guidance matrix. A self-enhanced refinement module continuously refines the multiplex graphs using these guidance matrices while providing effective supervision signals. MGRefine achieves mutual reinforcement between graph structures and representations, ensuring continuous optimization of the model throughout the learning process in a self-enhanced manner. Extensive experiments demonstrate that MGRefine outperforms state-of-the-art methods and also verify the effectiveness of MGRefine across various downstream tasks on several benchmark datasets.},
  archive  = {J},
  author   = {Qi Dai and Yu Gu and Xiaofeng Zhu and Xiaohua Li and Fangfang Li and Ge Yu},
  doi      = {10.1109/TBDATA.2025.3552331},
  journal  = {IEEE Transactions on Big Data},
  month    = {3},
  pages    = {1-12},
  title    = {Self-guided graph refinement with progressive fusion for multiplex graph contrastive representation learning},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective graph contrastive learning for
recommendation. <em>IEEE Transactions on Big Data</em>, 1–14. (<a
href="https://doi.org/10.1109/TBDATA.2025.3552341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Recently, numerous studies have integrated self-supervised contrastive learning with Graph Convolutional Networks (GCNs) to address the data sparsity and popularity bias to enhance recommendation performance. While such studies have made breakthroughs in accuracy metric, they often neglect non-accuracy objectives such as diversity, novelty and percentage of long-tail items, which greatly reduces the user experience in real-world applications. To this end, we propose a novel graph collaborative filtering model named Multi-Objective Graph Contrastive Learning for recommendation (MOGCL), designed to provide more comprehensive recommendations by considering multiple objectives. Specifically, MOGCL comprises three modules: a multi-objective embedding generation module, an embedding fusion module and a transfer learning module. In the multi-objective embedding generation module, we employ two GCN encoders with different goal orientations to generate node embeddings targeting accuracy and non-accuracy objectives, respectively. These embeddings are then effectively fused with complementary weights in the embedding fusion module. In the transfer learning module, we suggest an auxiliary self-supervised task to promote the maximization of the mutual information of the two sets of embeddings, so that the obtained final embeddings are more stable and comprehensive. The experimental results on three real-world datasets show that MOGCL achieves optimal trade-offs between multiple objectives comparing to the state-of-the-arts.},
  archive  = {J},
  author   = {Lei Zhang and Mingren Ke and Likang Wu and Wuji Zhang and Zihao Chen and Hongke Zhao},
  doi      = {10.1109/TBDATA.2025.3552341},
  journal  = {IEEE Transactions on Big Data},
  month    = {3},
  pages    = {1-14},
  title    = {Multi-objective graph contrastive learning for recommendation},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive graph structure learning neural rough differential
equations for multivariate time series forecasting. <em>IEEE
Transactions on Big Data</em>, 1–14. (<a
href="https://doi.org/10.1109/TBDATA.2025.3552334">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Multivariate time series forecasting has extensive applications in urban computing, such as financial analysis, weather prediction, and traffic forecasting. Using graph structures to model the complex correlations among variables in time series, and leveraging graph neural networks and recurrent neural networks for temporal aggregation and spatial propagation stage, has shown promise. However, traditional methods&#39; graph structure node learning and discrete neural architecture are not sensitive to issues such as sudden changes, time variance, and irregular sampling often found in real-world data. To address these challenges, we propose a method called Adaptive Graph structure Learning neural Rough Differential Equations (AGLRDE). Specifically, we combine dynamic and static graph structure learning to adaptively generate a more robust graph representation. Then we employ a spatio-temporal encoderdecoder based on Neural Rough Differential Equations (Neural RDE) to model spatio-temporal dependencies. Additionally, we introduce a path reconstruction loss to constrain the path generation stage. We conduct experiments on six benchmark datasets, demonstrating that our proposed method outperforms existing state-of-the-art methods. The results show that AGLRDE effectively handles aforementioned challenges, significantly improving the accuracy of multivariate time series forecasting.},
  archive  = {J},
  author   = {Yuming Su and Tinghuai Ma and Huan Rong and Mohamed Magdy Abdel Wahab},
  doi      = {10.1109/TBDATA.2025.3552334},
  journal  = {IEEE Transactions on Big Data},
  month    = {3},
  pages    = {1-14},
  title    = {Adaptive graph structure learning neural rough differential equations for multivariate time series forecasting},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incorporating confused phraseological knowledge based on
pinyin input method for chinese spelling correction. <em>IEEE
Transactions on Big Data</em>, 1–13. (<a
href="https://doi.org/10.1109/TBDATA.2025.3552344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Chinese Spelling Correction (CSC) is designed to detect and correct spelling errors that occur in Chinese text. In real life, most keyboard input scenarios use the pinyin input method. Researching spelling errors in this scenario is practical and valuable. However, there is currently no research that has truly proposed a model suitable for this scenario. Considering this concern, this paper proposes a model IPCK-IME, which incorporates confused phraseological knowledge based on the pinyin input method. The model integrates its own phonetic features with external similarity knowledge to guide the model to output more correct characters. Furthermore, to mitigate the influence of spelling errors on the semantics of sentences, a Gaussian bias is introduced into the self-attention network of the model. This approach aims to reduces the focus on typos and improve attention to local context. Empirical evidence indicates that our method surpasses existing models in correcting spelling errors generated by the pinyin input method. And, it is more appropriate for correcting Chinese spelling errors in real input scenarios.},
  archive  = {J},
  author   = {Weidong Zhao and Xiaoyu Wang and Xinjun An},
  doi      = {10.1109/TBDATA.2025.3552344},
  journal  = {IEEE Transactions on Big Data},
  month    = {3},
  pages    = {1-13},
  title    = {Incorporating confused phraseological knowledge based on pinyin input method for chinese spelling correction},
  year     = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
