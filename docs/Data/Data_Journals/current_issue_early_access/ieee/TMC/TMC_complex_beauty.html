<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TMC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tmc---77">TMC - 77</h2>
<ul>
<li><details>
<summary>
(2025). AUTHFi: Cross-technology device authentication via commodity
WiFi. <em>TMC</em>, 1–15. (<a
href="https://doi.org/10.1109/TMC.2025.3547010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The explosive growth of the Internet of Things (IoT) has dramatically increased the demand for secure mechanisms to protect against unauthorized access and attacks. Traditionally, expensive Software-Defined Radios (SDRs) have been utilized to gather IoT physical features, which are critical for reliable authentication. However, the high cost of SDRs makes them impractical for widespread deployment across the vast and diverse IoT ecosystem. In contrast, this paper presents AUTHFi, a novel cross-technology device authentication framework that transforms the SDR approach for collecting and authenticating IoT device signals (e.g., ZigBee and Bluetooth) by utilizing commercial WiFi devices. Specifically, AUTHFi leverages the recent advances in Cross-Technology Communication (CTC) to reconstruct the partial waveform of IoT transmission, thus eliminating the requirement for expensive SDRs. AUTHFi requires us to address several unique challenges. First, AUTHFi compensates for signal losses of the partial waveform to get more signal information. Then, it introduces an enhanced Carrier Frequency Offset (CFO) estimation and a fusion neural network that combines CFO and the reconstructed waveform for accurate device authentication. We implement AUTHFi based on RTL8812au (commodity WiFi) and CC2652P (commodity ZigBee/Bluetooth). Our thorough evaluation confirms that AUTHFi offers reliable authentication under various settings, achieving a maximum accuracy of 94.2%.},
  archive      = {J_TMC},
  author       = {Weizheng Wang and Dusit Niyato and Zehui Xiong and Zhimeng Yin},
  doi          = {10.1109/TMC.2025.3547010},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {AUTHFi: Cross-technology device authentication via commodity WiFi},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incremental least-recently-used algorithm: Good, robust, and
predictable performance. <em>TMC</em>, 1–15. (<a
href="https://doi.org/10.1109/TMC.2025.3547066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a replacement algorithm for file caching in mobile edge computing (MEC) networks. While there are numerous schemes for file replacement, it remains a challenge to achieve good, robust, and predictable performance simultaneously. To address this challenge, we introduce a general scheme called Incremental Least-Recently-Used (iLRU), which builds on the classic Least-Recently-Used (LRU) algorithm. iLRU initially caches only a “portion” of the file upon the first request and incrementally caches more when there are more requests for the file. In this regard, the request frequency can be inferred from the cached size without incurring additional overhead, where a larger cached size represents a higher request frequency. We derive the theoretical hit ratio of iLRU based on the Time-to-Live (TTL) analysis. With the Time-to-Live (TTL) analysis, we can theoretically derive the hit ratio and properties of iLRU and notably show that iLRU allocates more cache space to popular files, resulting in a higher hit ratio than LRU. Simulation results demonstrate the superior performance of iLRU and validate the accuracy of the theoretical hit ratio. Furthermore, we conduct simulations over various real-world traces to show that iLRU outperforms existing schemes across various real-world traces, defenestrating the robustness of iLRU.},
  archive      = {J_TMC},
  author       = {Jinbei Zhang and Chunpeng Chen and Kechao Cai and John C.S. Lui},
  doi          = {10.1109/TMC.2025.3547066},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Incremental least-recently-used algorithm: Good, robust, and predictable performance},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards privacy-enhanced and robust clustered federated
learning. <em>TMC</em>, 1–18. (<a
href="https://doi.org/10.1109/TMC.2025.3547149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustered federated learning (CFL) leverages data distribution similarities to cluster clients, facilitating personalized model training under data heterogeneity. However, most existing CFL schemes pose potential privacy risks for clients (e.g., gradient inversion attacks) as they rely on individual gradients for clustering. This also renders them incompatible with secure aggregation mechanisms that are widely employed in federated learning for privacy protection. Moreover, CFL introduces the risk of malicious clients dominating several clusters and conducting poisoning attacks therein, thereby threatening secure model training. To address these issues, we propose ProCFL, a Privacy-Enhanced and Robust CFL framework incorporating gradient-free clustering and peer validation. Specifically, we first design a new protocol for measuring data distribution similarity among clients without using their gradient information. Then, we transform the client clustering process into a weighted set covering problem and introduce a diversity-optimized clustering algorithm to achieve near-optimal clustering results while eliminating any need for prior knowledge. Furthermore, we develop a post-hoc detection mechanism that employs peer validation to identify and discard malicious client models. Extensive experimental evaluation of ProCFL validates its superior model robustness and accuracy performance compared to existing schemes.},
  archive      = {J_TMC},
  author       = {Yang Xu and Yunlin Tan and Cheng Zhang and Peng Sun and Yibang Zhang and Ju Ren and Hongbo Jiang and Yaoxue Zhang},
  doi          = {10.1109/TMC.2025.3547149},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Towards privacy-enhanced and robust clustered federated learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy preservation strategies for malware-infected edge
intelligence systems: A bayesian stochastic game-based approach.
<em>TMC</em>, 1–15. (<a
href="https://doi.org/10.1109/TMC.2025.3546910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malware in the Internet of Things (IoT) is prone to contaminating various IoT end-points through network communication and information transfer, leading to surreptitious privacy leakage and data theft. The existing privacy-preserving approaches including data masking, anonymization, and differential privacy always lack the consideration of strategic interactions among rational agents. Inspired by Bayesian games, we model incomplete stochastic games between IoT end-points and edge nodes in edge intelligence (EI)-enabled IoT systems to conduct probability analysis for predicting and defending privacy leakage caused by malware infection. It is notable that the posterior probability is defined based on the Bayes&#39; rule to reflect the statistical inference of incomplete privacy leakage information. Such a method can intrinsically characterize the actual situations of IoT end-points. Further, we propose a novel privacy preservation optimization approach named Bayesian advantage actor critic (BA2C) for the practical implementation of optimization decision in EI-enabled IoT privacy-preserving systems. Eventually, we conduct experimental simulations to understand the most effective parameters in decision-making among the successful detection rate, successful infection rate, and false alarm rate. We also compare traditional algorithms and validate the efficacy of the proposed approach.},
  archive      = {J_TMC},
  author       = {Yizhou Shen and Carlton Shepherd and Chuadhry Mujeeb Ahmed and Shigen Shen and Shui Yu},
  doi          = {10.1109/TMC.2025.3546910},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Privacy preservation strategies for malware-infected edge intelligence systems: A bayesian stochastic game-based approach},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trust online over-the-air computation for wireless federated
learning. <em>TMC</em>, 1–18. (<a
href="https://doi.org/10.1109/TMC.2025.3547148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using the wireless waveform superposition property, over-the-air computation (OAC) enables federated learning (FL) to achieve fast model aggregation. However, this computing paradigm is vulnerable to poisoning attacks due to the openness of a wireless channel over time, where malicious mobile devices can introduce cumulative errors for the global FL model in a time-varying wireless environment for each communication round. This article presents a trust online OAC (TO-OAC) scheme to minimize impacts on the global model introduced by malicious devices adjusting to dynamic attack and wireless channel fluctuations over time. TO-OAC achieves this by utilizing trustworthy security quantification of OAC for each FL training round. To optimize the cumulative training loss at the aggregation node with the long-term power and trust constraints of mobile devices, we propose a joint trust, power, and channel-aware algorithm to flexibly update local and global models in response to the dynamic changes in the wireless and secure environment. We analyze the performance limits for the aggregation of trust models, considering metrics for computation and communication through time. We then propose another trust online regularization over-the-air computation (TOR-OAC) as an improved version of the TO-OAC scheme to decrease convergence time while ensuring long-term trust and power limitation. Experimental results performed on real-life datasets show that the two proposed schemes (TO-OAC and TOR-OAC) outperform prior works, especially in noisy, time-varying wireless channels and malicious attacks.},
  archive      = {J_TMC},
  author       = {Mingjie Sun and Jie Zheng and Hongyang Du and Haijun Zhang and Dusit Niyato and Jiawen Kang and Jiacheng Wang and Jie Ren and Ling Gao and Zheng Wang},
  doi          = {10.1109/TMC.2025.3547148},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Trust online over-the-air computation for wireless federated learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards efficient, robust, and privacy-preserving incentives
for crowdsensing via blockchain. <em>TMC</em>, 1–15. (<a
href="https://doi.org/10.1109/TMC.2025.3546941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive development of mobile devices, mobile crowdsensing (MCS) has emerged as a promising approach for large-scale sensing data collection. In the research of MCS, blockchain technology has been widely adopted to decentralize the traditional mobile crowdsensing and tackle the problem of single point of failure. Incentive mechanisms are devised to boost participation with fairness and truthfulness. However, to better determine the incentive strategy, participants&#39; privacy can be disclosed on top of the blockchain and obtained by adversaries during the transmission and execution of user data, leading to serious security issues. In this paper, we propose a two-stage incentive scheme with efficiency, robustness and privacy preservation considered based on the combination of blockchain technology and Trusted Execution Environment (TEE). Detailedly, we design two kinds of smart contracts, where on-chain public contracts support the procedure of general crowdsensing interactions, and off-chain private ones enabled by TEE complete the privacy-preserving computations, including an online incentive mechanism for worker recruitment decisions and a truth discovery algorithm for data aggregation. Recovery mechanism and hash check mechanism are introduced to avoid TEE provider failures and TEE providers&#39; attacks, respectively. Our scheme is proved to be theoretically secure in terms of private information protection, worker participation anonymity, and data aggregation privacy. Experimental results also verify the feasibility and superiority of our incentive scheme.},
  archive      = {J_TMC},
  author       = {Yuanhang Zhou and Fei Tong and Chunming Kong and Shibo He and Guang Cheng},
  doi          = {10.1109/TMC.2025.3546941},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Towards efficient, robust, and privacy-preserving incentives for crowdsensing via blockchain},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Orchestrating joint offloading and scheduling for
low-latency edge SLAM. <em>TMC</em>, 1–16. (<a
href="https://doi.org/10.1109/TMC.2025.3547256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Simultaneous Localization and Mapping (vSLAM) is a prevailing technology for many emerging robotic applications. Achieving real-time SLAM on mobile robotic systems with limited computational resources is challenging because the complexity of SLAM algorithms increases over time. This restriction can be lifted by offloading computations to edge servers, forming the emerging paradigm of edge-assisted SLAM. Nevertheless, the exogenous and stochastic input processes affect the dynamics of the edge-assisted SLAM system. Moreover, the requirements of clients on SLAM metrics change over time, exerting implicit and time-varying effects on the system. In this paper, we aim to push the limit beyond existing edge-assist SLAM by proposing a new architecture that can handle the input-driven processes and also satisfy clients&#39; implicit and time-varying requirements. The key innovations of our work involve a regional feature prediction method for importance-aware local data processing, a configuration adaptation policy that integrates data compression/decompression and task offloading, and an input-dependent learning framework for task scheduling with constraint satisfaction. Extensive experiments prove that our architecture improves pose estimation accuracy and saves up to $47\%$ of communication costs compared with a popular edge-assisted SLAM system, as well as effectively satisfies the clients&#39; requirements.},
  archive      = {J_TMC},
  author       = {Yao Zhang and Yuyi Mao and Hui Wang and Zhiwen Yu and Song Guo and Jun Zhang and Liang Wang and Bin Guo},
  doi          = {10.1109/TMC.2025.3547256},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Orchestrating joint offloading and scheduling for low-latency edge SLAM},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FuseGrasp: Radar-camera fusion for robotic grasping of
transparent objects. <em>TMC</em>, 1–14. (<a
href="https://doi.org/10.1109/TMC.2025.3547371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transparent objects are prevalent in everyday environments, but their distinct physical properties pose significant challenges for camera-guided robotic arms. Current research is mainly dependent on camera-only approaches, which often falter in suboptimal conditions, such as low-light environments. In response to this challenge, we present FuseGrasp, the first radar-camera fusion system tailored to enhance the transparent objects manipulation. FuseGrasp exploits the weak penetrating property of millimeter-wave (mmWave) signals, which causes transparent materials to appear opaque, and combines it with the precise motion control of a robotic arm to acquire high-quality mmWave radar images of transparent objects. The system employs a carefully designed deep neural network to fuse radar and camera imagery, thereby improving depth completion and elevating the success rate of object grasping. Nevertheless, training FuseGrasp effectively is non-trivial, due to limited radar image datasets for transparent objects. We address this issue utilizing large RGB-D dataset, and propose an effective two-stage training approach: we first pre-train FuseGrasp on a large public RGB-D dataset of transparent objects, then fine-tune it on a self-built small RGB-D-Radar dataset. Furthermore, as a byproduct, FuseGrasp can determine the composition of transparent objects, such as glass or plastic, leveraging the material identification capability of mmWave radar. This identification result facilitates the robotic arm in modulating its grip force appropriately. Extensive testing reveals that FuseGrasp significantly improves the accuracy of depth reconstruction and material identification for transparent objects. Moreover, real-world robotic trials have confirmed that FuseGrasp markedly enhances the handling of transparent items. A video demonstration of FuseGrasp is available at https://youtu.be/MWDqv0sRSok.},
  archive      = {J_TMC},
  author       = {Hongyu Deng and Tianfan Xue and He Chen},
  doi          = {10.1109/TMC.2025.3547371},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {FuseGrasp: Radar-camera fusion for robotic grasping of transparent objects},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GIRP: Energy-efficient QoS-oriented microservice resource
provisioning via multi-objective multi-task reinforcement learning.
<em>TMC</em>, 1–15. (<a
href="https://doi.org/10.1109/TMC.2025.3547339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microservice architecture has revolutionized web service development by facilitating loosely coupled and independently developable components distributed as containers or virtual machines. While existing studies emphasize end-to-end latency, this paper investigates energy-efficient quality-of-service (QoS)-oriented microservice provisioning, focusing on both QoS satisfaction and power consumption (PC) conservation. We propose the Green and Intelligent Resource Provision (GIRP) architecture, integrating a data-driven energy-latency-aware resource allocation and scheduling manager to balance latency and PC. To reconcile the trade-offs involved, a dual-objective optimization problem is formulated to minimize latency and energy use by selecting proper servers, allocating CPU cores, and determining service replicas. To address challenges with discrete variables, dual objectives, and implicit mappings, we leverage a model-free deep deterministic policy gradient-based reinforcement learning algorithm. Specifically, we develop a multi-task agent via the Multi-gate Mixture-of-Experts model to simultaneously make two separate actions regarding CPU core numbers and service replica numbers, followed by a single-task agent to determine service scheduling. Extensive experiments on the DeathStarBenchmark testbed validate GIRP&#39;s effectiveness, demonstrating approximately 52% resource savings and a 43% reduction in PC compared to leading methods like Sinan, Firm, and heuristic-based algorithms. These results highlight GIRP&#39;s capability to optimize microservice orchestration by balancing end-to-end latency and power efficiency.},
  archive      = {J_TMC},
  author       = {Honggang Yuan and Ting Wang and Min Fu and Yuanming Shi},
  doi          = {10.1109/TMC.2025.3547339},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {GIRP: Energy-efficient QoS-oriented microservice resource provisioning via multi-objective multi-task reinforcement learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incentive mechanism design for federated learning with
dynamic network pricing. <em>TMC</em>, 1–16. (<a
href="https://doi.org/10.1109/TMC.2025.3546977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning protects users&#39; data privacy by sharing users&#39; local model parameters (instead of raw data) with a server. However, when massive users train a large machine learning model through federated learning, the dynamically varying and often heavy communication overhead can put significant pressure on the network operator. The operator may choose to dynamically change the network prices in response, which will eventually affect the payoffs of the server and users. This paper considers the under-explored yet important issue of the joint design of participation incentives (for encouraging users&#39; contribution to federated learning) and network pricing (for managing network resources). Due to heterogeneous users&#39; private information and multi-dimensional decisions, the optimization problems in Stage I of multi-stage games are non-convex. Nevertheless, we are able to analytically derive the corresponding optimal contract and pricing mechanism through proper transformations of constraints, variables, and functions, under three interaction structures of the participants. We show that the coordinated structure is better than the two uncoordinated structures, as it avoids the selfish behaviors of the network operator and the server; the vertically uncoordinated structure is better than the horizontally uncoordinated structure, as it avoids the interests misalignment between the server and the network operator. We also propose multi-period network pricing to reduce the implementation complexity of dynamic pricing. Numerical results based on real-world datasets show that our proposed mechanisms decrease the server&#39;s cost by up to 24.87% and increase the network operator&#39;s profit by up to 1245.25%, compared with the state-of-the-art benchmarks.},
  archive      = {J_TMC},
  author       = {Ningning Ding and Lin Gao and Jianwei Huang},
  doi          = {10.1109/TMC.2025.3546977},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Incentive mechanism design for federated learning with dynamic network pricing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Device power saving with time-frequency adaptation: Joint
BWP-DRX design with BWP switching delay considered. <em>TMC</em>, 1–15.
(<a href="https://doi.org/10.1109/TMC.2025.3547978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today&#39;s ever-growing data traffic landscape, optimizing network power efficiency and performance has become crucial. Discontinuous Reception (DRX) and Bandwidth Parts (BWP) are two key technologies that fulfill this pursuit. DRX is a time-domain power-saving technology that allows user equipment (UE) to switch off their radio frequency module. BWP switching is a frequency domain operation that allows UE to operate on only partial bandwidth for power saving. Investigating the interaction and trade-off between DRX and BWP is a must to optimize network efficiency and enhance network performance. This work proposed a novel BWP-DRX joint mechanism and its analytical model that leverages the concept of “Detect time” with the consideration of BWP switching delay. The model reduces packet loss rate by 50%, packet delay by 36% and increases the energy efficiency rate by 50% when arrival rate is high with the trade-off of 12% power efficiency reduction when arrival rate is low compared to the model without Detect time. The influence of each parameter is further analyzed to reach the best network efficiency under different traffic conditions.},
  archive      = {J_TMC},
  author       = {Cheng-Wei Tsai and Kuang-Hsun Lin and and Hung-Yu Wei},
  doi          = {10.1109/TMC.2025.3547978},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Device power saving with time-frequency adaptation: Joint BWP-DRX design with BWP switching delay considered},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint optimization for IRS-assisted self-powered IoT in 5G
mmWave networks. <em>TMC</em>, 1–15. (<a
href="https://doi.org/10.1109/TMC.2025.3547790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Harvesting energy from ambient energy source is the key technology for self-powered Internet of Things (IoT) devices to maintain continuous operation without an external power supply. Motivated by the expansion and popularity of 5G networks, we propose a novel solution for IoT devices which are self-powered via harvesting energy from the millimeter-wave (mmWave) communications in 5G mmWave networks. For overcoming the high path loss in mmWave communications, directional narrow-beam transmission is adopted to provide sufficient link budget between transceivers through beamforming technology, which however makes IoT devices difficult to scavenge energy from the mmWave signals. Hence, we employ multiple intelligent reflecting surfaces (IRSs) to assist in energy harvesting at the IoT devices and data transmission at the 5G users. Considering beam codebook design for 5G mmWave networks, this paper jointly optimizes the Discrete Fourier transform (DFT) codebook-based transmit codevectors at the 5G base station (BS) and the phase shifts of IRS&#39;s reflective elements for minimizing BS&#39;s transmit power, while satisfying the Signal to Interference plus Noise Ratio (SINR) constraints at users and energy harvesting constraints of IoT devices. Nevertheless, owing to the intricate coupling of variables and discrete constraints, this joint optimization problem is extremely non-convex and non-linear. To address such challenges, we propose a penalty dual-decomposition (PDD)-based algorithm which combines the penalty-based augmented Lagrangian method and block coordinate descent method. It explores the structure of the mmWave channel and performs a double iterations in which the joint optimization problem is decomposed into several simplified subproblems. Simulation results reveal that the above algorithm enhances the energy efficiency as compared to other algorithms.},
  archive      = {J_TMC},
  author       = {Tao Liu and Suiwen Zhang and Xiaomei Qu and Lijun Yang and Chengjie Li and Yihong Chen},
  doi          = {10.1109/TMC.2025.3547790},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint optimization for IRS-assisted self-powered IoT in 5G mmWave networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent moth-flame reinforcement learning based
broadcast beam optimization. <em>TMC</em>, 1–14. (<a
href="https://doi.org/10.1109/TMC.2025.3547946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, beamforming antenna array technologies are of utmost importance in 5G communication systems. These technologies are essential for optimizing the coverage and signal quality of the cellular network. However, the optimization of broadcast beams presents significant challenges due to the complex strategy profile space. Each beam can be configured with different widths and heights, making it difficult for conventional algorithms to handle. To address this issue, we propose a novel approach called Multi-Agent Moth-Flame Reinforcement Learning (MAMF-RL) algorithm for broadcast beam optimization. MAMF-RL combines reinforcement learning and moth-flame optimization algorithms to interactively search for the optimal broadcast beams. By decomposing the problem into multiple single-sector antenna configuration problems, MAMF-RL effectively reduces the algorithm complexity. We conducted experiments utilizing real data in an 18-sector wireless coverage area. To evaluate the performance of our proposed method, we compared it with traditional methods such as the particle swarm algorithm. The results demonstrate that our MAMF-RL model achieves an average coverage rate of 1.82% higher and a 13.74% lower overlapping coverage rate compared to traditional methods.},
  archive      = {J_TMC},
  author       = {Shan Huang and Haipeng Yao and Tianle Mai and Di Wu and Jiaqi Xu and F. Richard Yu},
  doi          = {10.1109/TMC.2025.3547946},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multi-agent moth-flame reinforcement learning based broadcast beam optimization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An AI-assisted all-in-one integrated coronary artery disease
diagnosis system using a portable heart sound sensor with an on-board
executable lightweight model. <em>TMC</em>, 1–15. (<a
href="https://doi.org/10.1109/TMC.2025.3547842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heart sounds play a crucial role in assessing Coronary Artery Disease (CAD). The advancement of Artificial Intelligence (AI) technologies has given rise to Computer Audition (CA)-based methods for CAD detection. However, previous research has focused primarily on analyzing and modeling heart sound data, overlooking practical application scenarios. In this work, we design a pervasive heart sound collection device used for high-quality heart sound data acquisition. Moreover, we introduce an on-board executable lightweight network tailored for the designed portable device, referred to as TYKDModel. Further, heart sound data from 41 CAD patients and 22 non-CAD healthy controls are collected using the developed device. Experimental results show that the TYKDModel exhibits low-computational complexity, with 52.16 K parameters and 5.03 M Floating-Point Operations (FLOPs). When deployed on the board, it requires only 1.10 MB of Random Access Memory (RAM) and 236.27 KB of Read-Only Memory (ROM), and takes around 1.72 seconds to perform a classification. Despite the low computational and spatial complexity, the TYKDModel achieves a notable classification accuracy of 85.2%, specificity of 88.6%, and sensitivity of 82.8% on the board. These results indicate the promising potential of AI-assisted all-in-one integrated system for the diagnosis of heart sound-assisted CAD.},
  archive      = {J_TMC},
  author       = {Haojie Zhang and Fuze Tian and Yang Tan and Lin Shen and Jingyu Liu and Jie Liu and Kun Qian and Yalei Han and Gong Su and Bin Hu and Björn W. Schuller and Yoshiharu Yamamoto},
  doi          = {10.1109/TMC.2025.3547842},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {An AI-assisted all-in-one integrated coronary artery disease diagnosis system using a portable heart sound sensor with an on-board executable lightweight model},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive stabilization control by deep reinforcement
learning for hovering drone surveillance. <em>TMC</em>, 1–15. (<a
href="https://doi.org/10.1109/TMC.2025.3548421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an adaptive stabilization control mechanism by using deep reinforcement learning (DRL) for hovering drones that have to execute a surveillance task for a long time. For long-endurance flights, we design and implement a buoyancy-aided unmanned aerial vehicle (UAV) that can use buoyancy lift to decrease the weight and increase the battery capacity so that the flight time can be significantly extended. However, the balloons of the buoyancy-aided UAV can cause “an inverted pendulum effect” and an instability issue on the drone attitude because the increased surface is easily affected by the gusty wind. We propose a buoyancy-aided adaptive stabilization control (BAASC) method with the DRL to stabilize the attitude and extend the flight time of the quadrotor-based buoyancy-aided UAV. This proposed model can immediately control the speeds of all rotors to balance the attitude based on the current state of the drone. Therefore, the degree of swing can be stabilized, and the inverted pendulum effect can be eliminated. The experimental results reveal that the designed buoyancy-aided UAV with the proposed BAASC scheme can effectively stabilize the attitude to extend the flight time by 112.8% compared with a nonbuoyancy-aided UAV under a gusty wind disturbance.},
  archive      = {J_TMC},
  author       = {Chao-Yang Lee and Ang-Hsun Tsai and Li-Chun Wang},
  doi          = {10.1109/TMC.2025.3548421},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Adaptive stabilization control by deep reinforcement learning for hovering drone surveillance},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning adaptive multi-timescale scheduling for mobile edge
computing. <em>TMC</em>, 1–15. (<a
href="https://doi.org/10.1109/TMC.2025.3548533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mobile edge computing (MEC), resource scheduling is crucial to task requests&#39; performance and service providers&#39; cost, involving multi-layer heterogeneous scheduling decisions. Existing MEC schedulers typically adopt static-timescale scheduling, where scheduling decisions are updated regularly at fixed intervals for all layers. The inflexible updating timescales lead to poor performance in the production networks. In this paper, we propose EdgeTimer, an unprecedented approach that automatically and adaptively determines respective updating timescales of multiple scheduling layers to achieve a better trade-off between the operation cost and service performance. Specifically, we design (i) a three-layer hierarchical deep reinforcement learning (DRL) framework for efficient learning of tightly coupled policies, (ii) a tailored multi-agent DRL algorithm for decentralized scheduling, with the convergence strictly proved, and (iii) a lightweight system defender for deterministic reliability assurance. Furthermore, we apply EdgeTimer to a wide range of Kubernetes scheduling rules, and evaluate it using production traces with different workload patterns. Through extensive trace-driven experiments, we demonstrate that EdgeTimer can significantly decrease the operation cost for service providers without sacrificing the delay performance, thereby improving overall profits, compared with the state-of-the-art approaches.},
  archive      = {J_TMC},
  author       = {Yijun Hao and Shusen Yang and Fang Li and Yifan Zhang and Shibo Wang and Xuebin Ren},
  doi          = {10.1109/TMC.2025.3548533},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Learning adaptive multi-timescale scheduling for mobile edge computing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint offloading decision, user association, and resource
allocation in hierarchical aerial computing: Collaboration of UAVs and
HAP. <em>TMC</em>, 1–17. (<a
href="https://doi.org/10.1109/TMC.2025.3548668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, applications are becoming increasingly computation-intensive and delay-sensitive owing to the rapid growth of Internet of Things (IoT) devices among ground users (GUs). Mobile edge computing (MEC) presents crucial computational support, but conventional MEC services often fail in remote areas and in disaster scenarios. This study presents a hierarchical aerial computing platform leveraging unmanned aerial vehicles (UAVs) and high-altitude platform (HAP) to meet the computation demands and latency requirements of various IoT applications for GUs. We propose a joint offloading decision, user association, and resource allocation (JOUR) scheme, utilizing binary offloading from GUs to UAVs and partial offloading from UAVs to HAP. The proposed scheme minimizes the energy consumption and latency while maximizing the load balancing. A matching game-based algorithm addresses the GUs offloading decision and GUs-UAVs association, followed by an enhanced soft actor-critic (ESAC) algorithm for UAV partial offloading decision, UAV computation resource allocation, and HAP computation resource allocation. Our simulation results demonstrate the effectiveness of the JOUR scheme in reducing the energy consumption and latency, while improving the load balancing and task completion rates. This demonstrates its potential for optimizing the hierarchical aerial computing platforms in dynamic IoT environments.},
  archive      = {J_TMC},
  author       = {Ahmadun Nabi and Sangman Moh},
  doi          = {10.1109/TMC.2025.3548668},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint offloading decision, user association, and resource allocation in hierarchical aerial computing: Collaboration of UAVs and HAP},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OACR<span class="math inline"><sup>2</sup></span>: Online
admission control and resource reservation for 5G slice networks with
deep reinforcement learning. <em>TMC</em>, 1–17. (<a
href="https://doi.org/10.1109/TMC.2025.3548767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network slicing architecture is expected to fulfill network applications with heterogeneous requirements through efficient slice admission control (SAC) policies. Existing SAC approaches entirely rely on current limited observations to make admission decisions, ignoring the potential impact of future demands. The short-sighted behaviors lead to poor service performance and infrastructure providers&#39; (InPs&#39;) revenue in practice. In this paper, we propose OACR$^{2}$, an online SAC approach based on deep reinforcement learning (DRL) that can exploit predictable future requests to make more precise admission control decisions for the long-term revenue, and reserve proper resources accordingly. Specifically, we design three novel schemes: (i) a requirement predictor based on long short-term memory (LSTM) and a novel input-output way to predict future unforeseen requests, (ii) a DRL admission controller based on the partially observable Markov decision process model to make precise admission decisions without accurate future request information, with the convergence strictly proved, and (iii) a decision defender to guarantee decision reliability. Extensive experiments on real-world traces demonstrate that compared to the No-wait, Wait-queue, and Wait-earliest time approaches, OACR$^{2}$ improves InPs&#39; revenue and acceptance ratio by up to 40.9% and 16.7%, respectively, without sacrificing online inference time (within 0.9 milliseconds).},
  archive      = {J_TMC},
  author       = {Fang Li and Yijun Hao and Shusen Yang and Peng Zhao},
  doi          = {10.1109/TMC.2025.3548767},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {OACR$^{2}$: Online admission control and resource reservation for 5G slice networks with deep reinforcement learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). H-STEP: Heuristic stable edge service entity placement for
mobile virtual reality systems. <em>TMC</em>, 1–12. (<a
href="https://doi.org/10.1109/TMC.2025.3548703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual reality (VR) technology, as a latency-sensitive application, can achieve real-time response to enhance the user&#39;s quality of experience (QoE) on edge devices. However, edge servers, unlike internally managed cloud servers, are prone to hardware failures, software abnormalities, and network attacks. Most prior studies have focused on reducing service delay and improving user coverage through service entity (SE) placement, often neglecting the critical impact of edge server malfunctions on user QoE. In this work, we design a stable service entity placement framework that connects users on faulty servers to collaborative edge servers, ensuring seamless task completion. This framework presents two primary challenges: determining the grouping of collaborative edge services and the placement of SEs. To address these challenges, we introduce a heuristic stable service entity placement (H-STEP) scheme. This scheme first determines the grouping of collaborative edge servers using an iterative search algorithm and then places SEs on suitable edge servers via a fast non-dominated sorting genetic placement algorithm. This approach balances stability benefits with total cost, enhancing the system&#39;s economic benefits. We theoretically analyze the performance of H-STEP and derive the performance gap between H-STEP and the optimal scheme. Extensive real-data-driven simulations demonstrate that H-STEP&#39;s performance closely approximates that of the optimal scheme and surpasses existing schemes.},
  archive      = {J_TMC},
  author       = {Xuejian Chi and Honglong Chen and Zhichen Ni and Haiyang Sun and Peng Sun and Dongxiao Yu},
  doi          = {10.1109/TMC.2025.3548703},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {H-STEP: Heuristic stable edge service entity placement for mobile virtual reality systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CHAR: Composite head-body activities recognition with a
single earable device. <em>TMC</em>, 1–17. (<a
href="https://doi.org/10.1109/TMC.2025.3548647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing popularity of earable devices stimulates great academic interest to design novel head gesture-based interaction technologies. But existing works simply consider it as a singular activity recognition problem. This is not in line with practice since users may have different body movements such as walking and jogging along with head gestures. It is also beneficial to recognize body movements during human-device interaction since it provides useful context information. As a result, it is significant to recognize such composite activities in which actions of different body parts happen simultaneously. In this paper, we propose a system called CHAR to recognize composite head-body activities with a single IMU sensor. The key idea of our solution is to make use of the inter-correlation of different activities and design a multi-task learning network to extract shared and specific representations. We implement a real-time prototype and conduct extensive experiments to evaluate it. The results show that CHAR can recognize 60 kinds of composite activities (12 head gestures and 5 body movements) with high accuracies of 89.7% and 85.1% in sufficient data and insufficient data cases, respectively.},
  archive      = {J_TMC},
  author       = {Peizhao Zhu and Yuzheng Zhu and Wenyuan Li and Yanbo He and Yongpan Zou and Kaishun Wu and Victor C. M. Leung},
  doi          = {10.1109/TMC.2025.3548647},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {CHAR: Composite head-body activities recognition with a single earable device},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MASA: Multimodal federated learning through modality-aware
and secure aggregation. <em>TMC</em>, 1–17. (<a
href="https://doi.org/10.1109/TMC.2025.3548954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a promising paradigm, federated learning has been applied to multimodal sensing tasks due to its deployment convenience. However, the recent advances in multimodal federated learning emphasize learning a high-quality multimodal model but overlook the model usage requirements of massive unimodal clients. Moreover, the privacy risk in model sharing and client data heterogeneity impact the efficacy of federated learning. In this paper, we propose a novel multimodal federated learning system named MASA. As a departure from existing approaches, MASA simultaneously enhances the model learning efficiency of both multimodal and unimodal clients while ensuring their data privacy. Firstly, we employ a gated cross-modal distillation scheme to achieve performance-aware knowledge transfer across modality-heterogeneous clients. To enhance the system security, MASA integrates a lightweight split-shuffle mechanism to realize the anonymization and encryption of model aggregation. Moreover, to reach personalized collaboration while protecting privacy, MASA features an attention-based spontaneous client clustering mechanism to form client cluster structures securely and distributedly. We evaluate our MASA on four public multimodal datasets for human activity recognition. The results show that our MASA outperforms leading multimodal federated learning methods on the model performance of both multimodal and unimodal clients.},
  archive      = {J_TMC},
  author       = {Jialin Guo and Yongjian Fu and Zhiwei Zhai and Xinyi Li and Yongheng Deng and Sheng Yue and Lili Chen and Hao Pan and Ju Ren},
  doi          = {10.1109/TMC.2025.3548954},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {MASA: Multimodal federated learning through modality-aware and secure aggregation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sensing metal coil vibration of headsets for eavesdropping
on online conversations with out-of-vocabulary words using RFID.
<em>TMC</em>, 1–13. (<a
href="https://doi.org/10.1109/TMC.2025.3548980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the most essential accessories, headsets have been widely used in common online conversations. The metal coil vibration patterns of headset speakers/microphones have been proven to be highly correlated with the speaker-produced/microphone-received sound. This paper presents an online conversation eavesdropping system, RFSpy, which uses only one RFID tag attached on a headset to alternately sense metal coil vibrations of headset speaker and microphone for eavesdropping on speaker-produced and microphone-received sound. In some accessible scenarios, assuming attackers secretly attach a small, battery-free RFID tag under one ear cushion of an eavesdropped user&#39;s headset without being noticed. Meanwhile, RFID readers are camouflaged as decorations placed in/out of rooms to transmit and receive RF signals. When the eavesdropped user talks with other users online through the headset, RFSpy first activates the RFID tag to capture the metal coil vibration patterns of headset speaker and microphone upon RF signals. Then, RFSpy reconstructs sound spectrograms from the RF signal-based vibration patterns for not only trained words but also untrained (i.e., out-of-vocabulary) words utilizing designed SSR network. Finally, RFSpy converts the sound spectrograms to conversation content through sound recognition API. Extensive experiments demonstrate that RFSpy can eavesdrop on online conversations with out-of-vocabulary words effectively.},
  archive      = {J_TMC},
  author       = {Yunzhong Chen and Jiadi Yu and Yingying Chen and Linghe Kong and Yanmin Zhu and Yichao Chen},
  doi          = {10.1109/TMC.2025.3548980},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Sensing metal coil vibration of headsets for eavesdropping on online conversations with out-of-vocabulary words using RFID},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multimodal scale normalization framework for vision-radar
small UAV positioning. <em>TMC</em>, 1–18. (<a
href="https://doi.org/10.1109/TMC.2025.3549620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) positioning is of crucial importance in diverse applications. However, it is extremely challenging to realize the precise UAVs positioning over long distances due to the small size and dramatic scale variations associated with the high mobility in the wide area. To tackle this issue, a multimodal scale normalization framework is proposed for the scale-robust precise pixel-level UAV positioning. The framework exploits our proposed distance-aware image slicing and distance-aware scale normalization module. Moreover, a modal fusion-based scale normalization network is proposed that can accept arbitrary low-resolution UAV patches and produce the consistent high-resolution images at a uniform UAV instance scale with a single learnable model. The proposed framework is generic and can be directly used in the existing pixel-level positioning pipelines to improve the positioning performance and scale robustness. To verify the proposed framework in the real application, a practical vision-radar UAV positioning system is developed. Experimental results on the real-world dataset demonstrate the generality and effectiveness of our framework. Moreover, the ablation experiments also confirm the contribution of each module in the framework.},
  archive      = {J_TMC},
  author       = {Yiyao Wan and Jiahuan Ji and Wenqing Xie and Guangyu Wu and Fuhui Zhou and Qihui Wu},
  doi          = {10.1109/TMC.2025.3549620},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A multimodal scale normalization framework for vision-radar small UAV positioning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint RIS and beamforming design for secure and
energy-efficient two-way relay communications. <em>TMC</em>, 1–17. (<a
href="https://doi.org/10.1109/TMC.2025.3549445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines the enhancement of secrecy energy efficiency (SEE) in a reconfigurable intelligent surface (RIS)-assisted two-way relay (TWR) system. We first establish a theoretical model for the system&#39;s secrecy rate, energy consumption, and SEE, and formulate the SEE maximization problem through the joint design of the RIS phase shifts and beamforming matrix. Using techniques such as weighted minimum mean square error (WMMSE), alternating optimization, and the augmented Lagrange method, we then develop a theoretical framework that identifies locally optimal solutions for the RIS and beamforming settings under unit- modulus and power constraints. The proposed framework is also shown to be applicable to solving the system&#39;s secrecy rate maximization problem. To address the computational complexity involved in optimizing the RIS phase shifts, we further propose a suboptimal scheme leveraging the Newton&#39;s method, which significantly reduces the computational burden while achieving performance close to the optimal SEE. Extensive numerical results validate the effectiveness of the proposed schemes, showing significant SEE improvements compared to traditional channel-capacity-based secure transmission scheme.},
  archive      = {J_TMC},
  author       = {Shuangrui Zhao and Xinghui Zhu and Yuanyu Zhang and Zhiwei Zhang and Yulong Shen},
  doi          = {10.1109/TMC.2025.3549445},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint RIS and beamforming design for secure and energy-efficient two-way relay communications},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NeFL: Nested model scaling for federated learning with
system heterogeneous clients. <em>TMC</em>, 1–13. (<a
href="https://doi.org/10.1109/TMC.2025.3549600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) enables distributed training while preserving data privacy, but stragglers-slow or incapable clients can significantly slow down the total training time and degrade performance. To mitigate the impact of stragglers, system heterogeneity, including heterogeneous computing and network bandwidth, has been addressed. While previous studies have addressed system heterogeneity by splitting models into submodels, they offer limited flexibility in model architecture design, without considering potential inconsistencies arising from training multiple submodel architectures. We propose nested federated learning (NeFL), a generalized framework that efficiently divides deep neural networks into submodels using both depthwise and widthwise scaling. To address the inconsistency arising from training multiple submodel architectures, NeFL decouples a subset of parameters from those being trained for each submodel. An averaging method is proposed to handle these decoupled parameters during aggregation. NeFL enables resource-constrained devices to effectively participate in the FL pipeline, facilitating larger datasets for model training. Experiments demonstrate that NeFL achieves performance gain, especially for the worst-case submodel compared to baseline approaches (7.63% improvement on CIFAR-100). Furthermore, NeFL aligns with recent advances in FL, such as leveraging pre-trained models and accounting for statistical heterogeneity. Our code is available online [1].},
  archive      = {J_TMC},
  author       = {Honggu Kang and Seohyeon Cha and Jinwoo Shin and Jongmyeong Lee and Joonhyuk Kang},
  doi          = {10.1109/TMC.2025.3549600},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {NeFL: Nested model scaling for federated learning with system heterogeneous clients},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Streamlining data transfer in collaborative SLAM through
bandwidth-aware map distillation. <em>TMC</em>, 1–13. (<a
href="https://doi.org/10.1109/TMC.2025.3549367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge intelligence offers a promising solution for Simultaneous Localization and Mapping (SLAM) in large-scale scenarios, where multiple robots collaboratively perceive the environment and upload their local maps to an edge server. However, maintaining mapping accuracy under constrained and dynamic communication resources remains a significant challenge for the practical deployment of robot swarms. Concurrent data uploads from multiple agents can exacerbate network congestion, leading to the loss of critical information, delayed updates, and, ultimately, the inconsistency of the generated maps. This paper presents Hermes, an edge-assisted collaborative mapping system designed for communication-constrained environments. Hermes streamlines data transfer through bandwidth-aware map distillation, ensuring only the most crucial messages are transmitted to the edge server. We quantify the importance of keyframes and landmarks based on their information entropy gain in pose estimation. By selectively sharing essential submaps, Hermes adaptively balances communication bandwidth and information richness during the mapping process. We implemented Hermes on heterogeneous platforms and conducted experiments using public datasets and self-collected campus data. Hermes exceeds SwarmMap by 50% in bandwidth utilization with similar accuracy and surpasses COVINS-G by 65% in trajectory error under highly constrained network resources.},
  archive      = {J_TMC},
  author       = {Rui Ge and Huanghuang Liang and Zheng Gong and Chuang Hu and Xiaobo Zhou and Dazhao Cheng},
  doi          = {10.1109/TMC.2025.3549367},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Streamlining data transfer in collaborative SLAM through bandwidth-aware map distillation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AMRE: Adaptive multilevel redundancy elimination for
multimodal mobile inference. <em>TMC</em>, 1–16. (<a
href="https://doi.org/10.1109/TMC.2025.3549422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given privacy and network load concerns, employing on-device multimodal neural networks (MNNs) for IoT data is a growing trend. However, the high computational demands of MNNs clash with limited on-device resources. MNNs involve input and model redundancies during inference, wasting resources to process redundant input components and run excess model parameters. Model Redundancy Elimination (MRE) reduces redundant parameters but cannot bypass inference for unnecessary input components. Input Redundancy Elimination (IRE) skips inference for redundant input components but cannot reduce computation for the remaining parts. MRE and IRE independently fail to meet the diverse computational needs of multimodal inference. To address these issues, we aim to combine the advantages of MRE and IRE to achieve a more efficient inference. We propose an adaptive multilevel redundancy elimination framework (AMRE), which supports both IRE and MRE. AMRE first establishes a collaborative inference mechanism for IRE and MRE. We then propose a multifunctional, lightweight policy model that adaptively controls the inference logic for each instance. Moreover, a three-stage training method is proposed to ensure the performance of collaborative inference in AMRE. We validate AMRE in three scenarios, achieving up to 52.91% lower latency, 56.79% lower energy cost, and a slight accuracy gain compared to state-of-the-art baselines.},
  archive      = {J_TMC},
  author       = {Qixuan Cai and Ruikai Chu and Kaixuan Zhang and Xiulong Liu and Xinyu Tong and Xin Xie and Jiancheng Chen and Keqiu Li},
  doi          = {10.1109/TMC.2025.3549422},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {AMRE: Adaptive multilevel redundancy elimination for multimodal mobile inference},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedHMIR: Unified framework for federated human-machine
synergy in personalization-generalization balancing identity
recognition. <em>TMC</em>, 1–18. (<a
href="https://doi.org/10.1109/TMC.2025.3549925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As device-free identity recognition (IR) gains popularity and the demand for the Internet of Things (IoT) continues to grow, a new-era IR system featuring multiple distributed recognition devices and edge servers faces two main challenges: model adaptability and balancing the personalization of devices with the generalization of the system. This research introduces FedHMIR, a federated framework designed to simultaneously address these challenges by harmonizing human-machine collaboration with personalization-generalization trade-offs. The proposed framework features a human-machine cooperative online internal update mechanism, leveraging reinforcement learning to maintain the adaptability of personalized local IR models. To counter overfitting and enhance the generalization of the overall IR system, an external update process incorporating a confidence index is introduced. Additionally, the framework employs asynchronous internal and external update procedures to effectively balance personalization and generalization between local and global models. Finally, extensive experiments on three diverse real-world datasets demonstrate the effectiveness and advantages of FedHMIR compared to state-of-the-art baselines.},
  archive      = {J_TMC},
  author       = {Qingyang Li and Yuanjiang Cao and Qianru Wang and Lina Yao and Zhiwen Yu and Jiangtao Cui},
  doi          = {10.1109/TMC.2025.3549925},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {FedHMIR: Unified framework for federated human-machine synergy in personalization-generalization balancing identity recognition},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An optimal reverse affine maximizer auction mechanism for
task allocation in mobile crowdsensing. <em>TMC</em>, 1–14. (<a
href="https://doi.org/10.1109/TMC.2025.3549504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowdsensing service (MCS) providers recruit users to complete data collection tasks with an incentive mechanism. How to maximize the utility of service providers has long been a popular topic in MCS research. Applying the existing reverse auction mechanism to an MCS may result in excessively high payments, thereby reducing the utility of the MCS provider. The affine maximizer auction (AMA) mechanism increases the revenue of service providers and meets dominant-strategy incentive-compatible (DSIC) characteristics. However, the AMA mechanism is a forward auction mechanism and cannot be applied to MCSs. Inspired by the AMA mechanism, this paper innovatively proposes a reverse affine maximizer auction (RAMA) mechanism to solve the task allocation problem of MCSs, effectively improving the MCS provider utility. Specifically, we construct a RAMA theoretical model and prove that the mechanism satisfies DSIC characteristics. For the discrete MCS task allocation problem, we use the reverse virtual valuation combinatorial auction (RVVCA) mechanism, a subclass of RAMA, to design a random mechanism ${\mathrm{RVVCA}}^{t}$ and prove that the ${\mathrm{RVVCA}}^{t}$ has a logarithmic approximate ratio. For the differentiable MCS task allocation problem, we use the deep learning transformer framework to design RAMANet, which can fit an exponential number of allocation solutions and output the optimal allocation and payment. We experimentally compare the algorithms of the RAMA family we propose, which use affine maximization, with existing state-of-the-art algorithms, demonstrating that the proposed algorithms significantly improve MCS provider utility.},
  archive      = {J_TMC},
  author       = {Jixian Zhang and Peng Chen and Xuelin Yang and Hao Wu and Weidong Li},
  doi          = {10.1109/TMC.2025.3549504},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {An optimal reverse affine maximizer auction mechanism for task allocation in mobile crowdsensing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HarmonyPath: Fine-grained flexible multipath transmission
for mobile differentiated services. <em>TMC</em>, 1–16. (<a
href="https://doi.org/10.1109/TMC.2025.3549505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The surge in mobile application services has led to diversified traffic and increased demands on network resources. Traditional multipath algorithms, designed for resource integration through subflow scheduling across paths, struggle with disharmonious transmission caused by terminal mobility and differentiated path resources. Especially when differentiated services are transmitted concurrently, disharmonious transmission can give rise to resource contention, causing a large number of subflows to congest a single path and leading to performance degradation. To mitigate these challenges, this paper introduces HarmonyPath, a fine-grained flexible multipath transmission mechanism that can ensure harmonious resource occupation. Specifically, HarmonyPath firstly employs an in-band telemetry protocol to gather path resource information, generating a network resource distribution map. Based on this map, it flexibly allocates path resources according to the network resource distribution and service requirements. Then, HarmonyPath establishes a collaborative matching model for service demands and path resources. Through matrix transformation and calculation, it rapidly generates and deploys the scheduling strategy. To further alleviate service contention, HarmonyPath employs heuristic algorithms to optimize the scheduling strategy and achieve precise multipath transmission. Experiments demonstrate that HarmonyPath surpasses traditional algorithms in the multipath transmission of differentiated services, offering flexible service resource guarantees and enhancing network resource utilization efficiency.},
  archive      = {J_TMC},
  author       = {Ziheng Xu and Wei Quan and Nan Cheng and Yuming Zhang and Mingyuan Liu and Xiaoting Ma and Xue Zhang and Hongke Zhang},
  doi          = {10.1109/TMC.2025.3549505},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {HarmonyPath: Fine-grained flexible multipath transmission for mobile differentiated services},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated multi-source domain adaptation for mmwave-based
human activity recognition. <em>TMC</em>, 1–14. (<a
href="https://doi.org/10.1109/TMC.2025.3549705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contactless mmWave-based human activity recognition (HAR) is essential for various applications, yet most existing approaches often assume consistent environments. Integrating domain adaptation offers a promising solution to this challenge. This prevailing paradigm works well when the source and target data are centralized on a single server while learning to adapt. However, in more universal and practical situations, such as personal health records, users&#39; biometric information, and financial issues, the raw data is typically protected by different privacy-preserving policies and is stored by multiple parties. Additionally, labeling RF signals in the target domain is a non-trivial and labor-intensive task for most end-users. To address these problems, this paper introduces FMDA, a federated multi-source domain adaptation framework for mmWave-based HAR. FMDA assesses the contribution of each source and performs weighted parameter aggregation for knowledge transfer. This facilitates unsupervised training of the target HAR model without requiring access to any source domain data. Moreover, the model is optimized by minimizing the generalization gaps between the source and target models, benefiting all participants during the learning process and enhancing overall performance. Extensive experiments demonstrate the effectiveness of FMDA. The results indicate that in the target domain, FMDA achieves comparable performance to supervised learning approaches, while also enhancing the efficacy of source domain models to varying degrees.},
  archive      = {J_TMC},
  author       = {Cui Zhao and Guotong Fang and Han Ding and Xinhui Liu and Fei Wang and Ge Wang and Kun Zhao and Zhi Wang and Wei Xi},
  doi          = {10.1109/TMC.2025.3549705},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Federated multi-source domain adaptation for mmwave-based human activity recognition},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting and characterising mobile app metamorphosis in
google play store. <em>TMC</em>, 1–16. (<a
href="https://doi.org/10.1109/TMC.2025.3550121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {App markets have evolved into highly competitive and dynamic environments for developers. While the traditional app life cycle involves incremental updates for feature enhancements and issue resolution, some apps deviate from this norm by undergoing significant transformations in their use cases or market positioning. We define this previously unstudied phenomenon as ‘app metamorphosis.’ In this paper, we propose a novel and efficient multi-modal search methodology to identify apps undergoing metamorphosis and apply it to analyse two snapshots of the Google Play Store taken five years apart. Our methodology uncovers various metamorphosis scenarios, including re-births, re-branding, re-purposing, and others, enabling comprehensive characterisation. Although these transformations may register as successful for app developers based on our defined success score metric (e.g., re-branded apps performing approximately 11.3% better than an average top app), we shed light on the concealed security and privacy risks that lurk within, potentially impacting even tech-savvy end-users.},
  archive      = {J_TMC},
  author       = {D. Denipitiyage and B. Silva and K. Gunathilaka and S. Seneviratne and A. Mahanti and A. Seneviratne and S. Chawla},
  doi          = {10.1109/TMC.2025.3550121},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Detecting and characterising mobile app metamorphosis in google play store},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LVMScissor: Split and schedule large vision model inference
on mobile edges via salp swarm algorithm. <em>TMC</em>, 1–16. (<a
href="https://doi.org/10.1109/TMC.2025.3550519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Computer Vision, the Large Vision Models (LVM) based on Vision Transformer (ViT) achieve advanced performance on general complex visual tasks. However, deploying these resource-intensive models on edge devices with limited computational power and memory is challenging, especially for those mobile edge devices. Existing model compression works downgrade the prediction accuracy and fail to adapt to dynamic network bandwidth or hardware changes. Besides, the split inference for typical Deep Neural Networks (DNN) is inefficient for LVM&#39;s large intermediate result size. To address the computation and bandwidth limitation of edge devices of LVM, we design a new split inference acceleration LVMScissor by leveraging model parallelism and meta-heuristic algorithm. We first implement an inter-layer ViT parallelism strategy. After modeling the parallelized ViT split problem into a Multi-task three-processor scheduling (MTS) problem, we propose LVM-MSSA, a scheduling algorithm based on a famous meta-heuristic algorithm, the Multi-objective Salp Swarm Algorithm (MSSA) to schedule model parallelism and split strategy. The evaluation results show that compared to state-of-the-art inference acceleration approaches, our solution is faster from $1.6\times$ to $6.92\times$ under variant LVMs, edge devices, datasets, and network traces.},
  archive      = {J_TMC},
  author       = {Yanting Liu and Rui Lu and Dan Wang},
  doi          = {10.1109/TMC.2025.3550519},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {LVMScissor: Split and schedule large vision model inference on mobile edges via salp swarm algorithm},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contract-inspired contest theory for controllable image
generation in mobile edge metaverse. <em>TMC</em>, 1–16. (<a
href="https://doi.org/10.1109/TMC.2025.3550815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advancement of immersive technologies has propelled the development of the Metaverse, where the convergence of virtual and physical realities necessitates the generation of high-quality, photorealistic images to enhance user experience. However, generating these images, especially through Generative Diffusion Models (GDMs), in mobile edge computing environments presents significant challenges due to the limited computing resources of edge devices and the dynamic nature of wireless networks. This paper proposes a novel framework that integrates contract-inspired contest theory, Deep Reinforcement Learning (DRL), and GDMs to optimize image generation in these resource-constrained environments. The framework addresses the critical challenges of resource allocation and semantic data transmission quality by incentivizing edge devices to efficiently transmit high-quality semantic data, which is essential for creating realistic and immersive images. The use of contest and contract theory ensures that edge devices are motivated to allocate resources effectively, while DRL dynamically adjusts to network conditions, optimizing the overall image generation process. Experimental results demonstrate that the proposed approach not only improves the quality of generated images but also achieves superior convergence speed and stability compared to traditional methods. This makes the framework particularly effective for optimizing complex resource allocation tasks in mobile edge Metaverse applications, offering enhanced performance and efficiency in creating immersive virtual environments.},
  archive      = {J_TMC},
  author       = {Guangyuan Liu and Hongyang Du and Jiacheng Wang and Dusit Niyato and Dong In Kim},
  doi          = {10.1109/TMC.2025.3550815},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Contract-inspired contest theory for controllable image generation in mobile edge metaverse},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cybertwin-enabled multipath transmission scheme in cloud
native networks. <em>TMC</em>, 1–16. (<a
href="https://doi.org/10.1109/TMC.2025.3550129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address issues arising from the independence of the radio access network, the IP bearer network, and the data center network, a Cybertwin-based cloud native network (CCNN) is proposed. However, due to diverse application requirements and user demands, providing individualized transmission services that meet these requirements within CCNN remains a major challenge. This paper proposes a Cybertwin-enabled multipath transmission scheme (CMTS) to provide personalized quality-of-service (QoS)-guaranteed transmission services by dynamically creating network paths tailored to users&#39; demands. Specifically, by introducing Cybertwin, CMTS allows separate and dynamic scheduling of service and access network resources from different providers, decouples users from network providers, and enables more flexible use of heterogeneous network resources. Moreover, CMTS can make resource scheduling decisions on demand by leveraging the user&#39;s personal information held by Cybertwin. To fully exploit the potential of multiple paths, we formulate network resource planning as an optimization problem aimed at minimizing link differences and propose a heuristic method for determining optimal policies. Finally, we present the first implementation of Cybertwin in CCNN, validate CMTS in both emulated and semi-physical environments, and conduct thorough evaluations with benchmarks. The results show that CMTS can deliver a personalized, QoS-guaranteed transmission service while achieving efficient resource utilization.},
  archive      = {J_TMC},
  author       = {Zhiyong Zeng and Meng Qin and Dandan Liang},
  doi          = {10.1109/TMC.2025.3550129},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A cybertwin-enabled multipath transmission scheme in cloud native networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying implementation flaws of SMS OTP authentication.
<em>TMC</em>, 1–15. (<a
href="https://doi.org/10.1109/TMC.2025.3550883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the Short Message Service (SMS) One-Time Passwords (OTP) authentication is widely adopted in mobile applications. However, due to improper implementation by developers, significant security flaws exist in the SMS OTP authentication mechanisms of some apps. To provide a comprehensive and accurate assessment, we propose a new approach. First, we locate the SMS OTP authentication page through UI exploration. Then, using hooking technology, we conduct simulated attacks to verify the security of the SMS OTP authentication in the app, focusing on its susceptibility to brute-force attacks. This approach is applicable to apps with app-side or UI-layer protection measures, uncovering hidden implementation flaws beneath these protections. Technically, we employ dynamic analysis based on the ART virtual machine instrumentation to obtain runtime information of the app and generate vulnerability verification scripts, overcoming the challenges posed by code-packing in program analysis. We implemented a semi-automatic tool named AuthChecker and tested it on 950 popular apps, identifying 87 apps with security flaws that potentially allow attackers to achieve unauthorized account access. Our findings highlight the security issues in SMS OTP authentication of apps, promoting improvements in vulnerability patching and preventive strategies by developers.},
  archive      = {J_TMC},
  author       = {Jiayu Zhao and Fannv He and Yiyu Yang and Yuqing Zhang},
  doi          = {10.1109/TMC.2025.3550883},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Identifying implementation flaws of SMS OTP authentication},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blockage-resilient integrated sensing and communication in
mmWave networks: Multi-view collaboration and efficient task allocation.
<em>TMC</em>, 1–15. (<a
href="https://doi.org/10.1109/TMC.2025.3551099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrated sensing and communication (ISAC) has emerged as a promising technology for future millimeter wave (mmWave) networks. However, the susceptibility of mmWave signals to blockages poses considerable challenges for ISAC as it can result in unreliable links and disrupted sensing. As a result, this paper investigates the blockage-resilient ISAC design that leverages the robustness offered by multi-base station (BS) collaboration. Given the dynamic blockages and the fluctuation in the targets&#39; radar cross section (RCS), the blockage-resilient multiBS collaborative ISAC design is cast as a chance constrained integer programming (CCIP) by jointly considering the diverse deadlines of different sensing tasks and the spatial/temporal user-target pairing for dual-functional radar and communication (DFRC) waveform scheduling. To facilitate efficient solution finding, we develop a group concatenating assisted reinforcement learning (GCRL) algorithm, where we linearize the chance constraints via variable grouping and concatenation, enabling the RL agent to understand the problem structure with bipartite graphs so as to develop an efficient branching policy. Extensive experiments demonstrate the resilience of the obtained ISAC scheme to dynamic blockages.},
  archive      = {J_TMC},
  author       = {Yue Cui and Haichuan Ding and Ying Ma and Xuanheng Li and Haixia Zhang and Yuguang Fang},
  doi          = {10.1109/TMC.2025.3551099},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Blockage-resilient integrated sensing and communication in mmWave networks: Multi-view collaboration and efficient task allocation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-UAV-assisted MEC in IoV with combined multi-modal
semantic communication under jamming attacks. <em>TMC</em>, 1–15. (<a
href="https://doi.org/10.1109/TMC.2025.3550965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic communication technology, which transmits only relevant semantic information, can significantly conserve communication resources and reduce service time. This technology is particularly promising for unmanned aerial vehicle (UAV)-assisted mobile edge computing (MEC) in the internet of vehicles (IoV). However, integrating semantic communication with UAV-assisted vehicle MEC is susceptible to malicious jamming. This paper introduces a reliable communication method that combines multi-modal semantic communication with UAV-assisted vehicle MEC to minimize delays in communication and computation while maintaining semantic accuracy during jamming attacks. Our approach optimizes UAV trajectories, user associations, and channel selections, enabling the UAV to select optimal positions when associating with different modal users and reducing the impact of jammers during multi-modal task reception. Due to the non-convex nature of the optimization problem and the highly dynamic environment, we employ the semantic communication combined with the multi-agent twin delayed deep deterministic policy gradient (SC-MA-TD3) approach, a multi-agent deep reinforcement learning (DRL) strategy that fosters UAV cooperation for efficient resource allocation. Simulation results show that our approach outperforms existing approaches in reducing delays and enhancing semantic accuracy.},
  archive      = {J_TMC},
  author       = {Shuai Liu and Helin Yang and Mengting Zheng and Liang Xiao},
  doi          = {10.1109/TMC.2025.3550965},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multi-UAV-assisted MEC in IoV with combined multi-modal semantic communication under jamming attacks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scheduling drone and mobile charger via hybrid-action deep
reinforcement learning. <em>TMC</em>, 1–18. (<a
href="https://doi.org/10.1109/TMC.2025.3551386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, there has been a growing interest in using chargers to extend the operational longevity of UAVs (drones). In this paper, we explore a charger-assisted drone application where a drone observes points of interest while a mobile charger moves to recharge its battery. We focus on the route and charging schedule of the drone and mobile charger to maximize observation utility in the shortest possible time, while ensuring continuous drone operation. In our problem, the drone and mobile charger cooperate to complete a task. Their discrete-continuous hybrid actions pose a major computational challenge. To address this issue, we present a hybrid-action deep reinforcement learning framework, called HaDMC, which uses a typical policy learning algorithm to generate latent continuous actions. We specifically design and train an action decoder. It involves two pipelines to convert the latent continuous actions into the original hybrid actions for the drone and mobile charger to directly interact with environment. We incorporate a mutual learning scheme into model training, emphasizing collaboration over individual actions. By extensive numerical experiments, we evaluate HaDMC and compare it with state-of-the-art approaches. The experimental results demonstrate the effectiveness and efficiency of our solution.},
  archive      = {J_TMC},
  author       = {Jizhe Dou and Haotian Zhang and Yang Luo and Guodong Sun},
  doi          = {10.1109/TMC.2025.3551386},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Scheduling drone and mobile charger via hybrid-action deep reinforcement learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HeadSonic: Usable bone conduction earphone authentication
via head-conducted sounds. <em>TMC</em>, 1–15. (<a
href="https://doi.org/10.1109/TMC.2025.3551272">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Earables (ear wearables) are rapidly emerging as a new platform encompassing a diverse of personal applications, prompting the development of authentication schemes to protect user privacy. Existing earable authentication methods are all specifically designed for air-conduction earphones, which are not suited for bone conduction earphones (BCEs) that rely on bone conduction mechanisms. In this paper, we propose HeadSonic, a usable BCE authentication system based on the unique head-conducted sounds, which can be acquired when the user wears the BCE device. Specifically, the system emits a millisecond-level sound to initiate the authentication session. The signal captured by the BCE microphone is propagated through the user&#39;s head, which is unique in density, geometry, and bone-tissue ratio. It operates implicitly, while maintaining robustness across different behaviors. Extensive experiments involving 60 subjects demonstrate that HeadSonic achieves a commendable balanced accuracy of 96.59%, proving its efficacy and resilience against replay and synthesis attacks. Our dataset and source codes are available at https://anonymous.4open.science/r/HeadSonic-1CE4.},
  archive      = {J_TMC},
  author       = {Zhixiang He and Jing Chen and Kun He and Yangyang Gu and Qiyi Deng and Zijian Zhang and Ruiying Du and Qingchuan Zhao and Cong Wu},
  doi          = {10.1109/TMC.2025.3551272},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {HeadSonic: Usable bone conduction earphone authentication via head-conducted sounds},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Acoustic eavesdropping from sound-induced vibrations with
multi-antenna mmWave radar. <em>TMC</em>, 1–16. (<a
href="https://doi.org/10.1109/TMC.2025.3551317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acoustic eavesdropping against private or confidential spaces is a significant threat in the realm of privacy protection. While the presence of soundproof material would weaken such an attack, current eavesdropping technology may be able to bypass these protections. Fortunately, existing studies either inadequately cover the full spectrum of human speech due to low-frequency responses or rely heavily on the prior knowledge used to train a model. To address these challenges, this paper introduces mmEcho, a new acoustic eavesdropping method that utilizes millimeter-wave signals to sense vibration induced by sound precisely. Through signal processing techniques such as the intra-chirp scheme and phase calibration algorithm, mmEcho achieves micrometer-level vibration extraction without requiring target-related data. To improve the range of eavesdropping attacks while reducing noise, we optimize radar signals by leveraging the widespread availability of multiple antennas on commercial off-the-shelf radars. We comprehensively evaluate the performance of mmEcho in different real-world settings. Experimental results demonstrate that, with the aid of multi-antenna technology, mmEcho can more effectively reconstruct the audio from the target at various distances, directions, sound insulators, reverberating objects, sound levels, and languages. Compared to existing methods, our approach provides better effectiveness without prior knowledge, such as the speech data from the target.},
  archive      = {J_TMC},
  author       = {Wenhao Li and Riccardo Spolaor and Chuanwen Luo and Yuchao Sun and Huashan Chen and Guoming Zhang and Yanni Yang and Xiuzhen Cheng and Pengfei Hu},
  doi          = {10.1109/TMC.2025.3551317},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Acoustic eavesdropping from sound-induced vibrations with multi-antenna mmWave radar},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PBN-CSMA/CA: A power back-off NOMA-based CSMA/CA protocol
for ad hoc networks. <em>TMC</em>, 1–14. (<a
href="https://doi.org/10.1109/TMC.2025.3551340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carrier-sense multiple access with collision avoidance (CSMA/CA) is one of the fundamental medium access control (MAC) protocols for ad hoc networks. As a network&#39;s size increases, its throughput degrades substantially because of packet collisions. To reduce the collision probability, combining non-orthogonal multiple access (NOMA) with CSMA/CA is a promising solution. However, existing NOMA-CSMA/CA protocols adopt distributed power selection and channel inversion power control, resulting in a high power collision probability and limiting the number of power levels. To address these issues, we propose a power back-off NOMA-based CSMA/CA (PBN-CSMA/CA) protocol for ad hoc networks. The proposed protocol achieves centralized power allocation, avoiding power collisions by employing the Zadoff-Chu (ZC) sequence and the power level allocation (PLA) frame. Additionally, power back-off (PB) control is used to set the transmission power, which expands the number of power levels and gives full play to the performance advantages of NOMA. To analyze the performance comprehensively, the closed-form expressions of the average outage probability, normalized saturation throughput, average packet delay and transmission energy consumption are theoretically analyzed. Both the analytical and simulation results demonstrate that the PBN-CSMA/CA protocol outperforms the existing NOMA-CSMA/CA and traditional CSMA/CA protocols, with significant throughput gains and delay reductions.},
  archive      = {J_TMC},
  author       = {Ningbo Zhang and Guangqian Peng and Hao Chen and Caitong Tang},
  doi          = {10.1109/TMC.2025.3551340},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {PBN-CSMA/CA: A power back-off NOMA-based CSMA/CA protocol for ad hoc networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A four-year retrospective of mobile access bandwidth
evolution: The inspiring, the frustrating, and the fluctuating.
<em>TMC</em>, 1–16. (<a
href="https://doi.org/10.1109/TMC.2025.3551595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in mobile technologies (like WiFi 6 and 5G) do not seem to deliver the promised access bandwidth. To effectively characterize mobile access bandwidth in the wild, we work with a major commercial mobile bandwidth testing app to conduct a long-term (2020-2023) and large-scale (involving 4.76M users) measurement study in China, based on coarse-grained general statistics and fine-grained sampling diagnostics. Our study presents distinct facts as to WiFi, 5G, and 4G: in the past few years, the average WiFi download bandwidth exhibits a considerable rise (by 119.7%), the average 5G download bandwidth constantly decreases (by a total of 20.2%) despite the enormous infrastructure investments, while the average 4G download bandwidth first declines (by 22.1%) and then increases (by 22.5%). The situations of upload bandwidths are generally similar to those of download bandwidths, except that 5G upload bandwidths manifest N-shaped $( \nearrow \searrow \nearrow )$ fluctuations. Our cross-layer and cross-technology analysis reveals a variety of impact factors as well as their complicated interplay as the root causes, such as the bottlenecks in underlying infrastructure (e.g., communication devices and wired Internet access), the traffic offloading from one access technology to another, the influence of the COVID-19 pandemic, and the side effects of aggressively migrating radio resources from 4G to 5G. With the longitudinal, holistic picture of today&#39;s mobile access bandwidth, we finally provide multifold practical implications on closing the technology gaps.},
  archive      = {J_TMC},
  author       = {Zhenhua Li and Ruoxuan Yang and Xinlei Yang and Jing Yang and Xingyao Li and Hao Lin and Feng Qian and Yunhao Liu and Zhi Liao and Daqiang Hu},
  doi          = {10.1109/TMC.2025.3551595},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A four-year retrospective of mobile access bandwidth evolution: The inspiring, the frustrating, and the fluctuating},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision language model-empowered contract theory for AIGC
task allocation in teleoperation. <em>TMC</em>, 1–15. (<a
href="https://doi.org/10.1109/TMC.2025.3551597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating low-light image enhancement techniques, in which diffusion-based AI-generated content (AIGC) models are promising, is necessary to enhance nighttime teleoperation. Remarkably, the AIGC model is computation-intensive, thus necessitating the allocation of AIGC tasks to edge servers with ample computational resources. Given the distinct cost of the AIGC model trained with varying-sized datasets and AIGC tasks possessing disparate demand, it is imperative to formulate a differential pricing strategy to optimize the utility of teleoperators and edge servers concurrently. Nonetheless, the pricing strategy formulation is under information asymmetry, i.e., the demand (e.g., the difficulty level of AIGC tasks and their distribution) of AIGC tasks is hidden information to edge servers. Additionally, manually assessing the difficulty level of AIGC tasks is tedious and unnecessary for teleoperators. To this end, we devise a framework of AIGC task allocation assisted by the Vision Language Model (VLM)-empowered contract theory, which includes two components: VLM-empowered difficulty assessment and contract theory-assisted AIGC task allocation. The first component enables automatic and accurate AIGC task difficulty assessment. The second component is capable of formulating the pricing strategy for edge servers under information asymmetry, thereby optimizing the utility of both edge servers and teleoperators. The simulation results demonstrated that our proposed framework can improve the average utility of teleoperators and edge servers by $10.88 \sim 12.43\%$ and $1.4 \sim 2.17\%$, respectively. Code and data are available at urlhttps://github.com/ZiJun0819/VLM-Contract-Theory.},
  archive      = {J_TMC},
  author       = {Zijun Zhan and Yaxian Dong and Daniel Mawunyo Doe and Yuqing Hu and Shuai Li and Shaohua Cao and Zhu Han},
  doi          = {10.1109/TMC.2025.3551597},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Vision language model-empowered contract theory for AIGC task allocation in teleoperation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Jointly-optimized trajectory generation and camera control
for 3D coverage planning. <em>TMC</em>, 1–18. (<a
href="https://doi.org/10.1109/TMC.2025.3551362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a jointly optimized trajectory generation and camera control approach, enabling an autonomous agent, such as an unmanned aerial vehicle (UAV) operating in 3D environments, to plan and execute coverage trajectories that maximally cover the surface area of a 3D object of interest. Specifically, the UAV&#39;s kinematic and camera control inputs are jointly optimized over a rolling planning horizon to achieve complete 3D coverage of the object. The proposed controller incorporates ray-tracing into the planning process to simulate the propagation of light rays, thereby determining the visible parts of the object through the UAV&#39;s camera. This integration enables the generation of precise look-ahead coverage trajectories. The coverage planning problem is formulated as a rolling finite-horizon optimal control problem and solved using mixed-integer programming techniques. Extensive real-world and synthetic experiments validate the performance of the proposed approach.},
  archive      = {J_TMC},
  author       = {Savvas Papaioannou and Panayiotis Kolios and Theocharis Theocharides and Christos G. Panayiotou and Marios M. Polycarpou},
  doi          = {10.1109/TMC.2025.3551362},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Jointly-optimized trajectory generation and camera control for 3D coverage planning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ubicon-BP: Towards ubiquitous, contactless blood pressure
detection using smartphone. <em>TMC</em>, 1–13. (<a
href="https://doi.org/10.1109/TMC.2025.3551315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blood pressure (BP) is a critical physiological parameter closely associated with severe diseases such as heart failure and kidney damage. Current methods either require additional or dedicated hardware, or closing touching to the devices, causing discomfort and inconvenience. Therefore, a convenient, contactless BP measurement solution is highly desired. In this work, we present Ubicon-BP, a ubiquitous, device-free, and contactless BP detection application. Ubicon-BP calculates BP based on the pulse transit time (PTT), a key feature that is medically proven correlated with BP. However, using smartphone sensors to contactless calculate PTT is non-trivial since it requires a micro-second level precision for cardiac event detection. To address this issue, we propose leveraging the acoustic sensors in smartphone to detect vibrations caused by heart valve movements, as well as camera sensors to measure finger pulses. To accurately measure heartbeat signal that are susceptible to motion, we first improve the sensing granularity of acoustic signals and then introduce the IQ-MVED model to eliminate motion interference. Furthermore, when recovering pulse signals from video signals, issues such as poor generalization performance arise. Consequently, we propose the TS-CAN and meta-learning models to obtain personalized pulse signals. Finally, we transform the extracted time-frequency features from the recovered heartbeats and pulse signals to the corresponding BP. Comprehensive testing involving 50 subjects reveal a standard deviation error of 4.27mmHg for diastolic pressure and 6.36mmHg for systolic pressure, respectively.},
  archive      = {J_TMC},
  author       = {Yuan Wu and Shoudu Bai and Qingyong Hu and Bo Wang and Min Li and Xinrong Hu and Yanjiao Chen},
  doi          = {10.1109/TMC.2025.3551315},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Ubicon-BP: Towards ubiquitous, contactless blood pressure detection using smartphone},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A joint secure mechanism of multi-task learning for a UAV
team under FDI attacks. <em>TMC</em>, 1–15. (<a
href="https://doi.org/10.1109/TMC.2025.3551537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A UAV team shows tremendous potential for various mobile scenarios. However, some evidences reveal their vulnerability to False Data Injection (FDI) attacks, which can significantly jeopardize the flight security or even lead to catastrophic incidents. Existing studies primarily focus on detecting or defending against FDI attacks at the trajectory control of individual UAVs, leaving a gap in a comprehensive secure mechanism that can simultaneously detect, localize, and compensate for such attacks across an entire UAV team. The complexity of developing such a solution is magnified by the multiple design goals, the inherent sophistication of UAV team, and practical attack assumptions. In this paper, we propose a joint secure framework based on multi-task deep learning to simultaneously detect FDI attacks, localize the compromised components, and compensate control signals to mitigate the impact of FDI attacks on promising UAV teams. Specifically, we design an all-in-one deep learning model framework with a temporal-spatial information extraction module and a hierarchical multi-task module to perform three tasks simultaneously. Moreover, we introduce an iterative learning method with experience replay to counteract knowledge decay during model training. Extensive experiments and real flight demonstrations are presented to validate the improved performance and the benefits of our proposed secure method. A demonstration video and our source code can be accessed via https://github.com/WingFeiTsang/JS/.},
  archive      = {J_TMC},
  author       = {Rongfei Zeng and Chenyang Jiang and Xingwei Wang and Baochun Li},
  doi          = {10.1109/TMC.2025.3551537},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A joint secure mechanism of multi-task learning for a UAV team under FDI attacks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain-specific transport protocols for in-network
processing at the edge: A case study of accelerating model
synchronization. <em>TMC</em>, 1–17. (<a
href="https://doi.org/10.1109/TMC.2025.3552220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, cross-device federated learning (FL) is the key to achieving personalization services for mobile users and has been widely employed by companies like Google, Microsoft, and Alibaba in production. With the explosive growth in the number of participants, the central FL server, which acts as the manager and aggregator of cross-device model training, would get overloaded, becoming the system bottlenecks. Inspired by the emerging wave of edge computing, an interesting question arises: Could edge clouds help cross-device FL systems overcome the bottleneck? This article provides a cautiously optimistic answer by proposing INP, a FL-specific In-Network Processing framework to achieve the goal. As in-network processing has broken the end-to-end principle of the involved communication and lacks the support of transport protocols, the key is to design domainspecific transport protocols for INP. To fill the gap, we propose the novel Model Download Protocol of MDP and Model Upload Protocol of MUP. With MDP and MUP, edge cloud nodes along the paths in INP can easily eliminate duplicated model downloads and pre-aggregate associated gradient uploads for the central FL server, thus alleviating its bottleneck effect, and further accelerating the entire training progress significantly.},
  archive      = {J_TMC},
  author       = {Shouxi Luo and Peidong Zhang and Xin Song and Pingzhi Fan and Huanlai Xing and Long Luo and Hongfang Yu},
  doi          = {10.1109/TMC.2025.3552220},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Domain-specific transport protocols for in-network processing at the edge: A case study of accelerating model synchronization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Communication-efficient federated learning by quantized
variance reduction for heterogeneous wireless edge networks.
<em>TMC</em>, 1–16. (<a
href="https://doi.org/10.1109/TMC.2025.3551759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) has been recognized as a viable solution for local-privacy-aware collaborative model training in wireless edge networks, but its practical deployment is hindered by the high communication overhead caused by frequent and costly server-device synchronization. Notably, most existing communication-efficient FL algorithms fail to reduce the significant inter-device variance resulting from the prevalent issue of device heterogeneity. This variance severely decelerates algorithm convergence, increasing communication overhead and making it more challenging to achieve a well-performed model. In this paper, we propose a novel communication-efficient FL algorithm, named FedQVR, which relies on a sophisticated variance-reduced scheme to achieve heterogeneity-robustness in the presence of quantized transmission and heterogeneous local updates among active edge devices. Comprehensive theoretical analysis justifies that FedQVR is inherently resilient to device heterogeneity and has a comparable convergence rate even with a small number of quantization bits, yielding significant communication savings. Besides, considering non-ideal wireless channels, we propose FedQVR-E which enhances the convergence of FedQVR by performing joint allocation of bandwidth and quantization bits across devices under constrained transmission delays. Extensive experimental results are also presented to demonstrate the superior performance of the proposed algorithms over their counterparts in terms of both communication efficiency and application performance.},
  archive      = {J_TMC},
  author       = {Shuai Wang and Yanqing Xu and Chaoqun You and Mingjie Shao and Tony Q. S. Quek},
  doi          = {10.1109/TMC.2025.3551759},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Communication-efficient federated learning by quantized variance reduction for heterogeneous wireless edge networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing resource block allocation for multicast in beyond
5G networks. <em>TMC</em>, 1–18. (<a
href="https://doi.org/10.1109/TMC.2025.3549590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New radio (NR) and non-orthogonal multiple access (NOMA) offer scalable and efficient resource allocation in Beyond 5G (B5G) networks. NR implements mixed numerology with flexible frame structures for future compatibility, whereas NOMA allows users with different channel states to share an identical Physical Resource Block (PRB). Multi-connectivity enables a user to connect to multiple networks for reliability, and multicast conveys data to users simultaneously that request the same content. However, resource allocation in the NOMA-based mixed numerology system with multi-connectivity for multicast remains unexplored. The problem is challenging due to 1) the different shapes of PRBs in NR and 2) the shared locations of PRBs in a frame with NOMA. In this paper, we formulate a new optimization problem, named Multicast, Multi-connectivity, and Multi-Dimensional Resource Allocation Problem (M $^{3}$ DRAP), and prove its NP-hardness and inapproximability. We propose an approximation algorithm for general M $^{3}$ DRAP with the ideas of Multicast Inter-Numerology Relation, Layer Dissimilarity, Subgrouping Nonuniformity, and Segmentation Preference. To find the intrinsic properties of PRB allocation for multicast in NOMA-based networks, we consider a single B5G usage scenario (e.g., eMBB, URLLC, or mMTC) and propose another approximation algorithm. Simulations demonstrate our algorithms improve the weighted sum rate by over 50% and increase the user satisfaction ratio by 1.5x.},
  archive      = {J_TMC},
  author       = {Ru-Jun Wang and Chih-Hang Wang and De-Nian Yang and Guang-Siang Lee and Wen-Tsuen Chen and Jang-Ping Sheu},
  doi          = {10.1109/TMC.2025.3549590},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Optimizing resource block allocation for multicast in beyond 5G networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring communication-efficient federated learning via
stateless in-network aggregation. <em>TMC</em>, 1–16. (<a
href="https://doi.org/10.1109/TMC.2025.3551368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an ambitious training paradigm, federated learning has garnered increasing attention in recent years, which enables collaborative training of a global model without accessing users&#39; private data. However, due to the simultaneous and constant model updates gathering from massive distributed clients, the central server generally becomes a performance bottleneck. Additionally, the stateful aggregation (retaining all the updates from each client) conducted by the central server further poses potential threats to privacy, since it may recover the raw data based on such model updates inversely. The state-of-the-art methodologies, however, fail to address these two problems concurrently and efficiently. To this end, we propose GAIN, a secure aggregation acceleration service for federated learning. At its core, GAIN leverages programmable switches deployed at the edge network to aggregate model updates in a stateless manner before transmitting them to the central server. Consequently, GAIN can accelerate the transmission and aggregation of model updates while eliminating the chance of recovering private data. We evaluate the performance of GAIN through FPGA-based experiments and large-scale simulations. The results show that GAIN can effectively reduce bandwidth overhead and achieve up to 4.11× training throughput acceleration while prioritizing privacy protection.},
  archive      = {J_TMC},
  author       = {Junxu Xia and Geyao Cheng and Wenfei Wu and Lailong Luo and Deke Guo},
  doi          = {10.1109/TMC.2025.3551368},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Exploring communication-efficient federated learning via stateless in-network aggregation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contextual bandits with non-stationary correlated rewards
for user association in MmWave vehicular networks. <em>TMC</em>, 1–14.
(<a href="https://doi.org/10.1109/TMC.2025.3552717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Millimeter wave (mmWave) communication has emerged as a key technology enabling ultra-low latency and high throughput in vehicular communication. Usually, an appropriate decision on user association requires timely channel information between vehicles and base stations (BSs), which is challenging given a fast-fading mmWave vehicular channel. In this paper, we propose a low-complexity semi-distributed contextual correlated upper confidence bound (SD-CC-UCB) algorithm to establish an up-to-date user association between vehicles and BSs without explicit measurement of channel state information (CSI). Under a contextual multi-arm bandits framework, SD-CC-UCB learns and predicts the transmission rate given the location and velocity of the vehicle, which can adequately capture the intricate channel condition for a prompt decision on user association. Further, SD-CC-UCB efficiently identifies the set of candidate BSs which probably support supreme transmission rates by leveraging the correlated distributions of transmission rates on different locations. To further refine the learning transmission rate to candidate BSs, each vehicle deploys the Thompson Sampling algorithm by taking the interference among vehicles and handover into consideration. Numerical results show that our proposed algorithm achieves the network throughput within 100%-103% of a benchmark algorithm which requires perfect instantaneous CSI, demonstrating the effectiveness of SD-CC-UCB in vehicular communications.},
  archive      = {J_TMC},
  author       = {Xiaoyang He and Xiaoxia Huang and Lanhua Li},
  doi          = {10.1109/TMC.2025.3552717},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Contextual bandits with non-stationary correlated rewards for user association in MmWave vehicular networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design optimization of NOMA aided multi-STAR-RIS for indoor
environments: A convex approximation imitated reinforcement learning
approach. <em>TMC</em>, 1–17. (<a
href="https://doi.org/10.1109/TMC.2025.3552521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-orthogonal multiple access (NOMA) enables multiple users to share the same frequency band, and simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) provides 360-degree full-space coverage, optimizing both transmission and reflection for improved network performance and dynamic control of the indoor environment. However, deploying STAR-RIS indoors presents challenges in interference mitigation, power consumption, and real-time configuration. In this work, a novel network architecture utilizing multiple access points (APs), STAR-RISs, and NOMA is proposed for indoor communication. To address these, we formulate an optimization problem involving user assignment, access point (AP) beamforming, and STAR-RIS phase control. A decomposition approach is used to solve the complex problem efficiently, employing a many-to-one matching algorithm for user-AP assignment and K-means clustering for resource management. Additionally, multi-agent deep reinforcement learning (MADRL) is leveraged to optimize the control of the STAR-RIS. Within the proposed MADRL framework, a novel approach is introduced in which each decision variable acts as an independent agent, enabling collaborative learning and decision making. The MADRL framework is enhanced by incorporating convex approximation (CA), which accelerates policy learning through suboptimal solutions from successive convex approximation (SCA), leading to faster adaptation and convergence. Simulations demonstrate significant improvements in network utility compared to baseline approaches.},
  archive      = {J_TMC},
  author       = {Yu Min Park and Sheikh Salman Hassan and Yan Kyaw Tun and Eui-Nam Huh and Walid Saad and Choong Seon Hong},
  doi          = {10.1109/TMC.2025.3552521},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Design optimization of NOMA aided multi-STAR-RIS for indoor environments: A convex approximation imitated reinforcement learning approach},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient and cost-effective vehicle recruitment for HD map
crowdsourcing. <em>TMC</em>, 1–14. (<a
href="https://doi.org/10.1109/TMC.2025.3552396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The high-definition (HD) map is a cornerstone of autonomous driving. The crowdsourcing paradigm is a cost-effective way to keep an HD map up-to-date. Current HD map crowdsourcing mechanisms aim to enhance HD map freshness within recruitment budgets. However, many overlook unique and critical traits of crowdsourcing vehicles, such as random arrival and heterogeneity, leading to either compromised map freshness or excessive recruitment costs. Furthermore, these characteristics complicate the characterization of the feasible space of the optimal recruitment policy, necessitating a method to compute it efficiently in dynamic transportation scenarios. To overcome these challenges, we propose an efficient and cost-effective vehicle recruitment (ENTER) mechanism. Specifically, the ENTER mechanism has a threshold structure and balances freshness with recruitment costs while accounting for the vehicles&#39; random arrival and heterogeneity. It also integrates the bound-based relative value iteration (RVI) algorithm, which utilizes the threshold-type structure and upper bounds of thresholds to reduce the feasible space and expedite convergence. Numerical results show that the proposed ENTER mechanism increases the HD map company&#39;s payoff by 23.40% and 43.91% compared to state-of-the-art mechanisms that do not account for vehicle heterogeneity and random arrivals, respectively. Furthermore, the bound-based RVI algorithm in the ENTER mechanism reduces computation time by an average of 18.91% compared to the leading RVI-based algorithm.},
  archive      = {J_TMC},
  author       = {Wentao Ye and Yuan Luo and Bo Liu and Jianwei Huang},
  doi          = {10.1109/TMC.2025.3552396},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Efficient and cost-effective vehicle recruitment for HD map crowdsourcing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic pricing based near-optimal resource allocation for
elastic edge offloading. <em>TMC</em>, 1–14. (<a
href="https://doi.org/10.1109/TMC.2025.3553188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mobile edge computing (MEC), task offloading can significantly reduce task execution latency and energy consumption of end user (EU). However, edge server (ES) resources are limited, necessitating efficient allocation to ensure the sustainable and healthy development for MEC system. In this paper, we propose a dynamic pricing mechanism based near-optimal resource allocation for elastic edge offloading. First, we construct a resource pricing model and accordingly develop the utility functions for both EU and ES, the optimal pricing model parameters are derived by optimizing the utility functions. In the meantime, our theoretical analysis reveals that the EU&#39;s utility function reaches a local maximum within the search range, but exhibits barely growth with increased resource allocation beyond this point. To this end, we further propose the Dynamic Inertia and Speed-Constrained particle swarm optimization (DISC-PSO) algorithm, which efficiently identifies the near-optimal resource allocation. Comprehensive simulation results validate the effectiveness of DISC-PSO algorithm, demonstrating that it significantly outperforms existing schemes by reducing the average number of iterations to reach a near-optimal solution by 86.88%, increasing the EU utility function value by 0.13%, and decreasing the variance of results by 96.78%.},
  archive      = {J_TMC},
  author       = {Yun Xia and Hai Xue and Di Zhang and Shahid Mumtaz and Xiaolong Xu and Joel J. P. C. Rodrigues},
  doi          = {10.1109/TMC.2025.3553188},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Dynamic pricing based near-optimal resource allocation for elastic edge offloading},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ExpertDRL: Request dispatching and instance configuration
for serverless edge inference with foundation models. <em>TMC</em>,
1–16. (<a href="https://doi.org/10.1109/TMC.2025.3553201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevalence of the pre-training &amp; fine-tuning paradigm enables machine learning models to quickly adapt to various downstream tasks by fine-tuning pre-trained foundation models (FMs), greatly facilitating various IoT applications that rely on model inference in dynamic edge serverless environments. Efficiently dispatching inference requests and configuring instances to batch inference requests can significantly enhance resource efficiency. However, existing serverless inference solutions are tailored for traditional models, make coarse-grained request dispatching and instance configuration decisions, fail to exploit the shared model backbone characteristics of the FM and capture delayed rewards in dynamic environments, and ignore communication latency between edge sites, resulting in high costs and constraint violations. In this paper, we leverage our insight that fine-grained batch inference requests can effectively exploit the shared model backbone feature of FM to save monetary costs. We propose an algorithm that incorporates deep reinforcement learning (DRL) and expert intervention for fine-grained request dispatching and instance configuration, where the DRL component outputs fractional solutions as guidance, while the expert intervention module integrates our insights—batching reduces monetary costs at the expense of increased inference latency, whereas higher configurations shorten inference latency. This module rounds fractional solutions and adjusts instance configurations to search for optimal solutions while satisfying constraints, with theoretical guarantees rigorously proved. Finally, we conducted our experiments on an OpenFaas-based platform and simulator, and extensive trace-driven evaluation results show that ExpertDRL can save costs by up to 85.14% and improve request acceptance ratio by up to 26.93%, compared to the state-of-the-art solution.},
  archive      = {J_TMC},
  author       = {Yue Zeng and Junlong Zhou and Baoliu Ye and Zhihao Qu and Song Guo and Tianjian Gong and Pan Li},
  doi          = {10.1109/TMC.2025.3553201},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {ExpertDRL: Request dispatching and instance configuration for serverless edge inference with foundation models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging online learning for domain-adaptation in
wi-fi-based device-free localization. <em>TMC</em>, 1–15. (<a
href="https://doi.org/10.1109/TMC.2025.3552538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wi-Fi-based device-free localization (DFL) will be an integral part of many emerging applications, such as smart healthcare and smart homes. One popular approach to DFL in Wi-Fi makes use of fingerprinting based on channel state information (CSI). Unfortunately, high-quality fingerprints cannot easily be obtained in many real-world environments due to the complicated, time-varying and multipath conditions which exist. Additionally, existing methods struggle to update the DFL models in a real-time manner to track changes of environment. To address these issues, an online data-driven modelling DFL framework is designed for robustness enhancement. Specifically, the raw CSI data is first augmented with the hidden layer parameters of an online deep neural network to strengthen the pair-to-pair mappings between signal variations and a target&#39;s location. The radio map created with the augmented fingerprints can be updated with new sequential data collected from other domains, such as different times and layouts of the same environment. Subsequently, a novel online DFL model is established using these augmented fingerprints, which itself can be updated with new sequential data from other domains without the need for retraining. A forgetting mechanism is considered to mitigate the effects of outdated data on the localization performance. To validate our new framework, a comprehensive set of experiments have been performed in various environments for different scenarios. The experimental results verify the robustness and responsive tracking ability of the proposed online data-driven modelling DFL framework.},
  archive      = {J_TMC},
  author       = {Jie Zhang and Jianqiang Xue and Yanjiao Li and Simon L. Cotton},
  doi          = {10.1109/TMC.2025.3552538},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Leveraging online learning for domain-adaptation in wi-fi-based device-free localization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reads: A personalized federated learning framework with
fine-grained layer aggregation and decentralized clustering.
<em>TMC</em>, 1–17. (<a
href="https://doi.org/10.1109/TMC.2025.3552982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The heterogeneity of local data and client performance, along with real-world system risks, is driving the evolution of federated learning (FL) towards personalized, model-heterogeneous, and decentralized approaches. However, due to the differing structures of heterogeneous models, it is hard to use them to identify clients with similar data distributions and further enhance the personalization of local models. Therefore, how to deal with data heterogeneity to obtain superior personalized local models for clients, while simultaneously addressing model heterogeneity and system risks is a challenging problem. In this paper, we propose a novel personalized FL framework with fine-gRained layEr aggregAtion and Decentralized cluStering (Reads), which integrates four key components: (1) deep mutual learning with privacy guarantee for model training and privacy preservation, (2) fine-grained layer similarity computation among heterogeneous model layers, (3) fully decentralized clustering for soft clustering of clients based on layer similarities, and (4) personalized layer aggregation for capturing common knowledge from other clients. Through Reads, clients obtain personalized models that accommodate model heterogeneity, while the system ensures robustness against a single point of failure. Extensive experiments demonstrate the efficacy of Reads in achieving these goals.},
  archive      = {J_TMC},
  author       = {Haoyu Fu and Fengsen Tian and Guoqiang Deng and Lingyu Liang and Xinglin Zhang},
  doi          = {10.1109/TMC.2025.3552982},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Reads: A personalized federated learning framework with fine-grained layer aggregation and decentralized clustering},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cost-efficient FEC scheme for time-sensitive multi-hop
transmissions in overlay networks. <em>TMC</em>, 1–14. (<a
href="https://doi.org/10.1109/TMC.2025.3553380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In pursuit of low latency, real-time communication (RTC) service providers usually use multi-hop overlay links worldwide to bypass congested links, especially for medium- and long-distance transmissions. In such multi-hop long-distance transmission scenarios, utilizing retransmission to recover lost packets can result in increased end-to-end latency. Therefore, Forward Error Correction (FEC) is viewed as a promising way to solve the loss problem. However, for multi-hop overlay transmission, existing FEC schemes either introduce a non-negligible processing delay at each hop or reduce the processing delay at the cost of a high coefficient overhead. In this work, we propose a multi-hop FEC scheme, i.e., FEC-OEM, which considers both processing delay and coefficient overhead. FEC-OEM is designed based on two observations we obtained from measurements. First, coefficient overhead can only be reduced through an implicit transmission way. Therefore, we design a modulation-based recoding module that enables implicit coefficient transmission and hop-by-hop recoding at the same time. Second, using on-the-fly computation is a promising way to reduce processing delay. Accordingly, we design an elimination method to make the modulation-based recoding can be carried out on-the-fly. Real-world experiments demonstrate that FEC-OEM can reduce the processing delay by up to 88% without increasing the coefficient overhead compared to state-of-the-art schemes. We also use FEC-OEM to transmit packets for applications with different loss tolerances, and the results show that FEC-OEM can improve the QoE more effectively than state-of-the-art coding schemes.},
  archive      = {J_TMC},
  author       = {Chao Xu and Jessie Hui Wang and Rui Li and Hao Wu and Jilong Wang and Jun Zhang and Kai Zheng},
  doi          = {10.1109/TMC.2025.3553380},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Cost-efficient FEC scheme for time-sensitive multi-hop transmissions in overlay networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Symmetry-informed MARL: A decentralized and cooperative UAV
swarm control approach for communication coverage. <em>TMC</em>, 1–18.
(<a href="https://doi.org/10.1109/TMC.2025.3553285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicle-mounted base stations (UAV-MBSs) provide flexible wireless connectivity, extending communication coverage in underserved areas. Recently, multi-agent reinforcement learning (MARL) has shown great potential for cooperative UAV swarm control to support efficient communication coverage in dynamic and complex environments. However, existing MARL-based methods often suffer from low sample efficiency due to its trial-and-error training characteristics, limiting its ability to control large UAV swarms with continuous state-action space and partial observation. We notice that UAV swarm systems in communication coverage tasks exhibit a spatial symmetry property, e.g., a rotation in the spatial observation of a UAV results in a same rotation in its optimal action. Exploiting this property, we formulate the task as a symmetric decentralized partially observable Markov decision process and introduce symmetry-informed MARL, featuring a novel network called the symmetry-informed graph neural network (SiGNN) to serve as the policy/value networks. SiGNN leverages the inherent symmetry in multi-UAV systems by embedding the symmetry into the network structure, thereby enhancing the training efficiency to handle large swarms with continuous control. Theoretical analysis shows that the SiGNN strictly preserves symmetry properties, which guarantees the effectiveness of the approach. Experiments in simulation were conducted to handle communication coverage using up to 20 UAVs with continuous control. Experimental results demonstrate that SiGNN-based MARL outperforms advanced baselines, verifying its superior sample efficiency, scalability and robustness.},
  archive      = {J_TMC},
  author       = {Rongye Shi and Xin Yu and Yandong Wang and Yongkai Tian and Zhenyu Liu and Wenjun Wu and Xiao-Ping Zhang and Manuela M. Veloso},
  doi          = {10.1109/TMC.2025.3553285},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Symmetry-informed MARL: A decentralized and cooperative UAV swarm control approach for communication coverage},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A federated learning-based data augmentation method for
privacy preservation under heterogeneous data. <em>TMC</em>, 1–14. (<a
href="https://doi.org/10.1109/TMC.2025.3553501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is an important distributed machine learning paradigm. This study proposes a privacy-preserving data augmentation model for federated learning of heterogeneous data, which is able to mitigate heterogeneity and augmenting the participant&#39;s local data while protecting data privacy. First, to address the problem of global model bias due to heterogeneous data, this study proposes a distributed generative adversarial network FedEqGAN. The model introduces a multi-source data feature fusion mechanism, which can learn the features of each data source to generate synthetic data. Second, addressing the privacy leakage issue caused by the disclosure of data distribution information, this paper proposes an encryption algorithm for heterogeneous environments FedHE, which utilizes homomorphic encryption to protect local data distributions and aggregates local data information through KL dispersion in order to construct global data distributions. Finally, for the privacy leakage problem caused by uploading model parameters in federation training, this paper proposes a federation model parameter encryption algorithm DPFedMP. This algorithm dynamically injects Gaussian noise into the model parameters according to the difference of data distribution to realize differential privacy protection and update the global model. Experiments show that the method is applicable to heterogeneous data environment, significantly enhancing model performance while ensuring data security.},
  archive      = {J_TMC},
  author       = {Yunpeng Xiao and Dengke Zhao and Xufeng Li and Tun Li and Rong Wang and Guoyin Wang},
  doi          = {10.1109/TMC.2025.3553501},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A federated learning-based data augmentation method for privacy preservation under heterogeneous data},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ACL: Adaptive edge-cloud collaborative learning for
heterogeneous devices with unlabeled local data. <em>TMC</em>, 1–15. (<a
href="https://doi.org/10.1109/TMC.2025.3553971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge-cloud collaborative learning emerges as a promising paradigm for adapting pre-trained deep neural network (DNN) models to the ever-changing edge data environments and specific downstream tasks. However, the heterogeneity of edge devices and unlabeled local data hinder the effectiveness of existing collaborative learning approaches. To address the above issues, we propose ACL, a novel adaptive edge-cloud collaborative learning paradigm for heterogeneous devices with unlabeled local data. In ACL, we first use FedNAS, a neural architecture search algorithm designed for collaborative learning to generate a customized model on each participating device, and then a lightweight semi-supervised collaborative learning framework HSSCL is used to fine-tune the pre-trained DNN model. Compared with the SOTA collaborative learning approaches, ACL achieves significant accuracy improvement, averaging 31.5% for image classification and 15.5% for object detection. Furthermore, it reduces time overhead by 3.1-5.1× and memory overhead by 6.3-12.5×. We will release our models and tools.},
  archive      = {J_TMC},
  author       = {Zhengyuan Zhang and Dong Zhao and Renhao Liu and Yuxing Yao and Xiangyu Li and Huadong Ma},
  doi          = {10.1109/TMC.2025.3553971},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {ACL: Adaptive edge-cloud collaborative learning for heterogeneous devices with unlabeled local data},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AIChronoLens: AI/ML explainability for time series
forecasting in mobile networks. <em>TMC</em>, 1–15. (<a
href="https://doi.org/10.1109/TMC.2025.3554035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting is increasingly considered a fundamental enabler for the management of next-generation mobile networks. While deep neural networks excel at short- and long-term forecasting, their complexity hinders interpretability, a crucial factor for production deployment. The existing EXplainable Artificial Intelligence (XAI) techniques, primarily designed for computer vision and natural language processing, struggle with time series data due to their lack of understanding of temporal characteristics of the input data. In this paper, we take the research on XAI for time series forecasting one step further by proposing AIChronoLens, a new tool that links legacy XAI explanations with the temporal properties of the input. AIChronoLens allows diving deep into the behavior of time series predictors and spotting, among other aspects, the hidden causes of forecast errors. We show that AIChronoLens&#39;s output can be utilized for meta-learning to predict when the original time series forecasting model makes errors and fix them in advance, thereby improving the accuracy of the predictors. Extensive evaluations with real-world mobile traffic traces pinpoint model behaviors that would not be possible to identify otherwise and show how model performance can be improved by 32 % upon re-training and by up to 39 % with meta-learning.},
  archive      = {J_TMC},
  author       = {Pablo Fernández Pérez and Claudio Fiandrino and Eloy Pérez Gómez and Hossein Mohammadalizadeh and Marco Fiore and Joerg Widmer},
  doi          = {10.1109/TMC.2025.3554035},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {AIChronoLens: AI/ML explainability for time series forecasting in mobile networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RaliSense: Extending WiFi respiratory detection range by
rapid alignment of dynamic components. <em>TMC</em>, 1–17. (<a
href="https://doi.org/10.1109/TMC.2025.3553924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {WiFi based respiratory detection has attracted increasing attentions due to its ubiquity and convenience. In Non-Line-of-Sight (NLoS) scenarios, WiFi signals reflected from human target are blocked by obstacles and become much weaker, thus limiting the sensing range and hindering the practical deployment. The existing best respiratory detection system extended the sensing range by scaling and aligning dynamic components in WiFi signals. However, its dynamic component scaling causes the amplification of noise, while its dynamic component alignment increases computation complexity due to the traversal on all possible rotation angles. To address the above issues, in this paper we first build WiFi sensing range models for respiratory detection in NLoS scenario, find factors that limit the sensing range, and then propose a new respiratory detection system named RaliSense which can further rapidly extend the sensing range in NLoS scenario. The main idea of RaliSense is rapidly aligning dynamic components without amplifying noise, based on change direction vector and CSI ratio sum polarity of dynamic components. The proposed change direction vector is obtained by calculating the direction on which the noisy dynamic components have the maximum variance, and CSI ratio sum polarity is then obtained by summing the dynamic components which have been rotated by the change direction vector. According to the CSI ratio sum polarity, the rotation angle is quickly adjusted for aligning dynamic components. Extensive simulation and experiment results verify the effectiveness of our proposed sensing range models. The results also demonstrate that our proposed system RaliSense can effectively extend sensing range in NLoS scenario, achieving a 22.7% improvement over the best existing work but spending only a quarter of its computation time.},
  archive      = {J_TMC},
  author       = {Linqing Gui and Siyi Zheng and Zhengxin Guo and Zhetao Li and Ming Gao and Schahram Dustdar and Fu Xiao},
  doi          = {10.1109/TMC.2025.3553924},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {RaliSense: Extending WiFi respiratory detection range by rapid alignment of dynamic components},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Budget-feasible diffusion mechanisms for mobile
crowdsourcing in social networks. <em>TMC</em>, 1–17. (<a
href="https://doi.org/10.1109/TMC.2025.3549751">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowdsourcing has emerged as a popular approach for organizations to leverage the collective intelligence of a crowd of users to obtain services. Considering users&#39; costs for providing services, it is vital for the requester to design incentive mechanisms to encourage users&#39; participation in crowdsourcing under the budget constraint. This aligns with the concept of budget-feasible mechanism design. Existing budget-feasible mechanisms often assume immediate user reachability and willingness of joining the crowdsourcing, which is unrealistic. To address this issue, a promising approach is to have participating users diffuse auction information to potential users in the social network. However, this brings another challenge in that participating users can be strategic and therefore hesitant to invite more potential competitors to join the crowdsourcing platform. In this paper, we focus on developing diffusion mechanisms that incentivize strategic users to actively diffuse auction information through the social network. This helps to attract more informed users and ultimately increases the value of the procured services. Specifically, we propose optimal budget-feasible diffusion mechanisms that simultaneously guarantee individual rationality, budget-feasibility, strong budget-balance, incentive-compatibility (i.e., users report real costs and diffuse auction information to all their neighbors) and approximation. Experiment results under real datasets further demonstrate the efficiency of proposed mechanisms.},
  archive      = {J_TMC},
  author       = {Xiang Liu and Weiwei Wu and Minming Li and Wanyuan Wang and Yifan Qin and Yingchao Zhao and Junzhou Luo},
  doi          = {10.1109/TMC.2025.3549751},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Budget-feasible diffusion mechanisms for mobile crowdsourcing in social networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight encoder-decoder framework for carpooling route
planning. <em>TMC</em>, 1–14. (<a
href="https://doi.org/10.1109/TMC.2025.3549757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carpooling Route Planning (CRP) has become an important issue with the growth of low-carbon traffic systems. We investigate a novel, meaningful and challenging scenario for CRP in industry, called Multi-Candidate Carpooling Route Planning (MCRP) problem, where each passenger may have several potential positions to get on and off the car. We surprisingly notice that this problem can be easily generalized for similar services such as express, takeout, or crowdsensing services, which means MCRP is a new fundamental combinatorial optimization problem. Traditional graph search algorithms or indexing methods are usually time and space consuming or perform poorly, which are not suitable for solving the problem. In this paper, we propose an end-to-end encoder-decoder model to plan a route for each many-to-one carpooling order with various data-driven mechanisms such as graph partitioning and feature crossover. The encoder is a filter-integrated Graph Convolution Network with external information fusion combining a supervised pre-training classification task, while the latter mimics a pointer network with a rule-based mask mechanism and a domain feature crossover module. We validate the effectiveness and efficiency of our model based on both synthetic and real-world datasets. Our code is available at https://github.com/GaoYucen/Lite-GD.},
  archive      = {J_TMC},
  author       = {Yucen Gao and Li Ma and Zhemeng Yu and Songjian Zhang and Hui Gao and Jun Fang and Xiaofeng Gao},
  doi          = {10.1109/TMC.2025.3549757},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A lightweight encoder-decoder framework for carpooling route planning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cloud-edge-end collaborative computing-enabled intelligent
sharding blockchain for industrial IoT based on PPO approach.
<em>TMC</em>, 1–14. (<a
href="https://doi.org/10.1109/TMC.2025.3554568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The security and reliability risks of industrial data have constrained the advancement of the Industrial Internet of Things (IIoT). Although blockchain can protect the security and reliability of industrial data through hash verification mechanisms, there are numerous challenges in the existing blockchain-enabled IIoT systems, such as the trilemma involving scalability, decentralization and security, high computational power consumption of consensus protocols and limited computational resources of industrial devices. To address these problems, an intelligent sharding blockchain-enabled IIoT framework is proposed, in which the intelligent sharding based on the reputation mechanism and the adaptive switching for multi-consensus protocols are utilized to enhance the decentralization, security and scalability of blockchain. Considering higher requirement of computational power of the sharding blockchain, a cloud-edge-end collaborative computing framework is introduced, in which the parallel computational offloading and the Terahertz communication technology are utilized to enhance the cooperation of the cloud-edge-end networks. Furthermore, due to the highly dynamic nature of industrial devices and industrial data, we consider and design the optimization problem as a Markov decision process (MDP), which is solved via the Proximal Policy Optimization (PPO) algorithm. Simulation results show that our proposed scheme can minimize total delay and maximize transaction throughput while guaranteeing the safety as well as decentralization of blockchain-enabled IIoT systems.},
  archive      = {J_TMC},
  author       = {Xin Xiong and Meng Li and F. Richard Yu and Haijun Zhang and Kan Wang and Pengbo Si},
  doi          = {10.1109/TMC.2025.3554568},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Cloud-edge-end collaborative computing-enabled intelligent sharding blockchain for industrial IoT based on PPO approach},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Edge AI inference as a service via dynamic resources from
repeated auctions. <em>TMC</em>, 1–17. (<a
href="https://doi.org/10.1109/TMC.2025.3554816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enable edge AI providers to recruit edge devices and use them to deploy AI models and provision inference services, we conduct a comprehensive mathematical and algorithmic study on a novel incentive and optimization mechanism based on repeated auctions. We first model and formulate a time-cumulative social cost optimization problem to capture the challenges of the trade-off between cost and accuracy, the dependency between adjacent auctions, and the need of achieving desired economic properties. Then, to solve this intractable non-linear integer program in an online manner, we design a set of polynomial-time algorithms that work together. Our approach dynamically chooses and switches winning bids under careful control, incorporates online learning to overcome posterior inference accuracy and workload queue dynamics, and leverages randomization to strategically convert fractional decisions of model placement and query dispatch into integers. We also allocate payments to meet the necessary and sufficient conditions for the desired economic properties. Further, we rigorously prove the constant competitive ratio, the sub-linear regret and fit, and the truthfulness and individual rationality for our proposed approach. Finally, through extensive experiments using real devices, AI models, and data traces, we have validated the substantial advantages of our proposed approach compared to the baselines and the state-of-the-art methods.},
  archive      = {J_TMC},
  author       = {Mingtao Ji and Hehan Zhao and Lei Jiao and Sheng Zhang and Xin Li and Zhuzhong Qian and Baoliu Ye},
  doi          = {10.1109/TMC.2025.3554816},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Edge AI inference as a service via dynamic resources from repeated auctions},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic AP clustering and power allocation for
CF-MMIMO-enabled federated learning using multi-agent DRL. <em>TMC</em>,
1–16. (<a href="https://doi.org/10.1109/TMC.2025.3554081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is recognized as a pivotal paradigm for 6 G, offering decentralized model training without compromising data privacy. Recent works have proposed deploying FL in cell-free massive MIMO (CF-mMIMO) networks for reliable model transmission between FL clients and the server. Nevertheless, the problem of simultaneous access point (AP) clustering (i.e., dynamically forming AP groups to facilitate client-server communication) and transmit power allocation has not been thoroughly investigated. Furthermore, most existing solutions do not simultaneously consider the fast decision-making requirements brought by user mobility and the scalability of solutions in large-scale networks. To address this gap, we propose DACPA, a multi-agent deep reinforcement learning (DRL)-based scheme that accounts for client mobility (walking speed) and heterogeneous computing capabilities. DACPA strategically assigns each client a customized AP cluster and corresponding transmit power configuration, thereby optimizing model update latency. Extensive simulation results demonstrate the superior performance of DACPA in terms of convergence stability, spectral efficiency, global model update latency, and average energy consumption.},
  archive      = {J_TMC},
  author       = {Ziqi Li and Jia Hu and Xi Li and Heli Zhang and Geyong Min},
  doi          = {10.1109/TMC.2025.3554081},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Dynamic AP clustering and power allocation for CF-MMIMO-enabled federated learning using multi-agent DRL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SmartSpr: A physics-informed mobile sprinkler scheduling
system for reducing urban particulate matter pollution. <em>TMC</em>,
1–16. (<a href="https://doi.org/10.1109/TMC.2025.3555448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban particulate pollution presents considerable public health hazards, underscoring the need for effective control measures in various cities. This paper proposes SmartSpr, a physics-informed urban mobile sprinkler scheduling system designed for enhanced efficiency in reducing particulate pollution. SmartSpr incorporates a Physics-Informed Neural Network (PINN)-based model, enriched with Bayesian optimization, to accurately simulate the impact of mobile sprinklers on particulate matter (PM) dispersion. Building on this sprinkling effect model, a selective sprinkling strategy considering the replenish process is proposed. This strategy employs a sparsity-driven decoupling simulated annealing algorithm to refine sprinkler routes, prioritizing areas with substantial environmental benefits. Extensive field experiments and simulations have validated SmartSpr, demonstrating a 64.8% reduction in prediction error of SmartSpr&#39;s sprinkling model compared to the leading baseline and an 18% enhancement in pollutant reduction efficiency of the proposed scheduling algorithm. Our codes have be publicly available at https://github.com/CheeseLuoo/Sprayer.},
  archive      = {J_TMC},
  author       = {Ji Luo and Zijian Xiao and Zuxin Li and Xuecheng Chen and Chaopeng Hong and Xiao-Ping Zhang and Xinlei Chen},
  doi          = {10.1109/TMC.2025.3555448},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {SmartSpr: A physics-informed mobile sprinkler scheduling system for reducing urban particulate matter pollution},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Security enhanced computation offloading for collaborative
inference at semantic-communication-empowered edge. <em>TMC</em>, 1–18.
(<a href="https://doi.org/10.1109/TMC.2025.3555298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic communication (SC) has emerged as a promising paradigm for upcoming intelligent applications, enabling mobile devices to collaboratively execute intelligent tasks with edge servers through computation offloading. However, few studies have addressed the problem of collaborative inference in SC networks. Traditional collaborative inference mechanisms may suffer performance decline in SC systems and are vulnerable to eavesdroppers. To address these issues, firstly, we present an encryptor that encrypts semantic information to avoid privacy leakage and a decryptor for restoration. Besides, we propose a novel SC-empowered edge computing framework enabling mobile devices to deploy a partial semantic encoder and offload the rest to edge servers. Based on this framework, we formulate the collaborative inference optimization problem, jointly optimizing delay, energy consumption, and privacy leakage. DNNPart is devised based on deep deterministic policy gradient to address the problem, which consists of a semantic attention mechanism that enables it to focus on important state variables, a hybrid action representation method that makes it adapt to mixed discrete and continuous action spaces, a dynamic model splitting algorithm that locates the optimal partition layer and adaptively splits the semantic coders. Integrated with these components, DNNPart iteratively optimizes the offloading strategy to find the optimal offloading strategy. Extensive simulations were conducted to verify the effectiveness of the proposed method by comparing it with baseline mechanisms.},
  archive      = {J_TMC},
  author       = {Jincheng Peng and Huanlai Xing and Xiangyi Chen and Yang Li and Yunhe Cui and Danyang Zheng and Laha Ale and Li Feng},
  doi          = {10.1109/TMC.2025.3555298},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Security enhanced computation offloading for collaborative inference at semantic-communication-empowered edge},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CrowdHMTware: A cross-level co-adaptation middleware for
context-aware mobile DL deployment. <em>TMC</em>, 1–17. (<a
href="https://doi.org/10.1109/TMC.2025.3549399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are many deep learning (DL) powered mobile and wearable applications today continuously and unobtrusively sensing the ambient surroundings to enhance all aspects of human lives. To enable robust and private mobile sensing, DL models are often deployed locally on resource-constrained mobile devices using techniques such as model compression or offloading. However, existing methods, either front-end algorithm level (i.e. DL model compression/partitioning) or back-end scheduling level (i.e. operator/resource scheduling), cannot be locally online because they require offline retraining to ensure accuracy or rely on manually pre-defined strategies, struggle with dynamic adaptability. The primary challenge lies in feeding back runtime performance from the back-end level to the front-end level optimization decision. Moreover, the adaptive mobile DL model porting middleware with cross-level co-adaptation is less explored, particularly in mobile environments with diversity and dynamics. In response, we introduce CrowdHMTware, a dynamic context-adaptive DL model deployment middleware for heterogeneous mobile devices. It establishes an automated adaptation loop between cross-level functional components, i.e. elastic inference, scalable offloading, and model-adaptive engine, enhancing scalability and adaptability. Experiments with four typical tasks across 15 platforms and a real-world case study demonstrate that ${\sf CrowdHMTware}$ can effectively scale DL model, offloading, and engine actions across diverse platforms and tasks. It hides run-time system issues from developers, reducing the required developer expertise.},
  archive      = {J_TMC},
  author       = {Sicong Liu and Bin Guo and Shiyan Luo and Yuzhan Wang and Hao Luo and Cheng Fang and Yuan Xu and Ke Ma and Yao Li and Zhiwen Yu},
  doi          = {10.1109/TMC.2025.3549399},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {CrowdHMTware: A cross-level co-adaptation middleware for context-aware mobile DL deployment},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A digital twin-based intelligent network architecture for
underwater acoustic sensor networks. <em>TMC</em>, 1–18. (<a
href="https://doi.org/10.1109/TMC.2025.3555640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater acoustic sensor networks (UASNs) drive toward strong environmental adaptability, intelligence, and multifunctionality. However, due to unique UASN characteristics, such as long propagation delay, dynamic channel quality, and high attenuation, existing studies present untimeliness, inefficiency, and inflexibility in real practice. Digital twin (DT) technology is promising for UASNs to break the above bottlenecks by providing high-fidelity status prediction and exploring optimal schemes. In this article, we propose a Digital Twin-based Network Architecture (DTNA), enhancing UASNs&#39; environmental adaptability, intelligence, and multifunctionality. By extracting real UASN information from local (node) and global (network) levels, we first design a layered architecture to improve the DT replica fidelity and UASN control flexibility. In local DT, we develop a resource allocation paradigm (RAPD), which rapidly perceives performance variations and iteratively optimizes allocation schemes to improve real-time environmental adaptability of resource allocation algorithms. In global DT, we aggregate decentralized local DT data and propose a collaborative Multi-agent reinforcement learning framework (CMFD) and a task-oriented network slicing (TNSD). CMFD patches scarce real data and provides extensive DT data to accelerate AI model training. TNSD unifies heterogeneous tasks&#39; demand extraction and efficiently provides comprehensive network status, improving the flexibility of multi-task scheduling algorithms. Finally, practical and simulation experiments verify the high fidelity of DT. Compared with the original UASN architecture, experiment results demonstrate that DTNA can: (i) improve the timeliness and robustness of resource allocation; (ii) greatly reduce the training time of AI algorithms; (iii) more rapidly obtain network status for multi-task scheduling at a low cost.},
  archive      = {J_TMC},
  author       = {Shanshan Song and Bingwen Huangfu and Jiani Guo and Jun Liu and Junhong Cui and Xuemin Shen},
  doi          = {10.1109/TMC.2025.3555640},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A digital twin-based intelligent network architecture for underwater acoustic sensor networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UAV-assisted IRS system in 5 g and beyond: Improving
reliability and enhancing the network life span. <em>TMC</em>, 1–13. (<a
href="https://doi.org/10.1109/TMC.2025.3556043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an unmanned aerial vehicle (UAV)-assisted intelligent reflecting surface (IRS) for device-to-device (D2D) communication in infrastructure-less scenarios. The aim of this paper is to enhance the reliability among D2D ground users (GUs) and extend the lifespan of 5 G and beyond 5 G (B5G) wireless communication system. This work may be applicable for packet delivery in bustling urban areas, especially where ground-to-ground (G2G) links are in deep fade. For modeling air-to-ground (A2G) links among GUs to IRS/UAV and IRS/UAV to GUs, we consider a height-dependent Nakagami-$m$ channel model for small-scale fading and height-dependent path-loss exponent for modeling large-scale fading. The lifespan of the network is improved by proposing height-dependent energy harvesting (EH) at UAV. We derive the cumulative distribution function (CDF) of the signal-to-noise ratio (SNR) whenever the signal reaches the receiving node, either via UAV or via IRS. We also develop the expression of spectral efficiency and derive a closed-form expression of an outage probability by taking the combined effect of the signal for the proposed scenario using decode-and-forward (DF) and amplify-and-forward (AF) relaying at the UAV. Additionally, the statistical parameters such as mean, variance, and probability density function (PDF) of total noise are derived, which is useful at the receiver node for estimating the bit error rate (BER). The analytical result is validated with simulation results, and the work is compared with the existing state-of-the-art.},
  archive      = {J_TMC},
  author       = {Pankaj Kumar and Nikita Goel and Manoj Tolani},
  doi          = {10.1109/TMC.2025.3556043},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {UAV-assisted IRS system in 5 g and beyond: Improving reliability and enhancing the network life span},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PGVMatch: Privacy-preserving and fine-grained crowdsourcing
task matching with lightweight on-chain public verifiability.
<em>TMC</em>, 1–14. (<a
href="https://doi.org/10.1109/TMC.2025.3556249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Secure task matching has been a crucial research problem in crowdsourcing, requiring the alignment of workers&#39; preferences and requesters&#39; task requirements while ensuring user privacy and matching integrity. Recently, some researchers applied blockchain to crowdsourcing, either replacing the platform for decentralization or recording proofs for public verification to defend against malicious platforms. However, they still suffer from unitary coarse-grained matching models or expensive on-chain costs. To address these limitations, we propose PGVMatch, a privacy-aware and fine-grained crowdsourcing task-matching scheme with lightweight on-chain public verifiability. Our scheme is constructed on our newly proposed cryptographic primitive–Multi-authority Attribute-Based Keyword Search with Public Verifiability (MABKS-PV), which avoids access policy leakage and key escrow risks on a single authority, meanwhile adding constant-size proof generation and lightweight verification algorithms to a basic ABKS construction. In PGVMatch, requesters can select workers with fine-grained attribute demands, and workers can pick interested tasks with multi-keyword search, preserving dual-side privacy. The matching process is conducted off-chain, while constant-size proofs are recorded on-chain for efficient and public verification of matching integrity. Security analysis and extensive experiments on the Hyperledger Fabric blockchain demonstrate both the security and our superior performance. PGVMatch outperforms the existing scheme with the fastest matching result verification, achieving a 29% improvement in throughput and a 33% reduction in latency.},
  archive      = {J_TMC},
  author       = {Liang Li and Haiqin Wu and Jiachen Shen and Zhenfu Cao and Xiaolei Dong},
  doi          = {10.1109/TMC.2025.3556249},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {PGVMatch: Privacy-preserving and fine-grained crowdsourcing task matching with lightweight on-chain public verifiability},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). COLoRIS: Localization-agnostic smart surfaces enabling
opportunistic ISAC in 6G networks. <em>TMC</em>, 1–14. (<a
href="https://doi.org/10.1109/TMC.2025.3556326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of Smart Surfaces in 6G communication networks, also dubbed as Reconfigurable Intelligent Surfaces (RISs), is a promising paradigm change gaining significant attention given its disruptive features. RISs are a key enabler in the realm of 6G Integrated Sensing and Communication (ISAC) systems where novel services can be offered together with the future mobile networks communication capabilities. This paper addresses the critical challenge of precisely localizing users within a communication network by leveraging the controlled-reflective properties of RIS elements without relying on more power-hungry traditional methods, e.g., GPS, adverting the need of deploying additional infrastructure and even avoiding interfering with communication efforts. Moreover, we go one step beyond: we build COLoRIS, an Opportunistic ISAC approach that leverages localization-agnostic RIS configurations to accurately position mobile users via trained learning models. Extensive experimental validation and simulations in large-scale synthetic scenarios show $\mathbf{5\%}$ positioning errors (with respect to field size) under different conditions. Further, we show that a low-complexity version running in a limited off-the-shelf (embedded, low-power) system achieves positioning errors in the $\mathbf{11\%}$ range at a negligible $\mathbf{+2.7\%}$ energy expense with respect to the classical RIS.},
  archive      = {J_TMC},
  author       = {Guillermo Encinas-Lago and Francesco Devoti and Marco Rossanese and Vincenzo Sciancalepore and Marco Di Renzo and Xavier Costa-Pérez},
  doi          = {10.1109/TMC.2025.3556326},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {COLoRIS: Localization-agnostic smart surfaces enabling opportunistic ISAC in 6G networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Computation offloading and resource allocation in mixed
cloud/vehicular-fog computing systems. <em>TMC</em>, 1–13. (<a
href="https://doi.org/10.1109/TMC.2025.3556315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the proliferation of vehicular user equipment (V-UE) in the Internet-of-Vehicles (IoV) systems, cloud computing alone cannot process all V-UE tasks, especially those latency-sensitive ones. Although static roadside fog nodes have been employed to offload computation from V-UEs, mobile fog nodes carried by vehicles that have the potential to further improve the performance of computation offloading for vehicular tasks have not been sufficiently studied for IoV systems. In this paper, we consider a mixed cloud/vehicular-fog computing (VFC) system that employs vehicle-carried fog nodes (V-FNs) in addition to cloud servers to offload tasks from V-UEs. To minimise the maximum service delay (which includes the transmission delay, queueing delay, and processing delay) among all V-UEs, we jointly optimise the offloading decisions of all V-UEs, the computation resource allocation at all V-FNs, the allocation of resource block (RB) and transmission power for all V-UEs while considering the mobility of V-UEs and V-FNs. The joint optimisation is solved by devising a fireworks algorithm-based offloading decision optimisation scheme, in conjunction with a bisection method-based V-FN computation resource allocation scheme and a clustering-based communication resource allocation scheme. Simulation results show that our proposed schemes outperform the benchmarks in terms of service the maximum delay among all V-UEs.},
  archive      = {J_TMC},
  author       = {Bintao Hu and Jianbo Du and Jie Zhang and Xiaoli Chu},
  doi          = {10.1109/TMC.2025.3556315},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Computation offloading and resource allocation in mixed Cloud/Vehicular-fog computing systems},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
