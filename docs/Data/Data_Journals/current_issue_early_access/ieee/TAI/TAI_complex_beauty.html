<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TAI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tai---24">TAI - 24</h2>
<ul>
<li><details>
<summary>
(2025). Large-scale heliostat field optimization for solar power
tower system using matrix-based differential evolution. <em>TAI</em>,
1–14. (<a href="https://doi.org/10.1109/TAI.2025.3545813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent optimization of a solar power tower heliostat field (SPTHF) is critical for harnessing solar energy in various scenarios. However, existing SPTHF optimization methods are typically based on specific geometric layout constraints and assume that each heliostat has the same size and height. As a result, these methods are not flexible or practical in many real-world SPTHF application scenarios. Therefore, this paper proposes a novel flexible SPTHF (FSPTHF) model that is more practical and involves fewer assumptions. This model enables the use of different layouts and simultaneous optimization of the parameters of each heliostat. As an FSPTHF can involve hundreds or even thousands of heliostats, optimizing the parameters of all heliostats results in a challenging large-scale optimization problem. To efficiently solve this problem, this paper proposes a matrix-based differential evolution algorithm, called HMDE, for large-scale heliostat design. The HMDE uses a matrix-based encoding and representation method to improve optimization accuracy and convergence speed, incorporating two novel designs. First, a dual elite-based mutation method is proposed to enhance the convergence speed of HMDE by learning from multiple elite individuals. Second, a multi-level crossover method is proposed to improve the optimization accuracy and convergence speed by integrating element-level and vector-level crossover based on matrix representation. Extensive experiments were conducted on 30 problem instances based on real-world data with three different layouts and problem dimensions up to 12,000, where state-of-the-art algorithms were used for comparison. The experimental results show that the proposed HMDE can effectively solve large-scale FSPTHF optimization problems.},
  archive      = {J_TAI},
  author       = {Dan-Ting Duan and Jian-Yu Li and Bing Sun and Xiao-Fang Liu and Qiang Yang and Qi-Jia Jiang and Zhi-Hui Zhan and Sam Kwong and Jun Zhang},
  doi          = {10.1109/TAI.2025.3545813},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Large-scale heliostat field optimization for solar power tower system using matrix-based differential evolution},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep graph convolutional autoencoder with conditional
normalizing flow for power distribution systems fault classification and
location. <em>TAI</em>, 1–15. (<a
href="https://doi.org/10.1109/TAI.2025.3547878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate fault classification and location are critical to ensure the reliability and resilience of large-scale power distribution systems (PDSs). The existing data-driven works in this area struggle to capture essential space-time correlations of PDS measurements and often rely on deterministic and shallow neural architectures. Furthermore, they encounter challenges like over-smoothing and the inability to capture deep correlations. To overcome these limitations, a novel deep space-time generative graph convolutional autoencoder (SGGCA) is proposed. First, the PDS is modeled as a space-time graph where the nodes and edges show the bus measurements and line impedance values, respectively. The proposed SGGCA’s encoder captures deep correlations of the space-time graph using a new graph convolution with early connections and identity transformations to mitigate the over-smoothing. Our encoder encompasses a new recurrent method to adjust graph convolution parameters without relying on node embeddings on the temporal dimension. Additionally, it incorporates generative modeling by capturing the probability distribution function of the latent representation through a conditional normalizing flow model. The extracted generative space-time features are enhanced by a multi-head attention mechanism to better capture task-relevant characteristics of the PDS measurements. The extracted features are fed to sparse decoders to classify and locate the faults in the PDS. The feature sparsity of decoders ensures a high generalization capacity and avoids overfitting. The proposed method is evaluated on the IEEE 69-bus and 123-bus systems. It achieves substantial improvements in fault classification accuracy by 3.33% and 6.26% and enhances fault location accuracy by 6.33% and 5.73% for the respective PDSs compared to state-of-the-art models.},
  archive      = {J_TAI},
  author       = {Mohsen Saffari and Mahdi Khodayar and Mohammad E. Khodayar and Seyed Saeed Fazlhashemi},
  doi          = {10.1109/TAI.2025.3547878},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Deep graph convolutional autoencoder with conditional normalizing flow for power distribution systems fault classification and location},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EMPOWER-KARE: Deep prompt learning for knowledge-aware
response generation in clinical counseling and legal support
conversations. <em>TAI</em>, 1–10. (<a
href="https://doi.org/10.1109/TAI.2025.3548628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the effect of external domain knowledge while generating responses in clinical counseling and legal support conversations for crime victims. To facilitate this task, we propose EMPOWER, a novel dual-tier dEep proMPt learning framework for knOWledge-aware rEsponse geneRation task. EMPOWER first learns the knowledge-attributed deep prompt to generate the relevant knowledge grounded on conversational context and, in the next step, it learns response-attributed deep prompt grounded on conversational context and the learned knowledge-attributed deep prompt to guide the knowledge-aware response generation. To develop EMPOWER, we introduce KARE, a novel dataset consisting of 5,000 Knowledge-grounded clinicAl counseling and legal suppoRt convErsations, specifically focused on crime victims. Experiments demonstrate that our proposed method significantly outperforms the state-of-the-art baseline approaches, achieving improvements of 11.50% in BLEU-4, 28.5% in Knowledge-F1, and 11.6% in BERTScore on the proposed dataset. Further analysis also shows the promising abilities of EMPOWER for knowledge-aware response generation task in clinical counseling and legal support conversations.},
  archive      = {J_TAI},
  author       = {Priyanshu Priya and Armita Mani Tripathi and Deeksha Varshney and Mauajama Firdaus and Asif Ekbal},
  doi          = {10.1109/TAI.2025.3548628},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {EMPOWER-KARE: Deep prompt learning for knowledge-aware response generation in clinical counseling and legal support conversations},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). C2RS: Multimodal knowledge graph completion with cross-modal
consistency and relation semantics. <em>TAI</em>, 1–13. (<a
href="https://doi.org/10.1109/TAI.2025.3548621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal knowledge graph completion (MKGC) is a popular research topic in recent years. However, existing methods rarely consider the alignment of different entity modalities in the process of multimodal fusion, and often lack sufficient attention to the semantic information conveyed by relations, thus resulting in unsatisfactory completion performance. To address these two issues, we propose a new multimodal knowledge graph completion model called C2RS. This model first designs a cross-modal consistency contrastive learning task to align different entity modalities for accurate entity representation. Then, C2RS develops a relation semantic encoding module based on the distributions of knowledge graph triples to extract the semantic information of relations for comprehensive relation representation. Finally, we encode the candidate triples with a triple encoder, and identify the correct entities through a scoring function to complete the multimodal knowledge graph. According to the extensive experiments on three public MKGC datasets, C2RS obviously outperforms the baseline methods. The code of C2RS is available at https://github.com/ADMIS-TONGJI/C2RS.},
  archive      = {J_TAI},
  author       = {Yulou Shu and Wengen Li and Jiaqi Wang and Yichao Zhang and Jihong Guan and Shuigeng Zhou},
  doi          = {10.1109/TAI.2025.3548621},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {C2RS: Multimodal knowledge graph completion with cross-modal consistency and relation semantics},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting postgraduate student engagement using artificial
intelligence (AI). <em>TAI</em>, 1–12. (<a
href="https://doi.org/10.1109/TAI.2025.3548016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing number of international students (IS) enrolled in Australian higher education institutions, combined with the widespread adoption of online and hybrid learning, has significant implications for understanding the factors that influence engagement among this diverse student group. Early identification of students with low engagement facilitates academic success, prevents poor outcomes, optimises resource allocation, improves teaching strategies, increases motivation, and supports long term success. . This study&#39;s main aim is to examine the use of AI to predict student engagement. Development of a theoretically informed survey that aimed to elicit post graduate students&#39; engagement was developed and validated by expert judgement. In total, 200 copies of the survey were distributed, 121 responses were received, and 96 were considered for this study representing a response rate of 48%. This study promotes a multidimensional approach, utilising AI and ML methodologies, to determine the influence of social and cultural contexts on student engagement This approach enables educators and institutions to create effective strategies for enhancing the learning experience of postgraduate students. Multiple AI and ML techniques have been utilised including synthetic data generation methods such GaussianCopula, TVAE, GAN, CopulaGAN, and CTGAN. These techniques are specifically employed to predict various dimensions of engagement, including personal, academic, intellectual, social, and professional engagement. . The performance of AI/ML algorithms, including SVM, KNN, DT, GBM, RF, NB, LR, and ET, was assessed using several metrics including F1 Score, Sensitivity, Specificity, Confusion Matrix, and Accuracy. The models used in this study achieved up to 85% accuracy, offering a solid foundation for guidelines and support to enhance decision making processes in higher education. These findings provide valuable insights for both academics and policy makers, laying the groundwork for evidence-based strategies to improve student engagement.},
  archive      = {J_TAI},
  author       = {Niusha Shafiabady and Tebbin Koo and Fareed Ud Din and Kabir Sattarshetty and Margaret Yen and Mamoun Alazab and Ethar Alsharaydeh},
  doi          = {10.1109/TAI.2025.3548016},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Predicting postgraduate student engagement using artificial intelligence (AI)},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive deep learning based short-term wind speed
forecasting model for variable terrain conditions. <em>TAI</em>, 1–11.
(<a href="https://doi.org/10.1109/TAI.2025.3547685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind flow can be highly unpredictable and suffer substantial fluctuations in speed and direction due to the shape and height of hills, mountains, and valleys, making accurate wind speed (WS) forecasting essential in complex terrain. Hourly WS data at 50 meters above ground, from MERRA-2, NASA (2015–2021), collected from five Indian wind stations for plain and complex terrain. This paper presents a novel and adaptive model for short-term WS forecasting. The paper’s key contributions are as follows: (a) The Partial Auto Correlation Function (PACF) is utilised to minimise the dimension of the set of Intrinsic Mode Functions (IMF), hence reducing training time; (b) The sample entropy (SampEn) was used to calculate the complexity of the reduced set of IMFs. Since a particular Deep Learning (DL) model-feature-combination was selected based on complexity, the proposed method is adaptive; (c) A novel bidirectional feature- LSTM framework for complicated IMFs has been suggested, resulting in improved forecasting accuracy; (d) The proposed model shows 55.94% superior forecasting performance compared to the persistence, hybrid, Ensemble empirical mode decomposition (EEMD), Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN) and Variational Mode Decomposition (VMD)-based DL models. It has achieved the lowest prediction variance between simple and complex terrain at 0.70%, ensuring robust forecasting performance. Dimension reduction of IMF’s and complexity-based model-feature selection helps reduce the training time by 68.77%, additionally forecasting quality is improved by 58.58% on average. These benefits highlight the model’s adaptability, effectiveness, and resilience in addressing WS forecasting challenges on complex terrain.},
  archive      = {J_TAI},
  author       = {Sourav Malakar and Saptarsi Goswami and Bhaswati Ganguli and Amlan Chakrabarti},
  doi          = {10.1109/TAI.2025.3547685},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {An adaptive deep learning based short-term wind speed forecasting model for variable terrain conditions},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MalaNet: A small world inspired neural network for automated
malaria diagnosis. <em>TAI</em>, 1–11. (<a
href="https://doi.org/10.1109/TAI.2025.3549406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a novel neural network architecture called MalaNet is proposed for the detection and diagnosis of malaria, an infectious disease that poses a major global health challenge. The proposed neural network architecture is inspired by small-world network principles, which generally involve the introduction of new links. A small-world neural network is realized by establishing new connections, thereby reducing the average path length and increasing clustering coefficient. These characteristics are known to enhance interconnectivity and improve feature propagation within the network. In the context of malaria diagnosis, these characteristics of MalaNet can enhance detection accuracy and enable better generalization in scenarios with limited data availability. Broadly, two variants of MalaNet are proposed in this work. First, a small-world-inspired Feed-Forward Neural Network (FNN) is developed for symptom and categorical feature-based diagnosis, providing an accessible solution when blood smear images are unavailable. Subsequently, a small-world-inspired Convolutional Neural Network (CNN) is developed for precise and automated diagnosis when blood smear images are available. Both variants of MalaNet are rigorously validated using the National Institute of Health Malaria dataset, a clinical dataset from Federal Polytechnic Ilaro Medical Centre, Nigeria, and the APTOS dataset. Comparative results against several state-of-the-art neural network models in the literature demonstrate MalaNet’s superior performance, generalization capability, and computational efficiency. The small-world neural network architecture proposed in this work enhances feature learning, diagnostic accuracy, and adaptability in limited-data and resource-constrained settings, motivating its application in disease diagnosis where timely and accurate results are critical.},
  archive      = {J_TAI},
  author       = {Shubham Dwivedi and Kartikeya Pandey and Kumar Shubham and Om Jee Pandey and Achyut Mani Tripathi and Tushar Sandhan and Rajesh M Hegde},
  doi          = {10.1109/TAI.2025.3549406},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {MalaNet: A small world inspired neural network for automated malaria diagnosis},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Non-uniform illumination attack for fooling convolutional
neural networks. <em>TAI</em>, 1–10. (<a
href="https://doi.org/10.1109/TAI.2025.3549396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional Neural Networks (CNNs) have made remarkable strides; however, they remain susceptible to vulnerabilities, particularly to image perturbations that humans can easily recognize. This weakness, often termed as ‘attacks,’ underscores the limited robustness of CNNs and the need for research into fortifying their resistance against such manipulations. This study introduces a novel Non-Uniform Illumination (NUI) attack technique, where images are subtly altered using varying NUI masks. Extensive experiments are conducted on widely-accepted datasets including CIFAR10, TinyImageNet, CalTech256 and NWPU-RESISC45 focusing on image classification with 12 different NUI masks. The resilience of VGG, ResNet, MobilenetV3-small, InceptionV3 and efficientNet b0 models against NUI attacks are evaluated. Our results show a substantial decline in the CNN models’ classification accuracy when subjected to NUI attacks, due to changes in the image pixel value distribution, indicating their vulnerability under non-uniform illumination. To mitigate this, a defense strategy is proposed, including NUI-attacked images, generated through the new NUI transformation, into the training set. The results demonstrate a significant enhancement in CNN model performance when confronted with perturbed images affected by NUI attacks. This strategy seeks to bolster CNN models’ resilience against NUI attacks. A comparative study with other attack techniques shows the effectiveness of the NUI attack and defense technique.11The code is available at https://github.com/Akshayjain97/Non-Uniform_Illumination},
  archive      = {J_TAI},
  author       = {Akshay Jain and Shiv Ram Dubey and Satish Kumar Singh and KC Santosh and Bidyut Baran Chaudhuri},
  doi          = {10.1109/TAI.2025.3549396},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Non-uniform illumination attack for fooling convolutional neural networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unimodal distributions for ordinal regression. <em>TAI</em>,
1–12. (<a href="https://doi.org/10.1109/TAI.2025.3549740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many real-world prediction tasks, the class labels contain information about the relative order between the labels that are not captured by commonly used loss functions such as multicategory cross-entropy. In ordinal regression, many works have incorporated ordinality into models and loss functions by promoting unimodality of the probability output. However, current approaches are based on heuristics, particularly non-parametric ones, which are still insufficiently explored in the literature. We analyze the set of unimodal distributions in the probability simplex, establishing fundamental properties and giving new perspectives to understand the ordinal regression problem. Two contributions are then proposed to incorporate the preference for unimodal distributions into the predictive model: 1) UnimodalNet, a new architecture that by construction ensures the output is a unimodal distribution, and 2) Wasserstein Regularization, a new loss term that relies on the notion of projection in a set to promote unimodality. Experiments show that the new architecture achieves top performance, while the proposed new loss term is very competitive while maintaining high unimodality.},
  archive      = {J_TAI},
  author       = {Jaime S. Cardoso and Ricardo P. M. Cruz and Tomé Albuquerque},
  doi          = {10.1109/TAI.2025.3549740},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Unimodal distributions for ordinal regression},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive hierarchical graph cut for multi-granularity
out-of-distribution detection. <em>TAI</em>, 1–10. (<a
href="https://doi.org/10.1109/TAI.2025.3550473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on a significant yet challenging task: out-of-distribution detection (OOD detection), which aims to distinguish and reject test samples with semantic shifts, so as to prevent models trained on in-distribution (ID) data from producing unreliable predictions. Although previous works have had decent success, they are ineffective for real-world challenging applications since these methods regard all unlabeled data as OOD data and ignore the case that different datasets have different label granularity. For example, “cat” on CIFAR-10 and “tabby cat” on Tiny-ImageNet share the same semantics but have different labels due to various label granularity. To this end, in this paper, we propose a novel Adaptive Hierarchical Graph Cut network (AHGC) to deeply explore the semantic relationship between different images. Specifically, we construct a hierarchical KNN graph to evaluate the similarities between different images based on the cosine similarity. Based on the linkage and density information of the graph, we cut the graph into multiple subgraphs to integrate these semantics-similar samples. If the labeled percentage in a subgraph is larger than a threshold, we will assign the label with the highest percentage to unlabeled images. To further improve the model generalization, we augment each image into two augmentation versions, and maximize the similarity between the two versions. Finally, we leverage the similarity score for OOD detection. Extensive experiments on two challenging benchmarks (CIFAR-10 and CIFAR-100) illustrate that in representative cases, AHGC outperforms state-of-the-art OOD detection methods by 81.24% on CIFAR-100 and by 40.47% on CIFAR-10 in terms of “FPR95”.},
  archive      = {J_TAI},
  author       = {Xiang Fang and Arvind Easwaran and Blaise Genest and Ponnuthurai Nagaratnam Suganthan},
  doi          = {10.1109/TAI.2025.3550473},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Adaptive hierarchical graph cut for multi-granularity out-of-distribution detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive survey on diagnostic microscopic imaging
modalities, challenges, taxonomy, and future directions for cervical
abnormality detection and grading. <em>TAI</em>, 1–24. (<a
href="https://doi.org/10.1109/TAI.2025.3551669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancer is one of the most severe diseases, affecting the lives of many people in the modern world. Among the various types of cancer, cervical cancer is one of the most frequently occurring cancers in the female population. In most cases, doctors and practitioners can typically only identify cervical cancer in its latter stages. Planning cancer therapy and increasing patient survival rates become very difficult as the disease progresses. As a result, diagnosing cervical cancer in its initial stages has become imperative to arrange proper therapy and surgery. In this paper, we present a survey of automatic computerized methods for diagnosing cervical abnormalities based on microscopic imaging modalities. The present survey was conducted by defining a novel taxonomy of the surveyed techniques based on the approaches they used. We also discuss the challenges and sub-challenges associated with an automatic cervical cancer diagnosis based on microscopic imaging modalities. Additionally, surveys on various public and private datasets used by the research community for developing new methods are presented. In this paper, the performances of published papers are compared. The paper concludes by suggesting possible research directions in these fields.},
  archive      = {J_TAI},
  author       = {Anindita Mohanta and Sourav Dey Roy and Niharika Nath and Abhijit Datta and Mrinal Kanti Bhowmik},
  doi          = {10.1109/TAI.2025.3551669},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-24},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {A comprehensive survey on diagnostic microscopic imaging modalities, challenges, taxonomy, and future directions for cervical abnormality detection and grading},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ensuring reliable learning in graph convolutional networks:
Convergence analysis and training methodology. <em>TAI</em>, 1–15. (<a
href="https://doi.org/10.1109/TAI.2025.3550458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in learning from graph-structured data have highlighted the importance of Graph Convolutional Networks (GCNs). Despite some research efforts on the theoretical aspects of GCNs, a gap remains in understanding their training process, especially concerning convergence analysis. This study introduces a two-stage training methodology for GCNs, incorporating both pre-training and fine-tuning phases. A two-layer GCN model is used for the convergence analysis and case studies. The convergence analysis that employs a Lyapunov-like approach is performed on the proposed learning algorithm, providing conditions to ensure the convergence of the model learning. Additionally, an automated learning rate scheduler is proposed based on the convergence conditions to prevent divergence and eliminate the need for manual tuning of the initial learning rate. The efficacy of the proposed method is demonstrated through case studies on the node classification problem. The results reveal that the proposed method outperforms gradient descent-based optimizers by achieving consistent training accuracies within a variation of 0.1% across various initial learning rates, without requiring manual tuning.},
  archive      = {J_TAI},
  author       = {Xinge Zhao and Chien Chern Cheah},
  doi          = {10.1109/TAI.2025.3550458},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Ensuring reliable learning in graph convolutional networks: Convergence analysis and training methodology},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detection of unknown-unknowns in human-in-loop
human-in-plant safety critical systems. <em>TAI</em>, 1–16. (<a
href="https://doi.org/10.1109/TAI.2025.3550913">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Errors in artificial intelligence (AI)-enabled autonomous systems (AAS) where both the cause and effect are unknown to the human operator at the time they occur are referred to as ‘unknown-unknown’ errors. This paper introduces a methodology for preemptively identifying ‘unknown-unknown’ errors in AAS that arise due to unpredictable human interactions and complex real-world usage scenarios, potentially leading to critical safety incidents through unsafe shifts in operational data distributions. We posit that AAS functioning in human-in-the-loop and human-in-the-plant modes must adhere to established physical laws, even when unknown-unknown errors occur. Our approach employs constructing physics-guided models from operational data, coupled with conformal inference for assessing structural breaks in the underlying model caused by violations of physical laws, thereby facilitating early detection of such errors before unsafe shifts in operational data distribution occur. Validation across diverse contexts–zero-day vulnerabilities in autonomous vehicles, hardware failures in artificial pancreas systems, and design deficiencies in aircraft in Maneuvering Characteristics Augmentation Systems (MCAS)–demonstrates our framework’s efficacy in preempting unsafe data distribution shifts due to unknown-unknowns. This methodology not only advances unknown-unknown error detection in AAS but also sets a new benchmark for integrating physics-guided models and machine learning to ensure system safety.},
  archive      = {J_TAI},
  author       = {Aranyak Maity and Ayan Banerjee and Sandeep K.S. Gupta},
  doi          = {10.1109/TAI.2025.3550913},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Detection of unknown-unknowns in human-in-loop human-in-plant safety critical systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GradCFA: A hybrid gradient-based counterfactual and feature
attribution explanation algorithm for local interpretation of neural
networks. <em>TAI</em>, 1–13. (<a
href="https://doi.org/10.1109/TAI.2025.3552057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explainable Artificial Intelligence (XAI) is increasingly essential as AI systems are deployed in critical fields such as healthcare and finance, offering transparency into AI-driven decisions. Two major XAI paradigms, counterfactual explanations (CFX) and feature attribution (FA), serve distinct roles in model interpretability. This study introduces GradCFA, a hybrid framework combining CFX and FA to improve interpretability by explicitly optimizing feasibility, plausibility, and diversity—key qualities often unbalanced in existing methods. Unlike most CFX research focused on binary classification, GradCFA extends to multi-class scenarios, supporting a wider range of applications. We evaluate GradCFA’s validity, proximity, sparsity, plausibility, and diversity against state-of-the-art methods, including Wachter, DiCE, CARE for CFX, and SHAP for FA. Results show GradCFA effectively generates feasible, plausible, and diverse counterfactuals while offering valuable FA insights. By identifying influential features and validating their impact, GradCFA advances AI interpretability.},
  archive      = {J_TAI},
  author       = {Jacob Sanderson and Hua Mao and Wai Lok Woo},
  doi          = {10.1109/TAI.2025.3552057},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {GradCFA: A hybrid gradient-based counterfactual and feature attribution explanation algorithm for local interpretation of neural networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning from n-tuple similarities and unlabeled data.
<em>TAI</em>, 1–11. (<a
href="https://doi.org/10.1109/TAI.2025.3552687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from pairwise similarity and unlabeled data (SU) is a recently emerging weakly-supervised learning method, which learns a classifier from similar data pairs (two instances belong to the same class) and unlabeled data. However, this framework is insoluble for triplet similarities and unlabeled data. To address this limitation, this paper develops a framework for learning from triplet similarities (three instances belonging to the same class) and unlabeled data points, denoted as TSU. This framework not only showcases the feasibility of constructing a TSU classifier but also serves as an inspiration to explore the broader challenge of addressing N-tuple similarities (N ≥ 2) and unlabeled data points. To tackle this more generalized problem, the present paper develop an advancing weakly-supervision framework of learning from N-tuple similarities (N instances belong to the same class) and unlabeled data points, named NSU. This framework provides a solid foundation for handling diverse similarity scenarios. Based on these findings, we propose empirical risk minimization estimators for both TSU and NSU classification. The estimation error bounds are also established for the proposed methods. Finally, experiments are performed to verify the effectiveness of the proposed algorithm.},
  archive      = {J_TAI},
  author       = {Junpeng Li and Shuying Huang and Changchun Hua and Yana Yang},
  doi          = {10.1109/TAI.2025.3552687},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Learning from N-tuple similarities and unlabeled data},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximum margin based activation clipping for post-training
overfitting mitigation in DNN classifiers. <em>TAI</em>, 1–8. (<a
href="https://doi.org/10.1109/TAI.2025.3552686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sources of overfitting in deep neural net (DNN) classifiers include: i) large class imbalances; ii) insufficient training set diversity; and iii) over-training. Recently, it was shown that backdoor data-poisoning also induces overfitting, with unusually large maximum classification margins (MMs) to the attacker’s target class. This is enabled by (unbounded) ReLU activation functions, which allow large signals to propagate in the DNN. Thus, an effective post-training backdoor mitigation approach (with no knowledge of the training set and no knowledge or control of the training process) was proposed, informed by a small, clean (poisoning-free) data set and choosing saturation levels on neural activations to limit the DNN’s MMs. Here, we show that non-malicious sources of overfitting also exhibit unusually large MMs. Thus, we propose novel post-training MM-based regularization that substantially mitigates non-malicious overfitting due to class imbalances and overtraining. Whereas backdoor mitigation and other adversarial learning defenses often trade off a classifier’s accuracy to achieve robustness against attacks, our approach, inspired by ideas from adversarial learning, helps the classifier’s generalization accuracy: as shown for CIFAR-10 and CIFAR-100, our approach improves both the accuracy for rare categories as well as overall. Moreover, unlike other overfitting mitigation methods, it does so with no knowledge of class imbalances, no knowledge of the training set, and without control of the training process.},
  archive      = {J_TAI},
  author       = {Hang Wang and David J. Miller and George Kesidis},
  doi          = {10.1109/TAI.2025.3552686},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-8},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Maximum margin based activation clipping for post-training overfitting mitigation in DNN classifiers},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CenFormer: Transformer-based network from centroid
generation for point cloud completion. <em>TAI</em>, 1–16. (<a
href="https://doi.org/10.1109/TAI.2025.3553456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point clouds captured from 3D scanners are often sparse and incomplete due to occlusions, limited viewpoints, and sensor constraints. These limitations hinder applications in robotics, autonomous navigation, and augmented reality. Hence, point cloud completion is crucial for generating reliable 3D object representations. Existing methods often struggle to capture structural patterns effectively, which leads to low-quality reconstructions. To address these challenges, we propose Centroid Transformer (CenFormer), a novel transformer-based network for point cloud completion. CenFormer introduces two distinct types of centroids, namely Preserved and Dispersed, to facilitate fine-grained reconstruction. The proposed design includes three innovations: i) a Centroid Generation Block to aggregate features for preserved centroids, ii) a Centroid Dispersion Block to predict offsets for dispersed centroids, and iii) a Fine-grained Point Generation Block to refine local patterns around centroids. These components jointly enable the network to effectively capture local structural details and strategically target missing regions for fine-grained 3D shape reconstruction. Experiments on various benchmark datasets demonstrate that CenFormer significantly outperforms state-of-the-art methods in both visualization results and quantitative metrics.},
  archive      = {J_TAI},
  author       = {Tran Thanh Phong Nguyen and Son Lam Phung and Vinod Gopaldasani and Jane Whitelaw and Hoang Thanh Le and Abdesselam Bouzerdoum},
  doi          = {10.1109/TAI.2025.3553456},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {CenFormer: Transformer-based network from centroid generation for point cloud completion},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic broad metric learning. <em>TAI</em>, 1–14. (<a
href="https://doi.org/10.1109/TAI.2025.3553832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many existing metric learning methods are based on fixed similarity constraints. However, the quality of fixed similarity constraints is usually hard to guarantee, and inflexible constraints also limit the performance of metric learning. Moreover, when new training samples are acquired, retraining the model is usually inefficient for many classical metric learning methods. This paper proposes a novel Dynamic Broad Metric Learning (DynBML) method to overcome the above limitations. DynBML trains a broad network with dynamic similarity constraints between samples and their target points to learn a discriminative data transformation with high representation ability. To overcome the weaknesses of fixed constraints, DynBML dynamically updates the target points to produce new constraints during the learning process. A Force-Directed Reference Points Generation (FD-RPG) algorithm is designed to generate reference points from the currently learned space, which encourage the new target points to be more discriminative. A new objective function is proposed to simultaneously learn the new target points and train the data transformation with the guidance of the reference points. Additionally, to avoid retraining the model from scratch when new data arrive, the incremental learning scheme of DynBML (I-DynBML) is developed, which efficiently updates the trained model of DynBML by generating and satisfying new constraints of new input. DynBML is evaluated on ten datasets to demonstrate its superiority. Experiment results show that the dynamic constraints constructed in DynBML improve the learning performance. The effectiveness and efficiency of the incremental learning scheme of DynBML are also verified.},
  archive      = {J_TAI},
  author       = {Xiaoman Hu and C. L. Philip Chen and Tong Zhang},
  doi          = {10.1109/TAI.2025.3553832},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Dynamic broad metric learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ShadowMaskFormer: Mask augmented patch embedding for shadow
removal. <em>TAI</em>, 1–11. (<a
href="https://doi.org/10.1109/TAI.2025.3554605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer recently emerged as the de facto model for computer vision tasks and has also been successfully applied to shadow removal. However, these existing methods heavily rely on intricate modifications to the attention mechanisms within the transformer blocks while using a generic patch embedding. As a result, it often leads to complex architectural designs requiring additional computation resources. In this work, we aim to explore the efficacy of incorporating shadow information within the early processing stage. Accordingly, we propose a transformer-based framework with a novel patch embedding that is tailored for shadow removal, dubbed ShadowMask-Former. Specifically, we present a simple and effective mask-augmented patch embedding to integrate shadow information and promote the model’s emphasis on acquiring knowledge for shadow regions. Extensive experiments conducted on the ISTD, ISTD+, and SRD benchmark datasets demonstrate the efficacy of our method against state-of-the-art approaches while using fewer model parameters. Our implementation is available at https://github.com/lizhh268/ShadowMaskFormer.},
  archive      = {J_TAI},
  author       = {Zhuohao Li and Guoyang Xie and Guannan Jiang and Zhichao Lu},
  doi          = {10.1109/TAI.2025.3554605},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {ShadowMaskFormer: Mask augmented patch embedding for shadow removal},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lorentz-equivariant quantum graph neural network for
high-energy physics. <em>TAI</em>, 1–11. (<a
href="https://doi.org/10.1109/TAI.2025.3554461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid data surge from the high-luminosity Large Hadron Collider introduces critical computational challenges requiring novel approaches for efficient data processing in particle physics. Quantum machine learning, with its capability to leverage the extensive Hilbert space of quantum hardware, offers a promising solution. However, current quantum graph neural networks (GNNs) lack robustness to noise and are often constrained by fixed symmetry groups, limiting adaptability in complex particle interaction modeling. This paper demonstrates that replacing the classical Lorentz Group Equivariant Block modules in LorentzNet with a dressed quantum circuit significantly enhances performance despite using ≈5.5 times fewer parameters. Additionally, quantum circuits effectively replace MLPs by inherently preserving symmetries, with Lorentz symmetry integration ensuring robust handling of relativistic invariance. Our Lorentz-Equivariant Quantum Graph Neural Network (Lorentz-EQGNN) achieved 74.00% test accuracy and an AUC of 87.38% on the Quark-Gluon jet tagging dataset, outperforming the classical and quantum GNNs with a reduced architecture using only 4 qubits. On the Electron-Photon dataset, Lorentz-EQGNN reached 67.00% test accuracy and an AUC of 68.20%, demonstrating competitive results with just 800 training samples. Evaluation of our model on generic MNIST and FashionMNIST datasets confirmed Lorentz-EQGNN’s efficiency, achieving 88.10% and 74.80% test accuracy, respectively. Ablation studies validated the impact of quantum components on performance, with notable improvements in background rejection rates over classical counterparts. These results highlight Lorentz-EQGNN’s potential for immediate applications in noise-resilient jet tagging, event classification, and broader data-scarce HEP tasks.},
  archive      = {J_TAI},
  author       = {Md Abrar Jahin and Md. Akmol Masud and Md Wahiduzzaman Suva and M. F. Mridha and Nilanjan Dey},
  doi          = {10.1109/TAI.2025.3554461},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Lorentz-equivariant quantum graph neural network for high-energy physics},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design of an ultra-thin metamaterial absorber with machine
learning-assisted absorption prediction. <em>TAI</em>, 1–15. (<a
href="https://doi.org/10.1109/TAI.2025.3554732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An absorber is a block of material employed to absorb a portion of the energy of an incident particle. Research on absorbers is rapidly expanding as a result of their prospective applications in several fields, including wireless communications and military purposes. However, conventional absorbers have dense size and design complexity that make them unsuitable for a multitude of practical applications. Metamaterial-based absorbers (MMAs) have garnered significant attention with respect to their low density, narrow layers, and high absorption capacity. In this paper, we introduce a new ultra-thin trilayered Ni–MgF2–Ni metamaterial absorber structure, which is designed using machine learning. It has a balanced and symmetrical layout with a metal-dielectric-metal arrangement and a high-temperature endurance. Its resonator design is defined by mathematical deduction from the Conference matrix. The performance of MMA has been evaluated at wavelengths ranging from 250 nm to 1150 nm, as well as in various modes-TM, TE, and TEM. The results demonstrate that the proposed MMA has exceptional absorption capacities, with an overall absorption of 96.18% within the test range. It offers excellent mean absorption percentages of 99% in the optical region (350 to 750 nm), 95.23% in the ultraviolet (UV) range, and 94.38% in the near-infrared (NIR) range. Furthermore, MMA exhibits an absorption efficiency of 99.99% at a particular wavelength of 424.93 nm. In this work, various machine learning techniques have been applied to predict the absorption of the proposed MMA design. The XGBoost meta-learner-based Stacking ensemble machine learning technique achieves the highest prediction efficiency. Finally, the explainable AI technique with the LIME framework has been used to analyze the predictions of applied machine learning models.},
  archive      = {J_TAI},
  author       = {Md. Jakir Hossain and Nafisa Mubashsara and Riasat Khan and Mohammad Abdul Matin and Panagiotis Sarigiannidis and Sotirios K. Goudos},
  doi          = {10.1109/TAI.2025.3554732},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Design of an ultra-thin metamaterial absorber with machine learning-assisted absorption prediction},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed fixed-time algorithms for time-varying
constrained optimization problems. <em>TAI</em>, 1–12. (<a
href="https://doi.org/10.1109/TAI.2025.3556095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the distributed form of the zeroing neural network for solving time-varying optimal problems is put forward. Compared with traditional centralized algorithms, distributed algorithms possess better privacy and scalability. This paper initially proposes a centralized time-varying optimisation algorithm with fixed-time convergence and certain robustness, which is based on the integration-enhanced zeroing neural network. Subsequently, the algorithm is enhanced, and two distributed algorithms are designed separately. Both of these two algorithms have a fixed convergence time and certain robustness. Additionally, this paper utilizes the penalty function approach to handle time-varying optimization problems with inequality constraints, thereby making the algorithm more widely applicable. The effectiveness of the algorithm is verified through several numerical examples, and the applicability of the algorithm is demonstrated by solving the package-level state-of-charge balancing problem.},
  archive      = {J_TAI},
  author       = {Xing He and Yue Li and Meng Zhang and Tingwen Huang},
  doi          = {10.1109/TAI.2025.3556095},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Distributed fixed-time algorithms for time-varying constrained optimization problems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Malicious clients and contribution co-aware federated
unlearning. <em>TAI</em>, 1–9. (<a
href="https://doi.org/10.1109/TAI.2025.3556092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing federated unlearning methods to eliminate the negative impact of malicious clients on the global model are influenced by unreasonable assumptions (e.g., an auxiliary dataset) or fail to balance model performance and efficiency. To overcome these shortcomings, we propose a malicious clients and contribution co-aware federated unlearning (MCC-Fed) method. Specifically, we introduce a method for detecting malicious clients to reduce their impact on the global model. Next, we design a contribution-aware metric, which accurately quantifies the negative impact of malicious clients on the global calculating their historical contribution ratio. Then, based on this metric, we propose a novel federated unlearning method in which benign clients use the contribution-aware metric as a regularization term to unlearn the influence of malicious clients, and restoring model performance. Experimental results demonstrate that our method effectively addresses the issue of excessive unlearning during the unlearning process, improves the efficiency of performance recovery, and enhances robustness against malicious clients.},
  archive      = {J_TAI},
  author       = {Yang Wang and Xue Li and Siguang Chen},
  doi          = {10.1109/TAI.2025.3556092},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-9},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Malicious clients and contribution co-aware federated unlearning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active gradient manipulation for privacy breaching in
vertical federated learning. <em>TAI</em>, 1–11. (<a
href="https://doi.org/10.1109/TAI.2025.3556094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) has emerged as a promising approach for privacy-preserving collaborative machine learning. Specifically, vertical FL (vFL) allows various devices in multi-agent systems to collectively train models on vertically partitioned data while safeguarding sensitive information. Recent research on vFL privacy analysis primarily explores passive settings where attackers adhere to the FL protocol. This perspective may underestimate the threats posed by vFL, as practical adversaries can deviate from the protocol to enhance their attack capabilities. In response, this work proposes two novel active data reconstruction attacks to compromise data privacy. Each attack induces gradient manipulation during the training phase to breach data privacy. Including an Active Inversion Network (AIN), our first attack exploits a subset of known data in the training set to make passive parties train an auto-encoder (AE) to reconstruct their private data. The second attack introduces an Active Generative Network (AGN) that relies only on the data distribution to train a conditional generative adversarial network (C-GAN) for private feature reconstruction. Our experiments demonstrate the effectiveness of both attacks in three real-world datasets: MNIST, CIFAR10, and USCensus. Additionally, we provide valuable insights and guidelines for enhancing the security of vFL systems through the application of calibrated noise via Local Differential Privacy (LDP).},
  archive      = {J_TAI},
  author       = {Tre’ R. Jeter and Minh N. Vu and Raed Alharbi and Jung Taek Seo and My T. Thai},
  doi          = {10.1109/TAI.2025.3556094},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Active gradient manipulation for privacy breaching in vertical federated learning},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
