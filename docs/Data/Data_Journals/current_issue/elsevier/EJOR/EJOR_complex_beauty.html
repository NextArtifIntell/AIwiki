<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>EJOR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ejor---23">EJOR - 23</h2>
<ul>
<li><details>
<summary>
(2025). Investigating the research and development performance of
chinese industry: A two-stage prospect data envelopment analysis
approach. <em>EJOR</em>, <em>323</em>(3), 1040–1059. (<a
href="https://doi.org/10.1016/j.ejor.2025.01.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With growing investments inindustry research and development (R&amp;D) innovation in China, evaluating whether R&amp;D resources assigned to industries areeffectively used is essential. However, limited research has been conducted on the assessment of R&amp;D effectiveness in Chinese industries that encompasses both the internal process of R&amp;D production and the psychological risks encountered by decision-makers (DMs).Hence, this study puts forward a two-stage prospect data envelopment analysis approach that can characterise the risk attitude of DM in evaluation. By employing this approach, we assess the R&amp;D activities of 28 industries in China from an overall perspective and explore the actual influence of DMs’ risk psychology on the evaluation results through sensitivity and comparative analyses. Furthermore, we categorise the R&amp;D performance of 28 Chinese industries into four quadrants for analysis and focus on the R&amp;D performance of key industries such as extraction of petroleum and natural gas, mining of ferrous metal ores and manufacture of tobacco. Based on the findings, we provide a range of policy recommendations regarding the R&amp;D activities of Chinese industries.},
  archive      = {J_EJOR},
  author       = {Hui-hui Liu and Guo-liang Yang and Jian-wei Gao and Ya-ping Wang and Guo-hua Ni},
  doi          = {10.1016/j.ejor.2025.01.002},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {1040-1059},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Investigating the research and development performance of chinese industry: A two-stage prospect data envelopment analysis approach},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Business cycle and realized losses in the consumer credit
industry. <em>EJOR</em>, <em>323</em>(3), 1024–1039. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the determinants of losses given default (LGD) in consumer credit. Utilizing a unique dataset encompassing over 6 million observations of Italian consumer credit over a long time span, we find that macroeconomic and social (MS) variables significantly enhance the forecasting performance at both individual and portfolio levels, improving R 2 by up to 10 percentage points. Our findings are robust across various model specifications. Non-linear forecast combination schemes employing neural networks consistently rank among the top performers in terms of mean absolute error, RMSE, R 2 , and model confidence sets in every tested scenario. Notably, every model that belongs to the superior set systematically includes MS variables. The relationship between expected LGD and macro predictors, as revealed by accumulated local effects plots and Shapley values, supports the intuition that lower real activity, a rising cost-of-debt to GDP ratio, and heightened economic uncertainty are associated with higher LGD for consumer credit. Our results on the influence of MS variables complement and slightly differ from those of related papers. These discrepancies can be attributed to the comprehensive nature of our database – spanning broader dimensions in space, time, sectors, and types of consumer credit – the variety of models utilized, and the analyses conducted.},
  archive      = {J_EJOR},
  author       = {Walter Distaso and Francesco Roccazzella and Frédéric Vrins},
  doi          = {10.1016/j.ejor.2024.12.026},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {1024-1039},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Business cycle and realized losses in the consumer credit industry},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Expected information of noisy attribute forecasts for
probabilistic forecasts. <em>EJOR</em>, <em>323</em>(3), 1013–1023. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper extends the maximum entropy (ME) model to include uncertainty about noisy moment forecasts. In this framework the noise propagates to the ME model through the constrained optimization’s Lagrange multipliers. The mutual information and expected Fisher information are included for assessing effects of the noisy moment forecasts on the ME model and its parameters. A new mean–variance decomposition of the mutual information is derived for the normal distribution when the mean and variance are both noisy. A simulation estimator is used to estimate the expected information for noisy ME models on finite support. A family of ensemble of individual level noisy ME forecast models is introduced which includes individual level versions of the conditional logit and multiplicative competitive interaction models as specific cases. To illustrate the implementation and merits of the proposed noisy ME framework, the classic loaded dice problem and discrete choice analysis are examined.},
  archive      = {J_EJOR},
  author       = {Omid M. Ardakani and Robert F. Bordley and Ehsan S. Soofi},
  doi          = {10.1016/j.ejor.2024.12.024},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {1013-1023},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Expected information of noisy attribute forecasts for probabilistic forecasts},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Does the quantity discount mechanism offer a loophole for
retailer collusion? Impacts and responses. <em>EJOR</em>,
<em>323</em>(3), 999–1012. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quantity discount mechanism is an effective and widely used tool by manufacturers to encourage downstream retailers to increase their order volumes. As wholesale prices decrease with larger order quantities, retailers have an incentive to collude and achieve joint procurement. Two joint procurement modes—group buying (GB) and agency procurement (AP)—are considered to characterize the phenomenon of retailer collusion. In GB mode, retailers purchase as a group and enjoy the same per-unit wholesale price. In contrast, in the AP mode, a leading retailer assumes responsibility for aggregating orders and submitting the total order to the manufacturer while having the authority to set the resale price. A dual-channel model is developed to investigate joint procurement among competing retailers, aiming to identify its underlying driving forces and impacts. Our findings indicate that, compared to individual purchasing (IP), GB is always attainable for retailers, whereas AP is only attainable under intense competition when retailers are symmetric. We reveal that retailers engaging in joint procurement do not always aim to achieve lower wholesale prices. In some cases, the objective may be to mitigate price competition. This finding suggests that joint procurement by retailers results in a reduction in total order quantity, which significantly diminishes the manufacturer’s profit. In response to the challenges of retailer collusion, we explore the feasibility and potential value of offering a coordinated quantity discount mechanism, wherein the manufacturer gives up the pursuit of maximizing its own profit in favor of optimizing the profits of the entire supply chain, making concessions to the retailers. We identify the scenarios in which a coordinated quantity discount contract can eliminate the loophole for retailer collusion and highlight both the value and necessity of achieving contract coordination.},
  archive      = {J_EJOR},
  author       = {Shaofu Du and Xiahui Sun and Li Hu and Tsan-Ming Choi},
  doi          = {10.1016/j.ejor.2024.12.007},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {999-1012},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Does the quantity discount mechanism offer a loophole for retailer collusion? impacts and responses},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-activity shift scheduling under uncertainty: The value
of shift flexibility. <em>EJOR</em>, <em>323</em>(3), 988–998. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a multi-activity shift scheduling problem under demand uncertainty, exploring various levels of flexibility in adapting aspects of the shift schedule (e.g., activity assignment, break assignment, selection of shift type and shift end time) to late-arriving demand information. To address the resulting complex two-stage stochastic combinatorial optimisation problems, we propose a novel two-stage stochastic mixed-integer programming formulation leveraging state-expanded networks and a clustering-based sequential sampling approach for efficiently solving large-scale problem instances. In computational experiments on stochastic problems derived from well-known multi-activity shift scheduling instances, we show that this method effectively solves instances with up to 10 activities and 100 demand scenarios, approaching near-optimality within an average time of less than one hour. From a managerial standpoint, our study provides insights into the structure of good first-stage scheduling decisions as well as into the impact of different flexibility levels on expected costs of the solutions, thereby offering valuable support for decisions such as adjusting employees’ salaries in exchange for increased shift flexibility.},
  archive      = {J_EJOR},
  author       = {Felix Hagemann and Till Frederik Porrmann and Michael Römer},
  doi          = {10.1016/j.ejor.2024.12.028},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {988-998},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multi-activity shift scheduling under uncertainty: The value of shift flexibility},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Measuring technical efficiency under variable returns to
scale using debreu’s loss function. <em>EJOR</em>, <em>323</em>(3),
975–987. (<a href="https://doi.org/10.1016/j.ejor.2024.12.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a model that makes two contributions to the measurement of technical efficiency under a technology with variable returns to scale. First, the criteria for identifying an optimal benchmark are not limited to technical dominance and Pareto efficiency, but also include maximum average productivity, defined as the ratio between a weighted linear aggregate of outputs and inputs. Second, the paper contributes a conceptual basis for correcting the shadow prices of inputs and outputs to reflect the influence of returns to scale. Debreu&#39;s loss function is used to value inefficiency as the difference between the virtual input and output using the shadow prices of the supporting hyperplane at the optimal reference. The efficiency score is a virtual profitability index with endogenous shadow prices that reflect the valuation of inputs and outputs with a microeconomic rationale, i.e., it is not a distance measure based on aggregation with exogenous weights of the difference between observed and optimal quantities. Two further results follow from these contributions. First, the radial input-output orientation to maximise productivity is endogenous. It is conditioned by the nature of the returns to scale. Second, the efficiency measure based on the loss function exhibits the desirable properties in a radial context, including the indication property, because the efficiency score incorporates non-radial slack.},
  archive      = {J_EJOR},
  author       = {Juan José Díaz-Hernández and David-José Cova-Alonso and Eduardo Martínez-Budría},
  doi          = {10.1016/j.ejor.2024.12.050},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {975-987},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Measuring technical efficiency under variable returns to scale using debreu&#39;s loss function},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The copeland ratio ranking method for abstract decision
problems. <em>EJOR</em>, <em>323</em>(3), 966–974. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the problem of ranking a finite number of alternatives on the basis of a dominance relation. We firstly investigate some disadvantages of the Copeland ranking method, of the degree ratio ranking method and of the modified degree ratio ranking method which were characterized by using clone properties and classical axiomatic properties. Then, we introduce some alternative axiomatic properties and propose a new ranking method which is defined by the Copeland ratio of alternatives (i.e., the Copeland score of an alternative divided by its total degree). We show that this proposed ranking method coincides with the Copeland ranking method, the degree ratio ranking method and the modified degree ratio ranking method for abstract decision problems with complete and asymmetric dominance relations. Subsequently, we prove that this new ranking method is able to overcome the mentioned disadvantages of these ranking methods. After that, we provide a characterization for the Copeland ratio ranking method using the introduced axiomatic properties.},
  archive      = {J_EJOR},
  author       = {Weibin Han and Adrian Van Deemen},
  doi          = {10.1016/j.ejor.2024.12.042},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {966-974},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The copeland ratio ranking method for abstract decision problems},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-objective evolutionary algorithm with
mutual-information-guided improvement phase for feature selection in
complex manufacturing processes. <em>EJOR</em>, <em>323</em>(3),
952–965. (<a href="https://doi.org/10.1016/j.ejor.2024.12.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex manufacturing processes (CMP) involve numerous features that impact product quality. Therefore, selecting key process features (KPF) is crucial for effective quality prediction and control in CMPs. This paper proposes a KPF (feature) selection method for the high-dimensional CMP data. The KPF selection problem is formulated as a bi-objective combinatorial optimization task of maximizing the geometric mean measure and minimizing the number of selected features. To solve this challenging high-dimensional KPF selection problem, we propose a novel multi-objective evolutionary algorithm (MOEA) called NSGAII-MIIP. NSGAII-MIIP applies an improvement phase (called MIIP) to purify the non-dominated solutions obtained by genetic operators during the iteration process to improve the FS performance. The improvement phase is guided by a mutual-information-based feature importance measure considering both a feature’s relevance degree to class (product quality level) and its redundancy degree to selected features. This allows MIIP to efficiently update non-dominated solutions by selecting relevant features and eliminating redundant features. Moreover, MIIP is seamlessly integrated into the solution ranking process of NSGAII-MIIP so that solutions from the improvement phase can be ranked together with original solutions in the population efficiently. Experiments on eight datasets show that NSGAII-MIIP has better KPF selection performance than eight state-of-the-art multi-objective FS methods. Moreover, NSGAII-MIIP exhibits superior search performance compared to eight typical multi-objective optimization algorithms.},
  archive      = {J_EJOR},
  author       = {An-Da Li and Zhen He and Qing Wang and Yang Zhang and Yanhui Ma},
  doi          = {10.1016/j.ejor.2024.12.036},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {952-965},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A multi-objective evolutionary algorithm with mutual-information-guided improvement phase for feature selection in complex manufacturing processes},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Opinion convergence and management: Opinion dynamics in
interactive group decision-making. <em>EJOR</em>, <em>323</em>(3),
938–951. (<a href="https://doi.org/10.1016/j.ejor.2024.12.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision-making processes are significantly influenced by internal social network interactions and external information inputs. While previous research has highlighted the role of social networks in opinion evolution, the dynamics of information dissemination and its interaction with these networks are less understood. To bridge this gap, we introduce the Social-Information-Opinion Dynamic Supernetwork (SIO-DS) model, which integrates critical factors such as the impact of external information and opinion propagation, alongside the influence of internal social network structures and individual willingness to adjust opinions. This model takes into account the varied levels of confidence and individualized dynamic influence among decision makers, recognizing both their asymmetry and diversity. It performs opinion dynamics using bounded confidence models and parameters that govern information dissemination. We found that scale-free networks, which feature influential leaders, are more effective at reaching consensus compared to small-world networks, which are hindered by limited inter-group connections. The speed of information dissemination is critical; moderate speeds help in maintaining a stable consensus by balancing social influence, while very fast or slow speeds risk exacerbating polarization based on how social influence is managed. The SIO-DS model has broad implications for enhancing decision-making in corporate management by optimizing network structures, in public policy by managing public opinion, and in crisis management by developing effective communication strategies. Ultimately, this model not only deepens our understanding of opinion dynamics but also provides practical tools for improving decision-making quality and efficiency in various contexts.},
  archive      = {J_EJOR},
  author       = {Yuan Xu and Shifeng Liu and T.C.E. Cheng and Xue Feng and Jun Wang and Xiaopu Shang},
  doi          = {10.1016/j.ejor.2024.12.046},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {938-951},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Opinion convergence and management: Opinion dynamics in interactive group decision-making},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven preference learning methods for sorting problems
with multiple temporal criteria. <em>EJOR</em>, <em>323</em>(3),
918–937. (<a href="https://doi.org/10.1016/j.ejor.2024.12.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present novel preference learning approaches for sorting problems with multiple temporal criteria. They leverage an additive value function as the basic preference model, adapted for accommodating time series data. Given assignment examples concerning reference alternatives, we learn such a model using convex quadratic programming. It is characterized by fixed-time discount factors and operates within a regularization framework. This approach enables the consideration of temporal interdependencies between timestamps while mitigating the risk of overfitting. To enhance scalability and accommodate learnable time discount factors, we introduce a novel monotonic Recurrent Neural Network (mRNN). It captures the evolving dynamics of preferences over time, while upholding critical properties inherent to multiple criteria sorting problems. These include criteria monotonicity, preference independence, and the natural ordering of classes. The proposed mRNN can describe the preference dynamics by depicting piecewise linear marginal value functions and personalized time discount factors along with time. Thus, it effectively combines the interpretability of traditional sorting methods with the predictive potential offered by deep preference learning models. We comprehensively assess the proposed models on synthetic data scenarios and a real-case study centered on classifying valuable users within a mobile gaming app based on their historical in-game behavioral sequences. Empirical findings underscore the notable performance improvements achieved by the proposed models when compared to a spectrum of baseline methods, spanning machine learning, deep learning, and conventional multiple criteria sorting approaches.},
  archive      = {J_EJOR},
  author       = {Yijun Li and Mengzhuo Guo and Miłosz Kadziński and Qingpeng Zhang and Chenxi Xu},
  doi          = {10.1016/j.ejor.2024.12.020},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {918-937},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Data-driven preference learning methods for sorting problems with multiple temporal criteria},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conical free disposal hull estimators of directional
distances and luenberger productivity indices for general technologies.
<em>EJOR</em>, <em>323</em>(3), 907–917. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Directional distances are a popular tool in productivity and efficiency analysis due to their versatility in evaluating the distance of Decision Making Units (DMU) to the efficient frontier of the production set. The theoretical and statistical properties of these measures are well-established in various contexts. However, the measurement of directional distances to the cone spanned by the attainable set has not yet been explored. This cone is necessary to define the Luenberger indices for general technologies. This paper aims to fill this gap by presenting a method for defining and estimating directional distances to this cone, applicable to general technologies without imposing convexity. We also discuss the statistical properties of these measures, enabling us to measure distances to non-convex attainable sets under Constant Returns to Scale (CRS), as well as measure and estimate Luenberger productivity indices and their decompositions for general technologies. In addition, we provide a detailed description of how to make inferences on these indices. Finally, we offer simulated data and a practical example of inference on Luenberger productivity indices and their decompositions using a well-known real data set.},
  archive      = {J_EJOR},
  author       = {Cinzia Daraio and Simone Di Leo and Léopold Simar},
  doi          = {10.1016/j.ejor.2024.12.025},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {907-917},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Conical free disposal hull estimators of directional distances and luenberger productivity indices for general technologies},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The collaborative berth allocation problem with
row-generation algorithms for stable cost allocations. <em>EJOR</em>,
<em>323</em>(3), 888–906. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent supply chain disruptions and crisis response policies (e.g., the COVID-19 pandemic and the Red Sea crisis) have highlighted the role of container terminals as crucial and scarce resources in the global economy. To tackle these challenges, the industry increasingly aims for advanced operational collaboration among multiple stakeholders, as demonstrated by the ambitions of the recently founded Gemini alliance. Nonetheless, collaborative planning models often disregard the requirements and incentives of stakeholders or simply solve idealized small instances. Motivated by the above, we design novel and effective collaboration mechanisms among terminal operators that share the resources (berths and quay cranes). We first define the collaborative berth allocation problem and propose a mixed integer linear programming (MILP) model to minimize the total cost of all terminals, referred to as the coalitional costs. We adopt the core and the nucleolus concepts from cooperative game theory to allocate the coalitional costs such that stakeholders have stable incentives to collaborate. To obtain solutions for realistic instance sizes, we propose two exact row-generation-based core and nucleolus algorithms that are versatile and can be used for various combinatorial optimization problems. To the best of our knowledge, the proposed row-generation approach for the nucleolus is the first of its kind for combinatorial optimization problems. Extensive experiments demonstrate that the collaborative berth allocation approach achieves up to 28.44% of cost savings, increasing the solution space in disruptive situations, while the proposed core and nucleolus solutions guarantee the collaboration incentives for individual terminals.},
  archive      = {J_EJOR},
  author       = {Xiaohuan Lyu and Eduardo Lalla-Ruiz and Frederik Schulte},
  doi          = {10.1016/j.ejor.2024.12.048},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {888-906},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The collaborative berth allocation problem with row-generation algorithms for stable cost allocations},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strategic decentralization of self-branded and contract
manufacturing businesses. <em>EJOR</em>, <em>323</em>(3), 868–887. (<a
href="https://doi.org/10.1016/j.ejor.2025.01.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the incentive of a competitive contract manufacturer (CCM) to adopt a decentralized structure by segregating contract manufacturing from its self-branded business. We consider an original equipment manufacturer (OEM) with the option to outsource production either to a CCM producing its self-branded product, or to a non-competitive contract manufacturer (NCM) also serving another OEM. The CCM has the option to centralize or decentralize its two businesses and competes in quantity with both OEMs in the end-user market. Our analysis of the strategic interactions between the OEM&#39;s outsourcing decision and the CCM&#39;s organizational structure choice shows that the likelihood of the OEM outsourcing to the CCM increases when the CCM adopts a decentralized structure compared to a centralized one. Under decentralization, a sufficiently low wholesale price offered by the contract manufacturing division provides the OEM with a competitive advantage. Consequently, the CCM is motivated to strategically deploy a decentralized structure to attract contract manufacturing business from the OEM, even though decentralization yields a lower profit than centralization. However, the CCM must be cautious when implementing a decentralized structure to secure orders from the OEM. The resulting intensified market competition undermines its profit from self-branded business and potentially makes it worse off from producing for the OEM. In such case, the CCM should maintain a centralized structure and uphold a purely competitive relationship with the OEM. Moreover, we demonstrate how the profitability of another OEM supplied by the NCM is influenced by the interplay between the CCM and the OEM.},
  archive      = {J_EJOR},
  author       = {Wei Li and Yanglei Li and Jing Chen and Bintong Chen},
  doi          = {10.1016/j.ejor.2025.01.017},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {868-887},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Strategic decentralization of self-branded and contract manufacturing businesses},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Managing social responsibility efforts with the
consideration of violation probability. <em>EJOR</em>, <em>323</em>(3),
852–867. (<a href="https://doi.org/10.1016/j.ejor.2025.01.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Corporate social responsibility (CSR) has a strong impact on the external image of the enterprise. The violation of CSR not only harms the enterprise but also negatively affects other firms in the supply chain. This paper establishes a game-theoretical model to study the management of social responsibility efforts with considerations of violation probability. The upstream manufacturer and downstream retailer can reduce the violation probability by exerting CSR efforts. Specifically, we study the following four models, including both participants exerting efforts, only the manufacturer exerting effort, only the retailer exerting effort, and neither participant exerting effort. Our analysis shows that as the effort cost of the manufacturer increases, the retailer may increase or decrease his effort level under both participants exerting efforts, due to the complementary and substitution effects between the efforts of the manufacturer and retailer. We also find that compared with both participants exerting efforts, the retailer may increase or decrease his effort level under only the retailer exerting effort, and the effort level of the manufacturer may grow or shrink under only the manufacturer exerting effort. In addition, we study the decision matrix for the manufacturer and retailer, and find that in equilibrium the manufacturer always has incentives to exert CSR effort, while the retailer may prefer a free ride and sometimes chooses not to exert effort. Interestingly, we find that the total supply chain profit may not be the highest under both participants exerting efforts, but it is the lowest under neither participant exerting effort.},
  archive      = {J_EJOR},
  author       = {Jiayan Xu and Housheng Duan and Sijing Deng},
  doi          = {10.1016/j.ejor.2025.01.016},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {852-867},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Managing social responsibility efforts with the consideration of violation probability},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exact algorithms for routing electric autonomous mobile
robots in intralogistics. <em>EJOR</em>, <em>323</em>(3), 830–851. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In intralogistics and manufacturing, autonomous mobile robots (AMRs) are usually electrically powered and recharged by battery swapping or induction. We investigate AMR route planning in these settings by studying different variants of the electric vehicle routing problem with due dates (EVRPD). We consider three common recharging strategies: battery swapping, inductive recharging with full recharges, and inductive recharging with partial recharges. Moreover, we consider two different objective functions: the standard objective of minimizing the total distance traveled and the minimization of the total completion times of transport jobs. The latter is of particular interest in intralogistics, where time aspects are of crucial importance and the earliest possible completion of jobs often has priority. In this context, recharging decisions also play an essential role. For solving the EVRPD variants, we propose exact branch-price-and-cut algorithms that rely on ad-hoc labeling algorithms tailored to the respective variants. We perform an extensive computational study to generate managerial insights on the AMR route planning problem and to assess the performance of our solution approach. The experiments are based on newly introduced instances featuring typical characteristics of AMR applications in intralogistics and manufacturing and on standard benchmark instances from the literature. The detailed analysis of our results reveals that inductive recharging with partial recharges is competitive with battery swapping, while using a full-recharges strategy has considerable drawbacks in an AMR setup.},
  archive      = {J_EJOR},
  author       = {Anne Meyer and Timo Gschwind and Boris Amberg and Dominik Colling},
  doi          = {10.1016/j.ejor.2024.12.041},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {830-851},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Exact algorithms for routing electric autonomous mobile robots in intralogistics},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flexibility-based price discrimination in a competitive
context considering consumers’ socioeconomic status. <em>EJOR</em>,
<em>323</em>(3), 810–829. (<a
href="https://doi.org/10.1016/j.ejor.2025.01.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines the impact of flexibility-based price discrimination (FBPD) on the pricing and quality strategy of the adopting firm and its competitor, as well as the impact on the welfare of consumers. We assume that the inflexible consumers being targeted for price discrimination can be either high-income consumers or low-income consumers, and the high-income consumers are more sensitive to product quality. We show that depending on who the targeted inflexible consumers are, the impact of FBPD on all firms and consumers can be either negative or positive. If an FBPD is to exploit the inflexibility of low-income consumers, it will not only make the vulnerable group even more disadvantaged but also lower the firms’ incentive to produce high-quality products. On the contrary, if an FBPD is to exploit the inflexibility of high-income consumers, it will increase the firms’ incentive to produce high-quality products, and the targeted consumers will be compensated by having higher quality products. However, the firms might engage in excessive quality enhancement, leading to a situation where the competition between the firms falls into a prisoner’s dilemma. Our research results suggest that the application of FBPD could necessitate a comprehensive regulatory framework to ensure ethical implementation while safeguarding consumer welfare, particularly that of vulnerable groups.},
  archive      = {J_EJOR},
  author       = {Jian Zhang and Emily B. Laidlaw and Raymond A. Patterson},
  doi          = {10.1016/j.ejor.2025.01.005},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {810-829},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Flexibility-based price discrimination in a competitive context considering consumers’ socioeconomic status},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coordinate or collaborate? Reducing food waste in
perishable-product supply chains. <em>EJOR</em>, <em>323</em>(3),
795–809. (<a href="https://doi.org/10.1016/j.ejor.2024.12.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reducing food waste in supply chains (SCs) with multiple decision-makers is challenging. A common approach grocery retailers use to reduce waste is requiring manufacturers to only send products with a long remaining shelf life (“minimum life on receipt”-MLOR). However, its impact on manufacturers remains unclear. To evaluate the effectiveness of MLOR agreements on food waste, we investigate two strategies: (1) collaborating on setting the MLOR level and (2) coordinating the SC via contract. Through collaboration, we analytically show that if the MLOR agreement does not demand solely fresh products, it raises manufacturer profits, enabling potential wholesale price reduction. This might incentivize retailers to collaborate to reduce the MLOR level. We demonstrate that the coordinating strategy can reduce waste in the SC and is most beneficial when the wholesale price is high, and the issuing policy is FIFO. We introduce possible coordination contracts and show that in coordinated SCs, manufacturers always provide the highest MLOR level without requiring any restrictive MLOR agreements. Governments mainly focus on reducing retail waste and promoting retailers to request higher MLOR. However, these efforts can backfire by creating more waste for manufacturers. Reducing the MLOR allows retailers to negotiate lower wholesale prices, increasing profitability while reducing waste. Although SC coordination is known for reducing inefficiency, it may not be the best strategy for reducing waste, especially when the issuing policy is more LIFO than FIFO. Specifically, while coordination might be a better strategy for online retailers, collaboration can be a better strategy for brick-and-mortar retailers.},
  archive      = {J_EJOR},
  author       = {Navid Mohamadi and Sandra Transchel and Jan C. Fransoo},
  doi          = {10.1016/j.ejor.2024.12.039},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {795-809},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Coordinate or collaborate? reducing food waste in perishable-product supply chains},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Judgmental selection of parameters for simple forecasting
models. <em>EJOR</em>, <em>323</em>(3), 780–794. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an era dominated by big data and machine and deep learning solutions, judgment has still an important role to play in decision making. Behavioural operations are on the rise as judgment complements automated algorithms in many practical settings. Over the years, new and exciting uses of judgment have emerged, with some providing fresh and innovative insights on algorithmic approaches. The forecasting field, in particular, has seen judgment infiltrating in several stages of the forecasting process, such as the production of purely judgmental forecasts, judgmental revisions of formal (statistical) forecasts, and as an alternative to statistical selection between forecasting models. In this paper, we take the first steps towards exploring a neglected use of judgment in forecasting: the manual selection of the parameters for forecasting models. We focus on a simple but widely-used forecasting model, the Simple Exponential Smoothing, and, through a behavioural experiment, we investigate the performance of individuals versus algorithms in selecting optimal modelling parameters under different conditions. Our results suggest that the use of judgment on the task of parameter selection could improve forecasting accuracy. However, individuals also suffer from anchoring biases.},
  archive      = {J_EJOR},
  author       = {Fotios Petropoulos and Evangelos Spiliotis},
  doi          = {10.1016/j.ejor.2024.12.034},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {780-794},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Judgmental selection of parameters for simple forecasting models},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trade-off between utility and fairness in two-agent
single-machine scheduling. <em>EJOR</em>, <em>323</em>(3), 767–779. (<a
href="https://doi.org/10.1016/j.ejor.2025.01.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem arising when two agents, each owning a set of jobs, compete to schedule their jobs on a common processing resource. Each schedule implies a certain utility for each agent and an overall system utility. We are interested in solutions that incorporate some criterion of fairness for the agents and, at the same time, are satisfactory from the viewpoint of system utility. More precisely, we investigate the trade-off between fairness and system utility when both agents want to minimize the total completion time of their respective jobs. We analyze the structure of the set of such trade-off solutions, and propose an exact algorithm for their computation, based on the Lagrangian relaxation of a MILP formulation of the problem. A large set of computational experiments has been carried out to show the viability of the approach. Moreover, the results show that in most cases a solution having a high degree of fairness can be obtained by sacrificing a very limited amount of system utility.},
  archive      = {J_EJOR},
  author       = {Alessandro Agnetis and Mario Benini and Gaia Nicosia and Andrea Pacifici},
  doi          = {10.1016/j.ejor.2025.01.025},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {767-779},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Trade-off between utility and fairness in two-agent single-machine scheduling},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new effective heuristic for the prisoner transportation
problem. <em>EJOR</em>, <em>323</em>(3), 753–766. (<a
href="https://doi.org/10.1016/j.ejor.2025.01.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Prisoner Transportation Problem is an NP-hard combinatorial problem and a complex variant of the Dial-a-Ride Problem. Given a set of requests for pick-up and delivery and a homogeneous fleet, it consists of assigning requests to vehicles to serve all requests, respecting the problem constraints such as route duration, capacity, ride time, time windows, multi-compartment assignment of conflicting prisoners and simultaneous services in order to optimize a given objective function. In this paper, we present a new solution framework to address this problem that leads to an efficient heuristic. A comparison with computational results from previous papers shows that the heuristic is very competitive for some classes of benchmark instances from the literature and clearly superior in the remaining cases. Finally, suggestions for future studies are presented.},
  archive      = {J_EJOR},
  author       = {Luciano Ferreira and Marcos Vinicius Milan Maciel and José Valério de Carvalho and Elsa Silva and Filipe Pereira Alvelos},
  doi          = {10.1016/j.ejor.2025.01.029},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {753-766},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A new effective heuristic for the prisoner transportation problem},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Formulations and branch-and-cut algorithms for the period
travelling salesman problem. <em>EJOR</em>, <em>323</em>(3), 739–752.
(<a href="https://doi.org/10.1016/j.ejor.2025.01.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we address two variants of the Period Travelling Salesman Problem: one where some nodes cannot be visited consecutively over the time horizon, and another one where this restriction is not imposed. A new flow-based formulation that uses specific information about the visit patterns of nodes is studied and empirical tests show that it is able to solve test instances where a flow-based formulation based on the Single Commodity Flow formulation for the Travelling Salesman Problem reached the time limit. Non-compact formulations are studied in this work as well. We propose two new sets of exponentially-sized valid inequalities that have not been studied yet in the literature. A formulation which is based on connectivity cuts per period enhanced with these sets of valid inequalities proved to be the most efficient and it was able to solve several instances.},
  archive      = {J_EJOR},
  author       = {Sofia Henriques and Ana Paias},
  doi          = {10.1016/j.ejor.2025.01.015},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {739-752},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Formulations and branch-and-cut algorithms for the period travelling salesman problem},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fairness in repetitive scheduling. <em>EJOR</em>,
<em>323</em>(3), 724–738. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research found that fairness plays a key role in customer satisfaction. Therefore, many manufacturing and services industries have become aware of the need to treat customers fairly. Still, there is a huge lack of models that enable industries to make operational decisions fairly, such as a fair scheduling of the customers’ jobs. Our main aim in this research is to provide a unified framework to enable schedulers to make fair decisions in repetitive scheduling environments. For doing so, we consider a set of repetitive scheduling problems involving a set of n clients. In each out of q consecutive operational periods ( e.g. days), each one of the customers submits a job for processing by an operational system. The scheduler’s aim is to provide a schedule for each of the q periods such that the quality of service (QoS) received by each of the clients will meet a certain predefined threshold. The QoS of a client may take several different forms, e.g. , the number of days that the customer receives its job later than a given due date, the number of times the customer receives his preferred time slot for service, or the sum of waiting times for service. We analyze the single machine variant of the problem for several different definitions of QoS, and classify the complexity of the corresponding problems using the theories of classical and parameterized complexity. We also study the price of fairness, i.e., the loss in the system’s efficiency that results from the need to provide fair solutions.},
  archive      = {J_EJOR},
  author       = {Danny Hermelin and Hendrik Molter and Rolf Niedermeier and Michael Pinedo and Dvir Shabtay},
  doi          = {10.1016/j.ejor.2024.12.052},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {724-738},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fairness in repetitive scheduling},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving the parallel processor scheduling and bin packing
problems with contiguity constraints: Mathematical models and
computational studies. <em>EJOR</em>, <em>323</em>(3), 701–723. (<a
href="https://doi.org/10.1016/j.ejor.2024.09.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The parallel processor scheduling and bin packing problems with contiguity constraints are important in the field of combinatorial optimization because both problems can be used as components of effective exact decomposition approaches for several two-dimensional packing problems. In this study, we provide an extensive review of existing mathematical formulations for the two problems, together with some model enhancements and lower bounding techniques, and we empirically evaluate the computational behavior of each of these elements using a state-of-the-art solver on a large set of literature instances. We also assess whether recent developments such as meet-in-the middle patterns and the reflect formulation can be used to solve the two problems more effectively. Our experiments demonstrate that some features, such as the mathematical model used, have a major impact on whether an approach is able to solve an instance, whereas other features, such as the use of symmetry-breaking constraints, do not bring any empirical advantage despite being useful in theory. Overall, our goal is to help the research community design more effective yet simpler algorithms to solve the parallel processor scheduling and bin packing problems with contiguity constraints and closely related extensions so that, eventually, those can be integrated into a larger number of exact methods for two-dimensional packing problems.},
  archive      = {J_EJOR},
  author       = {Fatih Burak Akçay and Maxence Delorme},
  doi          = {10.1016/j.ejor.2024.09.013},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {701-723},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Solving the parallel processor scheduling and bin packing problems with contiguity constraints: Mathematical models and computational studies},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
