<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TAI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tai---20">TAI - 20</h2>
<ul>
<li><details>
<summary>
(2025). Unformer: A transformer-based approach for adaptive
multiscale feature aggregation in underwater image enhancement.
<em>TAI</em>, <em>6</em>(4), 1024–1037. (<a
href="https://doi.org/10.1109/TAI.2024.3508667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater imaging is often compromised by light scattering and absorption, resulting in image degradation and distortion. This manifests as blurred details, color shifts, and diminished illumination and contrast, thereby hindering advancements in underwater research. To mitigate these issues, we propose Unformer, an innovative underwater image enhancement (UIE) technique that leverages a transformer-based architecture for multiscale adaptive feature aggregation. Our approach employs a multiscale feature fusion strategy that adaptively restores illumination and detail features. We reevaluate the relationship between convolution and transformer to develop a novel encoder structure. This structure effectively integrates both long-range and short-range dependencies, dynamically combines local and global features, and constructs a comprehensive global context. Furthermore, we propose a unique multibranch decoder architecture that enhances and efficiently extracts spatial context information through the transformer module. Extensive experiments on three datasets demonstrate that our proposed method outperforms other techniques in both subjective and objective evaluations. Compared with the latest methods, Unformer has improved the peak signal-to-noise ratio (PSNR) by 19.5% and 14.8% respectively on the LSUI and EUVP datasets. The code is available at: https://github.com/yhflq/Unformer.},
  archive      = {J_TAI},
  author       = {Yuhao Qing and Yueying Wang and Huaicheng Yan and Xiangpeng Xie and Zhengguang Wu},
  doi          = {10.1109/TAI.2024.3508667},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  number       = {4},
  pages        = {1024-1037},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Unformer: A transformer-based approach for adaptive multiscale feature aggregation in underwater image enhancement},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aperiodically intermittent control approach to finite-time
synchronization of delayed inertial memristive neural networks.
<em>TAI</em>, <em>6</em>(4), 1014–1023. (<a
href="https://doi.org/10.1109/TAI.2024.3507740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the finite-time synchronization (FTS) for inertial memristive neural networks (IMNNs) with time-delays by the aperiodically intermittent control approach. Compared with the reduced-order method utilized in the existing literature, this article considers the FTS of delayed IMNNs directly without order reduction. First, the error IMNNs with time-delays is designed through the theories of set-valued mappings and differential inclusions, and its finite-time stability problem is discussed by applying the finite-time stability theorem. Furthermore, by constructing nonperiodic intermittent state-feedback controller and nonperiodic intermittent adaptive control strategy, the sufficient criteria to ensure the FTS of the master–slave delayed IMNNs are derived, and the settling times are explicitly estimated. Finally, a simulation to confirm the availability of results is provided.},
  archive      = {J_TAI},
  author       = {Yuxin Jiang and Song Zhu and Mouquan Shen and Shiping Wen and Chaoxu Mu},
  doi          = {10.1109/TAI.2024.3507740},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  number       = {4},
  pages        = {1014-1023},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Aperiodically intermittent control approach to finite-time synchronization of delayed inertial memristive neural networks},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven event-triggered control for discrete-time neural
networks subject to actuator saturation. <em>TAI</em>, <em>6</em>(4),
1003–1013. (<a href="https://doi.org/10.1109/TAI.2024.3507736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the data-driven event-triggered control is addressed for unknown discrete-time neural networks (DTNNs) under actuator saturation and external perturbation. The research problem is raised due to the following two reasons: 1) a practical system is often affected by external perturbations and it is costly to acquire an accurate system model; 2) the network bandwidth and the control inputs are always constrained due to physical hardware. To handle the above issues, the methodology is to first establish a model-based stability condition under the designed saturated event-triggered controller and then to transform the model-based stability condition into a data-based stability condition relying only on the perturbation-corrupted data via the extended S-lemma. The key results are: 1) a data-based DTNNs system representation is presented by collecting perturbation-corrupted state-input data. Then, a data-based stability criterion is derived and the saturated event-triggered controller is designed without an explicit system model; 2) an optimization method is presented that can maximize the estimation of attractor (EoA) and minimize the estimated domain of attraction (DoA) simultaneously. Finally, the effectiveness of the proposed approach is illustrated and some quantitative analyses are offered by two numerical examples.},
  archive      = {J_TAI},
  author       = {Yanyan Ni and Zhen Wang and Xia Huang and Hao Shen},
  doi          = {10.1109/TAI.2024.3507736},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  number       = {4},
  pages        = {1003-1013},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Data-driven event-triggered control for discrete-time neural networks subject to actuator saturation},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A temporal–spatial graph network with a learnable adjacency
matrix for appliance-level electricity consumption prediction.
<em>TAI</em>, <em>6</em>(4), 989–1002. (<a
href="https://doi.org/10.1109/TAI.2024.3507734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the electricity consumption of individual appliances, known as appliance-level energy consumption (ALEC) prediction, is essential for effective energy management and conservation. Despite its importance, research in this area is limited and faces several challenges: 1) the correlation between the usage of different appliances has rarely been considered for ALEC prediction; 2) a learnable strategy for obtaining the optimal correlation between different appliance behaviors is lacking; and 3) it is difficult to accurately quantify the usage relationship among different appliances. To address these issues, we propose a graph-based temporal–spatial network that employs a learnable adjacency matrix for appliance-level load prediction in this work. The network comprises a temporal graph convolutional network (TGCN) and a learnable adjacency matrix that enables us to utilize correlations between appliances and quantify their relationships. To validate our approach, we compared our model with six others: a TGCN model with a fixed adjacency matrix where all elements are set to 0; a TGCN model with a fixed adjacency matrix where all elements are set to 0.5, except for the diagonal; a TGCN model with a randomly generated adjacency matrix, except for the diagonal; an Aug-LSTM model; a model with ResNetPlus architecture; and a feed-forward deep neural network. Five houses in four datasets: AMPDs, REFIT, UK-DALE, and SC-EDNRR are utilized. The metrics used in this study include root mean square error, explained variance score, mean absolute error, F-norm and coefficient of determination. Our experiments have validated the accuracy and practicality of our proposed approach across different datasets.},
  archive      = {J_TAI},
  author       = {Dandan Li and Jiaxing Xia and Jiangfeng Li and Changjiang Xiao and Vladimir Stankovic and Lina Stankovic and Qingjiang Shi},
  doi          = {10.1109/TAI.2024.3507734},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  number       = {4},
  pages        = {989-1002},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {A Temporal–Spatial graph network with a learnable adjacency matrix for appliance-level electricity consumption prediction},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Industrial process monitoring based on deep gaussian and
non-gaussian information fusion framework. <em>TAI</em>, <em>6</em>(4),
979–988. (<a href="https://doi.org/10.1109/TAI.2024.3507732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For industrial process monitoring, Gaussian and non-Gaussian data-driven models are two important representatives that have been developed separately in the past years. Although several attempts have been made to combine Gaussian and non-Gaussian data information for integrated process monitoring, this information fusion strategy can be further enhanced under the idea and framework of deep learning. Particularly, through collaborative learning and layer-by-layer information transformation, more patterns of both Gaussian and non-Gaussian components can be effectively extracted in different hidden layers of the deep model. Then, a further Bayesian model fusion strategy is formulated to ensemble monitoring results from both Gaussian and non-Gaussian data-driven models. Therefore, the main contribution of this article is to propose a deep Gaussian and non-Gaussian information fusion framework for data-driven industrial process monitoring. Both feasibility and superiority of the developed model are confirmed through a detailed industrial benchmark case study. Compared to both Gaussian and non-Gaussian deep models, the new deep information fusion model has obtained more satisfactory monitoring results.},
  archive      = {J_TAI},
  author       = {Zhiqiang Ge},
  doi          = {10.1109/TAI.2024.3507732},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  number       = {4},
  pages        = {979-988},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Industrial process monitoring based on deep gaussian and non-gaussian information fusion framework},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CheckSelect: Online checkpoint selection for flexible,
accurate, robust, and efficient data valuation. <em>TAI</em>,
<em>6</em>(4), 968–978. (<a
href="https://doi.org/10.1109/TAI.2024.3506494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we argue that data valuation techniques should be flexible, accurate, robust, and efficient (FARE). Here, accuracy and efficiency refer to the notion of identification of most important data points in less time compared to full training. Flexibility refers to the ability of the method to be used with various value functions, while robustness refers to the ability to be used with different data distributions from a related domain. We propose a two-phase approach toward achieving these objectives, where the first phase, checkpoint selection, extracts important model checkpoints while training on a related dataset, and the second data valuation and subset selection (DVSS) phase extracts the high-value subsets. A key challenge in this process is to efficiently determine the most important checkpoints during the training, since the total value function is unknown. We pose this as an online sparse approximation problem and propose a novel online orthogonal matching pursuit algorithm for solving it. Extensive experiments on standard datasets show that CheckSelect provides the best accuracy among the baselines while maintaining efficiency comparable to state of the art. We also demonstrate the flexibility and robustness of CheckSelect on a standard domain adaptation task, where it outperforms existing methods in data selection accuracy without the need to retrain on the full target-domain dataset.},
  archive      = {J_TAI},
  author       = {Soumi Das and Manasvi Sagarkar and Suparna Bhattacharya and Sourangshu Bhattacharya},
  doi          = {10.1109/TAI.2024.3506494},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  number       = {4},
  pages        = {968-978},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {CheckSelect: Online checkpoint selection for flexible, accurate, robust, and efficient data valuation},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A scalable unsupervised and back propagation free learning
with SACSOM: A novel approach to SOM-based architectures. <em>TAI</em>,
<em>6</em>(4), 955–967. (<a
href="https://doi.org/10.1109/TAI.2024.3504479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of computer vision is predominantly driven by supervised models, which, despite their efficacy, are computationally expensive and often intractable for many applications. Recently, research has expedited alternative avenues such as self-organizing maps (SOM)-based architectures, which offer significant advantages such as tractability, the absence of back-propagation, and feed-forward unsupervised learning. However, these SOM-based approaches frequently suffer from lower accuracy and limited generalization capabilities. To address these shortcomings, we propose a novel model called split and concur SOM (SACSOM). SACSOM overcomes the limitations of closely related SOM-based algorithms by utilizing multiple parallel branches, each equipped with its own SOM modules that process data independently with varying patch sizes. Furthermore, by creating groups of classes and using respective training samples to train independent subbranches in each branch, our approach accommodates datasets with a large number of classes. SACSOM employs a simple yet effective labeling technique requiring minimal labeled samples. The outputs from each branch, filtered by a threshold, contribute to the final prediction. Experimental validation on MNIST-digit, Fashion-MNIST, CIFAR-10, and CIFAR-100 demonstrates that SACSOM achieves competitive accuracy with significantly reduced computation time. Furthermore, it exhibits superior performance and generalization capabilities, even in high-noise scenarios. The weights of the single-layered SACSOM provide meaningful insights into the patch-based learning pattern, enhancing its tractability and making it ideal from the perspective of explainable AI. This study addresses the limitations of current clustering techniques, such as K-means and traditional SOMs, by proposing a lightweight, manageable, and fast architecture that does not require a GPU, making it suitable for low-powered devices.},
  archive      = {J_TAI},
  author       = {Gaurav R. Hirani and Kevin I-Kai Wang and Waleed H. Abdulla},
  doi          = {10.1109/TAI.2024.3504479},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  number       = {4},
  pages        = {955-967},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {A scalable unsupervised and back propagation free learning with SACSOM: A novel approach to SOM-based architectures},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). APR-net: Defense against adversarial examples based on
universal adversarial perturbation removal network. <em>TAI</em>,
<em>6</em>(4), 945–954. (<a
href="https://doi.org/10.1109/TAI.2024.3504478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial attack, a bleeding-edge technique that attempts to fool deep learning classification model by generating adversarial examples with imperceptible perturbations, is becoming a growing threat in artificial intelligence fields. Preprocessing models that remove perturbations are an effective approach for enhancing the robustness of classification models. However, most existing methods overlook a critical issue: although powerful preprocessing operations can remove adversarial perturbations, they may also weaken the representation of key features in the image, leading to decreased defense performance. To address this, we propose a novel universal defense model, APR-Net, which aims to remove adversarial perturbations while effectively preserving high-quality images. The key innovation of APR-Net lies in its dual-module design, which consists of a denoising module and an image restoration module. This design not only effectively eliminates imperceptible adversarial perturbations but also ensures the restoration of high-quality images. Unlike existing methods, APR-Net does not require modifications to the classifier architecture or specialized adversarial training, making it highly versatile. Extensive experiments on the ImageNet dataset demonstrate that APR-Net provides strong defense against various adversarial attack algorithms, significantly improves image quality, and outperforms other state-of-the-art defense methods in terms of overall performance.},
  archive      = {J_TAI},
  author       = {Wenxing Liao and Zhuxian Liu and Minghuang Shen and Riqing Chen and Xiaolong Liu},
  doi          = {10.1109/TAI.2024.3504478},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  number       = {4},
  pages        = {945-954},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {APR-net: Defense against adversarial examples based on universal adversarial perturbation removal network},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CH-net: A cross hybrid network for medical image
segmentation. <em>TAI</em>, <em>6</em>(4), 934–944. (<a
href="https://doi.org/10.1109/TAI.2024.3503541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and automated segmentation of medical images plays a crucial role in diagnostic evaluation and treatment planning. In recent years, hybrid models have gained considerable popularity in diverse medical image segmentation tasks, as they leverage the benefits of both convolution and self-attention to capture local and global dependencies simultaneously. However, most existing hybrid models treat convolution and self-attention as independent components and integrate them using simple fusion methods, neglecting the potential complementary information between their weight allocation mechanisms. To address this issue, we propose a cross hybrid network (CH-Net) for medical image segmentation, in which convolution and self-attention are hybridized in a cross-collaborative manner. Specifically, we introduce a cross hybrid module (CHM) between the parallel convolution layer and self-attention layer in each building block of CH-Net. This module extracts attention with distinct dimensional information from convolution and self-attention, respectively, and uses this complementary information to enhance the feature representation of both components. In contrast to the traditional approach where each module learned independently, the CHM facilitates the interactive learning of complementary information between convolutional layer and self-attention layer, which significantly enhances the segmentation capabilities of the model. The superiority of our approach over various hybrid models is demonstrated through experimental evaluations conducted on three publicly available benchmarks: ACDC, synapse, and EM.},
  archive      = {J_TAI},
  author       = {Jiale Li and Aiping Liu and Wei Wei and Ruobing Qian and Xun Chen},
  doi          = {10.1109/TAI.2024.3503541},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  number       = {4},
  pages        = {934-944},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {CH-net: A cross hybrid network for medical image segmentation},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DGeC: Dynamically and globally enhanced convolution.
<em>TAI</em>, <em>6</em>(4), 921–933. (<a
href="https://doi.org/10.1109/TAI.2024.3502577">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore the reasons for the poorer feature extraction ability of vanilla convolution and discover that there mainly exist three key factors that restrict its representation capability, i.e., regular sampling, static aggregation, and limited receptive field. With the cost of extra parameters and computations, existing approaches merely alleviate part of the limitations. It drives us to seek a more lightweight operator to further improve the extracted image features. Through a closer examination of the convolution process, we discover that it is composed of two distinct interactions: spatial-wise interaction and channel-wise interaction. Based on this discovery, we decouple the convolutional blocks into these two interactions which not only reduces the parameters and computations but also enables a richer ensemble of interactions. Then, we propose the dynamically and globally enhanced convolution (DGeC), which includes several components as follows: a dynamic area perceptor block (DAP) that dynamically samples spatial cues, an adaptive global context block (AGC) that introduces the location-aware global image information, and a channel attention perceptor block (CAP) that merges different channel-wise features. The experiments on ImageNet for image classification and on COCO-2017 for object detection validate the effectiveness of DGeC. As a result, our proposed method consistently improves the performance with fewer parameters and computations. In particular, DGeC achieves a 3.1% improvement in top-1 accuracy on ImageNet dataset compared to ResNet50. Moreover, with Faster RCNN and RetinaNet, our DGeC-ResNet50 also consistently outperforms ResNet and ResNeXt.},
  archive      = {J_TAI},
  author       = {Zihang Zhang and Yuling Liu and Zhili Zhou and Gaobo Yang and Xin Liao and Q. M. Jonathan Wu},
  doi          = {10.1109/TAI.2024.3502577},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  number       = {4},
  pages        = {921-933},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {DGeC: Dynamically and globally enhanced convolution},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LoRaDIP: Low-rank adaptation with deep image prior for
generative low-light image enhancement. <em>TAI</em>, <em>6</em>(4),
909–920. (<a href="https://doi.org/10.1109/TAI.2024.3499950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents LoRaDIP, a novel low-light image enhancement (LLIE) model based on deep image priors (DIPs). While DIP-based enhancement models are known for their zero-shot learning, their expensive computational cost remains a challenge. In addressing this issue, our proposed LoRaDIP introduces a low-rank adaptation technique, significantly reducing computational expenses without compromising performance. The contributions of this work are threefold. First, we eliminate the need for estimating initial illumination and reflectance, opting instead to directly estimate the illumination map from the observed image in a generative fashion. The illumination is parameterized by a DIP network. Second, considering the overparameterization of DIP networks, we introduce a low-rank adaptation technique to decrease the number of trainable parameters, thereby reducing computational demands. Third, differing from the existing DIP-based models that rely on a preset fixed number of iterations to halt the optimization process of Retinex decomposition, we propose an automatic stopping criterion based on stable rank, preventing unnecessary iterations. LoRaDIP not only inherits the advantage of requiring only the single input image but also exhibits reduced computational costs while maintaining or even surpassing the performance of state-of-the-art models.},
  archive      = {J_TAI},
  author       = {Zunjin Zhao and Daming Shi},
  doi          = {10.1109/TAI.2024.3499950},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  number       = {4},
  pages        = {909-920},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {LoRaDIP: Low-rank adaptation with deep image prior for generative low-light image enhancement},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiobjective optimization for traveling salesman problem:
A deep reinforcement learning algorithm via transfer learning.
<em>TAI</em>, <em>6</em>(4), 896–908. (<a
href="https://doi.org/10.1109/TAI.2024.3499946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A wide range of real applications can be modelled as the multiobjective traveling salesman problem (MOTSP), one of typical combinatorial optimization problems. Meta-heuristics can be used to address MOTSP. However, due to involving iteratively searching large solution space, they often entail significant computation time. Recently, deep reinforcement learning (DRL) algorithms have been employed in generating approximate optimal solutions to the single objective traveling salesman problems, as well as MOTSPs. This study proposes a multiobjective optimization algorithm based on DRL, called multiobjective pointer network (MOPN), where the input structure of the pointer network is redesigned to be applied to MOTSP. Furthermore, a training strategy utilizing a representative model and transfer learning is introduced to enhance the performance of MOPN. The proposed MOPN is insensitive to problem scale, meaning that a trained MOPN can address MOTSPs with different scales. Compared to meta-heuristics, MOPN takes much less time on forward propagation to obtain the pareto front. To verify the performance of our model, extensive experiments are conducted on three different MOTSPs to compare the MOPN with two state-of-the-art DRL models and two multiobjective meta-heuristics. Experimental results demonstrate that the proposed MOPN obtains the best solution with the least training time among all the compared DRL methods.},
  archive      = {J_TAI},
  author       = {Le-yang Gao and Rui Wang and Zhao-hong Jia and Chuang Liu},
  doi          = {10.1109/TAI.2024.3499946},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  number       = {4},
  pages        = {896-908},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Multiobjective optimization for traveling salesman problem: A deep reinforcement learning algorithm via transfer learning},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FAST: Feature aware similarity thresholding for weak
unlearning in black-box generative models. <em>TAI</em>, <em>6</em>(4),
885–895. (<a href="https://doi.org/10.1109/TAI.2024.3499939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The heightened emphasis on the regulation of deep generative models, propelled by escalating concerns pertaining to privacy and compliance with regulatory frameworks, underscores the imperative need for precise control mechanisms over these models. This urgency is particularly underscored by instances in which generative models generate outputs that encompass objectionable, offensive, or potentially injurious content. In response, machine unlearning has emerged to selectively forget specific knowledge or remove the influence of undesirable data subsets from pretrained models. However, modern machine unlearning approaches typically assume access to model parameters and architectural details during unlearning, which is not always feasible. In multitude of downstream tasks, these models function as black-box systems, with inaccessible pretrained parameters, architectures, and training data. In such scenarios, the possibility of filtering undesired outputs becomes a practical alternative. Our proposed method feature aware similarity thresholding (FAST) effectively suppresses undesired outputs by systematically encoding the representation of unwanted features in the latent space. We employ user-marked positive and negative samples to guide this process, leveraging the latent space&#39;s inherent capacity to capture these undesired representations. During inference, we use this identified representation in the latent space to compute projection similarity metrics with newly sampled latent vectors. Subsequently, we meticulously apply a threshold to exclude undesirable samples from the output.},
  archive      = {J_TAI},
  author       = {Subhodip Panda and A.P. Prathosh},
  doi          = {10.1109/TAI.2024.3499939},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  number       = {4},
  pages        = {885-895},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {FAST: Feature aware similarity thresholding for weak unlearning in black-box generative models},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active robust adversarial reinforcement learning under
temporally coupled perturbations. <em>TAI</em>, <em>6</em>(4), 874–884.
(<a href="https://doi.org/10.1109/TAI.2024.3499938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust reinforcement learning (RL) aims to improve the generalization of agents under model mismatch. As a major branch of robust RL, adversarial approaches formulate the problem as a zero-sum game in which adversaries seek to apply worst case perturbations to the dynamics. However, the potential constraints of adversarial perturbations are seldom addressed in existing approaches. In this article, we consider temporally coupled settings, where adversarial perturbations change continuously at a bounded rate. This kind of constraint can commonly arise in a variety of real-world situations (e.g., changes in wind speed and ocean currents). We propose a novel robust RL approach, named active robust adversarial RL (ARA-RL), that tackles this problem in an adversarial architecture. First, we introduce a type of RL adversary that generates temporally coupled perturbations on agent actions. Then, we embed a diagnostic module in the RL agent, enabling it to actively detect temporally coupled perturbations in unseen environments. Through adversarial training, the agent seeks to maximize its worst case performance and thus achieve robustness under perturbations. Finally, extensive experiments demonstrate that our proposed approach provides significant robustness against temporally coupled perturbations and outperforms other baselines on several continuous control tasks.},
  archive      = {J_TAI},
  author       = {Jiacheng Yang and Yuanda Wang and Lu Dong and Lei Xue and Changyin Sun},
  doi          = {10.1109/TAI.2024.3499938},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  number       = {4},
  pages        = {874-884},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Active robust adversarial reinforcement learning under temporally coupled perturbations},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HGFF: A deep reinforcement learning framework for lifetime
maximization in wireless sensor networks. <em>TAI</em>, <em>6</em>(4),
859–873. (<a href="https://doi.org/10.1109/TAI.2024.3497926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Planning the movement of the sink to maximize the lifetime in wireless sensor networks (WSNs) is an essential problem. Many existing mobile sink techniques based on mathematical programming or heuristics have demonstrated the feasibility of the task. Nevertheless, the huge computational cost or the over-reliance on human knowledge can result in relatively low performance. To balance the need for high-quality solutions to minimize inference time, we propose a new framework to construct the movement path of the sink automatically. We cast the lifetime maximization problem as an optimization task within a heterogeneous graph and learn movement policy for the sink by combining graph neural network (GNN) with deep reinforcement learning. Our approach comprises three key modules: 1) a heterogeneous GNN to learn representations of sites and sensors by aggregating features of neighbor nodes and extracting hierarchical graph features; 2) a multihead attention mechanism that allows the sites to attend to information from sensor nodes, which highly improves the expressive capacity of the learning model; and 3) a greedy policy that learns to append the next best site in the solution incrementally. We design twelve types of static and dynamic maps to simulate different WSNs in the real world, and extensive experiments are conducted to evaluate and analyze our approach. The empirical results show that our approach consistently outperforms the existing methods on all types of maps. Notably, our approach significantly extends the simulation lifetime without sacrificing a large increase in inference time.},
  archive      = {J_TAI},
  author       = {Xiaoxu Han and Xin Mu and Jinghui Zhong},
  doi          = {10.1109/TAI.2024.3497926},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  number       = {4},
  pages        = {859-873},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {HGFF: A deep reinforcement learning framework for lifetime maximization in wireless sensor networks},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analyzing hierarchical relationships and quality of
embedding in latent space. <em>TAI</em>, <em>6</em>(4), 843–858. (<a
href="https://doi.org/10.1109/TAI.2024.3497921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing learning models partition the generated representations using hyperplanes which form well defined groups of similar embeddings that is uniquely mapped to a particular class. However, in practical applications, the embedding space does not form distinct boundaries to segregate the class representations. There exists interaction among similar classes which cannot be visually determined in high-dimensional space. Moreover, the structure of the latent space remains obscure. As learned representations are frequently reused to reduce the inference time, it is important to analyse how semantically related classes interact among themselves in the latent space. Therefore, we propose a boundary estimation algorithm that minimises the inclusion of other classes in the embedding space to form groups of similar representations and compare the quality of these class embeddings for various models in an already encoded space. These groups are overlapping to denote ambiguous embeddings that cannot be mapped to a particular class with high confidence. The algorithm determines which representations to be included or discarded to form well defined regions, separating discriminating, ambiguous and rejected embeddings to depict a particular class. Later, we construct relation trees to evaluate the hierarchical relationships formed among the classes, and compare it with the WordNet ontology using phylogenetic tree comparison methods.},
  archive      = {J_TAI},
  author       = {Ankita Chatterjee and Jayanta Mukherjee and Partha Pratim Das},
  doi          = {10.1109/TAI.2024.3497921},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  number       = {4},
  pages        = {843-858},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Analyzing hierarchical relationships and quality of embedding in latent space},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Safe multiagent reinforcement learning with bilevel
optimization in autonomous driving. <em>TAI</em>, <em>6</em>(4),
829–842. (<a href="https://doi.org/10.1109/TAI.2024.3497919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring safety in multiagent reinforcement learning (MARL), particularly when deploying it in real-world applications such as autonomous driving, emerges as a critical challenge. To address this challenge, traditional safe MARL methods extend MARL approaches to incorporate safety considerations, aiming to minimize safety risk values. However, these safe MARL algorithms often fail to model other agents and lack convergence guarantees, particularly in dynamically complex environments. In this study, we propose a safe MARL method grounded in a Stackelberg model with bilevel optimization, for which convergence analysis is provided. Derived from our theoretical analysis, we develop two practical algorithms, namely constrained Stackelberg Q-learning (CSQ) and constrained Stackelberg multiagent deep deterministic policy gradient (CS-MADDPG), designed to facilitate MARL decision-making in some simulated autonomous driving applications such as traffic management. To evaluate the effectiveness of our algorithms, we developed a safe MARL autonomous driving benchmark and conducted experiments on challenging autonomous driving scenarios, such as merges, roundabouts, intersections, and racetracks. The experimental results indicate that our algorithms, CSQ and CS-MADDPG, outperform several strong MARL baselines, such as Bi-AC, MACPO, and MAPPO-L, regarding reward and safety performance.},
  archive      = {J_TAI},
  author       = {Zhi Zheng and Shangding Gu},
  doi          = {10.1109/TAI.2024.3497919},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  number       = {4},
  pages        = {829-842},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Safe multiagent reinforcement learning with bilevel optimization in autonomous driving},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generation with nuanced changes: Continuous image-to-image
translation with adversarial preferences. <em>TAI</em>, <em>6</em>(4),
816–828. (<a href="https://doi.org/10.1109/TAI.2024.3497915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most previous methods for continuous image-to-image translation resorted to binary attributes with restrictive description ability and thus cannot achieve satisfactory performance. Some works proposed to use fine-grained semantic information, relative attributes (RAs), preferences over pairs of images on the strength of a specified attribute. However, they still failed to reconcile both goals for smooth translation and for high-quality generation simultaneously. In this work, we propose a new model continuous translation via adversarial preferences (CTAP) to coordinate these two goals for high-quality continuous translation based on RAs. In CTAP, we simultaneously train two modules: a generator that translates an input image to the desired image with smooth nuanced changes w.r.t. the interested attributes; and a ranker that executes adversarial preferences consisting of the input image and the desired image. Particularly, adversarial preferences involve an adversarial ranking process: 1) the ranker thinks no difference between the desired image and the input image in terms of the interested attributes; 2) the generator fools the ranker to believe the attributes of its output image changes as expect compared with the input image. RAs over pairs of real images are introduced to guide the ranker to rank image pairs regarding the interested attributes only. With an effective ranker, the generator would “win” the adversarial game by producing high-quality images that present smooth changes. The experiments on two face datasets and one shoe dataset demonstrate that our CTAP achieves state-of-art results in generating high-fidelity images which exhibit smooth changes over the interested attributes.},
  archive      = {J_TAI},
  author       = {Yinghua Yao and Yuangang Pan and Ivor W. Tsang and Xin Yao},
  doi          = {10.1109/TAI.2024.3497915},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  number       = {4},
  pages        = {816-828},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Generation with nuanced changes: Continuous image-to-image translation with adversarial preferences},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial masked autoencoders are robust vision learners.
<em>TAI</em>, <em>6</em>(4), 805–815. (<a
href="https://doi.org/10.1109/TAI.2024.3497912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised learning, specifically masked image modeling, has achieved significant success, surpassing earlier contrastive learning methods. However, the robustness of these methods against adversarial attacks, which subtly manipulate inputs to mislead models, remains largely unexplored. This study investigates the adversarial robustness of self-supervised learning methods, exposing their vulnerabilities to various adversarial attacks. We introduce adversarial masked autoencoders (AMAEs), a novel framework designed to enforce adversarial robustness during the masked image modeling process. Through extensive experiments on four classification benchmarks involving eight different adversarial attacks, we demonstrate that AMAE consistently outperforms seven state-of-the-art baseline self-supervised learning methods in terms of adversarial robustness.},
  archive      = {J_TAI},
  author       = {Yuchong Yao and Nandakishor Desai and Marimuthu Palaniswami},
  doi          = {10.1109/TAI.2024.3497912},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  number       = {4},
  pages        = {805-815},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Adversarial masked autoencoders are robust vision learners},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consistent counterfactual explanations via anomaly control
and data coherence. <em>TAI</em>, <em>6</em>(4), 794–804. (<a
href="https://doi.org/10.1109/TAI.2024.3496616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Algorithmic recourses are popular methods to provide individuals impacted by machine learning models with recommendations on feasible actions for a more favorable prediction. Most of the previous algorithmic recourse methods work under the assumption that the predictive model does not change over time. However, in reality, models in deployment may both be periodically retrained and have their architecture changed. Therefore, it is desirable that the recourse should remain valid when such a model update occurs, unless new evidence arises. We call this feature consistency. This article presents anomaly control and data coherence (ACDC), a novel model-agnostic recourse method that generates counterfactual explanations, i.e., instance-level recourses. ACDC is inspired by anomaly detection methods and uses a one-class classifier to aid the search for valid, consistent, and feasible counterfactual explanations. The one-class classifier asserts that the generated counterfactual explanations lie on the data manifold and are not outliers of the target class. We compare ACDC against several state-of-the-art recourse methods across four datasets. Our experiments show that ACDC outperforms baselines both in generating consistent counterfactual explanations, and in generating feasible and plausible counterfactual explanations, while still having proximity measures similar to the baseline methods targeting the data manifold.},
  archive      = {J_TAI},
  author       = {Maria Movin and Federico Siciliano and Rui Ferreira and Fabrizio Silvestri and Gabriele Tolomei},
  doi          = {10.1109/TAI.2024.3496616},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  number       = {4},
  pages        = {794-804},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Consistent counterfactual explanations via anomaly control and data coherence},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
