<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TEVC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tevc---20">TEVC - 20</h2>
<ul>
<li><details>
<summary>
(2025). Characterization of constrained continuous multiobjective
optimization problems: A performance space perspective. <em>TEVC</em>,
<em>29</em>(1), 275–285. (<a
href="https://doi.org/10.1109/TEVC.2024.3366659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multiobjective optimization has gained much interest in the past few years. However, constrained multiobjective optimization problems (CMOPs) are still unsatisfactorily understood. Consequently, the choice of adequate CMOPs for benchmarking is difficult and lacks a formal background. This article takes a step toward addressing this issue by exploring CMOPs from a performance space perspective. First, it presents a novel performance assessment approach designed explicitly for constrained multiobjective optimization. This methodology offers a first attempt at simultaneously measuring the performance in approximating the Pareto front and constraint satisfaction. Second, it proposes an approach to measure the capability of the given optimization problem to differentiate among algorithm performances. Finally, this approach is used to compare eight frequently used artificial test suites of CMOPs. The experimental results reveal which suites are more efficient in discerning between four well-known multiobjective optimization algorithms.},
  archive      = {J_TEVC},
  author       = {Aljoša Vodopija and Tea Tušar and Bogdan Filipič},
  doi          = {10.1109/TEVC.2024.3366659},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {275-285},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Characterization of constrained continuous multiobjective optimization problems: A performance space perspective},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Determining metaheuristic similarity using behavioral
analysis. <em>TEVC</em>, <em>29</em>(1), 262–274. (<a
href="https://doi.org/10.1109/TEVC.2023.3346672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many nature-inspired metaheuristics have been published, with claims of originality based on the metaphor that inspired the algorithm. Rarely is empirical evidence given to show algorithmic originality. In order to provide an easy and computationally cheap approach to characterize algorithm search behavior, a suite of 20 behavioral characteristics is proposed. This behavioral characteristic suite allows for the search behavior of an algorithm to be quantified without manual inspection. By doing so, behavioral novelty of any given algorithm may be determined by comparing the behavioral characteristics to those of well-known metaheuristics. To illustrate this use, and to evaluate whether metaheuristics are behaviorally distinct, a host of metaheuristics is run on various benchmark functions. To evaluate behavioral similarity across all problems, while acknowledging behavior to be problem dependant, a novel method is proposed. In addition to this method, new behavioral characteristics are also proposed. The behavioral vectors generated for each benchmark function are clustered. The relationships and trends present in the different clusters are summarized by creating a pair-wise matrix for every metaheuristic pair, which tallies the number of times that the pair are found within the same cluster. The tallies are then analyzed in order to make inference regarding the distinctness of any metaheuristic’s behaviors, across many different benchmark functions. The analysis finds that the range of unique search behaviors is small and that most metaheuristics share their behaviors with most other metaheuristics. The analysis also identifies both unique algorithms, as well as algorithms which have no unique behaviors.},
  archive      = {J_TEVC},
  author       = {Lauren Hayward and Andries Engelbrecht},
  doi          = {10.1109/TEVC.2023.3346672},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {262-274},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Determining metaheuristic similarity using behavioral analysis},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A flexible ranking-based competitive swarm optimizer for
large-scale continuous multiobjective optimization. <em>TEVC</em>,
<em>29</em>(1), 247–261. (<a
href="https://doi.org/10.1109/TEVC.2024.3355221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the curse of dimensionality, the search efficiency of existing operators in large-scale decision space deteriorates dramatically. The competitive swarm optimizer (CSO)-based framework has great potential in tackling large-scale single-objective optimization problems. However, the existing CSOs only focus on the loser to winner learning paradigm and neglect the significance of the winner determination mechanism for large-scale search, which makes the algorithm difficult to escape from local optima. To remedy this issue, a flexible ranking-based CSO has been tailored for handling large-scale multiobjective optimization problems (MOPs). Concretely, a novel winner determination strategy is introduced to broadly identify high-quality individuals in the population to enhance diversity maintenance. In addition, a special competitive mechanism is adopted to guide the search direction, which is capable of efficiently increasing search space utilization. The simulation results validate that the proposed algorithm can significantly enhance the exploration and exploitation ability of the conventional CSO, and outperforms several state-of-the-art large-scale multiobjective optimization algorithms on both large-scale benchmark MOPs and application examples.},
  archive      = {J_TEVC},
  author       = {Xiangzhou Gao and Shenmin Song and Hu Zhang and Zhenkun Wang},
  doi          = {10.1109/TEVC.2024.3355221},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {247-261},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A flexible ranking-based competitive swarm optimizer for large-scale continuous multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bi-learning evolutionary algorithm for
transportation-constrained and distributed energy-efficient flexible
scheduling. <em>TEVC</em>, <em>29</em>(1), 232–246. (<a
href="https://doi.org/10.1109/TEVC.2024.3354850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of globalization and environmental concerns, distributed scheduling and energy-efficient scheduling have become crucial topics in the informational manufacturing system. Additionally, the growing consideration about realistic constraints, such as transportation time and finite transportation resources, has made the scheduling problem increasingly complex. Facing these challenges, special mechanisms are required to improve the efficiency of solving algorithms. In this article, a bi-learning evolutionary algorithm (BLEA) is proposed to solve the distributed energy-efficient flexible job shop problem with transportation constraints (DEFJSP-T). First, we integrate statistical learning (SL) and evolutionary learning (EL) in the framework, while decomposition and Pareto dominance methods are employed in different stages to handle conflicting objectives. During the SL stage, probability models are established to statistically search for advantageous substructures on each weight vector, and an update mechanism is devised to improve the exploration. In the EL stage, the genetic operators are introduced and an improved local search that takes into account the problem properties is proposed to realize sufficient exploitation. Finally, according to the performance of the SL, a novel switching mechanism between SL and EL is designed to ensure the rational allocation of computing resources. Extensive experiments are conducted to test the performances of the BLEA. The statistical comparison shows that the BLEA is superior in solving the DEFJSP-T in terms of efficiency and effectiveness.},
  archive      = {J_TEVC},
  author       = {Zixiao Pan and Ling Wang and Jingjing Wang and Qingfu Zhang},
  doi          = {10.1109/TEVC.2024.3354850},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {232-246},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A bi-learning evolutionary algorithm for transportation-constrained and distributed energy-efficient flexible scheduling},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward evolving dispatching rules with flow control
operations by grammar-guided linear genetic programming. <em>TEVC</em>,
<em>29</em>(1), 217–231. (<a
href="https://doi.org/10.1109/TEVC.2024.3353207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LGP has been successfully applied to dynamic job shop scheduling (DJSS) to automatically evolve dispatching rules. Flow control operations are crucial in concisely describing complex knowledge of dispatching rules, such as different dispatching rules in different conditions. However, existing linear genetic programming (LGP) methods for DJSS have not fully considered the use of flow control operations. They simply included flow control operations in their primitive set, which inevitably leads to a huge number of redundant and obscure solutions in LGP search spaces. To move one step toward evolving effective and interpretable dispatching rules, this article explicitly considers the characteristics of flow control operations via grammar-guided LGP and focuses on IF operations as a starting point. Specifically, this article designs a new set of normalized terminals to improve the interpretability of IF operations and proposes three restrictions by grammar rules on the usage of IF operations: 1) specifying the available inputs; 2) the maximum number; and 3) the possible locations of IF operations. The experiment results verify that the proposed method can achieve significantly better-test performance than state-of-the-art LGP methods and improves interpretability by IF-included dispatching rules. Further investigation confirms that the explicit introduction of IF operations helps effectively evolve different dispatching rules according to their decision situations.},
  archive      = {J_TEVC},
  author       = {Zhixing Huang and Yi Mei and Fangfang Zhang and Mengjie Zhang},
  doi          = {10.1109/TEVC.2024.3353207},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {217-231},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Toward evolving dispatching rules with flow control operations by grammar-guided linear genetic programming},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiobjective multitask optimization with multiple
knowledge types and transfer adaptation. <em>TEVC</em>, <em>29</em>(1),
205–216. (<a href="https://doi.org/10.1109/TEVC.2024.3353319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary multitasking (EMT) exploits the correlation among different tasks to help handle them through knowledge transfer (KT) techniques in evolutionary algorithms. In this area, multiobjective multitask optimization (MO-MTO) utilizes EMT to solve multiple multiobjective optimization tasks simultaneously. The key to addressing MO-MTO problems (MO-MTOPs) is to transfer appropriate knowledge among optimization tasks to assist the multiobjective evolutionary process. Both the type and the amount of knowledge can significantly affect the KT process. To achieve better KT behavior, we propose a multiple knowledge types and transfer adaptation (MKTA) framework for handling MO-MTOPs. The MKTA framework incorporates multiple types of knowledge in order to obtain comprehensive KT performance. It also provides transfer adaptation strategies to control: 1) the type of knowledge and 2) the amount of knowledge for KT via parameter adaptation approaches, thereby mitigating negative KT. Furthermore, we propose an evolution-path-model-based knowledge type and incorporate the existing unified-search-space-based knowledge type to form the knowledge pool for MKTA. Finally, the MKTA framework is coupled with a ranking-based differential evolution operator to constitute the complete algorithm MTDE-MKTA. In the experimental study, MTDE-MKTA outperformed ten advanced algorithms on 39 benchmark MO-MTOPs and six groups of realworld application problems.},
  archive      = {J_TEVC},
  author       = {Yanchi Li and Wenyin Gong},
  doi          = {10.1109/TEVC.2024.3353319},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {205-216},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiobjective multitask optimization with multiple knowledge types and transfer adaptation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Benchmarking derivative-free global optimization algorithms
under limited dimensions and large evaluation budgets. <em>TEVC</em>,
<em>29</em>(1), 187–204. (<a
href="https://doi.org/10.1109/TEVC.2024.3379756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the challenge of selecting the most suitable optimization algorithm by presenting a comprehensive computational comparison between stochastic and deterministic methods. The complexity of algorithm selection arises from the absence of a universal algorithm and the abundance of available options. Manual selection without comprehensive studies can lead to suboptimal or incorrect results. In order to address this issue, we carefully selected 25 promising and representative state-of-the-art algorithms from both aforementioned classes. The evaluation with up to the 20 dimensions and large evaluation budgets $(10^{5}{\times }n)$ was carried out in a significantly expanded and improved version of the DIRECTGOLib v2.0 library, which included ten distinct collections of primarily continuous test functions. The evaluation covered various aspects, such as solution quality, time complexity, and function evaluation usage. The rankings were determined using statistical tests and performance profiles. When it comes to the problems and algorithms examined in this study, EA4eig, EBOwithCMAR, APGSK-IMODE, 1-DTC-GL, OQNLP, and DIRMIN stand out as superior to other derivative-free solvers in terms of solution quality. While deterministic algorithms can locate reasonable solutions with comparatively fewer function evaluations, most stochastic algorithms require more extensive evaluation budgets to deliver comparable results. However, the performance of stochastic algorithms tends to excel in more complex and higher-dimensional problems. These research findings offer valuable insights for practitioners and researchers, enabling them to tackle diverse optimization problems effectively.},
  archive      = {J_TEVC},
  author       = {Linas Stripinis and Jakub Kůdela and Remigijus Paulavičius},
  doi          = {10.1109/TEVC.2024.3379756},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {187-204},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Benchmarking derivative-free global optimization algorithms under limited dimensions and large evaluation budgets},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple tasks for multiple objectives: A new multiobjective
optimization method via multitask optimization. <em>TEVC</em>,
<em>29</em>(1), 172–186. (<a
href="https://doi.org/10.1109/TEVC.2023.3294307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handling conflicting objectives and finding multiple Pareto optimal solutions are two challenging issues in solving multiobjective optimization problems (MOPs). Inspired by the efficiency of multitask optimization (MTO) in finding multiple optimal solutions of MTO problem (MTOP), we propose to treat MOP as a MTOP and solve it by using MTO. By transforming the MOP into a MTOP, not only that the difficulty in handling conflicting objectives can be avoided, but also that MTO can help efficiently find well-distributed multiple optimal solutions for MOP. With the above idea, this article proposes a new multiobjective optimization method via MTO, with the following three contributions: 1) a theorem is proposed to theoretically show the relationship between MOP and MTOP and how MOP can be transformed into a MTOP; 2) based on the theoretical analysis, a multiple tasks for multiple objectives (MTMOs) framework is proposed for solving MOP efficiently; and 3) a MTMO-based evolutionary algorithm is developed to solve MOP, together with two novel strategies. One is a target point estimation strategy for transforming the MOP into a MTOP automatically and accurately. The other is an archive-based implicit knowledge transfer strategy for efficiently transferring knowledge across multiple tasks to enhance the optimization results of multiple tasks together. The superiority of the proposed algorithm is validated in extensive experiments on 15 MOPs with objective numbers varying from 3 to 20 and with six state-of-the-art algorithms as competitors. Therefore, solving MOP and even many-objective optimization problem via MTO is a new, promising, and efficient method.},
  archive      = {J_TEVC},
  author       = {Jian-Yu Li and Zhi-Hui Zhan and Yun Li and Jun Zhang},
  doi          = {10.1109/TEVC.2023.3294307},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {172-186},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiple tasks for multiple objectives: A new multiobjective optimization method via multitask optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Locating drone stations for a truck-drone delivery system in
continuous space. <em>TEVC</em>, <em>29</em>(1), 158–171. (<a
href="https://doi.org/10.1109/TEVC.2023.3344350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Truck-drone delivery systems have been proposed for sustainable and economical last-mile distribution, especially in urban environments. To widen the service range, some works have recommended adding facilities, such as drone stations, considering the problem in discrete space by choosing from a predefined set. In this article, an evolutionary optimization approach to the design decision of where to locate drone stations in the continuous plane is introduced, modeled, and solved. Drone stations serve as facilities for storage, charging, and launching. A truck (or other land transport means) transports parcels to the drone stations from a depot and the drones launch from the stations and deliver the parcels to each customer. The objective is to determine the positions of the drone stations in 2-D space and establish the shortest fixed truck route from the depot through all the stations and returning to the depot. The problem is constrained by the radius of service for each drone and all customers must be served, if possible. We formulate the problem as a constrained nonlinear optimization problem and present two versions of an algorithm using particle swarm optimization (PSO) with a subordinate dynamic program. Computational results show that our approach achieves much better results than a standard commercial nonlinear solver in a similar amount of computational time for both maximizing coverage of customers and minimizing distance of the truck delivery route. A design case study concerning healthcare delivery throughout the Birmingham, Alabama (USA) metropolitan area is provided.},
  archive      = {J_TEVC},
  author       = {Lingyun Zhou and Daniel F. Silva and Alice E. Smith},
  doi          = {10.1109/TEVC.2023.3344350},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {158-171},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Locating drone stations for a truck-drone delivery system in continuous space},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finding the set of nearly optimal solutions of a
multiobjective optimization problem. <em>TEVC</em>, <em>29</em>(1),
145–157. (<a href="https://doi.org/10.1109/TEVC.2024.3353546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary multiobjective optimization (EMO) is a highly active research field that has attracted many researchers and practitioners over the past three decades. Surprisingly, until now, the goal of almost all EMO algorithms is to compute a suitable finite size representation of the Pareto set/front of a given multiobjective optimization problem or at least a part of it. In other words, the quest is restricted to optimal solutions. In this work, we argue that the entire set of nearly optimal solutions—which includes all optimal ones—is of potential interest for the decision maker as they contain in addition to the optimal solutions alternative realizations or backup solutions. We further make a first effort to reliably compute the set of nearly optimal solutions via EMO algorithms. To this end, we first propose a new set of interest, $N_{Q,\epsilon }$ , and analyze its topology. In a next step, we propose an unbounded archiver that aims to capture $N_{Q,\epsilon }$ and analyze it with respect to monotonicity and limit behavior. After this, we discuss the related subset selection problem which comes with unbounded archivers leading to four different algorithms. Finally, we numerically investigate the behavior of the archiver and the selection strategies, and present some results when using the archiver as external archiver to three widely used multiobjective evolutionary algorithms indicating the benefit of the new approach.},
  archive      = {J_TEVC},
  author       = {Oliver Schütze and Angel E. Rodríguez-Fernandez and Carlos Segura and Carlos Hernández},
  doi          = {10.1109/TEVC.2024.3353546},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {145-157},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Finding the set of nearly optimal solutions of a multiobjective optimization problem},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary multitask optimization with lower confidence
bound-based solution selection strategy. <em>TEVC</em>, <em>29</em>(1),
132–144. (<a href="https://doi.org/10.1109/TEVC.2023.3349250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary multitasking (EMT) is an emerging research direction within the evolutionary computation community, attempting to concurrently solve multiple optimization tasks by exploiting the underlying synergies between the tasks. Recently, numerous explicit transfer strategies have been developed for enhancing positive transfer among optimization tasks. Nevertheless, most of these methods conduct knowledge transfer by transferring the best solutions from a source task to the target task, while ignoring the proper use of information from the target task in solution selection. As a result, the transferred solutions could not well adapt to the target task, thus limiting the effectiveness of knowledge transfer across tasks. To address this issue, this article proposes a solution selection method based on the lower confidence bound (LCB) for EMT, which is designed by leveraging task-specific information of both source and target tasks. With the proposed LCB metric, a number of high-quality solutions that could be more helpful for the target task can be selected and transferred to enhance positive transfer in EMT. To verify the effectiveness of the proposed approach, the solution selection method is embedded into several existing EMT algorithms and then evaluated on the single-objective multitasking benchmarks, the multiobjective multitasking benchmark, and a real-world application. The obtained results confirmed the generality and efficacy of the proposed solution selection approach.},
  archive      = {J_TEVC},
  author       = {Zhenzhong Wang and Lulu Cao and Liang Feng and Min Jiang and Kay Chen Tan},
  doi          = {10.1109/TEVC.2023.3349250},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {132-144},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary multitask optimization with lower confidence bound-based solution selection strategy},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Speeding-up evolutionary algorithms to solve black-box
optimization problems. <em>TEVC</em>, <em>29</em>(1), 117–131. (<a
href="https://doi.org/10.1109/TEVC.2024.3352450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Population-based evolutionary algorithms are often considered when approaching computationally expensive black-box optimization problems. They employ a selection mechanism to choose the best solutions from a given population after comparing their objective values, which are then used to generate the next population. This iterative process explores the solution space efficiently, leading to improved solutions over time. However, one of the challenges of these algorithms is that they require a large number of evaluations to provide a quality solution, which might be computationally expensive when the evaluation cost is high. In some cases, it is possible to replace the original objective function with a less accurate approximation of lower cost. This introduces a tradeoff between the evaluation cost and its accuracy. In this article, we propose a technique capable of choosing an appropriate approximate function cost during the execution of the optimization algorithm. The proposal finds the minimum evaluation cost at which the solutions are still properly ranked, and consequently, more evaluations can be computed in the same amount of time with minimal accuracy loss. An experimental section on four very different problems reveals that the proposed approach can reach the same objective value in less than half of the time in certain cases.},
  archive      = {J_TEVC},
  author       = {Judith Echevarrieta and Etor Arza and Aritz Pérez},
  doi          = {10.1109/TEVC.2024.3352450},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {117-131},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Speeding-up evolutionary algorithms to solve black-box optimization problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ExTrEMO: Transfer evolutionary multiobjective optimization
with proof of faster convergence. <em>TEVC</em>, <em>29</em>(1),
102–116. (<a href="https://doi.org/10.1109/TEVC.2023.3349313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer multiobjective optimization promises sample-efficient discovery of near Pareto-optimal solutions to a target task by utilizing experiential priors from related source tasks. In this article, we show that in domains where evaluation data is at a premium, e.g., in scientific and engineering disciplines involving time-consuming computer simulations or complex real-world experimentation, knowledge transfer through surrogate models can be pivotal in saving sample evaluation costs. While state-of-the-art algorithms (without transfer) typically assume budgets in the order of only a few hundred evaluations, we seek to explore how far we can get on even tighter budgets. The uniqueness of our proposed expensive transfer evolutionary multiobjective optimizer (ExTrEMO) is that it can maximally utilize external information from hundreds of source datasets, including those that may be negatively correlated with the target task. This is achieved by melding evolutionary search with factorized transfer Gaussian process surrogates, capturing varied source-target correlations in potentially decentralized computation environments. We provide a regret bound analysis for ExTrEMO that translates to a theoretical proof of increasingly faster convergence as a result of multisource transfers. The theory is experimentally verified on benchmark functions and toward accelerated design of biomedical microdevices. We release our code at https://github.com/LiuJ-2023/ExTrEMO.},
  archive      = {J_TEVC},
  author       = {Jiao Liu and Abhishek Gupta and Chinchun Ooi and Yew-Soon Ong},
  doi          = {10.1109/TEVC.2023.3349313},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {102-116},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {ExTrEMO: Transfer evolutionary multiobjective optimization with proof of faster convergence},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing with low budgets: A comparison on the black-box
optimization benchmarking suite and OpenAI gym. <em>TEVC</em>,
<em>29</em>(1), 91–101. (<a
href="https://doi.org/10.1109/TEVC.2023.3346788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing ubiquity of machine learning (ML) has led it to enter various areas of computer science, including black-box optimization (BBO). Recent research is particularly concerned with Bayesian optimization (BO). BO-based algorithms are popular in the ML community, as they are used for hyperparameter optimization and more generally for algorithm configuration. However, their efficiency decreases as the dimensionality of the problem and the budget of evaluations increase. Meanwhile, derivative-free optimization methods have evolved independently in the optimization community. Therefore, we urge to understand whether cross-fertilization is possible between the two communities, ML and BBO, i.e., whether algorithms that are heavily used in ML also work well in BBO and vice versa. Comparative experiments often involve rather small benchmarks and show visible problems in the experimental setup, such as poor initialization of baselines, overfitting due to problem-specific setting of hyperparameters, and low statistical significance. With this article, we update and extend a comparative study presented by Hutter et al. in 2013. We compare BBO tools for ML with more classical heuristics, first on the well-known Black-Box Optimization Benchmarking test suite from the COCO environment and then on Direct Policy Search for OpenAI Gym, a reinforcement learning benchmark. Our results confirm that BO-based optimizers perform well on both benchmarks when budgets are limited, albeit with a higher computational cost, while they are often outperformed by algorithms from other families when the evaluation budget becomes larger. We also show that some algorithms from the BBO community perform surprisingly well on ML tasks.},
  archive      = {J_TEVC},
  author       = {Elena Raponi and Nathanaël Carraz Rakotonirina and Jérémy Rapin and Carola Doerr and Olivier Teytaud},
  doi          = {10.1109/TEVC.2023.3346788},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {91-101},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Optimizing with low budgets: A comparison on the black-box optimization benchmarking suite and OpenAI gym},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary multiobjective optimization for large-scale
portfolio selection with both random and uncertain returns.
<em>TEVC</em>, <em>29</em>(1), 76–90. (<a
href="https://doi.org/10.1109/TEVC.2023.3349073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of Big Data, managing large-scale portfolios of thousands of securities is one of the most challenging tasks in the asset management industry. This study uses an evolutionary multiobjective technique to solve large-scale portfolio optimization problems with both long-term listed and newly listed securities. The future returns of long-term listed securities are defined as random variables whose probability distributions are estimated based on sufficient historical data, while the returns of newly listed securities are defined as uncertain variables whose uncertainty distributions are estimated based on experts’ knowledge. Our approach defines security returns as theoretically uncertain random variables and proposes a three-moment optimization model with practical trading constraints. In this study, a framework for applying arbitrary multiobjective evolutionary algorithms to portfolio optimization is established, and a novel evolutionary algorithm based on large-scale optimization techniques is developed to solve the proposed model. The experimental results show that the proposed algorithm outperforms state-of-the-art evolutionary algorithms in large-scale portfolio optimization.},
  archive      = {J_TEVC},
  author       = {Weilong Liu and Yong Zhang and Kailong Liu and Barry Quinn and Xingyu Yang and Qiao Peng},
  doi          = {10.1109/TEVC.2023.3349073},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {76-90},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary multiobjective optimization for large-scale portfolio selection with both random and uncertain returns},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A surrogate-assisted constrained optimization evolutionary
algorithm by searching multiple kinds of global and local regions.
<em>TEVC</em>, <em>29</em>(1), 61–75. (<a
href="https://doi.org/10.1109/TEVC.2023.3346435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a surrogate-assisted evolutionary algorithm to tackle expensive inequality-constrained optimization problems through global exploration and local exploitation. The algorithm begins with an exploration stage that involves sampling in three kinds of global regions: 1) the feasible region; 2) the better-objective region; and 3) the converging region. Specifically, sampling in the uncertain feasible region mitigates issues caused by inaccurate objective surrogates. In addition, sampling in the uncertain region containing better-objective values than the current best-feasible solution reduces the risk of missing the global optimum due to inaccurate constraint surrogates. Moreover, sampling in the converging region facilitates quick convergence to the global feasible optimum. Following the exploration stage, promising feasible and infeasible solutions are further refined using local surrogate-based search strategies. To address the risk of missing the global optimum resulting from limited local region scope, the regions are adaptively extended if predicted infill points lie on the boundary. If an infill point is determined to showcase a better-objective value after accurate evaluation, a rewarding local search is performed within the local region. This exploration-exploitation process iterates until the computation budget is exhausted. Experimental results demonstrate that the proposed algorithm outperforms the selected state-of-the-art algorithms on the majority of tested problems.},
  archive      = {J_TEVC},
  author       = {Yong Zeng and Yuansheng Cheng and Jun Liu},
  doi          = {10.1109/TEVC.2023.3346435},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {61-75},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A surrogate-assisted constrained optimization evolutionary algorithm by searching multiple kinds of global and local regions},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary instance selection with multiple partial
adaptive classifiers for domain adaptation. <em>TEVC</em>,
<em>29</em>(1), 46–60. (<a
href="https://doi.org/10.1109/TEVC.2023.3346406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation reuses the knowledge learned from an existing (source) domain to classify unlabeled data from another related (target) domain. However, the two domains have different data distributions. Common approaches to bridge the two distributions are selecting/reweighting instances, building domain-invariant feature subspaces, or directly building adaptive classifiers. Recent domain adaptation work has shown that combining the above first two approaches before applying the third approach achieves better performance than performing each approach individually. However, most existing instance selection approaches are based on a ranking mechanism, ignore interdependences between instances, and require a predefined number of selected instances. Furthermore, adaptive classifiers are sensitive to their parameters which are challenging to optimize due to the lack of target labeled instances. This article introduces a novel evolutionary instance selection approach for domain adaptation. We propose a compacted representation and an efficient fitness function for particle swarm optimization to automatically determine the number of selected instances while considering the interdependencies among instances. This article also proposes to use multiple partial classifiers to build a more reliable and robust adaptive classifier. The results show that evolutionary instance selection selects better instances than the ranking approach. In cooperation with multiple partial classifiers, the proposed algorithm achieves better performance than nine state-of-the-art and well-known domain adaptation approaches.},
  archive      = {J_TEVC},
  author       = {Bach Hoai Nguyen and Bing Xue and Peter Andreae and Mengjie Zhang},
  doi          = {10.1109/TEVC.2023.3346406},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {46-60},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary instance selection with multiple partial adaptive classifiers for domain adaptation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A tractive population-assisted dual-population and two-phase
evolutionary algorithm for constrained multiobjective optimization.
<em>TEVC</em>, <em>29</em>(1), 31–45. (<a
href="https://doi.org/10.1109/TEVC.2023.3345470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Both dual-population and two-phase strategies are effective for utilizing infeasible solution information and significantly enhancing the ability of algorithms to solve constrained multiobjective optimization problems. However, most existing algorithms tend to underperform when facing problems with complex constraints. To address these issues, a constrained multiobjective evolutionary algorithm named DPTPEA, which combines dual-population and two-phase strategies, is proposed in this article. DPTPEA employs two collaborative populations [the exploitive population (expPop) and the tractive population (tracPop)] and divides the evolutionary process of the tracPop into two phases (Phase 1 and Phase 2). In Phase 1, the tracPop ignores constraints and drags the expPop across the infeasible region by sharing offspring information. In Phase 2, the tracPop adopts the epsilon-constrained method to converge toward the constrained Pareto front and to guide the expPop exploiting different feasible regions. Moreover, a dynamic cooperation strategy, a boundary point direction sampling strategy, and a dynamic environmental selection are proposed to improve the exploration ability of tracPop for solving complex problems. Comprehensive experiments on three popular test suites demonstrate that DPTPEA outperforms seven state-of-the-art algorithms on most test problems.},
  archive      = {J_TEVC},
  author       = {Shumin Xie and Kangshun Li and Wenxiang Wang and Hui Wang and Chaoda Peng and Hassan Jalil},
  doi          = {10.1109/TEVC.2023.3345470},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {31-45},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A tractive population-assisted dual-population and two-phase evolutionary algorithm for constrained multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge learning for evolutionary computation.
<em>TEVC</em>, <em>29</em>(1), 16–30. (<a
href="https://doi.org/10.1109/TEVC.2023.3278132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary computation (EC) is a kind of meta-heuristic algorithm that takes inspiration from natural evolution and swarm intelligence behaviors. In the EC algorithm, there is a huge amount of data generated during the evolutionary process. These data reflect the evolutionary behavior and therefore mining and utilizing these data can obtain promising knowledge for improving the effectiveness and efficiency of EC algorithms to better solve optimization problems. Considering this and inspired by the ability of human beings that acquire knowledge from the historical successful experiences of their predecessors, this article proposes a novel EC paradigm, named knowledge learning EC (KLEC). The KLEC aims to learn from historical successful experiences to obtain a knowledge library and to guide the evolutionary behaviors of individuals based on the knowledge library. The KLEC includes two main processes named learning from experiences to obtain knowledge and utilizing knowledge to guide evolution. First, KLEC maintains a knowledge library model (KLM) and updates this model by learning the successful experiences collected in every generation. Second, KLEC not only adopts the evolutionary operation but also utilizes the KLM to guide individuals for better evolution. The KLEC is a generic and effective framework, and we propose two algorithm instances of KLEC, which are knowledge learning (KL)-based differential evolution and KL-based particle swarm optimization. Also, we combine the KL framework with several state-of-the-art EC algorithms, showing that the performance of the state-of-the-art algorithms can be significantly enhanced by incorporating the KL framework.},
  archive      = {J_TEVC},
  author       = {Yi Jiang and Zhi-Hui Zhan and Kay Chen Tan and Jun Zhang},
  doi          = {10.1109/TEVC.2023.3278132},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {16-30},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Knowledge learning for evolutionary computation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constrained multiobjective optimization with escape and
expansion forces. <em>TEVC</em>, <em>29</em>(1), 2–15. (<a
href="https://doi.org/10.1109/TEVC.2023.3270483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constraints may scatter the Pareto optimal solutions of a constrained multiobjective optimization problem (CMOP) into multiple feasible regions. To avoid getting trapped in local optimal feasible regions or a part of the global optimal feasible regions, a constrained multiobjective evolutionary algorithm (CMOEA) should consider both the escape force and the expansion force carefully during the search process. However, most CMOEAs fail to provide these two forces effectively. As a remedy for this limitation, this article proposes a method called three-population evolutionary algorithm (TPEA). TPEA maintains three populations, termed Pop1, Pop2, and Pop3. Pop1 is a regular population, updated with a constrained NSGA-II variant. Pop2 and Pop3 are two auxiliary populations, containing the innermost and outermost nondominated infeasible solutions, respectively. The analysis reveals that these two types of nondominated infeasible solutions can contribute to the generation of escape and expansion forces, respectively. Due to these two forces, TPEA is likely to identify more global optimal feasible regions, which is crucial for constrained multiobjective optimization. Also, a mating selection strategy is developed in TPEA to coordinate the interaction among these three populations. Extensive experiments on 58 benchmark CMOPs and 35 real-world ones demonstrate that TPEA is significantly superior or comparable to six state-of-the-art CMOEAs on most test instances.},
  archive      = {J_TEVC},
  author       = {Zhi-Zhong Liu and Fan Wu and Juan Liu and Yunchuan Qin and Kenli Li},
  doi          = {10.1109/TEVC.2023.3270483},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {2-15},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Constrained multiobjective optimization with escape and expansion forces},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
