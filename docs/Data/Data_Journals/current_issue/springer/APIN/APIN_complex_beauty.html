<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>APIN_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="apin---34">APIN - 34</h2>
<ul>
<li><details>
<summary>
(2025). Unveiling the frontiers of deep learning: Innovations
shaping diverse domains. <em>APIN</em>, <em>55</em>(7), 1–55. (<a
href="https://doi.org/10.1007/s10489-025-06259-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) allows computer models to learn, visualize, optimize, refine, and predict data. To understand its present state, examining the most recent advancements and applications of deep learning across various domains is essential. However, prior reviews focused on DL applications in only one or two domains. The current review thoroughly investigates the use of DL in four different broad fields due to the plenty of relevant research literature in these domains. This wide range of coverage provides a comprehensive and interconnected understanding of DL’s influence and opportunities, which is lacking in other reviews. The study also discusses DL frameworks and addresses the benefits and challenges of utilizing DL in each field, which is only occasionally available in other reviews. DL frameworks like TensorFlow and PyTorch make it easy to develop innovative DL applications across diverse domains by providing model development and deployment platforms. This helps bridge theoretical progress and practical implementation. Deep learning solves complex problems and advances technology in many fields, demonstrating its revolutionary potential and adaptability. CNN-LSTM models with attention mechanisms can forecast traffic with 99% accuracy. Fungal-diseased mango leaves can be classified with 97.13% accuracy by the multi-layer CNN model. However, deep learning requires rigorous data collection to analyze and process large amounts of data because it is independent of training data. Thus, large-scale medical, research, healthcare, and environmental data compilation are challenging, reducing deep learning effectiveness. Future research should address data volume, privacy, domain complexity, and data quality issues in DL datasets.},
  archive      = {J_APIN},
  author       = {Ahmed, Shams Forruque and Alam, Md. Sakib Bin and Kabir, Maliha and Afrin, Shaila and Rafa, Sabiha Jannat and Mehjabin, Aanushka and Gandomi, Amir H.},
  doi          = {10.1007/s10489-025-06259-x},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-55},
  shortjournal = {Appl. Intell.},
  title        = {Unveiling the frontiers of deep learning: Innovations shaping diverse domains},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An integrated interpretation and clustering model based on
attribute grouping. <em>APIN</em>, <em>55</em>(7), 1–13. (<a
href="https://doi.org/10.1007/s10489-025-06262-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is a technique in unsupervised learning used to group unlabeled data. However, traditional clustering algorithms cannot provide explanations for the clustering process and its results, which limits their applicability in certain fields. Existing methods to address the lack of interpretability in clustering algorithms typically focus on explaining the results after the clustering process is complete. Few studies explore embedding interpretability directly into the clustering process, and most of these methods rely on data prototypes to express interpretability, which often leads to explanations that are not intuitive and user-friendly. To address this, a feature-based method is proposed to embed interpretability into the clustering process. This approach provides users with intuitive and easy-to-understand explanations and introduces a new direction for research on embedding interpretability into clustering. The method operates in two stages: in the first stage, all attributes are grouped; in the second stage, an optimization formula is used to complete both the clustering and the weighting of each attribute group. The proposed method was evaluated on multiple synthetic and real-world datasets and compared with other methods. The experimental results show that the method improves clustering accuracy by approximately 5 percent and interpretability by around 40 percent compared to existing approaches.},
  archive      = {J_APIN},
  author       = {Chen, Liang and Sun, Leming and Zhong, Caiming},
  doi          = {10.1007/s10489-025-06262-2},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {An integrated interpretation and clustering model based on attribute grouping},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep attribute graph clustering based on bisymmetric network
information fusion and mutual influence. <em>APIN</em>, <em>55</em>(7),
1–19. (<a href="https://doi.org/10.1007/s10489-025-06295-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep attribute graph clustering has always been a challenging task and an important research topic for real-world data. In recent years, there has been a growing trend in using multi-network information fusion for deep attributed graph clustering. However, existing methods in deep attributed graph clustering have not effectively integrated representations learned from multiple networks and failed to construct a joint loss function that could impact the overall network model, resulting in poor clustering results. To address the aforementioned issues, we proposed AGC-BNIFI, an attribute graph clustering method based on dual symmetric network information fusion and mutual influence. The network of this method consists of a symmetric graph autoencoder and an autoencoder. The two different encoders are combined to improve the attribute learning ability. First, a symmetric graph autoencoder with a symmetric structure is proposed to capture complex linear and adapt to complex graph structure relationships and propagate heterogeneous information of joint embedding and structural features, and can reconstruct the attribute matrix and adjacency matrix; secondly, a layer-by-layer adaptive dynamic fusion module is designed to adaptively fuse the representations learned by each layer of the two encoders, and then learn a better joint representation for clustering tasks; finally, a multi-distribution self-supervision module with soft clustering assignments obtained from different networks that learn from each other and influence each other is proposed, which integrates representation learning and clustering tasks into an end-to-end framework, and jointly optimizes representation learning and clustering tasks by designing a joint loss function. Extensive experimental results on four graph datasets demonstrate the superiority of AGC-BNIFI over state-of-the-art methods. On the Coauthor-Physics dataset, compared to MBN, AGC-BNIFI achieved improvements of 2.6%, 1.1%, 4.3%, and 6.3% in four clustering metrics, respectively.},
  archive      = {J_APIN},
  author       = {Tan, Shuqiu and Zhang, Lei and Liu, Yahui and Zhang, Jianxun},
  doi          = {10.1007/s10489-025-06295-7},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Deep attribute graph clustering based on bisymmetric network information fusion and mutual influence},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic linguistic hesitant fuzzy multi-attribute
decision making for rural revitalization project selection of china.
<em>APIN</em>, <em>55</em>(7), 1–41. (<a
href="https://doi.org/10.1007/s10489-025-06305-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rural revitalization strategy has pointed out the right direction for solving Chinese &quot;three rural&quot; problems. Selecting the most suitable rural revitalization project can be regarded as a multi-attribute decision making (MADM) problem. This paper utilizes the probabilistic linguistic (PL) hesitant fuzzy sets (PLHFSs) to characterize the uncertain information of evaluating rural revitalization projects. PLHFS introduces the characteristics of linguistic hesitant fuzzy set (LHFS) into probabilistic linguistic term set (PLTS), which can represent the membership degrees of linguistic terms (LTs) and the associated probabilities to the set, simultaneously. The normalized and ordered PLHFS is proposed. Some new operation laws for PLHFSs are defined by using Archimedean T-norm and T-conorm (ATT) functions. By employing the Maclaurin symmetric mean (MSM) operator and power average (PA) operator, this paper develops a probabilistic linguistic hesitant fuzzy Archimedean power Maclaurin symmetric mean (PLHFAPMSM) operator and a probabilistic linguistic hesitant fuzzy Archimedean power weighted Maclaurin symmetric mean (PLHFAPWMSM) operator. Some desirable properties of the PLHFAPMSM and PLHFAPWMSM operators are discussed deeply. For MADM with PLHFSs, the individual attribute weight vector for each alternative is derived by data envelopment analysis (DEA). Further, the comprehensive attribute weight vector is determined by a linear goal programming model. Thereby, using the PLHFAPWMSM operator, a new method for MADM with PLHFSs is proposed. Finally, a practical example of rural revitalization project selection is analyzed to illustrate the effectiveness and feasibility of the proposed method.},
  archive      = {J_APIN},
  author       = {Dong, Jiu-Ying and Gong, Si-Hang and Wan, Shu-Ping},
  doi          = {10.1007/s10489-025-06305-8},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-41},
  shortjournal = {Appl. Intell.},
  title        = {Probabilistic linguistic hesitant fuzzy multi-attribute decision making for rural revitalization project selection of china},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep reinforcement learning approach and its application
in multi-USV adversarial game simulation. <em>APIN</em>, <em>55</em>(7),
1–24. (<a href="https://doi.org/10.1007/s10489-025-06380-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the progression of unmanned surface vehicle (USV) intelligence and the maturation of cluster control technologies, intelligent decision-making methods for multi-USV adversarial games have become pivotal technological focuses. Deep reinforcement learning (DRL), a prominent subset of artificial intelligence, has recently achieved notable advancements, heralding significant potential for this field. The intrinsic curiosity module (ICM), self-play (SP), and posthumous credit assignment (POCA) are integrated with proximal policy optimization (PPO) to address the challenges of sparse reward, low sample utilization, and credit assignment in multi-USV adversarial games, and a novel proximal policy optimization algorithm (PPO-ICMSPPOCA) is finally constructed. The algorithm generates intrinsic rewards through iterative training during multi-USV adversarial games while simultaneously addressing the evaluation of each USV&#39;s specific contribution to the team and the challenge of varying numbers of USVs. A perturbation mathematical model for a USV with three degrees of freedom is established, considering the influence of external environmental disturbances and variations in the USV&#39;s state on its hydrodynamic performance in this paper. With the Unity3D and ML-Agents toolkit platforms, multi-USV adversarial game simulation scenes, which can integrate and load various reinforcement learning (RL) algorithms, have been developed. Symmetric or asymmetric game experiments of different scales are conducted in adversarial games. The experiments show that the red teams with our algorithms can learn adversarial tactics more quickly, such as troop dispersion and coordinated attacks. Over 100 episodes, the red teams with ICM, SP, and POCA achieved win rates of 88.25%, 86.75%, and 91.33%, respectively, exhibiting higher game intelligence while obtaining higher cumulative rewards.},
  archive      = {J_APIN},
  author       = {Rao, Jinjun and Wang, Cong and Liu, Mei and Chen, Jinbo and Lei, Jingtao and Giernacki, Wojciech},
  doi          = {10.1007/s10489-025-06380-x},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {A deep reinforcement learning approach and its application in multi-USV adversarial game simulation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New 2D hyperchaotic cubic-tent map and improved 3D hilbert
diffusion for image encryption. <em>APIN</em>, <em>55</em>(7), 1–25. (<a
href="https://doi.org/10.1007/s10489-025-06414-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In image encryption, the effectiveness of chaotic maps significantly affects the effect of image encryption technology. However, existing chaotic maps have an issue of uneven value distribution when generating chaotic sequences, which could pose a threat to information security. To address this issue, a new two-dimensional Cubic-Tent map (2D-CTM) has been developed based on the Cubic and Tent maps. A series of comparative experiments on the 2D-CTM effectively validate its excellent chaotic properties. A novel image encryption algorithm utilizing 2D-CTM (CTM-IEA) is developed to encrypt images. This algorithm includes bit-level random scrambling, bit-level flipping, and improved 3D Hilbert diffusion process. First, the binary elements corresponding to different pixels in the plaintext image are randomly scrambled. Subsequently, the scrambled binary elements are flipped using a chaotic matrix, thoroughly obfuscating the binary information of the plaintext image and successfully hiding the plaintext information. Finally, the improved 3D Hilbert diffusion is applied to the image, eliminating pixel correlation in the original image and enhancing its security. Additionally, bit-level scrambling and diffusion are carried out in three rounds, which bolster the image’s defense against differential attacks. Compared to traditional encryption methods, this approach offers improved security by ensuring more uniform chaotic sequences and integrating a multi-round, bit-level encryption process. The security analysis shows that the key space reaches $${2}^{471}$$ , with correlation coefficients of 0.0006, 0.00004, and $$-$$ 0.0010, and an information entropy of 7.9998. The NPCR is 99.6084%, and the UACI is 33.4620%, which prove the effectiveness and reliability of the algorithm.},
  archive      = {J_APIN},
  author       = {Xu, Xin-li and Song, Xin-guang and Liu, Si-hang and Zhou, Nan-run and Wang, Meng-meng},
  doi          = {10.1007/s10489-025-06414-4},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {New 2D hyperchaotic cubic-tent map and improved 3D hilbert diffusion for image encryption},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Demystifying the black box: AI-enhanced logistic regression
for lead scoring. <em>APIN</em>, <em>55</em>(7), 1–14. (<a
href="https://doi.org/10.1007/s10489-025-06430-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To mitigate interpretability challenges in business decision-making due to the black-box nature of generative Artificial Intelligence(AI), and to address high information processing costs and inconsistent feature collection standards, a novel marketing lead evaluation framework integrating large language models (LLMs) and classical machine learning algorithms was developed. The framework encompasses three modules: (1) a multi-agent question-answering system leveraging Retrieval-Augmented Generation(RAG) and LLMs; (2) a feature extraction and memory module for precise natural language and public data processing; and (3) a logistic regression (LR) model, trained on 540,000 automotive lead records, with associated calculation logic for decision support. Results indicate that the multi-agent system accurately identifies intentions and routes modules, the feature extraction module reduces manual follow-up costs, and the LR-guided LLM output enhances interpretability. These findings highlight the framework’s potential for auditing abnormal events and advancing marketing intelligence and business systematization.},
  archive      = {J_APIN},
  author       = {LIU, Bingran},
  doi          = {10.1007/s10489-025-06430-4},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Demystifying the black box: AI-enhanced logistic regression for lead scoring},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual heterogeneous graph contrastive learning for QoS
prediction. <em>APIN</em>, <em>55</em>(7), 1–15. (<a
href="https://doi.org/10.1007/s10489-025-06431-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of Web Services leads to homogeneity issues, making accurate Quality of Service (QoS) prediction extremely helpful for inexperienced users to choose suitable services. However, the complex relationship between users and services in service invocation poses numerous challenges on QoS prediction. Given the capability of graph neural networks in modeling diverse relationships, a Dual Heterogeneous Graph Contrastive Learning method (DHGCL) is proposed in this paper to achieve high-accuracy QoS prediction. First, a dual heterogeneous graph is innovatively constructed, in which a global interaction graph is generated by a proposed graph learning to enable the direct interactions concerning the distant neighbors, while a local relationship graph is simultaneously constructed to enhance the close associations between users and services through spectral clustering. On this basis, the graph convolution network on the meta-paths is further designed to acquire the embedding of nodes for both of these two graphs. Finally, the global-local contrastive learning is served as a self-supervised mechanism to balance global interaction and local relationship information, and to complete the final QoS prediction. Extensive experiments have proven that our DHGCL method can achieve significantly higher accuracy than most of existing methods with the help of the dual heterogeneous graph.},
  archive      = {J_APIN},
  author       = {Xiu, Yuting and Ding, Ding and Wu, Ziteng and Zhao, Yuekun and Liu, Jiaqi},
  doi          = {10.1007/s10489-025-06431-3},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Dual heterogeneous graph contrastive learning for QoS prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel classification method based on an online extended
belief rule base with a human-in-the-loop strategy. <em>APIN</em>,
<em>55</em>(7), 1–26. (<a
href="https://doi.org/10.1007/s10489-025-06434-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification methods, such as fault diagnosis and intrusion detection, are widely used in modeling complex systems. The accuracy and credibility of these methods directly affect the reliability of the modeling results, which in turn determines the effectiveness of engineering decisions. Additionally, the model&#39;s ability to be dynamically updated should be considered, given the intricate and ever-changing nature of engineering environments. For online models, adding new training samples without considering their suitability can lead to problems such as poor model performance and increased rule base complexity. Furthermore, amid constantly arriving new samples in a dynamic environment, modeling based only on initial expert knowledge can result in new samples not being fully used. Therefore, a novel classification method based on an online extended belief rule base with a human-in-the-loop strategy (OEBRB-H) is proposed in this paper. First, a fuzzy c-means algorithm based on expert knowledge (FBE) is designed to evaluate model parameters online. Second, a human-in-the-loop strategy for dividing the new sample set and a domain-value-based rule updating method are proposed for model optimization. Finally, two case studies, namely, aeroengine inter-shaft bearing fault diagnosis and industrial control intrusion detection, are performed. The results indicate that the model proposed in this paper can maintain both credibility and high accuracy in dynamic environments.},
  archive      = {J_APIN},
  author       = {Li, Jinyuan and Qian, Guangyu and He, Wei and Zhu, Hailong and Zhou, Guohui},
  doi          = {10.1007/s10489-025-06434-0},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {A novel classification method based on an online extended belief rule base with a human-in-the-loop strategy},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IAMTrack: Interframe appearance and modality tokens
propagation with temporal modeling for RGBT tracking. <em>APIN</em>,
<em>55</em>(7), 1–19. (<a
href="https://doi.org/10.1007/s10489-025-06438-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGBT tracking has emerged as a robust solution for various applications, including surveillance, autonomous driving, and robotics, owing to its resilience in challenging environments. However, existing RGBT tracking approaches often overlook target appearance changes, location shifts, and the dynamic significance of modality features, limiting long-term tracking accuracy. To address these limitations, we propose IAMTrack, a novel transformer-based framework that achieves sequential tracking by propagating modality and appearance tokens across frames. The method compresses the discriminative features of each modality into modality tokens to transmit modality quality and target location information in real time, allowing the model to focus more on features with high modality quality and features with high target probability, while suppressing noise and redundant information. It also compresses the appearance features of objects similar in appearance across frames into appearance tokens to convey changes in appearance. To further enhance the token learning capability, we design a temporal generalized relation modelling approach that guides future predictions based on past information. The experimental results show that IAMTrack outperforms existing methods in various RGBT tracking scenarios, especially in UAV tracking tasks. Compared with those of previous methods, the MPRs and MSRs of the VTUAV short-term and long-term subdatasets are improved by $$1.7\%/2.1\%$$ and $$2.5\%/2.2\%$$ , respectively.},
  archive      = {J_APIN},
  author       = {Shi, Huiwei and Mu, Xiaodong and He, Hao and Zhong, Chengliang and Zhang, Bo and Zhao, Peng},
  doi          = {10.1007/s10489-025-06438-w},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {IAMTrack: Interframe appearance and modality tokens propagation with temporal modeling for RGBT tracking},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine sound anomaly detection based on dual-channel
feature fusion variational auto-encoder. <em>APIN</em>, <em>55</em>(7),
1–17. (<a href="https://doi.org/10.1007/s10489-025-06449-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing intelligence and automation of industrial equipment, the technology for detecting equipment anomalies has become increasingly important. Compared to image-based anomaly detection methods, sound-based anomaly detection methods have the advantages of being non-intrusive, real-time and having lower data collection costs. These advantages make them highly valuable for research. Currently, deep learning methods that focus on spectrogram reconstruction have become widely utilized in the field of machine sound anomaly detection research. However, previous methods only attempted to mitigate the impact of noise without enabling the model to fully learn the distribution of sound features during the reconstruction process. In this paper, a novel Dual-Channel Feature Fusion Variational Autoencoder (DCFF-VAE) is proposed to effectively improve its reconstruction ability and help it better learn the normal sound features. In this method, the deep features extracted from the convolution layer and bidirectional gated cycle unit in the encoder are integrated by means of concatenation to make full use of the important features in the sound. Subsequently, grouped deconvolution is applied in the decoder to reduce model complexity while enhancing its perceptual ability for features. Additionally, during the anomaly detection phase, anomaly scores are calculated based on the Mahalanobis distance to better capture the differences between normal and abnormal sounds. Anomaly detection experiments conducted on five types of machines demonstrate that DCFF-VAE not only achieves the best stability but also surpasses the best comparison method by 3.14% and 1.21% in AUC and pAUC metrics, respectively.},
  archive      = {J_APIN},
  author       = {Zhang, Chen and Wei, Yongkang and Wang, Xiaofeng and Wu, Xiaoxuan and Zhu, Xuhui},
  doi          = {10.1007/s10489-025-06449-7},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Machine sound anomaly detection based on dual-channel feature fusion variational auto-encoder},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Harmful data enhanced anomaly detection for quasi-periodic
multivariate time series. <em>APIN</em>, <em>55</em>(7), 1–20. (<a
href="https://doi.org/10.1007/s10489-025-06461-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate quasiperiodic time series (MQTS) anomaly detection has demonstrated significant potential across various practical applications, including health monitoring, intelligent maintenance, and quantitative trading. Recent research has introduced diverse methods based on autoencoders (AEs) and generative adversarial networks (GANs) that learn latent representations of normal data and subsequently detect anomalies through reconstruction errors. However, anomalous training set data can cause model pollution, which harms the ability to of the utilized model reconstruct normal data. The current data extreme imbalance creates an enormous challenge in terms of stripping out these anomalies. In this paper, we propose a GAN-based multivariate quasiperiodic time series anomaly detection method called IGANomaly (I represents isolation). This method isolates normal and harmful samples via pseudolabeling and then learns harmful data patterns to enhance the process of reconstructing of normal samples. First, the reconstruction error and potential feature distribution are jointly analyzed. Bimodal dynamic alignment is achieved through multiview clustering, thus overcoming the limitation of unidimensional determination. Second, dual reconstruction constraints for the generator and a gradient penalty mechanism for the discriminator are constructed. While maintaining the reconstruction quality achieved for normal samples, the propagation path of abnormal features is actively perturbed through a gradient inversion strategy. On three public datasets, IGANomaly achieves $$F1\ scores$$ of 0.811, 0.846, and 0.619, demonstrating an average improvement of 18.9% over the best baseline methods.},
  archive      = {J_APIN},
  author       = {Wang, Liyuan and Zhou, Yong and Ke, Wuping and Zheng, Desheng and Min, Fan and Li, Hui},
  doi          = {10.1007/s10489-025-06461-x},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Harmful data enhanced anomaly detection for quasi-periodic multivariate time series},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical-enhanced graph convolutional networks
leveraging causal inference for aspect-based sentiment analysis.
<em>APIN</em>, <em>55</em>(7), 1–19. (<a
href="https://doi.org/10.1007/s10489-025-06465-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) aims to determine the sentiment polarity of a particular aspect in a sentence. Existing research focuses on shortening the distance between opinion words and aspect words, resulting in spurious correlations. At the same time, the use of different dependent tools will bring different types of noise, destroying the effectiveness of the model. To address these issues, we propose a causal model of hierarchically augmented graph convolutional networks (CausalGCN). Specifically, we subdivide the language features into four relationships and then construct their corresponding mask matrices based on different relationships. At the same time, we introduce an instrumental variable to eliminate the confounders generated by the tool. Our model then combines the resulting mask matrix with localized attention at multiple levels. We treat the relationships between words and adjacent tensors as nodes and edges respectively, resulting in a multi-channel graph. Finally, we utilize graph convolutional networks to enhance relationship-aware node representations. Experimental results on three benchmark datasets demonstrate the effectiveness of the proposed model.},
  archive      = {J_APIN},
  author       = {Zhou, Fengling and Li, Zhixin and Zhang, Canlong and Ma, Huifang},
  doi          = {10.1007/s10489-025-06465-7},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Hierarchical-enhanced graph convolutional networks leveraging causal inference for aspect-based sentiment analysis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DRHGNN: A dynamic residual hypergraph neural network for
aspect sentiment triplet extraction. <em>APIN</em>, <em>55</em>(7),
1–13. (<a href="https://doi.org/10.1007/s10489-025-06466-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect Sentiment Triple Extraction (ASTE) is an emerging sentiment analysis task. Many existing methods focus on designing a new labeling scheme to enable end-to-end operation of the model. However, these methods overlook the relationships between words in the ASTE task. In this paper, we propose the Dynamic Residual Hypergraph Neural Network (DRHGNN), which fully considers the relationships between words. Specifically, based on the pre-defined ten types of word pair relationships, we employ a graph attention network to model sentence features as a relational graph matrix. Subsequently, we use a dynamic hypergraph network to learn deep features from the transformed graph structure, then constructing relation-aware node representations. Furthermore, we integrate a residual connection to improve the performance of our DRHGNN model. Finally, we design a relationship constraint to dynamically control the number of hyperedges, thereby enhancing the effectiveness of the dynamic hypergraph neural network. Extensive experimental results on benchmark datasets show that our proposed model significantly outperforms state-of-the-art methods, demonstrating the effectiveness and robustness of the model.},
  archive      = {J_APIN},
  author       = {Guo, Peng and Yu, Zihao and Li, Chao and Sun, Jun},
  doi          = {10.1007/s10489-025-06466-6},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {DRHGNN: A dynamic residual hypergraph neural network for aspect sentiment triplet extraction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ResU-KAN: A medical image segmentation model integrating
residual convolutional attention and atrous spatial pyramid pooling.
<em>APIN</em>, <em>55</em>(7), 1–16. (<a
href="https://doi.org/10.1007/s10489-025-06467-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of medical imaging data, precise segmentation and analysis of medical images face unprecedented challenges. Addressing small sample sizes, significant variations, and structurally complex medical imaging data to improve the accuracy of early diagnosis has become a key issue in the medical field. This study proposes a Residual U-KAN model (ResU-KAN) to tackle this challenge and improve medical image segmentation accuracy. First, to address the model’s shortcomings in capturing long-distance dependencies and issues like potential gradient vanishing (or explosion) and overfitting, we introduce a Residual Convolution Attention (RCA) module. Second, to expand the model’s receptive field while performing multi-scale feature extraction, we introduce an Atrous Spatial Pyramid Pooling module (ASPP). Finally, experiments were conducted on three publicly available medical imaging datasets, and comparative analysis with existing state-of-the-art methods demonstrated the effectiveness of the proposed approach. Project page: https://github.com/Alfreda12/ResU-KAN},
  archive      = {J_APIN},
  author       = {Wang, Haibin and Zhao, Zhenfeng and Liu, Qi and Wang, Shenwen},
  doi          = {10.1007/s10489-025-06467-5},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {ResU-KAN: A medical image segmentation model integrating residual convolutional attention and atrous spatial pyramid pooling},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-temporal context-aware network for 3D-craft
generation. <em>APIN</em>, <em>55</em>(7), 1–15. (<a
href="https://doi.org/10.1007/s10489-025-06468-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generative modeling of 3D objects in the real world is an interesting but challenging task commonly constrained by process and order. Most existing methods focus on spatial relations to address this issue, neglecting the rich information between temporal sequences. To close this gap, we deliver a spatial-temporal context-aware network to explore the prediction of ordered actions for 3D object construction. Specifically, our approach is mainly formed by two modules, i.e., the spatial-context module and the temporal-context module. The spatial-context module is designed to learn the physical constraints in 3D object construction, such as spatial constraints and gravity. Meanwhile, the temporal-context module integrates the temporal context of action orders in history on the fly toward more accurate predictions. After that, the features of such two modules are merged to finalize the perdition of the following action’s position and block type. The entire model is optimized by the stochastic gradient descent optimization (SGD) method in an end-to-end manner. Extensive experiments conducted on the 3D-Craft dataset demonstrate that the proposed method surpasses the state-of-the-art methods with a large margin, i.e., improving $$4.5\%$$ absolute ACC@1, $$3.3\%$$ absolute ACC@5, and $$4.1\%$$ absolute ACC@10. Moreover, the comprehensive ablation studies and insightful analysis further validate the effectiveness of the proposed method.},
  archive      = {J_APIN},
  author       = {Ji, Ruyi and Wang, Qunbo and Wang, Boying and Zhang, Hangu and Zhang, Wentao and Dai, Lin and Wang, Yanni},
  doi          = {10.1007/s10489-025-06468-4},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Spatial-temporal context-aware network for 3D-craft generation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effective selection of public IoT services by learning
uncertain environmental factors using fingerprint attention.
<em>APIN</em>, <em>55</em>(7), 1–16. (<a
href="https://doi.org/10.1007/s10489-025-06472-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scope of the Internet of Things (IoT) environment has been expanding from private to public spaces, where selecting the most appropriate service by predicting the service quality has become a timely problem. However, IoT services can be physically affected by (1) uncertain environmental factors such as obstacles and (2) interference among services in the same environment while interacting with users. Using the traditional modeling-based approach, analyzing the influence of such factors on the service quality requires modeling efforts and lacks generalizability. In this study, we propose Learning Physical Environment factors based on the Attention mechanism to Select Services for UsERs (PLEASSURE), a novel framework that selects IoT services by learning the uncertain influence and predicting the long-term quality from the users’ feedback without additional modeling. Furthermore, we propose fingerprint attention that extends the attention mechanism to capture the physical interference among services. We evaluate PLEASSURE by simulating various IoT environments with mobile users and IoT services. The results show that PLEASSURE outperforms the baseline algorithms in rewards consisting of users’ feedback on satisfaction and interference.},
  archive      = {J_APIN},
  author       = {Baek, KyeongDeok and Ko, In-Young},
  doi          = {10.1007/s10489-025-06472-8},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Effective selection of public IoT services by learning uncertain environmental factors using fingerprint attention},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable multi-agent reinforcement learning via
multi-head variational autoencoders. <em>APIN</em>, <em>55</em>(7),
1–19. (<a href="https://doi.org/10.1007/s10489-025-06473-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent deep reinforcement learning (RL) is increasingly proficient at making collective decisions in complex systems. However, the black-box nature of DRL decision networks often renders agent behaviors difficult to interpret, thereby undermining human trust. Although several reinforcement learning explanation methods have been proposed, most mainly identify factors influencing decisions without elucidating the underlying causal mechanisms based on physical models. Moreover, these methods do not address the generalizability of interpretability within multi-agent system settings. To overcome these challenges, we propose a multi-agent RL network based on multi-head variational autoencoders (MVAE), which generates decisions with interpretable physical semantics for unmanned systems. The MVAE directly encodes multiple types of semantically meaningful features with physical interpretations from the latent space and generates decisions by integrating these semantics according to physical models. Furthermore, considering the different latent variable distributions in continuous and discrete action scenarios, we design two distinct MVAE models based on Gaussian and Dirichlet distributions, respectively, and design training frameworks using deterministic policy gradient networks and proximal policy optimization networks in a multi-agent environment. Additionally, we develop a visualization method to intuitively convey interpretability in both continuous and discrete action scenarios. Simulation experiments comparing our method with existing baselines demonstrate that our approach achieves superior decision-making performance under interpretability conditions, and further validate its performance in large-scale scenarios.},
  archive      = {J_APIN},
  author       = {Li, Peizhang and Fei, Qing and Chen, Zhen},
  doi          = {10.1007/s10489-025-06473-7},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Interpretable multi-agent reinforcement learning via multi-head variational autoencoders},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A filter-wrapper model for high-dimensional feature
selection based on evolutionary computation. <em>APIN</em>,
<em>55</em>(7), 1–13. (<a
href="https://doi.org/10.1007/s10489-025-06474-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In machine learning, feature selection plays an important role in improving prediction accuracy and reducing time complexity. This paper proposes a filter-wrapper model to obtain a feature subset from high-dimensional data in a short time. Firstly, features are ranked by information gain and Fisher Score. Secondly, the feature search is realized by binary evolutionary computation based on wrapper. To avoid wasting a lot of searches on low-ranked features, an adaptive feature selection strategy is adopted to guide population search and position update. Finally, a learning strategy is proposed, in which learners study from exemplars and complete position update, and the exemplars are constituted by optimal solutions to balance exploration and exploitation. To demonstrate the effectiveness and efficiency of the proposed model, three binary evolutionary computations, including particle swarm optimization, grey wolf optimizer, and fish migration optimization, are applied to the model, and they present excellent performance in high-dimensional data sets.},
  archive      = {J_APIN},
  author       = {Hu, Pei and Zhu, Jiulong},
  doi          = {10.1007/s10489-025-06474-6},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {A filter-wrapper model for high-dimensional feature selection based on evolutionary computation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust stochastic quasi-newton algorithm for non-convex
machine learning. <em>APIN</em>, <em>55</em>(7), 1–14. (<a
href="https://doi.org/10.1007/s10489-025-06475-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic quasi-Newton methods have garnered considerable attention within large-scale machine learning optimization. Nevertheless, the presence of a stochastic gradient equaling zero poses a significant obstacle to updating the quasi-Newton matrix, thereby impacting the stability of the quasi-Newton algorithm. To address this issue, a checkpoint mechanism is introduced, i.e., checking the value of $$\textbf{s}_k$$ before updating the quasi-Newton matrix, which effectively prevents zero increments in the optimization variable and enhances algorithmic stability during iterations. Meanwhile, a novel gradient incremental formulation is introduced to satisfy curvature conditions, facilitating convergence for non-convex objectives. Additionally, finite-memory techniques are employed to reduce storage requirements in large-scale machine learning tasks. The last iteration of the proposed algorithm is proven to converge in a non-convex setting, which is better than average and minimum iteration convergence. Finally, experiments are conducted on benchmark datasets to compare the proposed RSLBFGS algorithm with other popular first and second-order methods, demonstrating the effectiveness and robustness of RSLBFGS.},
  archive      = {J_APIN},
  author       = {Liu, Hanger and Liang, Yuqing and Liu, Jinlan and Xu, Dongpo},
  doi          = {10.1007/s10489-025-06475-5},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {A robust stochastic quasi-newton algorithm for non-convex machine learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view clustering with filtered bipartite graph.
<em>APIN</em>, <em>55</em>(7), 1–16. (<a
href="https://doi.org/10.1007/s10489-025-06476-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key challenge of graph-based multi-view clustering methods lies in how to capture a consensus clustering structure. Although existing methods have achieved good performances, they still share the following limitations: 1) The high computational complexity caused by large graph leaning. 2) The contaminated information in different views reduces the consistency of the fused graph. 3) The two-stage clustering strategy leads to sub-optimal solutions and error accumulation. To solve the above issues, we propose a novel multi-view clustering algorithm termed Multi-View Clustering with Filtered Bipartite Graph (MVC-FBG). In the graph construction stage, we select representative anchors to construct anchor graphs with less space complexity. Then we explicitly filter out the contaminated information to preserve the consistency in different views. Moreover, a low-rank constraint is imposed on the Laplacian matrix of the unified graph to obtain the clustering results directly. Furthermore, we design an efficient alternating optimization algorithm to solve our model, which enjoys a linear time complexity that can scale well with the data size. Extensive experimental results on different scale datasets demonstrate the effectiveness and efficiency of our proposed method.},
  archive      = {J_APIN},
  author       = {Ji, Jintian and Peng, Hailei and Feng, Songhe},
  doi          = {10.1007/s10489-025-06476-4},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Multi-view clustering with filtered bipartite graph},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WMFusion: A w-shaped dual encoder and single decoder network
for multimodal medical image fusion. <em>APIN</em>, <em>55</em>(7),
1–16. (<a href="https://doi.org/10.1007/s10489-025-06477-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current deep learning-based multimodal medical image fusion algorithms usually use a single feature extractor to extract features from images of different modalities. However, these approaches tend to overlook the distinctive features of different modality medical images, resulting in feature loss. In addition, applying complex network structures to low-level image-processing tasks would waste computational power. Therefore, we innovatively design an end-to-end multimodal fusion network with a dual encoder and single decoder structure, which resembles the letter ‘W’, and we have termed WMFusion. Specifically, we first develop a multi-scale context dynamic feature extractor (MCDFE) that employs context-gated convolution to extract multiscale features from different modalities effectively. Subsequently, we propose a local-global feature fusion module (LGFM) for fusing features of different scales, and we design a cross-modality bidirectional interaction structure in the local branch. Finally, feature redundancy is suppressed and the fusion image is reconstructed by a spatial channel reconstruction module (SCRM) with a spatial and channel reconstruction unit. A large number of experimental results demonstrate that our proposed WMFusion method is superior to some state-of-the-art algorithms in terms of both subjective and objective evaluation metrics, and has satisfactory computation efficiency.},
  archive      = {J_APIN},
  author       = {Shao, Yu and Yu, Lei and Tang, Haozhe},
  doi          = {10.1007/s10489-025-06477-3},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {WMFusion: A W-shaped dual encoder and single decoder network for multimodal medical image fusion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximizing diversity in k-pattern set mining through
constraint programming and entropy. <em>APIN</em>, <em>55</em>(7), 1–24.
(<a href="https://doi.org/10.1007/s10489-025-06482-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting diverse and frequent closed itemsets from large datasets is a core challenge in pattern mining, with significant implications across domains such as fraud detection, recommendation systems, and machine learning. Existing approaches often lack flexibility and efficiency, and struggle with initial itemset selection bias and redundancy. This paper addresses these research gaps by introducing a compact and modular constraint programming model that formalizes the search for diverse patterns. Our approach incorporates a novel global constraint derived from a relaxed Overlap diversity measure, using tighter lower and upper bounds to improve filtering capabilities. Unlike traditional methods, we leverage an entropy-based optimization framework that combines joint entropy maximization with top-k pattern mining to identify the maximally k-diverse pattern set. Our approach ensures more comprehensive and informative pattern discovery by minimizing redundancy and promoting pattern diversity. Extensive experiments validate the effectiveness of the proposed method, demonstrating significant performance gains and superior pattern quality compared to state-of-the-art approaches. Implemented in both sequential and parallel versions, the framework offers an efficient and adaptable solution for anytime pattern mining tasks in various domains.},
  archive      = {J_APIN},
  author       = {Douad, Mohamed El Amine and Aribi, Noureddine and Loudni, Samir and Hien, Arnold and Lebbah, Yahia},
  doi          = {10.1007/s10489-025-06482-6},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {Maximizing diversity in k-pattern set mining through constraint programming and entropy},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-layer contrastive learning for aspect-aligned
multimodal sentiment analysis. <em>APIN</em>, <em>55</em>(7), 1–18. (<a
href="https://doi.org/10.1007/s10489-025-06483-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal Aspect-Based Sentiment Analysis (MABSA) aims to identify the sentiment polarity of aspects by incorporating visual information into text. Image and text are two types of modality information with significant modality gaps in both data form and semantic expression. Narrowing the modality gaps and feature fusion are two crucial challenges in MABSA. To address these issues, this paper introduces an aspect-enhanced alignment and fusion strategy with dual-layer contrastive learning to tackle the cross-modal fusion problem. Unlike traditional contrastive learning methods, our approach increases the number of negative samples, enabling the model to learn more discriminative features and better capture fine-grained cross-modal relationships. The proposed approach leverages overlapping aspect information as multi-modal pivots to first bridge the modality gaps and then integrate visual and text information in the multi-modal feature space, thereby improving multi-modal sentiment analysis performance. We first introduce an aspect-guided modality alignment strategy that narrows the fundamental modality gaps between image and text using modality contrastive learning. Then, we design an aspect-oriented multi-modal fusion approach to promote cross-modal feature fusion through symmetric cross-modal interaction. Extensive experiments demonstrate that the proposed approach outperforms other state-of-the-art (SOTA) MABSA methods on three MABSA benchmark datasets. In-depth analysis further validates the effectiveness of the proposed multi-modal fusion approach for MABSA.},
  archive      = {J_APIN},
  author       = {Guo, Junjun and Yan, Zida and Zhang, Guanghua},
  doi          = {10.1007/s10489-025-06483-5},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Dual-layer contrastive learning for aspect-aligned multimodal sentiment analysis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale spatiotemporal normality learning for
unsupervised video anomaly detection. <em>APIN</em>, <em>55</em>(7),
1–15. (<a href="https://doi.org/10.1007/s10489-025-06485-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly detection aims to automatically identify abnormal spatiotemporal patterns in surveillance videos. While unsupervised methods avoid the high cost of collecting abnormal data by learning from regular events, they often struggle to effectively model the inherent multiscale nature of video data. To address this challenge, we propose Multi-Scale Spatiotemporal Normality Learning (MS $$^2$$ NL), a unified framework that systematically processes and integrates multiscale features across both spatial and temporal dimensions. Our framework employs an attention-enhanced stepwise fusion module to aggregate spatial features at different resolutions, enabling comprehensive modeling of appearance patterns from local textures to global structures. For temporal information processing, we design a dynamic aggregation module based on one-dimensional dilated convolutions that effectively captures motion dependencies across multi-scale feature maps while maintaining computational efficiency. These multiscale features are processed through dual decoders: a temporal decoder that learns motion normality through RGB-to-optical-flow mapping, and a spatial decoder that models appearance normality via future frame prediction, with multiscale prototype features stored in an external memory network. This sophisticated handling of multiscale information enables MS $$^2$$ NL to capture subtle spatial deviations while maintaining sensitivity to temporal anomalies. Extensive experiments on benchmark datasets demonstrate the effectiveness of our approach, achieving state-of-the-art frame-level AUROCs of 98.3%, 91.5%, and 74.9% on the UCSD Ped2, CUHK Avenue, and ShanghaiTech datasets, respectively.},
  archive      = {J_APIN},
  author       = {Liu, Caitian and Gong, Linxiao and Chen, Xiong},
  doi          = {10.1007/s10489-025-06485-3},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Multi-scale spatiotemporal normality learning for unsupervised video anomaly detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive federated deep reinforcement learning for edge
offloading in heterogeneous AGI-MEC networks. <em>APIN</em>,
<em>55</em>(7), 1–22. (<a
href="https://doi.org/10.1007/s10489-025-06486-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To support massive applications of mobile terminals (MTs), the combination of air-ground integrated (AGI) networks and mobile edge computing (MEC) technology has emerged. However, how to intelligently manage MTs to satisfy their performance requirements faces several challenges, such as the high communication burden of collaborative decision-making, real-time changes in environmental information, MT mobility, and heterogeneous performance requirements. To deal with these challenges, we propose an adaptive federated deep deterministic policy gradient (AFDDPG) algorithm tailored to the edge offloading problem. Specifically, an adaptive federated training framework is first constructed to acquire global knowledge by sharing model parameters instead of original data among agents. This framework enables the algorithm to maintain a low communication burden while achieving high solution accuracy. Then, a hybrid reward function is proposed to enhance the exploration intensity in the action space by jointly considering the group interests and the unique features of each agent. Accordingly, the convergence performance of the algorithm in complex environments with multiple constraints is improved. Subsequently, an adaptive local update method is presented, which generates personalized local models through biased model aggregation to cope with the heterogeneous requirements of MTs. Finally, the convergence of the proposed AFDDPG algorithm is analysed, and the effectiveness of the algorithm is demonstrated by extensive simulations.},
  archive      = {J_APIN},
  author       = {Fan, Chenchen and Wang, Qingling},
  doi          = {10.1007/s10489-025-06486-2},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive federated deep reinforcement learning for edge offloading in heterogeneous AGI-MEC networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated text annotation: A new paradigm for generalizable
text-to-image person retrieval. <em>APIN</em>, <em>55</em>(7), 1–14. (<a
href="https://doi.org/10.1007/s10489-025-06487-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retrieving specific person images based on textual descriptions, known as Text-to-Image Person Retrieval (TIPR), has emerged as a challenging research problem. While existing methods primarily focus on architectural refinements and feature representation enhancements, the critical aspect of textual description quality remains understudied. We propose a novel framework that automatically generates stylistically consistent textual descriptions to enhance TIPR generalizability. Specifically, we develop a dual-model architecture employing both captioning and retrieval models to quantitatively evaluate the impact of textual descriptions on retrieval performance. Comparative analysis reveals that manually annotated descriptions exhibit significant stylistic variations due to subjective biases among different annotators. To address this, our framework utilizes the captioning model to generate structurally consistent textual descriptions, enabling subsequent training and inference of the retrieval model based on automated annotations. Notably, our framework achieves a 18.60% improvement in Rank-1 accuracy over manual annotations on the RSTPReid dataset. We systematically investigate the impact of identity quantity during testing and explore prompt-guided strategy to enhance image caption quality. Furthermore, this paradigm ensures superior generalization capabilities for well-trained retrieval models. Extensive experiments demonstrate that our approach improves the applicability of TIPR systems. Comparison framework of manual and automated annotation performance. The left panel illustrates the process of generating automated annotations and the details of captioner training and testing. The right panel demonstrates the training and testing processes using different image-text pairs and compares the final results on the RSTPReid dataset. This results show that the performance of automated annotations surpasses that of manual annotations on this dataset},
  archive      = {J_APIN},
  author       = {Liu, Delong and Wang, Peng and Zhao, Zhicheng and Su, Fei},
  doi          = {10.1007/s10489-025-06487-1},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Automated text annotation: A new paradigm for generalizable text-to-image person retrieval},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). COFA: Counterfactual attention framework for trustworthy
wafer map failure classification. <em>APIN</em>, <em>55</em>(7), 1–21.
(<a href="https://doi.org/10.1007/s10489-025-06488-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classifying wafer map failure pattern plays a crucial role in semiconductor manufacturing, as it can help identify the underlying cause of abnormalities, thus reducing production costs. Existing works have shown that deep learning methods have great advantages in recognizing failure patterns. However, recent studies mainly focus on utilizing attention mechanisms to pinpoint critical regions as salient features, while ignoring the imperceptible underlying features and the causal relationship between prediction results and attention. This paper introduces a model-agnostic classification framework that leverages counterfactual explanations to enhance attention. Our approach consists of two steps: counterfactual example generation (Explain) and attention-based classifier refinement (Reinforce). The counterfactual explainer is designed to identify key pixel-level features, the adjustment of which could lead to different predictions. These generated counterfactual examples reveal hidden causal factors in the classifier’s decision-making process. Then the classifier utilizes these pixel features as attention, conducting reliable classification under the guidance of counterfactual examples. Through extensive experiments on real-world datasets, we demonstrate the effectiveness of our proposed model. It achieves an accuracy of 98.125 $$\%$$ in the defect classification task on the WM-811K dataset and 92.544 $$\%$$ on the MixedWM38 dataset, outperforming state-of-the-art attention methods such as SENet, CBAM, and Vision Transformer by over 5%. Our results highlight the superiority of our approach and its potential for practical implementation in the semiconductor manufacturing domain.},
  archive      = {J_APIN},
  author       = {Feng, Kaiyue and Wang, Jia and Yin, Chenke and Li, Andong},
  doi          = {10.1007/s10489-025-06488-0},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {COFA: Counterfactual attention framework for trustworthy wafer map failure classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LPPSLF: A lightweight privacy-preserving split learning
framework for smart surveillance systems. <em>APIN</em>, <em>55</em>(7),
1–18. (<a href="https://doi.org/10.1007/s10489-025-06489-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In smart surveillance systems, cameras often have limited computational capacity, which necessitates the offloading of captured images or videos to cloud servers for analysis, raising significant privacy concerns. To address these challenges, we propose a lightweight privacy-preserving split learning framework tailored for smart surveillance systems. In this framework, an upper model is deployed on resource-constrained cameras to extract intermediate features from image segments, which are then transmitted to a lower model on the cloud for further analysis and training. This approach reduces the likelihood of sensitive data exposure by avoiding the transmission of raw images or videos. Furthermore, our framework incorporates adversarial training to defend against reconstruction attacks, preventing adversaries from deducing private information from the intermediate features. Compared to traditional split learning methods, the proposed solution significantly reduces client-side memory usage and computation time, making it well-suited for deployment on low-resource devices. Experimental results on CIFAR10, CIFAR100, and SVHN datasets demonstrate the effectiveness of our framework, with reductions in the server-side decoder’s reconstruction classification accuracy to 12.18%, 2.18%, and 13.09%, respectively. These results validate the framework’s ability to enhance privacy while maintaining computational efficiency.},
  archive      = {J_APIN},
  author       = {Wang, Liang and Chen, Hao and Zuo, Lina and Liu, Haibo},
  doi          = {10.1007/s10489-025-06489-z},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {LPPSLF: A lightweight privacy-preserving split learning framework for smart surveillance systems},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced frustrum multi-scale VoteNet for 3D object
detection in cluttered indoor scene. <em>APIN</em>, <em>55</em>(7),
1–15. (<a href="https://doi.org/10.1007/s10489-025-06492-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The low-cost Kinect sensor is capable of simultaneously acquiring RGB images and depth information, providing a comprehensive representation of 3D scenes. However, a significant drawback of the Kinect sensor is its susceptibility to low perception accuracy, particularly in cluttered indoor scenes. To tackle these issues, we introduce a novel EF-MSVoteNet framework for Kinect-based indoor 3D object detection. This framework integrates two key modules: The Enhanced Frustum (EF) and Multi-Scale Voting Network (MSVoteNet). After obtaining 2D bounding boxes via a 2D detector, the EF module no longer segments the scene but instead accumulates all frustum regions within a three-dimensional space. The EF module not only enhances the resolution of point clouds within the frustum in relation to the background but also substantially enhances the feature representation of object-related point clouds within the 3D scene. In addition, the proposed MSVoteNet module is a structurally flexible multi-scale voting network. It enhances feature extraction and integration across different scales by incorporating a multi-scale structure into the traditional VoteNet. The performance analysis is carried out on the SUN RGB-D and ScanNet datasets, which were collected using RGB-D sensors in cluttered indoor environments, and it demonstrates the efficacy and effectiveness of our proposed methods. The source code is available at: https://github.com/zerrows2/EF-MSVoteNet},
  archive      = {J_APIN},
  author       = {Zhang, Xuesong and He, Yu and Song, Cunli and Zhuang, Yan},
  doi          = {10.1007/s10489-025-06492-4},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Enhanced frustrum multi-scale VoteNet for 3D object detection in cluttered indoor scene},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AuGQ: Augmented quantization granularity to overcome
accuracy degradation for sub-byte quantized deep neural networks.
<em>APIN</em>, <em>55</em>(7), 1–20. (<a
href="https://doi.org/10.1007/s10489-025-06495-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deployment of neural networks on IoT devices unleashes the potential for various innovative applications, but the sheer size and computation of many deep learning (DL) networks prevented its widespread. Quantization mitigates this issue by reducing model precision, enabling deployment on resource-constrained edge devices. However, at extremely low bit-widths, such as 2-bit and 4-bit, the aggressive compression leads to significant accuracy degradation due to the reduced representational capacity of the neural network. A critical aspect of effective quantization is identifying the range of real values (FP32) that impact model accuracy. To address accuracy loss at sub-byte levels, we introduce Augmented Quantization (AuGQ), a novel granularity technique tailored for low bit-width quantization. AuGQ segments the range of real-valued (FP32) weight and activation distributions into small uniform intervals, applying affine quantization in each interval to enhance accuracy. We evaluated AuGQ using both post-training quantization (PTQ) and quantization-aware training (QAT) methods, achieving accuracy levels comparable to full precision (32-bit) DL networks. Our findings demonstrate that AuGQ is agnostic to the training pipeline and batch normalization folding, distinguishing it from conventional quantization techniques. Furthermore, when integrated into state-of-the-art PTQ algorithms, AuGQ necessitates only 64 training samples for fine-tuning which is $$16\times $$ fewer than traditional methods. This reduction facilitates the application of high-accuracy quantization at sub-byte bit-widths, making it suitable for practical IoT deployments and enhancing computational efficiency on edge devices.},
  archive      = {J_APIN},
  author       = {Mujtaba, Ahmed and Lee, Wai Kong and Ko, Byoung Chul and Chang, Hyung Jin and Hwang, Seong Oun},
  doi          = {10.1007/s10489-025-06495-1},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {AuGQ: Augmented quantization granularity to overcome accuracy degradation for sub-byte quantized deep neural networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continual learning with selective nets. <em>APIN</em>,
<em>55</em>(7), 1–15. (<a
href="https://doi.org/10.1007/s10489-025-06497-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread adoption of foundation models has significantly transformed machine learning, enabling even straightforward architectures to achieve results comparable to state-of-the-art methods. Inspired by the brain’s natural learning process-where studying a new concept activates distinct neural pathways and recalling that memory requires a specific stimulus to fully recover the information-we present a novel approach to dynamic task identification and submodel selection in continual learning. Our method leverages the power of the learning robust visual features without supervision model (DINOv2) foundation model to handle multi-experience datasets by dividing them into multiple experiences, each representing a subset of classes. To build a memory of these classes, we employ strategies such as using random real images, distilled images, k-nearest neighbours (kNN) to identify the closest samples to each cluster, and support vector machines (SVM) to select the most representative samples. During testing, where the task identification (ID) is not provided, we extract features of the test image and use distance measurements to match it with the stored features. Additionally, we introduce a new forgetting metric specifically designed to measure the forgetting rate in task-agnostic continual learning scenarios, unlike traditional task-specific approaches. This metric captures the extent of knowledge loss across tasks where the task identity is unknown during inference. Despite its simple architecture, our method delivers competitive performance across various datasets, surpassing state-of-the-art results in certain instances.},
  archive      = {J_APIN},
  author       = {Tung Luu, Hai and Szemenyei, Marton},
  doi          = {10.1007/s10489-025-06497-z},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Continual learning with selective nets},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decomposition dynamic multi-graph convolutional recurrent
network for traffic forecasting. <em>APIN</em>, <em>55</em>(7), 1–17.
(<a href="https://doi.org/10.1007/s10489-025-06503-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow prediction is crucial for urban traffic management. Traffic data is typically collected from sensors deployed along roadways, which often record both valid and erroneous data. However, most existing studies assume that the collected data is perfectly accurate, overlooking the existence of erroneous data. Meanwhile, graph neural networks are widely applied in traffic forecasting due to their ability to effectively capture correlations between nodes in a network. However, existing methods often rely solely on either static or dynamic graph structures, which may not accurately reflect the complex spatial relationships between nodes. To address these issues, we propose a decomposition dynamic multi-graph convolutional recurrent network (DDMGCRN). DDMGCRN utilizes a residual decomposition mechanism to separate erroneous data from valid data, thereby mitigating its impact. Additionally, DDMGCRN introduces sensor-specific spatial identity embeddings and timestamp embeddings to construct dynamic graphs. It further integrates static graphs for multi-graph fusion, facilitating more effective spatial feature extraction. Furthermore, to address the limitations of RNN-based models in capturing global temporal dependencies, DDMGCRN incorporates a global temporal attention module. Experimental results on four real-world datasets show that DDMGCRN outperforms all baseline models on the PEMS08 dataset, achieving a mean absolute error (MAE) of 14.13, which improves performance by approximately 4.85% compared to the best baseline model. The source code is available at https://github.com/hulongfei123/DDMGCRN .},
  archive      = {J_APIN},
  author       = {Hu, Longfei and Wei, Lai and Lin, Yeqing},
  doi          = {10.1007/s10489-025-06503-4},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Decomposition dynamic multi-graph convolutional recurrent network for traffic forecasting},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convolution-aware networks for random missing traffic data
imputation. <em>APIN</em>, <em>55</em>(7), 1–19. (<a
href="https://doi.org/10.1007/s10489-025-06506-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integrity of traffic data is fundamental to alleviating the challenges in urban cities by computing. However, traffic data often exhibits a random missing characteristic due to sensor failure or network packet loss. Existing methods endowed too much prior knowledge on random missing data, such as data decay over time or data distribution correlation analysis. Thus, there is an urgent need for a data-driven and efficient traffic data interpolation method to assist downstream urban computing. Therefore, this paper proposes a fully convolutional spatial-temporal graph neural network (FC-STGNN) for traffic data imputation. Specifically, we apply a temporal convolutional network (TCN) to extract temporal features. Due to the dilated causal convolutions, it is possible to extract temporal features across time nodes, effectively alleviating the impact of data loss at a certain moment. Furthermore, we design a graph convolutional network (GCN) with residual connections to aggregate traffic data between adjacent road segments in the road network. Combining these two components enables spatiotemporal modeling of traffic data in data-missing environments. Finally, we conduct experiments on two real-world traffic datasets. The experiments demonstrate that our proposed method outperforms most baseline methods and owns a modest computational cost.},
  archive      = {J_APIN},
  author       = {Zhao, Zhenzhen and Shen, Guojiang and Zhou, Wenfeng and Gu, Wenjie and Chen, Chao and Kong, Xiangjie},
  doi          = {10.1007/s10489-025-06506-1},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Convolution-aware networks for random missing traffic data imputation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
