<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AIL_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ail---10">AIL - 10</h2>
<ul>
<li><details>
<summary>
(2025). AI, law and beyond. A transdisciplinary ecosystem for the
future of AI &amp; law. <em>AIL</em>, <em>33</em>(1), 253–270. (<a
href="https://doi.org/10.1007/s10506-024-09404-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We live in exciting times for AI and Law: technical developments are moving at a breakneck pace, and at the same time, the call for more robust AI governance and regulation grows stronger. How should we as an AI &amp; Law community navigate these dramatic developments and claims? In this Presidential Address, I present my ideas for a way forward: researching, developing and evaluating real AI systems for the legal field with researchers from AI, Law and beyond. I will demonstrate how we at the Netherlands National Police Lab AI are developing responsible AI by combining insights from different disciplines, and how this connects to the future of our field.},
  archive      = {J_AIL},
  author       = {Bex, Floris J.},
  doi          = {10.1007/s10506-024-09404-y},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {253-270},
  shortjournal = {Artif. Intell. Law},
  title        = {AI, law and beyond. a transdisciplinary ecosystem for the future of AI &amp; law},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automating petition classification in brazil’s legal system:
A two-step deep learning approach. <em>AIL</em>, <em>33</em>(1),
227–251. (<a href="https://doi.org/10.1007/s10506-023-09385-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated classification of legal documents has been the subject of extensive research in recent years. However, this is still a challenging task for long documents, since it is difficult for a model to identify the most relevant information for classification. In this paper, we propose a two-stage supervised learning approach for the classification of petitions, a type of legal document that requests a court order. The proposed approach is based on a word-level encoder–decoder Seq2Seq deep neural network, such as a Bidirectional Long Short-Term Memory (BiLSTM) or a Bidirectional Encoder Representations from Transformers (BERT) model, and a document-level Support Vector Machine classifier. To address the challenges posed by the lengthy legal documents, the approach introduces a human-in-the-loop approach, whose task is to localize and tag relevant segments of text in the word-level training part, which dramatically reduces the dimension of the document classifier input vector. We performed experiments to validate our approach using a real-world dataset comprised of 270 intermediate petitions, which were carefully annotated by specialists from the 15th civil unit of the State of Alagoas, Brazil. Our results revealed that both BiLSTM and BERT-Convolutional Neural Networks variants achieved an accuracy of up to 95.49%, and also outperformed baseline classifiers based on the Term Frequency–Inverse Document Frequency test vectorizer. The proposed approach is currently being utilized to automate the aforementioned justice unit, thereby increasing its efficiency in handling repetitive tasks.},
  archive      = {J_AIL},
  author       = {Costa, Yuri D. R. and Oliveira, Hugo and Nogueira, Valério and Massa, Lucas and Yang, Xu and Barbosa, Adriano and Oliveira, Krerley and Vieira, Thales},
  doi          = {10.1007/s10506-023-09385-4},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {227-251},
  shortjournal = {Artif. Intell. Law},
  title        = {Automating petition classification in brazil’s legal system: A two-step deep learning approach},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward representing interpretation in factor-based models of
precedent. <em>AIL</em>, <em>33</em>(1), 199–226. (<a
href="https://doi.org/10.1007/s10506-023-09384-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article discusses the desirability and feasibility of modeling precedents with multiple interpretations within factor-based models of precedential constraint. The main idea is that allowing multiple reasonable interpretations of cases and modeling precedential constraint as a function of what all reasonable interpretations compel may be advantageous. The article explains the potential benefits of extending the models in this way with a focus on incorporating a theory of vertical precedent in U.S. federal appellate courts. It also considers the costs of extending the models in this way, such as the significant increase in the functional size of the case base and the need to provide some kind of ordering on interpretations to select a “best” interpretation. Finally, the article suggests partially incorporating multiple interpretations of dimensions as a realistic starting point for incorporating interpretations generally, and shows how doing so can help address difficulties with dimensions. The conclusion remarks on the use of interpretations to deal with inconsistent precedents.},
  archive      = {J_AIL},
  author       = {Rigoni, Adam},
  doi          = {10.1007/s10506-023-09384-5},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {199-226},
  shortjournal = {Artif. Intell. Law},
  title        = {Toward representing interpretation in factor-based models of precedent},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decision support for detecting sensitive text in government
records. <em>AIL</em>, <em>33</em>(1), 171–197. (<a
href="https://doi.org/10.1007/s10506-023-09383-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Freedom of information laws promote transparency by permitting individuals and organizations to obtain government documents. However, exemptions from disclosure are necessary to protect privacy and to permit government officials to deliberate freely. Deliberative language is often the most challenging and burdensome exemption to detect, leading to high processing costs and delays in responding to open-records requests. This paper describes a novel deliberative-language detection model trained on a new annotated training set. The deliberative-language detection model is a component of a decision-support system for open-records requests under the US Freedom of Information Act, the FOIA Assistant, that ingests documents responsive to an open-records requests, suggests passages likely to be subject to deliberative language, privacy, or other exemptions, and assists analysts in rapidly redacting suggested passages. The tool’s interface is based on extensive human-factors and usability studies with analysts and is currently in operational testing by multiple US federal agencies.},
  archive      = {J_AIL},
  author       = {Branting, Karl and Brown, Bradford and Giannella, Chris and Guilder, James Van and Harrold, Jeff and Howell, Sarah and Baron, Jason R.},
  doi          = {10.1007/s10506-023-09383-6},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {171-197},
  shortjournal = {Artif. Intell. Law},
  title        = {Decision support for detecting sensitive text in government records},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025a). Correction to: Reasoning with inconsistent precedents.
<em>AIL</em>, <em>33</em>(1), 167–170. (<a
href="https://doi.org/10.1007/s10506-024-09392-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIL},
  author       = {Canavotto, Ilaria},
  doi          = {10.1007/s10506-024-09392-z},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {167-170},
  shortjournal = {Artif. Intell. Law},
  title        = {Correction to: Reasoning with inconsistent precedents},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025b). Reasoning with inconsistent precedents. <em>AIL</em>,
<em>33</em>(1), 137–166. (<a
href="https://doi.org/10.1007/s10506-023-09382-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational models of legal precedent-based reasoning developed in AI and Law are typically based on the simplifying assumption that the background set of precedent cases is consistent. Besides being unrealistic in the legal domain, this assumption is problematic for recent promising applications of these models to the development of explainable AI methods. In this paper I explore a model of legal precedent-based reasoning that, unlike existing models, does not rely on the assumption that the background set of precedent cases is consistent. The model is a generalization of the reason model of precedential constraint. I first show that the model supports an interesting deontic logic, where consistent obligations can be derived from inconsistent case bases. I then provide an explanation of this surprising result by proposing a reformulation of the model in terms of cases that support a new potential decision and cases that conflict with it. Finally, I show that the reformulation of the model allows us to verify that inconsistent case bases do not make verification that a decision is permissible substantially more complex than consistent case bases and to introduce intuitive criteria to compare different permissible decisions.},
  archive      = {J_AIL},
  author       = {Canavotto, Ilaria},
  doi          = {10.1007/s10506-023-09382-7},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {137-166},
  shortjournal = {Artif. Intell. Law},
  title        = {Reasoning with inconsistent precedents},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural network to identify requests, decisions, and
arguments in court rulings on custody. <em>AIL</em>, <em>33</em>(1),
101–135. (<a href="https://doi.org/10.1007/s10506-023-09380-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Court rulings are among the most important documents in all legal systems. This article describes a study in which natural language processing is used for the automatic characterization of Spanish judgments that deal with the physical custody (joint or individual) of minors. The model was trained to identify a set of elements: the type of custody requested by the plaintiff, the type of custody decided on by the court, and eight of the most commonly used arguments in this type of judgment. Two jurists independently annotated more than 3000 judgments, which were used to train a model based on transformers. The main difficulties encountered in this task were the complexity of the judicial language and the need to work with appellate court rulings that have a more complicated structure than decisions at first instance. For the complete court rulings, the F1 score of the inter-annotator agreement ranged from 0.60 to 0.86 and the Kappa index from 0.33 to 0.73. The F1 score of the agreement between the model and the annotators ranged from 0.66 to 0.93 and the Kappa index from 0.57 to 0.80. These results in which the model performance exceeds even the inter-annotator agreement show the high ability of transformers to identify abstract entities in legal texts.},
  archive      = {J_AIL},
  author       = {Muñoz-Soro, José Félix and del Hoyo Alonso, Rafael and Montañes, Rosa and Lacueva, Francisco},
  doi          = {10.1007/s10506-023-09380-9},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {101-135},
  shortjournal = {Artif. Intell. Law},
  title        = {A neural network to identify requests, decisions, and arguments in court rulings on custody},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Natural language processing for legal document review:
Categorising deontic modalities in contracts. <em>AIL</em>,
<em>33</em>(1), 79–100. (<a
href="https://doi.org/10.1007/s10506-023-09379-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The contract review process can be a costly and time-consuming task for lawyers and clients alike, requiring significant effort to identify and evaluate the legal implications of individual clauses. To address this challenge, we propose the use of natural language processing techniques, specifically text classification based on deontic tags, to streamline the process. Our research question is whether natural language processing techniques, specifically dense vector embeddings, can help semi-automate the contract review process and reduce time and costs for legal professionals reviewing deontic modalities in contracts. In this study, we create a domain-specific dataset and train both baseline and neural network models for contract sentence classification. This approach offers a more efficient and cost-effective solution for contract review, mimicking the work of a lawyer. Our approach achieves an accuracy of 0.90, showcasing its effectiveness in identifying and evaluating individual contract sentences.},
  archive      = {J_AIL},
  author       = {Graham, S. Georgette and Soltani, Hamidreza and Isiaq, Olufemi},
  doi          = {10.1007/s10506-023-09379-2},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {79-100},
  shortjournal = {Artif. Intell. Law},
  title        = {Natural language processing for legal document review: Categorising deontic modalities in contracts},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A large scale benchmark for session-based recommendations on
the legal domain. <em>AIL</em>, <em>33</em>(1), 43–78. (<a
href="https://doi.org/10.1007/s10506-023-09378-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of legal documents in various formats and their dispersion across multiple courts present a significant challenge for users seeking precise matches to their information requirements. Despite notable advancements in legal information retrieval systems, research into legal recommender systems remains limited. A plausible factor contributing to this scarcity could be the absence of extensive publicly accessible datasets or benchmarks. While a few studies have emerged in this field, a comprehensive analysis of the distinct attributes of legal data that influence the design of effective legal recommenders is notably absent in the current literature. This paper addresses this gap by initially amassing a comprehensive session-based dataset from Jusbrasil, one of Brazil’s largest online legal platforms. Subsequently, we scrutinize and discourse key facets of legal session-based recommendation data, including session duration, types of recommendable legal artifacts, coverage, and popularity. Furthermore, we introduce the first session-based recommendation benchmark tailored to the legal domain, shedding light on the performance and constraints of several renowned session-based recommendation approaches. These evaluations are based on real-world data sourced from Jusbrasil.},
  archive      = {J_AIL},
  author       = {Domingues, Marcos Aurélio and de Moura, Edleno Silva and Marinho, Leandro Balby and da Silva, Altigran},
  doi          = {10.1007/s10506-023-09378-3},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {43-78},
  shortjournal = {Artif. Intell. Law},
  title        = {A large scale benchmark for session-based recommendations on the legal domain},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating legal event and context information for chinese
similar case analysis. <em>AIL</em>, <em>33</em>(1), 1–42. (<a
href="https://doi.org/10.1007/s10506-023-09377-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Similar case analysis (SCA) is an essential topic in legal artificial intelligence, serving as a reference for legal professionals. Most existing works treat SCA as a traditional text classification task and ignore some important legal elements that affect the verdict and case similarity, like legal events, and thus are easily misled by semantic structure. To address this issue, we propose a Legal Event-Context Model named LECM to improve the accuracy and interpretability of SCA based on Chinese legal corpus. The event-context integration mechanism, which is an essential component of the LECM, is proposed to integrate the legal event and context information based on the attention mechanism, enabling legal events to be associated with their corresponding relevant contexts. We introduce an event detection module to obtain the legal event information, which is pre-trained on a legal event detection dataset to avoid labeling events manually. We conduct extensive experiments on two SCA tasks, i.e., similar case matching (SCM) and similar case retrieval (SCR). Compared with baseline models, LECM is validated by about 13% and 11% average improvement in terms of mean average precision and accuracy respectively, for SCR and SCM tasks. These results indicate that LECM effectively utilizes event-context knowledge to enhance SCA performance and its potential application in various legal document analysis tasks.},
  archive      = {J_AIL},
  author       = {Dan, Jingpei and Xu, Lanlin and Wang, Yuming},
  doi          = {10.1007/s10506-023-09377-4},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {1-42},
  shortjournal = {Artif. Intell. Law},
  title        = {Integrating legal event and context information for chinese similar case analysis},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
