<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJMLC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijmlc---38">IJMLC - 38</h2>
<ul>
<li><details>
<summary>
(2025). Reinforced multi-modal cyberbullying detection with subgraph
neural networks. <em>IJMLC</em>, <em>16</em>(3), 2161–2180. (<a
href="https://doi.org/10.1007/s13042-024-02384-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social networks have become an indispensable part of contemporary life, and the widespread occurrence of cyberbullying among young people on these sites has sparked serious societal issues. Information on social media often encompasses various heterogeneous elements, such as locations, individuals, organizations, and more. Despite this complexity, text analysis has dominated most studies on cyberbullying detection, ignoring the variety of media data present in social networks. This paper proposes a novel framework for tackling this gap: RSBully is a multi-agent Reinforced Guided Weighted Multi-relational Subgraph Neural Network that is intended to detect cyberbullying effectively. It organizes elements of different types using heterogeneous information networks (HINs) and then transforms them into a weighted multi-relation graph to model the relationship between social media sessions. Second, RSBully uses a reinforced subgraph neural network to eliminate redundant information in social media data by extracting the prominent subgraphs of the graph and capturing intrinsic correlation between modalities and bullying behaviors with interpretability. Comprehensive experimental assessments on real-world social media datasets show that the performance of the RSBully framework outperforms various current state-of-the-art models.},
  archive      = {J_IJMLC},
  author       = {Luo, Kai and Zheng, Ce and Guan, Zhenyu},
  doi          = {10.1007/s13042-024-02384-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2161-2180},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Reinforced multi-modal cyberbullying detection with subgraph neural networks},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced and lightweight design of small object detector
based on YOLOv5s model. <em>IJMLC</em>, <em>16</em>(3), 2139–2159. (<a
href="https://doi.org/10.1007/s13042-024-02383-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the challenges of dense target distribution and complex backgrounds in small detection targets, existing small object detection algorithms suffer from poor performance and high model complexity, which is extremely difficult to deploy on embedded platforms. To address above issues, we optimized the YOLOv5s model structure to enhance detection accuracy. To avoid incurring extra computational expenses, we introduced a local pruning strategy to reduce redundancy, which enables the detection model more suitable for embedded systems. Considering pruning may cause accuracy degradation, we employ knowledge distillation techniques combining feature distillation and output distillation. Specifically, we transfer the knowledge from a high-precision teacher model to a student model, enabling exceptional real-time performance. The experimental results on the VisDrone2019 dataset show that compared to the original algorithm, our model has reduced the parameter count by 50.38%, computation by 51.81%, and model size by 52.94%, totaling just 8 M. The average precision (mAP@0.5) improved to 42.2%. Our proposed model outperforms the current state-of-the-art methods for small object detection in terms of both accuracy and computational efficiency.},
  archive      = {J_IJMLC},
  author       = {Jiang, Hui and Ma, Yongjie and Hong, Tiansong and Gong, Tao},
  doi          = {10.1007/s13042-024-02383-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2139-2159},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Enhanced and lightweight design of small object detector based on YOLOv5s model},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning based magnet design for arm MRI
system. <em>IJMLC</em>, <em>16</em>(3), 2127–2138. (<a
href="https://doi.org/10.1007/s13042-024-02382-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Throwing elbow is a common sports injury that can be diagnosed more promptly by portable magnetic resonance imaging (MRI) than by conventional superconducting MRI. The main magnet of portable MRI systems typically consists of permanent magnets. However, the limited length of the main magnet can lead to poor magnetic field homogeneity, resulting in image distortion. Therefore, it is essential to optimize the permanent magnets arrangement. The traditional genetic algorithm (GA) lacks a timely feedback mechanism during the search process, and there is no gradual interaction with the magnetic field map in a single iteration, which has potential for improvement. To address this problem, a deep reinforcement learning (DRL) based magnet design algorithm for an arm MRI system is proposed. Based on the magnetic field map, the method is performed to design a high homogeneity magnet under the weight constraint on the main magnet, significantly better than the multi-objective method NSGA-II. The results indicate that the proposed method achieves a 26.7% gain in homogeneity at a higher average magnetic field strength compared to the GA. In a scenario where the volume of the main magnet is uniform and without weight constraint, an adaptive search mechanism is proposed that enables the method to achieve a 62.90% improvement in homogeneity compared to the GA.},
  archive      = {J_IJMLC},
  author       = {Pang, Yanwei and Guo, Yishun and Liu, Yiming and Song, Zhanjie and Wang, Zhenchang},
  doi          = {10.1007/s13042-024-02382-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2127-2138},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Deep reinforcement learning based magnet design for arm MRI system},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual insurance for generalized zero-shot learning.
<em>IJMLC</em>, <em>16</em>(3), 2111–2125. (<a
href="https://doi.org/10.1007/s13042-024-02381-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional zero-shot learning aims to use the trained model to accurately classify samples from unseen classes, while for the more difficult task of generalized zero-shot learning, the trained model needs to classify samples from both seen and unseen classes into the correct classes. Because only seen class samples are available during training, generalized zero-shot learning meets great challenges in classification. Generative model is one of the good methods to solve this problem. However, the samples generated by the generative model are often of poor quality. In addition, there are semantic redundancies in the generated samples that are not conducive to classification. To solve these problems, we proposed the dual insurance model (DI-GAN) for generalized zero-shot learning in this paper, including a feature generation module and a semantic separation module. They guarantee the high quality of generated features and the good classification performance respectively. Specifically, the first insurance is based on generative adversarial network, whose generator is constrained by a clustering method to make the generated samples close to the real samples. The second insurance is based on variational autoencoder, including semantic separation, instance network and classification network. Semantic separation is designed to extract the semantically related parts which are beneficial to classification, while instance network acting on the semantically related parts is used to ensure the classification performance. Extensive experiments on four benchmark datasets show the competitiveness of the proposed DI-GAN.},
  archive      = {J_IJMLC},
  author       = {Liang, Jiahao and Fang, Xiaozhao and Kang, Peipei and Han, Na and Li, Chuang},
  doi          = {10.1007/s13042-024-02381-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2111-2125},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dual insurance for generalized zero-shot learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ultra-high-definition underwater image enhancement via
dual-domain interactive transformer network. <em>IJMLC</em>,
<em>16</em>(3), 2093–2109. (<a
href="https://doi.org/10.1007/s13042-024-02379-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of ultra-high-definition (UHD) imaging device is increasingly being used for underwater image acquisition. However, due to light scattering and underwater impurities, UHD underwater images often suffer from color deviations and edge blurriness. Many studies have attempted to enhance underwater images by integrating frequency domain and spatial domain information. Nonetheless, these approaches often interactively fuse dual-domain features only in the final fusion module, neglecting the complementary and guiding roles of frequency domain and spatial domain features. Additionally, the extraction of dual-domain features is independent of each other, which leads to the sharp advantages and disadvantages of the dual-domain features extracted by these methods. Consequently, these methods impose high demands on the feature fusion capabilities of the fusion module. But in order to handle UHD underwater images, the fusion modules in these methods often stack only a limited number of convolution and activation function operations. This limitation results in insufficient fusion capability, leading to defects in the restoration of edges and colors in the images. To address these issues, we develop a dual-domain interaction network for enhancing UHD underwater images. The network takes into account both frequency domain and spatial domain features to complement and guide each other’s feature extraction patterns, and fully integrates the dual-domain features in the model to better recover image details and colors. Specifically, the network consists of a U-shaped structure, where each layer is composed of dual-domain interaction transformer blocks containing interactive multi-head attention and interactive simple gate feed-forward networks. The interactive multi-head attention captures local interaction features of frequency domain and spatial domain information using convolution operation, followed by multi-head attention operation to extract global information of the mixed features. The interactive simple gate feed-forward network further enhances the model’s dual-domain interaction capability and cross-dimensional feature extraction ability, resulting in clearer edges and more realistic colors in the images. Experimental results demonstrate that the performance of our proposal in enhancing underwater images is significantly better than existing methods.},
  archive      = {J_IJMLC},
  author       = {Li, Weiwei and Cao, Feiyuan and Wei, Yiwen and Shi, Zhenghao and Jia, Xiuyi},
  doi          = {10.1007/s13042-024-02379-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2093-2109},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Ultra-high-definition underwater image enhancement via dual-domain interactive transformer network},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Triple confidence-aware encoder–decoder model for
commonsense knowledge graph completion. <em>IJMLC</em>, <em>16</em>(3),
2073–2091. (<a
href="https://doi.org/10.1007/s13042-024-02378-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Commonsense knowledge is essential for performing inference and retrieval in many artificial intelligence applications, including those in natural language processing and expert system. However, a large amount of valuable commonsense knowledge exists implicitly or is missing in commonsense knowledge graphs (KGs). In this case, commonsense knowledge graph completion (CKGC) is proposed to solve this incomplete problem by inferring missing parts of commonsense triples, e.g., (?, HasPrerequisite, turn computer on) or (get onto web, HasPrerequisite, ?). Some existing methods attempt to learn as much entity semantic information as possible by exploiting the structural and semantic context of entities for improving the performance of CKGC. However, we found that the existing models only pay attention to entities and relations of the commonsense triples and ignore the important confidence (weight) information related to the commonsense triples. In this paper we innovatively introduce commonsense triple confidence into CKGC and propose a confidence-aware encoder–decoder CKGC model. In the encoding stage, we propose a method to incorporate the commonsense triple confidence into RGCN (relational graph convolutional network), so that the encoder can learn a more accurate semantic representation of a triple by considering the triple confidence constraints. Moreover, the commonsense KGs are usually sparse, because there are a large number of entities with an in-degree of 1 in the commonsense triples. Therefore, we propose to add a new relation (called similar edge) between two similar entities for compensating the sparsity of commonsense KGs. In the decoding stage, considering that entities in the commonsense triples are sentence-level entities (e.g., the tail entity turn computer on mentioned above), we propose a joint decoding model by fusing effectively the existing InteractE and ConvTransE models. Experiments show that our new model achieves better performance compared to the previous competitive models. In particular, the incorporating of the confidence of triples actually brings significant improvements to CKGC.},
  archive      = {J_IJMLC},
  author       = {Chen, Hongzhi and Zhang, Fu and Li, Qinghui and Li, Xiang and Ding, Yifan and Zhang, Daqing and Cheng, Jingwei and Wang, Xing},
  doi          = {10.1007/s13042-024-02378-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2073-2091},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Triple confidence-aware encoder–decoder model for commonsense knowledge graph completion},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic path planning fusion algorithm with improved a*
algorithm and dynamic window approach. <em>IJMLC</em>, <em>16</em>(3),
2057–2071. (<a
href="https://doi.org/10.1007/s13042-024-02377-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of robotics, path planning in complex dynamic environments has become a significant research hotspot. Existing methods often suffer from inadequate dynamic obstacle avoidance capabilities and low exploration efficiency. These issues primarily arise from inconsistencies caused by insufficient utilization of environmental maps in actual path planning. To address these challenges, we propose an improved algorithm that integrates the enhanced A* algorithm with the optimized dynamic window approach (DWA). The enhanced A* algorithm improves the robot’s path smoothness and accelerates global exploration efficiency, while the optimized DWA enhances local static and dynamic obstacle avoidance capabilities. We performed simulation experiments using MATLAB and conducted experiments in real dynamic environments simulated with Gazebo. Simulation results indicate that, compared to the traditional A* algorithm, our method optimizes traversed grids by 25% and reduces time by 23% in global planning. In dynamic obstacle avoidance, our approach improves path length by 2.7% and reduces time by 19.2% compared to the traditional DWA, demonstrating significant performance enhancements.},
  archive      = {J_IJMLC},
  author       = {Zhang, Jianfeng and Guo, Jielong and Zhu, Daxin and Xie, Yufang},
  doi          = {10.1007/s13042-024-02377-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2057-2071},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dynamic path planning fusion algorithm with improved a* algorithm and dynamic window approach},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LSSMSD: Defending against black-box DNN model stealing based
on localized stochastic sensitivity. <em>IJMLC</em>, <em>16</em>(3),
2041–2056. (<a
href="https://doi.org/10.1007/s13042-024-02376-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning as a service (MLaaS) has become a widely adopted approach, allowing customers to access even the most complex machine learning models through a pay-per-query model. Black-box distribution has been widely used to keep models secret in MLaaS. However, even with black-box distribution alleviating certain risks, the functionality of a model can still be compromised when customers gain access to their model’s predictions. To protect the intellectual property of model owners, we propose an effective defense method against model stealing attacks with the localized stochastic sensitivity (LSS), namely LSSMSD. First, suspicious queries are detected by employing an out-of-distribution (OOD) detector. Addressing a critical issue with many existing defense methods that overly rely on OOD detection results, thus affecting the model’s fidelity, we innovatively introduce LSS to solve this problem. By calculating the LSS of suspicious queries, we can selectively output misleading predictions for queries with high LSS using an misinformation mechanism. Extensive experiments demonstrate that LSSMSD offers robust protections for victim models against black-box proxy attacks such as Jacobian-based dataset augmentation and Knockoff Nets. It significantly reduces accuracies of attackers’ substitute models (up to 77.94%) while yields minimal impact to benign user accuracies (average $$-2.72\%$$ ), thereby maintaining the fidelity of the victim model.},
  archive      = {J_IJMLC},
  author       = {Zhang, Xueli and Chen, Jiale and Li, Qihua and Zhang, Jianjun and Ng, Wing W. Y. and Wang, Ting},
  doi          = {10.1007/s13042-024-02376-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2041-2056},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {LSSMSD: Defending against black-box DNN model stealing based on localized stochastic sensitivity},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CHNSCDA: CircRNA-disease association prediction based on
strongly correlated heterogeneous neighbor sampling. <em>IJMLC</em>,
<em>16</em>(3), 2023–2039. (<a
href="https://doi.org/10.1007/s13042-024-02375-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Circular RNAs (circRNAs) are a special class of endogenous non-coding RNA molecules with a closed circular structure. Numerous studies have demonstrated that exploring the association between circRNAs and diseases is beneficial in revealing the pathogenesis of diseases. However, traditional biological experimental methods are time-consuming. Although some methods have explored the circRNA associated with diseases from different perspectives, how to effectively integrate the multi-perspective data of circRNAs has not been well studied, and the feature aggregation between heterogeneous nodes has not been fully considered. Based on these considerations, a novel computational framework, called CHNSCDA, is proposed to efficiently forecast unknown circRNA-disease associations(CDAs). Specifically, we calculate the sequence similarity and functional similarity for circRNAs, as well as the semantic similarity for diseases. Then the similarities of circRNAs and diseases are combined with Gaussian interaction profile kernels (GIPs) similarity, respectively. These similarities are fused by taking the maximum values. Moreover, circRNA-circRNA associations and disease-disease associations with strong correlations are selectively combined to construct a heterogeneous network. Subsequently, we predict the potential CDAs based on the multi-head dynamic attention mechanism and multi-layer convolutional neural network. The experimental results show that CHNSCDA outperforms the other four state-of-the-art methods and achieves an area under the ROC curve of 0.9803 in 5-fold cross validation (5-fold CV). In addition, extensive ablation comparison experiments were conducted to confirm the validity of different similarity feature aggregation methods, feature aggregation methods, and dynamic attention. Case studies further demonstrate the outstanding performance of CHNSCDA in predicting potential CDAs.},
  archive      = {J_IJMLC},
  author       = {Lin, Yuanyuan and Wang, Nianrui and Liu, Jiangyan and Zhang, Fangqin and Wei, Zhouchao and Yi, Ming},
  doi          = {10.1007/s13042-024-02375-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2023-2039},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {CHNSCDA: CircRNA-disease association prediction based on strongly correlated heterogeneous neighbor sampling},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-agent collaborative algorithm for task-oriented
dialogue systems. <em>IJMLC</em>, <em>16</em>(3), 2009–2022. (<a
href="https://doi.org/10.1007/s13042-024-02374-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, reinforcement learning has found successful applications in dialogue systems. However, when confronted with task-oriented dialogue systems, optimizing the strategy becomes challenging due to difficulties in state tracking and the complexity of multitasking. Task-oriented dialogue systems based on reinforcement learning encounter issues such as poor collaboration, non-unique learning goals, and non-staticity arising from the absence of agent cooperation. To address these challenges, this paper introduces a novel multi-agent cooperative dialogue (MACD) algorithm for task-oriented dialogue systems. In MACD, a deep neural network framework is employed to facilitate information exchange among multiple agents within task-oriented dialogue systems. This integration enables the consolidation of observations from individual agents, leading to the derivation of joint observations and fostering information sharing among the agents. Consequently, MACD aims to mitigate the problem of non-stationarity resulting from the lack of shared information among multiple agents. In the context of multi-agent strategy learning within task-oriented dialogue systems, we employ the MADDPG architecture to address the challenge of inadequate joint strategy learning among multiple agents. By integrating single-agent observations and multi-agent strategy learning, we aim to alleviate the collaborative deficiencies inherent in task-oriented dialogue systems involving multiple agents. Through experimentation with reinforcement learning algorithms such as MACD, DQN, OPPA, JOIE, and QMIX on the MultiWOZ 2.0 corpus, our results demonstrate significant enhancements. Specifically, the proposed algorithm effectively elevates the success rate of multi-agent collaboration in accomplishing dialogue tasks in composite task scenarios. Furthermore, it mitigates the occurrence of ineffective dialogues during the dialogue rounds. Comparative analysis reveals that our approach surpasses conventional reinforcement learning algorithms in facilitating agent information interaction and joint strategy learning within the task-oriented dialogue context.},
  archive      = {J_IJMLC},
  author       = {Sun, Jingtao and Kou, Jiayin and Shi, Weipeng and Hou, Wenyan},
  doi          = {10.1007/s13042-024-02374-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2009-2022},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A multi-agent collaborative algorithm for task-oriented dialogue systems},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault-tolerant control design for nonlinear multilateral
teleoperation system with unreliable communication channels and actuator
constraints. <em>IJMLC</em>, <em>16</em>(3), 1991–2007. (<a
href="https://doi.org/10.1007/s13042-024-02373-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For nonlinear multilateral teleoperation systems, unreliable communication channels and actuator constraints are the main challenging issues to achieve the stability condition and satisfy the required performance. In this paper, a novel fault-tolerant control algorithm is proposed for a class of multi-degree-of-freedom nonlinear multilateral teleoperation systems with the aforementioned problems and unknown environmental forces. The time-varying delays and packet dropouts are incorporated in the unreliable communication channels, and the considered systems are modeled as a kind of T-S fuzzy systems with multiple time-varying delays. For actuator constraints, both the actuator failures and the unknown control directions are investigated in such research, by designing a novel fault-tolerant control scheme, the failures and control directions can be estimated simultaneously. Next, the radial basis function neural network (RBFNN) is introduced to estimate the unknown environmental force, and the estimated results are incorporated in the controller design and the mean-square stability of the closed-loop system with disturbance attenuation level is guaranteed. Finally, a numerical simulation example is given to show the effectiveness of the proposed method.},
  archive      = {J_IJMLC},
  author       = {Ke, Huan-Yu and Chen, Yang-Jie and Li, Ming and Li, Jian-Ning},
  doi          = {10.1007/s13042-024-02373-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1991-2007},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fault-tolerant control design for nonlinear multilateral teleoperation system with unreliable communication channels and actuator constraints},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating global semantics and enhanced local subgraph for
inductive link prediction. <em>IJMLC</em>, <em>16</em>(3), 1971–1990.
(<a href="https://doi.org/10.1007/s13042-024-02372-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inductive link prediction (ILP) predicts missing triplets involving unseen entities in knowledge graphs (KGs). Existing ILP research mainly addresses seen-unseen entities in the original KG (semi-inductive link prediction) and unseen-unseen entities in emerging KGs (fully-inductive link prediction). Bridging-inductive link prediction, which focuses on unseen entities that carry evolutionary information from the original KG to the emerging KG, has not been extensively studied so far. This study introduces a novel model called GSELI (integrating global semantics and enhanced local subgraph for inductive link prediction), which comprises three components. (1) The contrastive learning-based global semantic features (CLSF) module extracts relation-specific semantic features between the original and emerging KGs and employs semantic-aware contrastive learning to optimize these features. (2) The GNN-based enhanced local subgraph (GELS) module employs personalized PageRank (PPR)-based local clustering to sample tightly-related subgraphs and incorporates complete neighboring relations to enhance the topological information of subgraphs. (3) Joint contrastive learning and supervised learning training. Experimental results on various benchmark datasets demonstrate that GSELI outperforms the baseline models in both fully-inductive and bridging-inductive link predictions.},
  archive      = {J_IJMLC},
  author       = {Liang, Xinyu and Si, Guannan and Li, Jianxin and An, Zhaoliang and Tian, Pengxin and Zhou, Fengyu and Wang, Xiaoliang},
  doi          = {10.1007/s13042-024-02372-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1971-1990},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Integrating global semantics and enhanced local subgraph for inductive link prediction},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Iterative filter pruning with combined feature maps and
knowledge distillation. <em>IJMLC</em>, <em>16</em>(3), 1955–1969. (<a
href="https://doi.org/10.1007/s13042-024-02371-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have been successfully implemented in various computer vision tasks. However, the remarkable achievements are accompanied by high memory and high computation, which hinder the deployment and application of CNNs on resource-constrained mobile devices. Filter pruning is proposed as an effective method to solve the above problems. In this paper, we propose an iterative filter pruning method that combines feature map properties and knowledge distillation. This method can maximize the important feature information (e.g., spatial features) in the feature map by calculating the information capacity and feature relevance of the feature map, and then pruning based on the set criteria. Then, the pruned network learns the complete feature information of the standard CNN architecture in order to quickly and completely recover the lost accuracy before the next pruning operation. The alternating operation of pruning and knowledge distillation can effectively and comprehensively achieve network compression. Experiments on image classification datasets via mainstream CNN architectures indicate the effectiveness of our approach. For example, on CIFAR-10, our method reduces Floating Point Operations (FLOPs) by 71.8% and parameters by 71.0% with an accuracy improvement of 0.24% over the ResNet-110 benchmark. On ImageNet, our method achieves 55.6% reduction in FLOPs and 52.5% reduction in model memory at the cost of losing only 0.17% of Top-5 on ResNet-50.},
  archive      = {J_IJMLC},
  author       = {Liu, Yajun and Fan, Kefeng and Zhou, Wenju},
  doi          = {10.1007/s13042-024-02371-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1955-1969},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Iterative filter pruning with combined feature maps and knowledge distillation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting complex copy-move forgery using KeyPoint-siamese
capsule network against adversarial attacks. <em>IJMLC</em>,
<em>16</em>(3), 1927–1953. (<a
href="https://doi.org/10.1007/s13042-024-02370-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital image forensics, particularly in the realm of detecting Copy-Move Forgery (CMF), is exposed to significant challenges, especially in the face of intricate adversarial attacks. In response to these challenges, this paper presents a robust approach for detecting complex CMFs in digital images using the KeyPoint-Siamese Capsule Network (KP-SCN) and evaluates its resilience against adversarial attacks. The KP-SCN architecture incorporates keypoint detection, a Siamese network for feature extraction, and a capsule network for forgery detection. The method showcases enhanced robustness against adversarial attacks, specifically addressing image perturbation, patch removal, patch replacement, and spatial transformation attacks. By using hierarchical feature representations and dynamic routing in capsule networks, the model effectively handles complex CMF, including rotation, scaling, and non-linear transformations. The proposed KP-SCN approach employs a large dataset for training the KP-SCN, enabling it to identify copy-move forgeries by comparing extracted keypoints and their spatial relationships. KP-SCN demonstrates superior performance compared to the state-of-the-art on the CoMoFoD dataset, achieving precision, recall, and F1-score values of 95.62%, 93.78%, and 94.69%, respectively, and shows strong results on other datasets. For CASIA v2.0, the precision, recall, and F1-score are 90.45%, 88.97%, and 89.70%; for MICC-F2000, they are 91.32%, 90.27%, and 90.79%; for MICC-F600, they are 92.21%, 91.10%, and 91.65%; for MICC-F8multi, they are 89.75%, 87.92%, and 88.83%; and for IMD, they are 93.14%, 92.58%, and 92.86%. The KP-SCN framework maintains high detection rates under various manipulations, including JPEG compression, rotation, scaling, noise, blurring, brightness changes, contrast adjustment, and zoom motion blur compared to the other methods. For instance, it achieves an 80.657% detection rate for CoMoFoD under JPEG compression and 97.883% for IMD under a 10-degree rotation. These findings validate the robustness and adaptability of KP-SCN, making it a reliable solution for real-world forensic applications.},
  archive      = {J_IJMLC},
  author       = {Aiswerya, S. B. and Jawhar, S. Joseph},
  doi          = {10.1007/s13042-024-02370-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1927-1953},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Detecting complex copy-move forgery using KeyPoint-siamese capsule network against adversarial attacks},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-low frequency features fusion and integrated
classification SCNs for intelligent fault diagnosis of rolling bearing.
<em>IJMLC</em>, <em>16</em>(3), 1889–1926. (<a
href="https://doi.org/10.1007/s13042-024-02369-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For fault diagnosis of the rolling bearing, it is difficult to accurately extract and recognize fault features of the vibration signal. In this paper, a novel feature extraction method based on optimized Maximum Correlated Kurtosis Deconvolution (MCKD) by an improved Black Widow Optimization Algorithm (IBWOA) and Singular Value Decomposition (SVD) method was proposed, and an integrated classification Stochastic Configuration Networks (ISCNs) model was designed for fault recognition. Firstly, SVD was used to denoise and reconstruct the signal, in which fault features of the reconstructed signal were highlighted by MCKD; however, the filtering effect of MCKD was seriously affected by accurate value of some parameters, so IBWOA was proposed to realize optimized selection of them. Then, Wavelet Packet Decomposition (WPD) was used to deal with the signal after the feature enhancement, and the high-frequency and low-frequency singular values were extracted as the feature vectors. Finally, the ISCNs model was designed to train and classify the low-frequency and high-frequency feature vectors several times, which were then decided by the principle of ”minority obeying majority”. Simulation experiments show that the proposed method can effectively highlight and extract bearing fault features, and the average diagnostic accuracy can maximum reach 99.66% according to multiple experiments.},
  archive      = {J_IJMLC},
  author       = {Li, Kun and Wu, Hao and Han, Ying},
  doi          = {10.1007/s13042-024-02369-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1889-1926},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {High-low frequency features fusion and integrated classification SCNs for intelligent fault diagnosis of rolling bearing},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Video anomaly detection based on multi-scale optical flow
spatio-temporal enhancement and normality mining. <em>IJMLC</em>,
<em>16</em>(3), 1873–1888. (<a
href="https://doi.org/10.1007/s13042-024-02368-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly detection aims to detect anomaly scores in video frames, and it is a challenging research area since the types of anomalies are limitless. In response to the fact that abnormal behavior is likely to be misidentified as normal and anomalies are typically generated by the fast motion of foreground objects, this paper proposes a novel model called the Multi-scale Optical Flow Spatio-Temporal Enhancement and Normality Mining Network (MOFSTE-NM). It contains the Spatio-temporal Information Attention Enhancement Module (SIAEM) that incorporates reconstructed optical flows at multiple scales and considers spatial and temporal aspects. This strategy reduces the influence of the background and normal objects, enhancing the model’s ability to focus on anomalous fast moving objects in the foreground. Additionally, we propose a Normality Mining Convolution (NMC) module embedded in the decoder to refine the boundary between normality and abnormality. The NMC uses a multihead attention mechanism for dynamic weight adjustment, enabling the precise extraction of normal information. We compute the final anomaly score by fusing two components: (1) the reconstruction error of the optical flows and (2) the peak signal-to-noise ratio between the predicted frame and its ground truth. We evaluate our model on three well-established video anomaly detection datasets. A comparison of different models indicates that the proposed model achieves superior performance compared to state-of-the-art approaches, with area under the receiver operating characteristic curve (AUROC) values of 99.23 $$\%$$ on UCSD Ped2, 88.84 $$\%$$ on CUHK Avenue, and 74.80 $$\%$$ on Shanghaitech.},
  archive      = {J_IJMLC},
  author       = {He, Qiang and Shi, Ruinian and Chen, Linlin and Huo, Lianzhi},
  doi          = {10.1007/s13042-024-02368-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1873-1888},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Video anomaly detection based on multi-scale optical flow spatio-temporal enhancement and normality mining},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PTEKC: Pre-training with event knowledge of ConceptNet for
cross-lingual event causality identification. <em>IJMLC</em>,
<em>16</em>(3), 1859–1872. (<a
href="https://doi.org/10.1007/s13042-024-02367-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event causality identification (ECI) aims to identify causal relations between events in texts. Although existing event causality identification works based on fine-tuning pre-trained language models (PLMs) have achieved promising results, they suffer from prohibitive computation costs, catastrophic forgetting of distributional knowledge, as well as poor interpretability. Particularly in low-resource and cross-linguistic scenarios, existing multi-lingual models are generally confronted with the so-called curse of multilinguality, language bias, and hence result in low accuracy and generalization ability. In this paper, we propose a paradigm, termed Pre-training with Event Knowledge of ConceptNet (PTEKC), to couple Multi-lingual Pre-trained Language Models (mPLMs) with event knowledge for cross-lingual event causality identification. Specifically, we have develop a parameter-sharing adapter plugin that facilitates the integration of event knowledge into the frozen PLMs. This approach significantly diminishes the number of trainable parameters and greatly reduces the risk of catastrophic forgetting. Our Adapter integrates multi-lingual alignment event knowledge into the mPLMs through two designed pre-training tasks, namely event masking and self-supervised link prediction. Extensive experiments on the benchmark dataset MECI show that PTEKC is parameter-efficient and can effectively incorporate multi-lingual alignment event knowledge for improving cross-lingual event causality identification.},
  archive      = {J_IJMLC},
  author       = {Zhu, Enchang and Yu, Zhengtao and Huang, Yuxin and Gao, Shengxiang and Xian, Yantuan},
  doi          = {10.1007/s13042-024-02367-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1859-1872},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {PTEKC: Pre-training with event knowledge of ConceptNet for cross-lingual event causality identification},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stock closing price prediction based on
ICEEMDAN-FA-BiLSTM–GM combined model. <em>IJMLC</em>, <em>16</em>(3),
1833–1857. (<a
href="https://doi.org/10.1007/s13042-024-02366-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accuracy of stock price forecasting is of great significance in investment decision-making and risk management. However, the complexity and fluctuation of stock prices challenge the traditional forecasting methods to achieve the best accuracy. To improve the accuracy of stock price prediction, a sophisticated combination prediction method based on ICEEMDAN-FA-BiLSTM–GM has been proposed in this article. In this paper, a comprehensive and effective indicator system is constructed, covering 60 indicators such as traditional factors, market sentiment, macroeconomic indicators and company financial data, which affect stock prices. In the data preprocessing stage, in order to eliminate the influence of noise, the stock closing price series is first decomposed by using the ICEEMDAN method, which effectively divides them into high-frequency and low-frequency components according to their respective frequencies. Subsequently, LLE technique is used to narrow down the remaining indicators to obtain 9 narrowed features. Finally, each high-frequency subsequence is combined with all the dimensionality reduction features respectively to construct new indicator sets for input to the model. In the prediction stage, the hyperparameters of the prediction model for each subseries have been determined using the FA algorithm. The prediction has been carried out separately for the high-frequency and low-frequency components, employing the BiLSTM and GM prediction methods. Ultimately, the prediction results of each subseries have been superimposed to obtain the final stock price prediction value. In this paper, an empirical study was conducted using stock price data such as Shanghai composite index. The experimental results show that the established stock price prediction model based on ICEEMDAN-FA-BiLSTM–GM has obvious advantages in terms of prediction accuracy and stability compared with traditional methods and other combined prediction methods. This model can provide more accurate stock price prediction and promote the rationalization of investment decision and the accuracy of risk control.},
  archive      = {J_IJMLC},
  author       = {Xie, Lewei and Wan, Ruibo and Wang, Yuxin and Li, Fangjian},
  doi          = {10.1007/s13042-024-02366-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1833-1857},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Stock closing price prediction based on ICEEMDAN-FA-BiLSTM–GM combined model},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning from high-dimensional cyber-physical data streams:
A case of large-scale smart grid. <em>IJMLC</em>, <em>16</em>(3),
1819–1831. (<a
href="https://doi.org/10.1007/s13042-024-02365-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality of data and complexity of decision boundaries in high-dimensional data streams that are collected from cyber-physical power systems can greatly influence the process of learning from data and diagnosing faults in such critical systems. These systems generate massive amounts of data that overburden the system with excessive computational costs. Another issue is the presence of noise in recorded measurements that poses a challenge to the learning process, leading to a degradation in the performance of fault diagnosis. Furthermore, the diagnostic model is often provided with a mixture of redundant measurements that may deviate it from learning normal and fault distributions. This paper presents the effect of feature engineering on mitigating the aforementioned challenges in learning from data streams collected from cyber-physical systems. A data-driven fault diagnosis framework for a 118-bus power system is constructed by integrating feature selection, dimensionality reduction methods, and decision models. A comparative study is enabled accordingly to compare several advanced techniques in both domains. Dimensionality reduction and feature selection methods are compared both jointly and separately. Finally, experiments are concluded, and a setting is suggested that enhances data quality for fault diagnosis.},
  archive      = {J_IJMLC},
  author       = {Hassani, Hossein and Hallaji, Ehsan and Razavi-Far, Roozbeh and Saif, Mehrdad},
  doi          = {10.1007/s13042-024-02365-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1819-1831},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Learning from high-dimensional cyber-physical data streams: A case of large-scale smart grid},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A traffic flow forecasting method based on hybrid
spatial–temporal gated convolution. <em>IJMLC</em>, <em>16</em>(3),
1805–1817. (<a
href="https://doi.org/10.1007/s13042-024-02364-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influenced by the urban road network, traffic flow has complex temporal and spatial correlation characteristics. Traffic flow forecasting is an important problem in the intelligent transportation system, which is related to the safety and stability of the transportation system. At present, many researchers ignore the research need for traffic flow forecasting beyond one hour. To address the issue of long-term traffic flow prediction, this paper proposes a traffic flow prediction model (HSTGCNN) based on a hybrid spatial–temporal gated convolution. Spatial–temporal attention mechanism and Gated convolution are the main components of HSTGCNN. The spatial–temporal attention mechanism can effectively obtain the spatial–temporal features of traffic flow, and gated convolution plays an important role in extracting longer-term features. The usage of dilated causal convolution effectively improves the long-term prediction ability of the model. HSTGCNN predicts the traffic conditions of 1 h, 1.5 h, and 2 h on two general traffic flow datasets. Experimental results show that the prediction accuracy of HSTGCNN is generally better than that of Temporal Graph Convolutional Network (T-GCN), Graph WaveNet, and other baselines.},
  archive      = {J_IJMLC},
  author       = {Zhang, Ying and Yang, Songhao and Wang, Hongchao and Cheng, Yongqiang and Wang, Jinyu and Cao, Liping and An, Ziying},
  doi          = {10.1007/s13042-024-02364-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1805-1817},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A traffic flow forecasting method based on hybrid spatial–temporal gated convolution},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Backdoor learning curves: Explaining backdoor poisoning
beyond influence functions. <em>IJMLC</em>, <em>16</em>(3), 1779–1804.
(<a href="https://doi.org/10.1007/s13042-024-02363-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Backdoor attacks inject poisoning samples during training, with the goal of forcing a machine learning model to output an attacker-chosen class when presented with a specific trigger at test time. Although backdoor attacks have been demonstrated in a variety of settings and against different models, the factors affecting their effectiveness are still not well understood. In this work, we provide a unifying framework to study the process of backdoor learning under the lens of incremental learning and influence functions. We show that the effectiveness of backdoor attacks depends on (i) the complexity of the learning algorithm, controlled by its hyperparameters; (ii) the fraction of backdoor samples injected into the training set; and (iii) the size and visibility of the backdoor trigger. These factors affect how fast a model learns to correlate the presence of the backdoor trigger with the target class. Our analysis unveils the intriguing existence of a region in the hyperparameter space in which the accuracy of clean test samples is still high while backdoor attacks are ineffective, thereby suggesting novel criteria to improve existing defenses.},
  archive      = {J_IJMLC},
  author       = {Cinà, Antonio Emanuele and Grosse, Kathrin and Vascon, Sebastiano and Demontis, Ambra and Biggio, Battista and Roli, Fabio and Pelillo, Marcello},
  doi          = {10.1007/s13042-024-02363-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1779-1804},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Backdoor learning curves: Explaining backdoor poisoning beyond influence functions},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature correlation fusion and feature selection under
adaptive neighborhood group approximation space. <em>IJMLC</em>,
<em>16</em>(3), 1761–1778. (<a
href="https://doi.org/10.1007/s13042-024-02362-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world scenarios, features often exhibit dynamic interdependence and interaction. While neighborhood rough sets in feature selection have been extensively studied, approaches focusing on searching over feature groups have received less attention. Drawing inspiration from this premise, a feature fusion method grounded in minimum redundancy is proposed to integrate fragmented features. Maximizing Jeffrey divergence constructs a metric function, facilitating the inscription of knowledge granules on the feature groups. This distance function effectively coordinates the importance of feature groups by mapping samples into an adaptive approximation space. Subsequently, traditional uncertainty measures are extended to the neighborhood granules formed by the feature groups. An objective function based on these metrics of neighborhood uncertainty measures is designed to ascertain the importance of feature groups, presenting a novel feature selection algorithm based on this function. Empirical evaluations of the proposed algorithms are conducted using various datasets sourced from the University of California, Irvine (UCI), providing a comprehensive assessment of the efficacy and performance. The experimental results demonstrate the effectiveness of the algorithm.},
  archive      = {J_IJMLC},
  author       = {Li, Gengsen and Sang, Binbin and Cui, Shaoguo and Chen, Hongmei},
  doi          = {10.1007/s13042-024-02362-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1761-1778},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Feature correlation fusion and feature selection under adaptive neighborhood group approximation space},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving numerical and engineering optimization problems
using a dynamic dual-population differential evolution algorithm.
<em>IJMLC</em>, <em>16</em>(3), 1701–1760. (<a
href="https://doi.org/10.1007/s13042-024-02361-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution (DE) is a cutting-edge meta-heuristic algorithm known for its simplicity and low computational overhead. But the traditional DE cannot effectively balance between exploration and exploitation. To solve this problem, in this paper, a dynamic dual-population DE variant (ADPDE) is proposed. Firstly, the dynamic population division mechanism based on individual potential value is presented to divide the population into two subgroups, effectively improving the population diversity. Secondly, a nonlinear reduction mechanism is designed to dynamically adjust the size of potential subgroup to allocate computing resources reasonably. Thirdly, two unique mutation strategies are adopted for two subgroups respectively to better utilise the effective information of potential individuals and ensure fast convergence speed. Finally, adaptive parameter setting methods of two subgroups further achieve the balance between exploration and exploitation. The effectiveness of improved strategies is verified on 21 classical benchmark functions. Then, to verify the overall performance of ADPDE, it is compared with three standard DE algorithms, eight excellent DE variants and seven advanced evolutionary algorithms on CEC2013, CEC2017 and CEC2020 test suites, respectively, and the results show that ADPDE has higher accuracy and faster convergence speed. Furthermore, ADPDE is compared with eight well-known optimizers and CEC2020 winner algorithms on nine real-world engineering optimization problems, and the results indicate ADPDE has the development potential for constrained optimization problems as well.},
  archive      = {J_IJMLC},
  author       = {Zuo, Wenlu and Gao, Yuelin},
  doi          = {10.1007/s13042-024-02361-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1701-1760},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Solving numerical and engineering optimization problems using a dynamic dual-population differential evolution algorithm},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image recoloring for multiple types of color vision
deficiency. <em>IJMLC</em>, <em>16</em>(3), 1691–1700. (<a
href="https://doi.org/10.1007/s13042-024-02360-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are many techniques for recoloring images with different effects and improving color discrimination in patients with color vision defects. However, certain issues still persist, such as the unnatural and discordant colors of objects in the converted image. To address these problems, we have explored a comprehensive set of methods to achieve image recoloration. Our approach enables the resulting images to possess three essential characteristics: naturalness, harmonization, and distinguishability, thereby fulfilling the requirements of Color Vision Deficiency individuals. The method comprises two components: recommended palette generation and image recoloring. The former can learn the color distribution of different objects in nature, while the latter can recolor the image in conjunction with the recommended palette. Our experimental findings demonstrate that our approach is feasible and provides a direction for future research.},
  archive      = {J_IJMLC},
  author       = {Jin, Xin and Li, Dandan and Rong, Yiqing and Zou, Dongqing and Zhou, Wu and Zhang, Xiaokun},
  doi          = {10.1007/s13042-024-02360-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1691-1700},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Image recoloring for multiple types of color vision deficiency},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scnet: Shape-aware convolution with KFNN for point clouds
completion. <em>IJMLC</em>, <em>16</em>(3), 1671–1690. (<a
href="https://doi.org/10.1007/s13042-024-02359-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scanned 3D point cloud data is typically noisy and incomplete. Existing point cloud completion methods tend to learn a mapping of available parts to the complete one but ignore the structural relationships in local regions. They are less competent in learning point distributions and recovering the details of the object. This paper proposes a shape-aware point cloud completion network (SCNet) that employs multi-scale features and a coarse-to-fine strategy to generate detailed, complete point clouds. Firstly, we introduce a K-feature nearest neighbor algorithm to explore local geometric structure and design a novel shape-aware graph convolution that utilizes multiple learnable filters to perceive local shape changes in different directions. Secondly, we adopt non-local feature expansion to generate a coarse point cloud as the rough shape and merge it with the input data to preserve the original structure. Finally, we employ a residual network to fine-tune the point coordinates to smooth the merged point cloud, which is then optimized to a fine point cloud using a refinement module with shape-aware graph convolution and local attention mechanisms. Extensive experiments demonstrate that our SCNet outperforms other methods on the same point cloud completion benchmark and is more stable and robust.},
  archive      = {J_IJMLC},
  author       = {Wu, Xiangyang and Lu, Ziyuan and Qu, Chongchong and Zhou, Haixin and Miao, Yongwei},
  doi          = {10.1007/s13042-024-02359-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1671-1690},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Scnet: Shape-aware convolution with KFNN for point clouds completion},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing ocular diseases recognition with domain adaptive
framework: Leveraging domain confusion. <em>IJMLC</em>, <em>16</em>(3),
1661–1669. (<a
href="https://doi.org/10.1007/s13042-024-02358-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual health and optimal eyesight hold immense importance in our lives. However, ocular diseases can inflict emotional and financial hardships on patients and families. While various clinical methods exist for diagnosing ocular conditions, early screening of retinal images offers not only a cost-effective approach but also the detection of potential ocular diseases at earlier stages. Simultaneously, many studies have harnessed Convolutional Neural Networks (CNNs) for image recognition, capitalizing on their potential. Nevertheless, the applicability of most networks tends to be limited across different domains. When well-trained models from a domain are applied to another domain, a significant decline in accuracy might occur, thereby constraining the networks’ practical implementation and wider adoption. In this research endeavor, we present a domain adaptive framework, ResNet-50 with Maximum Mean Discrepancy (RMMD). Initially, we employed ResNet-50 architecture as a foundational network, a popular network used for modification and experimenting with whether a module could improve the accuracy. Additionally, we introduce the concept of Maximum Mean Discrepancy (MMD), a metric for quantifying domain differences. Subsequently, we integrate MMD into the loss function, inducing a state of confusion within the network concerning domain disparities. The outcomes derived from the OIA-ODIR dataset substantiate the efficacy of our proposed network. Our framework attains an impressive accuracy of 40.51% (F1) and 81.06% (AUC, Area Under the Receiver Operating Characteristic Curve), marking a notable enhancement of 9.52% and 7.18% respectively when juxtaposed with the fundamental ResNet-50 model, compared with raw ResNet-50 30.99% (F1) and 73.88% (AUC).},
  archive      = {J_IJMLC},
  author       = {Wang, Zayn},
  doi          = {10.1007/s13042-024-02358-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1661-1669},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Enhancing ocular diseases recognition with domain adaptive framework: Leveraging domain confusion},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). YOLO-SDH: Improved YOLOv5 using scaled decoupled head for
object detection. <em>IJMLC</em>, <em>16</em>(3), 1643–1660. (<a
href="https://doi.org/10.1007/s13042-024-02357-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a crucial component of computer vision tasks, object detection serves a significant role in a variety of fields, including autonomous driving, defect detection, and remote sensing image recognition. However, the majority of current object detection networks fail to achieve a decent balance between detection accuracy and detection efficiency, and there is room for improvement in terms of detection accuracy. In response, to improve detection accuracy, a more efficient network framework, YOLO-SDH, was proposed in this paper based on You Only Look Once v5 (YOLOv5). In addition, a decoupled head that automatically adjusts the number of channels according to the model size was proposed, which can enhance the network’s detection effect by separating the classification and regression tasks.On the premise of requiring less computation, a lightweight deformable convolution module is proposed so that the convolution can extract ROI over a wider range, thereby enhancing the accuracy of the object detection network. Experiments were run on the datasets of PASCAL VOC2012, NEU-DET, AW, and RSOD. In comparison to the original YOLOv5, the mAP 0.5 of YOLO-SDH improved by 1.29–3.03%, the F1-score improved by 1.2–3.2%, the Precision improved by 0.7–4.2%, demonstrating the algorithm’s efficacy and superiority.},
  archive      = {J_IJMLC},
  author       = {Ren, Zhijie and Yao, Kang and Sheng, Silong and Wang, Beibei and Lang, Xianli and Wan, Dahang and Fu, Weiwei},
  doi          = {10.1007/s13042-024-02357-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1643-1660},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {YOLO-SDH: Improved YOLOv5 using scaled decoupled head for object detection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight graph neural network architecture search based
on heuristic algorithms. <em>IJMLC</em>, <em>16</em>(3), 1625–1641. (<a
href="https://doi.org/10.1007/s13042-024-02356-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A graph neural network is a deep learning model for processing graph data. In recent years, graph neural network architectures have become more and more complex as the research progresses, thus the design of graph neural networks has become an important task. Graph Neural Architecture Search aims to automate the design of graph neural network architectures. However, current methods require large computational resources, cannot be applied in lightweight scenarios, and the search process is not transparent. To address these challenges, this paper proposes a graph neural network architecture search method based on a heuristic algorithm combining tabu search and evolutionary strategies (Gnas-Te). Gnas-Te mainly consists of a tabu search algorithm module and an evolutionary strategy algorithm module. The tabu Search Algorithm Module designs and implements for the first time the tabu Search Algorithm suitable for the search of graph neural network architectures, and uses the maintenance of the tabu table to guide the search process. The evolutionary strategy Algorithm Module implements the evolutionary strategy Algorithm for the search of architectures with the design goal of being light-weight. After the reflection and implementation of Gnas-Te, in order to provide an accurate evaluation of the neural architecture search process, a new metric EASI is proposed. Gnas-Te searched architecture is comparable to the excellent human-designed graph neural network architecture. Experimental results on three real datasets show that Gnas-Te has a 1.37% improvement in search accuracy and a 37.7% reduction in search time to the state-of-the-art graph neural network architecture search method for an graph node classification task and can find high allround-performance architectures which are comparable to the excellent human-designed graph neural network architecture. Gnas-Te implements a lightweight and efficient search method that reduces the need of computational resources for searching graph neural network structures and meets the need for high-accuracy architecture search in the case of insufficient computational resources.},
  archive      = {J_IJMLC},
  author       = {Zhao, ZiHao and Tang, XiangHong and Lu, JianGuang and Huang, Yong},
  doi          = {10.1007/s13042-024-02356-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1625-1641},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Lightweight graph neural network architecture search based on heuristic algorithms},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-refined variational transformer for image-conditioned
layout generation. <em>IJMLC</em>, <em>16</em>(3), 1607–1624. (<a
href="https://doi.org/10.1007/s13042-024-02355-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Layout generation is an emerging computer vision task that incorporates the challenges of object localization and aesthetic evaluation, widely used in advertisements, posters, and slides design. An ideal layout should consider both the intra-domain relationship within layout elements and the inter-domain relationship between layout elements and the image. However, most previous methods simply focus on image-content-agnostic layout generation without leveraging the complex visual information from the image. To address this limitation, we propose a novel paradigm called image-conditioned layout generation, which aims to add text overlays to an image in a semantically coherent manner. Specifically, we introduce the Image-Conditioned Variational Transformer (ICVT) that autoregressively generates diverse layouts in an image. Firstly, the self-attention mechanism is adopted to model the contextual relationship within layout elements, while the cross-attention mechanism is used to fuse the visual information of conditional images. Subsequently, we take them as building blocks of the conditional variational autoencoder (CVAE), which demonstrates attractive diversity. Secondly, to alleviate the gap between the layout elements domain and the visual domain, we design a Geometry Alignment module, in which the geometric information of the image is aligned with the layout representation. Thirdly, we present a self-refinement mechanism to automatically refine the failure case of generated layout, effectively improving the quality of generation. Experimental results show that our model can adaptively generate layouts in the non-intrusive area of the image, resulting in a harmonious layout design.},
  archive      = {J_IJMLC},
  author       = {Cao, Yunning and Liu, Chuanbin and Ma, Ye and Zhou, Min and Ge, Tiezheng and Jiang, Yuning and Xie, Hongtao},
  doi          = {10.1007/s13042-024-02355-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1607-1624},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Self-refined variational transformer for image-conditioned layout generation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Propagation tree says: Dynamic evolution characteristics
learning approach for rumor detection. <em>IJMLC</em>, <em>16</em>(3),
1589–1605. (<a
href="https://doi.org/10.1007/s13042-024-02354-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the rapid spread of rumors on social media, which has a detrimental effect on our lives, it is becoming increasingly important to detect rumors. It has been proved that the study of dynamic graphs is helpful to capture the temporal change of information transmission and understand the evolution trend and pattern change of events. However, the dynamic learning methods currently studied do not fully consider the interaction characteristics of the evolutionary process. Therefore, it is difficult to fully capture the structural and semantic differences between them. In order to fully exploit the potential correlations of such temporal information, we propose a novel model named dynamic evolution characteristics learning (DECL) method for rumor detection. First, we partition the temporal snapshot sequences based on the propagation structure of rumors. Secondly, a multi-task graph contrastive learning method is adopted to enable the graph encoder to capture the essential features of rumors, and to fully explore the temporal structural differences and semantic similarities between true rumor and false rumor events. Experimental results on three real-world social media datasets confirm the effectiveness of our model for rumor detection tasks.},
  archive      = {J_IJMLC},
  author       = {Zhao, Shouhao and Ji, Shujuan and Lv, Jiandong and Fang, Xianwen},
  doi          = {10.1007/s13042-024-02354-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1589-1605},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Propagation tree says: Dynamic evolution characteristics learning approach for rumor detection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised progressive graph neural network for
enhanced multi-behavior recommendation. <em>IJMLC</em>, <em>16</em>(3),
1573–1588. (<a
href="https://doi.org/10.1007/s13042-024-02353-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-behavior recommendation (MBR) aims to enhance the accuracy of predicting target behavior by considering multiple behaviors simultaneously. Recent researches have attempted to capture the dependencies within behavioral sequences to improve recommendation outcomes, exemplified by the sequential pattern “click $$\rightarrow $$ cart $$\rightarrow $$ buy”. However, their performances are still limited due to the following two problems. Firstly, potential leapfrogging relations among behaviors are underexplored, notably in cases where users purchase directly post-click, bypassing the cart stage. Skipping intermediate behavior allows for better modeling of real-world realities. Secondly, the uneven distribution of user behaviors and item popularity presents a challenge for model training, resulting in prevalence bias and over-reliance issues. To this end, we propose a self-supervised progressive graph neural network model, namely SSPGNN. The model can capture a broader range of behavioral dependencies by using a dual-behavior chain. In addition, we design a self-supervised learning mechanism, including intra- and inter-behavioral self-supervised learning, the former within a single behavior and the latter across multiple behaviors, to address the problems of prevalence bias and overdependence. Extensive experiments on real-world datasets and comparative analyses with state-of-the-art algorithms demonstrate the effectiveness of the proposed SSPGNN. The source codes of this work are available at https://github.com/ZZY-GraphMiningLab/SSPGNN .},
  archive      = {J_IJMLC},
  author       = {Liu, Tianhang and Zhou, Hui and Li, Chao and Zhao, Zhongying},
  doi          = {10.1007/s13042-024-02353-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1573-1588},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Self-supervised progressive graph neural network for enhanced multi-behavior recommendation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GRPIC: An end-to-end image captioning model using three
visual features. <em>IJMLC</em>, <em>16</em>(3), 1559–1572. (<a
href="https://doi.org/10.1007/s13042-024-02352-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {lmage captioning is a multimodal task involving both computer vision and natural language processing. Recently, there has been a substantial improvement in the performance of image captioning with the introduction of multi-feature extraction methods. However, existing single-feature and multi-feature methods still face challenges such as a low refinement degree, weak feature complementarity, and lack of an end-to-end model. To tackle these issues, we propose an end-to-end image captioning model called GRPIC (Grid-Region-Pixel Image Captioning), which integrates three types of image features: region features, grid features, and pixel features. Our model utilizes the Swin Transformer for extracting grid features, DETR for extracting region features, and Deeplab for extracting pixel features. We merge pixel-level features with region and grid features to extract more refined contextual and detailed information. Additionally, we incorporate absolute position information and pairwise align the three features to fully leverage their complementarity. Qualitative and quantitative experiments conducted on the MSCOCO dataset demonstrate that our model achieved a 2.3% improvement in CIDEr, reaching 136.1 CIDEr compared to traditional dual-feature methods on the Karpathy test split. Furthermore, observation of the actual generated descriptions shows that the model also produced more refined captions.},
  archive      = {J_IJMLC},
  author       = {Peng, Shixin and Xiong, Can and Liu, Leyuan and Yang, Laurence T. and Chen, Jingying},
  doi          = {10.1007/s13042-024-02352-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1559-1572},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {GRPIC: An end-to-end image captioning model using three visual features},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Label distribution learning by utilizing common and
label-specific feature fusion space. <em>IJMLC</em>, <em>16</em>(3),
1545–1558. (<a
href="https://doi.org/10.1007/s13042-024-02351-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label Distribution Learning (LDL) is a novel machine learning paradigm that focuses on the description degrees of labels to a particular instance. Existing LDL algorithms generally learn with the original input space, that is, all features are simply employed in the discrimination processes of all class labels. However, this common-used data representation strategy ignores that each label is supposed to possess some specific characteristics of its own and therefore, may lead to sub-optimal performance. We propose label distribution learning by utilizing common and label-specific feature fusion space (LDL-CLSFS) in this paper. It first partitions all instances by label-value rankings. Second, it constructs label-specific features of each label by conducting clustering analysis on different instance categories. Third, it performs training and testing by querying the clustering results. Comprehensive experiments on several real-world label distribution data sets validate the superiority of our method against other LDL algorithms as well as the effectiveness of label-specific features.},
  archive      = {J_IJMLC},
  author       = {Zhang, Ziyun and Wang, Jing and Geng, Xin},
  doi          = {10.1007/s13042-024-02351-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1545-1558},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Label distribution learning by utilizing common and label-specific feature fusion space},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An ordered subsets orthogonal nonnegative matrix
factorization framework with application to image clustering.
<em>IJMLC</em>, <em>16</em>(3), 1531–1543. (<a
href="https://doi.org/10.1007/s13042-024-02350-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonnegative matrix factorization (NMF) for image clustering attains impressive machine learning performances. However, the current iterative methods for optimizing NMF problems involve numerous matrix calculations and suffer from high computational costs in large-scale images. To address this issue, this paper presents an ordered subsets orthogonal NMF framework (OS-ONMF) that divides the data matrix in an orderly manner into several subsets and performs NMF on each subset. It balances clustering performance and computational efficiency. After decomposition, each ordered subset still contains the core information of the original data. That is, blocking does not reduce image resolutions but can greatly shorten running time. This framework is a general model that can be applied to various existing iterative update algorithms. We also provide a subset selection method and a convergence analysis of the algorithm. Finally, we conducted clustering experiments on seven real-world image datasets. The experimental results showed that the proposed method can greatly shorten the running time without reducing clustering accuracy.},
  archive      = {J_IJMLC},
  author       = {Ma, Limin and Tong, Can and Qi, Shouliang and Yao, Yudong and Teng, Yueyang},
  doi          = {10.1007/s13042-024-02350-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1531-1543},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An ordered subsets orthogonal nonnegative matrix factorization framework with application to image clustering},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Clustered automated machine learning (CAML) model for
clinical coding multi-label classification. <em>IJMLC</em>,
<em>16</em>(3), 1507–1529. (<a
href="https://doi.org/10.1007/s13042-024-02349-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical coding is a time-consuming task that involves manually identifying and classifying patients’ diseases. This task becomes even more challenging when classifying across multiple diagnoses and performing multi-label classification. Automated Machine Learning (AutoML) techniques can improve this classification process. However, no previous study has developed an AutoML-based approach for multi-label clinical coding. To address this gap, a novel approach, called Clustered Automated Machine Learning (CAML), is introduced in this paper. CAML utilizes the AutoML library Auto-Sklearn and cTAKES feature extraction method. CAML clusters binary diagnosis labels using Hamming distance and employs the AutoML library to select the best algorithm for each cluster. The effectiveness of CAML is evaluated by comparing its performance with that of the Auto-Sklearn model on five different datasets from the Medical Information Mart for Intensive Care (MIMIC III) database of reports. These datasets vary in size, label set, and related diseases. The results demonstrate that CAML outperforms Auto-Sklearn in terms of Micro F1-score and Weighted F1-score, with an overall improvement ratio of 35.15% and 40.56%, respectively. The CAML approach offers the potential to improve healthcare quality by facilitating more accurate diagnoses and treatment decisions, ultimately enhancing patient outcomes.},
  archive      = {J_IJMLC},
  author       = {Mustafa, Akram and Rahimi Azghadi, Mostafa},
  doi          = {10.1007/s13042-024-02349-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1507-1529},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Clustered automated machine learning (CAML) model for clinical coding multi-label classification},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contextual feature fusion and refinement network for
camouflaged object detection. <em>IJMLC</em>, <em>16</em>(3), 1489–1505.
(<a href="https://doi.org/10.1007/s13042-024-02348-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged object detection (COD) is a challenging task due to its irregular shape and color similarity or even blending into the surrounding environment. It is difficult to achieve satisfactory results by directly using salient object detection methods due to the low contrast with the surrounding environment and obscure object boundary in camouflaged object detection. To determine the location of the camouflaged objects and achieve accurate segmentation, the interaction between features is essential. Similarly, an effective feature aggregation method is also very important. In this paper, we propose a contextual fusion and feature refinement network (CFNet). Specifically, we propose a multiple-receptive-fields-based feature extraction module (MFM) that obtains features from multiple scales of receptive fields. Then, the features are input to an attention-based information interaction module (AIM), which establishes the information flow between adjacent layers through an attention mechanism. Finally, the features are fused and optimized layer by layer using a feature fusion module (FFM). We validate the proposed CFNet as an effective COD model on four benchmark datasets, and the generalization ability of our proposed model is verified in the salient object detection task.},
  archive      = {J_IJMLC},
  author       = {Yang, Jinyu and Shi, Yanjiao and Jiang, Ying and Lu, Zixuan and Yi, Yugen},
  doi          = {10.1007/s13042-024-02348-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1489-1505},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Contextual feature fusion and refinement network for camouflaged object detection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight skeleton-based action recognition model based on
global–local feature extraction and fusion. <em>IJMLC</em>,
<em>16</em>(3), 1477–1488. (<a
href="https://doi.org/10.1007/s13042-024-02347-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skeleton-based action recognition has become a research hotspot in the field of computer vision because of its lightweight and strong anti-interference. However, there are disadvantages such as single feature extraction, limited expression ability, and low recognition accuracy. To solve these problems, we propose a lightweight Skeleton-based action recognition model based on global–local feature extraction and fusion (GLF-GCN). GLF-GCN includes a Feature extraction of non-connected nodes Module (Global-GCN), a Feature extraction of adjacent nodes Module (Local-GCN), and a Dynamic Fusion module. More specifically, Global-GCN combines one-dimensional convolution and shift operations to capture spatio-temporal dependencies across global nodes, using shift operations as a replacement for spatio-temporal graph convolution to reduce computational complexity. Meanwhile, Local-GCN captures temporal and spatial local information from first-order neighboring nodes. On this basis, Dynamic Fusion integrates global information based on joint hierarchy and local information based on body parts to discern the varying dependency relationships among different body parts and joints, improving the model’s ability to interpret different skeleton action sequences. The experimental results on single stream and multi-stream data show that the proposed model has higher accuracy, which attains the state-of-the-art performance.},
  archive      = {J_IJMLC},
  author       = {Deng, Zhe and Wang, Yulin and Wei, Xing and Yang, Fan and Zhao, Chong and Lu, Yang},
  doi          = {10.1007/s13042-024-02347-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1477-1488},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Lightweight skeleton-based action recognition model based on global–local feature extraction and fusion},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visual tracking with screening region enrichment and target
validation. <em>IJMLC</em>, <em>16</em>(3), 1461–1475. (<a
href="https://doi.org/10.1007/s13042-024-02346-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The introduction of the one-stream one-stage framework has led to remarkable advances in visual object tracking, resulting in exceptional tracking performance. Most existing one-stream one-stage tracking pipelines have achieved a relative balance between accuracy and speed. However, they focus solely on integrating feature learning and relational modelling. In complex scenes, the tracking performance often falls short due to confounding factors such as changes in target scale, occlusion, and fast motion. In these cases, numerous trackers cannot sufficiently exploit the target feature information and face the dilemma of information loss. To address these challenges, we propose a screening enrichment for transformer-based tracking. Our method incorporates a screening enrichment module as an additional processing operation in the integration of feature learning and relational modelling. The module effectively distinguishes target areas within the search regions. It also enriches the associations between tokens of target area information. In addition, we introduce our box validation module. This module uses the target position information from the previous frame to validate and revise the target position in the current frame. This process enables more accurate target localization. Through these innovations, we have developed a powerful and efficient tracker. It achieves state-of-the-art performance on six benchmark datasets, including GOT-10K, LaSOT, TrackingNet, UAV123, TNL2K and VOT2020. On the GOT-10K benchmarks, Specifically, on the GOT-10K benchmarks, our proposed tracker reaches an impressive Success Rate ( $$S{{R}_{0.5}}$$ ) of 85.4 and an Average Overlap (AO) of 75.3. Experimental results show that our proposed tracker outperforms other state-of-the-art trackers in terms of tracking accuracy.},
  archive      = {J_IJMLC},
  author       = {Sun, Yiqiu and Zhou, Dongming and Yan, Kaixiang},
  doi          = {10.1007/s13042-024-02346-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1461-1475},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Visual tracking with screening region enrichment and target validation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
