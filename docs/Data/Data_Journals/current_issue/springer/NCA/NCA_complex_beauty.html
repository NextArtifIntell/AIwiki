<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NCA_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="nca---16">NCA - 16</h2>
<ul>
<li><details>
<summary>
(2025). Improving paraphrase generation using supervised
neural-based statistical machine translation framework. <em>NCA</em>,
<em>37</em>(11), 7705–7719. (<a
href="https://doi.org/10.1007/s00521-023-08830-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In phrase generation (PG), a sentence in the natural language is changed into a new one with a different syntactic structure but having the same semantic meaning. The present sequence-to-sequence strategy aims to recall the words and structures from the training dataset rather than learning the words&#39; semantics. As a result, the resulting statements are frequently grammatically accurate but incorrect linguistically. The neural machine translation approach suffers to handle unusual words, domain mismatch, and unfamiliar words, but it takes context well. This work presents a novel model for creating paraphrases that use neural-based statistical machine translation (NSMT). Our approach creates potential paraphrases for any source input, calculates the level of semantic similarity between text segments of any length, and encodes paraphrases in a continuous space. To evaluate the suggested model, Quora Question Pair and Microsoft Common Objects in Context benchmark datasets are used. We demonstrate that the proposed technique achieves cutting-edge performance on both datasets using automatic and human assessments. Experimental findings across tasks and datasets demonstrate that the suggested NSMT-based PG outperforms those achieved with traditional phrase-based techniques. We also show that the proposed technique may be used automatically for the development of paraphrases for a variety of languages.},
  archive      = {J_NCA},
  author       = {Razaq, Abdur and Shah, Babar and Khan, Gohar and Alfandi, Omar and Ullah, Abrar and Halim, Zahid and Ur Rahman, Atta},
  doi          = {10.1007/s00521-023-08830-4},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7705-7719},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving paraphrase generation using supervised neural-based statistical machine translation framework},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detection of tampered real time videos using deep neural
networks. <em>NCA</em>, <em>37</em>(11), 7691–7703. (<a
href="https://doi.org/10.1007/s00521-024-09988-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been a significant increase in the creation and sharing of videos that promote the utilization of digitally interactive multimedia, including music, graphics, and videos, across various devices. This trend encompasses both social networking applications and everyday tasks, mirroring the growing reliance on digital communication devices. Forgery techniques and motivations in the digital realm have undergone significant advancements. Previously, video editing methods were employed to enhance digital content. However, the proliferation of affordable and user-friendly video editing software has introduced several drawbacks and risks associated with these editing techniques. These editing tools can be misused to create misleading, altered, or fabricated videos for malicious purposes, such as spreading misinformation, deception, or defamation. In order to produce altered or fraudulent videos, additional footage is mixed, edited, or synthesized. Sophisticated editing techniques can make it challenging to detect forged videos, making it easier for forgeries to be mistakenly perceived as genuine. Existing method uses methods that detect forgery in videos with simply static backgrounds only. Proposed systems uses a deep learning strategy that incorporates transfer learning utilizing VGG16 and Customized CNN layers to categorize real time videos as tampered or authentic. With the aid of deep neural networks, the suggested method may identify forgery in films with both static and moving backgrounds. The experimental findings show that the suggested strategy is more accurate and effective than existing methods also it provides trustworthy results with low computing cost and strong detection performance.},
  archive      = {J_NCA},
  author       = {Koshy, Litty and Shyry, S. Prayla},
  doi          = {10.1007/s00521-024-09988-1},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7691-7703},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detection of tampered real time videos using deep neural networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A study of progressive data flow knowledge tracing based on
reconstructed attention mechanism. <em>NCA</em>, <em>37</em>(11),
7675–7689. (<a
href="https://doi.org/10.1007/s00521-024-10011-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge tracing (KT) is an essential task in intellectual education, which measures learners’ ability to learn new knowledge by collecting historical learning information from learners. With the introduction of Recurrent Neural Networks (RNN) and Transformer into the field of KT, although effective, they focus only on the temporal order in which the learner information is affected. To model accurately, we propose a KT model BPKT (Bayesian-Attention mechanism Progressive data flow for KT) that allows exercise embedding to be layered in different forms and incorporated into the model multiple times. The BPKT model integrates the relationship between exercises covering knowledge points in both the temporal and spatial aspects, and defines a Bayesian-Attention mechanism based on this, with an in-depth analysis of the realistic meaning of the micro-parameters Q, K, and V in the mechanism. Through experiments on four real benchmark datasets, the results show that the BPKT model is helpful for predicting learners’ future responses on large-scale datasets.},
  archive      = {J_NCA},
  author       = {Wu, Qianxi and Wang, Min and Zhou, Guohui and Ji, Weidong},
  doi          = {10.1007/s00521-024-10011-w},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7675-7689},
  shortjournal = {Neural Comput. Appl.},
  title        = {A study of progressive data flow knowledge tracing based on reconstructed attention mechanism},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep perceptual framework for affective video tagging
through multiband EEG signals modeling. <em>NCA</em>, <em>37</em>(11),
7657–7674. (<a
href="https://doi.org/10.1007/s00521-023-09086-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, multimedia content, such as photographs and movies, is ingrained in every aspect of human lives and has become a vital component of their entertainment. Multimedia content, such as videos or movie clips, is typically created with the intent to evoke certain feelings or emotions in viewers. Thus, by examining the viewer’s cognitive state while watching such content, its affectiveness can be evaluated. Considering the emotional aspect of videos, in this paper, a deep learning-based paradigm for affective tagging of video clips is proposed, in which participants’ irrational EEG responses are used to examine how people perceive videos. The information behind different brain regions, frequency waves, and connections among them play an important role in understanding a human’s cognitive state. Thus, here a contribution is made toward the effective modeling of EEG signals through two different representations, i.e., spatial feature matrix and combined power spectral density maps. The proposed feature representations highlight the spatial features of EEG signals and are therefore used to train a convolution neural network model for implicit tagging of two categories of videos in the Arousal domain, i.e., “Low Arousal” and “High Arousal.” The arousal emotional space represents the excitement level of the viewer; thus, this domain is selected to analyze the viewer’s engagement while watching video clips. The proposed model is developed using the EEG data taken from publicly available datasets “AMIGOS” and “DREAMER.” The model is tested using two different approaches, i.e., single-subject classification and multi-subject classification, and an average accuracy of 90%-95% and 90%-93% is achieved, respectively. The simulations presented in this paper show the pioneering applicability of the proposed framework for the development of brain–computer interface (BCI) devices for affective tagging of videos.},
  archive      = {J_NCA},
  author       = {Sharma, Shanu and Dubey, Ashwani Kumar and Ranjan, Priya and Rocha, Alvaro},
  doi          = {10.1007/s00521-023-09086-8},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7657-7674},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep perceptual framework for affective video tagging through multiband EEG signals modeling},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Denoising histopathology images for the detection of breast
cancer. <em>NCA</em>, <em>37</em>(11), 7641–7655. (<a
href="https://doi.org/10.1007/s00521-023-08771-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the leading causes of mortality for women worldwide, both in developing and developed economies, is breast cancer. The gold standard for diagnosing cancer is still histological diagnosis, despite major advances in medical understanding. Admittedly, due to the sophistication of histopathology images and the significant increase in workload, this process takes a long time. Therefore, this field requires the development of automated and precise histopathology image analysis tools. Using deep learning, we proposed a system for denoising, detecting, and classifying breast cancer using deep learning architectures that are designed to solve certain related problems. CNN-based architectures are used to extract features from images, which are then put into a fully connected layer for the classification of malignant and benign cells, as well as their subclasses, in the suggested framework. The effectiveness of the suggested framework is evaluated through experiments leveraging accepted benchmark data sets. We achieve an accuracy of 94% and an F1 score of more than 90%.},
  archive      = {J_NCA},
  author       = {Zeb, Muhammad Haider and Al-Obeidat, Feras and Tubaishat, Abdallah and Qayum, Fawad and Fazeel, Ahsan and Amin, Muhammad},
  doi          = {10.1007/s00521-023-08771-y},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7641-7655},
  shortjournal = {Neural Comput. Appl.},
  title        = {Denoising histopathology images for the detection of breast cancer},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic gait analysis through computer vision: A pilot
study. <em>NCA</em>, <em>37</em>(11), 7619–7639. (<a
href="https://doi.org/10.1007/s00521-023-08549-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kinesiologists who study people&#39;s posture during walking depend on spreadsheets and visual posture reviews. Gold-standard evaluation relies on expert evaluation, not mediated by technology. However, today there are technological advances to automate specific processes adequately. Our proposal focuses on developing software based on computer vision and artificial intelligence (AI) to support recognition in the gait cycle and walking activities. The software is deployed in an architecture based on microservices to support the image analysis process with high concurrency. We opted for an open-source alternative, Openpose, because it is one of the most popular detection libraries for pose estimation and is capable of real-time multi-person pose analysis. We validate the choice through a proof of concept in which we prove that it can be possible to obtain valuable results for the kinesiology care process. This software assists specialists in analyzing and measuring lower extremity angles and distances during gait. We developed an information system based on open-source pose estimation algorithms for clinical decision-making. The technological approach was obtained by analyzing similar proposals and considering the characteristics of the clinic. We used a real-time multi-person pose estimation as an essential element enabling machines to visually comprehend and analyze humans and their interactions. In this instance, we identified accuracy metrics and optimized the evaluation process time. Using a non-probabilistic sample, we analyzed the videos of users performing the gait exercises. These results indicate that although the algorithms still need to achieve perfect accuracy, they save manual work for the final evaluation. On average, using the platforms reduces by about 50% the total time required to generate the final reports delivered by the kinesiology clinic. This proposal has always been justified as a support to the professional work and not as a replacement. We propose an information system based on open-source pose estimation algorithms for clinical decision-making. The technological approach was obtained by analyzing similar proposals and considering the characteristics of the clinic. We used a real-time multi-person pose estimation as an essential element enabling machines to visually comprehend and analyze humans and their interactions. While these recognition alternatives have been explored for some time, linking with particular needs and improving healthcare processes is critical.},
  archive      = {J_NCA},
  author       = {Díaz-Arancibia, Jaime and Córdova, Matías and Arango-López, Jeferson and Ahumada, Danay and Moreira, Fernando},
  doi          = {10.1007/s00521-023-08549-2},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7619-7639},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic gait analysis through computer vision: A pilot study},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A non-invasive approach for calcium deficiency detection in
pears using machine learning. <em>NCA</em>, <em>37</em>(11), 7609–7618.
(<a href="https://doi.org/10.1007/s00521-023-08444-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A pear is a sweet fruit that is rich in dietary fiber, antioxidants, and plant compounds. The nutritional disorder in pears is either due to deficiency of nutrients or toxicity of nutrients. The techniques to identify the nutrients deficiencies include tissue testing, soil analysis, plant analysis, and visual deficiency symptoms. The effects of alfalfa greening, black end, and cork spot are minimised by correcting the calcium nutrition in the pear tree. In this paper, a two-class decision jungle model is proposed for the recognition of calcium deficiency in pears based on a non-invasive approach. The calcium deficiency in pears makes a bumpy fruit surface and leaves yellow color on the affected area than the rest of the skin results in the greyish corky lesion. The nutrient deficiency that results in serious disorders in pears not only influences the plant but also impacts the fruit quality. The introduction of artificial intelligence in the agriculture industry has helped farmers to produce healthier fruits. The artificial intelligence provides a real-time data for the classifier that results in increasing agricultural efficiencies, better crop yields and reduce fruit production costs by facilitating the routine and most complex tasks. The two-class decision jungle model achieves an accuracy of 98% with a database of 1000 samples. The other approaches, such as Boosted decision tree, Bayes point machine, Logistic regression, Neural Network, and SVM, have an accuracy of 92.20%, 84.3%, 72.5%, 82.4%, and 72.5%, respectively for the equivalent datasets. The highest accuracy is achieved with the proposed two class decision jungle that has non-linear decision boundaries and the performance is resilient in the presence of features that consist of noise. The number of calcium-deficient and healthy pears is 500 each. The geometrical features are extracted for the development of an artificial intelligence-based model for the classification of two classes like calcium deficient and healthy pear. The extracted features are split into training, validation, and testing. For training, validation, and testing, 80%, 10% and 10% samples are used respectively. The precision level is observed to be 0.974 and test accuracy is achieved as 98.7% and the overall accuracy 98% which are better than the existing 88.2% accuracy for pears using Support Vector Machine.},
  archive      = {J_NCA},
  author       = {Yogesh and Dubey, Ashwani Kumar and Rocha, Alvaro},
  doi          = {10.1007/s00521-023-08444-w},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7609-7618},
  shortjournal = {Neural Comput. Appl.},
  title        = {A non-invasive approach for calcium deficiency detection in pears using machine learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic review of integrated information theory: A
perspective from artificial intelligence and the cognitive sciences.
<em>NCA</em>, <em>37</em>(11), 7575–7607. (<a
href="https://doi.org/10.1007/s00521-023-08328-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of consciousness has gained momentum in recent years by the scientific community. In this same sense, the relationship between cognitive sciences and artificial intelligence presents a fundamental theoretical framework in the study of integrated information theory (IIT) as a theory that makes its way into the knowledge of consciousness. However, there are few studies that integrate these topics and a systematic review of the literature is highly pertinent. This paper seeks to identify methods, methodologies or computational solutions using artificial intelligence and cognitive science fundamentals that can provide some kind of solution to the challenges posed by IIT.},
  archive      = {J_NCA},
  author       = {Guerrero, Luz Enith and Castillo, Luis Fernando and Arango-López, Jeferson and Moreira, Fernando},
  doi          = {10.1007/s00521-023-08328-z},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7575-7607},
  shortjournal = {Neural Comput. Appl.},
  title        = {A systematic review of integrated information theory: A perspective from artificial intelligence and the cognitive sciences},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SureUnet: Sparse autorepresentation encoder u-net for noise
artifact suppression in low-dose CT. <em>NCA</em>, <em>37</em>(11),
7561–7573. (<a
href="https://doi.org/10.1007/s00521-023-08847-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-dose computed tomography (LDCT) is desirable due to ionizing radiation, but the resulting images suffer from serious streak artifacts and spot noise. Recently, deep learning (DL)-based methods have emerged as promising alternatives for medical image processing. However, most DL-based methods are built intuitively and lack interpretability, and it is difficult to effectively separate the artifacts and noise in LDCT images. Obtaining diagnostically useful images, especially when using a low-dose scanner protocol, remains an open challenge. To improve the quality of LDCT images, we developed a novel processing network called the sparse autorepresentation U-Net (SureUnet). First, inspired by multilayer convolutional sparse coding (CSC), we constructed a sparse autorepresentation encoder to sufficiently capture and represent hierarchical image features. Then, we chose the widely used U-Net model for sparse autorepresentation block applications and designed SureUnet by adding a feature decoding block. Therefore, every module has well-defined interpretability in our network. Additionally, hybrid loss functions were specifically designed, including the mean absolute error, edge loss and perceptual loss. Through the cooperation of multiple loss functions, the noise artifact suppression effect of the network was improved. The visual results obtained on the MAYO and UIH datasets show that the proposed method’s noise artifact suppression effect was more significant. The quantitative results showed promising improvement levels compared to those of the other state-of-the-art methods. The SureUnet model significantly outperformed the compared methods on two datasets, with margins of 0.4 dB for the PSNR, 0.007 for the SSIM, and 1.6 for the FID on the MAYO dataset and margins of 0.5 dB for the PSNR, 0.004 for the SSIM and 2.9 for the FID on the UIH dataset. This work paves the way for sparse autorepresentation in DL for processing LDCT images. Experimental results have demonstrated the competitive performance of SureUnet in terms of noise suppression, structural fidelity and visual impression improvement.},
  archive      = {J_NCA},
  author       = {Liu, Jin and Zhang, Tingyu and Kang, Yanqin and Qiang, Jun and Hu, Dianlin and Zhang, Yikun},
  doi          = {10.1007/s00521-023-08847-9},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7561-7573},
  shortjournal = {Neural Comput. Appl.},
  title        = {SureUnet: Sparse autorepresentation encoder U-net for noise artifact suppression in low-dose CT},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MixDA: Mixup domain adaptation for glaucoma detection on
fundus images. <em>NCA</em>, <em>37</em>(11), 7541–7560. (<a
href="https://doi.org/10.1007/s00521-023-08572-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural network has achieved promising results for automatic glaucoma detection on fundus images. Nevertheless, the intrinsic discrepancy across glaucoma datasets is challenging for the data-driven neural network approaches. This discrepancy leads to the domain gap that affects model performance and declines model generalization capability. Existing domain adaptation-based transfer learning methods mostly fine-tune pretrained models on target domains to reduce the domain gap. However, this feature learning-based adaptation method is implicit, and it is not an optimal solution for transfer learning on the diverse glaucoma datasets. In this paper, we propose a mixup domain adaptation (mixDA) method that bridges domain adaptation with domain mixup to improve model performance across divergent glaucoma datasets. Specifically, the domain adaptation reduces the domain gap of glaucoma datasets in transfer learning with an explicit adaptation manner. Meanwhile, the domain mixup further minimizes the risk of outliers after domain adaptation and improves the model generalization capability. Extensive experiments show the superiority of our mixDA on several public glaucoma datasets. Moreover, our method outperforms state-of-the-art methods by a large margin on four glaucoma datasets: REFUGE, LAG, ORIGA, and RIM-ONE.},
  archive      = {J_NCA},
  author       = {Yan, Ming and Lin, Yun and Peng, Xi and Zeng, Zeng},
  doi          = {10.1007/s00521-023-08572-3},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7541-7560},
  shortjournal = {Neural Comput. Appl.},
  title        = {MixDA: Mixup domain adaptation for glaucoma detection on fundus images},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diabetic retinopathy classification based on dense
connectivity and asymmetric convolutional neural network. <em>NCA</em>,
<em>37</em>(11), 7527–7540. (<a
href="https://doi.org/10.1007/s00521-022-07952-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy (DR) is the leading cause of blindness in diabetics. The low contrast and microscopic nature of the lesions lead to a high false positive rate for automated DR screening. To address this issue, we propose a neural network named AC-DenseNet for the five-stage DR classification. In order to exploit the shallow features and enhance the feature extraction performance, dense connectivity is added to the convolution layer of AC-DenseNet. For the convolution layer to be more robust for DR detection in rotated or flipped pictures, asymmetric convolution branches are also introduced. In addition, attention mechanisms and auxiliary classifiers are incorporated into the network for the improvement of the performance of DR classification. We validate AC-DenseNet on the enhanced Kaggle dataset. The results show that AC-DenseNet can achieve 88.8% accuracy, 97.1% specificity, and 88.7% sensitivity, demonstrating that our model outperforms several state-of-the-art algorithms.},
  archive      = {J_NCA},
  author       = {Cao, Juan and Chen, Jiaran and Zhang, Xinying and Peng, Yang},
  doi          = {10.1007/s00521-022-07952-5},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7527-7540},
  shortjournal = {Neural Comput. Appl.},
  title        = {Diabetic retinopathy classification based on dense connectivity and asymmetric convolutional neural network},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DH-GAC: Deep hierarchical context fusion network with
modified geodesic active contour for multiple neurofibromatosis
segmentation. <em>NCA</em>, <em>37</em>(11), 7511–7526. (<a
href="https://doi.org/10.1007/s00521-022-07945-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Delineating accurately and simultaneously all lesions is vital and challenging for computer-aided diagnosis for multiple neurofibromatosis (NF). However, existing CNN-based segmentation methods paid little attention to weak boundaries. Moreover, due to the intensity-inhomogeneous distribution of medical images, the ambiguous boundaries, and highly variable locations, sizes and shapes of the lesions, delineating multiple lesions simultaneously remains quite challenging. To address these challenges, we introduce a novel end-to-end segmentation framework of multiple NF, deep hierarchical geodesic active contour (DH-GAC). It leverages the elaborately designed deep hierarchical context fusion network (DH-CFN) to improve the generalization and robustness of DH-GAC, and the modified geodesic active contour (MGAC) to delineate precisely all lesions as much as possible. Specifically, it employs DH-CFN to predict specific parameter maps of each image for MGAC and feeds them into the energy function of MGAC to delineate NF lesions, which makes DH-GAC end-to-end trainable. Moreover, to improve the generalization of DH-GAC, we adopt two different settings to initialize the surface for DH-GAC. Experimental results demonstrate that DH-GAC not only improves the segmentation precision, but also overcomes the intrinsic drawback of classical geodesic active contour in boundary delineation.},
  archive      = {J_NCA},
  author       = {Wu, Xiangqiong and Tan, Guanghua and Pu, Bin and Duan, Mingxing and Cai, Wenli},
  doi          = {10.1007/s00521-022-07945-4},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7511-7526},
  shortjournal = {Neural Comput. Appl.},
  title        = {DH-GAC: Deep hierarchical context fusion network with modified geodesic active contour for multiple neurofibromatosis segmentation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CSPP-IQA: A multi-scale spatial pyramid pooling-based
approach for blind image quality assessment. <em>NCA</em>,
<em>37</em>(11), 7499–7510. (<a
href="https://doi.org/10.1007/s00521-022-07874-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional image quality assessment (IQA) methods are usually based on convolutional neural networks (CNNs). For these IQA methods using CNNs, limited by the feature size of the fully connected layer, the input image needs be tailored to a pre-defined size, which usually results in destroying the original structure and content of the input image and thus reduces the accuracy of the quality assessment. In this paper, a blind image quality assessment method (named CSPP-IQA), which is based on multi-scale spatial pyramid pooling, is proposed. CSPP-IQA allows inputting the original image when assessing the image quality without any image adjustment. Moreover, by facilitating the convolutional block attention module and image understanding module, CSPP-IQA achieved better accuracy, generalization and efficiency than traditional IQA methods. The result of experiments running on real-scene IQA datasets in this study verified the effectiveness and efficiency of CSPP-IQA.},
  archive      = {J_NCA},
  author       = {Chen, Jingjing and Qin, Feng and Lu, Fangfang and Guo, Lingling and Li, Chao and Yan, Ke and Zhou, Xiaokang},
  doi          = {10.1007/s00521-022-07874-2},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7499-7510},
  shortjournal = {Neural Comput. Appl.},
  title        = {CSPP-IQA: A multi-scale spatial pyramid pooling-based approach for blind image quality assessment},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CWC-transformer: A visual transformer approach for
compressed whole slide image classification. <em>NCA</em>,
<em>37</em>(11), 7485–7497. (<a
href="https://doi.org/10.1007/s00521-022-07857-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of Artificial Intelligence (AI) technology accelerates the application of computational pathology in clinical decision-making. Due to the restriction of computing resources and annotation information, it is challenging for AI-based computational pathology methods to effectively process and analyze the gigapixel whole slide image (WSI). Conventional methods utilize multiple instance learning (MIL) to convert WSI into patches for classification. However, without the patch-level annotation, it is difficult to extract discriminative features, even with pre-trained networks. Furthermore, forcibly applying the patch-level conversion will break the pathological characteristics of WSI from the spatial structure. In this study, we present a two-stage framework named Compressed WSI Classification (CWC-Transformer) to effectively solve the problems of feature extraction and spatial information loss in WSI classification. In the compression stage, we adopt contrastive learning to present a feature compression method, which not only extracts the discriminative features but also decreases the data deviation caused by staining and scanning inconsistency. In the learning stage, we extend the advantages of the convolutional neural network and transformer mechanism to enhance the co-relations between local and global information to provide the final results jointly. Experiments on three large-scale public datasets of different tasks show that our proposed framework outperforms other advanced methods in terms of robustness and interpretation.},
  archive      = {J_NCA},
  author       = {Wang, Yaowei and Guo, Jing and Yang, Yun and Kang, Yan and Xia, Yuelong and Li, Zhenhui and Duan, Yongchun and Wang, Kelong},
  doi          = {10.1007/s00521-022-07857-3},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7485-7497},
  shortjournal = {Neural Comput. Appl.},
  title        = {CWC-transformer: A visual transformer approach for compressed whole slide image classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Most relevant point query on road networks. <em>NCA</em>,
<em>37</em>(11), 7473–7483. (<a
href="https://doi.org/10.1007/s00521-022-07485-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs are widespread in many real-life practical applications. One of a graph’s fundamental and popular researches is investigating the relations between two given vertices. The relationship between nodes in the graph can be measured by the shortest distance. Moreover, the number of paths is also a popular metric to assess the relationship of different nodes. In many location-based services, users make decisions on the basis of both the two metrics. To address this problem, we propose a new hybrid-metric based on the number of paths with a distance constraint for road networks, which are special graphs. Based on it, a most relevant node query on road networks is identified. To handle this problem, we first propose a Shortest-Distance Constrained DFS, which uses the shortest distance to prune unqualified nodes. To further improve query efficiency, we present Batch Query DFS algorithm, which only needs only one DFS search. Our experiments on four real-life road networks demonstrate the performance of the proposed algorithms.},
  archive      = {J_NCA},
  author       = {Zhang, Zining and Yang, Shenghong and Qin, Yunchuan and Yang, Zhibang and Huang, Yang and Zhou, Xu},
  doi          = {10.1007/s00521-022-07485-x},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7473-7483},
  shortjournal = {Neural Comput. Appl.},
  title        = {Most relevant point query on road networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-instance discriminative contrastive learning for brain
image representation. <em>NCA</em>, <em>37</em>(11), 7459–7472. (<a
href="https://doi.org/10.1007/s00521-022-07524-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the problem of learning discriminative representation for brain images, which is a critical task toward understanding brain developments. Related studies usually extract manual and statistical features from the functional magnetic resonance images (MRIs) to differentiate brain patterns. However, these features fail to consider the implicit and high-order variances, and the existing representation methods often suffer from the weak manual features and the small-size sample. This paper introduces a weakly-supervised representation learning model, dubbed multi-instance discriminative contrastive learning (MIDCL), to identify the different MRI patterns. MIDCL yields two versions for each instance of a subject by introducing noise patterns and then achieves latent representations for them via training an encoder network and a projection network. Due to the multi-instance problem, MIDCL simultaneously minimizes an unsupervised contrastive loss (UCL) between the two representations at the level of instances and a supervised contrastive loss (SCL) between the two concatenated feature vectors at the level of subjects. We finally conducted experiments on two publicly available brain image datasets. The experiment results manifest that MIDCL could benefit from both UCL and SCL, thereby improving brain image classification performance in comparison with the state-of-the-art models.},
  archive      = {J_NCA},
  author       = {Zhang, Yupei and Liu, Shuhui and Qu, Xiran and Shang, Xuequn},
  doi          = {10.1007/s00521-022-07524-7},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7459-7472},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-instance discriminative contrastive learning for brain image representation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
