<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JTSA_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jtsa---9">JTSA - 9</h2>
<ul>
<li><details>
<summary>
(2025). Fractional stochastic volatility model. <em>JTSA</em>,
<em>46</em>(2), 378–397. (<a
href="https://doi.org/10.1111/jtsa.12749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a discrete-time fractional stochastic volatility model (FSV) based on fractional Gaussian noise. The new model includes the standard stochastic volatility model as a special case and has the same limit as the fractional integrated stochastic volatility (FISV) model, which is the continuous-time fractional Ornstein–Uhlenbeck process. A simulated maximum likelihood method, which maximizes the time-domain log-likelihood function calculated by the importance sampling technique, and a frequency-domain quasi maximum likelihood method (or quasi Whittle) are employed to estimate the model parameters. Simulation studies suggest that, while both estimation methods can accurately estimate the model, the simulated maximum likelihood method outperforms the quasi Whittle method. As an illustration, we fit the FSV and FISV models with the proposed estimation techniques to the S&amp;P 500 composite index over a sample period spanning 45 years.},
  archive      = {J_JTSA},
  author       = {Shuping Shi and Xiaobin Liu and Jun Yu},
  doi          = {10.1111/jtsa.12749},
  journal      = {Journal of Time Series Analysis},
  month        = {3},
  number       = {2},
  pages        = {378-397},
  shortjournal = {J. Time Series Anal.},
  title        = {Fractional stochastic volatility model},
  volume       = {46},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Risk parity portfolio optimization under heavy-tailed
returns and dynamic correlations. <em>JTSA</em>, <em>46</em>(2),
353–377. (<a href="https://doi.org/10.1111/jtsa.12792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Risk parity portfolio optimization, using expected shortfall as the risk measure, is investigated when asset returns are fat-tailed and heteroscedastic with regime switching dynamic correlations. The conditional return distribution is modeled by an elliptical multi-variate generalized hyperbolic distribution, allowing for fast parameter estimation via an expectation-maximization algorithm, and a semi-closed form of the risk contributions. A new method for efficient computation of non-Gaussian risk parity weights sidesteps the need for numerical simulations or Cornish–Fisher-type approximations. Accounting for fat-tailed returns, the risk parity allocation is less sensitive to volatility shocks, thereby generating lower portfolio turnover, in particular during market turmoils such as the global financial crisis or the COVID shock. While risk parity portfolios are rather robust to the misuse of the Gaussian distribution, a sophisticated time series model can improve risk-adjusted returns, strongly reduces drawdowns during periods of market stress and enables to use a holistic risk model for portfolio and risk management.},
  archive      = {J_JTSA},
  author       = {Marc S. Paolella and Paweł Polak and Patrick S. Walker},
  doi          = {10.1111/jtsa.12792},
  journal      = {Journal of Time Series Analysis},
  month        = {3},
  number       = {2},
  pages        = {353-377},
  shortjournal = {J. Time Series Anal.},
  title        = {Risk parity portfolio optimization under heavy-tailed returns and dynamic correlations},
  volume       = {46},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Non-causal and non-invertible ARMA models: Identification,
estimation and application in equity portfolios. <em>JTSA</em>,
<em>46</em>(2), 325–352. (<a
href="https://doi.org/10.1111/jtsa.12776">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mixed causal-non-causal invertible-non-invertible autoregressive moving-average (MARMA) models have the advantage of incorporating roots inside the unit circle, thus adjusting the dynamics of financial returns that depend on future expectations. This article introduces new techniques for estimating, identifying and simulating MARMA models. Although the estimation of the parameters is done using second-order moments, the identification relies on the existence of high-order dynamics, captured in the high-order spectral densities and the correlation of the squared residuals. A comprehensive Monte Carlo study demonstrated the robust performance of our estimation and identification methods. We propose an empirical application to 24 portfolios from emerging markets based on the factors: size, book-to-market, profitability, investment and momentum. All portfolios exhibited forward-looking behavior, showing significant non-causal and non-invertible dynamics. Moreover, we found the residuals to be uncorrelated and independent, with no trace of conditional volatility.},
  archive      = {J_JTSA},
  author       = {Alain Hecq and Daniel Velasquez-Gaviria},
  doi          = {10.1111/jtsa.12776},
  journal      = {Journal of Time Series Analysis},
  month        = {3},
  number       = {2},
  pages        = {325-352},
  shortjournal = {J. Time Series Anal.},
  title        = {Non-causal and non-invertible ARMA models: Identification, estimation and application in equity portfolios},
  volume       = {46},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized covariance-based inference for models
set-identified from independence restrictions. <em>JTSA</em>,
<em>46</em>(2), 300–324. (<a
href="https://doi.org/10.1111/jtsa.12779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article develops statistical inference methods for a class of set-identified models, where the errors are known functions of observations and the parameters satisfy either serial or/and cross-sectional independence conditions. This class of models includes the independent component analysis (ICA), Structural Vector Autoregressive (SVAR), and multi-variate mixed causal–non-causal models. We use the Generalized Covariance (GCov) estimator to compute the residual-based portmanteau statistic for testing the error independence hypothesis. Next, we build the confidence sets for the identified sets of parameters by inverting the test statistic. We also discuss the choice (design) of these statistics. The approach is illustrated by simulations examining the under-identification condition in an ICA model and an application to financial return series.},
  archive      = {J_JTSA},
  author       = {Christian Gourieroux and Joann Jasiak},
  doi          = {10.1111/jtsa.12779},
  journal      = {Journal of Time Series Analysis},
  month        = {3},
  number       = {2},
  pages        = {300-324},
  shortjournal = {J. Time Series Anal.},
  title        = {Generalized covariance-based inference for models set-identified from independence restrictions},
  volume       = {46},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The liquidity uncertainty premium puzzle. <em>JTSA</em>,
<em>46</em>(2), 286–299. (<a
href="https://doi.org/10.1111/jtsa.12802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The puzzling negative relation between liquidity uncertainty and asset returns, originally put forward by Chordia, Subrahmanyam, and Anshuman (2001) and confirmed by the subsequent empirical literature up to date, is neither robust to the aggregation period, nor to the observation frequency used to compute the volatility of trading volume. We demonstrate that their procedure involves an estimation bias due to the persistence and skewness of volumes. When using an alternative approach based on high-frequency data to measure liquidity uncertainty, the relationship turns out to be positive. However, portfolio strategies based on liquidity uncertainty do not appear to be profitable.},
  archive      = {J_JTSA},
  author       = {Maria Flora and Ilaria Gianstefani and Roberto Renò},
  doi          = {10.1111/jtsa.12802},
  journal      = {Journal of Time Series Analysis},
  month        = {3},
  number       = {2},
  pages        = {286-299},
  shortjournal = {J. Time Series Anal.},
  title        = {The liquidity uncertainty premium puzzle},
  volume       = {46},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting the yield curve: The role of additional and
time-varying decay parameters, conditional heteroscedasticity, and
macro-economic factors. <em>JTSA</em>, <em>46</em>(2), 258–285. (<a
href="https://doi.org/10.1111/jtsa.12769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we analyse the forecasting performance of several parametric extensions of the popular Dynamic Nelson–Siegel (DNS) model for the yield curve. Our focus is on the role of additional and time-varying decay parameters, conditional heteroscedasticity, and macroeconomic variables. We also consider the role of several popular restrictions on the dynamics of the factors. Using a novel dataset of end-of-month continuously compounded Treasury yields on US zero-coupon bonds and frequentist estimation based on the extended Kalman filter, we show that a second decay parameter does not contribute to better forecasts. In concordance with the preferred habitat theory, we also show that the best forecasting model depends on the maturity. For short maturities, the best performance is obtained in a heteroscedastic model with a time-varying decay parameter. However, for long maturities, neither the time-varying decay nor the heteroscedasticity plays any role, and the best forecasts are obtained in the basic DNS model with the shape of the yield curve depending on macroeconomic activity. Finally, we find that assuming non-stationary factors is helpful in forecasting at long horizons.},
  archive      = {J_JTSA},
  author       = {João F. Caldeira and Werley C. Cordeiro and Esther Ruiz and André A.P. Santos},
  doi          = {10.1111/jtsa.12769},
  journal      = {Journal of Time Series Analysis},
  month        = {3},
  number       = {2},
  pages        = {258-285},
  shortjournal = {J. Time Series Anal.},
  title        = {Forecasting the yield curve: The role of additional and time-varying decay parameters, conditional heteroscedasticity, and macro-economic factors},
  volume       = {46},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ridge regularized estimation of VAR models for inference.
<em>JTSA</em>, <em>46</em>(2), 235–257. (<a
href="https://doi.org/10.1111/jtsa.12737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ridge regression is a popular method for dense least squares regularization. In this article, ridge regression is studied in the context of VAR model estimation and inference. The implications of anisotropic penalization are discussed, and a comparison is made with Bayesian ridge-type estimators. The asymptotic distribution and the properties of cross-validation techniques are analyzed. Finally, the estimation of impulse response functions is evaluated with Monte Carlo simulations and ridge regression is compared with a number of similar and competing methods.},
  archive      = {J_JTSA},
  author       = {Giovanni Ballarin},
  doi          = {10.1111/jtsa.12737},
  journal      = {Journal of Time Series Analysis},
  month        = {3},
  number       = {2},
  pages        = {235-257},
  shortjournal = {J. Time Series Anal.},
  title        = {Ridge regularized estimation of VAR models for inference},
  volume       = {46},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-frequency instruments and identification-robust
inference for stochastic volatility models. <em>JTSA</em>,
<em>46</em>(2), 216–234. (<a
href="https://doi.org/10.1111/jtsa.12812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel class of stochastic volatility models, which can utilize and relate many high-frequency realized volatility (RV) measures to latent volatility. Instrumental variable methods provide a unified framework for estimation and testing. We study parameter inference problems in the proposed framework with nonstationary stochastic volatility and exogenous predictors in the latent volatility process. Identification-robust methods are developed for a joint hypothesis involving the volatility persistence parameter and the autocorrelation parameter of the composite error (or the noise ratio). For inference about the volatility persistence parameter, projection techniques are applied. The proposed tests include Anderson-Rubin-type tests and their point-optimal versions. For distributional theory, we provide finite-sample tests and confidence sets for Gaussian errors, establish exact Monte Carlo test procedures for non-Gaussian errors (possibly heavy-tailed), and show asymptotic validity under weaker assumptions. Simulation results show that the proposed tests outperform the asymptotic test regarding size and exhibit excellent power in empirically realistic settings. The proposed inference methods are applied to IBM&#39;s price and option data (2009–2013). We consider 175 different instruments (IVs) spanning 22 classes and analyze their ability to describe the low-frequency volatility. IVs are compared based on the average length of the proposed identification-robust confidence intervals. The superior instrument set mostly comprises 5-min HF realized measures, and these IVs produce confidence sets which show that the volatility process is nearly unit-root. In addition, we find RVs with higher frequency yield wider confidence intervals than RVs with slightly lower frequency, indicating that these confidence intervals adjust to absorb market microstructure noise. Furthermore, when we consider irrelevant or weak IVs (jumps and signed jumps), the proposed tests produce unbounded confidence intervals. We also find that both RV and BV measures produce almost identical confidence intervals across all 14 subclasses, confirming that our methodology is robust in the presence of jumps. Finally, although jumps contain little information regarding the low-frequency volatility, we find evidence that there may be a nonlinear relationship between jumps and low-frequency volatility.},
  archive      = {J_JTSA},
  author       = {Md. Nazmul Ahsan and Jean-Marie Dufour},
  doi          = {10.1111/jtsa.12812},
  journal      = {Journal of Time Series Analysis},
  month        = {3},
  number       = {2},
  pages        = {216-234},
  shortjournal = {J. Time Series Anal.},
  title        = {High-frequency instruments and identification-robust inference for stochastic volatility models},
  volume       = {46},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time series for QFFE: Special issue of the journal of time
series analysis. <em>JTSA</em>, <em>46</em>(2), 214–215. (<a
href="https://doi.org/10.1111/jtsa.12814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JTSA},
  author       = {Christian Francq and Christophe Hurlin and Sébastien Laurent and Jean-Michel Zakoian},
  doi          = {10.1111/jtsa.12814},
  journal      = {Journal of Time Series Analysis},
  month        = {3},
  number       = {2},
  pages        = {214-215},
  shortjournal = {J. Time Series Anal.},
  title        = {Time series for QFFE: Special issue of the journal of time series analysis},
  volume       = {46},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
