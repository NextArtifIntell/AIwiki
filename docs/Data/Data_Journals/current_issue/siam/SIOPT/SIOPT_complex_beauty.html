<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SIOPT_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="siopt---22">SIOPT - 22</h2>
<ul>
<li><details>
<summary>
(2025). On the complexity of matrix putinar’s positivstellensätz.
<em>SIOPT</em>, <em>35</em>(1), 567–591. (<a
href="https://doi.org/10.1137/24M1675461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper studies the complexity of matrix Putinar’s Positivstellensätz on the semialgebraic set that is given by the polynomial matrix inequality. When the quadratic module generated by the constrained polynomial matrix is Archimedean, we prove a polynomial bound on the degrees of terms appearing in the representation of matrix Putinar’s Positivstellensätz. Estimates on the exponent and constant are given. As a byproduct, a polynomial bound on the convergence rate of matrix sum-of-squares relaxations is obtained, which resolves an open question raised by Dinh and Pham [J. Complexity, 41 (2017), pp. 58–71]. When the constraining set is unbounded, we also prove a similar bound for the matrix version of Putinar–Vasilescu’s Positivstellensätz by exploiting homogenization techniques.},
  archive      = {J_SIOPT},
  author       = {Lei Huang},
  doi          = {10.1137/24M1675461},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {567-591},
  shortjournal = {SIAM J. Optim.},
  title        = {On the complexity of matrix putinar’s positivstellensätz},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the connections between optimization algorithms, lyapunov
functions, and differential equations: Theory and insights.
<em>SIOPT</em>, <em>35</em>(1), 537–566. (<a
href="https://doi.org/10.1137/23M1625287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We revisit the general framework introduced by Fazylab et al. [SIAM J. Optim., 28 (2018), pp. 2654–2689] to construct Lyapunov functions for optimization algorithms in discrete and continuous time. For smooth, strongly convex objective functions, we relax the requirements necessary for such a construction. As a result, we are able to prove for Polyak’s ordinary differential equations and for a two-parameter family of Nesterov algorithms rates of convergence that improve on those available in the literature. We analyze the interpretation of Nesterov algorithms as discretizations of the Polyak equation. We show that the algorithms are instances of additive Runge–Kutta integrators and discuss the reasons why most discretizations of the differential equation do not result in optimization algorithms with acceleration. We also introduce a modification of Polyak’s equation and study its convergence properties. Finally, we extend the general framework to the stochastic scenario and consider an application to random algorithms with acceleration for overparameterized models; again we are able to prove convergence rates that improve on those in the literature.},
  archive      = {J_SIOPT},
  author       = {Paul Dobson and Jesus M. Sanz-Serna and Konstantinos C. Zygalakis},
  doi          = {10.1137/23M1625287},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {537-566},
  shortjournal = {SIAM J. Optim.},
  title        = {On the connections between optimization algorithms, lyapunov functions, and differential equations: Theory and insights},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-stage distributionally robust conic linear programming
over 1-wasserstein balls. <em>SIOPT</em>, <em>35</em>(1), 506–536. (<a
href="https://doi.org/10.1137/23M1626839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper studies two-stage distributionally robust conic linear programming under constraint uncertainty over type-1 Wasserstein balls. We present optimality conditions for the dual of the worst-case expectation problem, which characterizes worst-case uncertain parameters for its inner maximization problem. This condition offers an alternative proof, a counterexample, and an extension to previous works. Additionally, the condition highlights the potential advantage of a specific distance metric for out-of-sample performance, as exemplified in a numerical study on a facility location problem with demand uncertainty. Furthermore, cutting-plane-based algorithms, equipped with a unified scenario generation framework, are proposed for addressing both unbounded support and second-stage dual feasible regions, with a finite convergence proof under less stringent assumptions.},
  archive      = {J_SIOPT},
  author       = {Geunyeong Byeon and Kaiwen Fang and Kibaek Kim},
  doi          = {10.1137/23M1626839},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {506-536},
  shortjournal = {SIAM J. Optim.},
  title        = {Two-stage distributionally robust conic linear programming over 1-wasserstein balls},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive partitioning for chance-constrained problems with
finite support. <em>SIOPT</em>, <em>35</em>(1), 476–505. (<a
href="https://doi.org/10.1137/24M1632772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper studies chance-constrained stochastic optimization problems with finite support. It presents an iterative method that solves reduced-size chance-constrained models obtained by partitioning the scenario set. Each reduced problem is constructed to yield a bound on the optimal value of the original problem. We show how to adapt the partitioning of the scenario set so that our adaptive method returns the optimal solution of the original chance-constrained problem in a finite number of iterations. At the heart of the method lie two fundamental operations: refinement and merging. A refinement operation divides a subset of the partition, whereas a merging operation combines a group of subsets into one. We describe how to use these operations to enhance the bound obtained in each step of the method while preserving the small size of the reduced model. Under mild conditions, we prove that, for specific refinement and merge operations, the bound obtained after solving each reduced model strictly improves throughout the iterative process. Our general method allows the seamless integration of various computational enhancements, significantly reducing the computational time required to solve the reduced chance-constrained problems. The method’s efficiency is assessed through numerical experiments on chance-constrained multidimensional knapsack problems. We study the impact of our method’s components and compare its performance against other methods from the recent literature.},
  archive      = {J_SIOPT},
  author       = {Marius Roland and Alexandre Forel and Thibaut Vidal},
  doi          = {10.1137/24M1632772},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {476-505},
  shortjournal = {SIAM J. Optim.},
  title        = {Adaptive partitioning for chance-constrained problems with finite support},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Addressing hierarchical jointly convex generalized nash
equilibrium problems with nonsmooth payoffs. <em>SIOPT</em>,
<em>35</em>(1), 445–475. (<a
href="https://doi.org/10.1137/23M1574026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a generalized Nash equilibrium problem whose joint feasible region is implicitly defined as the solution set of another Nash game. This structure arises, e.g., in multiportfolio selection contexts, whenever agents interact at different hierarchical levels. We consider nonsmooth terms in all players’ objectives, to promote, for example, sparsity in the solution. Under standard assumptions, we show that the equilibrium problems we deal with have a nonempty solution set and turn out to be jointly convex. To compute variational equilibria, we devise different first-order projection Tikhonov-like methods whose convergence properties are studied. We provide complexity bounds and equip our analysis with numerical tests using real-world financial datasets.},
  archive      = {J_SIOPT},
  author       = {Lorenzo Lampariello and Simone Sagratella and Valerio Giuseppe Sasso},
  doi          = {10.1137/23M1574026},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {445-475},
  shortjournal = {SIAM J. Optim.},
  title        = {Addressing hierarchical jointly convex generalized nash equilibrium problems with nonsmooth payoffs},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stability analysis of discrete-time linear complementarity
systems. <em>SIOPT</em>, <em>35</em>(1), 419–444. (<a
href="https://doi.org/10.1137/20M1387377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A Discrete-Time Linear Complementarity System (DLCS) is a dynamical system in discrete time whose state evolution is governed by linear dynamics in states and algebraic variables that solve a Linear Complementarity Problem (LCP). The DLCS is the hybrid dynamical system that is the discrete-time counterpart of the well-known Linear Complementarity System (LCS). We derive sufficient conditions for Lyapunov stability of a DLCS when using a quadratic Lyapunov function that depends only on the state variables and a quadratic Lyapunov function that depends both on the state and the algebraic variables. The sufficient conditions require checking the feasibility of a copositive program over nonconvex cones. Our results only assume that the LCP is solvable and do not require the solutions to be unique. We devise a novel, exact cutting plane algorithm for the verification of stability and the computation of the Lyapunov functions. To the best of our knowledge, our algorithm is the first exact approach for stability verification of DLCS. A number of numerical examples are presented to illustrate the approach. Though our main object of study in this paper is the DLCS, the proposed algorithm can be readily applied to the stability verification of LCS. In this context, we show the equivalence between the stability of a LCS and the DLCS, resulting from a time-stepping procedure applied to the LCS for all sufficiently small time steps.},
  archive      = {J_SIOPT},
  author       = {Arvind U. Raghunathan and Jeffrey T. Linderoth},
  doi          = {10.1137/20M1387377},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {419-444},
  shortjournal = {SIAM J. Optim.},
  title        = {Stability analysis of discrete-time linear complementarity systems},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Everything is possible: Constructing spectrahedra with
prescribed facial dimensions. <em>SIOPT</em>, <em>35</em>(1), 400–418.
(<a href="https://doi.org/10.1137/24M164344X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Given any finite set of nonnegative integers, there exists a closed convex set whose facial dimension signature coincides with this set of integers, that is, the dimensions of its nonempty faces comprise exactly this set of integers. In this work, we show that such sets can be realized as solution sets of systems of finitely many convex quadratic inequalities, and hence are representable via second-order cone programming problems, and are, in particular, spectrahedral. It also follows that these sets are facially exposed, in contrast to earlier constructions. We obtain a lower bound on the minimum number of convex quadratic inequalities needed to represent a closed convex set with prescribed facial dimension signature and show that our bound is tight for some special cases. Finally, we relate the question of finding efficient representations with indecomposability of integer sequences and other topics and discuss a substantial number of open questions.},
  archive      = {J_SIOPT},
  author       = {Vera Roshchina and Levent Tunçel},
  doi          = {10.1137/24M164344X},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {400-418},
  shortjournal = {SIAM J. Optim.},
  title        = {Everything is possible: Constructing spectrahedra with prescribed facial dimensions},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved guarantees for optimal nash equilibrium seeking and
bilevel variational inequalities. <em>SIOPT</em>, <em>35</em>(1),
369–399. (<a href="https://doi.org/10.1137/23M1589402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a class of hierarchical variational inequality (VI) problems that subsumes VI-constrained optimization and several other problem classes, including the optimal solution selection problem and the optimal Nash equilibrium (NE) seeking problem. Our main contribution is threefold. (i) We consider bilevel VIs with monotone and Lipschitz continuous mappings and devise a single-timescale iteratively regularized extragradient method, named IR-EG. We improve the existing iteration complexity results for addressing both bilevel VI and VI-constrained convex optimization problems. (ii) Under the strong monotonicity of the outer-level mapping, we develop a method named IR-EG and derive faster guarantees than those in (i). We also study the iteration complexity of this method under a constant regularization parameter. These results appear to be new for both bilevel VIs and VI-constrained optimization. (iii) To our knowledge, complexity guarantees for computing the optimal NE in nonconvex settings do not exist. Motivated by this lacuna, we consider VI-constrained nonconvex optimization problems and devise an inexactly projected gradient method, named IPR-EG, where the projection onto the unknown set of equilibria is performed using IR-EG with a prescribed termination criterion and an adaptive regularization parameter. We obtain new complexity guarantees in terms of a residual map and an infeasibility metric for computing a stationary point. We validate the theoretical findings using preliminary numerical experiments for computing the best and the worst NEs.},
  archive      = {J_SIOPT},
  author       = {Sepideh Samadi and Farzad Yousefian},
  doi          = {10.1137/23M1589402},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {369-399},
  shortjournal = {SIAM J. Optim.},
  title        = {Improved guarantees for optimal nash equilibrium seeking and bilevel variational inequalities},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Splitting the conditional gradient algorithm.
<em>SIOPT</em>, <em>35</em>(1), 347–368. (<a
href="https://doi.org/10.1137/24M1638008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a novel generalization of the conditional gradient (CG/Frank–Wolfe) algorithm for minimizing a smooth function under an intersection of compact convex sets, using a first-order oracle for and linear minimization oracles (LMOs) for the individual sets. Although this computational framework presents many advantages, there are only a small number of algorithms which require one LMO evaluation per set per iteration; furthermore, these algorithms require to be convex. Our algorithm appears to be the first in this class which is proven to also converge in the nonconvex setting. Our approach combines a penalty method and a product-space relaxation. We show that one CG step is a sufficient subroutine for our penalty method to converge, and we provide several analytical results on the product-space relaxation’s properties and connections to other problems in optimization. We prove that our average Frank–Wolfe gap converges at a rate of —only a log factor worse than the vanilla CG algorithm with one set.},
  archive      = {J_SIOPT},
  author       = {Zev Woodstock and Sebastian Pokutta},
  doi          = {10.1137/24M1638008},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {347-368},
  shortjournal = {SIAM J. Optim.},
  title        = {Splitting the conditional gradient algorithm},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A solution method for arbitrary polyhedral convex set
optimization problems. <em>SIOPT</em>, <em>35</em>(1), 330–346. (<a
href="https://doi.org/10.1137/23M1608227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We provide a solution method for the polyhedral convex set optimization problem, that is, the problem to minimize a set-valued mapping with polyhedral convex graph with respect to a set ordering relation which is generated by a polyhedral convex cone . The method is proven to be correct and finite without any further assumption to the problem.},
  archive      = {J_SIOPT},
  author       = {Andreas Löhne},
  doi          = {10.1137/23M1608227},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {330-346},
  shortjournal = {SIAM J. Optim.},
  title        = {A solution method for arbitrary polyhedral convex set optimization problems},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tight error bounds for the sign-constrained stiefel
manifold. <em>SIOPT</em>, <em>35</em>(1), 302–329. (<a
href="https://doi.org/10.1137/24M1659030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The sign-constrained Stiefel manifold in is a segment of the Stiefel manifold with fixed signs (nonnegative or nonpositive) for some entries of the matrices. It includes the nonnegative Stiefel manifold as a special case. We present global and local error bounds that provide an inequality with easily computable residual functions and explicit coefficients to bound the distance from matrices in to the sign-constrained Stiefel manifold. Moreover, we show that the error bounds cannot be improved except for the multiplicative constants under some mild conditions, which explains why two square-root terms are necessary in the bounds when and why the -norm can be used in the bounds when or for the sign constraints and orthogonality, respectively. The error bounds are applied to derive exact penalty methods for minimizing a Lipschitz continuous function with orthogonality and sign constraints.},
  archive      = {J_SIOPT},
  author       = {Xiaojun Chen and Yifan He and Zaikun Zhang},
  doi          = {10.1137/24M1659030},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {302-329},
  shortjournal = {SIAM J. Optim.},
  title        = {Tight error bounds for the sign-constrained stiefel manifold},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence analyses of davis–yin splitting via scaled
relative graphs. <em>SIOPT</em>, <em>35</em>(1), 270–301. (<a
href="https://doi.org/10.1137/23M1621320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Davis–Yin splitting (DYS) has found a wide range of applications in optimization, but its linear rates of convergence have not been studied extensively. The scaled relative graph (SRG) simplifies the convergence analysis of operator splitting methods by mapping the action of the operator to the complex plane, but the prior SRG theory did not fully apply to the DYS operator. In this work, we formalize an SRG theory for the DYS operator and use it to obtain tighter contraction factors.},
  archive      = {J_SIOPT},
  author       = {Jongmin Lee and Soheun Yi and Ernest K. Ryu},
  doi          = {10.1137/23M1621320},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {270-301},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergence analyses of Davis–Yin splitting via scaled relative graphs},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A sequential quadratic programming method with
high-probability complexity bounds for nonlinear equality-constrained
stochastic optimization. <em>SIOPT</em>, <em>35</em>(1), 240–269. (<a
href="https://doi.org/10.1137/23M1549006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A step-search sequential quadratic programming method is proposed for solving nonlinear equality-constrained stochastic optimization problems. It is assumed that constraint function values and derivatives are available, but only stochastic approximations of the objective function and its associated derivatives can be computed via inexact probabilistic zeroth- and first-order oracles. Under reasonable assumptions, a high probability bound on the number of iterations that the algorithm requires to reach a first-order -stationary iterate is derived, where is lower bounded by a positive quantity dictated by the noise level of the inexact probabilistic zeroth- and first-order oracles. Numerical results on standard nonlinear optimization test problems illustrate the advantages and limitations of our proposed method.},
  archive      = {J_SIOPT},
  author       = {Albert S. Berahas and Miaolan Xie and Baoyu Zhou},
  doi          = {10.1137/23M1549006},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {240-269},
  shortjournal = {SIAM J. Optim.},
  title        = {A sequential quadratic programming method with high-probability complexity bounds for nonlinear equality-constrained stochastic optimization},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the geometric convergence of byzantine-resilient
distributed optimization algorithms. <em>SIOPT</em>, <em>35</em>(1),
210–239. (<a href="https://doi.org/10.1137/23M1573410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The problem of designing distributed optimization algorithms that are resilient to Byzantine adversaries has received significant attention. For the Byzantine-resilient distributed optimization problem, the goal is to (approximately) minimize the average of the local cost functions held by the regular (nonadversarial) agents in the network. In this paper, we provide a general algorithmic framework for Byzantine-resilient distributed optimization which includes some state-of-the-art algorithms as special cases. We analyze the convergence of algorithms within the framework, and derive a geometric rate of convergence of all regular agents to a ball around the optimal solution (whose size we characterize). Furthermore, we show that approximate consensus can be achieved geometrically fast under some minimal conditions. Our analysis provides insights into the relationship among the convergence region, distance between regular agents’ values, step size, and properties of the agents’ functions for Byzantine-resilient distributed optimization.},
  archive      = {J_SIOPT},
  author       = {Kananart Kuwaranancharoen and Shreyas Sundaram},
  doi          = {10.1137/23M1573410},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {210-239},
  shortjournal = {SIAM J. Optim.},
  title        = {On the geometric convergence of byzantine-resilient distributed optimization algorithms},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerated minimax algorithms flock together.
<em>SIOPT</em>, <em>35</em>(1), 180–209. (<a
href="https://doi.org/10.1137/22M1504597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Several new accelerated methods in minimax optimization and fixed-point iterations have recently been discovered, and, interestingly, they rely on a mechanism distinct from Nesterov’s momentum-based acceleration. In this work, we show that these accelerated algorithms exhibit what we call the merging path (MP) property; the trajectories of these algorithms merge quickly. Using this novel MP property, we establish point convergence of existing accelerated minimax algorithms and derive new state-of-the-art algorithms for the strongly-convex-strongly-concave setup and for the prox-grad setup.},
  archive      = {J_SIOPT},
  author       = {TaeHo Yoon and Ernest K. Ryu},
  doi          = {10.1137/22M1504597},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {180-209},
  shortjournal = {SIAM J. Optim.},
  title        = {Accelerated minimax algorithms flock together},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic optimization over proximally smooth sets.
<em>SIOPT</em>, <em>35</em>(1), 157–179. (<a
href="https://doi.org/10.1137/20M1320225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We introduce a class of stochastic algorithms for minimizing weakly convex functions over proximally smooth sets. As their main building blocks, the algorithms use simplified models of the objective function and the constraint set, along with a retraction operation to restore feasibility. All the proposed methods come equipped with a finite time efficiency guarantee in terms of a natural stationarity measure. We discuss consequences for nonsmooth optimization over smooth manifolds and over sets cut out by weakly convex inequalities.},
  archive      = {J_SIOPT},
  author       = {Damek Davis and Dmitriy Drusvyatskiy and Zhan Shi},
  doi          = {10.1137/20M1320225},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {157-179},
  shortjournal = {SIAM J. Optim.},
  title        = {Stochastic optimization over proximally smooth sets},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Policy mirror descent inherently explores action space.
<em>SIOPT</em>, <em>35</em>(1), 116–156. (<a
href="https://doi.org/10.1137/23M1560215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Explicit exploration in the action space was assumed to be indispensable for online policy gradient methods to avoid a drastic degradation in sample complexity, for solving general reinforcement learning problems over finite state and action spaces. In this paper, we establish for the first time an sample complexity for online policy gradient methods without incorporating any exploration strategies. The essential development consists of two new on-policy evaluation operators and a novel analysis of the stochastic policy mirror descent method (SPMD) [G. Lan, Math. Program., 198 (2022), pp. 1059–1106]. SPMD with the first evaluation operator, called value-based estimation, tailors to the Kullback–Leibler divergence. Provided the Markov chains on the state space of generated policies are uniformly mixing with a nondiminishing minimal visitation measure, an sample complexity is obtained with a linear dependence on the size of the action space. SPMD with the second evaluation operator, namely truncated on-policy Monte Carlo (TOMC), attains an sample complexity, where mildly depends on the effective horizon and the size of the action space with properly chosen Bregman divergence (e.g., Tsallis divergence). SPMD with TOMC also exhibits stronger convergence properties in that it controls the optimality gap with high probability rather than in expectation. In contrast to explicit exploration, these new policy gradient methods can prevent repeatedly committing to potentially high-risk actions when searching for optimal policies.},
  archive      = {J_SIOPT},
  author       = {Yan Li and Guanghui Lan},
  doi          = {10.1137/23M1560215},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {116-156},
  shortjournal = {SIAM J. Optim.},
  title        = {Policy mirror descent inherently explores action space},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stability properties for parametric linear programs under
data ambiguities. <em>SIOPT</em>, <em>35</em>(1), 92–115. (<a
href="https://doi.org/10.1137/23M1618156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we study a new parametric robust linear problem (PRLP) whose data are allowed to be perturbed not only on the objective and constraint functions but also on the size of the uncertainty sets. Using a dual approach, we examine the stability and sensitivity properties of PRLP by looking at how the behaviors of its optimal value function and solution map change according to the change of the parameters. More precisely, we examine the closedness and lower and upper semicontinuity of the solution map and the lower and upper semicontinuity as well as Lipschitz property of the optimal value function of PRLP varying around a reference parameter. In this way, we obtain the nonemptiness and boundedness of the solution sets and a characterization for the Lipschitz continuity of the optimal value function for semi-infinite linear programs when fixing the corresponding index sets.},
  archive      = {J_SIOPT},
  author       = {Thai Doan Chuong and Cao Thanh Tinh},
  doi          = {10.1137/23M1618156},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {92-115},
  shortjournal = {SIAM J. Optim.},
  title        = {Stability properties for parametric linear programs under data ambiguities},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Kurdyka–łojasiewicz exponent via hadamard parametrization.
<em>SIOPT</em>, <em>35</em>(1), 62–91. (<a
href="https://doi.org/10.1137/24M1636186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a class of -regularized optimization problems and the associated smooth “overparameterized” optimization problems built upon the Hadamard parametrization, or equivalently, the Hadamard difference parametrization (HDP). We characterize the set of second-order stationary points of the HDP-based model and show that they correspond to some stationary points of the corresponding -regularized model. More importantly, we show that the Kurdyka–Łojasiewicz (KL) exponent of the HDP-based model at a second-order stationary point can be inferred from that of the corresponding -regularized model under suitable assumptions. Our assumptions are general enough to cover a wide variety of loss functions commonly used in -regularized models, such as the least squares loss function and the logistic loss function. Since the KL exponents of many -regularized models are explicitly known in the literature, our results allow us to leverage these known exponents to deduce the KL exponents at second-order stationary points of the corresponding HDP-based models, which were previously unknown. Finally, we demonstrate how these explicit KL exponents at second-order stationary points can be applied to deducing the explicit local convergence rate of a standard gradient descent method for minimizing the HDP-based model.},
  archive      = {J_SIOPT},
  author       = {Wenqing Ouyang and Yuncheng Liu and Ting Kei Pong and Hao Wang},
  doi          = {10.1137/24M1636186},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {62-91},
  shortjournal = {SIAM J. Optim.},
  title        = {Kurdyka–Łojasiewicz exponent via hadamard parametrization},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consistency of sample-based stationary points for
infinite-dimensional stochastic optimization. <em>SIOPT</em>,
<em>35</em>(1), 42–61. (<a
href="https://doi.org/10.1137/23M1600608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider stochastic optimization problems with possibly nonsmooth integrands posed in infinite-dimensional decision spaces and approximate these stochastic programs via a sample-based approaches. We establish the asymptotic consistency of approximate Clarke stationary points of the sample-based approximations. Our framework is applied to risk-averse semilinear PDE-constrained optimization using the average value-at-risk and risk-neutral bilinear PDE-constrained optimization.},
  archive      = {J_SIOPT},
  author       = {Johannes Milz},
  doi          = {10.1137/23M1600608},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {42-61},
  shortjournal = {SIAM J. Optim.},
  title        = {Consistency of sample-based stationary points for infinite-dimensional stochastic optimization},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence properties of proximal (sub)gradient methods
without convexity or smoothness of any of the functions. <em>SIOPT</em>,
<em>35</em>(1), 28–41. (<a
href="https://doi.org/10.1137/23M1592158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We establish convergence properties for a framework that includes a variety of proximal subgradient methods, where none of the involved functions needs to be convex or differentiable. The functions are assumed to be Clarke-regular. Our results cover the projected and conditional variants for the constrained case, the use of the inertial/momentum terms, and incremental methods when each of the functions is itself a sum, and the methods process the components in this sum separately.},
  archive      = {J_SIOPT},
  author       = {Mikhail V. Solodov},
  doi          = {10.1137/23M1592158},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {28-41},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergence properties of proximal (Sub)gradient methods without convexity or smoothness of any of the functions},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Derivative-free approaches for chance-constrained problems
with right-hand side uncertainty. <em>SIOPT</em>, <em>35</em>(1), 1–27.
(<a href="https://doi.org/10.1137/23M1622635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This work addresses (mixed-integer) joint chance-constrained optimization problems in which the only uncertain parameter corresponds to the right-hand side coefficients in an inequality system. It exploits one-dimensional marginals to construct upper and lower models for the underlying joint probability function, which need not be differentiable or satisfy generalized concavity properties. Based on these models, two optimization methods are proposed. Neither of them requires the probability function’s (sub)gradients and can thus be considered derivative-free methods. The first approach iteratively enriches an upper model for the probability function within an outer approximation algorithm that is shown to compute, under mild assumptions, an approximate global solution to the nonconvex chance-constrained problem. When the problem’s data is linear, the outer approximation algorithm requires solving (approximately) a mixed-integer linear programming problem per iteration. The second method works with a lower model and penalization techniques to efficiently compute points satisfying a new criticality condition. The approach, which handles only continuous variables, defines iterates as critical points of a nonlinear master program that can be handled with off-the-shelf nonlinear programming solvers. Numerical experiments on academic chance-constrained problems highlight the approach’s potential and limitations.},
  archive      = {J_SIOPT},
  author       = {W. de Oliveira},
  doi          = {10.1137/23M1622635},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {1-27},
  shortjournal = {SIAM J. Optim.},
  title        = {Derivative-free approaches for chance-constrained problems with right-hand side uncertainty},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
