<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>OR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="or---33">OR - 33</h2>
<ul>
<li><details>
<summary>
(2025). Technical note—on the convergence rate of stochastic
approximation for gradient-based stochastic optimization. <em>OR</em>,
<em>73</em>(2), 1143–1150. (<a
href="https://doi.org/10.1287/opre.2023.0055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider stochastic optimization via gradient-based search. Under a stochastic approximation framework, we apply a recently developed convergence rate analysis to provide a new finite-time error bound for a class of problems with convex differentiable structures. For noisy black-box functions, our main result allows us to derive finite-time bounds in the setting where the gradients are estimated via finite-difference estimators, including those based on randomized directions such as the simultaneous perturbation stochastic approximation algorithm. In particular, the convergence rate analysis sheds light on when it may be advantageous to use such randomized gradient estimates in terms of problem dimension and noise levels. Funding: This work was supported by the Air Force Office of Scientific Research [Grant FA95502010211] and the National Science Foundation [Grants IIS-2123684 and CMMI-2027527].},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0055},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {1143-1150},
  shortjournal = {Oper. Res.},
  title        = {Technical Note—On the convergence rate of stochastic approximation for gradient-based stochastic optimization},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recovering dantzig–wolfe bounds by cutting planes.
<em>OR</em>, <em>73</em>(2), 1128–1142. (<a
href="https://doi.org/10.1287/opre.2023.0048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dantzig–Wolfe (DW) decomposition is a well-known technique in mixed-integer programming (MIP) for decomposing and convexifying constraints to obtain potentially strong dual bounds. We investigate cutting planes that can be derived using the DW decomposition algorithm and show that these cuts can provide the same dual bounds as DW decomposition. More precisely, we generate one cut for each DW block, and when combined with the constraints in the original formulation, these cuts imply the objective function cut one can simply write using the DW bound. This approach typically leads to a formulation with lower dual degeneracy that consequently has a better computational performance when solved by standard MIP solvers in the original space. We also discuss how to strengthen these cuts to improve the computational performance further. We test our approach on the multiple knapsack assignment problem and the temporal knapsack problem, and we show that the proposed cuts are helpful in accelerating the solution time without the need to implement branch and price. Funding: This work was supported by the Office of Naval Research [Grant N00014-21-1-2575]. Supplemental Material: The e-companion is available at https://doi.org/10.1287/opre.2023.0048 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0048},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {1128-1142},
  shortjournal = {Oper. Res.},
  title        = {Recovering Dantzig–Wolfe bounds by cutting planes},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Computing bayes–nash equilibrium strategies in auction games
via simultaneous online dual averaging. <em>OR</em>, <em>73</em>(2),
1102–1127. (<a href="https://doi.org/10.1287/opre.2022.0287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Auctions are modeled as Bayesian games with continuous type and action spaces. Determining equilibria in auction games is computationally hard in general, and no exact solution theory is known. We introduce an algorithmic framework in which we discretize type and action space and then learn distributional strategies via online optimization algorithms. One advantage of distributional strategies is that we do not have to make any assumptions on the shape of the bid function. Besides, the expected utility of agents is linear in the strategies. It follows that, if our optimization algorithms converge to a pure strategy, then they converge to an approximate equilibrium of the discretized game with high precision. Importantly, we show that the equilibrium of the discretized game approximates an equilibrium in the continuous game. In a wide variety of auction games, we provide empirical evidence that the approach approximates the analytical (pure) Bayes–Nash equilibrium closely. This speed and precision are remarkable because, in many finite games, learning dynamics do not converge or are even chaotic. In standard models in which agents are symmetric, we find equilibrium in seconds. Whereas we focus on dual averaging, we show that the overall approach converges independent of the regularizer, and alternative online convex optimization methods achieve similar results even though the discretized game satisfies neither monotonicity nor variational stability globally. The method allows for interdependent valuations and different types of utility functions, and it can be used to find equilibrium in auction markets and beyond. Funding: M. Bichler was supported by the Deutsche Forschungsgemeinschaft (DFG) (German Research Foundation) [Grant BI 1057/9]. M. Fichtl and M. Oberlechner were funded by the DFG [Grant GRK 2201/2 - Projektnummer 277991500].},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0287},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {1102-1127},
  shortjournal = {Oper. Res.},
  title        = {Computing Bayes–Nash equilibrium strategies in auction games via simultaneous online dual averaging},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Linear classifiers under infinite imbalance. <em>OR</em>,
<em>73</em>(2), 1075–1101. (<a
href="https://doi.org/10.1287/opre.2021.0376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the behavior of linear discriminant functions for binary classification in the infinite-imbalance limit, where the sample size of one class grows without bound while the sample size of the other remains fixed. The coefficients of the classifier minimize an empirical loss specified through a weight function. We show that for a broad class of weight functions, the intercept diverges but the rest of the coefficient vector has a finite almost sure limit under infinite imbalance, extending prior work on logistic regression. The limit depends on the left-tail growth rate of the weight function, for which we distinguish two cases: subexponential and exponential. The limiting coefficient vectors reflect robustness or conservatism properties in the sense that they optimize against certain worst-case alternatives. In the subexponential case, the limit is equivalent to an implicit choice of upsampling distribution for the minority class. We apply these ideas in a credit risk setting, with particular emphasis on performance in the high-sensitivity and high-specificity regions. Supplemental Material: The computer code and data that support the findings of this study are available within this article’s supplemental material at https://pubsonline.informs.org/doi/suppl/10.1287/opre.2021.0376 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0376},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {1075-1101},
  shortjournal = {Oper. Res.},
  title        = {Linear classifiers under infinite imbalance},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inverse optimization: Theory and applications. <em>OR</em>,
<em>73</em>(2), 1046–1074. (<a
href="https://doi.org/10.1287/opre.2022.0382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverse optimization describes a process that is the “reverse” of traditional mathematical optimization. Unlike traditional optimization, which seeks to compute optimal decisions given an objective and constraints, inverse optimization takes decisions as input and determines objective and/or constraint parameters that render these decisions approximately or exactly optimal. In recent years, there has been an explosion of interest in the mathematics and applications of inverse optimization. This paper provides a comprehensive review of both the methodological and application-oriented literature in this field. Funding: T. C. Y. Chan received funding support from the Natural Science and Engineering Research Council of Canada. Supplemental Material: The e-companion is available at https://doi.org/10.1287/opre.2022.0382 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0382},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {1046-1074},
  shortjournal = {Oper. Res.},
  title        = {Inverse optimization: Theory and applications},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fluid policies, reoptimization, and performance guarantees
in dynamic resource allocation. <em>OR</em>, <em>73</em>(2), 1029–1045.
(<a href="https://doi.org/10.1287/opre.2022.0601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many sequential decision problems involve deciding how to allocate shared resources across a set of independent systems at each point in time. A classic example is the restless bandit problem, in which a budget constraint limits the selection of arms. Fluid relaxations provide a natural approximation technique for this broad class of problems. A recent stream of research has established strong performance guarantees for feasible policies based on fluid relaxations. In this paper, we generalize and improve these recent performance results. First, we provide easy-to-implement feasible fluid policies that achieve performance within O ( N ) of optimal, where N is the number of subproblems. This result holds for a general class of dynamic resource allocation problems with heterogeneous subproblems and multiple shared resource constraints. Second, we show using a novel proof technique that a feasible fluid policy that chooses actions using a reoptimized fluid value function achieves performance within O ( N ) of optimal as well. To the best of our knowledge, this performance guarantee is the first one for reoptimization for the general dynamic resource allocation problems that we consider. The scaling of the constants with respect to time in these results implies similar results in the infinite horizon setting. Finally, we develop and analyze a class of feasible fluid-budget balancing policies that stay “close” to actions selected by an optimal fluid policy while simultaneously using as much of the shared resources as possible. We show that this policy achieves performance within O (1) of optimal under particular nondegeneracy assumptions. This result generalizes recent advances for restless bandit problems by considering (a) any finite number of actions for each subproblem and (b) heterogeneous subproblems with a fixed number of types. We demonstrate the use of these techniques on dynamic multiwarehouse inventory problems and find empirically that these fluid-based policies achieve excellent performance, as our theory suggests. Supplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2022.0601 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0601},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {1029-1045},
  shortjournal = {Oper. Res.},
  title        = {Fluid policies, reoptimization, and performance guarantees in dynamic resource allocation},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixed-integer optimization with constraint learning.
<em>OR</em>, <em>73</em>(2), 1011–1028. (<a
href="https://doi.org/10.1287/opre.2021.0707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish a broad methodological foundation for mixed-integer optimization with learned constraints. We propose an end-to-end pipeline for data-driven decision making in which constraints and objectives are directly learned from data using machine learning, and the trained models are embedded in an optimization formulation. We exploit the mixed-integer optimization representability of many machine learning methods, including linear models, decision trees, ensembles, and multilayer perceptrons, which allows us to capture various underlying relationships between decisions, contextual variables, and outcomes. We also introduce two approaches for handling the inherent uncertainty of learning from data. First, we characterize a decision trust region using the convex hull of the observations to ensure credible recommendations and avoid extrapolation. We efficiently incorporate this representation using column generation and propose a more flexible formulation to deal with low-density regions and high-dimensional data sets. Then, we propose an ensemble learning approach that enforces constraint satisfaction over multiple bootstrapped estimators or multiple algorithms. In combination with domain-driven components, the embedded models and trust region define a mixed-integer optimization problem for prescription generation. We implement this framework as a Python package ( OptiCL ) for practitioners. We demonstrate the method in both World Food Programme planning and chemotherapy optimization. The case studies illustrate the framework’s ability to generate high-quality prescriptions and the value added by the trust region, the use of ensembles to control model robustness, the consideration of multiple machine learning methods, and the inclusion of multiple learned constraints. Funding: This work was supported by the Dutch Scientific Council [Grant OCENW.GROOT.2019.015] and the National Science Foundation [Grant 174530]. Additionally, H. Wiberg was supported by the National Science Foundation Graduate Research Fellowship [Grant 174530]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2021.0707 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0707},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {1011-1028},
  shortjournal = {Oper. Res.},
  title        = {Mixed-integer optimization with constraint learning},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online matching frameworks under stochastic rewards, product
ranking, and unknown patience. <em>OR</em>, <em>73</em>(2), 995–1010.
(<a href="https://doi.org/10.1287/opre.2021.0371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study generalizations of online bipartite matching in which each arriving vertex (customer) views a ranked list of offline vertices (products) and matches to (purchases) the first one they deem acceptable. The number of products that the customer has patience to view can be stochastic and dependent on the products seen. We develop a framework that views the interaction with each customer as an abstract resource consumption process and derive new results for these online matching problems under the adversarial, nonstationary, and independent and identically-distributed arrival models, assuming we can (approximately) solve the product ranking problem for each single customer. To that end, we show new results for product ranking under two cascade-click models: an optimal algorithm when each item has its own hazard rate for making the customer depart and a 1/2-approximate algorithm when the customer has a general item-independent patience distribution. We also present a constant-factor 0.027-approximate algorithm in a new model where items are not initially available and arrive over time. We complement these positive results by presenting three additional negative results relating to these problems. Funding: N. Grammel was supported in part by NSF award [CCF-1918749] and by research awards from Amazon and Google. A. Srinivasan was supported in part by NSF awards [CCF-1422569, CCF-1749864, and CCF-1918749], as well as research awards from Adobe, Amazon, and Google. W. Ma was supported in part by a research award from Amazon. Supplemental Material: The e-companion is available at https://doi.org/10.1287/opre.2021.0371 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0371},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {995-1010},
  shortjournal = {Oper. Res.},
  title        = {Online matching frameworks under stochastic rewards, product ranking, and unknown patience},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Technical note—improved sample-complexity bounds in
stochastic optimization. <em>OR</em>, <em>73</em>(2), 986–994. (<a
href="https://doi.org/10.1287/opre.2018.0340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world network-optimization problems often involve uncertain parameters during the optimization phase. Stochastic optimization is a key approach introduced in the 1950s to address such uncertainty. This paper presents improved upper bounds on the number of samples required for the sample-average approximation method in stochastic optimization. It enhances the sample complexity of existing approaches in this setting, providing faster approximation algorithms for any method that employs this framework. This work is particularly relevant for solving problems like the stochastic Steiner tree problem. Funding: The research of A. Baveja is partially supported by the United States Department of Transportation (via the University Transportation Research Center Program) [Grant 49198-25-26] and the British Council [the UKIERI Research Program]. The work of A. Chavan was done while he was a graduate student at the University of Maryland. The research of A. Srinivasan is partially supported by the National Science Foundation [Awards CNS 1010789, CCF-1422569, CCF-1749864, and CCF-1918749]; Adobe, Inc. [research awards]; Amazon, Inc.; and Google, Inc. The research of P. Xu was supported in part by the National Science Foundation [Awards CNS 1010789 and CCF-1422569 (when he was a graduate student)] and is partially funded by the National Science Foundation [CRII Award IIS-1948157]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2018.0340 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2018.0340},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {986-994},
  shortjournal = {Oper. Res.},
  title        = {Technical Note—Improved sample-complexity bounds in stochastic optimization},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributionally robust optimization under distorted
expectations. <em>OR</em>, <em>73</em>(2), 969–985. (<a
href="https://doi.org/10.1287/opre.2020.0685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributionally robust optimization (DRO) has arisen as an important paradigm for addressing the issue of distributional ambiguity in decision optimization. In the case in which a decision maker is not risk neutral, the most common scheme applied in DRO for capturing the risk attitude is to employ an expected utility functional. In this paper, we propose to address a decision maker’s risk attitude in DRO by following an alternative scheme known as dual expected utility. In this scheme, a distortion function is applied to convert physical probabilities into subjective probabilities so that the resulting expectation, called a distorted expectation, captures the decision maker’s risk attitude. Unlike an expected utility functional, which is linear in probability, in the dual scheme, the distorted expectation is generally nonlinear in probability. We distinguish DRO based on distorted expectations by coining the term “distributionally robust distortion risk optimization” (DRDRO) and show that DRDRO problems can be equally, if not more, tractable to solve as DRO problems based on utility functionals. Our tractability results hold for any distortion function, and hence, our scheme provides more flexibility in capturing more realistic forms of risk attitudes. These include, as an important example, the inverse S-shaped distortion functionals in cumulative prospect theory. We demonstrate through a numerical example that a production manager who overly weights “very good” and “very bad” outcomes may act as if the manager is risk averse when distributional ambiguity is considered. Funding: J. Cai gratefully acknowledges financial support from the Natural Sciences and Engineering Research Council of Canada [Grant RGPIN-2022-03354]. J. Y.-M. Li gratefully acknowledges financial support from the Natural Sciences and Engineering Research Council of Canada [Grant RGPIN-2014-05602]. T. Mao gratefully acknowledges financial support from the National Natural Science Foundation of China [Grants 12371476, 71671176, and 71921001]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2020.0685 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2020.0685},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {969-985},
  shortjournal = {Oper. Res.},
  title        = {Distributionally robust optimization under distorted expectations},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Customer scheduling in large service systems under model
uncertainty. <em>OR</em>, <em>73</em>(2), 949–968. (<a
href="https://doi.org/10.1287/opre.2022.0144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scheduling in the context of many-server queues has received considerable attention. When there are multiple customer classes and many servers, it is common to make simplifying assumptions that result in a “low-fidelity” model, potentially leading to model misspecification. However, empirical evidence suggests that these assumptions may not accurately reflect real-world scenarios. Although relaxing these assumptions can yield a more accurate “high-fidelity” model, it often becomes complex and challenging, if not impossible, to solve. In this paper, we introduce a novel approach for decision makers to generate high-quality scheduling policies for large service systems based on a simple and tractable low-fidelity model instead of its complex and intractable high-fidelity counterpart. At the core of our approach is a robust control formulation, wherein optimization is conducted against an imaginary adversary. This adversary optimally exploits the potential weaknesses of a scheduling rule within prescribed limits defined by an uncertainty set by dynamically perturbing the low-fidelity model. This process assists decision-makers in assessing the vulnerability of a given scheduling policy to model errors stemming from the low-fidelity model. Moreover, our proposed robust control framework is complemented by practical data-driven schemes for uncertainty set selection. Extensive numerical experiments, including a case study based on a U.S. call center data set, substantiate the effectiveness of our framework by revealing scheduling policies that can significantly reduce the system’s costs in comparison with established benchmarks in the literature. Supplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2022.0144 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0144},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {949-968},
  shortjournal = {Oper. Res.},
  title        = {Customer scheduling in large service systems under model uncertainty},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic localization methods for convex discrete
optimization via simulation. <em>OR</em>, <em>73</em>(2), 927–948. (<a
href="https://doi.org/10.1287/opre.2022.0030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop and analyze a set of new sequential simulation-optimization algorithms for large-scale multidimensional discrete optimization via simulation problems with a convexity structure. The “large-scale” notion refers to that the discrete decision variable has a large number of values from which to choose on each dimension of the decision variable. The proposed algorithms are targeted to identify a solution that is close to the optimal solution given any precision level with any given probability. To achieve this target, utilizing the convexity structure, our algorithm design does not need to scan all the choices of the decision variable, but instead sequentially draws a subset of choices of the decision variable and uses them to “localize” potentially near-optimal solutions to an adaptively shrinking region. To show the power of the proposed methods based on the localization idea, we first consider one-dimensional large-scale problems. We develop the shrinking uniform sampling algorithm, which is proved to achieve the target with an optimal expected simulation cost under an asymptotic criterion. For multidimensional problems, we combine the idea of localization with subgradient information and propose a framework to design stochastic cutting-plane methods, whose expected simulation costs have a low dependence on the scale and the dimension of the problems. In addition, utilizing the discrete nature of the problems, we propose a stochastic dimension-reduction algorithm, which does not require prior information about the Lipschitz constant of the objective function, and its simulation costs are upper bounded by a value that is independent of the Lipschitz constant. We implement the proposed algorithms on synthetic problems and queueing simulation-optimization problems and demonstrate better performances compared with benchmark methods especially for large-scale examples. Funding: H. Zhang and J. Lavaei were funded by grants from Army Research Office (ARO), Office of Naval Research (ONR), Air Force Office of Scientific Research(AFOSR), and National Science Foundation (NSF). H. Zhang was partially supported by the Two Sigma PhD Fellowship. Z. Zheng was partially supported by the Hellman Fellows Fund and NSF. Supplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2022.0030 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0030},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {927-948},
  shortjournal = {Oper. Res.},
  title        = {Stochastic localization methods for convex discrete optimization via simulation},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A doubly stochastic simulator with applications in arrivals
modeling and simulation. <em>OR</em>, <em>73</em>(2), 910–926. (<a
href="https://doi.org/10.1287/opre.2021.0597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a framework that integrates classic Monte Carlo simulators and Wasserstein generative adversarial networks to model, estimate, and simulate a broad class of arrival processes with general nonstationary and multidimensional random arrival rates. Classic Monte Carlo simulators have advantages in capturing the interpretable “physics” of a stochastic object, whereas neural network–based simulators have advantages in capturing less interpretable complicated dependence within a high-dimensional distribution. We propose a doubly stochastic simulator that integrates a stochastic generative neural network and a classic Monte Carlo Poisson simulator to utilize the advantages of both. Such integration brings challenges to both theoretical reliability and computational tractability for the estimation of the simulator given real data, in which the estimation is done through minimizing the Wasserstein distance between the distribution of the simulation output and of real data. Regarding theoretical properties, we prove consistency and convergence rate for the estimated simulator under a nonparametric smoothness assumption. Regarding computational efficiency and tractability for the estimation procedure, we address a challenge in gradient evaluation that arises from the discontinuity in the Monte Carlo Poisson simulator. Numerical experiments with synthetic and real data sets are implemented to illustrate the performance of the proposed framework. Supplemental Material: The electronic companion is available at https://doi.org/10.1287/opre.2021.0597 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0597},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {910-926},
  shortjournal = {Oper. Res.},
  title        = {A doubly stochastic simulator with applications in arrivals modeling and simulation},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning and optimization with seasonal patterns.
<em>OR</em>, <em>73</em>(2), 894–909. (<a
href="https://doi.org/10.1287/opre.2023.0017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A standard assumption adopted in the multiarmed bandit (MAB) framework is that the mean rewards are constant over time. This assumption can be restrictive in the business world as decision makers often face an evolving environment in which the mean rewards are time-varying. In this paper, we consider a nonstationary MAB model with K arms whose mean rewards vary over time in a periodic manner. The unknown periods can be different across arms and scale with the length of the horizon T polynomially. We propose a two-stage policy that combines the Fourier analysis with a confidence bound–based learning procedure to learn the periods and minimize the regret. In stage one, the policy correctly estimates the periods of all arms with high probability. In stage two, the policy explores the periodic mean rewards of arms using the periods estimated in stage one and exploits the optimal arm in the long run. We show that our learning policy incurs a regret upper bound O ˜ ( T ∑ k = 1 K T k ) , where T k is the period of arm k . Moreover, we establish a general lower bound Ω ( T max k { T k } ) for any policy. Therefore, our policy is near optimal up to a factor of K . Funding: The research of N. Chen is partly supported by the Natural Sciences and Engineering Research Council of Canada [Discovery Grant RGPIN-2020-04038]. C. Wang acknowledges support from the National Natural Science Foundation of China [Grants 72293561 and 71802115] and the Tsinghua University Initiative Scientific Research Program. Supplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2023.0017 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0017},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {894-909},
  shortjournal = {Oper. Res.},
  title        = {Learning and optimization with seasonal patterns},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multivariate almost stochastic dominance: Transfer
characterizations and sufficient conditions under dependence
uncertainty. <em>OR</em>, <em>73</em>(2), 879–893. (<a
href="https://doi.org/10.1287/opre.2022.0596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most often, important decisions involve several unknown attributes. This produces a double challenge in the sense that both assessing the individual multiattribute preferences and assessing the joint distribution of the attributes can be extremely hard. To handle the first challenge, we suggest multivariate almost stochastic dominance, a relation based on bounding marginal utilities. We provide necessary and sufficient characterizations in terms of simple transfers, which are easily communicated to decision makers and, thus, can be used for preference elicitation. To handle the second challenge, we develop sufficient conditions that do not consider the dependence structure and are based on either marginal distributions of the attributes or just their means and variances. We apply the theoretical results to a case study of comparing the efficiency of photovoltaic plants. Funding: M. Scarsini is a member of Gruppo Nazionale per l’Analisi Matematica, la Probabilità, e le loro Applicazioni-Istituto Nazionale di Alta Matematica Francesco Severi (GNAMPA-INdAM). His work was partially supported by GNAMPA-INdAM (Project CUP_E53C22001930001 “Limiting behavior of stochastic dynamics in the Schelling segregation model”) and the Italian Ministry of Education, Universities, and Research (Research Projects of National Interest 2017 Project ALGADIMAR “Algorithms, Games, and Digital Markets”). Supplemental Material: The online companion is available at https://doi.org/10.1287/opre.2022.0596 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0596},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {879-893},
  shortjournal = {Oper. Res.},
  title        = {Multivariate almost stochastic dominance: Transfer characterizations and sufficient conditions under dependence uncertainty},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified theory of robust and distributionally robust
optimization via the primal-worst-equals-dual-best principle.
<em>OR</em>, <em>73</em>(2), 862–878. (<a
href="https://doi.org/10.1287/opre.2021.0268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust optimization and distributionally robust optimization are modeling paradigms for decision making under uncertainty where the uncertain parameters are only known to reside in an uncertainty set or are governed by any probability distribution from within an ambiguity set, respectively, and a decision is sought that minimizes a cost function under the most adverse outcome of the uncertainty. In this paper, we develop a rigorous and general theory of robust and distributionally robust nonlinear optimization using the language of convex analysis. Our framework is based on a generalized “primal-worst-equals-dual-best” principle that establishes strong duality between a semi-infinite primal worst and a nonconvex dual best formulation, both of which admit finite convex reformulations. This principle offers an alternative formulation for robust optimization problems that obviates the need to mobilize the machinery of abstract semi-infinite duality theory to prove strong duality in distributionally robust optimization. We illustrate the modeling power of our approach through convex reformulations for distributionally robust optimization problems whose ambiguity sets are defined through general optimal transport distances, which generalize earlier results for Wasserstein ambiguity sets. Funding: This research was supported by the Swiss National Science Foundation [NCCR Automation Grant 51NF40_180545] and the Engineering and Physical Sciences Research Council [Grant EP/R045518/1]. Supplemental Material: The e-companion is available at https://doi.org/10.1287/opre.2021.0268 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0268},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {862-878},
  shortjournal = {Oper. Res.},
  title        = {A unified theory of robust and distributionally robust optimization via the primal-worst-equals-dual-best principle},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved decision rule approximations for multistage robust
optimization via copositive programming. <em>OR</em>, <em>73</em>(2),
842–861. (<a href="https://doi.org/10.1287/opre.2018.0505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study decision rule approximations for generic multistage robust linear optimization problems. We examine linear decision rules for the case when the objective coefficients, the recourse matrices, and the right-hand sides are uncertain, and we explore quadratic decision rules for the case when only the right-hand sides are uncertain. The resulting optimization problems are NP hard but amenable to copositive programming reformulations that give rise to tight, tractable semidefinite programming solution approaches. We further enhance these approximations through new piecewise decision rule schemes. Finally, we prove that our proposed approximations are tighter than the state-of-the-art schemes and demonstrate their superiority through numerical experiments. Funding: G. A. Hanasusanto was supported by the National Science Foundation [Grants 1752125 and 2153606]. Supplemental Material: The e-companion is available at https://doi.org/10.1287/opre.2018.0505 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2018.0505},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {842-861},
  shortjournal = {Oper. Res.},
  title        = {Improved decision rule approximations for multistage robust optimization via copositive programming},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Technical note—a data-driven approach to beating SAA out of
sample. <em>OR</em>, <em>73</em>(2), 829–841. (<a
href="https://doi.org/10.1287/opre.2021.0393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whereas solutions of distributionally robust optimization (DRO) problems can sometimes have a higher out-of-sample expected reward than the sample average approximation (SAA), there is no guarantee. In this paper, we introduce a class of distributionally optimistic optimization (DOO) models and show that it is always possible to “beat” SAA out-of-sample if we consider not just worst case (DRO) models but also best case (DOO) ones. We also show, however, that this comes at a cost: optimistic solutions are more sensitive to model error than either worst case or SAA optimizers and, hence, are less robust, and calibrating the worst or best case model to outperform SAA may be difficult when data are limited. Funding: J. Gotoh is supported in part by the Japan Society for the Promotion of Science [Grant 20H00285]. M. J. Kim is supported in part by the Natural Sciences and Engineering Research Council of Canada [Discovery Grant RGPIN-2015-04019]. A. E. B. Lim is supported by the Ministry of Education, Singapore, under its 2021 Academic Research Fund Tier 2 grant call [Grant MOE-T2EP20121-0014]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2021.0393 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0393},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {829-841},
  shortjournal = {Oper. Res.},
  title        = {Technical Note—A data-driven approach to beating SAA out of sample},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Technical note—on adaptivity in nonstationary stochastic
optimization with bandit feedback. <em>OR</em>, <em>73</em>(2), 819–828.
(<a href="https://doi.org/10.1287/opre.2022.0576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the nonstationary stochastic optimization problem with bandit feedback and dynamic regret measures. The seminal work of Besbes et al. (2015) shows that, when aggregated function changes are known a priori, a simple restarting algorithm attains the optimal dynamic regret. In this work, we design a stochastic optimization algorithm with fixed step sizes, which, combined with the multiscale sampling framework in existing research, achieves the optimal dynamic regret in nonstationary stochastic optimization without prior knowledge of function changing budget, thereby closing a question that has been open for a while. We also establish an additional result showing that any algorithm achieving good regret against stationary benchmarks with high probability could be automatically converted to an algorithm that achieves good regret against dynamic benchmarks (for problems that admit O ˜ ( T ) regret against stationary benchmarks in fully adversarial settings, a dynamic regret of O ˜ ( V T 1 / 3 T 2 / 3 ) is expected), which is potentially applicable to a wide class of bandit convex optimization and other types of bandit algorithms.},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0576},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {819-828},
  shortjournal = {Oper. Res.},
  title        = {Technical Note—On adaptivity in nonstationary stochastic optimization with bandit feedback},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic online fisher markets: Static pricing limits and
adaptive enhancements. <em>OR</em>, <em>73</em>(2), 798–818. (<a
href="https://doi.org/10.1287/opre.2023.0636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fisher markets are one of the most fundamental models for resource allocation. However, the problem of computing equilibrium prices in Fisher markets typically relies on complete knowledge of users’ budgets and utility functions and requires transactions to happen in a static market where all users are present simultaneously. Motivated by these practical considerations, we study an online variant of Fisher markets, wherein users with privately known utility and budget parameters, drawn independently and identically (i.i.d.) from a distribution, arrive sequentially. In this setting, we first study the limitations of static pricing algorithms, which set uniform prices for all users, along two performance metrics: (i) regret, that is, the optimality gap in the objective of the Eisenberg-Gale program between an online algorithm and an oracle with complete information, and (ii) capacity violations, that is, the overconsumption of goods relative to their capacities. Given the limitations of static pricing, we design adaptive posted-pricing algorithms, one with knowledge of the distribution of users’ budget and utility parameters and another that adjusts prices solely based on past observations of user consumption, that is, revealed preference feedback, with improved performance guarantees. Finally, we present numerical experiments to compare our revealed preference algorithm’s performance to several benchmarks. Funding: This work was supported by the Stanford Interdisciplinary Graduate Fellowship. Supplemental Material: All supplemental materials, including the computer code and data that support the findings of this study, are available at https://doi.org/10.1287/opre.2023.0636 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0636},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {798-818},
  shortjournal = {Oper. Res.},
  title        = {Stochastic online fisher markets: Static pricing limits and adaptive enhancements},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal fairness in learning and earning: Price protection
guarantee and phase transitions. <em>OR</em>, <em>73</em>(2), 775–797.
(<a href="https://doi.org/10.1287/opre.2022.0629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the prevalence of price protection guarantee which helps to promote temporal fairness in dynamic pricing, we study the impact of such policy on the design of online learning algorithms for data-driven dynamic pricing with initially unknown customer demand. Under the price protection guarantee, a customer who purchased a product in the past can receive a refund from the seller during the so-called price protection period (typically defined as a certain time window after the purchase date) in case the seller decides to lower the price. We consider a setting where a firm sells a product over a horizon of T time steps. For this setting, we characterize how the value of M , the length of the price protection period, can affect the optimal regret of the learning process. We derive the optimal regret by first establishing a fundamental impossible regime with the novel refund-aware regret lower bound analysis. Then, we propose LEAP , a phased exploration type algorithm for Learning and EArning under Price Protection, to match this lower bound up to logarithmic factors or even doubly logarithmic factors (when there are only two prices available to the seller). Our results reveal the surprising phase transitions of the optimal regret with respect to M . Specifically, when M is not too large, the optimal regret has no major difference when compared with that of the classic setting with no price protection guarantee. In addition, there also exists an upper limit on how much the optimal regret can deteriorate when M grows large. Finally, we conduct extensive numerical simulations with both synthetic and real-world data sets to show the benefit of LEAP over other heuristic methods for this problem. The numerical results suggest that under certain realistic assumptions, it is indeed beneficial for the seller to set a longer price protection period. Supplemental Material: The computer code and data that support the findings of this study are available within this article’s supplemental material at https://doi.org/10.1287/opre.2022.0629 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0629},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {775-797},
  shortjournal = {Oper. Res.},
  title        = {Temporal fairness in learning and earning: Price protection guarantee and phase transitions},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Political districting to minimize county splits.
<em>OR</em>, <em>73</em>(2), 752–774. (<a
href="https://doi.org/10.1287/opre.2023.0094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When partitioning a state into political districts, a common criterion is that political subdivisions, like counties, should not be split across multiple districts. This criterion is encoded into most state constitutions and is sometimes enforced quite strictly by the courts. However, map drawers, courts, and the public typically do not know what amount of splitting is truly necessary, even to satisfy basic criteria, like contiguity and population balance. In this paper, we provide answers for all congressional, state senate, and state house districts in the United States using 2020 census data. Our approach is based on integer programming. The associated codes and experimental results are available on GitHub. Funding: This material is based upon work supported by the National Science Foundation [Grant 1942065]. Supplementary Material: All supplemental materials, including the computer code that supports the findings of this study, are available at https://doi.org/10.1287/opre.2023.0094 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0094},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {752-774},
  shortjournal = {Oper. Res.},
  title        = {Political districting to minimize county splits},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EFX: A simpler approach and an (almost) optimal guarantee
via rainbow cycle number. <em>OR</em>, <em>73</em>(2), 738–751. (<a
href="https://doi.org/10.1287/opre.2023.0433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existence of envy-freeness up to any good (EFX) allocations is a fundamental open problem in discrete fair division. The goal is to determine the existence of an allocation of a set of indivisible goods among n agents for which no agent envies another, following the removal of any single good from the other agent’s bundle. Because the general problem has been elusive, progress is made on two fronts: (i) proving existence when n is small and (ii) proving the existence of relaxations of EFX. In this paper, we improve and simplify the state-of-the-art results on both fronts with new techniques. For the case of three agents, the existence of EFX was first shown with additive valuations and then extended to nice-cancelable valuations. As our first main result, we simplify and improve this result by showing the existence of EFX allocations when two of the agents have general monotone valuations and one has a maximin share (MMS)–feasible valuation (a strict generalization of nice-cancelable valuation functions). Our approach is significantly simpler than the previous ones, and it also avoids using the standard concepts of envy graph and champion graph and may find use in other fair-division problems. Second, we consider approximate EFX allocations with few unallocated goods (charity). Through a promising new method using a problem in extremal combinatorics called rainbow cycle number (RCN), the existence of ( 1 − ϵ ) -EFX allocation with O ( ( n / ϵ ) 4 5 ) charity was established. This is done by upper bounding the RCN by O ( d 4 ) in d -dimension. They conjecture RCN to be O ( d ) . We almost settle this conjecture by improving the upper bound to O ( d log d ) and thereby get (almost) optimal charity of O ˜ ( ( n / ϵ ) 1 2 ) that is possible through this method. Our technique is much simpler than the previous ones and is based on the probabilistic method. Funding: This work was supported by the Division of Computing and Communication Foundations (B. R. Chaudhury, R. Mehta, J. Garg) [Grants CCF-1750436, CCF-1942321, CCF-2334461], the National Science Foundation (N. Alon) [Grant DMS-2154082], and the United States–Israel Binational Science Foundation (N. Alon) [Grant 2018267].},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0433},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {738-751},
  shortjournal = {Oper. Res.},
  title        = {EFX: A simpler approach and an (Almost) optimal guarantee via rainbow cycle number},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural estimation of markov decision processes in
high-dimensional state space with finite-time guarantees. <em>OR</em>,
<em>73</em>(2), 720–737. (<a
href="https://doi.org/10.1287/opre.2022.0511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the task of estimating a structural model of dynamic decisions by a human agent based on the observable history of implemented actions and visited states. This problem has an inherent nested structure: In the inner problem, an optimal policy for a given reward function is identified, whereas in the outer problem, a measure of fit is maximized. Several approaches have been proposed to alleviate the computational burden of this nested-loop structure, but these methods still suffer from high complexity when the state space is either discrete with large cardinality or continuous in high dimensions. Other approaches in the inverse reinforcement learning literature emphasize policy estimation at the expense of reduced reward estimation accuracy. In this paper, we propose a single-loop estimation algorithm with finite time guarantees that is equipped to deal with high-dimensional state spaces without compromising reward estimation accuracy. In the proposed algorithm, each policy improvement step is followed by a stochastic gradient step for likelihood maximization. We show the proposed algorithm converges to a stationary solution with a finite-time guarantee. Further, if the reward is parameterized linearly, the algorithm approximates the maximum likelihood estimator sublinearly. Funding: M. Hong and S. Zeng are supported by the National Science Foundation [Grants EPCN-2311007 and CCF-1910385]. This work is also part of AI-CLIMATE: “AI Institute for Climate-Land Interactions, Mitigation, Adaptation, Tradeoffs and Economy” and is supported by the U.S. Department of Agriculture National Institute of Food and Agriculture and the National Science Foundation National AI Research Institutes [Competitive Award 2023-67021-39829]. A. Garcia is partially supported by the Army Research Office [Grant W911NF-22-1-0213]. Supplemental Material: The computer code and data that support the findings of this study are available within this article’s supplemental material at https://doi.org/10.1287/opre.2022.0511 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0511},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {720-737},
  shortjournal = {Oper. Res.},
  title        = {Structural estimation of markov decision processes in high-dimensional state space with finite-time guarantees},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient algorithms for a class of stochastic hidden convex
optimization and its applications in network revenue management.
<em>OR</em>, <em>73</em>(2), 704–719. (<a
href="https://doi.org/10.1287/opre.2022.0216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a class of stochastic nonconvex optimization in the form of min x ∈ X F ( x ) ≔ E ξ [ f ( ϕ ( x , ξ ) ) ] , that is, F is a composition of a convex function f and a random function ϕ . Leveraging an (implicit) convex reformulation via a variable transformation u = E [ ϕ ( x , ξ ) ] , we develop stochastic gradient-based algorithms and establish their sample and gradient complexities for achieving an ϵ -global optimal solution. Interestingly, our proposed Mirror Stochastic Gradient (MSG) method operates only in the original x -space using gradient estimators of the original nonconvex objective F and achieves O ˜ ( ϵ − 2 ) complexities, matching the lower bounds for solving stochastic convex optimization problems. Under booking limits control, we formulate the air-cargo network revenue management (NRM) problem with random two-dimensional capacity, random consumption, and routing flexibility as a special case of the stochastic nonconvex optimization, where the random function ϕ ( x , ξ ) = x ∧ ξ , that is, the random demand ξ truncates the booking limit decision x . Extensive numerical experiments demonstrate the superior performance of our proposed MSG algorithm for booking limit control with higher revenue and lower computation cost than state-of-the-art bid-price-based control policies, especially when the variance of random capacity is large. Funding: This work was partly supported by the National Science Foundation [Grants CMMI-1761699, CRII-1755829], the ZJU-UIUC Institute Research Program, and NCCR Automation in Switzerland. Supplemental Material: The computer code and data that support the findings of this study are available within this article’s supplemental material at https://doi.org/10.1287/opre.2022.0216 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0216},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {704-719},
  shortjournal = {Oper. Res.},
  title        = {Efficient algorithms for a class of stochastic hidden convex optimization and its applications in network revenue management},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On (random-order) online contention resolution schemes for
the matching polytope of (bipartite) graphs. <em>OR</em>,
<em>73</em>(2), 689–703. (<a
href="https://doi.org/10.1287/opre.2023.0339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online Contention Resolution Schemes (OCRSs) represent a modern tool for selecting a subset of elements, subject to resource constraints, when the elements are presented to the algorithm sequentially. OCRSs have led to some of the best-known competitive ratio guarantees for online resource allocation problems, with the added benefit of treating different online decisions—accept/reject, probing, pricing—in a unified manner. This paper analyzes OCRSs for resource constraints defined by matchings in graphs, a fundamental structure in combinatorial optimization. We consider two dimensions of variants: the elements being presented in adversarial or random order; and the graph being bipartite or general. We improve the state of the art for all combinations of variants, both in terms of algorithmic guarantees and impossibility results. Some of our algorithmic guarantees are best-known, even compared with Contention Resolution Schemes that can choose the order of arrival or are offline. All in all, our results for OCRSs directly improve the best-known competitive ratios for online accept/reject, probing, and pricing problems on graphs in a unified manner. Supplemental Material: The computer code and data that support the findings of this study are available within this article’s supplemental material at https://doi.org/10.1287/opre.2023.0339 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0339},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {689-703},
  shortjournal = {Oper. Res.},
  title        = {On (Random-order) online contention resolution schemes for the matching polytope of (Bipartite) graphs},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ordinary and prophet planning under uncertainty in bernoulli
congestion games. <em>OR</em>, <em>73</em>(2), 672–688. (<a
href="https://doi.org/10.1287/opre.2023.0252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider an atomic congestion game in which each player i participates in the game with an exogenous and known probability p i ∈ ( 0 , 1 ] , independently of everybody else, or stays out and incurs no cost. We compute the parameterized price of anarchy to characterize the impact of demand uncertainty on the efficiency of selfish behavior, considering two different notions of a social planner. A prophet planner knows the realization of the random participation in the game; the ordinary planner does not. As a consequence, a prophet planner can compute an adaptive social optimum that selects different solutions depending on the players who turn out to be active, whereas an ordinary planner faces the same uncertainty as the players and can only minimize the expected social cost according to the player participation distribution. For both types of planners, we obtain tight bounds for the price of anarchy by solving suitable optimization problems parameterized by the maximum participation probability q = max i p i . In the case of affine costs, we find an analytic expression for the corresponding bounds. Funding: The research of R. Cominetti was supported by Fondo Nacional de Desarrollo Científico y Tecnológico [Grants 1171501 and ANID/PIA/ACT192094]. M. Scarsini gratefully acknowledges the support and hospitality of Fondo Nacional de Desarrollo Científico y Tecnológico [Grant 1130564] and Núcleo Milenio “Información y Coordinación en Redes.” The research of M. Scarsini was supported by the Gruppo Nazionale per l’Analisi Matematica, la Probabilità e le loro Applicazioni [Grant CUP_E53C22001930001], the Ministero dell’Università e della Ricerca [Grants PRIN 2017 ALGADIMAR and PRIN 2022 2022EKNE5K], and the European Union–Next Generation EU, Component M4C2, Investment 1.1 [Grant PRIN PNRR P2022XT8C8]. This work was also supported by European Cooperation in Science and Technology [Grant CA16228 GAMENET]. Supplemental Material: The computer code and data that support the findings of this study are available within this article’s supplemental material at https://doi.org/10.1287/opre.2023.0252 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0252},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {672-688},
  shortjournal = {Oper. Res.},
  title        = {Ordinary and prophet planning under uncertainty in bernoulli congestion games},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Asymptotically tight bounds on the optimal pricing strategy
with patient customers. <em>OR</em>, <em>73</em>(2), 664–671. (<a
href="https://doi.org/10.1287/opre.2021.0459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work considers a monopolist seller facing both patient and impatient customers. Given the current price, the impatient customers will either purchase or leave immediately, depending on the relative magnitude between this price and their valuation of the product. In comparison, the patient customers will wait for some periods to see if the price will drop to their valuation, and if that occurs, they will purchase immediately. The monopolist designs the pricing strategy to maximize the long-run average revenue from them. We give tight bounds on both the optimal strategy’s cycle period and the optimal revenue when the patient customers possess a high patience level. This result answers the open question of the optimal cycle period raised by extant work. Later we also extend our theoretical result to the general case with multiple patience levels. Funding: C. Zhou is supported in part by NSFC [Grant 11871364] and IoTeX Foundation Industry [Grant A-8001180-00-00]. Supplemental Material: The computer code and data that support the findings of this study are available within this article’s supplemental material at https://doi.org/10.1287/opre.2021.0459 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0459},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {664-671},
  shortjournal = {Oper. Res.},
  title        = {Asymptotically tight bounds on the optimal pricing strategy with patient customers},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalization guarantees for multi-item profit
maximization: Pricing, auctions, and randomized mechanisms. <em>OR</em>,
<em>73</em>(2), 648–663. (<a
href="https://doi.org/10.1287/opre.2021.0026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study multi-item profit maximization when there is an underlying distribution over buyers’ values. In practice, a full description of the distribution is typically unavailable, so we study the setting where the mechanism designer only has samples from the distribution. If the designer uses the samples to optimize over a complex mechanism class—such as the set of all multi-item, multibuyer mechanisms—a mechanism may have high average profit over the samples, but low expected profit. This raises the central question of this paper: How many samples are sufficient to ensure that a mechanism’s average profit is close to its expected profit? To answer this question, we uncover structure shared by many pricing, auction, and lottery mechanisms: For any set of buyers’ values, profit is piecewise linear in the mechanism’s parameters. Using this structure, we prove new bounds for mechanism classes not yet studied in the sample-based mechanism design literature and match or improve over the best-known guarantees for many classes. Finally, we provide tools for optimizing an important tradeoff: More complex mechanisms typically have higher average profit over the samples than simpler mechanisms, but more samples are required to ensure that average profit nearly matches expected profit. Funding: This material is based on work supported by the National Science Foundation [Grants CCF-1422910, CCF-1535967, CCF-1733556, CCF-1910321, IIS-1617590, IIS-1618714, IIS-1718457, IIS-1901403, RI-2312342, SES-1919453 and a Graduate Research Fellowship]; the Army Research Office [Awards W911NF2010081, W911NF1710082, and W911NF2210266]; Office of Naval Research [Award N00014-23-1-2876]; the Defense Advanced Research Projects Agency [Cooperative Agreement HR00112020003]; Vannevar Bush Faculty Fellowship; an Amazon [Research Award]; a Microsoft Research [Faculty Fellowship]; an Amazon Web Services [Machine Learning Research Award]; a Bloomberg [Data Science research grant]; an International Business Machines Corporation [PhD Fellowship]; and a fellowship from Carnegie Mellon University&#39;s Center for Machine Learning and Health. Supplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2021.0026 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0026},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {648-663},
  shortjournal = {Oper. Res.},
  title        = {Generalization guarantees for multi-item profit maximization: Pricing, auctions, and randomized mechanisms},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monetizing positive externalities to mitigate the
infrastructure underinvestment problem. <em>OR</em>, <em>73</em>(2),
632–647. (<a href="https://doi.org/10.1287/opre.2023.0075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many cities face challenges in financing their infrastructure. If a decision maker cannot capture all the benefits of its investment, there is a risk of underinvestment. Hong Kong’s transit operator designed a scheme in which it not only receives fare revenues, but also participates in a property management business, exploiting the positive externalities of public transport on nearby property prices. We develop a stochastic Stackelberg game of timing to explore the rationale of this scheme. The underlying problem is nontrivial because the operator faces a two-dimensional optimal stopping problem that cannot be reduced by a change of numéraire. We determine the operator’s optimal investment policy via the intermediation of a “penalized problem” and derive comparative statics. We determine the circumstances under which monetizing positive externalities effectively favors infrastructure investment. Other management problems have similar structures. Funding: This work was supported by the National Science Foundation [Grant NSF-DMS 220 4795]. Supplemental Material: All supplemental materials, including the computer code and data that support the findings of this study, are available at https://doi.org/10.1287/opre.2023.0075 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0075},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {632-647},
  shortjournal = {Oper. Res.},
  title        = {Monetizing positive externalities to mitigate the infrastructure underinvestment problem},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Budget-driven multiperiod hub location: A robust time-series
approach. <em>OR</em>, <em>73</em>(2), 613–631. (<a
href="https://doi.org/10.1287/opre.2022.0319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the (un)capacitated multiperiod hub location problem with uncertain periodic demands. With a distributionally robust approach that considers time series, we build a model driven by budgets on periodic costs. In particular, we construct a nested ambiguity set that characterizes uncertain periodic demands via a general multivariate time-series model, and to ensure stable periodic costs, we propose to constrain each expected periodic cost within a budget whereas optimizing the robustness level by maximizing the size of the nested ambiguity set. Statistically, the nested ambiguity set ensures that the model’s solution enjoys finite-sample performance guarantees under certain regularity conditions on the underlying VAR( p ) or VARMA( p , q ) process of the stochastic demand. Operationally, we show that our budget-driven model in the uncapacitated case essentially optimizes a “Sharpe ratio”–type criterion over the worst case among all periods, and we discuss how cost budgets would affect the optimal robustness level. Computationally, the uncapacitated model can be efficiently solved via a bisection search algorithm that solves (in each iteration) a mixed-integer conic program, whereas the capacitated model can be approximated by using decision rules. Finally, numerical experiments demonstrate the attractiveness and competitiveness of our proposed model. Funding: Z. Chen is funded in part by the Hong Kong Research Grants Council General Research Fund [CUHK-11507223] and the National Natural Science Foundation of China [72394395, 72422002]. S. Wang is supported by the National Natural Science Foundation of China [Grants 72471224, 72171221, 71922020, and 71988101], the Fundamental Research Funds for the Central Universities [Grant UCAS-E2ET0808X2], and a grant from MOE Social Science Laboratory of Digital Economic Forecasts and Policy Simulation at UCAS. J. Hu is supported by the National Natural Science Foundation of China [Grants 72192843 and 71872171]. Supplemental Material: All supplemental materials, including the code, data, and files required to reproduce the results, were reviewed and are available at https://doi.org/10.1287/opre.2022.0319 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0319},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {613-631},
  shortjournal = {Oper. Res.},
  title        = {Budget-driven multiperiod hub location: A robust time-series approach},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust workforce management with crowdsourced delivery.
<em>OR</em>, <em>73</em>(2), 595–612. (<a
href="https://doi.org/10.1287/opre.2023.0125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate how crowdsourced delivery platforms with both contracted and ad hoc couriers can effectively manage their workforce to meet delivery demands amidst uncertainties. Our objective is to minimize the hiring costs of contracted couriers and the crowdsourcing costs of ad hoc couriers, while considering the uncertain availability and behavior of the latter. Because of the complication of calibrating these uncertainties through data-driven approaches, we instead introduce a basic reduced information model to estimate the upper bound of the crowdsourcing cost and a generalized reduced information model to obtain a tighter bound. Subsequently, we formulate a robust satisficing model associated with the generalized reduced information model and show that a binary search algorithm can tackle the model exactly by solving a modest number of convex optimization problems. Our numerical tests using Solomon’s data sets show that reduced information models provide decent approximations for practical delivery scenarios. Simulation tests further demonstrate that the robust satisficing model has better out-of-sample performance than the empirical optimization model that minimizes the total cost under historical scenarios. Funding: C. Cheng was supported by the National Natural Science Foundation of China [Grants 72471042, 72101049, and 72232001] and the Fundamental Research Funds for the Central Universities [Grant DUT23RC(3)045]. M. Sim and Y. Zhao were supported by the Ministry of Education, Singapore, under its 2019 Academic Research Fund Tier 3 [Grant MOE-2019-T3-1-010]. Supplemental Material: All supplemental materials, including the computer code and data that support the findings of this study, are available at https://doi.org/10.1287/opre.2023.0125 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0125},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {595-612},
  shortjournal = {Oper. Res.},
  title        = {Robust workforce management with crowdsourced delivery},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Search for an immobile hider on a binary tree with
unreliable locational information. <em>OR</em>, <em>73</em>(2), 583–594.
(<a href="https://doi.org/10.1287/opre.2023.0128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial search of a network for an immobile Hider (or target) was introduced and solved for rooted trees by Shmuel Gal in 1979. In this zero-sum game, a Hider picks a point to hide on the tree and a Searcher picks a unit speed trajectory starting at the root. The payoff (to the Hider) is the search time. In Gal’s model (and many subsequent investigations), the Searcher receives no additional information after the Hider chooses his location. In reality, the Searcher will often receive such locational information. For homeland security, mobile sensors on vehicles have been used to locate radioactive material stashed in an urban environment. In a military setting, mobile sensors can detect chemical signatures from land mines. In predator-prey search, the predator often has specially attuned senses (hearing for wolves, vision for eagles, smell for dogs, sonar for bats, pressure sensors for sharks) that may help it locate the prey. How can such noisy locational information be used by the Searcher to modify her route? We model such information as signals which indicate which of two branches of a binary tree should be searched first, where all signals have a known accuracy p &lt; 1. Our solution calculates which branch (at every branch node) is favored , meaning it should always be searched first when the signal is in that direction. When the signal is in the other direction, we calculate the probability the signal should be followed. Compared with the optimal Hider strategy in the classic search game of Gal, the Hider’s optimal distribution for this model is more skewed toward leaf nodes that are further from the root. Funding: This work was supported by the Air Force Office of Scientific Research [Grant FA9550-23-1-0556]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2023.0128 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0128},
  journal      = {Operations Research},
  month        = {3-4},
  number       = {2},
  pages        = {583-594},
  shortjournal = {Oper. Res.},
  title        = {Search for an immobile hider on a binary tree with unreliable locational information},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
